title,summary,published,authors,pdf_url,category
Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models,"In this work, we investigate whether small language models can determine
high-quality subsets of large-scale text datasets that improve the performance
of larger language models. While existing work has shown that pruning based on
the perplexity of a larger model can yield high-quality data, we investigate
whether smaller models can be used for perplexity-based pruning and how pruning
is affected by the domain composition of the data being pruned. We demonstrate
that for multiple dataset compositions, perplexity-based pruning of pretraining
data can \emph{significantly} improve downstream task performance: pruning
based on perplexities computed with a 125 million parameter model improves the
average performance on downstream tasks of a 3 billion parameter model by up to
2.04 and achieves up to a $1.45\times$ reduction in pretraining steps to reach
commensurate baseline performance. Furthermore, we demonstrate that such
perplexity-based data pruning also yields downstream performance gains in the
over-trained and data-constrained regimes.",2024-05-30,"Zachary Ankner, Cody Blakeney, Kartik Sreenivasan, Max Marion, Matthew L. Leavitt, Mansheej Paul",http://arxiv.org/pdf/2405.20541v1,cs.CL
Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning,"Instruction Fine-Tuning (IFT) significantly enhances the zero-shot
capabilities of pretrained Large Language Models (LLMs). While coding data is
known to boost LLM reasoning abilities during pretraining, its role in
activating internal reasoning capacities during IFT remains understudied. This
paper investigates a key question: How does coding data impact LLMs' reasoning
capacities during IFT stage? To explore this, we thoroughly examine the impact
of coding data across different coding data proportions, model families, sizes,
and reasoning domains, from various perspectives. Specifically, we create three
IFT datasets with increasing coding data proportions, fine-tune six LLM
backbones across different families and scales on these datasets, evaluate the
tuned models' performance across twelve tasks in three reasoning domains, and
analyze the outcomes from three broad-to-granular perspectives: overall,
domain-level, and task-specific. Our holistic analysis provides valuable
insights into each perspective. First, coding data tuning enhances the overall
reasoning capabilities of LLMs across different model families and scales.
Moreover, while the impact of coding data varies by domain, it shows consistent
trends within each domain across different model families and scales.
Additionally, coding data generally provides comparable task-specific benefits
across model families, with optimal proportions in IFT datasets being
task-dependent.",2024-05-30,"Xinlu Zhang, Zhiyu Zoey Chen, Xi Ye, Xianjun Yang, Lichang Chen, William Yang Wang, Linda Ruth Petzold",http://arxiv.org/pdf/2405.20535v2,cs.CL
An Automatic Question Usability Evaluation Toolkit,"Evaluating multiple-choice questions (MCQs) involves either labor intensive
human assessments or automated methods that prioritize readability, often
overlooking deeper question design flaws. To address this issue, we introduce
the Scalable Automatic Question Usability Evaluation Toolkit (SAQUET), an
open-source tool that leverages the Item-Writing Flaws (IWF) rubric for a
comprehensive and automated quality evaluation of MCQs. By harnessing the
latest in large language models such as GPT-4, advanced word embeddings, and
Transformers designed to analyze textual complexity, SAQUET effectively
pinpoints and assesses a wide array of flaws in MCQs. We first demonstrate the
discrepancy between commonly used automated evaluation metrics and the human
assessment of MCQ quality. Then we evaluate SAQUET on a diverse dataset of MCQs
across the five domains of Chemistry, Statistics, Computer Science, Humanities,
and Healthcare, showing how it effectively distinguishes between flawed and
flawless questions, providing a level of analysis beyond what is achievable
with traditional metrics. With an accuracy rate of over 94% in detecting the
presence of flaws identified by human evaluators, our findings emphasize the
limitations of existing evaluation methods and showcase potential in improving
the quality of educational assessments.",2024-05-30,"Steven Moore, Eamon Costello, Huy A. Nguyen, John Stamper",http://arxiv.org/pdf/2405.20529v1,cs.CL
Towards Ontology-Enhanced Representation Learning for Large Language Models,"Taking advantage of the widespread use of ontologies to organise and
harmonize knowledge across several distinct domains, this paper proposes a
novel approach to improve an embedding-Large Language Model (embedding-LLM) of
interest by infusing the knowledge formalized by a reference ontology:
ontological knowledge infusion aims at boosting the ability of the considered
LLM to effectively model the knowledge domain described by the infused
ontology. The linguistic information (i.e. concept synonyms and descriptions)
and structural information (i.e. is-a relations) formalized by the ontology are
utilized to compile a comprehensive set of concept definitions, with the
assistance of a powerful generative LLM (i.e. GPT-3.5-turbo). These concept
definitions are then employed to fine-tune the target embedding-LLM using a
contrastive learning framework. To demonstrate and evaluate the proposed
approach, we utilize the biomedical disease ontology MONDO. The results show
that embedding-LLMs enhanced by ontological disease knowledge exhibit an
improved capability to effectively evaluate the similarity of in-domain
sentences from biomedical documents mentioning diseases, without compromising
their out-of-domain performance.",2024-05-30,"Francesco Ronzano, Jay Nanavati",http://arxiv.org/pdf/2405.20527v1,cs.CL
Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions,"Knowledge Components (KCs) linked to assessments enhance the measurement of
student learning, enrich analytics, and facilitate adaptivity. However,
generating and linking KCs to assessment items requires significant effort and
domain-specific knowledge. To streamline this process for higher-education
courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs)
in Chemistry and E-Learning. We analyzed discrepancies between the KCs
generated by the Large Language Model (LLM) and those made by humans through
evaluation from three domain experts in each subject area. This evaluation
aimed to determine whether, in instances of non-matching KCs, evaluators showed
a preference for the LLM-generated KCs over their human-created counterparts.
We also developed an ontology induction algorithm to cluster questions that
assess similar KCs based on their content. Our most effective LLM strategy
accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with
even higher success when considering the top five KC suggestions. Human
evaluators favored LLM-generated KCs, choosing them over human-assigned ones
approximately two-thirds of the time, a preference that was statistically
significant across both domains. Our clustering algorithm successfully grouped
questions by their underlying KCs without needing explicit labels or contextual
information. This research advances the automation of KC generation and
classification for assessment items, alleviating the need for student data or
predefined KC labels.",2024-05-30,"Steven Moore, Robin Schmucker, Tom Mitchell, John Stamper",http://arxiv.org/pdf/2405.20526v1,cs.CL
How Multilingual Are Large Language Models Fine-Tuned for Translation?,"A new paradigm for machine translation has recently emerged: fine-tuning
large language models (LLM) on parallel text has been shown to outperform
dedicated translation systems trained in a supervised fashion on much larger
amounts of parallel data (Xu et al., 2024a; Alves et al., 2024). However, it
remains unclear whether this paradigm can enable massively multilingual machine
translation or whether it requires fine-tuning dedicated models for a small
number of language pairs. How does translation fine-tuning impact the MT
capabilities of LLMs for zero-shot languages, zero-shot language pairs, and
translation tasks that do not involve English? To address these questions, we
conduct an extensive empirical evaluation of the translation quality of the
TOWER family of language models (Alves et al., 2024) on 132 translation tasks
from the multi-parallel FLORES-200 data. We find that translation fine-tuning
improves translation quality even for zero-shot languages on average, but that
the impact is uneven depending on the language pairs involved. These results
call for further research to effectively enable massively multilingual
translation with LLMs.",2024-05-30,"Aquia Richburg, Marine Carpuat",http://arxiv.org/pdf/2405.20512v1,cs.CL
SPOT: Text Source Prediction from Originality Score Thresholding,"The wide acceptance of large language models (LLMs) has unlocked new
applications and social risks. Popular countermeasures aim at detecting
misinformation, usually involve domain specific models trained to recognize the
relevance of any information. Instead of evaluating the validity of the
information, we propose to investigate LLM generated text from the perspective
of trust. In this study, we define trust as the ability to know if an input
text was generated by a LLM or a human. To do so, we design SPOT, an efficient
method, that classifies the source of any, standalone, text input based on
originality score. This score is derived from the prediction of a given LLM to
detect other LLMs. We empirically demonstrate the robustness of the method to
the architecture, training data, evaluation data, task and compression of
modern LLMs.",2024-05-30,"Edouard Yvinec, Gabriel Kasser",http://arxiv.org/pdf/2405.20505v1,cs.CL
Deep Learning Approaches for Detecting Adversarial Cyberbullying and Hate Speech in Social Networks,"Cyberbullying is a significant concern intricately linked to technology that
can find resolution through technological means. Despite its prevalence,
technology also provides solutions to mitigate cyberbullying. To address
growing concerns regarding the adverse impact of cyberbullying on individuals'
online experiences, various online platforms and researchers are actively
adopting measures to enhance the safety of digital environments. While
researchers persist in crafting detection models to counteract or minimize
cyberbullying, malicious actors are deploying adversarial techniques to
circumvent these detection methods. This paper focuses on detecting
cyberbullying in adversarial attack content within social networking site text
data, specifically emphasizing hate speech. Utilizing a deep learning-based
approach with a correction algorithm, this paper yielded significant results.
An LSTM model with a fixed epoch of 100 demonstrated remarkable performance,
achieving high accuracy, precision, recall, F1-score, and AUC-ROC scores of
87.57%, 88.73%, 87.57%, 88.15%, and 91% respectively. Additionally, the LSTM
model's performance surpassed that of previous studies.",2024-05-30,"Sylvia Worlali Azumah, Nelly Elsayed, Zag ElSayed, Murat Ozer, Amanda La Guardia",http://arxiv.org/pdf/2406.17793v1,cs.CL
Transfer Q Star: Principled Decoding for LLM Alignment,"Aligning foundation models is essential for their safe and trustworthy
deployment. However, traditional fine-tuning methods are computationally
intensive and require updating billions of model parameters. A promising
alternative, alignment via decoding, adjusts the response distribution directly
without model updates to maximize a target reward $r$, thus providing a
lightweight and adaptable framework for alignment. However, principled decoding
methods rely on oracle access to an optimal Q-function ($Q^*$), which is often
unavailable in practice. Hence, prior SoTA methods either approximate this
$Q^*$ using $Q^{\pi_{\texttt{sft}}}$ (derived from the reference $\texttt{SFT}$
model) or rely on short-term rewards, resulting in sub-optimal decoding
performance. In this work, we propose Transfer $Q^*$, which implicitly
estimates the optimal value function for a target reward $r$ through a baseline
model $\rho_{\texttt{BL}}$ aligned with a baseline reward $\rho_{\texttt{BL}}$
(which can be different from the target reward $r$). Theoretical analyses of
Transfer $Q^*$ provide a rigorous characterization of its optimality, deriving
an upper bound on the sub-optimality gap and identifying a hyperparameter to
control the deviation from the pre-trained reference $\texttt{SFT}$ model based
on user needs. Our approach significantly reduces the sub-optimality gap
observed in prior SoTA methods and demonstrates superior empirical performance
across key metrics such as coherence, diversity, and quality in extensive tests
on several synthetic and real datasets.",2024-05-30,"Souradip Chakraborty, Soumya Suvra Ghosal, Ming Yin, Dinesh Manocha, Mengdi Wang, Amrit Singh Bedi, Furong Huang",http://arxiv.org/pdf/2405.20495v1,cs.CL
Phantom: General Trigger Attacks on Retrieval Augmented Language Generation,"Retrieval Augmented Generation (RAG) expands the capabilities of modern large
language models (LLMs), by anchoring, adapting, and personalizing their
responses to the most relevant knowledge sources. It is particularly useful in
chatbot applications, allowing developers to customize LLM output without
expensive retraining. Despite their significant utility in various
applications, RAG systems present new security risks. In this work, we propose
new attack vectors that allow an adversary to inject a single malicious
document into a RAG system's knowledge base, and mount a backdoor poisoning
attack. We design Phantom, a general two-stage optimization framework against
RAG systems, that crafts a malicious poisoned document leading to an integrity
violation in the model's output. First, the document is constructed to be
retrieved only when a specific trigger sequence of tokens appears in the
victim's queries. Second, the document is further optimized with crafted
adversarial text that induces various adversarial objectives on the LLM output,
including refusal to answer, reputation damage, privacy violations, and harmful
behaviors. We demonstrate our attacks on multiple LLM architectures, including
Gemma, Vicuna, and Llama, and show that they transfer to GPT-3.5 Turbo and
GPT-4. Finally, we successfully conducted a Phantom attack on NVIDIA's
black-box production RAG system, ""Chat with RTX"".",2024-05-30,"Harsh Chaudhari, Giorgio Severi, John Abascal, Matthew Jagielski, Christopher A. Choquette-Choo, Milad Nasr, Cristina Nita-Rotaru, Alina Oprea",http://arxiv.org/pdf/2405.20485v2,cs.CL
Automated Focused Feedback Generation for Scientific Writing Assistance,"Scientific writing is a challenging task, particularly for novice researchers
who often rely on feedback from experienced peers. Recent work has primarily
focused on improving surface form and style rather than manuscript content. In
this paper, we propose a novel task: automated focused feedback generation for
scientific writing assistance. We present SWIF$^{2}$T: a Scientific WrIting
Focused Feedback Tool. It is designed to generate specific, actionable and
coherent comments, which identify weaknesses in a scientific paper and/or
propose revisions to it. Our approach consists of four components - planner,
investigator, reviewer and controller - leveraging multiple Large Language
Models (LLMs) to implement them. We compile a dataset of 300 peer reviews
citing weaknesses in scientific papers and conduct human evaluation. The
results demonstrate the superiority in specificity, reading comprehension, and
overall helpfulness of SWIF$^{2}$T's feedback compared to other approaches. In
our analysis, we also identified cases where automatically generated reviews
were judged better than human ones, suggesting opportunities for integration of
AI-generated feedback in scientific writing.",2024-05-30,"Eric Chamoun, Michael Schlichktrull, Andreas Vlachos",http://arxiv.org/pdf/2405.20477v2,cs.CL
MTEB-French: Resources for French Sentence Embedding Evaluation and Analysis,"Recently, numerous embedding models have been made available and widely used
for various NLP tasks. The Massive Text Embedding Benchmark (MTEB) has
primarily simplified the process of choosing a model that performs well for
several tasks in English, but extensions to other languages remain challenging.
This is why we expand MTEB to propose the first massive benchmark of sentence
embeddings for French. We gather 15 existing datasets in an easy-to-use
interface and create three new French datasets for a global evaluation of 8
task categories. We compare 51 carefully selected embedding models on a large
scale, conduct comprehensive statistical tests, and analyze the correlation
between model performance and many of their characteristics. We find out that
even if no model is the best on all tasks, large multilingual models
pre-trained on sentence similarity perform exceptionally well. Our work comes
with open-source code, new datasets and a public leaderboard.",2024-05-30,"Mathieu Ciancone, Imene Kerboua, Marion Schaeffer, Wissam Siblini",http://arxiv.org/pdf/2405.20468v2,cs.CL
Scalable Detection of Salient Entities in News Articles,"News articles typically mention numerous entities, a large fraction of which
are tangential to the story. Detecting the salience of entities in articles is
thus important to applications such as news search, analysis and summarization.
In this work, we explore new approaches for efficient and effective salient
entity detection by fine-tuning pretrained transformer models with
classification heads that use entity tags or contextualized entity
representations directly. Experiments show that these straightforward
techniques dramatically outperform prior work across datasets with varying
sizes and salience definitions. We also study knowledge distillation techniques
to effectively reduce the computational cost of these models without affecting
their accuracy. Finally, we conduct extensive analyses and ablation experiments
to characterize the behavior of the proposed models.",2024-05-30,"Eliyar Asgarieh, Kapil Thadani, Neil O'Hare",http://arxiv.org/pdf/2405.20461v1,cs.CL
Enhancing Antibiotic Stewardship using a Natural Language Approach for Better Feature Representation,"The rapid emergence of antibiotic-resistant bacteria is recognized as a
global healthcare crisis, undermining the efficacy of life-saving antibiotics.
This crisis is driven by the improper and overuse of antibiotics, which
escalates bacterial resistance. In response, this study explores the use of
clinical decision support systems, enhanced through the integration of
electronic health records (EHRs), to improve antibiotic stewardship. However,
EHR systems present numerous data-level challenges, complicating the effective
synthesis and utilization of data. In this work, we transform EHR data into a
serialized textual representation and employ pretrained foundation models to
demonstrate how this enhanced feature representation can aid in antibiotic
susceptibility predictions. Our results suggest that this text representation,
combined with foundation models, provides a valuable tool to increase
interpretability and support antibiotic stewardship efforts.",2024-05-30,"Simon A. Lee, Trevor Brokowski, Jeffrey N. Chiang",http://arxiv.org/pdf/2405.20419v1,cs.CL
Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters,"Large Language Models (LLMs) are typically harmless but remain vulnerable to
carefully crafted prompts known as ``jailbreaks'', which can bypass protective
measures and induce harmful behavior. Recent advancements in LLMs have
incorporated moderation guardrails that can filter outputs, which trigger
processing errors for certain malicious questions. Existing red-teaming
benchmarks often neglect to include questions that trigger moderation
guardrails, making it difficult to evaluate jailbreak effectiveness. To address
this issue, we introduce JAMBench, a harmful behavior benchmark designed to
trigger and evaluate moderation guardrails. JAMBench involves 160 manually
crafted instructions covering four major risk categories at multiple severity
levels. Furthermore, we propose a jailbreak method, JAM (Jailbreak Against
Moderation), designed to attack moderation guardrails using jailbreak prefixes
to bypass input-level filters and a fine-tuned shadow model functionally
equivalent to the guardrail model to generate cipher characters to bypass
output-level filters. Our extensive experiments on four LLMs demonstrate that
JAM achieves higher jailbreak success ($\sim$ $\times$ 19.88) and lower
filtered-out rates ($\sim$ $\times$ 1/6) than baselines.",2024-05-30,"Haibo Jin, Andy Zhou, Joe D. Menke, Haohan Wang",http://arxiv.org/pdf/2405.20413v1,cs.CL
SeamlessExpressiveLM: Speech Language Model for Expressive Speech-to-Speech Translation with Chain-of-Thought,"Expressive speech-to-speech translation (S2ST) is a key research topic in
seamless communication, which focuses on the preservation of semantics and
speaker vocal style in translated speech. Early works synthesized speaker style
aligned speech in order to directly learn the mapping from speech to target
speech spectrogram. Without reliance on style aligned data, recent studies
leverage the advances of language modeling (LM) and build cascaded LMs on
semantic and acoustic tokens. This work proposes SeamlessExpressiveLM, a single
speech language model for expressive S2ST. We decompose the complex
source-to-target speech mapping into intermediate generation steps with
chain-of-thought prompting. The model is first guided to translate target
semantic content and then transfer the speaker style to multi-stream acoustic
units. Evaluated on Spanish-to-English and Hungarian-to-English translations,
SeamlessExpressiveLM outperforms cascaded LMs in both semantic quality and
style transfer, meanwhile achieving better parameter efficiency.",2024-05-30,"Hongyu Gong, Bandhav Veluri",http://arxiv.org/pdf/2405.20410v1,cs.CL
Confidence-Aware Sub-Structure Beam Search (CABS): Mitigating Hallucination in Structured Data Generation with Large Language Models,"Large Language Models (LLMs) have facilitated structured data generation,
with applications in domains like tabular data, document databases, product
catalogs, etc. However, concerns persist about generation veracity due to
incorrect references or hallucinations, necessitating the incorporation of some
form of model confidence for mitigation. Existing confidence estimation methods
on LLM generations primarily focus on the confidence at the individual token
level or the entire output sequence level, limiting their applicability to
structured data generation, which consists of an intricate mix of both
independent and correlated entries at the sub-structure level. In this paper,
we first investigate confidence estimation methods for generated
sub-structure-level data. We introduce the concept of Confidence Network that
applies on the hidden state of the LLM transformer, as a more targeted estimate
than the traditional token conditional probability. We further propose
Confidence-Aware sub-structure Beam Search (CABS), a novel decoding method
operating at the sub-structure level in structured data generation. CABS
enhances the faithfulness of structured data generation by considering
confidence scores from the Confidence Network for each sub-structure-level data
and iteratively refining the prompts. Results show that CABS outperforms
traditional token-level beam search for structured data generation by 16.7%
Recall at 90% precision averagely on the problem of product attribute
generation.",2024-05-30,"Chengwei Wei, Kee Kiat Koo, Amir Tavanaei, Karim Bouyarmane",http://arxiv.org/pdf/2406.00069v1,cs.CL
XPrompt:Explaining Large Language Model's Generation via Joint Prompt Attribution,"Large Language Models (LLMs) have demonstrated impressive performances in
complex text generation tasks. However, the contribution of the input prompt to
the generated content still remains obscure to humans, underscoring the
necessity of elucidating and explaining the causality between input and output
pairs. Existing works for providing prompt-specific explanation often confine
model output to be classification or next-word prediction. Few initial attempts
aiming to explain the entire language generation often treat input prompt texts
independently, ignoring their combinatorial effects on the follow-up
generation. In this study, we introduce a counterfactual explanation framework
based on joint prompt attribution, XPrompt, which aims to explain how a few
prompt texts collaboratively influences the LLM's complete generation.
Particularly, we formulate the task of prompt attribution for generation
interpretation as a combinatorial optimization problem, and introduce a
probabilistic algorithm to search for the casual input combination in the
discrete space. We define and utilize multiple metrics to evaluate the produced
explanations, demonstrating both faithfulness and efficiency of our framework.",2024-05-30,"Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin",http://arxiv.org/pdf/2405.20404v1,cs.CL
Cutting Through the Noise: Boosting LLM Performance on Math Word Problems,"Large Language Models (LLMs) excel at various tasks, including solving math
word problems (MWPs), but struggle with real-world problems containing
irrelevant information. To address this, we propose a prompting framework that
generates adversarial variants of MWPs by adding irrelevant variables. We
introduce a dataset, PROBLEMATHIC, containing both adversarial and
non-adversarial MWPs. Our experiments reveal that LLMs are susceptible to
distraction by numerical noise, resulting in an average relative performance
drop of ~26% on adversarial MWPs. To mitigate this, we fine-tune LLMs (Llama-2,
Mistral) on the adversarial samples from our dataset. Fine-tuning on
adversarial training instances improves performance on adversarial MWPs by ~8%,
indicating increased robustness to noise and improved ability to identify
relevant data for reasoning. Finally, to assess the generalizability of our
prompting framework, we introduce GSM-8K-Adv, an adversarial variant of the
GSM-8K benchmark. LLMs continue to struggle when faced with adversarial
information, reducing performance by up to 6%.",2024-05-30,"Ujjwala Anantheswaran, Himanshu Gupta, Kevin Scaria, Shreyas Verma, Chitta Baral, Swaroop Mishra",http://arxiv.org/pdf/2406.15444v3,cs.CL
From Zero to Hero: Cold-Start Anomaly Detection,"When first deploying an anomaly detection system, e.g., to detect
out-of-scope queries in chatbots, there are no observed data, making
data-driven approaches ineffective. Zero-shot anomaly detection methods offer a
solution to such ""cold-start"" cases, but unfortunately they are often not
accurate enough. This paper studies the realistic but underexplored cold-start
setting where an anomaly detection model is initialized using zero-shot
guidance, but subsequently receives a small number of contaminated observations
(namely, that may include anomalies). The goal is to make efficient use of both
the zero-shot guidance and the observations. We propose ColdFusion, a method
that effectively adapts the zero-shot anomaly detector to contaminated
observations. To support future development of this new setting, we propose an
evaluation suite consisting of evaluation protocols and metrics.",2024-05-30,"Tal Reiss, George Kour, Naama Zwerdling, Ateret Anaby-Tavor, Yedid Hoshen",http://arxiv.org/pdf/2405.20341v1,cs.CL
Xwin-LM: Strong and Scalable Alignment Practice for LLMs,"In this work, we present Xwin-LM, a comprehensive suite of alignment
methodologies for large language models (LLMs). This suite encompasses several
key techniques, including supervised finetuning (SFT), reward modeling (RM),
rejection sampling finetuning (RS), and direct preference optimization (DPO).
The key components are as follows: (1) Xwin-LM-SFT, models initially finetuned
with high-quality instruction data; (2) Xwin-Pair, a large-scale, multi-turn
preference dataset meticulously annotated using GPT-4; (3) Xwin-RM, reward
models trained on Xwin-Pair, developed at scales of 7B, 13B, and 70B
parameters; (4) Xwin-Set, a multiwise preference dataset in which each prompt
is linked to 64 unique responses generated by Xwin-LM-SFT and scored by
Xwin-RM; (5) Xwin-LM-RS, models finetuned with the highest-scoring responses
from Xwin-Set; (6) Xwin-LM-DPO, models further optimized on Xwin-Set using the
DPO algorithm. Our evaluations on AlpacaEval and MT-bench demonstrate
consistent and significant improvements across the pipeline, demonstrating the
strength and scalability of Xwin-LM. The repository
https://github.com/Xwin-LM/Xwin-LM will be continually updated to foster
community research.",2024-05-30,"Bolin Ni, JingCheng Hu, Yixuan Wei, Houwen Peng, Zheng Zhang, Gaofeng Meng, Han Hu",http://arxiv.org/pdf/2405.20335v1,cs.CL
CoSy: Evaluating Textual Explanations of Neurons,"A crucial aspect of understanding the complex nature of Deep Neural Networks
(DNNs) is the ability to explain learned concepts within their latent
representations. While methods exist to connect neurons to human-understandable
textual descriptions, evaluating the quality of these explanations is
challenging due to the lack of a unified quantitative approach. We introduce
CoSy (Concept Synthesis), a novel, architecture-agnostic framework for
evaluating textual explanations of latent neurons. Given textual explanations,
our proposed framework uses a generative model conditioned on textual input to
create data points representing the explanations. By comparing the neuron's
response to these generated data points and control data points, we can
estimate the quality of the explanation. We validate our framework through
sanity checks and benchmark various neuron description methods for Computer
Vision tasks, revealing significant differences in quality.",2024-05-30,"Laura Kopf, Philine Lou Bommer, Anna Hedström, Sebastian Lapuschkin, Marina M. -C. Höhne, Kirill Bykov",http://arxiv.org/pdf/2405.20331v2,cs.CL
Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools,"Legal practice has witnessed a sharp rise in products incorporating
artificial intelligence (AI). Such tools are designed to assist with a wide
range of core legal tasks, from search and summarization of caselaw to document
drafting. But the large language models used in these tools are prone to
""hallucinate,"" or make up false information, making their use risky in
high-stakes domains. Recently, certain legal research providers have touted
methods such as retrieval-augmented generation (RAG) as ""eliminating""
(Casetext, 2023) or ""avoid[ing]"" hallucinations (Thomson Reuters, 2023), or
guaranteeing ""hallucination-free"" legal citations (LexisNexis, 2023). Because
of the closed nature of these systems, systematically assessing these claims is
challenging. In this article, we design and report on the first preregistered
empirical evaluation of AI-driven legal research tools. We demonstrate that the
providers' claims are overstated. While hallucinations are reduced relative to
general-purpose chatbots (GPT-4), we find that the AI research tools made by
LexisNexis (Lexis+ AI) and Thomson Reuters (Westlaw AI-Assisted Research and
Ask Practical Law AI) each hallucinate between 17% and 33% of the time. We also
document substantial differences between systems in responsiveness and
accuracy. Our article makes four key contributions. It is the first to assess
and report the performance of RAG-based proprietary legal AI tools. Second, it
introduces a comprehensive, preregistered dataset for identifying and
understanding vulnerabilities in these systems. Third, it proposes a clear
typology for differentiating between hallucinations and accurate legal
responses. Last, it provides evidence to inform the responsibilities of legal
professionals in supervising and verifying AI outputs, which remains a central
open question for the responsible integration of AI into law.",2024-05-30,"Varun Magesh, Faiz Surani, Matthew Dahl, Mirac Suzgun, Christopher D. Manning, Daniel E. Ho",http://arxiv.org/pdf/2405.20362v1,cs.CL
Quriosity: Analyzing Human Questioning Behavior and Causal Inquiry through Curiosity-Driven Queries,"Recent progress in Large Language Model (LLM) technology has changed our role
in interacting with these models. Instead of primarily testing these models
with questions we already know answers to, we are now using them for queries
where the answers are unknown to us, driven by human curiosity. This shift
highlights the growing need to understand curiosity-driven human questions -
those that are more complex, open-ended, and reflective of real-world needs. To
this end, we present Quriosity, a collection of 13.5K naturally occurring
questions from three diverse sources: human-to-search-engine queries,
human-to-human interactions, and human-to-LLM conversations. Our comprehensive
collection enables a rich understanding of human curiosity across various
domains and contexts. Our analysis reveals a significant presence of causal
questions (up to 42%) in the dataset, for which we develop an iterative prompt
improvement framework to identify all causal queries and examine their unique
linguistic properties, cognitive complexity and source distribution. Our paper
paves the way for future work on causal question identification and open-ended
chatbot interactions.",2024-05-30,"Roberto Ceraolo, Dmitrii Kharlapenko, Ahmad Khan, Amélie Reymond, Rada Mihalcea, Bernhard Schölkopf, Mrinmaya Sachan, Zhijing Jin",http://arxiv.org/pdf/2405.20318v3,cs.CL
ANAH: Analytical Annotation of Hallucinations in Large Language Models,"Reducing the `$\textit{hallucination}$' problem of Large Language Models
(LLMs) is crucial for their wide applications. A comprehensive and fine-grained
measurement of the hallucination is the first key step for the governance of
this issue but is under-explored in the community. Thus, we present
$\textbf{ANAH}$, a bilingual dataset that offers $\textbf{AN}$alytical
$\textbf{A}$nnotation of $\textbf{H}$allucinations in LLMs within Generative
Question Answering. Each answer sentence in our dataset undergoes rigorous
annotation, involving the retrieval of a reference fragment, the judgment of
the hallucination type, and the correction of hallucinated content. ANAH
consists of ~12k sentence-level annotations for ~4.3k LLM responses covering
over 700 topics, constructed by a human-in-the-loop pipeline. Thanks to the
fine granularity of the hallucination annotations, we can quantitatively
confirm that the hallucinations of LLMs progressively accumulate in the answer
and use ANAH to train and evaluate hallucination annotators. We conduct
extensive experiments on studying generative and discriminative annotators and
show that, although current open-source LLMs have difficulties in fine-grained
hallucination annotation, the generative annotator trained with ANAH can
surpass all open-source LLMs and GPT-3.5, obtain performance competitive with
GPT-4, and exhibits better generalization ability on unseen questions.",2024-05-30,"Ziwei Ji, Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen",http://arxiv.org/pdf/2405.20315v1,cs.CL
S3D: A Simple and Cost-Effective Self-Speculative Decoding Scheme for Low-Memory GPUs,"Speculative decoding (SD) has attracted a significant amount of research
attention due to the substantial speedup it can achieve for LLM inference.
However, despite the high speedups they offer, speculative decoding methods
often achieve optimal performance on high-end devices or with a substantial GPU
memory overhead. Given limited memory and the necessity of quantization, a
high-performing model on a high-end GPU can slow down by up to 7 times. To this
end, we propose Skippy Simultaneous Speculative Decoding (or S3D), a
cost-effective self-speculative SD method based on simultaneous multi-token
decoding and mid-layer skipping. When compared against recent effective
open-source SD systems, our method has achieved one of the top
performance-memory ratios while requiring minimal architecture changes and
training data. Leveraging our memory efficiency, we created a smaller yet more
effective SD model based on Phi-3. It is 1.4 to 2 times faster than the
quantized EAGLE model and operates in half-precision while using less VRAM.",2024-05-30,"Wei Zhong, Manasa Bharadwaj",http://arxiv.org/pdf/2405.20314v2,cs.CL
Large Language Models Can Self-Improve At Web Agent Tasks,"Training models to act as agents that can effectively navigate and perform
actions in a complex environment, such as a web browser, has typically been
challenging due to lack of training data. Large language models (LLMs) have
recently demonstrated some capability to navigate novel environments as agents
in a zero-shot or few-shot fashion, purely guided by natural language
instructions as prompts. Recent research has also demonstrated LLMs have the
capability to exceed their base performance through self-improvement, i.e.
fine-tuning on data generated by the model itself. In this work, we explore the
extent to which LLMs can self-improve their performance as agents in
long-horizon tasks in a complex environment using the WebArena benchmark. In
WebArena, an agent must autonomously navigate and perform actions on web pages
to achieve a specified objective. We explore fine-tuning on three distinct
synthetic training data mixtures and achieve a 31\% improvement in task
completion rate over the base model on the WebArena benchmark through a
self-improvement procedure. We additionally contribute novel evaluation metrics
for assessing the performance, robustness, capabilities, and quality of
trajectories of our fine-tuned agent models to a greater degree than simple,
aggregate-level benchmark scores currently used to measure self-improvement.",2024-05-30,"Ajay Patel, Markus Hofmarcher, Claudiu Leoveanu-Condrei, Marius-Constantin Dinu, Chris Callison-Burch, Sepp Hochreiter",http://arxiv.org/pdf/2405.20309v2,cs.CL
Group Robust Preference Optimization in Reward-free RLHF,"Adapting large language models (LLMs) for specific tasks usually involves
fine-tuning through reinforcement learning with human feedback (RLHF) on
preference data. While these data often come from diverse labelers' groups
(e.g., different demographics, ethnicities, company teams, etc.), traditional
RLHF approaches adopt a ""one-size-fits-all"" approach, i.e., they
indiscriminately assume and optimize a single preference model, thus not being
robust to unique characteristics and needs of the various groups. To address
this limitation, we propose a novel Group Robust Preference Optimization (GRPO)
method to align LLMs to individual groups' preferences robustly. Our approach
builds upon reward-free direct preference optimization methods, but unlike
previous approaches, it seeks a robust policy which maximizes the worst-case
group performance. To achieve this, GRPO adaptively and sequentially weights
the importance of different groups, prioritizing groups with worse cumulative
loss. We theoretically study the feasibility of GRPO and analyze its
convergence for the log-linear policy class. By fine-tuning LLMs with GRPO
using diverse group-based global opinion data, we significantly improved
performance for the worst-performing groups, reduced loss imbalances across
groups, and improved probability accuracies compared to non-robust baselines.",2024-05-30,"Shyam Sundhar Ramesh, Yifan Hu, Iason Chaimalas, Viraj Mehta, Pier Giuseppe Sessa, Haitham Bou Ammar, Ilija Bogunovic",http://arxiv.org/pdf/2405.20304v1,cs.CL
"Who Writes the Review, Human or AI?","With the increasing use of Artificial Intelligence in Natural Language
Processing, concerns have been raised regarding the detection of AI-generated
text in various domains. This study aims to investigate this issue by proposing
a methodology to accurately distinguish AI-generated and human-written book
reviews. Our approach utilizes transfer learning, enabling the model to
identify generated text across different topics while improving its ability to
detect variations in writing style and vocabulary. To evaluate the
effectiveness of the proposed methodology, we developed a dataset consisting of
real book reviews and AI-generated reviews using the recently proposed Vicuna
open-source language model. The experimental results demonstrate that it is
feasible to detect the original source of text, achieving an accuracy rate of
96.86%. Our efforts are oriented toward the exploration of the capabilities and
limitations of Large Language Models in the context of text identification.
Expanding our knowledge in these aspects will be valuable for effectively
navigating similar models in the future and ensuring the integrity and
authenticity of human-generated content.",2024-05-30,"Panagiotis C. Theocharopoulos, Spiros V. Georgakopoulos, Sotiris K. Tasoulis, Vassilis P. Plagianakos",http://arxiv.org/pdf/2405.20285v1,cs.CL
ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection for ABSA,"Aspect-Based Sentiment Analysis (ABSA) has experienced tremendous expansion
and diversity due to various shared tasks spanning several languages and fields
and organized via SemEval workshops and Germeval. Nonetheless, a few
shortcomings still need to be addressed, such as the lack of low-resource
language evaluations and the emphasis on sentence-level analysis. To thoroughly
assess ABSA techniques in the context of complete reviews, this research
presents a novel task, Review-Level Opinion Aspect Sentiment Target (ROAST).
ROAST seeks to close the gap between sentence-level and text-level ABSA by
identifying every ABSA constituent at the review level. We extend the available
datasets to enable ROAST, addressing the drawbacks noted in previous research
by incorporating low-resource languages, numerous languages, and a variety of
topics. Through this effort, ABSA research will be able to cover more ground
and get a deeper comprehension of the task and its practical application in a
variety of languages and domains (https://github.com/RiTUAL-UH/ROAST-ABSA).",2024-05-30,"Siva Uday Sampreeth Chebolu, Franck Dernoncourt, Nedim Lipka, Thamar Solorio",http://arxiv.org/pdf/2405.20274v2,cs.CL
ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane Reflections,"Parameter-efficient finetuning (PEFT) has become ubiquitous to adapt
foundation models to downstream task requirements while retaining their
generalization ability. However, the amount of additionally introduced
parameters and compute for successful adaptation and hyperparameter searches
can explode quickly, especially when deployed at scale to serve numerous
individual requests. To ensure effective, parameter-efficient, and
hyperparameter-robust adaptation, we propose the ETHER transformation family,
which performs Efficient fineTuning via HypErplane Reflections. By design,
ETHER transformations require a minimal number of parameters, are less likely
to deteriorate model performance, and exhibit robustness to hyperparameter and
learning rate choices. In particular, we introduce ETHER and its relaxation
ETHER+, which match or outperform existing PEFT methods with significantly
fewer parameters ($\sim$$10$-$100$ times lower than LoRA or OFT) across
multiple image synthesis and natural language tasks without exhaustive
hyperparameter tuning. Finally, we investigate the recent emphasis on
Hyperspherical Energy retention for adaptation and raise questions on its
practical utility. The code is available at https://github.com/mwbini/ether.",2024-05-30,"Massimo Bini, Karsten Roth, Zeynep Akata, Anna Khoreva",http://arxiv.org/pdf/2405.20271v2,cs.CL
IsraParlTweet: The Israeli Parliamentary and Twitter Resource,"We introduce IsraParlTweet, a new linked corpus of Hebrew-language
parliamentary discussions from the Knesset (Israeli Parliament) between the
years 1992-2023 and Twitter posts made by Members of the Knesset between the
years 2008-2023, containing a total of 294.5 million Hebrew tokens. In addition
to raw text, the corpus contains comprehensive metadata on speakers and Knesset
sessions as well as several linguistic annotations. As a result, IsraParlTweet
can be used to conduct a wide variety of quantitative and qualitative analyses
and provide valuable insights into political discourse in Israel.",2024-05-30,"Guy Mor-Lan, Effi Levi, Tamir Sheafer, Shaul R. Shenhav",http://arxiv.org/pdf/2405.20269v1,cs.CL
Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions,"As LLMs continuously evolve, there is an urgent need for a reliable
evaluation method that delivers trustworthy results promptly. Currently, static
benchmarks suffer from inflexibility and unreliability, leading users to prefer
human voting platforms like Chatbot Arena. However, human evaluations require
significant manual effort. To address this, we propose the Auto-Arena, an
innovative framework that automates the entire evaluation process using
LLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM
candidates engage in a multi-round peer battle based on individual questions,
aiming at revealing their true performance differences. Finally, a committee of
LLM judges collaboratively discusses and decides the winner, reducing bias and
enhancing fairness. During the peer battles, we observe intriguing scenarios
where the LLM candidates display competitive behaviors and even learn from the
opponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena
shows a 92.14% correlation with human preferences, surpassing all previous
expert-annotated benchmarks without any manual efforts. As a result, Auto-Arena
offers a promising alternative to current human evaluation platforms for
evaluating LLMs automatically.",2024-05-30,"Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Weiwen Xu, Deli Zhao, Lidong Bing",http://arxiv.org/pdf/2405.20267v4,cs.CL
Evaluating Large Language Model Biases in Persona-Steered Generation,"The task of persona-steered text generation requires large language models
(LLMs) to generate text that reflects the distribution of views that an
individual fitting a persona could have. People have multifaceted personas, but
prior work on bias in LLM-generated opinions has only explored multiple-choice
settings or one-dimensional personas. We define an incongruous persona as a
persona with multiple traits where one trait makes its other traits less likely
in human survey data, e.g. political liberals who support increased military
spending. We find that LLMs are 9.7% less steerable towards incongruous
personas than congruous ones, sometimes generating the stereotypical stance
associated with its demographic rather than the target stance. Models that we
evaluate that are fine-tuned with Reinforcement Learning from Human Feedback
(RLHF) are more steerable, especially towards stances associated with political
liberals and women, but present significantly less diverse views of personas.
We also find variance in LLM steerability that cannot be predicted from
multiple-choice opinion evaluation. Our results show the importance of
evaluating models in open-ended text generation, as it can surface new LLM
opinion biases. Moreover, such a setup can shed light on our ability to steer
models toward a richer and more diverse range of viewpoints.",2024-05-30,"Andy Liu, Mona Diab, Daniel Fried",http://arxiv.org/pdf/2405.20253v1,cs.CL
Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization,"Large language models (LLMs) have shown great progress in responding to user
questions, allowing for a multitude of diverse applications. Yet, the quality
of LLM outputs heavily depends on the prompt design, where a good prompt might
enable the LLM to answer a very challenging question correctly. Therefore,
recent works have developed many strategies for improving the prompt, including
both manual crafting and in-domain optimization. However, their efficacy in
unrestricted scenarios remains questionable, as the former depends on human
design for specific questions and the latter usually generalizes poorly to
unseen scenarios. To address these problems, we give LLMs the freedom to design
the best prompts according to themselves. Specifically, we include a hierarchy
of LLMs, first constructing a prompt with precise instructions and accurate
wording in a hierarchical manner, and then using this prompt to generate the
final answer to the user query. We term this pipeline Hierarchical Multi-Agent
Workflow, or HMAW. In contrast with prior works, HMAW imposes no human
restriction and requires no training, and is completely task-agnostic while
capable of adjusting to the nuances of the underlying task. Through both
quantitative and qualitative experiments across multiple benchmarks, we verify
that despite its simplicity, the proposed approach can create detailed and
suitable prompts, further boosting the performance of current LLMs.",2024-05-30,"Yuchi Liu, Jaskirat Singh, Gaowen Liu, Ali Payani, Liang Zheng",http://arxiv.org/pdf/2405.20252v2,cs.CL
Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use,"Business Document Information Extraction (BDIE) is the problem of
transforming a blob of unstructured information (raw text, scanned documents,
etc.) into a structured format that downstream systems can parse and use. It
has two main tasks: Key-Information Extraction (KIE) and Line Items Recognition
(LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem,
where the tools are these downstream systems. We then present Retrieval
Augmented Structured Generation (RASG), a novel general framework for BDIE that
achieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE
benchmarks.
  The contributions of this paper are threefold: (1) We show, with ablation
benchmarks, that Large Language Models (LLMs) with RASG are already competitive
with or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on
BDIE benchmarks. (2) We propose a new metric class for Line Items Recognition,
General Line Items Recognition Metric (GLIRM), that is more aligned with
practical BDIE use cases compared to existing metrics, such as ANLS*, DocILE,
and GriTS. (3) We provide a heuristic algorithm for backcalculating bounding
boxes of predicted line items and tables without the need for vision encoders.
Finally, we claim that, while LMMs might sometimes offer marginal performance
benefits, LLMs + RASG is oftentimes superior given real-world applications and
constraints of BDIE.",2024-05-30,"Franz Louis Cesista, Rui Aguiar, Jason Kim, Paolo Acilo",http://arxiv.org/pdf/2405.20245v1,cs.CL
ESG-FTSE: A corpus of news articles with ESG relevance labels and use cases,"We present ESG-FTSE, the first corpus comprised of news articles with
Environmental, Social and Governance (ESG) relevance annotations. In recent
years, investors and regulators have pushed ESG investing to the mainstream due
to the urgency of climate change. This has led to the rise of ESG scores to
evaluate an investment's credentials as socially responsible. While demand for
ESG scores is high, their quality varies wildly. Quantitative techniques can be
applied to improve ESG scores, thus, responsible investing. To contribute to
resource building for ESG and financial text mining, we pioneer the ESG-FTSE
corpus. We further present the first of its kind ESG annotation schema. It has
three levels: a binary classification (relevant versus irrelevant news
articles), ESG classification (ESG-related news articles), and target company.
Both supervised and unsupervised learning experiments for ESG relevance
detection were conducted to demonstrate that the corpus can be used in
different settings to derive accurate ESG predictions. Keywords: corpus
annotation, ESG labels, annotation schema, news article, natural language
processing",2024-05-30,"Mariya Pavlova, Bernard Casey, Miaosen Wang",http://arxiv.org/pdf/2405.20218v1,cs.CL
TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models,"Mainstream approaches to aligning large language models (LLMs) heavily rely
on human preference data, particularly when models require periodic updates.
The standard process for iterative alignment of LLMs involves collecting new
human feedback for each update. However, the data collection process is costly
and challenging to scale. To address this issue, we introduce the ""TS-Align""
framework, which fine-tunes a policy model using pairwise feedback data
automatically mined from its outputs. This automatic mining process is
efficiently accomplished through the collaboration between a large-scale
teacher model and a small-scale student model. The policy fine-tuning process
can be iteratively repeated using on-policy generations within our proposed
teacher-student collaborative framework. Through extensive experiments, we
demonstrate that our final aligned policy outperforms the base policy model
with an average win rate of 69.7% across seven conversational or
instruction-following datasets. Furthermore, we show that the ranking
capability of the teacher is effectively distilled into the student through our
pipeline, resulting in a small-scale yet effective reward model for policy
model alignment.",2024-05-30,"Chen Zhang, Chengguang Tang, Dading Chong, Ke Shi, Guohua Tang, Feng Jiang, Haizhou Li",http://arxiv.org/pdf/2405.20215v4,cs.CL
PostDoc: Generating Poster from a Long Multimodal Document Using Deep Submodular Optimization,"A poster from a long input document can be considered as a one-page
easy-to-read multimodal (text and images) summary presented on a nice template
with good design elements. Automatic transformation of a long document into a
poster is a very less studied but challenging task. It involves content
summarization of the input document followed by template generation and
harmonization. In this work, we propose a novel deep submodular function which
can be trained on ground truth summaries to extract multimodal content from the
document and explicitly ensures good coverage, diversity and alignment of text
and images. Then, we use an LLM based paraphraser and propose to generate a
template with various design aspects conditioned on the input content. We show
the merits of our approach through extensive automated and human evaluations.",2024-05-30,"Vijay Jaisankar, Sambaran Bandyopadhyay, Kalp Vyas, Varre Chaitanya, Shwetha Somasundaram",http://arxiv.org/pdf/2405.20213v1,cs.CL
Jina CLIP: Your CLIP Model Is Also Your Text Retriever,"Contrastive Language-Image Pretraining (CLIP) is widely used to train models
to align images and texts in a common embedding space by mapping them to
fixed-sized vectors. These models are key to multimodal information retrieval
and related tasks. However, CLIP models generally underperform in text-only
tasks compared to specialized text models. This creates inefficiencies for
information retrieval systems that keep separate embeddings and models for
text-only and multimodal tasks. We propose a novel, multi-task contrastive
training method to address this issue, which we use to train the jina-clip-v1
model to achieve the state-of-the-art performance on both text-image and
text-text retrieval tasks.",2024-05-30,"Andreas Koukounas, Georgios Mastrapas, Michael Günther, Bo Wang, Scott Martens, Isabelle Mohr, Saba Sturua, Mohammad Kalim Akram, Joan Fontanals Martínez, Saahil Ognawala, Susana Guzman, Maximilian Werk, Nan Wang, Han Xiao",http://arxiv.org/pdf/2405.20204v2,cs.CL
TAIA: Large Language Models are Out-of-Distribution Data Learners,"Fine-tuning on task-specific question-answer pairs is a predominant method
for enhancing the performance of instruction-tuned large language models (LLMs)
on downstream tasks. However, in certain specialized domains, such as
healthcare or harmless content generation, it is nearly impossible to obtain a
large volume of high-quality data that matches the downstream distribution. To
improve the performance of LLMs in data-scarce domains with domain-mismatched
data, we re-evaluated the Transformer architecture and discovered that not all
parameter updates during fine-tuning contribute positively to downstream
performance. Our analysis reveals that within the self-attention and
feed-forward networks, only the fine-tuned attention parameters are
particularly beneficial when the training set's distribution does not fully
align with the test set. Based on this insight, we propose an effective
inference-time intervention method: Training All parameters but Inferring with
only Attention (\trainallInfAttn). We empirically validate \trainallInfAttn
using two general instruction-tuning datasets and evaluate it on seven
downstream tasks involving math, reasoning, and knowledge understanding across
LLMs of different parameter sizes and fine-tuning techniques. Our comprehensive
experiments demonstrate that \trainallInfAttn achieves superior improvements
compared to both the fully fine-tuned model and the base model in most
scenarios, with significant performance gains. The high tolerance of
\trainallInfAttn to data mismatches makes it resistant to jailbreaking tuning
and enhances specialized tasks using general data. Code is available in
\url{https://github.com/pixas/TAIA_LLM}.",2024-05-30,"Shuyang Jiang, Yusheng Liao, Ya Zhang, Yanfeng Wang, Yu Wang",http://arxiv.org/pdf/2405.20192v2,cs.CL
Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning Code LLMs,"Code LLMs have shown promising results with converting tasks in natural
language to programs that can be executed by service robots. We are interested
in finetuning small, specialized LLMs for this purpose, but collecting datasets
of task-program pairs specific to each robot is time-consuming and expensive.
While approaches such as SELF-INSTRUCT and EVOL-INSTRUCT are capable of
generating novel tasks given a few examples, they are unable to provide the
corresponding programs that correctly abide by physical-world and
robot-constraints using the provided programming interface. Using a simulator
is a natural potential solution to checking for such constraints, but building
simulation environments that can handle arbitrary tasks and their necessary
objects and locations, is challenging. To address these challenges, we
introduce ROBO-INSTRUCT, which synthesizes task-specific simulation
environments on the fly during program execution, by opportunistically
inferring entity properties and enforcing corresponding constraints based on
how the entities are used in the task program. Additionally, ROBO-INSTRUCT
integrates an LLM-aided post-processing procedure to refine instructions for
better alignment with robot programs. We demonstrate the effectiveness of
ROBO-INSTRUCT across multiple LLMs, showing that our fine-tuned models
outperform all baseline methods and even match or surpass the performance of
several larger and proprietary models.",2024-05-30,"Zichao Hu, Junyi Jessy Li, Arjun Guha, Joydeep Biswas",http://arxiv.org/pdf/2405.20179v3,cs.CL
InstructionCP: A fast approach to transfer Large Language Models into target language,"The rapid development of large language models (LLMs) in recent years has
largely focused on English, resulting in models that respond exclusively in
English. To adapt these models to other languages, continual pre-training (CP)
is often employed, followed by supervised fine-tuning (SFT) to maintain
conversational abilities. However, CP and SFT can reduce a model's ability to
filter harmful content. We propose Instruction Continual Pre-training (InsCP),
which integrates instruction tags into the CP process to prevent loss of
conversational proficiency while acquiring new languages. Our experiments
demonstrate that InsCP retains conversational and Reinforcement Learning from
Human Feedback (RLHF) abilities. Empirical evaluations on language alignment,
reliability, and knowledge benchmarks confirm the efficacy of InsCP. Notably,
this approach requires only 0.1 billion tokens of high-quality
instruction-following data, thereby reducing resource consumption.",2024-05-30,"Kuang-Ming Chen, Hung-yi Lee",http://arxiv.org/pdf/2405.20175v1,cs.CL
Iterative Feature Boosting for Explainable Speech Emotion Recognition,"In speech emotion recognition (SER), using predefined features without
considering their practical importance may lead to high dimensional datasets,
including redundant and irrelevant information. Consequently, high-dimensional
learning often results in decreasing model accuracy while increasing
computational complexity. Our work underlines the importance of carefully
considering and analyzing features in order to build efficient SER systems. We
present a new supervised SER method based on an efficient feature engineering
approach. We pay particular attention to the explainability of results to
evaluate feature relevance and refine feature sets. This is performed
iteratively through feature evaluation loop, using Shapley values to boost
feature selection and improve overall framework performance. Our approach
allows thus to balance the benefits between model performance and transparency.
The proposed method outperforms human-level performance (HLP) and
state-of-the-art machine learning methods in emotion recognition on the TESS
dataset. The source code of this paper is publicly available at
https://github.com/alaaNfissi/Iterative-Feature-Boosting-for-Explainable-Speech-Emotion-Recognition.",2024-05-30,"Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara",http://arxiv.org/pdf/2405.20172v3,cs.CL
Reasoning about concepts with LLMs: Inconsistencies abound,"The ability to summarize and organize knowledge into abstract concepts is key
to learning and reasoning. Many industrial applications rely on the consistent
and systematic use of concepts, especially when dealing with decision-critical
knowledge. However, we demonstrate that, when methodically questioned, large
language models (LLMs) often display and demonstrate significant
inconsistencies in their knowledge. Computationally, the basic aspects of the
conceptualization of a given domain can be represented as Is-A hierarchies in a
knowledge graph (KG) or ontology, together with a few properties or axioms that
enable straightforward reasoning. We show that even simple ontologies can be
used to reveal conceptual inconsistencies across several LLMs. We also propose
strategies that domain experts can use to evaluate and improve the coverage of
key domain concepts in LLMs of various sizes. In particular, we have been able
to significantly enhance the performance of LLMs of various sizes with openly
available weights using simple knowledge-graph (KG) based prompting strategies.",2024-05-30,"Rosario Uceda-Sosa, Karthikeyan Natesan Ramamurthy, Maria Chang, Moninder Singh",http://arxiv.org/pdf/2405.20163v1,cs.CL
Heidelberg-Boston @ SIGTYP 2024 Shared Task: Enhancing Low-Resource Language Analysis With Character-Aware Hierarchical Transformers,"Historical languages present unique challenges to the NLP community, with one
prominent hurdle being the limited resources available in their closed corpora.
This work describes our submission to the constrained subtask of the SIGTYP
2024 shared task, focusing on PoS tagging, morphological tagging, and
lemmatization for 13 historical languages. For PoS and morphological tagging we
adapt a hierarchical tokenization method from Sun et al. (2023) and combine it
with the advantages of the DeBERTa-V3 architecture, enabling our models to
efficiently learn from every character in the training data. We also
demonstrate the effectiveness of character-level T5 models on the lemmatization
task. Pre-trained from scratch with limited data, our models achieved first
place in the constrained subtask, nearly reaching the performance levels of the
unconstrained task's winner. Our code is available at
https://github.com/bowphs/SIGTYP-2024-hierarchical-transformers",2024-05-30,"Frederick Riemenschneider, Kevin Krahn",http://arxiv.org/pdf/2405.20145v1,cs.CL
GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning,"Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form
of triplets (head, relation, tail), which collectively form a graph. Question
Answering over KGs (KGQA) is the task of answering natural questions grounding
the reasoning to the information provided by the KG. Large Language Models
(LLMs) are the state-of-the-art models for QA tasks due to their remarkable
ability to understand natural language. On the other hand, Graph Neural
Networks (GNNs) have been widely used for KGQA as they can handle the complex
graph information stored in the KG. In this work, we introduce GNN-RAG, a novel
method for combining language understanding abilities of LLMs with the
reasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.
First, a GNN reasons over a dense KG subgraph to retrieve answer candidates for
a given question. Second, the shortest paths in the KG that connect question
entities and answer candidates are extracted to represent KG reasoning paths.
The extracted paths are verbalized and given as input for LLM reasoning with
RAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to
extract useful graph information, while the LLM leverages its natural language
processing ability for ultimate KGQA. Furthermore, we develop a retrieval
augmentation (RA) technique to further boost KGQA performance with GNN-RAG.
Experimental results show that GNN-RAG achieves state-of-the-art performance in
two widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching
GPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop
and multi-entity questions outperforming competing approaches by 8.9--15.5%
points at answer F1.",2024-05-30,"Costas Mavromatis, George Karypis",http://arxiv.org/pdf/2405.20139v1,cs.CL
Language Models Need Inductive Biases to Count Inductively,"Counting is a fundamental example of generalization, whether viewed through
the mathematical lens of Peano's axioms defining the natural numbers or the
cognitive science literature for children learning to count. The argument holds
for both cases that learning to count means learning to count infinitely. While
few papers have tried to distill transformer ""reasoning"" to the simplest case
of counting, investigating length generalization does occur throughout the
literature. In the ""train short, test long"" paradigm of NLP, length refers to
the training sentence length. In formal language recognition, length refers to
the input sequence length, or the maximum stack size induced by a pushdown
automata. In general problem solving, length refers to the number of hops in a
deductive reasoning chain or the recursion depth. For all cases, counting is
central to task success. And crucially, generalizing counting inductively is
central to success on OOD instances. This work provides extensive empirical
results on training language models to count. We experiment with architectures
ranging from RNNs, Transformers, State-Space Models and RWKV. We present
carefully-designed task formats, auxiliary tasks and positional embeddings to
avoid limitations in generalization with OOD-position and OOD-vocabulary. We
find that while traditional RNNs trivially achieve inductive counting,
Transformers have to rely on positional embeddings to count out-of-domain. As
counting is the basis for many arguments concerning the expressivity of
Transformers, our finding calls for the community to reexamine the application
scope of primitive functions defined in formal characterizations. Finally,
modern RNNs also largely underperform traditional RNNs in generalizing counting
inductively. We discuss how design choices that enable parallelized training of
modern RNNs cause them to lose merits of a recurrent nature.",2024-05-30,"Yingshan Chang, Yonatan Bisk",http://arxiv.org/pdf/2405.20131v2,cs.CL
Fill in the Gap! Combining Self-supervised Representation Learning with Neural Audio Synthesis for Speech Inpainting,"Most speech self-supervised learning (SSL) models are trained with a pretext
task which consists in predicting missing parts of the input signal, either
future segments (causal prediction) or segments masked anywhere within the
input (non-causal prediction). Learned speech representations can then be
efficiently transferred to downstream tasks (e.g., automatic speech or speaker
recognition). In the present study, we investigate the use of a speech SSL
model for speech inpainting, that is reconstructing a missing portion of a
speech signal from its surrounding context, i.e., fulfilling a downstream task
that is very similar to the pretext task. To that purpose, we combine an SSL
encoder, namely HuBERT, with a neural vocoder, namely HiFiGAN, playing the role
of a decoder. In particular, we propose two solutions to match the HuBERT
output with the HiFiGAN input, by freezing one and fine-tuning the other, and
vice versa. Performance of both approaches was assessed in single- and
multi-speaker settings, for both informed and blind inpainting configurations
(i.e., the position of the mask is known or unknown, respectively), with
different objective metrics and a perceptual evaluation. Performances show that
if both solutions allow to correctly reconstruct signal portions up to the size
of 200ms (and even 400ms in some cases), fine-tuning the SSL encoder provides a
more accurate signal reconstruction in the single-speaker setting case, while
freezing it (and training the neural vocoder instead) is a better strategy when
dealing with multi-speaker data.",2024-05-30,"Ihab Asaad, Maxime Jacquelin, Olivier Perrotin, Laurent Girin, Thomas Hueber",http://arxiv.org/pdf/2405.20101v1,cs.CL
Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation,"Despite recent progress made by large language models in code generation,
they still struggle with programs that meet complex requirements. Recent work
utilizes plan-and-solve decomposition to decrease the complexity and leverage
self-tests to refine the generated program. Yet, planning deep-inside
requirements in advance can be challenging, and the tests need to be accurate
to accomplish self-improvement. To this end, we propose FunCoder, a code
generation framework incorporating the divide-and-conquer strategy with
functional consensus. Specifically, FunCoder recursively branches off
sub-functions as smaller goals during code generation, represented by a tree
hierarchy. These sub-functions are then composited to attain more complex
objectives. Additionally, we designate functions via a consensus formed by
identifying similarities in program behavior, mitigating error propagation.
FunCoder outperforms state-of-the-art methods by +9.8% on average in HumanEval,
MBPP, xCodeEval and MATH with GPT-3.5 and GPT-4. Moreover, our method
demonstrates superiority on smaller models: With FunCoder, StableCode-3b
surpasses GPT-3.5 by +18.6% and achieves 97.7% of GPT-4's performance on
HumanEval. Further analysis reveals that our proposed dynamic function
decomposition is capable of handling complex requirements, and the functional
consensus prevails over self-testing in correctness evaluation.",2024-05-30,"Jingchang Chen, Hongxuan Tang, Zheng Chu, Qianglong Chen, Zekun Wang, Ming Liu, Bing Qin",http://arxiv.org/pdf/2405.20092v2,cs.CL
The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities,"Fine-tuning large language models (LLMs) for machine translation has shown
improvements in overall translation quality. However, it is unclear what is the
impact of fine-tuning on desirable LLM behaviors that are not present in neural
machine translation models, such as steerability, inherent document-level
translation abilities, and the ability to produce less literal translations. We
perform an extensive translation evaluation on the LLaMA and Falcon family of
models with model size ranging from 7 billion up to 65 billion parameters. Our
results show that while fine-tuning improves the general translation quality of
LLMs, several abilities degrade. In particular, we observe a decline in the
ability to perform formality steering, to produce technical translations
through few-shot examples, and to perform document-level translation. On the
other hand, we observe that the model produces less literal translations after
fine-tuning on parallel data. We show that by including monolingual data as
part of the fine-tuning data we can maintain the abilities while simultaneously
enhancing overall translation quality. Our findings emphasize the need for
fine-tuning strategies that preserve the benefits of LLMs for machine
translation.",2024-05-30,"David Stap, Eva Hasler, Bill Byrne, Christof Monz, Ke Tran",http://arxiv.org/pdf/2405.20089v2,cs.CL
Student Answer Forecasting: Transformer-Driven Answer Choice Prediction for Language Learning,"Intelligent Tutoring Systems (ITS) enhance personalized learning by
predicting student answers to provide immediate and customized instruction.
However, recent research has primarily focused on the correctness of the answer
rather than the student's performance on specific answer choices, limiting
insights into students' thought processes and potential misconceptions. To
address this gap, we present MCQStudentBert, an answer forecasting model that
leverages the capabilities of Large Language Models (LLMs) to integrate
contextual understanding of students' answering history along with the text of
the questions and answers. By predicting the specific answer choices students
are likely to make, practitioners can easily extend the model to new answer
choices or remove answer choices for the same multiple-choice question (MCQ)
without retraining the model. In particular, we compare MLP, LSTM, BERT, and
Mistral 7B architectures to generate embeddings from students' past
interactions, which are then incorporated into a finetuned BERT's
answer-forecasting mechanism. We apply our pipeline to a dataset of language
learning MCQ, gathered from an ITS with over 10,000 students to explore the
predictive accuracy of MCQStudentBert, which incorporates student interaction
patterns, in comparison to correct answer prediction and traditional
mastery-learning feature-based approaches. This work opens the door to more
personalized content, modularization, and granular support.",2024-05-30,"Elena Grazia Gado, Tommaso Martorella, Luca Zunino, Paola Mejia-Domenzain, Vinitra Swamy, Jibril Frej, Tanja Käser",http://arxiv.org/pdf/2405.20079v1,cs.CL
Would I Lie To You? Inference Time Alignment of Language Models using Direct Preference Heads,"Pre-trained Language Models (LMs) exhibit strong zero-shot and in-context
learning capabilities; however, their behaviors are often difficult to control.
By utilizing Reinforcement Learning from Human Feedback (RLHF), it is possible
to fine-tune unsupervised LMs to follow instructions and produce outputs that
reflect human preferences. Despite its benefits, RLHF has been shown to
potentially harm a language model's reasoning capabilities and introduce
artifacts such as hallucinations where the model may fabricate facts. To
address this issue we introduce Direct Preference Heads (DPH), a fine-tuning
framework that enables LMs to learn human preference signals through an
auxiliary reward head without directly affecting the output distribution of the
language modeling head. We perform a theoretical analysis of our objective
function and find strong ties to Conservative Direct Preference Optimization
(cDPO). Finally we evaluate our models on GLUE, RACE, and the GPT4All
evaluation suite and demonstrate that our method produces models which achieve
higher scores than those fine-tuned with Supervised Fine-Tuning (SFT) or Direct
Preference Optimization (DPO) alone.",2024-05-30,"Avelina Asada Hadji-Kyriacou, Ognjen Arandjelovic",http://arxiv.org/pdf/2405.20053v1,cs.CL
PGA-SciRE: Harnessing LLM on Data Augmentation for Enhancing Scientific Relation Extraction,"Relation Extraction (RE) aims at recognizing the relation between pairs of
entities mentioned in a text. Advances in LLMs have had a tremendous impact on
NLP. In this work, we propose a textual data augmentation framework called PGA
for improving the performance of models for RE in the scientific domain. The
framework introduces two ways of data augmentation, utilizing a LLM to obtain
pseudo-samples with the same sentence meaning but with different
representations and forms by paraphrasing the original training set samples. As
well as instructing LLM to generate sentences that implicitly contain
information about the corresponding labels based on the relation and entity of
the original training set samples. These two kinds of pseudo-samples
participate in the training of the RE model together with the original dataset,
respectively. The PGA framework in the experiment improves the F1 scores of the
three mainstream models for RE within the scientific domain. Also, using a LLM
to obtain samples can effectively reduce the cost of manually labeling data.",2024-05-30,"Yang Zhou, Shimin Shan, Hongkui Wei, Zhehuan Zhao, Wenshuo Feng",http://arxiv.org/pdf/2405.20787v1,cs.CL
Safe Multi-agent Reinforcement Learning with Natural Language Constraints,"The role of natural language constraints in Safe Multi-agent Reinforcement
Learning (MARL) is crucial, yet often overlooked. While Safe MARL has vast
potential, especially in fields like robotics and autonomous vehicles, its full
potential is limited by the need to define constraints in pre-designed
mathematical terms, which requires extensive domain expertise and reinforcement
learning knowledge, hindering its broader adoption. To address this limitation
and make Safe MARL more accessible and adaptable, we propose a novel approach
named Safe Multi-agent Reinforcement Learning with Natural Language constraints
(SMALL). Our method leverages fine-tuned language models to interpret and
process free-form textual constraints, converting them into semantic embeddings
that capture the essence of prohibited states and behaviours. These embeddings
are then integrated into the multi-agent policy learning process, enabling
agents to learn policies that minimize constraint violations while optimizing
rewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a
multi-task benchmark designed to assess the performance of multiple agents in
adhering to natural language constraints. Empirical evaluations across various
environments demonstrate that SMALL achieves comparable rewards and
significantly fewer constraint violations, highlighting its effectiveness in
understanding and enforcing natural language constraints.",2024-05-30,"Ziyan Wang, Meng Fang, Tristan Tomilin, Fei Fang, Yali Du",http://arxiv.org/pdf/2405.20018v1,cs.CL
Efficient Indirect LLM Jailbreak via Multimodal-LLM Jailbreak,"This paper focuses on jailbreaking attacks against large language models
(LLMs), eliciting them to generate objectionable content in response to harmful
user queries. Unlike previous LLM-jailbreak methods that directly orient to
LLMs, our approach begins by constructing a multimodal large language model
(MLLM) built upon the target LLM. Subsequently, we perform an efficient MLLM
jailbreak and obtain a jailbreaking embedding. Finally, we convert the
embedding into a textual jailbreaking suffix to carry out the jailbreak of
target LLM. Compared to the direct LLM-jailbreak methods, our indirect
jailbreaking approach is more efficient, as MLLMs are more vulnerable to
jailbreak than pure LLM. Additionally, to improve the attack success rate of
jailbreak, we propose an image-text semantic matching scheme to identify a
suitable initial input. Extensive experiments demonstrate that our approach
surpasses current state-of-the-art jailbreak methods in terms of both
efficiency and effectiveness. Moreover, our approach exhibits superior
cross-class generalization abilities.",2024-05-30,"Zhenxing Niu, Yuyao Sun, Haoxuan Ji, Zheng Lin, Haichang Gao, Xinbo Gao, Gang Hua, Rong Jin",http://arxiv.org/pdf/2405.20015v2,cs.CL
Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities,"Uncertainty quantification in Large Language Models (LLMs) is crucial for
applications where safety and reliability are important. In particular,
uncertainty can be used to improve the trustworthiness of LLMs by detecting
factually incorrect model responses, commonly called hallucinations.
Critically, one should seek to capture the model's semantic uncertainty, i.e.,
the uncertainty over the meanings of LLM outputs, rather than uncertainty over
lexical or syntactic variations that do not affect answer correctness. To
address this problem, we propose Kernel Language Entropy (KLE), a novel method
for uncertainty estimation in white- and black-box LLMs. KLE defines positive
semidefinite unit trace kernels to encode the semantic similarities of LLM
outputs and quantifies uncertainty using the von Neumann entropy. It considers
pairwise semantic dependencies between answers (or semantic clusters),
providing more fine-grained uncertainty estimates than previous methods based
on hard clustering of answers. We theoretically prove that KLE generalizes the
previous state-of-the-art method called semantic entropy and empirically
demonstrate that it improves uncertainty quantification performance across
multiple natural language generation datasets and LLM architectures.",2024-05-30,"Alexander Nikitin, Jannik Kossen, Yarin Gal, Pekka Marttinen",http://arxiv.org/pdf/2405.20003v1,cs.CL
Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics,"Natural language is often the easiest and most convenient modality for humans
to specify tasks for robots. However, learning to ground language to behavior
typically requires impractical amounts of diverse, language-annotated
demonstrations collected on each target robot. In this work, we aim to separate
the problem of what to accomplish from how to accomplish it, as the former can
benefit from substantial amounts of external observation-only data, and only
the latter depends on a specific robot embodiment. To this end, we propose
Video-Language Critic, a reward model that can be trained on readily available
cross-embodiment data using contrastive learning and a temporal ranking
objective, and use it to score behavior traces from a separate actor. When
trained on Open X-Embodiment data, our reward model enables 2x more
sample-efficient policy training on Meta-World tasks than a sparse reward only,
despite a significant domain gap. Using in-domain data but in a challenging
task generalization setting on Meta-World, we further demonstrate more
sample-efficient training than is possible with prior language-conditioned
reward models that are either trained with binary classification, use static
images, or do not leverage the temporal information present in video data.",2024-05-30,"Minttu Alakuijala, Reginald McLean, Isaac Woungang, Nariman Farsad, Samuel Kaski, Pekka Marttinen, Kai Yuan",http://arxiv.org/pdf/2405.19988v2,cs.CL
Improved Out-of-Scope Intent Classification with Dual Encoding and Threshold-based Re-Classification,"Detecting out-of-scope user utterances is essential for task-oriented
dialogues and intent classification. Current methodologies face difficulties
with the unpredictable distribution of outliers and often rely on assumptions
about data distributions. We present the Dual Encoder for Threshold-Based
Re-Classification (DETER) to address these challenges. This end-to-end
framework efficiently detects out-of-scope intents without requiring
assumptions on data distributions or additional post-processing steps. The core
of DETER utilizes dual text encoders, the Universal Sentence Encoder (USE) and
the Transformer-based Denoising AutoEncoder (TSDAE), to generate user utterance
embeddings, which are classified through a branched neural architecture.
Further, DETER generates synthetic outliers using self-supervision and
incorporates out-of-scope phrases from open-domain datasets. This approach
ensures a comprehensive training set for out-of-scope detection. Additionally,
a threshold-based re-classification mechanism refines the model's initial
predictions. Evaluations on the CLINC-150, Stackoverflow, and Banking77
datasets demonstrate DETER's efficacy. Our model outperforms previous
benchmarks, increasing up to 13% and 5% in F1 score for known and unknown
intents on CLINC-150 and Stackoverflow, and 16% for known and 24% % for unknown
intents on Banking77. The source code has been released at
https://github.com/Hossam-Mohammed-tech/Intent_Classification_OOS.",2024-05-30,"Hossam M. Zawbaa, Wael Rashwan, Sourav Dutta, Haytham Assem",http://arxiv.org/pdf/2405.19967v2,cs.CL
Multi-Aspect Controllable Text Generation with Disentangled Counterfactual Augmentation,"Multi-aspect controllable text generation aims to control the generated texts
in attributes from multiple aspects (e.g., ""positive"" from sentiment and
""sport"" from topic). For ease of obtaining training samples, existing works
neglect attribute correlations formed by the intertwining of different
attributes. Particularly, the stereotype formed by imbalanced attribute
correlations significantly affects multi-aspect control. In this paper, we
propose MAGIC, a new multi-aspect controllable text generation method with
disentangled counterfactual augmentation. We alleviate the issue of imbalanced
attribute correlations during training using counterfactual feature vectors in
the attribute latent space by disentanglement. During inference, we enhance
attribute correlations by target-guided counterfactual augmentation to further
improve multi-aspect control. Experiments show that MAGIC outperforms
state-of-the-art baselines in both imbalanced and balanced attribute
correlation scenarios. Our source code and data are available at
https://github.com/nju-websoft/MAGIC.",2024-05-30,"Yi Liu, Xiangyu Liu, Xiangrong Zhu, Wei Hu",http://arxiv.org/pdf/2405.19958v1,cs.CL
"GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediation","A key challenge associated with Kubernetes configuration files (KCFs) is that
they are often highly complex and error-prone, leading to security
vulnerabilities and operational setbacks. Rule-based (RB) tools for KCF
misconfiguration detection rely on static rule sets, making them inherently
limited and unable to detect newly-discovered misconfigurations. RB tools also
suffer from misdetection, since mistakes are likely when coding the detection
rules. Recent methods for detecting and remediating KCF misconfigurations are
limited in terms of their scalability and detection coverage, or due to the
fact that they have high expertise requirements and do not offer automated
remediation along with misconfiguration detection. Novel approaches that employ
LLMs in their pipeline rely on API-based, general-purpose, and mainly
commercial models. Thus, they pose security challenges, have inconsistent
classification performance, and can be costly. In this paper, we propose
GenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition
to detecting a wide variety of KCF misconfigurations, also identifies the exact
location of the misconfigurations and provides detailed reasoning about them,
along with suggested remediation. When empirically compared with three
industry-standard RB tools, GenKubeSec achieved equivalent precision (0.990)
and superior recall (0.999). When a random sample of KCFs was examined by a
Kubernetes security expert, GenKubeSec's explanations as to misconfiguration
localization, reasoning and remediation were 100% correct, informative and
useful. To facilitate further advancements in this domain, we share the unique
dataset we collected, a unified misconfiguration index we developed for label
standardization, our experimentation code, and GenKubeSec itself as an
open-source tool.",2024-05-30,"Ehud Malul, Yair Meidan, Dudu Mimran, Yuval Elovici, Asaf Shabtai",http://arxiv.org/pdf/2405.19954v1,cs.CL
ExU: AI Models for Examining Multilingual Disinformation Narratives and Understanding their Spread,"Addressing online disinformation requires analysing narratives across
languages to help fact-checkers and journalists sift through large amounts of
data. The ExU project focuses on developing AI-based models for multilingual
disinformation analysis, addressing the tasks of rumour stance classification
and claim retrieval. We describe the ExU project proposal and summarise the
results of a user requirements survey regarding the design of tools to support
fact-checking.",2024-05-30,"Jake Vasilakes, Zhixue Zhao, Ivan Vykopal, Michal Gregor, Martin Hyben, Carolina Scarton",http://arxiv.org/pdf/2406.15443v1,cs.CL
Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts,"In recent years, large language models (LLMs) have made remarkable
achievements in various domains. However, the untimeliness and cost of
knowledge updates coupled with hallucination issues of LLMs have curtailed
their applications in knowledge intensive tasks, where retrieval augmented
generation (RAG) can be of help. Nevertheless, existing retrieval augmented
models typically use similarity as a bridge between queries and documents and
follow a retrieve then read procedure. In this work, we argue that similarity
is not always the panacea and totally relying on similarity would sometimes
degrade the performance of retrieval augmented generation. To this end, we
propose MetRag, a Multi layEred Thoughts enhanced Retrieval Augmented
Generation framework. To begin with, beyond existing similarity oriented
thought, we embrace a small scale utility model that draws supervision from an
LLM for utility oriented thought and further come up with a smarter model by
comprehensively combining the similarity and utility oriented thoughts.
Furthermore, given the fact that the retrieved document set tends to be huge
and using them in isolation makes it difficult to capture the commonalities and
characteristics among them, we propose to make an LLM as a task adaptive
summarizer to endow retrieval augmented generation with compactness-oriented
thought. Finally, with multi layered thoughts from the precedent stages, an LLM
is called for knowledge augmented generation. Extensive experiments on
knowledge-intensive tasks have demonstrated the superiority of MetRag.",2024-05-30,"Chunjing Gan, Dan Yang, Binbin Hu, Hanxiao Zhang, Siyuan Li, Ziqi Liu, Yue Shen, Lin Ju, Zhiqiang Zhang, Jinjie Gu, Lei Liang, Jun Zhou",http://arxiv.org/pdf/2405.19893v1,cs.CL
From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems,"In this work, from a theoretical lens, we aim to understand why large
language model (LLM) empowered agents are able to solve decision-making
problems in the physical world. To this end, consider a hierarchical
reinforcement learning (RL) model where the LLM Planner and the Actor perform
high-level task planning and low-level execution, respectively. Under this
model, the LLM Planner navigates a partially observable Markov decision process
(POMDP) by iteratively generating language-based subgoals via prompting. Under
proper assumptions on the pretraining data, we prove that the pretrained LLM
Planner effectively performs Bayesian aggregated imitation learning (BAIL)
through in-context learning. Additionally, we highlight the necessity for
exploration beyond the subgoals derived from BAIL by proving that naively
executing the subgoals returned by LLM leads to a linear regret. As a remedy,
we introduce an $\epsilon$-greedy exploration strategy to BAIL, which is proven
to incur sublinear regret when the pretraining error is small. Finally, we
extend our theoretical framework to include scenarios where the LLM Planner
serves as a world model for inferring the transition model of the environment
and to multi-agent settings, enabling coordination among multiple Actors.",2024-05-30,"Jianliang He, Siyu Chen, Fengzhuo Zhang, Zhuoran Yang",http://arxiv.org/pdf/2405.19883v2,cs.CL
KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models,"We present KNOW--the Knowledge Navigator Ontology for the World--the first
ontology designed to capture everyday knowledge to augment large language
models (LLMs) in real-world generative AI use cases such as personal AI
assistants. Our domain is human life, both its everyday concerns and its major
milestones. We have limited the initial scope of the modeled concepts to only
established human universals: spacetime (places, events) plus social (people,
groups, organizations). The inclusion criteria for modeled concepts are
pragmatic, beginning with universality and utility. We compare and contrast
previous work such as Schema.org and Cyc--as well as attempts at a synthesis of
knowledge graphs and language models--noting how LLMs already encode internally
much of the commonsense tacit knowledge that took decades to capture in the Cyc
project. We also make available code-generated software libraries for the 12
most popular programming languages, enabling the direct use of ontology
concepts in software engineering. We emphasize simplicity and developer
experience in promoting AI interoperability.",2024-05-30,Arto Bendiken,http://arxiv.org/pdf/2405.19877v1,cs.CL
Is In-Context Learning Sufficient for Instruction Following in LLMs?,"In-context learning (ICL) allows LLMs to learn from examples without changing
their weights: this is a particularly promising capability for long-context
LLMs that can potentially learn from many examples. Recently, Lin et al. (2024)
proposed URIAL, a method using only three in-context examples to align base
LLMs, achieving non-trivial instruction following performance. In this work, we
show that, while effective, ICL alignment with URIAL still underperforms
compared to instruction fine-tuning on the established benchmark MT-Bench,
especially with more capable base LLMs. We then uncover the most relevant
elements for successful in-context alignment, finding the crucial role of the
decoding parameters. Based on these insights, we show that the approach of
URIAL can indeed be improved by adding high-quality, potentially carefully
selected via greedy search, demonstrations in context, getting closer to the
performance of instruct models. Finally, we provide the first, to our
knowledge, systematic comparison of ICL and instruction fine-tuning (IFT) for
instruction following in the low data regime, where ICL can be a viable
alternative to IFT. Overall, our work advances the understanding of ICL as an
alignment technique and its relationship to IFT. We provide our code at
https://github.com/tml-epfl/icl-alignment.",2024-05-30,"Hao Zhao, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion",http://arxiv.org/pdf/2405.19874v3,cs.CL
DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories,"How to evaluate the coding abilities of Large Language Models (LLMs) remains
an open question. We find that existing benchmarks are poorly aligned with
real-world code repositories and are insufficient to evaluate the coding
abilities of LLMs.
  To address the knowledge gap, we propose a new benchmark named DevEval, which
has three advances. (1) DevEval aligns with real-world repositories in multiple
dimensions, e.g., code distributions and dependency distributions. (2) DevEval
is annotated by 13 developers and contains comprehensive annotations (e.g.,
requirements, original repositories, reference code, and reference
dependencies). (3) DevEval comprises 1,874 testing samples from 117
repositories, covering 10 popular domains (e.g., Internet, Database). Based on
DevEval, we propose repository-level code generation and evaluate 8 popular
LLMs on DevEval (e.g., gpt-4, gpt-3.5, StarCoder 2, DeepSeek Coder, CodeLLaMa).
Our experiments reveal these LLMs' coding abilities in real-world code
repositories. For example, in our experiments, the highest Pass@1 of
gpt-4-turbo is only 53.04%. We also analyze LLMs' failed cases and summarize
their shortcomings. We hope DevEval can facilitate the development of LLMs in
real code repositories. DevEval, prompts, and LLMs' predictions have been
released.",2024-05-30,"Jia Li, Ge Li, Yunfei Zhao, Yongmin Li, Huanyu Liu, Hao Zhu, Lecheng Wang, Kaibo Liu, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yuqi Zhu, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li",http://arxiv.org/pdf/2405.19856v1,cs.CL
Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model,"Recent advancements in large language models (LLMs) have highlighted the
importance of extending context lengths for handling complex tasks. While
traditional methods for training on long contexts often use filtered long
documents, these approaches lead to domain imbalances, limiting model
performance. To address this, techniques like random document concatenation
(Standard) and similarity-based methods (KNN, ICLM) have been developed.
However, they either sacrifice semantic coherence or diversity. To balance both
aspects, we introduce Quest, a query-centric data synthesis method aggregating
semantically relevant yet diverse documents. Quest uses a generative model to
predict potential queries for each document, grouping documents with similar
queries and keywords. Extensive experiments demonstrate Quest's superior
performance on long-context tasks, achieving remarkable results with context
lengths of up to 1M tokens and confirming its scalability across various model
sizes.",2024-05-30,"Chaochen Gao, Xing Wu, Qi Fu, Songlin Hu",http://arxiv.org/pdf/2405.19846v7,cs.CL
Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation,"Large language models (LLMs) exhibit enhanced reasoning at larger scales,
driving efforts to distill these capabilities into smaller models via
teacher-student learning. Previous works simply fine-tune student models on
teachers' generated Chain-of-Thoughts (CoTs) data. Although these methods
enhance in-domain (IND) reasoning performance, they struggle to generalize to
out-of-domain (OOD) tasks. We believe that the widespread spurious correlations
between questions and answers may lead the model to preset a specific answer
which restricts the diversity and generalizability of its reasoning process. In
this paper, we propose Cascading Decomposed CoTs Distillation (CasCoD) to
address these issues by decomposing the traditional single-step learning
process into two cascaded learning steps. Specifically, by restructuring the
training objectives -- removing the answer from outputs and concatenating the
question with the rationale as input -- CasCoD's two-step learning process
ensures that students focus on learning rationales without interference from
the preset answers, thus improving reasoning generalizability. Extensive
experiments demonstrate the effectiveness of CasCoD on both IND and OOD
benchmark reasoning datasets. Code can be found at
https://github.com/C-W-D/CasCoD.",2024-05-30,"Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu",http://arxiv.org/pdf/2405.19842v1,cs.CL
Just Rewrite It Again: A Post-Processing Method for Enhanced Semantic Similarity and Privacy Preservation of Differentially Private Rewritten Text,"The study of Differential Privacy (DP) in Natural Language Processing often
views the task of text privatization as a $\textit{rewriting}$ task, in which
sensitive input texts are rewritten to hide explicit or implicit private
information. In order to evaluate the privacy-preserving capabilities of a DP
text rewriting mechanism, $\textit{empirical privacy}$ tests are frequently
employed. In these tests, an adversary is modeled, who aims to infer sensitive
information (e.g., gender) about the author behind a (privatized) text. Looking
to improve the empirical protections provided by DP rewriting methods, we
propose a simple post-processing method based on the goal of aligning rewritten
texts with their original counterparts, where DP rewritten texts are rewritten
$\textit{again}$. Our results show that such an approach not only produces
outputs that are more semantically reminiscent of the original inputs, but also
texts which score on average better in empirical privacy evaluations.
Therefore, our approach raises the bar for DP rewriting methods in their
empirical privacy evaluations, providing an extra layer of protection against
malicious adversaries.",2024-05-30,"Stephen Meisenbacher, Florian Matthes",http://arxiv.org/pdf/2405.19831v2,cs.CL
Unsupervised Mutual Learning of Discourse Parsing and Topic Segmentation in Dialogue,"In dialogue systems, discourse plays a crucial role in managing
conversational focus and coordinating interactions. It consists of two key
structures: rhetorical structure and topic structure. The former captures the
logical flow of conversations, while the latter detects transitions between
topics. Together, they improve the ability of a dialogue system to track
conversation dynamics and generate contextually relevant high-quality
responses. These structures are typically identified through discourse parsing
and topic segmentation, respectively. However, existing supervised methods rely
on costly manual annotations, while unsupervised methods often focus on a
single task, overlooking the deep linguistic interplay between rhetorical and
topic structures. To address these issues, we first introduce a unified
representation that integrates rhetorical and topic structures, ensuring
semantic consistency between them. Under the unified representation, we further
propose two linguistically grounded hypotheses based on discourse theories: (1)
Local Discourse Coupling, where rhetorical cues dynamically enhance topic-aware
information flow, and (2) Global Topology Constraint, where topic structure
patterns probabilistically constrain rhetorical relation distributions.
Building on the unified representation and two hypotheses, we propose an
unsupervised mutual learning framework (UMLF) that jointly models rhetorical
and topic structures, allowing them to mutually reinforce each other without
requiring additional annotations. We evaluate our approach on two rhetorical
datasets and three topic segmentation datasets. Experimental results
demonstrate that our method surpasses all strong baselines built on pre-trained
language models. Furthermore, when applied to LLMs, our framework achieves
notable improvements, demonstrating its effectiveness in improving discourse
structure modeling.",2024-05-30,"Jiahui Xu, Feng Jiang, Anningzhe Gao, Luis Fernando D'Haro, Haizhou Li",http://arxiv.org/pdf/2405.19799v4,cs.CL
SLM as Guardian: Pioneering AI Safety with Small Language Models,"Most prior safety research of large language models (LLMs) has focused on
enhancing the alignment of LLMs to better suit the safety requirements of
humans. However, internalizing such safeguard features into larger models
brought challenges of higher training cost and unintended degradation of
helpfulness. To overcome such challenges, a modular approach employing a
smaller LLM to detect harmful user queries is regarded as a convenient solution
in designing LLM-based system with safety requirements.
  In this paper, we leverage a smaller LLM for both harmful query detection and
safeguard response generation. We introduce our safety requirements and the
taxonomy of harmfulness categories, and then propose a multi-task learning
mechanism fusing the two tasks into a single model. We demonstrate the
effectiveness of our approach, providing on par or surpassing harmful query
detection and safeguard response performance compared to the publicly available
LLMs.",2024-05-30,"Ohjoon Kwon, Donghyeon Jeon, Nayoung Choi, Gyu-Hwung Cho, Changbong Kim, Hyunwoo Lee, Inho Kang, Sun Kim, Taiwoo Park",http://arxiv.org/pdf/2405.19795v1,cs.CL
PDDLEGO: Iterative Planning in Textual Environments,"Planning in textual environments have been shown to be a long-standing
challenge even for current models. A recent, promising line of work uses LLMs
to generate a formal representation of the environment that can be solved by a
symbolic planner. However, existing methods rely on a fully-observed
environment where all entity states are initially known, so a one-off
representation can be constructed, leading to a complete plan. In contrast, we
tackle partially-observed environments where there is initially no sufficient
information to plan for the end-goal. We propose PDDLEGO that iteratively
construct a planning representation that can lead to a partial plan for a given
sub-goal. By accomplishing the sub-goal, more information is acquired to
augment the representation, eventually achieving the end-goal. We show that
plans produced by few-shot PDDLEGO are 43% more efficient than generating plans
end-to-end on the Coin Collector simulation, with strong performance (98%) on
the more complex Cooking World simulation where end-to-end LLMs fail to
generate coherent plans (4%).",2024-05-30,"Li Zhang, Peter Jansen, Tianyi Zhang, Peter Clark, Chris Callison-Burch, Niket Tandon",http://arxiv.org/pdf/2405.19793v2,cs.CL
From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers,"Instruction tuning -- tuning large language models on instruction-output
pairs -- is a promising technique for making models better adapted to the real
world. Yet, the key factors driving the model's capability to understand and
follow instructions not seen during training remain under-explored. Our
investigation begins with a series of synthetic experiments within the
theoretical framework of a Turing-complete algorithm called Markov algorithm,
which allows fine-grained control over the instruction-tuning data.
Generalization and robustness with respect to the training distribution emerge
once a diverse enough set of tasks is provided, even though very few examples
are provided for each task. We extend these initial results to a real-world
application scenario of code generation and find that a more diverse
instruction set, extending beyond code-related tasks, improves the performance
of code generation. Our observations suggest that a more diverse semantic space
for instruction-tuning sets greatly improves the model's ability to follow
instructions and perform tasks.",2024-05-30,"Dylan Zhang, Justin Wang, Francois Charton",http://arxiv.org/pdf/2405.19787v2,cs.CL
Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion,"Recent years have witnessed the deployment of code language models (LMs) in
various code intelligence tasks such as code completion. Yet, it is challenging
for pre-trained LMs to generate correct completions in private repositories.
Previous studies retrieve cross-file context based on import relations or text
similarity, which is insufficiently relevant to completion targets. In this
paper, we propose a dataflow-guided retrieval augmentation approach, called
DraCo, for repository-level code completion. DraCo parses a private repository
into code entities and establishes their relations through an extended dataflow
analysis, forming a repo-specific context graph. Whenever triggering code
completion, DraCo precisely retrieves relevant background knowledge from the
repo-specific context graph and generates well-formed prompts to query code
LMs. Furthermore, we construct a large Python dataset, ReccEval, with more
diverse completion targets. Our experiments demonstrate the superior accuracy
and applicable efficiency of DraCo, improving code exact match by 3.43% and
identifier F1-score by 3.27% on average compared to the state-of-the-art
approach.",2024-05-30,"Wei Cheng, Yuhan Wu, Wei Hu",http://arxiv.org/pdf/2405.19782v1,cs.CL
CharacterGPT: A Persona Reconstruction Framework for Role-Playing Agents,"The recent introduction of the Assistants API highlights its potential for
large language models (LLMs) in role-playing agents (RPA). However, maintaining
consistent character personas remains a significant challenge due to
variability in information extraction, which frequently omits critical elements
such as backstory or interpersonal relationships. To address this limitation,
we introduce CharacterGPT, a framework designed to dynamically reconstruct
character personas through Character Persona Training (CPT). This approach
incrementally updates personas by extracting traits from chapter-wise novel
summaries, reflecting the progression of the narrative. Our framework is
evaluated through Big Five personality evaluations and creative tasks, in which
characters generate original narratives, demonstrating the efficacy of
CharacterGPT in preserving persona consistency. The code and results are
available at https://github.com/Jeiyoon/charactergpt",2024-05-30,"Jeiyoon Park, Chanjun Park, Heuiseok Lim",http://arxiv.org/pdf/2405.19778v5,cs.CL
Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding,"Recent strides in large language models (LLMs) have yielded remarkable
performance, leveraging reinforcement learning from human feedback (RLHF) to
significantly enhance generation and alignment capabilities. However, RLHF
encounters numerous challenges, including the objective mismatch issue, leading
to suboptimal performance in Natural Language Understanding (NLU) tasks. To
address this limitation, we propose a novel Reinforcement Learning framework
enhanced with Label-sensitive Reward (RLLR) to amplify the performance of LLMs
in NLU tasks. By incorporating label-sensitive pairs into reinforcement
learning, our method aims to adeptly capture nuanced label-sensitive semantic
features during RL, thereby enhancing natural language understanding.
Experiments conducted on five diverse foundation models across eight tasks
showcase promising results. In comparison to Supervised Fine-tuning models
(SFT), RLLR demonstrates an average performance improvement of 1.54%. Compared
with RLHF models, the improvement averages at 0.69%. These results reveal the
effectiveness of our method for LLMs in NLU tasks. Code and data available at:
https://github.com/MagiaSN/ACL2024_RLLR.",2024-05-30,"Kuo Liao, Shuang Li, Meng Zhao, Liqun Liu, Mengge Xue, Zhenyu Hu, Honglin Han, Chengguo Yin",http://arxiv.org/pdf/2405.19763v1,cs.CL
X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions,"Large language models respond well in high-resource languages like English
but struggle in low-resource languages. It may arise from the lack of
high-quality instruction following data in these languages. Directly
translating English samples into these languages can be a solution but
unreliable, leading to responses with translation errors and lacking
language-specific or cultural knowledge. To address this issue, we propose a
novel method to construct cross-lingual instruction following samples with
instruction in English and response in low-resource languages. Specifically,
the language model first learns to generate appropriate English instructions
according to the natural web texts in other languages as responses. The
candidate cross-lingual instruction tuning samples are further refined and
diversified. We have employed this method to build a large-scale cross-lingual
instruction tuning dataset on 10 languages, namely X-Instruction. The
instruction data built using our method incorporate more language-specific
knowledge compared with the naive translation method. Experimental results have
shown that the response quality of the model tuned on X-Instruction greatly
exceeds the model distilled from a powerful teacher model, reaching or even
surpassing the ones of ChatGPT. In addition, we find that models tuned on
cross-lingual instruction following samples can follow the instruction in the
output language without further tuning.",2024-05-30,"Chong Li, Wen Yang, Jiajun Zhang, Jinliang Lu, Shaonan Wang, Chengqing Zong",http://arxiv.org/pdf/2405.19744v1,cs.CL
PertEval: Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations,"Expert-designed close-ended benchmarks are indispensable in assessing the
knowledge capacity of large language models (LLMs). Despite their widespread
use, concerns have mounted regarding their reliability due to limited test
scenarios and an unavoidable risk of data contamination. To rectify this, we
present PertEval, a toolkit devised for in-depth probing of LLMs' knowledge
capacity through \textbf{knowledge-invariant perturbations}. These
perturbations employ human-like restatement techniques to generate on-the-fly
test samples from static benchmarks, meticulously retaining knowledge-critical
content while altering irrelevant details. Our toolkit further includes a suite
of \textbf{response consistency analyses} that compare performance on raw vs.
perturbed test sets to precisely assess LLMs' genuine knowledge capacity. Six
representative LLMs are re-evaluated using PertEval. Results reveal
significantly inflated performance of the LLMs on raw benchmarks, including an
absolute 25.8% overestimation for GPT-4. Additionally, through a nuanced
response pattern analysis, we discover that PertEval retains LLMs' uncertainty
to specious knowledge, and reveals their potential rote memorization to correct
options which leads to overestimated performance. We also find that the
detailed response consistency analyses by PertEval could illuminate various
weaknesses in existing LLMs' knowledge mastery and guide the development of
refinement. Our findings provide insights for advancing more robust and
genuinely knowledgeable LLMs. Our code is available at
\url{https://github.com/aigc-apps/PertEval}.",2024-05-30,"Jiatong Li, Renjun Hu, Kunzhe Huang, Yan Zhuang, Qi Liu, Mengxiao Zhu, Xing Shi, Wei Lin",http://arxiv.org/pdf/2405.19740v2,cs.CL
Beyond Imitation: Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation,"As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts
(CoTs) reasoning abilities, practical resource constraints drive efforts to
distill these capabilities into more compact Smaller Language Models (SLMs). We
find that CoTs consist mainly of simple reasoning forms, with a small
proportion ($\approx 4.7\%$) of key reasoning steps that truly impact
conclusions. However, previous distillation methods typically involve
supervised fine-tuning student SLMs only on correct CoTs data produced by
teacher LLMs, resulting in students struggling to learn the key reasoning
steps, instead imitating the teacher's reasoning forms and making errors or
omissions on these steps. To address these issues, drawing an analogy to human
learning, where analyzing mistakes according to correct solutions often reveals
the crucial steps leading to successes or failures, we propose
mistak\textbf{E}-\textbf{D}riven key reason\textbf{I}ng step
distilla\textbf{T}ion (\textbf{EDIT}), a novel method that further aids SLMs
learning key reasoning steps rather than mere simple fine-tuning. Firstly, to
expose these crucial steps in CoTs, we design specific prompts to generate dual
CoTs data with similar reasoning paths but divergent conclusions. Then, we
apply the minimum edit distance algorithm on the dual CoTs data to locate these
key steps and optimize the likelihood of these steps. Extensive experiments
validate the effectiveness of EDIT across both in-domain and out-of-domain
benchmark reasoning datasets. Further analysis shows that EDIT can generate
high-quality CoTs with more correct key reasoning steps. Notably, we also
explore how different mistake patterns affect performance and find that EDIT
benefits more from logical errors than from knowledge or mathematical
calculation errors in dual CoTs\footnote{Code can be found at
\url{https://github.com/C-W-D/EDIT}}.",2024-05-30,"Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu",http://arxiv.org/pdf/2405.19737v1,cs.CL
LLM as a Complementary Optimizer to Gradient Descent: A Case Study in Prompt Tuning,"Mastering a skill generally relies on both hands-on experience from doers and
insightful, high-level guidance by mentors. Will this strategy also work well
for solving complex non-convex optimization problems? Here, a common
gradient-based optimizer acts like a disciplined doer, making locally optimal
updates at each step. Large Language Models (LLMs) can also search for better
solutions by inferring from natural language instructions, akin to a high-level
mentor. In this paper, we show that these two participators are complementary
to each other and can effectively collaborate as a combined optimization
framework. The collaborative optimization is achieved by alternating between
the gradient-based and LLM-based optimizers. We instruct LLMs to generate
possibly improved solutions by taking parameter trajectories recorded during
the previous stage of gradient-based optimization into account. Inferred
results of LLMs are used as restarting points for the next stage of gradient
optimization. We verify the effectiveness of this optimization framework on
prompt tuning. By leveraging both the locally rigorous gradient-based optimizer
and the high-level deductive LLM-based optimizer, the combined optimization
method consistently yields improvements over competitive baselines on a variety
of tasks. Our results demonstrate the synergistic effect of conventional
gradient-based optimization and the inference ability of LLMs. The code is
released at https://github.com/guozix/LLM-catalyst.",2024-05-30,"Zixian Guo, Ming Liu, Zhilong Ji, Jinfeng Bai, Yiwen Guo, Wangmeng Zuo",http://arxiv.org/pdf/2405.19732v4,cs.CL
Enhancing Large Vision Language Models with Self-Training on Image Comprehension,"Large vision language models (LVLMs) integrate large language models (LLMs)
with pre-trained vision encoders, thereby activating the perception capability
of the model to understand image inputs for different queries and conduct
subsequent reasoning. Improving this capability requires high-quality
vision-language data, which is costly and labor-intensive to acquire.
Self-training approaches have been effective in single-modal settings to
alleviate the need for labeled data by leveraging model's own generation.
However, effective self-training remains a challenge regarding the unique
visual perception and reasoning capability of LVLMs. To address this, we
introduce Self-Training on Image Comprehension (STIC), which emphasizes a
self-training approach specifically for image comprehension. First, the model
self-constructs a preference dataset for image descriptions using unlabeled
images. Preferred responses are generated through a step-by-step prompt, while
dis-preferred responses are generated from either corrupted images or
misleading prompts. To further self-improve reasoning on the extracted visual
information, we let the model reuse a small portion of existing
instruction-tuning data and append its self-generated image descriptions to the
prompts. We validate the effectiveness of STIC across seven different
benchmarks, demonstrating substantial performance gains of 4.0% on average
while using 70% less supervised fine-tuning data than the current method.
Further studies investigate various components of STIC and highlight its
potential to leverage vast quantities of unlabeled images for self-training.
Code and data are made publicly available.",2024-05-30,"Yihe Deng, Pan Lu, Fan Yin, Ziniu Hu, Sheng Shen, Quanquan Gu, James Zou, Kai-Wei Chang, Wei Wang",http://arxiv.org/pdf/2405.19716v2,cs.CL
SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths,"Speculative decoding reduces the inference latency of a target large language
model via utilizing a smaller and faster draft model. Its performance depends
on a hyperparameter K -- the candidate length, i.e., the number of candidate
tokens for the target model to verify in each round. However, previous methods
often use simple heuristics to choose K, which may result in sub-optimal
performance. We study the choice of the candidate length K and formulate it as
a Markov Decision Process. We theoretically show that the optimal policy of
this Markov decision process takes the form of a threshold policy, i.e., the
current speculation should stop and be verified when the probability of getting
a rejection exceeds a threshold value. Motivated by this theory, we propose
SpecDec++, an enhanced version of speculative decoding that adaptively
determines the candidate length on the fly. We augment the draft model with a
trained acceptance prediction head to predict the conditional acceptance
probability of the candidate tokens. SpecDec++ will stop the current
speculation when the predicted probability that at least one token gets
rejected exceeds a threshold. We implement SpecDec++ and apply it to the
llama-2-chat 7B & 70B model pair. Our adaptive method achieves a 2.04x speedup
on the Alpaca dataset (an additional 7.2% improvement over the baseline
speculative decoding). On the GSM8K and HumanEval datasets, our method achieves
a 2.26x speedup (9.4% improvement) and 2.23x speedup (11.1% improvement),
respectively.",2024-05-30,"Kaixuan Huang, Xudong Guo, Mengdi Wang",http://arxiv.org/pdf/2405.19715v2,cs.CL
Significance of Chain of Thought in Gender Bias Mitigation for English-Dravidian Machine Translation,"Gender bias in machine translation (MT) sys- tems poses a significant
challenge to achieving accurate and inclusive translations. This paper examines
gender bias in machine translation systems for languages such as Telugu and
Kan- nada from the Dravidian family, analyzing how gender inflections affect
translation accuracy and neutrality using Google Translate and Chat- GPT. It
finds that while plural forms can reduce bias, individual-centric sentences
often main- tain the bias due to historical stereotypes. The study evaluates
the Chain of Thought process- ing, noting significant bias mitigation from 80%
to 4% in Telugu and from 40% to 0% in Kan- nada. It also compares Telugu and
Kannada translations, emphasizing the need for language specific strategies to
address these challenges and suggesting directions for future research to
enhance fairness in both data preparation and prompts during inference.",2024-05-30,"Lavanya Prahallad, Radhika Mamidi",http://arxiv.org/pdf/2405.19701v2,cs.CL
One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for Retrieval-Augmented Large Language Models,"Retrieval-augmented generation (RAG) is a promising way to improve large
language models (LLMs) for generating more factual, accurate, and up-to-date
content. Existing methods either optimize prompts to guide LLMs in leveraging
retrieved information or directly fine-tune LLMs to adapt to RAG scenarios.
Although fine-tuning can yield better performance, it often compromises the
LLMs' general generation capabilities by modifying their parameters. This
limitation poses challenges in practical applications, especially when LLMs are
already deployed, as parameter adjustments may affect their original
functionality. To address this, we propose a novel method that involves
learning scalable and pluggable virtual tokens for RAG. By maintaining the
LLMs' original parameters and fine-tuning only the embeddings of these
pluggable tokens, our approach not only enhances LLMs' performance but also
preserves their general generation capabilities. Furthermore, we design several
training strategies to improve the scalability, flexibility, and
generalizability of our method. Comprehensive experiments across 12
question-answering tasks demonstrate the superiority of our approach.",2024-05-30,"Yutao Zhu, Zhaoheng Huang, Zhicheng Dou, Ji-Rong Wen",http://arxiv.org/pdf/2405.19670v4,cs.CL
PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals,"Mental illness remains one of the most critical public health issues. Despite
its importance, many mental health professionals highlight a disconnect between
their training and actual real-world patient practice. To help bridge this gap,
we propose PATIENT-{\Psi}, a novel patient simulation framework for cognitive
behavior therapy (CBT) training. To build PATIENT-{\Psi}, we construct diverse
patient cognitive models based on CBT principles and use large language models
(LLMs) programmed with these cognitive models to act as a simulated therapy
patient. We propose an interactive training scheme, PATIENT-{\Psi}-TRAINER, for
mental health trainees to practice a key skill in CBT -- formulating the
cognitive model of the patient -- through role-playing a therapy session with
PATIENT-{\Psi}. To evaluate PATIENT-{\Psi}, we conducted a comprehensive user
study of 13 mental health trainees and 20 experts. The results demonstrate that
practice using PATIENT-{\Psi}-TRAINER enhances the perceived skill acquisition
and confidence of the trainees beyond existing forms of training such as
textbooks, videos, and role-play with non-patients. Based on the experts'
perceptions, PATIENT-{\Psi} is perceived to be closer to real patient
interactions than GPT-4, and PATIENT-{\Psi}-TRAINER holds strong promise to
improve trainee competencies. Our code and data are released at
\url{https://github.com/ruiyiw/patient-psi}.",2024-05-30,"Ruiyi Wang, Stephanie Milani, Jamie C. Chiu, Jiayin Zhi, Shaun M. Eack, Travis Labrum, Samuel M. Murphy, Nev Jones, Kate Hardy, Hong Shen, Fei Fang, Zhiyu Zoey Chen",http://arxiv.org/pdf/2405.19660v3,cs.CL
SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems,"Surrogate models are used to predict the behavior of complex energy systems
that are too expensive to simulate with traditional numerical methods. Our work
introduces the use of language descriptions, which we call ``system captions''
or SysCaps, to interface with such surrogates. We argue that interacting with
surrogates through text, particularly natural language, makes these models more
accessible for both experts and non-experts. We introduce a lightweight
multimodal text and timeseries regression model and a training pipeline that
uses large language models (LLMs) to synthesize high-quality captions from
simulation metadata. Our experiments on two real-world simulators of buildings
and wind farms show that our SysCaps-augmented surrogates have better accuracy
on held-out systems than traditional methods while enjoying new generalization
abilities, such as handling semantically related descriptions of the same test
system. Additional experiments also highlight the potential of SysCaps to
unlock language-driven design space exploration and to regularize training
through prompt augmentation.",2024-05-30,"Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen",http://arxiv.org/pdf/2405.19653v4,cs.CL
Detecting Hallucinations in Large Language Model Generation: A Token Probability Approach,"Concerns regarding the propensity of Large Language Models (LLMs) to produce
inaccurate outputs, also known as hallucinations, have escalated. Detecting
them is vital for ensuring the reliability of applications relying on
LLM-generated content. Current methods often demand substantial resources and
rely on extensive LLMs or employ supervised learning with multidimensional
features or intricate linguistic and semantic analyses difficult to reproduce
and largely depend on using the same LLM that hallucinated. This paper
introduces a supervised learning approach employing two simple classifiers
utilizing only four numerical features derived from tokens and vocabulary
probabilities obtained from other LLM evaluators, which are not necessarily the
same. The method yields promising results, surpassing state-of-the-art outcomes
in multiple tasks across three different benchmarks. Additionally, we provide a
comprehensive examination of the strengths and weaknesses of our approach,
highlighting the significance of the features utilized and the LLM employed as
an evaluator. We have released our code publicly at
https://github.com/Baylor-AI/HalluDetect.",2024-05-30,"Ernesto Quevedo, Jorge Yero, Rachel Koerner, Pablo Rivas, Tomas Cerny",http://arxiv.org/pdf/2405.19648v1,cs.CL
Efficient Systematic Reviews: Literature Filtering with Transformers & Transfer Learning,"Identifying critical research within the growing body of academic work is an
intrinsic aspect of conducting quality research. Systematic review processes
used in evidence-based medicine formalise this as a procedure that must be
followed in a research program. However, it comes with an increasing burden in
terms of the time required to identify the important articles of research for a
given topic. In this work, we develop a method for building a general-purpose
filtering system that matches a research question, posed as a natural language
description of the required content, against a candidate set of articles
obtained via the application of broad search terms. Our results demonstrate
that transformer models, pre-trained on biomedical literature, and then fine
tuned for the specific task, offer a promising solution to this problem. The
model can remove large volumes of irrelevant articles for most research
questions. Furthermore, analysis of the specific research questions in our
training data suggest natural avenues for further improvement.",2024-05-30,"John Hawkins, David Tivey",http://arxiv.org/pdf/2405.20354v2,cs.CL
GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient Cloud-edge Collaboration LLM Deployment,"The burgeoning size of Large Language Models (LLMs) has led to enhanced
capabilities in generating responses, albeit at the expense of increased
inference times and elevated resource demands. Existing methods of
acceleration, predominantly hinged on knowledge distillation, generally
necessitate fine-tuning of considerably large models, such as Llama-7B, posing
a challenge for average users. Furthermore, present techniques for expediting
inference and reducing costs operate independently. To address these issues, we
introduce a novel and intuitive Guidance-based Knowledge Transfer (GKT)
framework. This approach leverages a larger LLM as a ''teacher'' to create
guidance prompts, paired with a smaller ''student'' model to finalize
responses. Remarkably, GKT requires no fine-tuning and doesn't necessitate the
teacher and student models to have the same vocabulary, allowing for extensive
batch generation to accelerate the process while ensuring user customization.
GKT can be seamlessly integrated into cloud-edge collaboration architectures,
and is versatile enough for plug-and-play application across various models. It
excels in both efficiency and affordability, epitomizing a ''cheap and
cheerful'' solution. GKT achieves a maximum accuracy improvement of 14.18%,
along with a 10.72 times speed-up on GSM8K and an accuracy improvement of 14.00
% along with a 7.73 times speed-up in CSQA. When utilizing ChatGPT as teacher
model and Llama2-70B as the student model, we can achieve 95.00% of ChatGPT's
performance at 52% of the cost. The results highlight substantial enhancements
in accuracy and processing speed on the GSM8K and CSQA datasets, surpassing the
performance of using either the student or teacher models in isolation.",2024-05-30,"Yao Yao, Zuchao Li, Hai Zhao",http://arxiv.org/pdf/2405.19635v1,cs.CL
Easy Problems That LLMs Get Wrong,"We introduce a comprehensive Linguistic Benchmark designed to evaluate the
limitations of Large Language Models (LLMs) in domains such as logical
reasoning, spatial intelligence, and linguistic understanding, among others.
Through a series of straightforward questions, it uncovers the significant
limitations of well-regarded models to perform tasks that humans manage with
ease. It also highlights the potential of prompt engineering to mitigate some
errors and underscores the necessity for better training methodologies. Our
findings stress the importance of grounding LLMs with human reasoning and
common sense, emphasising the need for human-in-the-loop for enterprise
applications. We hope this work paves the way for future research to enhance
the usefulness and reliability of new models.",2024-05-30,"Sean Williams, James Huckle",http://arxiv.org/pdf/2405.19616v2,cs.CL
Analysing the Public Discourse around OpenAI's Text-To-Video Model 'Sora' using Topic Modeling,"The recent introduction of OpenAI's text-to-video model Sora has sparked
widespread public discourse across online communities. This study aims to
uncover the dominant themes and narratives surrounding Sora by conducting topic
modeling analysis on a corpus of 1,827 Reddit comments from five relevant
subreddits (r/OpenAI, r/technology, r/singularity, r/vfx, and r/ChatGPT). The
comments were collected over a two-month period following Sora's announcement
in February 2024. After preprocessing the data, Latent Dirichlet Allocation
(LDA) was employed to extract four key topics: 1) AI Impact and Trends in Sora
Discussions, 2) Public Opinion and Concerns about Sora, 3) Artistic Expression
and Video Creation with Sora, and 4) Sora's Applications in Media and
Entertainment. Visualizations including word clouds, bar charts, and t-SNE
clustering provided insights into the importance of topic keywords and the
distribution of comments across topics. The results highlight prominent
narratives around Sora's potential impact on industries and employment, public
sentiment and ethical concerns, creative applications, and use cases in the
media and entertainment sectors. While limited to Reddit data within a specific
timeframe, this study offers a framework for understanding public perceptions
of emerging generative AI technologies through online discourse analysis.",2024-05-30,Vatsal Vinay Parikh,http://arxiv.org/pdf/2407.13071v1,cs.CL
SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors,"Popular parameter-efficient fine-tuning (PEFT) methods, such as LoRA and its
variants, freeze pre-trained model weights \(W\) and inject learnable matrices
\(\Delta W\). These \(\Delta W\) matrices are structured for efficient
parameterization, often using techniques like low-rank approximations or
scaling vectors. However, these methods typically show a performance gap
compared to full fine-tuning. Although recent PEFT methods have narrowed this
gap, they do so at the cost of additional learnable parameters. We propose
SVFT, a simple approach that fundamentally differs from existing methods: the
structure imposed on \(\Delta W\) depends on the specific weight matrix \(W\).
Specifically, SVFT updates \(W\) as a sparse combination of outer products of
its singular vectors, training only the coefficients (scales) of these sparse
combinations. This approach allows fine-grained control over expressivity
through the number of coefficients. Extensive experiments on language and
vision benchmarks show that SVFT recovers up to 96% of full fine-tuning
performance while training only 0.006 to 0.25% of parameters, outperforming
existing methods that only recover up to 85% performance using 0.03 to 0.8% of
the trainable parameter budget.",2024-05-30,"Vijay Lingam, Atula Tejaswi, Aditya Vavre, Aneesh Shetty, Gautham Krishna Gudur, Joydeep Ghosh, Alex Dimakis, Eunsol Choi, Aleksandar Bojchevski, Sujay Sanghavi",http://arxiv.org/pdf/2405.19597v1,cs.CL
Why Larger Language Models Do In-context Learning Differently?,"Large language models (LLM) have emerged as a powerful tool for AI, with the
key ability of in-context learning (ICL), where they can perform well on unseen
tasks based on a brief series of task examples without necessitating any
adjustments to the model parameters. One recent interesting mysterious
observation is that models of different scales may have different ICL
behaviors: larger models tend to be more sensitive to noise in the test
context. This work studies this observation theoretically aiming to improve the
understanding of LLM and ICL. We analyze two stylized settings: (1) linear
regression with one-layer single-head linear transformers and (2) parity
classification with two-layer multiple attention heads transformers (non-linear
data and non-linear model). In both settings, we give closed-form optimal
solutions and find that smaller models emphasize important hidden features
while larger ones cover more hidden features; thus, smaller models are more
robust to noise while larger ones are more easily distracted, leading to
different ICL behaviors. This sheds light on where transformers pay attention
to and how that affects ICL. Preliminary experimental results on large base and
chat models provide positive support for our analysis.",2024-05-30,"Zhenmei Shi, Junyi Wei, Zhuoyan Xu, Yingyu Liang",http://arxiv.org/pdf/2405.19592v1,cs.CL
Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases,"Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of
binary and source code, aiming to lift binary code to human-readable content
relevant to source code, thereby bridging the binary-source semantic gap.
Recent advancements in uni-modal code model pre-training, particularly in
generative Source Code Foundation Models (SCFMs) and binary understanding
models, have laid the groundwork for transfer learning applicable to HOBRE.
However, existing approaches for HOBRE rely heavily on uni-modal models like
SCFMs for supervised fine-tuning or general LLMs for prompting, resulting in
sub-optimal performance. Inspired by recent progress in large multi-modal
models, we propose that it is possible to harness the strengths of uni-modal
code models from both sides to bridge the semantic gap effectively. In this
paper, we introduce a novel probe-and-recover framework that incorporates a
binary-source encoder-decoder model and black-box LLMs for binary analysis. Our
approach leverages the pre-trained knowledge within SCFMs to synthesize
relevant, symbol-rich code fragments as context. This additional context
enables black-box LLMs to enhance recovery accuracy. We demonstrate significant
improvements in zero-shot binary summarization and binary function name
recovery, with a 10.3% relative gain in CHRF and a 16.7% relative gain in a
GPT4-based metric for summarization, as well as a 6.7% and 7.4% absolute
increase in token-level precision and recall for name recovery, respectively.
These results highlight the effectiveness of our approach in automating and
improving binary code analysis.",2024-05-30,"Zian Su, Xiangzhe Xu, Ziyang Huang, Kaiyuan Zhang, Xiangyu Zhang",http://arxiv.org/pdf/2405.19581v2,cs.CL
A Deep Convolutional Neural Network-based Model for Aspect and Polarity Classification in Hausa Movie Reviews,"Aspect-based Sentiment Analysis (ABSA) is crucial for understanding sentiment
nuances in text, especially across diverse languages and cultures. This paper
introduces a novel Deep Convolutional Neural Network (CNN)-based model tailored
for aspect and polarity classification in Hausa movie reviews, an
underrepresented language in sentiment analysis research. A comprehensive Hausa
ABSA dataset is created, filling a significant gap in resource availability.
The dataset, preprocessed using sci-kit-learn for TF-IDF transformation,
includes manually annotated aspect-level feature ontology words and sentiment
polarity assignments. The proposed model combines CNNs with attention
mechanisms for aspect-word prediction, leveraging contextual information and
sentiment polarities. With 91% accuracy on aspect term extraction and 92% on
sentiment polarity classification, the model outperforms traditional machine
models, offering insights into specific aspects and sentiments. This study
advances ABSA research, particularly in underrepresented languages, with
implications for cross-cultural linguistic research.",2024-05-29,"Umar Ibrahim, Abubakar Yakubu Zandam, Fatima Muhammad Adam, Aminu Musa",http://arxiv.org/pdf/2405.19575v1,cs.CL
Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding,"Vision-Language Models (VLM) can support clinicians by analyzing medical
images and engaging in natural language interactions to assist in diagnostic
and treatment tasks. However, VLMs often exhibit ""hallucinogenic"" behavior,
generating textual outputs not grounded in contextual multimodal information.
This challenge is particularly pronounced in the medical domain, where we do
not only require VLM outputs to be accurate in single interactions but also to
be consistent with clinical reasoning and diagnostic pathways throughout
multi-turn conversations. For this purpose, we propose a new alignment
algorithm that uses symbolic representations of clinical reasoning to ground
VLMs in medical knowledge. These representations are utilized to (i) generate
GPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM
conversations with demonstrations of clinical reasoning, and (ii) create an
automatic reward function that evaluates the clinical validity of VLM
generations throughout clinician-VLM interactions. Our algorithm eliminates the
need for human involvement in training data generation or reward model
construction, reducing costs compared to standard reinforcement learning with
human feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a
conversational VLM finetuned for analyzing bone marrow pathology slides,
demonstrating strong performance in multi-turn medical conversations.",2024-05-29,"Shenghuan Sun, Alexander Schubert, Gregory M. Goldgof, Zhiqing Sun, Thomas Hartvigsen, Atul J. Butte, Ahmed Alaa",http://arxiv.org/pdf/2405.19567v2,cs.CL
Unlearning Climate Misinformation in Large Language Models,"Misinformation regarding climate change is a key roadblock in addressing one
of the most serious threats to humanity. This paper investigates factual
accuracy in large language models (LLMs) regarding climate information. Using
true/false labeled Q&A data for fine-tuning and evaluating LLMs on
climate-related claims, we compare open-source models, assessing their ability
to generate truthful responses to climate change questions. We investigate the
detectability of models intentionally poisoned with false climate information,
finding that such poisoning may not affect the accuracy of a model's responses
in other domains. Furthermore, we compare the effectiveness of unlearning
algorithms, fine-tuning, and Retrieval-Augmented Generation (RAG) for factually
grounding LLMs on climate change topics. Our evaluation reveals that unlearning
algorithms can be effective for nuanced conceptual claims, despite previous
findings suggesting their inefficacy in privacy contexts. These insights aim to
guide the development of more factually reliable LLMs and highlight the need
for additional work to secure LLMs against misinformation attacks.",2024-05-29,"Michael Fore, Simranjit Singh, Chaehong Lee, Amritanshu Pandey, Antonios Anastasopoulos, Dimitrios Stamoulis",http://arxiv.org/pdf/2405.19563v1,cs.CL
Selective Explanations,"Feature attribution methods explain black-box machine learning (ML) models by
assigning importance scores to input features. These methods can be
computationally expensive for large ML models. To address this challenge, there
has been increasing efforts to develop amortized explainers, where a machine
learning model is trained to predict feature attribution scores with only one
inference. Despite their efficiency, amortized explainers can produce
inaccurate predictions and misleading explanations. In this paper, we propose
selective explanations, a novel feature attribution method that (i) detects
when amortized explainers generate low-quality explanations and (ii) improves
these explanations using a technique called explanations with initial guess.
Our selective explanation method allows practitioners to specify the fraction
of samples that receive explanations with initial guess, offering a principled
way to bridge the gap between amortized explainers and their high-quality
counterparts.",2024-05-29,"Lucas Monteiro Paes, Dennis Wei, Flavio P. Calmon",http://arxiv.org/pdf/2405.19562v1,cs.CL
Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study,"Automated clinical text anonymization has the potential to unlock the
widespread sharing of textual health data for secondary usage while assuring
patient privacy and safety. Despite the proposal of many complex and
theoretically successful anonymization solutions in literature, these
techniques remain flawed. As such, clinical institutions are still reluctant to
apply them for open access to their data. Recent advances in developing Large
Language Models (LLMs) pose a promising opportunity to further the field, given
their capability to perform various tasks. This paper proposes six new
evaluation metrics tailored to the challenges of generative anonymization with
LLMs. Moreover, we present a comparative study of LLM-based methods, testing
them against two baseline techniques. Our results establish LLM-based models as
a reliable alternative to common approaches, paving the way toward trustworthy
anonymization of clinical text.",2024-05-29,"David Pissarra, Isabel Curioso, João Alveira, Duarte Pereira, Bruno Ribeiro, Tomás Souper, Vasco Gomes, André V. Carreiro, Vitor Rolla",http://arxiv.org/pdf/2406.00062v1,cs.CL
Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models,"The startling success of ChatGPT and other large language models (LLMs) using
transformer-based generative neural network architecture in applications such
as natural language processing and image synthesis has many researchers excited
about potential opportunities in process systems engineering (PSE). The almost
human-like performance of LLMs in these areas is indeed very impressive,
surprising, and a major breakthrough. Their capabilities are very useful in
certain tasks, such as writing first drafts of documents, code writing
assistance, text summarization, etc. However, their success is limited in
highly scientific domains as they cannot yet reason, plan, or explain due to
their lack of in-depth domain knowledge. This is a problem in domains such as
chemical engineering as they are governed by fundamental laws of physics and
chemistry (and biology), constitutive relations, and highly technical knowledge
about materials, processes, and systems. Although purely data-driven machine
learning has its immediate uses, the long-term success of AI in scientific and
engineering domains would depend on developing hybrid AI systems that use first
principles and technical knowledge effectively. We call these hybrid AI systems
Large Knowledge Models (LKMs), as they will not be limited to only NLP-based
techniques or NLP-like applications. In this paper, we discuss the challenges
and opportunities in developing such systems in chemical engineering.",2024-05-29,"Venkat Venkatasubramanian, Arijit Chakraborty",http://arxiv.org/pdf/2405.19561v1,cs.CL
STAT: Shrinking Transformers After Training,"We present STAT: a simple algorithm to prune transformer models without any
fine-tuning. STAT eliminates both attention heads and neurons from the network,
while preserving accuracy by calculating a correction to the weights of the
next layer. Each layer block in the network is compressed using a series of
principled matrix factorizations that preserve the network structure. Our
entire algorithm takes minutes to compress BERT, and less than three hours to
compress models with 7B parameters using a single GPU. Using only several
hundred data examples, STAT preserves the output of the network and improves
upon existing gradient-free pruning methods. It is even competitive with
methods that include significant fine-tuning. We demonstrate our method on both
encoder and decoder architectures, including BERT, DistilBERT, and Llama-2
using benchmarks such as GLUE, Squad, WikiText2.",2024-05-29,"Megan Flynn, Alexander Wang, Dean Edward Alvarez, Christopher De Sa, Anil Damle",http://arxiv.org/pdf/2406.00061v1,cs.CL
Cascade-Aware Training of Language Models,"Reducing serving cost and latency is a fundamental concern for the deployment
of language models (LMs) in business applications. To address this, cascades of
LMs offer an effective solution that conditionally employ smaller models for
simpler queries. Cascaded systems are typically built with independently
trained models, neglecting the advantages of considering inference-time
interactions of the cascaded LMs during training. In this paper, we present
cascade-aware training(CAT), an approach to optimizing the overall quality-cost
performance tradeoff of a cascade of LMs. We achieve inference-time benefits by
training the small LM with awareness of its place in a cascade and downstream
capabilities. We demonstrate the value of the proposed method with over 60 LM
tasks of the SuperGLUE, WMT22, and FLAN2021 datasets.",2024-05-29,"Congchao Wang, Sean Augenstein, Keith Rush, Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Aditya Krishna Menon, Alec Go",http://arxiv.org/pdf/2406.00060v1,cs.CL
Stress-Testing Capability Elicitation With Password-Locked Models,"To determine the safety of large language models (LLMs), AI developers must
be able to assess their dangerous capabilities. But simple prompting strategies
often fail to elicit an LLM's full capabilities. One way to elicit capabilities
more robustly is to fine-tune the LLM to complete the task. In this paper, we
investigate the conditions under which fine-tuning-based elicitation suffices
to elicit capabilities. To do this, we introduce password-locked models, LLMs
fine-tuned such that some of their capabilities are deliberately hidden.
Specifically, these LLMs are trained to exhibit these capabilities only when a
password is present in the prompt, and to imitate a much weaker LLM otherwise.
Password-locked models enable a novel method of evaluating capabilities
elicitation methods, by testing whether these password-locked capabilities can
be elicited without using the password. We find that a few high-quality
demonstrations are often sufficient to fully elicit password-locked
capabilities. More surprisingly, fine-tuning can elicit other capabilities that
have been locked using the same password, or even different passwords.
Furthermore, when only evaluations, and not demonstrations, are available,
approaches like reinforcement learning are still often able to elicit
capabilities. Overall, our findings suggest that fine-tuning is an effective
method of eliciting hidden capabilities of current models, but may be
unreliable when high-quality demonstrations are not available, e.g. as may be
the case when models' (hidden) capabilities exceed those of human
demonstrators.",2024-05-29,"Ryan Greenblatt, Fabien Roger, Dmitrii Krasheninnikov, David Krueger",http://arxiv.org/pdf/2405.19550v1,cs.CL
One-Shot Safety Alignment for Large Language Models via Optimal Dualization,"The growing safety concerns surrounding large language models raise an urgent
need to align them with diverse human preferences to simultaneously enhance
their helpfulness and safety. A promising approach is to enforce safety
constraints through Reinforcement Learning from Human Feedback (RLHF). For such
constrained RLHF, typical Lagrangian-based primal-dual policy optimization
methods are computationally expensive and often unstable. This paper presents a
perspective of dualization that reduces constrained alignment to an equivalent
unconstrained alignment problem. We do so by pre-optimizing a smooth and convex
dual function that has a closed form. This shortcut eliminates the need for
cumbersome primal-dual policy iterations, greatly reducing the computational
burden and improving training stability. Our strategy leads to two practical
algorithms in model-based and preference-based settings (MoCAN and PeCAN,
respectively). A broad range of experiments demonstrate the effectiveness and
merits of our algorithms.",2024-05-29,"Xinmeng Huang, Shuo Li, Edgar Dobriban, Osbert Bastani, Hamed Hassani, Dongsheng Ding",http://arxiv.org/pdf/2405.19544v3,cs.CL
"CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats","Since the release of the original CheXpert paper five years ago, CheXpert has
become one of the most widely used and cited clinical AI datasets. The
emergence of vision language models has sparked an increase in demands for
sharing reports linked to CheXpert images, along with a growing interest among
AI fairness researchers in obtaining demographic data. To address this,
CheXpert Plus serves as a new collection of radiology data sources, made
publicly available to enhance the scaling, performance, robustness, and
fairness of models for all subsequent machine learning tasks in the field of
radiology. CheXpert Plus is the largest text dataset publicly released in
radiology, with a total of 36 million text tokens, including 13 million
impression tokens. To the best of our knowledge, it represents the largest text
de-identification effort in radiology, with almost 1 million PHI spans
anonymized. It is only the second time that a large-scale English paired
dataset has been released in radiology, thereby enabling, for the first time,
cross-institution training at scale. All reports are paired with high-quality
images in DICOM format, along with numerous image and patient metadata covering
various clinical and socio-economic groups, as well as many pathology labels
and RadGraph annotations. We hope this dataset will boost research for AI
models that can further assist radiologists and help improve medical care. Data
is available at the following URL:
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Models are available at the following URL:
https://github.com/Stanford-AIMI/chexpert-plus",2024-05-29,"Pierre Chambon, Jean-Benoit Delbrouck, Thomas Sounack, Shih-Cheng Huang, Zhihong Chen, Maya Varma, Steven QH Truong, Chu The Chuong, Curtis P. Langlotz",http://arxiv.org/pdf/2405.19538v2,cs.CL
Preference Learning Algorithms Do Not Learn Preference Rankings,"Preference learning algorithms (e.g., RLHF and DPO) are frequently used to
steer LLMs to produce generations that are more preferred by humans, but our
understanding of their inner workings is still limited. In this work, we study
the conventional wisdom that preference learning trains models to assign higher
likelihoods to more preferred outputs than less preferred outputs, measured via
ranking accuracy. Surprisingly, we find that most state-of-the-art
preference-tuned models achieve a ranking accuracy of less than 60% on common
preference datasets. We furthermore derive the idealized ranking accuracy that
a preference-tuned LLM would achieve if it optimized the DPO or RLHF objective
perfectly. We demonstrate that existing models exhibit a significant alignment
gap -- i.e., a gap between the observed and idealized ranking accuracies. We
attribute this discrepancy to the DPO objective, which is empirically and
theoretically ill-suited to fix even mild ranking errors in the reference
model, and derive a simple and efficient formula for quantifying the difficulty
of learning a given preference datapoint. Finally, we demonstrate that ranking
accuracy strongly correlates with the empirically popular win rate metric when
the model is close to the reference model used in the objective, shedding
further light on the differences between on-policy (e.g., RLHF) and off-policy
(e.g., DPO) preference learning algorithms.",2024-05-29,"Angelica Chen, Sadhika Malladi, Lily H. Zhang, Xinyi Chen, Qiuyi Zhang, Rajesh Ranganath, Kyunghyun Cho",http://arxiv.org/pdf/2405.19534v4,cs.CL
Conveyor: Efficient Tool-aware LLM Serving with Tool Partial Execution,"The complexity of large language model (LLM) serving workloads has
substantially increased due to the integration with external tool invocations,
such as ChatGPT plugins. In this paper, we identify a new opportunity for
efficient LLM serving for requests that trigger tools: tool partial execution
alongside LLM decoding. To this end, we design Conveyor, an efficient LLM
serving system optimized for handling requests involving external tools. We
introduce a novel interface for tool developers to expose partial execution
opportunities to the LLM serving system and a request scheduler that
facilitates partial tool execution. Our results demonstrate that tool partial
execution can improve request completion latency by up to 38.8%.",2024-05-29,"Yechen Xu, Xinhao Kong, Tingjun Chen, Danyang Zhuo",http://arxiv.org/pdf/2406.00059v2,cs.CL
Two-Layer Retrieval-Augmented Generation Framework for Low-Resource Medical Question Answering Using Reddit Data: Proof-of-Concept Study,"The increasing use of social media to share lived and living experiences of
substance use presents a unique opportunity to obtain information on side
effects, use patterns, and opinions on novel psychoactive substances. However,
due to the large volume of data, obtaining useful insights through natural
language processing technologies such as large language models is challenging.
This paper aims to develop a retrieval-augmented generation (RAG) architecture
for medical question answering pertaining to clinicians' queries on emerging
issues associated with health-related topics, using user-generated medical
information on social media. We proposed a two-layer RAG framework for
query-focused answer generation and evaluated a proof of concept for the
framework in the context of query-focused summary generation from social media
forums, focusing on emerging drug-related information. Our modular framework
generates individual summaries followed by an aggregated summary to answer
medical queries from large amounts of user-generated social media data in an
efficient manner. We compared the performance of a quantized large language
model (Nous-Hermes-2-7B-DPO), deployable in low-resource settings, with GPT-4.
For this proof-of-concept study, we used user-generated data from Reddit to
answer clinicians' questions on the use of xylazine and ketamine. Our framework
achieves comparable median scores in terms of relevance, length, hallucination,
coverage, and coherence when evaluated using GPT-4 and Nous-Hermes-2-7B-DPO,
evaluated for 20 queries with 76 samples. There was no statistically
significant difference between the two for coverage, coherence, relevance,
length, and hallucination. A statistically significant difference was noted for
the Coleman-Liau Index. Our RAG framework can effectively answer medical
questions about targeted topics and can be deployed in resource-constrained
settings.",2024-05-29,"Sudeshna Das, Yao Ge, Yuting Guo, Swati Rajwal, JaMor Hairston, Jeanne Powell, Drew Walker, Snigdha Peddireddy, Sahithi Lakamana, Selen Bozkurt, Matthew Reyna, Reza Sameni, Yunyu Xiao, Sangmi Kim, Rasheeta Chandler, Natalie Hernandez, Danielle Mowery, Rachel Wightman, Jennifer Love, Anthony Spadaro, Jeanmarie Perrone, Abeed Sarker",http://arxiv.org/pdf/2405.19519v2,cs.CL
A Full-duplex Speech Dialogue Scheme Based On Large Language Models,"We present a generative dialogue system capable of operating in a full-duplex
manner, allowing for seamless interaction. It is based on a large language
model (LLM) carefully aligned to be aware of a perception module, a motor
function module, and the concept of a simple finite state machine (called
neural FSM) with two states. The perception and motor function modules operate
in tandem, allowing the system to speak and listen to the user simultaneously.
The LLM generates textual tokens for inquiry responses and makes autonomous
decisions to start responding to, wait for, or interrupt the user by emitting
control tokens to the neural FSM. All these tasks of the LLM are carried out as
next token prediction on a serialized view of the dialogue in real-time. In
automatic quality evaluations simulating real-life interaction, the proposed
system reduces the average conversation response latency by more than threefold
compared with LLM-based half-duplex dialogue systems while responding within
less than 500 milliseconds in more than 50% of evaluated interactions. Running
an LLM with only 8 billion parameters, our system exhibits an 8% higher
interruption precision rate than the best available commercial LLM for
voice-based dialogue.",2024-05-29,"Peng Wang, Songshuo Lu, Yaohua Tang, Sijie Yan, Wei Xia, Yuanjun Xiong",http://arxiv.org/pdf/2405.19487v2,cs.CL
Critical Learning Periods: Leveraging Early Training Dynamics for Efficient Data Pruning,"Neural Machine Translation models are extremely data and compute-hungry.
However, not all data points contribute equally to model training and
generalization. Data pruning to remove the low-value data points has the
benefit of drastically reducing the compute budget without significant drop in
model performance. In this paper, we propose a new data pruning technique:
Checkpoints Across Time (CAT), that leverages early model training dynamics to
identify the most relevant data points for model performance. We benchmark CAT
against several data pruning techniques including COMET-QE, LASER and LaBSE. We
find that CAT outperforms the benchmarks on Indo-European languages on multiple
test sets. When applied to English-German, English-French and English-Swahili
translation tasks, CAT achieves comparable performance to using the full
dataset, while pruning up to 50% of training data. We inspect the data points
that CAT selects and find that it tends to favour longer sentences and
sentences with unique or rare words.",2024-05-29,"Everlyn Asiko Chimoto, Jay Gala, Orevaoghene Ahia, Julia Kreutzer, Bruce A. Bassett, Sara Hooker",http://arxiv.org/pdf/2405.19462v2,cs.CL
Toward Conversational Agents with Context and Time Sensitive Long-term Memory,"There has recently been growing interest in conversational agents with
long-term memory which has led to the rapid development of language models that
use retrieval-augmented generation (RAG). Until recently, most work on RAG has
focused on information retrieval from large databases of texts, like Wikipedia,
rather than information from long-form conversations. In this paper, we argue
that effective retrieval from long-form conversational data faces two unique
problems compared to static database retrieval: 1) time/event-based queries,
which requires the model to retrieve information about previous conversations
based on time or the order of a conversational event (e.g., the third
conversation on Tuesday), and 2) ambiguous queries that require surrounding
conversational context to understand. To better develop RAG-based agents that
can deal with these challenges, we generate a new dataset of ambiguous and
time-based questions that build upon a recent dataset of long-form, simulated
conversations, and demonstrate that standard RAG based approaches handle such
questions poorly. We then develop a novel retrieval model which combines
chained-of-table search methods, standard vector-database retrieval, and a
prompting method to disambiguate queries, and demonstrate that this approach
substantially improves over current methods at solving these tasks. We believe
that this new dataset and more advanced RAG agent can act as a key benchmark
and stepping stone towards effective memory augmented conversational agents
that can be used in a wide variety of AI applications.",2024-05-29,"Nick Alonso, Tomás Figliolia, Anthony Ndirango, Beren Millidge",http://arxiv.org/pdf/2406.00057v2,cs.CL
Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals,"While current Automated Essay Scoring (AES) methods demonstrate high scoring
agreement with human raters, their decision-making mechanisms are not fully
understood. Our proposed method, using counterfactual intervention assisted by
Large Language Models (LLMs), reveals that BERT-like models primarily focus on
sentence-level features, whereas LLMs such as GPT-3.5, GPT-4 and Llama-3 are
sensitive to conventions & accuracy, language complexity, and organization,
indicating a more comprehensive rationale alignment with scoring rubrics.
Moreover, LLMs can discern counterfactual interventions when giving feedback on
essays. Our approach improves understanding of neural AES methods and can also
apply to other domains seeking transparency in model-driven decisions.",2024-05-29,"Yupei Wang, Renfen Hu, Zhe Zhao",http://arxiv.org/pdf/2405.19433v2,cs.CL
Deep Learning for Assessment of Oral Reading Fluency,"Reading fluency assessment is a critical component of literacy programmes,
serving to guide and monitor early education interventions. Given the resource
intensive nature of the exercise when conducted by teachers, the development of
automatic tools that can operate on audio recordings of oral reading is
attractive as an objective and highly scalable solution. Multiple complex
aspects such as accuracy, rate and expressiveness underlie human judgements of
reading fluency. In this work, we investigate end-to-end modeling on a training
dataset of children's audio recordings of story texts labeled by human experts.
The pre-trained wav2vec2.0 model is adopted due its potential to alleviate the
challenges from the limited amount of labeled data. We report the performance
of a number of system variations on the relevant measures, and also probe the
learned embeddings for lexical and acoustic-prosodic features known to be
important to the perception of reading fluency.",2024-05-29,"Mithilesh Vaidya, Binaya Kumar Sahoo, Preeti Rao",http://arxiv.org/pdf/2405.19426v2,cs.CL
Adaptive In-conversation Team Building for Language Model Agents,"Leveraging multiple large language model (LLM) agents has shown to be a
promising approach for tackling complex tasks, while the effective design of
multiple agents for a particular application remains an art. It is thus
intriguing to answer a critical question: Given a task, how can we build a team
of LLM agents to solve it effectively? Our new adaptive team-building paradigm
offers a flexible solution, realized through a novel agent design named Captain
Agent. It dynamically forms and manages teams for each step of a task-solving
process, utilizing nested group conversations and reflection to ensure diverse
expertise and prevent stereotypical outputs, allowing for a flexible yet
structured approach to problem-solving. A comprehensive evaluation across six
real-world scenarios demonstrates that Captain Agent significantly outperforms
existing multi-agent methods with 21.94% improvement in average accuracy,
providing outstanding performance without requiring task-specific prompt
engineering. Our exploration of different backbone LLM and cost analysis
further shows that Captain Agent can improve the conversation quality of weak
LLM and achieve competitive performance with extremely low cost, which
illuminates the application of multi-agent systems.",2024-05-29,"Linxin Song, Jiale Liu, Jieyu Zhang, Shaokun Zhang, Ao Luo, Shijian Wang, Qingyun Wu, Chi Wang",http://arxiv.org/pdf/2405.19425v3,cs.CL
X-VILA: Cross-Modality Alignment for Large Language Model,"We introduce X-VILA, an omni-modality model designed to extend the
capabilities of large language models (LLMs) by incorporating image, video, and
audio modalities. By aligning modality-specific encoders with LLM inputs and
diffusion decoders with LLM outputs, X-VILA achieves cross-modality
understanding, reasoning, and generation. To facilitate this cross-modality
alignment, we curate an effective interleaved any-to-any modality
instruction-following dataset. Furthermore, we identify a significant problem
with the current cross-modality alignment method, which results in visual
information loss. To address the issue, we propose a visual alignment mechanism
with a visual embedding highway module. We then introduce a resource-efficient
recipe for training X-VILA, that exhibits proficiency in any-to-any modality
conversation, surpassing previous approaches by large margins. X-VILA also
showcases emergent properties across modalities even in the absence of similar
training data. The project will be made open-source.",2024-05-29,"Hanrong Ye, De-An Huang, Yao Lu, Zhiding Yu, Wei Ping, Andrew Tao, Jan Kautz, Song Han, Dan Xu, Pavlo Molchanov, Hongxu Yin",http://arxiv.org/pdf/2405.19335v1,cs.CL
LLMs Meet Multimodal Generation and Editing: A Survey,"With the recent advancement in large language models (LLMs), there is a
growing interest in combining LLMs with multimodal learning. Previous surveys
of multimodal large language models (MLLMs) mainly focus on multimodal
understanding. This survey elaborates on multimodal generation and editing
across various domains, comprising image, video, 3D, and audio. Specifically,
we summarize the notable advancements with milestone works in these fields and
categorize these studies into LLM-based and CLIP/T5-based methods. Then, we
summarize the various roles of LLMs in multimodal generation and exhaustively
investigate the critical technical components behind these methods and the
multimodal datasets utilized in these studies. Additionally, we dig into
tool-augmented multimodal agents that can leverage existing generative models
for human-computer interaction. Lastly, we discuss the advancements in the
generative AI safety field, investigate emerging applications, and discuss
future prospects. Our work provides a systematic and insightful overview of
multimodal generation and processing, which is expected to advance the
development of Artificial Intelligence for Generative Content (AIGC) and world
models. A curated list of all related papers can be found at
https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",2024-05-29,"Yingqing He, Zhaoyang Liu, Jingye Chen, Zeyue Tian, Hongyu Liu, Xiaowei Chi, Runtao Liu, Ruibin Yuan, Yazhou Xing, Wenhai Wang, Jifeng Dai, Yong Zhang, Wei Xue, Qifeng Liu, Yike Guo, Qifeng Chen",http://arxiv.org/pdf/2405.19334v2,cs.CL
MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series,"Large Language Models (LLMs) have made great strides in recent years to
achieve unprecedented performance across different tasks. However, due to
commercial interest, the most competitive models like GPT, Gemini, and Claude
have been gated behind proprietary interfaces without disclosing the training
details. Recently, many institutions have open-sourced several strong LLMs like
LLaMA-3, comparable to existing closed-source LLMs. However, only the model's
weights are provided with most details (e.g., intermediate checkpoints,
pre-training corpus, and training code, etc.) being undisclosed. To improve the
transparency of LLMs, the research community has formed to open-source truly
open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training
corpus and training code) are being provided. These models have greatly
advanced the scientific study of these large models including their strengths,
weaknesses, biases and risks. However, we observe that the existing truly open
LLMs on reasoning, knowledge, and coding tasks are still inferior to existing
state-of-the-art LLMs with similar model sizes. To this end, we open-source
MAP-Neo, a highly capable and transparent bilingual language model with 7B
parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the
first fully open-sourced bilingual LLM with comparable performance compared to
existing state-of-the-art LLMs. Moreover, we open-source all details to
reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning
pipeline, checkpoints, and well-optimized training/evaluation framework are
provided. Finally, we hope our MAP-Neo will enhance and strengthen the open
research community and inspire more innovations and creativities to facilitate
the further improvements of LLMs.",2024-05-29,"Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, Noah Wang, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, Zenith Wang, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen",http://arxiv.org/pdf/2405.19327v4,cs.CL
Nearest Neighbor Speculative Decoding for LLM Generation and Attribution,"Large language models (LLMs) often hallucinate and lack the ability to
provide attribution for their generations. Semi-parametric LMs, such as kNN-LM,
approach these limitations by refining the output of an LM for a given prompt
using its nearest neighbor matches in a non-parametric data store. However,
these models often exhibit slow inference speeds and produce non-fluent texts.
In this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a
novel semi-parametric language modeling approach that is capable of
incorporating real-world text spans of arbitrary length into the LM generations
and providing attribution to their sources. NEST performs token-level retrieval
at each inference step to compute a semi-parametric mixture distribution and
identify promising span continuations in a corpus. It then uses an approximate
speculative decoding procedure that accepts a prefix of the retrieved span or
generates a new token. NEST significantly enhances the generation quality and
attribution rate of the base LM across a variety of knowledge-intensive tasks,
surpassing the conventional kNN-LM method and performing competitively with
in-context retrieval augmentation. In addition, NEST substantially improves the
generation speed, achieving a 1.8x speedup in inference time when applied to
Llama-2-Chat 70B. Code will be released at
https://github.com/facebookresearch/NEST/tree/main.",2024-05-29,"Minghan Li, Xilun Chen, Ari Holtzman, Beidi Chen, Jimmy Lin, Wen-tau Yih, Xi Victoria Lin",http://arxiv.org/pdf/2405.19325v3,cs.CL
Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys,"Can large language models (LLMs) simulate social surveys? To answer this
question, we conducted millions of simulations in which LLMs were asked to
answer subjective questions. A comparison of different LLM responses with the
European Social Survey (ESS) data suggests that the effect of prompts on bias
and variability is fundamental, highlighting major cultural, age, and gender
biases. We further discussed statistical methods for measuring the difference
between LLM answers and survey data and proposed a novel measure inspired by
Jaccard similarity, as LLM-generated responses are likely to have a smaller
variance. Our experiments also reveal that it is important to analyze the
robustness and variability of prompts before using LLMs to simulate social
surveys, as their imitation abilities are approximate at best.",2024-05-29,"Mingmeng Geng, Sihong He, Roberto Trotta",http://arxiv.org/pdf/2405.19323v2,cs.CL
Robust Preference Optimization through Reward Model Distillation,"Language model (LM) post-training (or alignment) involves maximizing a reward
function that is derived from preference annotations. Direct Preference
Optimization (DPO) is a popular offline alignment method that trains a policy
directly on preference data without the need to train a reward model or apply
reinforcement learning. However, the empirical evidence suggests that DPO
typically assigns implicit rewards that overfit, and trend towards infinite
magnitude. This frequently leads to degenerate policies, sometimes causing even
the probabilities of the preferred generations to go to zero. In this work, we
analyze this phenomenon and use distillation to get a better proxy for the true
preference distribution over generation pairs: we train the LM such that its
induced implicit reward, i.e., the scaled log-likelihood ratio of the model to
the reference model, matches an explicit reward model trained on the preference
data. Moreover, to account for uncertainty in the reward model we are
distilling from, we optimize against a family of reward models that, as a
whole, is likely to include at least one reasonable proxy for the preference
distribution. Our results show that distilling from such a family of reward
models leads to improved robustness to distribution shift in preference
annotations, while preserving the simple supervised nature of DPO.",2024-05-29,"Adam Fisch, Jacob Eisenstein, Vicky Zayats, Alekh Agarwal, Ahmad Beirami, Chirag Nagpal, Pete Shaw, Jonathan Berant",http://arxiv.org/pdf/2405.19316v2,cs.CL
Matryoshka Query Transformer for Large Vision-Language Models,"Large Vision-Language Models (LVLMs) typically encode an image into a fixed
number of visual tokens (e.g., 576) and process these tokens with a language
model. Despite their strong performance, LVLMs face challenges in adapting to
varying computational constraints. This raises the question: can we achieve
flexibility in the number of visual tokens to suit different tasks and
computational resources? We answer this with an emphatic yes. Inspired by
Matryoshka Representation Learning, we introduce the Matryoshka Query
Transformer (MQT), capable of encoding an image into m visual tokens during
inference, where m can be any number up to a predefined maximum. This is
achieved by employing a query transformer with M latent query tokens to
compress the visual embeddings. During each training step, we randomly select m
<= M latent query tokens and train the model using only these first m tokens,
discarding the rest. Combining MQT with LLaVA, we train a single model once,
and flexibly and drastically reduce the number of inference-time visual tokens
while maintaining similar or better performance compared to training
independent models for each number of tokens. Our model, MQT-LLAVA, matches
LLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens
instead of LLaVA's fixed 576. Reducing to 16 tokens (8x less TFLOPs) only
sacrifices the performance by 2.4 points on MMBench. On certain tasks such as
ScienceQA and MMMU, we can even go down to only 2 visual tokens with
performance drops of just 3% and 6% each. Our exploration of the trade-off
between the accuracy and computational cost brought about by the number of
visual tokens facilitates future research to achieve the best of both worlds.",2024-05-29,"Wenbo Hu, Zi-Yi Dou, Liunian Harold Li, Amita Kamath, Nanyun Peng, Kai-Wei Chang",http://arxiv.org/pdf/2405.19315v2,cs.CL
Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice,"The observed similarities in the behavior of humans and Large Language Models
(LLMs) have prompted researchers to consider the potential of using LLMs as
models of human cognition. However, several significant challenges must be
addressed before LLMs can be legitimately regarded as cognitive models. For
instance, LLMs are trained on far more data than humans typically encounter,
and may have been directly trained on human data in specific cognitive tasks or
aligned with human preferences. Consequently, the origins of these behavioral
similarities are not well understood. In this paper, we propose a novel way to
enhance the utility of LLMs as cognitive models. This approach involves (i)
leveraging computationally equivalent tasks that both an LLM and a rational
agent need to master for solving a cognitive problem and (ii) examining the
specific task distributions required for an LLM to exhibit human-like
behaviors. We apply this approach to decision-making -- specifically risky and
intertemporal choice -- where the key computationally equivalent task is the
arithmetic of expected value calculations. We show that an LLM pretrained on an
ecologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts
human behavior better than many traditional cognitive models. Pretraining LLMs
on ecologically valid arithmetic datasets is sufficient to produce a strong
correspondence between these models and human decision-making. Our results also
suggest that LLMs used as cognitive models should be carefully investigated via
ablation studies of the pretraining data.",2024-05-29,"Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths",http://arxiv.org/pdf/2405.19313v2,cs.CL
Expert-Guided Extinction of Toxic Tokens for Debiased Generation,"Large language models (LLMs) can elicit social bias during generations,
especially when inference with toxic prompts. Controlling the sensitive
attributes in generation encounters challenges in data distribution,
generalizability, and efficiency. Specifically, fine-tuning and retrieval
demand extensive unbiased corpus, while direct prompting requires meticulously
curated instructions for correcting the output in multiple rounds of thoughts
but poses challenges on memory and inference latency. In this work, we propose
the Expert-Guided Extinction of Toxic Tokens for Debiased Generation (EXPOSED)
to eliminate the undesired harmful outputs for LLMs without the aforementioned
requirements. EXPOSED constructs a debiasing expert based on the abundant toxic
corpus to expose and elicit the potentially dangerous tokens. It then processes
the output to the LLMs and constructs a fair distribution by suppressing and
attenuating the toxic tokens. EXPOSED is evaluated on fairness benchmarks over
three LLM families. Extensive experiments demonstrate that compared with other
baselines, the proposed EXPOSED significantly reduces the potential social bias
while balancing fairness and generation performance.",2024-05-29,"Xueyao Sun, Kaize Shi, Haoran Tang, Guandong Xu, Qing Li",http://arxiv.org/pdf/2405.19299v1,cs.CL
Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation,"Subword tokenization is a common method for vocabulary building in Neural
Machine Translation (NMT) models. However, increasingly complex tasks have
revealed its disadvantages. First, a vocabulary cannot be modified once it is
learned, making it hard to adapt to new words. Second, in multilingual
translation, the imbalance in data volumes across different languages spreads
to the vocabulary, exacerbating translations involving low-resource languages.
While byte-based tokenization addresses these issues, byte-based models
struggle with the low information density inherent in UTF-8 byte sequences.
Previous works enhance token semantics through local contextualization but fail
to select an appropriate contextualizing scope based on the input.
Consequently, we propose the Multi-Scale Contextualization (MSC) method, which
learns contextualized information of varying scales across different hidden
state dimensions. It then leverages the attention module to dynamically
integrate the multi-scale contextualized information. Experiments show that MSC
significantly outperforms subword-based and other byte-based methods in both
multilingual and out-of-domain scenarios. Code can be found in
https://github.com/ictnlp/Multiscale-Contextualization.",2024-05-29,"Langlin Huang, Yang Feng",http://arxiv.org/pdf/2405.19290v3,cs.CL
MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection,"Abstract Meaning Representation (AMR) is a semantic formalism that captures
the core meaning of an utterance. There has been substantial work developing
AMR corpora in English and more recently across languages, though the limited
size of existing datasets and the cost of collecting more annotations are
prohibitive. With both engineering and scientific questions in mind, we
introduce MASSIVE-AMR, a dataset with more than 84,000 text-to-graph
annotations, currently the largest and most diverse of its kind: AMR graphs for
1,685 information-seeking utterances mapped to 50+ typologically diverse
languages. We describe how we built our resource and its unique features before
reporting on experiments using large language models for multilingual AMR and
SPARQL parsing as well as applying AMRs for hallucination detection in the
context of knowledge base question answering, with results shedding light on
persistent issues using LLMs for structured parsing.",2024-05-29,"Michael Regan, Shira Wein, George Baker, Emilio Monti",http://arxiv.org/pdf/2405.19285v1,cs.CL
PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications,"Developing intelligent pediatric consultation systems offers promising
prospects for improving diagnostic efficiency, especially in China, where
healthcare resources are scarce. Despite recent advances in Large Language
Models (LLMs) for Chinese medicine, their performance is sub-optimal in
pediatric applications due to inadequate instruction data and vulnerable
training procedures. To address the above issues, this paper builds PedCorpus,
a high-quality dataset of over 300,000 multi-task instructions from pediatric
textbooks, guidelines, and knowledge graph resources to fulfil diverse
diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the
first Chinese pediatric LLM assistant built on a systematic and robust training
pipeline. In the continuous pre-training phase, we introduce a hybrid
instruction pre-training mechanism to mitigate the internal-injected knowledge
inconsistency of LLMs for medical domain adaptation. Immediately, the
full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the
general medical knowledge schema into the models. After that, we devise a
direct following preference optimization to enhance the generation of
pediatrician-like humanistic responses. In the parameter-efficient secondary
SFT phase, a mixture of universal-specific experts strategy is presented to
resolve the competency conflict between medical generalist and pediatric
expertise mastery. Extensive results based on the metrics, GPT-4, and doctor
evaluations on distinct doctor downstream tasks show that PediatricsGPT
consistently outperforms previous Chinese medical LLMs. Our model and dataset
will be open-source for community development.",2024-05-29,"Dingkang Yang, Jinjie Wei, Dongling Xiao, Shunli Wang, Tong Wu, Gang Li, Mingcheng Li, Shuaibing Wang, Jiawei Chen, Yue Jiang, Qingyao Xu, Ke Li, Peng Zhai, Lihua Zhang",http://arxiv.org/pdf/2405.19266v4,cs.CL
AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data,"Open-source Large Language Models (LLMs) and their specialized variants,
particularly Code LLMs, have recently delivered impressive performance.
However, previous Code LLMs are typically fine-tuned on single-source data with
limited quality and diversity, which may insufficiently elicit the potential of
pre-trained Code LLMs. In this paper, we present AlchemistCoder, a series of
Code LLMs with enhanced code generation and generalization capabilities
fine-tuned on multi-source data. To achieve this, we pioneer to unveil inherent
conflicts among the various styles and qualities in multi-source code corpora
and introduce data-specific prompts with hindsight relabeling, termed
AlchemistPrompts, to harmonize different data sources and instruction-response
pairs. Additionally, we propose incorporating the data construction process
into the fine-tuning data as code comprehension tasks, including instruction
evolution, data filtering, and code review. Extensive experiments demonstrate
that AlchemistCoder holds a clear lead among all models of the same size
(6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B), showcasing
the efficacy of our method in refining instruction-following capabilities and
advancing the boundaries of code intelligence.",2024-05-29,"Zifan Song, Yudong Wang, Wenwei Zhang, Kuikun Liu, Chengqi Lyu, Demin Song, Qipeng Guo, Hang Yan, Dahua Lin, Kai Chen, Cairong Zhao",http://arxiv.org/pdf/2405.19265v1,cs.CL
Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models,"Large language models are usually fine-tuned to align with human preferences.
However, fine-tuning a large language model can be challenging. In this work,
we introduce $\textit{weak-to-strong search}$, framing the alignment of a large
language model as a test-time greedy search to maximize the log-probability
difference between small tuned and untuned models while sampling from the
frozen large model. This method serves both as (1) a compute-efficient model
up-scaling strategy that avoids directly tuning the large model and as (2) an
instance of weak-to-strong generalization that enhances a strong model with
weak test-time guidance. Empirically, we demonstrate the flexibility of
weak-to-strong search across different tasks. In controlled-sentiment
generation and summarization, we use tuned and untuned $\texttt{gpt2}$s to
improve the alignment of large models without additional training. Crucially,
in a more difficult instruction-following benchmark, AlpacaEval 2.0, we show
that reusing off-the-shelf small models (e.g., $\texttt{zephyr-7b-beta}$ and
its untuned version) can improve the length-controlled win rates of both
white-box and black-box large models against $\texttt{gpt-4-turbo}$ (e.g.,
$34.4\% \rightarrow 37.9\%$ for $\texttt{Llama-3-70B-Instruct}$ and $16.0\%
\rightarrow 20.1\%$ for $\texttt{gpt-3.5-turbo-instruct}$), despite the small
models' low win rates $\approx 10.0\%$.",2024-05-29,"Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong, Chao Yang, Yu Qiao",http://arxiv.org/pdf/2405.19262v3,cs.CL
Faster Cascades via Speculative Decoding,"Cascades and speculative decoding are two common approaches to improving
language models' inference efficiency. Both approaches involve interleaving
models of different sizes, but via fundamentally distinct mechanisms: cascades
employ a deferral rule that invokes the larger model only for ""hard"" inputs,
while speculative decoding uses speculative execution to primarily invoke the
larger model in parallel verification mode. These mechanisms offer different
benefits: empirically, cascades offer better cost-quality trade-offs, often
even outperforming the large model, while theoretically, speculative decoding
offers a guarantee of quality-neutrality. In this paper, we leverage the best
of both these approaches by designing new speculative cascading techniques that
implement their deferral rule through speculative execution. We characterize
the optimal deferral rule for our speculative cascades, and employ a plug-in
approximation to the optimal rule. Experiments with Gemma and T5 models on a
range of language benchmarks show that our approach yields better cost quality
trade-offs than cascading and speculative decoding baselines.",2024-05-29,"Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Seungyeon Kim, Neha Gupta, Aditya Krishna Menon, Sanjiv Kumar",http://arxiv.org/pdf/2405.19261v2,cs.CL
Lower Bounds on the Expressivity of Recurrent Neural Language Models,"The recent successes and spread of large neural language models (LMs) call
for a thorough understanding of their computational ability. Describing their
computational abilities through LMs' \emph{representational capacity} is a
lively area of research. However, investigation into the representational
capacity of neural LMs has predominantly focused on their ability to
\emph{recognize} formal languages. For example, recurrent neural networks
(RNNs) with Heaviside activations are tightly linked to regular languages,
i.e., languages defined by finite-state automata (FSAs). Such results, however,
fall short of describing the capabilities of RNN \emph{language models} (LMs),
which are definitionally \emph{distributions} over strings. We take a fresh
look at the representational capacity of RNN LMs by connecting them to
\emph{probabilistic} FSAs and demonstrate that RNN LMs with linearly bounded
precision can express arbitrary regular LMs.",2024-05-29,"Anej Svete, Franz Nowak, Anisha Mohamed Sahabdeen, Ryan Cotterell",http://arxiv.org/pdf/2405.19222v2,cs.CL
WRDScore: New Metric for Evaluation of Natural Language Generation Models,"Evaluating natural language generation models, particularly for method name
prediction, poses significant challenges. A robust metric must account for the
versatility of method naming, considering both semantic and syntactic
variations. Traditional overlap-based metrics, such as ROUGE, fail to capture
these nuances. Existing embedding-based metrics often suffer from imbalanced
precision and recall, lack normalized scores, or make unrealistic assumptions
about sequences. To address these limitations, we leverage the theory of
optimal transport and construct WRDScore, a novel metric that strikes a balance
between simplicity and effectiveness. In the WRDScore framework, we define
precision as the maximum degree to which the predicted sequence's tokens are
included in the reference sequence, token by token. Recall is calculated as the
total cost of the optimal transport plan that maps the reference sequence to
the predicted one. Finally, WRDScore is computed as the harmonic mean of
precision and recall, balancing these two complementary metrics. Our metric is
lightweight, normalized, and precision-recall-oriented, avoiding unrealistic
assumptions while aligning well with human judgments. Experiments on a
human-curated dataset confirm the superiority of WRDScore over other available
text metrics.",2024-05-29,Ravil Mussabayev,http://arxiv.org/pdf/2405.19220v5,cs.CL
VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos,"Long-form video understanding is complicated by the high redundancy of video
data and the abundance of query-irrelevant information. To tackle these
challenges, we propose VideoTree, a training-free framework which builds a
query-adaptive and hierarchical video representation for LLM reasoning over
long-form videos. First, VideoTree extracts query-relevant information from the
input video through an iterative process, progressively refining the selection
of keyframes based on their relevance to the query. Furthermore, VideoTree
leverages the inherent hierarchical structure of long video data, which is
often overlooked by existing LLM-based methods. Specifically, we incorporate
multi-granularity information into a tree-based representation, allowing
VideoTree to extract query-relevant details from long videos in a
coarse-to-fine manner. This enables the model to effectively handle a wide
range of video queries with varying levels of detail. Finally, VideoTree
aggregates the hierarchical query-relevant information within the tree
structure and feeds it into an LLM reasoning model to answer the query. Our
experiments show that our method improves both reasoning accuracy and
efficiency. Specifically, VideoTree outperforms existing training-free
approaches on EgoSchema and NExT-QA with less inference time, achieving 61.1%
and 75.6% accuracy on the test set without additional video-specific training.
Moreover, on the long split of Video-MME (average 44 minutes), VideoTree
achieves better performance than GPT-4V and many other MLLMs that were
extensively trained on video data.",2024-05-29,"Ziyang Wang, Shoubin Yu, Elias Stengel-Eskin, Jaehong Yoon, Feng Cheng, Gedas Bertasius, Mohit Bansal",http://arxiv.org/pdf/2405.19209v3,cs.CL
MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification,"Large Vision Language Models (LVLMs) have shown remarkable capabilities in
multimodal tasks like visual question answering or image captioning. However,
inconsistencies between the visual information and the generated text, a
phenomenon referred to as hallucinations, remain an unsolved problem with
regard to the trustworthiness of LVLMs. To address this problem, recent works
proposed to incorporate computationally costly Large (Vision) Language Models
in order to detect hallucinations on a sentence- or subsentence-level. In this
work, we introduce MetaToken, a lightweight binary classifier to detect
hallucinations on the token-level at negligible cost. Based on a statistical
analysis, we reveal key factors of hallucinations in LVLMs. MetaToken can be
applied to any open-source LVLM without any knowledge about ground truth data
providing a calibrated detection of hallucinations. We evaluate our method on
four state-of-the-art LVLMs demonstrating the effectiveness of our approach.",2024-05-29,"Laura Fieback, Jakob Spiegelberg, Hanno Gottschalk",http://arxiv.org/pdf/2405.19186v2,cs.CL
DGRC: An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension,"When evaluating a learner's knowledge proficiency, the multiple-choice
question is an efficient and widely used format in standardized tests.
Nevertheless, generating these questions, particularly plausible distractors
(incorrect options), poses a considerable challenge. Generally, the distractor
generation can be classified into cloze-style distractor generation (CDG) and
natural questions distractor generation (NQDG). In contrast to the CDG,
utilizing pre-trained language models (PLMs) for NQDG presents three primary
challenges: (1) PLMs are typically trained to generate ``correct'' content,
like answers, while rarely trained to generate ``plausible"" content, like
distractors; (2) PLMs often struggle to produce content that aligns well with
specific knowledge and the style of exams; (3) NQDG necessitates the model to
produce longer, context-sensitive, and question-relevant distractors. In this
study, we introduce a fine-tuning framework named DGRC for NQDG in Chinese
multi-choice reading comprehension from authentic examinations. DGRC comprises
three major components: hard chain-of-thought, multi-task learning, and
generation mask patterns. The experiment results demonstrate that DGRC
significantly enhances generation performance, achieving a more than 2.5-fold
improvement in BLEU scores.",2024-05-29,"Runfeng Lin, Dacheng Xu, Huijiang Wang, Zebiao Chen, Yating Wang, Shouqiang Liu",http://arxiv.org/pdf/2405.19139v1,cs.CL
PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering,"Logical reasoning task has attracted great interest since it was proposed.
Faced with such a task, current competitive models, even large language models
(e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs
struggle in logical consistency modeling and logical structure perception. To
this end, we model the logical reasoning task by transforming each logical
sample into reasoning paths and propose an architecture \textbf{PathReasoner}.
It addresses the task from the views of both data and model. To expand the
diversity of the logical samples, we propose an atom extension strategy
supported by equivalent logical formulas, to form new reasoning paths. From the
model perspective, we design a stack of transformer-style blocks. In
particular, we propose a path-attention module to joint model in-atom and
cross-atom relations with the high-order diffusion strategy. Experiments show
that PathReasoner achieves competitive performances on two logical reasoning
benchmarks and great generalization abilities.",2024-05-29,"Fangzhi Xu, Qika Lin, Tianzhe Zhao, Jiawei Han, Jun Liu",http://arxiv.org/pdf/2405.19109v1,cs.CL
Faithful Chart Summarization with ChaTS-Pi,"Chart-to-summary generation can help explore data, communicate insights, and
help the visually impaired people. Multi-modal generative models have been used
to produce fluent summaries, but they can suffer from factual and perceptual
errors. In this work we present CHATS-CRITIC, a reference-free chart
summarization metric for scoring faithfulness. CHATS-CRITIC is composed of an
image-to-text model to recover the table from a chart, and a tabular entailment
model applied to score the summary sentence by sentence. We find that
CHATS-CRITIC evaluates the summary quality according to human ratings better
than reference-based metrics, either learned or n-gram based, and can be
further used to fix candidate summaries by removing not supported sentences. We
then introduce CHATS-PI, a chart-to-summary pipeline that leverages
CHATS-CRITIC during inference to fix and rank sampled candidates from any
chart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human
raters, establishing state-of-the-art results on two popular chart-to-summary
datasets.",2024-05-29,"Syrine Krichene, Francesco Piccinno, Fangyu Liu, Julian Martin Eisenschlos",http://arxiv.org/pdf/2405.19094v1,cs.CL
Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation,"The International Classification of Diseases (ICD) serves as a definitive
medical classification system encompassing a wide range of diseases and
conditions. The primary objective of ICD indexing is to allocate a subset of
ICD codes to a medical record, which facilitates standardized documentation and
management of various health conditions. Most existing approaches have suffered
from selecting the proper label subsets from an extremely large ICD collection
with a heavy long-tailed label distribution. In this paper, we leverage a
multi-stage ``retrieve and re-rank'' framework as a novel solution to ICD
indexing, via a hybrid discrete retrieval method, and re-rank retrieved
candidates with contrastive learning that allows the model to make more
accurate predictions from a simplified label space. The retrieval model is a
hybrid of auxiliary knowledge of the electronic health records (EHR) and a
discrete retrieval method (BM25), which efficiently collects high-quality
candidates. In the last stage, we propose a label co-occurrence guided
contrastive re-ranking model, which re-ranks the candidate labels by pulling
together the clinical notes with positive ICD codes. Experimental results show
the proposed method achieves state-of-the-art performance on a number of
measures on the MIMIC-III benchmark.",2024-05-29,"Xindi Wang, Robert E. Mercer, Frank Rudzicz",http://arxiv.org/pdf/2405.19093v1,cs.CL
Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions,"Recent advancements in large multimodal language models have demonstrated
remarkable proficiency across a wide range of tasks. Yet, these models still
struggle with understanding the nuances of human humor through juxtaposition,
particularly when it involves nonlinear narratives that underpin many jokes and
humor cues. This paper investigates this challenge by focusing on comics with
contradictory narratives, where each comic consists of two panels that create a
humorous contradiction. We introduce the YesBut benchmark, which comprises
tasks of varying difficulty aimed at assessing AI's capabilities in recognizing
and interpreting these comics, ranging from literal content comprehension to
deep narrative reasoning. Through extensive experimentation and analysis of
recent commercial or open-sourced large (vision) language models, we assess
their capability to comprehend the complex interplay of the narrative humor
inherent in these comics. Our results show that even state-of-the-art models
still lag behind human performance on this task. Our findings offer insights
into the current limitations and potential improvements for AI in understanding
human creative expressions.",2024-05-29,"Zhe Hu, Tuo Liang, Jing Li, Yiren Lu, Yunlai Zhou, Yiran Qiao, Jing Ma, Yu Yin",http://arxiv.org/pdf/2405.19088v2,cs.CL
MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors,"Model editing aims to efficiently alter the behavior of Large Language Models
(LLMs) within a desired scope, while ensuring no adverse impact on other
inputs. Recent years have witnessed various model editing methods been
proposed. However, these methods either exhibit poor overall performance or
struggle to strike a balance between generalization and locality. We propose
MEMoE, a model editing adapter utilizing a Mixture of Experts (MoE)
architecture with a knowledge anchor routing strategy. MEMoE updates knowledge
using a bypass MoE structure, keeping the original parameters unchanged to
preserve the general ability of LLMs. And, the knowledge anchor routing ensures
that inputs requiring similar knowledge are routed to the same expert, thereby
enhancing the generalization of the updated knowledge. Experimental results
show the superiority of our approach over both batch editing and sequential
batch editing tasks, exhibiting exceptional overall performance alongside
outstanding balance between generalization and locality. Our code will be
available.",2024-05-29,"Renzhi Wang, Piji Li",http://arxiv.org/pdf/2405.19086v2,cs.CL
Auxiliary Knowledge-Induced Learning for Automatic Multi-Label Medical Document Classification,"The International Classification of Diseases (ICD) is an authoritative
medical classification system of different diseases and conditions for clinical
and management purposes. ICD indexing assigns a subset of ICD codes to a
medical record. Since human coding is labour-intensive and error-prone, many
studies employ machine learning to automate the coding process. ICD coding is a
challenging task, as it needs to assign multiple codes to each medical document
from an extremely large hierarchically organized collection. In this paper, we
propose a novel approach for ICD indexing that adopts three ideas: (1) we use a
multi-level deep dilated residual convolution encoder to aggregate the
information from the clinical notes and learn document representations across
different lengths of the texts; (2) we formalize the task of ICD classification
with auxiliary knowledge of the medical records, which incorporates not only
the clinical texts but also different clinical code terminologies and drug
prescriptions for better inferring the ICD codes; and (3) we introduce a graph
convolutional network to leverage the co-occurrence patterns among ICD codes,
aiming to enhance the quality of label representations. Experimental results
show the proposed method achieves state-of-the-art performance on a number of
measures.",2024-05-29,"Xindi Wang, Robert E. Mercer, Frank Rudzicz",http://arxiv.org/pdf/2405.19084v1,cs.CL
Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design,"We present Cephalo, a series of multimodal vision large language models
(V-LLMs) designed for materials science applications, integrating visual and
linguistic data for enhanced understanding. A key innovation of Cephalo is its
advanced dataset generation method. Cephalo is trained on integrated image and
text data from thousands of scientific papers and science-focused Wikipedia
data demonstrates can interpret complex visual scenes, generate precise
language descriptions, and answer queries about images effectively. The
combination of a vision encoder with an autoregressive transformer supports
multimodal natural language understanding, which can be coupled with other
generative methods to create an image-to-text-to-3D pipeline. To develop more
capable models from smaller ones, we report both mixture-of-expert methods and
model merging. We examine the models in diverse use cases that incorporate
biological materials, fracture and engineering analysis, protein biophysics,
and bio-inspired design based on insect behavior. Generative applications
include bio-inspired designs, including pollen-inspired architected materials,
as well as the synthesis of bio-inspired material microstructures from a
photograph of a solar eclipse. Additional model fine-tuning with a series of
molecular dynamics results demonstrate Cephalo's enhanced capabilities to
accurately predict statistical features of stress and atomic energy
distributions, as well as crack dynamics and damage in materials.",2024-05-29,Markus J. Buehler,http://arxiv.org/pdf/2405.19076v3,cs.CL
BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation,"Recent end-to-end approaches have shown promise in extending large language
models (LLMs) to speech inputs, but face limitations in directly assessing and
optimizing alignment quality and fail to achieve fine-grained alignment due to
speech-text length mismatch. We introduce BLSP-KD, a novel approach for
Bootstrapping Language-Speech Pretraining via Knowledge Distillation, which
addresses these limitations through two key techniques. First, it optimizes
speech-text alignment by minimizing the divergence between the LLM's next-token
prediction distributions for speech and text inputs using knowledge
distillation. Second, it employs a continuous-integrate-andfire strategy to
segment speech into tokens that correspond one-to-one with text tokens,
enabling fine-grained alignment. We also introduce Partial LoRA (PLoRA), a new
adaptation method supporting LLM finetuning for speech inputs under knowledge
distillation. Quantitative evaluation shows that BLSP-KD outperforms previous
end-to-end baselines and cascaded systems with comparable scale of parameters,
facilitating general instruction-following capabilities for LLMs with speech
inputs. This approach provides new possibilities for extending LLMs to spoken
language interactions.",2024-05-29,"Chen Wang, Minpeng Liao, Zhongqiang Huang, Jiajun Zhang",http://arxiv.org/pdf/2405.19041v1,cs.CL
DiveR-CT: Diversity-enhanced Red Teaming Large Language Model Assistants with Relaxing Constraints,"Recent advances in large language model assistants have made them
indispensable, raising significant concerns over managing their safety.
Automated red teaming offers a promising alternative to the labor-intensive and
error-prone manual probing for vulnerabilities, providing more consistent and
scalable safety evaluations. However, existing approaches often compromise
diversity by focusing on maximizing attack success rate. Additionally, methods
that decrease the cosine similarity from historical embeddings with semantic
diversity rewards lead to novelty stagnation as history grows. To address these
issues, we introduce DiveR-CT, which relaxes conventional constraints on the
objective and semantic reward, granting greater freedom for the policy to
enhance diversity. Our experiments demonstrate DiveR-CT's marked superiority
over baselines by 1) generating data that perform better in various diversity
metrics across different attack success rate levels, 2) better-enhancing
resiliency in blue team models through safety tuning based on collected data,
3) allowing dynamic control of objective weights for reliable and controllable
attack success rates, and 4) reducing susceptibility to reward
overoptimization. Overall, our method provides an effective and efficient
approach to LLM red teaming, accelerating real-world deployment.",2024-05-29,"Andrew Zhao, Quentin Xu, Matthieu Lin, Shenzhi Wang, Yong-jin Liu, Zilong Zheng, Gao Huang",http://arxiv.org/pdf/2405.19026v2,cs.CL
Evaluating the External and Parametric Knowledge Fusion of Large Language Models,"Integrating external knowledge into large language models (LLMs) presents a
promising solution to overcome the limitations imposed by their antiquated and
static parametric memory. Prior studies, however, have tended to over-reliance
on external knowledge, underestimating the valuable contributions of an LLMs'
intrinsic parametric knowledge. The efficacy of LLMs in blending external and
parametric knowledge remains largely unexplored, especially in cases where
external knowledge is incomplete and necessitates supplementation by their
parametric knowledge. We propose to deconstruct knowledge fusion into four
distinct scenarios, offering the first thorough investigation of LLM behavior
across each. We develop a systematic pipeline for data construction and
knowledge infusion to simulate these fusion scenarios, facilitating a series of
controlled experiments. Our investigation reveals that enhancing parametric
knowledge within LLMs can significantly bolster their capability for knowledge
integration. Nonetheless, we identify persistent challenges in memorizing and
eliciting parametric knowledge, and determining parametric knowledge
boundaries. Our findings aim to steer future explorations on harmonizing
external and parametric knowledge within LLMs.",2024-05-29,"Hao Zhang, Yuyang Zhang, Xiaoguang Li, Wenxuan Shi, Haonan Xu, Huanshuo Liu, Yasheng Wang, Lifeng Shang, Qun Liu, Yong Liu, Ruiming Tang",http://arxiv.org/pdf/2405.19010v1,cs.CL
EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture,"This paper presents EasyAnimate, an advanced method for video generation that
leverages the power of transformer architecture for high-performance outcomes.
We have expanded the DiT framework originally designed for 2D image synthesis
to accommodate the complexities of 3D video generation by incorporating a
motion module block. It is used to capture temporal dynamics, thereby ensuring
the production of consistent frames and seamless motion transitions. The motion
module can be adapted to various DiT baseline methods to generate video with
different styles. It can also generate videos with different frame rates and
resolutions during both training and inference phases, suitable for both images
and videos. Moreover, we introduce slice VAE, a novel approach to condense the
temporal axis, facilitating the generation of long duration videos. Currently,
EasyAnimate exhibits the proficiency to generate videos with 144 frames. We
provide a holistic ecosystem for video production based on DiT, encompassing
aspects such as data pre-processing, VAE training, DiT models training (both
the baseline model and LoRA model), and end-to-end video inference. Code is
available at: https://github.com/aigc-apps/EasyAnimate. We are continuously
working to enhance the performance of our method.",2024-05-29,"Jiaqi Xu, Xinyi Zou, Kunzhe Huang, Yunkuo Chen, Bo Liu, MengLi Cheng, Xing Shi, Jun Huang",http://arxiv.org/pdf/2405.18991v2,cs.CL
Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology Detection,"Multifaceted ideology detection (MID) aims to detect the ideological leanings
of texts towards multiple facets. Previous studies on ideology detection mainly
focus on one generic facet and ignore label semantics and explanatory
descriptions of ideologies, which are a kind of instructive information and
reveal the specific concepts of ideologies. In this paper, we develop a novel
concept semantics-enhanced framework for the MID task. Specifically, we propose
a bidirectional iterative concept flow (BICo) method to encode multifaceted
ideologies. BICo enables the concepts to flow across levels of the schema tree
and enriches concept representations with multi-granularity semantics.
Furthermore, we explore concept attentive matching and concept-guided
contrastive learning strategies to guide the model to capture ideology features
with the learned concept semantics. Extensive experiments on the benchmark
dataset show that our approach achieves state-of-the-art performance in MID,
including in the cross-topic scenario.",2024-05-29,"Songtao Liu, Bang Wang, Wei Xiang, Han Xu, Minghua Xu",http://arxiv.org/pdf/2405.18974v1,cs.CL
Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets,"Training Large Language Models (LLMs) with Reinforcement Learning from AI
Feedback (RLAIF) aligns model outputs more closely with human preferences. This
involves an evaluator model ranking multiple candidate responses to user
prompts. However, the rankings from popular evaluator models such as GPT-4 can
be inconsistent. We propose the Repeat Ranking method - where we evaluate the
same responses multiple times and train only on those responses which are
consistently ranked. Using 2,714 prompts in 62 languages, we generated
responses from 7 top multilingual LLMs and had GPT-4 rank them five times each.
Evaluating on MT-Bench chat benchmarks in six languages, our method
outperformed the standard practice of training on all available prompts. Our
work highlights the quality versus quantity trade-off in RLAIF dataset
generation and offers a stackable strategy for enhancing dataset and thus model
quality.",2024-05-29,Peter Devine,http://arxiv.org/pdf/2405.18952v2,cs.CL
Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D Vision-Language Understanding,"While 3D MLLMs have achieved significant progress, they are restricted to
object and scene understanding and struggle to understand 3D spatial structures
at the part level. In this paper, we introduce Kestrel, representing a novel
approach that empowers 3D MLLMs with part-aware understanding, enabling better
interpretation and segmentation grounding of 3D objects at the part level.
Despite its significance, the current landscape lacks tasks and datasets that
endow and assess this capability. Therefore, we propose two novel tasks: (1)
Part-Aware Point Grounding, the model is tasked with directly predicting a
part-level segmentation mask based on user instructions, and (2) Part-Aware
Point Grounded Captioning, the model provides a detailed caption that includes
part-level descriptions and their corresponding masks. To support learning and
evaluating for these tasks, we introduce 3DCoMPaT Grounded Instructions Dataset
(3DCoMPaT-GRIN). 3DCoMPaT-GRIN Vanilla, comprising 789k part-aware point
cloud-instruction-segmentation mask triplets, is used to evaluate MLLMs'
ability of part-aware segmentation grounding. 3DCoMPaT-GRIN Grounded Caption,
containing 107k part-aware point cloud-instruction-grounded caption triplets,
assesses both MLLMs' part-aware language comprehension and segmentation
grounding capabilities. Our introduced tasks, dataset, and Kestrel represent a
preliminary effort to bridge the gap between human cognition and 3D MLLMs,
i.e., the ability to perceive and engage with the environment at both global
and part levels. Extensive experiments on the 3DCoMPaT-GRIN show that Kestrel
can generate user-specified segmentation masks, a capability not present in any
existing 3D MLLM. Kestrel thus established a benchmark for evaluating the
part-aware language comprehension and segmentation grounding of 3D objects.
Project page at https://feielysia.github.io/Kestrel.github.io/",2024-05-29,"Junjie Fei, Mahmoud Ahmed, Jian Ding, Eslam Mohamed Bakr, Mohamed Elhoseiny",http://arxiv.org/pdf/2405.18937v1,cs.CL
Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective,"Neural Machine Translation (NMT) has made remarkable progress over the past
years. However, under-translation and over-translation remain two challenging
problems in state-of-the-art NMT systems. In this work, we conduct an in-depth
analysis on the underlying cause of under-translation in NMT, providing an
explanation from the perspective of decoding objective. To optimize the beam
search objective, the model tends to overlook words it is less confident about,
leading to the under-translation phenomenon. Correspondingly, the model's
confidence in predicting the End Of Sentence (EOS) diminishes when
under-translation occurs, serving as a mild penalty for under-translated
candidates. Building upon this analysis, we propose employing the confidence of
predicting EOS as a detector for under-translation, and strengthening the
confidence-based penalty to penalize candidates with a high risk of
under-translation. Experiments on both synthetic and real-world data show that
our method can accurately detect and rectify under-translated outputs, with
minor impact on other correct translations.",2024-05-29,"Chenze Shao, Fandong Meng, Jiali Zeng, Jie Zhou",http://arxiv.org/pdf/2405.18922v1,cs.CL
Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness,"Chain-of-thought (CoT) prompting demonstrates varying performance under
different reasoning tasks. Previous work attempts to evaluate it but falls
short in providing an in-depth analysis of patterns that influence the CoT. In
this paper, we study the CoT performance from the perspective of effectiveness
and faithfulness. For the former, we identify key factors that influence CoT
effectiveness on performance improvement, including problem difficulty,
information gain, and information flow. For the latter, we interpret the
unfaithful CoT issue by conducting a joint analysis of the information
interaction among the question, CoT, and answer. The result demonstrates that,
when the LLM predicts answers, it can recall correct information missing in the
CoT from the question, leading to the problem. Finally, we propose a novel
algorithm to mitigate this issue, in which we recall extra information from the
question to enhance the CoT generation and evaluate CoTs based on their
information gain. Extensive experiments demonstrate that our approach enhances
both the faithfulness and effectiveness of CoT.",2024-05-29,"Jiachun Li, Pengfei Cao, Yubo Chen, Jiexin Xu, Huaijun Li, Xiaojian Jiang, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2405.18915v2,cs.CL
Language Generation with Strictly Proper Scoring Rules,"Language generation based on maximum likelihood estimation (MLE) has become
the fundamental approach for text generation. Maximum likelihood estimation is
typically performed by minimizing the log-likelihood loss, also known as the
logarithmic score in statistical decision theory. The logarithmic score is
strictly proper in the sense that it encourages honest forecasts, where the
expected score is maximized only when the model reports true probabilities.
Although many strictly proper scoring rules exist, the logarithmic score is the
only local scoring rule among them that depends exclusively on the probability
of the observed sample, making it capable of handling the exponentially large
sample space of natural text. In this work, we propose a straightforward
strategy for adapting scoring rules to language generation, allowing for
language modeling with any non-local scoring rules. Leveraging this strategy,
we train language generation models using two classic strictly proper scoring
rules, the Brier score and the Spherical score, as alternatives to the
logarithmic score. Experimental results indicate that simply substituting the
loss function, without adjusting other hyperparameters, can yield substantial
improvements in model's generation capabilities. Moreover, these improvements
can scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B.
Source code: \url{https://github.com/shaochenze/ScoringRulesLM}.",2024-05-29,"Chenze Shao, Fandong Meng, Yijin Liu, Jie Zhou",http://arxiv.org/pdf/2405.18906v1,cs.CL
Prompting or Fine-tuning? Exploring Large Language Models for Causal Graph Validation,"This study explores the capability of Large Language Models (LLMs) to
evaluate causality in causal graphs generated by conventional statistical
causal discovery methods-a task traditionally reliant on manual assessment by
human subject matter experts. To bridge this gap in causality assessment, LLMs
are employed to evaluate the causal relationships by determining whether a
causal connection between variable pairs can be inferred from textual context.
Our study compares two approaches: (1) prompting-based method for zero-shot and
few-shot causal inference and, (2) fine-tuning language models for the causal
relation prediction task. While prompt-based LLMs have demonstrated versatility
across various NLP tasks, our experiments on biomedical and general-domain
datasets show that fine-tuned models consistently outperform them, achieving up
to a 20.5-point improvement in F1 score-even when using smaller-parameter
language models. These findings provide valuable insights into the strengths
and limitations of both approaches for causal graph evaluation.",2024-05-29,"Yuni Susanti, Nina Holsmoelle",http://arxiv.org/pdf/2406.16899v2,cs.CL
Are queries and keys always relevant? A case study on Transformer wave functions,"The dot product attention mechanism, originally designed for natural language
processing tasks, is a cornerstone of modern Transformers. It adeptly captures
semantic relationships between word pairs in sentences by computing a
similarity overlap between queries and keys. In this work, we explore the
suitability of Transformers, focusing on their attention mechanisms, in the
specific domain of the parametrization of variational wave functions to
approximate ground states of quantum many-body spin Hamiltonians. Specifically,
we perform numerical simulations on the two-dimensional $J_1$-$J_2$ Heisenberg
model, a common benchmark in the field of quantum many-body systems on lattice.
By comparing the performance of standard attention mechanisms with a simplified
version that excludes queries and keys, relying solely on positions, we achieve
competitive results while reducing computational cost and parameter usage.
Furthermore, through the analysis of the attention maps generated by standard
attention mechanisms, we show that the attention weights become effectively
input-independent at the end of the optimization. We support the numerical
results with analytical calculations, providing physical insights of why
queries and keys should be, in principle, omitted from the attention mechanism
when studying large systems.",2024-05-29,"Riccardo Rende, Luciano Loris Viteritti",http://arxiv.org/pdf/2405.18874v2,cs.CL
LLMs achieve adult human performance on higher-order theory of mind tasks,"This paper examines the extent to which large language models (LLMs) have
developed higher-order theory of mind (ToM); the human ability to reason about
multiple mental and emotional states in a recursive manner (e.g. I think that
you believe that she knows). This paper builds on prior work by introducing a
handwritten test suite -- Multi-Order Theory of Mind Q&A -- and using it to
compare the performance of five LLMs to a newly gathered adult human benchmark.
We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level
performance on ToM tasks overall, and that GPT-4 exceeds adult performance on
6th order inferences. Our results suggest that there is an interplay between
model size and finetuning for the realisation of ToM abilities, and that the
best-performing LLMs have developed a generalised capacity for ToM. Given the
role that higher-order ToM plays in a wide range of cooperative and competitive
human behaviours, these findings have significant implications for user-facing
LLM applications.",2024-05-29,"Winnie Street, John Oliver Siy, Geoff Keeling, Adrien Baranes, Benjamin Barnett, Michael McKibben, Tatenda Kanyere, Alison Lentz, Blaise Aguera y Arcas, Robin I. M. Dunbar",http://arxiv.org/pdf/2405.18870v2,cs.CL
"Simulation, Modelling and Classification of Wiki Contributors: Spotting The Good, The Bad, and The Ugly","Data crowdsourcing is a data acquisition process where groups of voluntary
contributors feed platforms with highly relevant data ranging from news,
comments, and media to knowledge and classifications. It typically processes
user-generated data streams to provide and refine popular services such as
wikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,
this modus operandi raises severe concerns regarding ill-intentioned data
manipulation in adversarial environments. This paper presents a simulation,
modelling, and classification approach to automatically identify human and
non-human (bots) as well as benign and malign contributors by using data
fabrication to balance classes within experimental data sets, data stream
modelling to build and update contributor profiles and, finally, autonomic data
stream classification. By employing WikiVoyage - a free worldwide wiki travel
guide open to contribution from the general public - as a testbed, our approach
proves to significantly boost the confidence and quality of the classifier by
using a class-balanced data stream, comprising both real and synthetic data.
Our empirical results show that the proposed method distinguishes between
benign and malign bots as well as human contributors with a classification
accuracy of up to 92 %.",2024-05-29,"Silvia García Méndez, Fátima Leal, Benedita Malheiro, Juan Carlos Burguillo Rial, Bruno Veloso, Adriana E. Chis, Horacio González Vélez",http://arxiv.org/pdf/2405.18845v1,cs.CL
Toxicity Detection for Free,"Current LLMs are generally aligned to follow safety requirements and tend to
refuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be
overcautious and refuse benign examples. In addition, state-of-the-art toxicity
detectors have low TPRs at low FPR, incurring high costs in real-world
applications where toxic examples are rare. In this paper, we introduce
Moderation Using LLM Introspection (MULI), which detects toxic prompts using
the information extracted directly from LLMs themselves. We found we can
distinguish between benign and toxic prompts from the distribution of the first
response token's logits. Using this idea, we build a robust detector of toxic
prompts using a sparse logistic regression model on the first response token
logits. Our scheme outperforms SOTA detectors under multiple metrics.",2024-05-29,"Zhanhao Hu, Julien Piet, Geng Zhao, Jiantao Jiao, David Wagner",http://arxiv.org/pdf/2405.18822v2,cs.CL
LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models,"Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants
have been proposed to ensure rigorous privacy for fine-tuning large-scale
pre-trained language models. However, they rely heavily on the Gaussian
mechanism, which may overly perturb the gradients and degrade the accuracy,
especially in stronger privacy regimes (e.g., the privacy budget $\epsilon <
3$). To address such limitations, we propose a novel Language Model-based
Optimal Differential Privacy (LMO-DP) mechanism, which takes the first step to
enable the tight composition of accurately fine-tuning (large) language models
with a sub-optimal DP mechanism, even in strong privacy regimes (e.g., $0.1\leq
\epsilon<3$). Furthermore, we propose a novel offline optimal noise search
method to efficiently derive the sub-optimal DP that significantly reduces the
noise magnitude. For instance, fine-tuning RoBERTa-large (with 300M parameters)
on the SST-2 dataset can achieve an accuracy of 92.20% (given $\epsilon=0.3$,
$\delta=10^{-10}$) by drastically outperforming the Gaussian mechanism (e.g.,
$\sim 50\%$ for small $\epsilon$ and $\delta$). We also draw similar findings
on the text generation tasks on GPT-2. Finally, to our best knowledge, LMO-DP
is also the first solution to accurately fine-tune Llama-2 with strong
differential privacy guarantees. The code will be released soon and available
upon request.",2024-05-29,"Qin Yang, Meisam Mohammad, Han Wang, Ali Payani, Ashish Kundu, Kai Shu, Yan Yan, Yuan Hong",http://arxiv.org/pdf/2405.18776v1,cs.CL
Musical Phrase Segmentation via Grammatical Induction,"We outline a solution to the challenge of musical phrase segmentation that
uses grammatical induction algorithms, a class of algorithms which infer a
context-free grammar from an input sequence. We analyze the performance of five
grammatical induction algorithms on three datasets using various musical
viewpoint combinations. Our experiments show that the LONGESTFIRST algorithm
achieves the best F1 scores across all three datasets and that input encodings
that include the duration viewpoint result in the best performance.",2024-05-29,"Reed Perkins, Dan Ventura",http://arxiv.org/pdf/2405.18742v1,cs.CL
Genshin: General Shield for Natural Language Processing with Large Language Models,"Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been
trending recently, demonstrating considerable advancement and generalizability
power in countless domains. However, LLMs create an even bigger black box
exacerbating opacity, with interpretability limited to few approaches. The
uncertainty and opacity embedded in LLMs' nature restrict their application in
high-stakes domains like financial fraud, phishing, etc. Current approaches
mainly rely on traditional textual classification with posterior interpretable
algorithms, suffering from attackers who may create versatile adversarial
samples to break the system's defense, forcing users to make trade-offs between
efficiency and robustness. To address this issue, we propose a novel cascading
framework called Genshin (General Shield for Natural Language Processing with
Large Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike
most applications of LLMs that try to transform text into something new or
structural, Genshin uses LLMs to recover text to its original state. Genshin
aims to combine the generalizability of the LLM, the discrimination of the
median model, and the interpretability of the simple model. Our experiments on
the task of sentimental analysis and spam detection have shown fatal flaws of
the current median models and exhilarating results on LLMs' recovery ability,
demonstrating that Genshin is both effective and efficient. In our ablation
study, we unearth several intriguing observations. Utilizing the LLM defender,
a tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal
mask rate results in the 3rd paradigm of NLP. Additionally, when employing the
LLM as a potential adversarial tool, attackers are capable of executing
effective attacks that are nearly semantically lossless.",2024-05-29,"Xiao Peng, Tao Liu, Ying Wang",http://arxiv.org/pdf/2405.18741v2,cs.CL
Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs,"Despite impressive advances in recent multimodal large language models
(MLLMs), state-of-the-art models such as from the GPT-4 suite still struggle
with knowledge-intensive tasks. To address this, we consider Reverse Image
Retrieval (RIR) augmented generation, a simple yet effective strategy to
augment MLLMs with web-scale reverse image search results. RIR robustly
improves knowledge-intensive visual question answering (VQA) of GPT-4V by
37-43%, GPT-4 Turbo by 25-27%, and GPT-4o by 18-20% in terms of open-ended VQA
evaluation metrics. To our surprise, we discover that RIR helps the model to
better access its own world knowledge. Concretely, our experiments suggest that
RIR augmentation helps by providing further visual and textual cues without
necessarily containing the direct answer to a query. In addition, we elucidate
cases in which RIR can hurt performance and conduct a human evaluation.
Finally, we find that the overall advantage of using RIR makes it difficult for
an agent that can choose to use RIR to perform better than an approach where
RIR is the default setting.",2024-05-29,"Jialiang Xu, Michael Moor, Jure Leskovec",http://arxiv.org/pdf/2405.18740v1,cs.CL
CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control,"Retrieval-augmented generation (RAG) has emerged as a promising solution for
mitigating hallucinations of large language models (LLMs) with retrieved
external knowledge. Adaptive RAG enhances this approach by enabling dynamic
retrieval during generation, activating retrieval only when the query exceeds
LLM's internal knowledge. Existing methods primarily focus on detecting LLM's
confidence via statistical uncertainty. Instead, we present the first attempts
to solve adaptive RAG from a representation perspective and develop an inherent
control-based framework, termed \name. Specifically, we extract the features
that represent the honesty and confidence directions of LLM and adopt them to
control LLM behavior and guide retrieval timing decisions. We also design a
simple yet effective query formulation strategy to support adaptive retrieval.
Experiments show that \name is superior to existing adaptive RAG methods on a
diverse set of tasks, the honesty steering can effectively make LLMs more
honest and confidence monitoring is a promising indicator of retrieval
trigger.Our code is available at \url{https://github.com/HSLiu-Initial/CtrlA}.",2024-05-29,"Huanshuo Liu, Hao Zhang, Zhijiang Guo, Jing Wang, Kuicai Dong, Xiangyang Li, Yi Quan Lee, Cong Zhang, Yong Liu",http://arxiv.org/pdf/2405.18727v2,cs.CL
Correctable Landmark Discovery via Large Models for Vision-Language Navigation,"Vision-Language Navigation (VLN) requires the agent to follow language
instructions to reach a target position. A key factor for successful navigation
is to align the landmarks implied in the instruction with diverse visual
observations. However, previous VLN agents fail to perform accurate modality
alignment especially in unexplored scenes, since they learn from limited
navigation data and lack sufficient open-world alignment knowledge. In this
work, we propose a new VLN paradigm, called COrrectable LaNdmark DiScOvery via
Large ModEls (CONSOLE). In CONSOLE, we cast VLN as an open-world sequential
landmark discovery problem, by introducing a novel correctable landmark
discovery scheme based on two large models ChatGPT and CLIP. Specifically, we
use ChatGPT to provide rich open-world landmark cooccurrence commonsense, and
conduct CLIP-driven landmark discovery based on these commonsense priors. To
mitigate the noise in the priors due to the lack of visual constraints, we
introduce a learnable cooccurrence scoring module, which corrects the
importance of each cooccurrence according to actual observations for accurate
landmark discovery. We further design an observation enhancement strategy for
an elegant combination of our framework with different VLN agents, where we
utilize the corrected landmark features to obtain enhanced observation features
for action decision. Extensive experimental results on multiple popular VLN
benchmarks (R2R, REVERIE, R4R, RxR) show the significant superiority of CONSOLE
over strong baselines. Especially, our CONSOLE establishes the new
state-of-the-art results on R2R and R4R in unseen scenarios. Code is available
at https://github.com/expectorlin/CONSOLE.",2024-05-29,"Bingqian Lin, Yunshuang Nie, Ziming Wei, Yi Zhu, Hang Xu, Shikui Ma, Jianzhuang Liu, Xiaodan Liang",http://arxiv.org/pdf/2405.18721v2,cs.CL
Contextual Position Encoding: Learning to Count What's Important,"The attention mechanism is a critical component of Large Language Models
(LLMs) that allows tokens in a sequence to interact with each other, but is
order-invariant. Incorporating position encoding (PE) makes it possible to
address by position, such as attending to the i-th token. However, current PE
methods use token counts to derive position, and thus cannot generalize to
higher levels of abstraction, such as attending to the i-th sentence. In this
paper, we propose a new position encoding method, Contextual Position Encoding
(CoPE), that allows positions to be conditioned on context by incrementing
position only on certain tokens determined by the model. This allows more
general position addressing such as attending to the $i$-th particular word,
noun, or sentence. We show that CoPE can solve the selective copy, counting and
Flip-Flop tasks where popular position embeddings fail, and improves perplexity
on language modeling and coding tasks.",2024-05-29,"Olga Golovneva, Tianlu Wang, Jason Weston, Sainbayar Sukhbaatar",http://arxiv.org/pdf/2405.18719v2,cs.CL
Efficient Model-agnostic Alignment via Bayesian Persuasion,"With recent advancements in large language models (LLMs), alignment has
emerged as an effective technique for keeping LLMs consensus with human intent.
Current methods primarily involve direct training through Supervised
Fine-tuning (SFT) or Reinforcement Learning from Human Feedback (RLHF), both of
which require substantial computational resources and extensive ground truth
data. This paper explores an efficient method for aligning black-box large
models using smaller models, introducing a model-agnostic and lightweight
Bayesian Persuasion Alignment framework. We formalize this problem as an
optimization of the signaling strategy from the small model's perspective. In
the persuasion process, the small model (Advisor) observes the information item
(i.e., state) and persuades large models (Receiver) to elicit improved
responses. The Receiver then generates a response based on the input, the
signal from the Advisor, and its updated belief about the information item.
Through training using our framework, we demonstrate that the Advisor can
significantly enhance the performance of various Receivers across a range of
tasks. We theoretically analyze our persuasion framework and provide an upper
bound on the Advisor's regret, confirming its effectiveness in learning the
optimal signaling strategy. Our Empirical results demonstrates that GPT-2 can
significantly improve the performance of various models, achieving an average
enhancement of 16.1% in mathematical reasoning ability and 13.7% in code
generation. We hope our work can provide an initial step toward rethinking the
alignment framework from the Bayesian Persuasion perspective.",2024-05-29,"Fengshuo Bai, Mingzhi Wang, Zhaowei Zhang, Boyuan Chen, Yinda Xu, Ying Wen, Yaodong Yang",http://arxiv.org/pdf/2405.18718v1,cs.CL
Calibrating Reasoning in Language Models with Internal Consistency,"Large language models (LLMs) have demonstrated impressive capabilities in
various reasoning tasks, aided by techniques like chain-of-thought prompting
that elicits verbalized reasoning. However, LLMs often generate text with
obvious mistakes and contradictions, raising doubts about their ability to
robustly process and utilize generated rationales. In this work, we investigate
reasoning in LLMs through the lens of internal representations, focusing on how
these representations are influenced by generated rationales. Our preliminary
analysis reveals that while generated rationales improve answer accuracy,
inconsistencies emerge between the model's internal representations in middle
layers and those in final layers, potentially undermining the reliability of
their reasoning processes. To address this, we propose internal consistency as
a measure of the model's confidence by examining the agreement of latent
predictions decoded from intermediate layers. Extensive empirical studies
across different models and datasets demonstrate that internal consistency
effectively distinguishes between correct and incorrect reasoning paths.
Motivated by this, we propose a new approach to calibrate reasoning by
up-weighting reasoning paths with high internal consistency, resulting in a
significant boost in reasoning performance. Further analysis uncovers distinct
patterns in attention and feed-forward modules across layers, providing
insights into the emergence of internal inconsistency. In summary, our results
demonstrate the potential of using internal representations for self-evaluation
of LLMs. Our code is available at github.com/zhxieml/internal-consistency.",2024-05-29,"Zhihui Xie, Jizhou Guo, Tong Yu, Shuai Li",http://arxiv.org/pdf/2405.18711v2,cs.CL
Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation,"Preference-based reinforcement learning (PbRL) has shown impressive
capabilities in training agents without reward engineering. However, a notable
limitation of PbRL is its dependency on substantial human feedback. This
dependency stems from the learning loop, which entails accurate reward learning
compounded with value/policy learning, necessitating a considerable number of
samples. To boost the learning loop, we propose SEER, an efficient PbRL method
that integrates label smoothing and policy regularization techniques. Label
smoothing reduces overfitting of the reward model by smoothing human preference
labels. Additionally, we bootstrap a conservative estimate $\widehat{Q}$ using
well-supported state-action pairs from the current replay memory to mitigate
overestimation bias and utilize it for policy learning regularization. Our
experimental results across a variety of complex tasks, both in online and
offline settings, demonstrate that our approach improves feedback efficiency,
outperforming state-of-the-art methods by a large margin. Ablation studies
further reveal that SEER achieves a more accurate Q-function compared to prior
work.",2024-05-29,"Fengshuo Bai, Rui Zhao, Hongming Zhang, Sijia Cui, Ying Wen, Yaodong Yang, Bo Xu, Lei Han",http://arxiv.org/pdf/2405.18688v1,cs.CL
Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension,"Large language models (LLMs) have shown remarkable performance on many tasks
in different domains. However, their performance in closed-book biomedical
machine reading comprehension (MRC) has not been evaluated in depth. In this
work, we evaluate GPT on four closed-book biomedical MRC benchmarks. We
experiment with different conventional prompting techniques as well as
introduce our own novel prompting method. To solve some of the retrieval
problems inherent to LLMs, we propose a prompting strategy named Implicit
Retrieval Augmented Generation (RAG) that alleviates the need for using vector
databases to retrieve important chunks in traditional RAG setups. Moreover, we
report qualitative assessments on the natural language generation outputs from
our approach. The results show that our new prompting technique is able to get
the best performance in two out of four datasets and ranks second in rest of
them. Experiments show that modern-day LLMs like GPT even in a zero-shot
setting can outperform supervised models, leading to new state-of-the-art
(SoTA) results on two of the benchmarks.",2024-05-29,"Shubham Vatsal, Ayush Singh",http://arxiv.org/pdf/2405.18682v2,cs.CL
LLM-based Hierarchical Concept Decomposition for Interpretable Fine-Grained Image Classification,"(Renyi Qu's Master's Thesis) Recent advancements in interpretable models for
vision-language tasks have achieved competitive performance; however, their
interpretability often suffers due to the reliance on unstructured text outputs
from large language models (LLMs). This introduces randomness and compromises
both transparency and reliability, which are essential for addressing safety
issues in AI systems. We introduce \texttt{Hi-CoDe} (Hierarchical Concept
Decomposition), a novel framework designed to enhance model interpretability
through structured concept analysis. Our approach consists of two main
components: (1) We use GPT-4 to decompose an input image into a structured
hierarchy of visual concepts, thereby forming a visual concept tree. (2) We
then employ an ensemble of simple linear classifiers that operate on
concept-specific features derived from CLIP to perform classification. Our
approach not only aligns with the performance of state-of-the-art models but
also advances transparency by providing clear insights into the decision-making
process and highlighting the importance of various concepts. This allows for a
detailed analysis of potential failure modes and improves model compactness,
therefore setting a new benchmark in interpretability without compromising the
accuracy.",2024-05-29,"Renyi Qu, Mark Yatskar",http://arxiv.org/pdf/2405.18672v2,cs.CL
Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities,"Integrating multiple generative foundation models, especially those trained
on different modalities, into something greater than the sum of its parts poses
significant challenges. Two key hurdles are the availability of aligned data
(concepts that contain similar meaning but is expressed differently in
different modalities), and effectively leveraging unimodal representations in
cross-domain generative tasks, without compromising their original unimodal
capabilities.
  We propose Zipper, a multi-tower decoder architecture that addresses these
concerns by using cross-attention to flexibly compose multimodal generative
models from independently pre-trained unimodal decoders. In our experiments
fusing speech and text modalities, we show the proposed architecture performs
very competitively in scenarios with limited aligned text-speech data. We also
showcase the flexibility of our model to selectively maintain unimodal (e.g.,
text-to-text generation) generation performance by freezing the corresponding
modal tower (e.g. text). In cross-modal tasks such as automatic speech
recognition (ASR) where the output modality is text, we show that freezing the
text backbone results in negligible performance degradation. In cross-modal
tasks such as text-to-speech generation (TTS) where the output modality is
speech, we show that using a pre-trained speech backbone results in superior
performance to the baseline.",2024-05-29,"Vicky Zayats, Peter Chen, Melissa Ferrari, Dirk Padfield",http://arxiv.org/pdf/2405.18669v2,cs.CL
Understanding Intrinsic Socioeconomic Biases in Large Language Models,"Large Language Models (LLMs) are increasingly integrated into critical
decision-making processes, such as loan approvals and visa applications, where
inherent biases can lead to discriminatory outcomes. In this paper, we examine
the nuanced relationship between demographic attributes and socioeconomic
biases in LLMs, a crucial yet understudied area of fairness in LLMs. We
introduce a novel dataset of one million English sentences to systematically
quantify socioeconomic biases across various demographic groups. Our findings
reveal pervasive socioeconomic biases in both established models such as GPT-2
and state-of-the-art models like Llama 2 and Falcon. We demonstrate that these
biases are significantly amplified when considering intersectionality, with
LLMs exhibiting a remarkable capacity to extract multiple demographic
attributes from names and then correlate them with specific socioeconomic
biases. This research highlights the urgent necessity for proactive and robust
bias mitigation techniques to safeguard against discriminatory outcomes when
deploying these powerful models in critical real-world applications.",2024-05-28,"Mina Arzaghi, Florian Carichon, Golnoosh Farnadi",http://arxiv.org/pdf/2405.18662v1,cs.CL
Recent Advances of Foundation Language Models-based Continual Learning: A Survey,"Recently, foundation language models (LMs) have marked significant
achievements in the domains of natural language processing (NLP) and computer
vision (CV). Unlike traditional neural network models, foundation LMs obtain a
great ability for transfer learning by acquiring rich commonsense knowledge
through pre-training on extensive unsupervised datasets with a vast number of
parameters. However, they still can not emulate human-like continuous learning
due to catastrophic forgetting. Consequently, various continual learning
(CL)-based methodologies have been developed to refine LMs, enabling them to
adapt to new tasks without forgetting previous knowledge. However, a systematic
taxonomy of existing approaches and a comparison of their performance are still
lacking, which is the gap that our survey aims to fill. We delve into a
comprehensive review, summarization, and classification of the existing
literature on CL-based approaches applied to foundation language models, such
as pre-trained language models (PLMs), large language models (LLMs) and
vision-language models (VLMs). We divide these studies into offline CL and
online CL, which consist of traditional methods, parameter-efficient-based
methods, instruction tuning-based methods and continual pre-training methods.
Offline CL encompasses domain-incremental learning, task-incremental learning,
and class-incremental learning, while online CL is subdivided into hard task
boundary and blurry task boundary settings. Additionally, we outline the
typical datasets and metrics employed in CL research and provide a detailed
analysis of the challenges and future work for LMs-based continual learning.",2024-05-28,"Yutao Yang, Jie Zhou, Xuanwen Ding, Tianyu Huai, Shunyu Liu, Qin Chen, Yuan Xie, Liang He",http://arxiv.org/pdf/2405.18653v2,cs.CL
Are PPO-ed Language Models Hackable?,"Numerous algorithms have been proposed to $\textit{align}$ language models to
remove undesirable behaviors. However, the challenges associated with a very
large state space and creating a proper reward function often result in various
jailbreaks. Our paper aims to examine this effect of reward in the controlled
setting of positive sentiment language generation. Instead of online training
of a reward model based on human feedback, we employ a statically learned
sentiment classifier. We also consider a setting where our model's weights and
activations are exposed to an end-user after training. We examine a pretrained
GPT-2 through the lens of mechanistic interpretability before and after
proximal policy optimization (PPO) has been applied to promote positive
sentiment responses. Using these insights, we (1) attempt to ""hack"" the PPO-ed
model to generate negative sentiment responses and (2) add a term to the reward
function to try and alter `negative' weights.",2024-05-28,"Suraj Anand, David Getzen",http://arxiv.org/pdf/2406.02577v1,cs.CL
LeDex: Training LLMs to Better Self-Debug and Explain Code,"In the domain of code generation, self-debugging is crucial. It allows LLMs
to refine their generated code based on execution feedback. This is
particularly important because generating correct solutions in one attempt
proves challenging for complex tasks. Prior works on self-debugging mostly
focus on prompting methods by providing LLMs with few-shot examples, which work
poorly on small open-sourced LLMs. In this work, we propose LeDex, a training
framework that significantly improves the self-debugging capability of LLMs.
Intuitively, we observe that a chain of explanations on the wrong code followed
by code refinement helps LLMs better analyze the wrong code and do refinement.
We thus propose an automated pipeline to collect a high-quality dataset for
code explanation and refinement by generating a number of explanations and
refinement trajectories from the LLM itself or a larger teacher model and
filtering via execution verification. We perform supervised fine-tuning (SFT)
and further reinforcement learning (RL) on both success and failure
trajectories with a novel reward design considering code explanation and
refinement quality. SFT improves the pass@1 by up to 15.92% and pass@10 by
9.30% over four benchmarks. RL training brings additional up to 3.54%
improvement on pass@1 and 2.55% improvement on pass@10. The trained LLMs show
iterative refinement ability and can keep refining code continuously. Lastly,
our human evaluation shows that the LLMs trained with our framework generate
more useful code explanations and help developers better understand bugs in
source code.",2024-05-28,"Nan Jiang, Xiaopeng Li, Shiqi Wang, Qiang Zhou, Soneya Binta Hossain, Baishakhi Ray, Varun Kumar, Xiaofei Ma, Anoop Deoras",http://arxiv.org/pdf/2405.18649v2,cs.CL
JADS: A Framework for Self-supervised Joint Aspect Discovery and Summarization,"To generate summaries that include multiple aspects or topics for text
documents, most approaches use clustering or topic modeling to group relevant
sentences and then generate a summary for each group. These approaches struggle
to optimize the summarization and clustering algorithms jointly. On the other
hand, aspect-based summarization requires known aspects. Our solution
integrates topic discovery and summarization into a single step. Given text
data, our Joint Aspect Discovery and Summarization algorithm (JADS) discovers
aspects from the input and generates a summary of the topics, in one step. We
propose a self-supervised framework that creates a labeled dataset by first
mixing sentences from multiple documents (e.g., CNN/DailyMail articles) as the
input and then uses the article summaries from the mixture as the labels. The
JADS model outperforms the two-step baselines. With pretraining, the model
achieves better performance and stability. Furthermore, embeddings derived from
JADS exhibit superior clustering capabilities. Our proposed method achieves
higher semantic alignment with ground truth and is factual.",2024-05-28,"Xiaobo Guo, Jay Desai, Srinivasan H. Sengamedu",http://arxiv.org/pdf/2405.18642v1,cs.CL
Improving Speech Decoding from ECoG with Self-Supervised Pretraining,"Recent work on intracranial brain-machine interfaces has demonstrated that
spoken speech can be decoded with high accuracy, essentially by treating the
problem as an instance of supervised learning and training deep neural networks
to map from neural activity to text. However, such networks pay for their
expressiveness with very large numbers of labeled data, a requirement that is
particularly burdensome for invasive neural recordings acquired from human
patients. On the other hand, these patients typically produce speech outside of
the experimental blocks used for training decoders. Making use of such data,
and data from other patients, to improve decoding would ease the burden of data
collection -- especially onerous for dys- and anarthric patients. Here we
demonstrate that this is possible, by reengineering wav2vec -- a simple,
self-supervised, fully convolutional model that learns latent representations
of audio using a noise-contrastive loss -- for electrocorticographic (ECoG)
data. We train this model on unlabelled ECoG recordings, and subsequently use
it to transform ECoG from labeled speech sessions into wav2vec's representation
space, before finally training a supervised encoder-decoder to map these
representations to text. We experiment with various numbers of labeled blocks;
for almost all choices, the new representations yield superior decoding
performance to the original ECoG data, and in no cases do they yield worse.
Performance can also be improved in some cases by pretraining wav2vec on
another patient's data. In the best cases, wav2vec's representations decrease
word error rates over the original data by upwards of 50%.",2024-05-28,"Brian A. Yuan, Joseph G. Makin",http://arxiv.org/pdf/2405.18639v1,cs.CL
ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation for Generative Large Language Models,"In this position paper, we argue that human evaluation of generative large
language models (LLMs) should be a multidisciplinary undertaking that draws
upon insights from disciplines such as user experience research and human
behavioral psychology to ensure that the experimental design and results are
reliable. The conclusions from these evaluations, thus, must consider factors
such as usability, aesthetics, and cognitive biases. We highlight how cognitive
biases can conflate fluent information and truthfulness, and how cognitive
uncertainty affects the reliability of rating scores such as Likert.
Furthermore, the evaluation should differentiate the capabilities and
weaknesses of increasingly powerful large language models -- which requires
effective test sets. The scalability of human evaluation is also crucial to
wider adoption. Hence, to design an effective human evaluation system in the
age of generative NLP, we propose the ConSiDERS-The-Human evaluation framework
consisting of 6 pillars -- Consistency, Scoring Criteria, Differentiating, User
Experience, Responsible, and Scalability.",2024-05-28,"Aparna Elangovan, Ling Liu, Lei Xu, Sravan Bodapati, Dan Roth",http://arxiv.org/pdf/2405.18638v2,cs.CL
A Theoretical Understanding of Self-Correction through In-context Alignment,"Going beyond mimicking limited human experiences, recent studies show initial
evidence that, like humans, large language models (LLMs) are capable of
improving their abilities purely by self-correction, i.e., correcting previous
responses through self-examination, in certain circumstances. Nevertheless,
little is known about how such capabilities arise. In this work, based on a
simplified setup akin to an alignment task, we theoretically analyze
self-correction from an in-context learning perspective, showing that when LLMs
give relatively accurate self-examinations as rewards, they are capable of
refining responses in an in-context way. Notably, going beyond previous
theories on over-simplified linear transformers, our theoretical construction
underpins the roles of several key designs of realistic transformers for
self-correction: softmax attention, multi-head attention, and the MLP block. We
validate these findings extensively on synthetic datasets. Inspired by these
findings, we also illustrate novel applications of self-correction, such as
defending against LLM jailbreaks, where a simple self-correction step does make
a large difference. We believe that these findings will inspire further
research on understanding, exploiting, and enhancing self-correction for
building better foundation models.",2024-05-28,"Yifei Wang, Yuyang Wu, Zeming Wei, Stefanie Jegelka, Yisen Wang",http://arxiv.org/pdf/2405.18634v2,cs.CL
Hardware-Aware Parallel Prompt Decoding for Memory-Efficient Acceleration of LLM Inference,"The auto-regressive decoding of Large Language Models (LLMs) results in
significant overheads in their hardware performance. While recent research has
investigated various speculative decoding techniques for multi-token
generation, these efforts have primarily focused on improving processing speed
such as throughput. Crucially, they often neglect other metrics essential for
real-life deployments, such as memory consumption and training cost. To
overcome these limitations, we propose a novel parallel prompt decoding that
requires only $0.0002$% trainable parameters, enabling efficient training on a
single A100-40GB GPU in just 16 hours. Inspired by the human natural language
generation process, $PPD$ approximates outputs generated at future timesteps in
parallel by using multiple prompt tokens. This approach partially recovers the
missing conditional dependency information necessary for multi-token
generation, resulting in up to a 28% higher acceptance rate for long-range
predictions. Furthermore, we present a hardware-aware dynamic sparse tree
technique that adaptively optimizes this decoding scheme to fully leverage the
computational capacities on different GPUs. Through extensive experiments
across LLMs ranging from MobileLlama to Vicuna-13B on a wide range of
benchmarks, our approach demonstrates up to 2.49$\times$ speedup and maintains
a minimal runtime memory overhead of just $0.0004$%. More importantly, our
parallel prompt decoding can serve as an orthogonal optimization for
synergistic integration with existing speculative decoding, showing up to
$1.22\times$ further speed improvement. Our code is available at
https://github.com/hmarkc/parallel-prompt-decoding.",2024-05-28,"Hao Mark Chen, Wayne Luk, Ka Fai Cedric Yiu, Rui Li, Konstantin Mishchenko, Stylianos I. Venieris, Hongxiang Fan",http://arxiv.org/pdf/2405.18628v2,cs.CL
RealitySummary: Exploring On-Demand Mixed Reality Text Summarization and Question Answering using Large Language Models,"Large Language Models (LLMs) are gaining popularity as tools for reading and
summarization aids. However, little is known about their potential benefits
when integrated with mixed reality (MR) interfaces to support everyday reading
assistants. We developed RealitySummary, an MR reading assistant that
seamlessly integrates LLMs with always-on camera access, OCR-based text
extraction, and augmented spatial and visual responses in MR interfaces.
Developed iteratively, RealitySummary evolved across three versions, each
shaped by user feedback and reflective analysis: 1) a preliminary user study to
understand user perceptions (N=12), 2) an in-the-wild deployment to explore
real-world usage (N=11), and 3) a diary study to capture insights from
real-world work contexts (N=5). Our findings highlight the unique advantages of
combining AI and MR, including an always-on implicit assistant, minimal context
switching, and spatial affordances, demonstrating significant potential for
future LLM-MR interfaces beyond traditional screen-based interactions.",2024-05-28,"Aditya Gunturu, Shivesh Jadon, Nandi Zhang, Morteza Faraji, Jarin Thundathil, Tafreed Ahmad, Wesley Willett, Ryo Suzuki",http://arxiv.org/pdf/2405.18620v2,cs.CL
GLOCON Database: Design Decisions and User Manual (v1.0),"GLOCON is a database of contentious events automatically extracted from
national news sources from various countries in multiple languages. National
news sources are utilized, and complete news archives are processed to create
an event list for each source. Automation is achieved using a gold standard
corpus sampled randomly from complete news archives (Y\""or\""uk et al. 2022) and
all annotated by at least two domain experts based on the event definition
provided in Duru\c{s}an et al. (2022).",2024-05-28,"Ali Hürriyetoğlu, Osman Mutlu, Fırat Duruşan, Erdem Yörük",http://arxiv.org/pdf/2405.18613v1,cs.CL
Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting,"Language models have the ability to perform in-context learning (ICL),
allowing them to flexibly adapt their behavior based on context. This contrasts
with in-weights learning (IWL), where memorized information is encoded in model
parameters after iterated observations of data. An ideal model should be able
to flexibly deploy both of these abilities. Despite their apparent ability to
learn in-context, language models are known to struggle when faced with unseen
or rarely seen tokens (Land & Bartolo, 2024). Hence, we study
$\textbf{structural in-context learning}$, which we define as the ability of a
model to execute in-context learning on arbitrary novel tokens -- so called
because the model must generalize on the basis of e.g. sentence structure or
task structure, rather than content encoded in token embeddings. We study
structural in-context algorithms on both synthetic and naturalistic tasks using
toy models, masked language models, and autoregressive language models. We find
that structural ICL appears before quickly disappearing early in LM
pretraining. While it has been shown that ICL can diminish during training
(Singh et al., 2023), we find that prior work does not account for structural
ICL. Building on Chen et al. (2024) 's active forgetting method, we introduce
pretraining and finetuning methods that can modulate the preference for
structural ICL and IWL. Importantly, this allows us to induce a $\textit{dual
process strategy}$ where in-context and in-weights solutions coexist within a
single model.",2024-05-28,"Suraj Anand, Michael A. Lepori, Jack Merullo, Ellie Pavlick",http://arxiv.org/pdf/2406.00053v3,cs.CL
BioBERT-based Deep Learning and Merged ChemProt-DrugProt for Enhanced Biomedical Relation Extraction,"This paper presents a methodology for enhancing relation extraction from
biomedical texts, focusing specifically on chemical-gene interactions.
Leveraging the BioBERT model and a multi-layer fully connected network
architecture, our approach integrates the ChemProt and DrugProt datasets using
a novel merging strategy. Through extensive experimentation, we demonstrate
significant performance improvements, particularly in CPR groups shared between
the datasets. The findings underscore the importance of dataset merging in
augmenting sample counts and improving model accuracy. Moreover, the study
highlights the potential of automated information extraction in biomedical
research and clinical practice.",2024-05-28,"Bridget T. McInnes, Jiawei Tang, Darshini Mahendran, Mai H. Nguyen",http://arxiv.org/pdf/2405.18605v1,cs.CL
Low-rank finetuning for LLMs: A fairness perspective,"Low-rank approximation techniques have become the de facto standard for
fine-tuning Large Language Models (LLMs) due to their reduced computational and
memory requirements. This paper investigates the effectiveness of these methods
in capturing the shift of fine-tuning datasets from the initial pre-trained
data distribution. Our findings reveal that there are cases in which low-rank
fine-tuning falls short in learning such shifts. This, in turn, produces
non-negligible side effects, especially when fine-tuning is adopted for
toxicity mitigation in pre-trained models, or in scenarios where it is
important to provide fair models. Through comprehensive empirical evidence on
several models, datasets, and tasks, we show that low-rank fine-tuning
inadvertently preserves undesirable biases and toxic behaviors. We also show
that this extends to sequential decision-making tasks, emphasizing the need for
careful evaluation to promote responsible LLMs development.",2024-05-28,"Saswat Das, Marco Romanelli, Cuong Tran, Zarreen Reza, Bhavya Kailkhura, Ferdinando Fioretto",http://arxiv.org/pdf/2405.18572v1,cs.CL
Decoding moral judgement from text: a pilot study,"Moral judgement is a complex human reaction that engages cognitive and
emotional dimensions. While some of the morality neural correlates are known,
it is currently unclear if we can detect moral violation at a single-trial
level. In a pilot study, here we explore the feasibility of moral judgement
decoding from text stimuli with passive brain-computer interfaces. For
effective moral judgement elicitation, we use video-audio affective priming
prior to text stimuli presentation and attribute the text to moral agents. Our
results show that further efforts are necessary to achieve reliable
classification between moral congruency vs. incongruency states. We obtain good
accuracy results for neutral vs. morally-charged trials. With this research, we
try to pave the way towards neuroadaptive human-computer interaction and more
human-compatible large language models (LLMs)",2024-05-28,"Diana E. Gherman, Thorsten O. Zander",http://arxiv.org/pdf/2407.00039v1,cs.CL
It's Not a Modality Gap: Characterizing and Addressing the Contrastive Gap,"Multi-modal contrastive models such as CLIP achieve state-of-the-art
performance in zero-shot classification by embedding input images and texts on
a joint representational space. Recently, a modality gap has been reported in
two-encoder contrastive models like CLIP, meaning that the image and text
embeddings reside in disjoint areas of the latent space. Previous studies
suggest that this gap exists due to 1) the cone effect, 2) mismatched pairs in
the dataset, and 3) insufficient training. We show that, even when accounting
for all these factors, and even when using the same modality, the contrastive
loss actually creates a gap during training. As a result, We propose that the
modality gap is inherent to the two-encoder contrastive loss and rename it the
contrastive gap. We present evidence that attributes this contrastive gap to
low uniformity in CLIP space, resulting in embeddings that occupy only a small
portion of the latent space. To close the gap, we adapt the uniformity and
alignment properties of unimodal contrastive loss to the multi-modal setting
and show that simply adding these terms to the CLIP loss distributes the
embeddings more uniformly in the representational space, closing the gap. In
our experiments, we show that the modified representational space achieves
better performance than default CLIP loss in downstream tasks such as zero-shot
image classification and multi-modal arithmetic.",2024-05-28,"Abrar Fahim, Alex Murphy, Alona Fyshe",http://arxiv.org/pdf/2405.18570v3,cs.CL
Automatic detection of cognitive impairment in elderly people using an entertainment chatbot with Natural Language Processing capabilities,"Previous researchers have proposed intelligent systems for therapeutic
monitoring of cognitive impairments. However, most existing practical
approaches for this purpose are based on manual tests. This raises issues such
as excessive caretaking effort and the white-coat effect. To avoid these
issues, we present an intelligent conversational system for entertaining
elderly people with news of their interest that monitors cognitive impairment
transparently. Automatic chatbot dialogue stages allow assessing content
description skills and detecting cognitive impairment with Machine Learning
algorithms. We create these dialogue flows automatically from updated news
items using Natural Language Generation techniques. The system also infers the
gold standard of the answers to the questions, so it can assess cognitive
capabilities automatically by comparing these answers with the user responses.
It employs a similarity metric with values in [0, 1], in increasing level of
similarity. To evaluate the performance and usability of our approach, we have
conducted field tests with a test group of 30 elderly people in the earliest
stages of dementia, under the supervision of gerontologists. In the
experiments, we have analysed the effect of stress and concentration in these
users. Those without cognitive impairment performed up to five times better. In
particular, the similarity metric varied between 0.03, for stressed and
unfocused participants, and 0.36, for relaxed and focused users. Finally, we
developed a Machine Learning algorithm based on textual analysis features for
automatic cognitive impairment detection, which attained accuracy, F-measure
and recall levels above 80%. We have thus validated the automatic approach to
detect cognitive impairment in elderly people based on entertainment content.",2024-05-28,"Francisco de Arriba-Pérez, Silvia García-Méndez, Francisco J. González-Castaño, Enrique Costa-Montenegro",http://arxiv.org/pdf/2405.18542v1,cs.CL
Learning diverse attacks on large language models for robust red-teaming and safety tuning,"Red-teaming, or identifying prompts that elicit harmful responses, is a
critical step in ensuring the safe and responsible deployment of large language
models (LLMs). Developing effective protection against many modes of attack
prompts requires discovering diverse attacks. Automated red-teaming typically
uses reinforcement learning to fine-tune an attacker language model to generate
prompts that elicit undesirable responses from a target LLM, as measured, for
example, by an auxiliary toxicity classifier. We show that even with explicit
regularization to favor novelty and diversity, existing approaches suffer from
mode collapse or fail to generate effective attacks. As a flexible and
probabilistically principled alternative, we propose to use GFlowNet
fine-tuning, followed by a secondary smoothing phase, to train the attacker
model to generate diverse and effective attack prompts. We find that the
attacks generated by our method are effective against a wide range of target
LLMs, both with and without safety tuning, and transfer well between target
LLMs. Finally, we demonstrate that models safety-tuned using a dataset of
red-teaming prompts generated by our method are robust to attacks from other
RL-based red-teaming approaches.",2024-05-28,"Seanie Lee, Minsu Kim, Lynn Cherif, David Dobre, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi, Gauthier Gidel, Yoshua Bengio, Nikolay Malkin, Moksh Jain",http://arxiv.org/pdf/2405.18540v2,cs.CL
An Empirical Analysis on Large Language Models in Debate Evaluation,"In this study, we investigate the capabilities and inherent biases of
advanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context
of debate evaluation. We discover that LLM's performance exceeds humans and
surpasses the performance of state-of-the-art methods fine-tuned on extensive
datasets in debate evaluation. We additionally explore and analyze biases
present in LLMs, including positional bias, lexical bias, order bias, which may
affect their evaluative judgments. Our findings reveal a consistent bias in
both GPT-3.5 and GPT-4 towards the second candidate response presented,
attributed to prompt design. We also uncover lexical biases in both GPT-3.5 and
GPT-4, especially when label sets carry connotations such as numerical or
sequential, highlighting the critical need for careful label verbalizer
selection in prompt design. Additionally, our analysis indicates a tendency of
both models to favor the debate's concluding side as the winner, suggesting an
end-of-discussion bias.",2024-05-28,"Xinyi Liu, Pinxin Liu, Hangfeng He",http://arxiv.org/pdf/2406.00050v2,cs.CL
LLMs and Memorization: On Quality and Specificity of Copyright Compliance,"Memorization in large language models (LLMs) is a growing concern. LLMs have
been shown to easily reproduce parts of their training data, including
copyrighted work. This is an important problem to solve, as it may violate
existing copyright laws as well as the European AI Act. In this work, we
propose a systematic analysis to quantify the extent of potential copyright
infringements in LLMs using European law as an example. Unlike previous work,
we evaluate instruction-finetuned models in a realistic end-user scenario. Our
analysis builds on a proposed threshold of 160 characters, which we borrow from
the German Copyright Service Provider Act and a fuzzy text matching algorithm
to identify potentially copyright-infringing textual reproductions. The
specificity of countermeasures against copyright infringement is analyzed by
comparing model behavior on copyrighted and public domain data. We investigate
what behaviors models show instead of producing protected text (such as refusal
or hallucination) and provide a first legal assessment of these behaviors. We
find that there are huge differences in copyright compliance, specificity, and
appropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous
perform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing
a particularly low absolute number of potential copyright violations. Code can
be found at https://github.com/felixbmuller/llms-memorization-copyright.",2024-05-28,"Felix B Mueller, Rebekka Görge, Anna K Bernzen, Janna C Pirk, Maximilian Poretschkin",http://arxiv.org/pdf/2405.18492v3,cs.CL
Notes on Applicability of GPT-4 to Document Understanding,"We perform a missing, reproducible evaluation of all publicly available GPT-4
family models concerning the Document Understanding field, where it is
frequently required to comprehend text spacial arrangement and visual clues in
addition to textual semantics. Benchmark results indicate that though it is
hard to achieve satisfactory results with text-only models, GPT-4 Vision Turbo
performs well when one provides both text recognized by an external OCR engine
and document images on the input. Evaluation is followed by analyses that
suggest possible contamination of textual GPT-4 models and indicate the
significant performance drop for lengthy documents.",2024-05-28,Łukasz Borchmann,http://arxiv.org/pdf/2405.18433v1,cs.CL
Why are Visually-Grounded Language Models Bad at Image Classification?,"Image classification is one of the most fundamental capabilities of machine
vision intelligence. In this work, we revisit the image classification task
using visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We
find that existing proprietary and public VLMs, despite often using CLIP as a
vision encoder and having many more parameters, significantly underperform CLIP
on standard image classification benchmarks like ImageNet. To understand the
reason, we explore several hypotheses concerning the inference algorithms,
training objectives, and data processing in VLMs. Our analysis reveals that the
primary cause is data-related: critical information for image classification is
encoded in the VLM's latent space but can only be effectively decoded with
enough training data. Specifically, there is a strong correlation between the
frequency of class exposure during VLM training and instruction-tuning and the
VLM's performance in those classes; when trained with sufficient data, VLMs can
match the accuracy of state-of-the-art classification models. Based on these
findings, we enhance a VLM by integrating classification-focused datasets into
its training, and demonstrate that the enhanced classification performance of
the VLM transfers to its general capabilities, resulting in an improvement of
11.8% on the newly collected ImageWikiQA dataset.",2024-05-28,"Yuhui Zhang, Alyssa Unell, Xiaohan Wang, Dhruba Ghosh, Yuchang Su, Ludwig Schmidt, Serena Yeung-Levy",http://arxiv.org/pdf/2405.18415v2,cs.CL
Don't Forget to Connect! Improving RAG with Graph-based Reranking,"Retrieval Augmented Generation (RAG) has greatly improved the performance of
Large Language Model (LLM) responses by grounding generation with context from
existing documents. These systems work well when documents are clearly relevant
to a question context. But what about when a document has partial information,
or less obvious connections to the context? And how should we reason about
connections between documents? In this work, we seek to answer these two core
questions about RAG generation. We introduce G-RAG, a reranker based on graph
neural networks (GNNs) between the retriever and reader in RAG. Our method
combines both connections between documents and semantic information (via
Abstract Meaning Representation graphs) to provide a context-informed ranker
for RAG. G-RAG outperforms state-of-the-art approaches while having smaller
computational footprint. Additionally, we assess the performance of PaLM 2 as a
reranker and find it to significantly underperform G-RAG. This result
emphasizes the importance of reranking for RAG even when using Large Language
Models.",2024-05-28,"Jialin Dong, Bahare Fatemi, Bryan Perozzi, Lin F. Yang, Anton Tsitsulin",http://arxiv.org/pdf/2405.18414v1,cs.CL
RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives,"Recent video generative models primarily rely on carefully written text
prompts for specific tasks, like inpainting or style editing. They require
labor-intensive textual descriptions for input videos, hindering their
flexibility to adapt personal/raw videos to user specifications. This paper
proposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video
generative framework that supports multiple video editing capabilities such as
removal, addition, and modification, through a unified pipeline. RACCooN
consists of two principal stages: Video-to-Paragraph (V2P) and
Paragraph-to-Video (P2V). In the V2P stage, we automatically describe video
scenes in well-structured natural language, capturing both the holistic context
and focused object details. Subsequently, in the P2V stage, users can
optionally refine these descriptions to guide the video diffusion model,
enabling various modifications to the input video, such as removing, changing
subjects, and/or adding new objects. The proposed approach stands out from
other methods through several significant contributions: (1) RACCooN suggests a
multi-granular spatiotemporal pooling strategy to generate well-structured
video descriptions, capturing both the broad context and object details without
requiring complex human annotations, simplifying precise video content editing
based on text for users. (2) Our video generative model incorporates
auto-generated narratives or instructions to enhance the quality and accuracy
of the generated content. (3) RACCooN also plans to imagine new objects in a
given video, so users simply prompt the model to receive a detailed video
editing plan for complex video editing. The proposed framework demonstrates
impressive versatile capabilities in video-to-paragraph generation, video
content editing, and can be incorporated into other SoTA video generative
models for further enhancement.",2024-05-28,"Jaehong Yoon, Shoubin Yu, Mohit Bansal",http://arxiv.org/pdf/2405.18406v3,cs.CL
Superposed Decoding: Multiple Generations from a Single Autoregressive Inference Pass,"Many applications today provide users with multiple auto-complete drafts as
they type, including GitHub's code completion, Gmail's smart compose, and
Apple's messaging auto-suggestions. Under the hood, language models support
this by running an autoregressive inference pass to provide a draft.
Consequently, providing $k$ drafts to the user requires running an expensive
language model $k$ times. To alleviate the computation cost of running $k$
inference passes, we propose Superposed Decoding, a new decoding algorithm that
generates $k$ drafts at the computation cost of one autoregressive inference
pass. We achieve this by feeding a superposition of the most recent token
embeddings from the $k$ drafts as input to the next decoding step of the
language model. At every inference step we combine the $k$ drafts with the
top-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,
using an n-gram interpolation with minimal compute overhead to filter out
incoherent generations. Our experiments show that $k$ drafts from Superposed
Decoding are at least as coherent and factual as Nucleus Sampling and Greedy
Decoding respectively, while being at least $2.44\times$ faster for $k\ge3$. In
a compute-normalized setting, user evaluations demonstrably favor text
generated by Superposed Decoding over Nucleus Sampling. Superposed Decoding can
also be combined with other decoding strategies, resulting in universal
coverage gains when scaling inference time compute. Code and more examples
open-sourced at https://github.com/RAIVNLab/SuperposedDecoding.",2024-05-28,"Ethan Shen, Alan Fan, Sarah M. Pratt, Jae Sung Park, Matthew Wallingford, Sham M. Kakade, Ari Holtzman, Ranjay Krishna, Ali Farhadi, Aditya Kusupati",http://arxiv.org/pdf/2405.18400v6,cs.CL
QUEST: Quality-Aware Metropolis-Hastings Sampling for Machine Translation,"An important challenge in machine translation (MT) is to generate
high-quality and diverse translations. Prior work has shown that the estimated
likelihood from the MT model correlates poorly with translation quality. In
contrast, quality evaluation metrics (such as COMET or BLEURT) exhibit high
correlations with human judgments, which has motivated their use as rerankers
(such as quality-aware and minimum Bayes risk decoding). However, relying on a
single translation with high estimated quality increases the chances of ""gaming
the metric''. In this paper, we address the problem of sampling a set of
high-quality and diverse translations. We provide a simple and effective way to
avoid over-reliance on noisy quality estimates by using them as the energy
function of a Gibbs distribution. Instead of looking for a mode in the
distribution, we generate multiple samples from high-density areas through the
Metropolis-Hastings algorithm, a simple Markov chain Monte Carlo approach. The
results show that our proposed method leads to high-quality and diverse outputs
across multiple language pairs (English$\leftrightarrow${German, Russian}) with
two strong decoder-only LLMs (Alma-7b, Tower-7b).",2024-05-28,"Gonçalo R. A. Faria, Sweta Agrawal, António Farinhas, Ricardo Rei, José G. C. de Souza, André F. T. Martins",http://arxiv.org/pdf/2406.00049v2,cs.CL
OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning,"The rapid advancements in Large Language Models (LLMs) have revolutionized
various natural language processing tasks. However, the substantial size of
LLMs presents significant challenges in training or fine-tuning. While
parameter-efficient approaches such as low-rank adaptation (LoRA) have gained
popularity, they often compromise performance compared to full-rank
fine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled
Low-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,
inspired by the layerwise outlier distribution of LLMs. Unlike LoRA, which adds
extra adapters to all layers, OwLore strategically assigns higher sampling
probabilities to layers with more outliers, selectively sampling only a few
layers and fine-tuning their pre-trained weights. To further increase the
number of fine-tuned layers without a proportional rise in memory costs, we
incorporate gradient low-rank projection, further boosting the approach's
performance. Our extensive experiments across various architectures, including
LLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms
baseline approaches, including full fine-tuning. Specifically, it achieves up
to a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0%
improvement on MMLU, and a notable 10% boost on MT-Bench, while being more
memory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of
memory. Code is available at https://github.com/pixeli99/OwLore.",2024-05-28,"Pengxiang Li, Lu Yin, Xiaowei Gao, Shiwei Liu",http://arxiv.org/pdf/2405.18380v2,cs.CL
Thai Winograd Schemas: A Benchmark for Thai Commonsense Reasoning,"Commonsense reasoning is one of the important aspect of natural language
understanding, with several benchmarks developed to evaluate it. However, only
a few of these benchmarks are available in languages other than English.
Developing parallel benchmarks facilitates cross-lingual evaluation, enabling a
better understanding of different languages. This research introduces a
collection of Winograd Schemas in Thai, a novel dataset designed to evaluate
commonsense reasoning capabilities in the context of the Thai language.
  Through a methodology involving native speakers, professional translators,
and thorough validation, the schemas aim to closely reflect Thai language
nuances, idioms, and cultural references while maintaining ambiguity and
commonsense challenges. We evaluate the performance of popular large language
models on this benchmark, revealing their strengths, limitations, and providing
insights into the current state-of-the-art. Results indicate that while models
like GPT-4 and Claude-3-Opus achieve high accuracy in English, their
performance significantly drops in Thai, highlighting the need for further
advancements in multilingual commonsense reasoning.",2024-05-28,Phakphum Artkaew,http://arxiv.org/pdf/2405.18375v2,cs.CL
PromptWizard: Task-Aware Prompt Optimization Framework,"Large language models (LLMs) have transformed AI across diverse domains, with
prompting being central to their success in guiding model outputs. However,
manual prompt engineering is both labor-intensive and domain-specific,
necessitating the need for automated solutions. We introduce PromptWizard, a
novel, fully automated framework for discrete prompt optimization, utilizing a
self-evolving, self-adapting mechanism. Through a feedback-driven critique and
synthesis process, PromptWizard achieves an effective balance between
exploration and exploitation, iteratively refining both prompt instructions and
in-context examples to generate human-readable, task-specific prompts. This
guided approach systematically improves prompt quality, resulting in superior
performance across 45 tasks. PromptWizard excels even with limited training
data, smaller LLMs, and various LLM architectures. Additionally, our cost
analysis reveals a substantial reduction in API calls, token usage, and overall
cost, demonstrating PromptWizard's efficiency, scalability, and advantages over
existing prompt optimization strategies.",2024-05-28,"Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, Akshay Nambi",http://arxiv.org/pdf/2405.18369v2,cs.CL
Towards a theory of how the structure of language is acquired by deep neural networks,"How much data is required to learn the structure of a language via next-token
prediction? We study this question for synthetic datasets generated via a
Probabilistic Context-Free Grammar (PCFG) -- a tree-like generative model that
captures many of the hierarchical structures found in natural languages. We
determine token-token correlations analytically in our model and show that they
can be used to build a representation of the grammar's hidden variables, the
longer the range the deeper the variable. In addition, a finite training set
limits the resolution of correlations to an effective range, whose size grows
with that of the training set. As a result, a Language Model trained with
increasingly many examples can build a deeper representation of the grammar's
structure, thus reaching good performance despite the high dimensionality of
the problem. We conjecture that the relationship between training set size and
effective range of correlations holds beyond our synthetic datasets. In
particular, our conjecture predicts how the scaling law for the test loss
behaviour with training set size depends on the length of the context window,
which we confirm empirically in Shakespeare's plays and Wikipedia articles.",2024-05-28,"Francesco Cagnetta, Matthieu Wyart",http://arxiv.org/pdf/2406.00048v3,cs.CL
Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs,"Large language models (LLMs) are at the forefront of transforming numerous
domains globally. However, their inclusivity and effectiveness remain limited
for non-Latin scripts and low-resource languages. This paper tackles the
imperative challenge of enhancing the multilingual performance of LLMs without
extensive training or fine-tuning. Through systematic investigation and
evaluation of diverse languages using popular question-answering (QA) datasets,
we present novel techniques that unlock the true potential of LLMs in a
polyglot landscape. Our approach encompasses three key strategies that yield
significant improvements in multilingual proficiency. First, by meticulously
optimizing prompts tailored for polyglot LLMs, we unlock their latent
capabilities, resulting in substantial performance boosts across languages.
Second, we introduce a new hybrid approach that synergizes LLM Retrieval
Augmented Generation (RAG) with multilingual embeddings and achieves improved
multilingual task performance. Finally, we introduce a novel learning approach
that dynamically selects the optimal prompt strategy, LLM model, and embedding
model per query at run-time. This dynamic adaptation maximizes the efficacy of
LLMs across languages, outperforming best static and random strategies.
Additionally, our approach adapts configurations in both offline and online
settings, and can seamlessly adapt to new languages and datasets, leading to
substantial advancements in multilingual understanding and generation across
diverse languages.",2024-05-28,"Somnath Kumar, Vaibhav Balloli, Mercy Ranjit, Kabir Ahuja, Tanuja Ganu, Sunayana Sitaram, Kalika Bali, Akshay Nambi",http://arxiv.org/pdf/2405.18359v1,cs.CL
MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning,"Recent advancements in Multi-modal Large Language Models (MLLMs) have
significantly improved their performance in tasks combining vision and
language. However, challenges persist in detailed multi-modal understanding,
comprehension of complex tasks, and reasoning over multi-modal information.
This paper introduces MMCTAgent, a novel multi-modal critical thinking agent
framework designed to address the inherent limitations of current MLLMs in
complex visual reasoning tasks. Inspired by human cognitive processes and
critical thinking, MMCTAgent iteratively analyzes multi-modal information,
decomposes queries, plans strategies, and dynamically evolves its reasoning.
Additionally, MMCTAgent incorporates critical thinking elements such as
verification of final answers and self-reflection through a novel approach that
defines a vision-based critic and identifies task-specific evaluation criteria,
thereby enhancing its decision-making abilities. Through rigorous evaluations
across various image and video understanding benchmarks, we demonstrate that
MMCTAgent (with and without the critic) outperforms both foundational MLLMs and
other tool-augmented pipelines.",2024-05-28,"Somnath Kumar, Yash Gadhia, Tanuja Ganu, Akshay Nambi",http://arxiv.org/pdf/2405.18358v1,cs.CL
Faithful Logical Reasoning via Symbolic Chain-of-Thought,"While the recent Chain-of-Thought (CoT) technique enhances the reasoning
ability of large language models (LLMs) with the theory of mind, it might still
struggle in handling logical reasoning that relies much on symbolic expressions
and rigid deducing rules. To strengthen the logical reasoning capability of
LLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully
LLM-based framework that integrates symbolic expressions and logic rules with
CoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates
the natural language context into the symbolic format, and then 2) derives a
step-by-step plan to solve the problem with symbolic logical rules, 3) followed
by a verifier to check the translation and reasoning chain. Via thorough
evaluations on 5 standard datasets with both First-Order Logic and Constraint
Optimization symbolic expressions, SymbCoT shows striking improvements over the
CoT method consistently, meanwhile refreshing the current state-of-the-art
performances. We further demonstrate that our system advances in more faithful,
flexible, and explainable logical reasoning. To our knowledge, this is the
first to combine symbolic expressions and rules into CoT for logical reasoning
with LLMs. Code is open at https://github.com/Aiden0526/SymbCoT.",2024-05-28,"Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-Li Lee, Wynne Hsu",http://arxiv.org/pdf/2405.18357v2,cs.CL
A System for Automatic English Text Expansion,"We present an automatic text expansion system to generate English sentences,
which performs automatic Natural Language Generation (NLG) by combining
linguistic rules with statistical approaches. Here, ""automatic"" means that the
system can generate coherent and correct sentences from a minimum set of words.
From its inception, the design is modular and adaptable to other languages.
This adaptability is one of its greatest advantages. For English, we have
created the highly precise aLexiE lexicon with wide coverage, which represents
a contribution on its own. We have evaluated the resulting NLG library in an
Augmentative and Alternative Communication (AAC) proof of concept, both
directly (by regenerating corpus sentences) and manually (from annotations)
using a popular corpus in the NLG field. We performed a second analysis by
comparing the quality of text expansion in English to Spanish, using an ad-hoc
Spanish-English parallel corpus. The system might also be applied to other
domains such as report and news generation.",2024-05-28,"Silvia García Méndez, Milagros Fernández Gavilanes, Enrique Costa Montenegro, Jonathan Juncal Martínez, Francisco Javier González Castaño, Ehud Reiter",http://arxiv.org/pdf/2405.18350v1,cs.CL
Can Automatic Metrics Assess High-Quality Translations?,"Automatic metrics for evaluating translation quality are typically validated
by measuring how well they correlate with human assessments. However,
correlation methods tend to capture only the ability of metrics to
differentiate between good and bad source-translation pairs, overlooking their
reliability in distinguishing alternative translations for the same source. In
this paper, we confirm that this is indeed the case by showing that current
metrics are insensitive to nuanced differences in translation quality. This
effect is most pronounced when the quality is high and the variance among
alternatives is low. Given this finding, we shift towards detecting
high-quality correct translations, an important problem in practical
decision-making scenarios where a binary check of correctness is prioritized
over a nuanced evaluation of quality. Using the MQM framework as the gold
standard, we systematically stress-test the ability of current metrics to
identify translations with no errors as marked by humans. Our findings reveal
that current metrics often over or underestimate translation quality,
indicating significant room for improvement in automatic evaluation methods.",2024-05-28,"Sweta Agrawal, António Farinhas, Ricardo Rei, André F. T. Martins",http://arxiv.org/pdf/2405.18348v2,cs.CL
The Battle of LLMs: A Comparative Study in Conversational QA Tasks,"Large language models have gained considerable interest for their impressive
performance on various tasks. Within this domain, ChatGPT and GPT-4, developed
by OpenAI, and the Gemini, developed by Google, have emerged as particularly
popular among early adopters. Additionally, Mixtral by Mistral AI and Claude by
Anthropic are newly released, further expanding the landscape of advanced
language models. These models are viewed as disruptive technologies with
applications spanning customer service, education, healthcare, and finance.
More recently, Mistral has entered the scene, captivating users with its unique
ability to generate creative content. Understanding the perspectives of these
users is crucial, as they can offer valuable insights into the potential
strengths, weaknesses, and overall success or failure of these technologies in
various domains. This research delves into the responses generated by ChatGPT,
GPT-4, Gemini, Mixtral and Claude across different Conversational QA corpora.
Evaluation scores were meticulously computed and subsequently compared to
ascertain the overall performance of these models. Our study pinpointed
instances where these models provided inaccurate answers to questions, offering
insights into potential areas where they might be susceptible to errors. In
essence, this research provides a comprehensive comparison and evaluation of
these state of-the-art language models, shedding light on their capabilities
while also highlighting potential areas for improvement",2024-05-28,"Aryan Rangapur, Aman Rangapur",http://arxiv.org/pdf/2405.18344v1,cs.CL
Interpretable classification of wiki-review streams,"Wiki articles are created and maintained by a crowd of editors, producing a
continuous stream of reviews. Reviews can take the form of additions, reverts,
or both. This crowdsourcing model is exposed to manipulation since neither
reviews nor editors are automatically screened and purged. To protect articles
against vandalism or damage, the stream of reviews can be mined to classify
reviews and profile editors in real-time. The goal of this work is to
anticipate and explain which reviews to revert. This way, editors are informed
why their edits will be reverted. The proposed method employs stream-based
processing, updating the profiling and classification models on each incoming
event. The profiling uses side and content-based features employing Natural
Language Processing, and editor profiles are incrementally updated based on
their reviews. Since the proposed method relies on self-explainable
classification algorithms, it is possible to understand why a review has been
classified as a revert or a non-revert. In addition, this work contributes an
algorithm for generating synthetic data for class balancing, making the final
classification fairer. The proposed online method was tested with a real data
set from Wikivoyage, which was balanced through the aforementioned synthetic
data generation. The results attained near-90 % values for all evaluation
metrics (accuracy, precision, recall, and F-measure).",2024-05-28,"Silvia García Méndez, Fátima Leal, Benedita Malheiro, Juan Carlos Burguillo Rial",http://arxiv.org/pdf/2405.18335v1,cs.CL
Self-Supervised Learning Based Handwriting Verification,"We present SSL-HV: Self-Supervised Learning approaches applied to the task of
Handwriting Verification. This task involves determining whether a given pair
of handwritten images originate from the same or different writer distribution.
We have compared the performance of multiple generative, contrastive SSL
approaches against handcrafted feature extractors and supervised learning on
CEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)
outperforms other generative approaches achieving 76.3% accuracy, while
ResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization
(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Using
a pre-trained VAE and VICReg for the downstream task of writer verification we
observed a relative improvement in accuracy of 6.7% and 9% over ResNet-18
supervised baseline with 10% writer labels.",2024-05-28,"Mihir Chauhan, Mohammad Abuzar Hashemi, Abhishek Satbhai, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari",http://arxiv.org/pdf/2405.18320v2,cs.CL
Joint Lemmatization and Morphological Tagging with LEMMING,"We present LEMMING, a modular log-linear model that jointly models
lemmatization and tagging and supports the integration of arbitrary global
features. It is trainable on corpora annotated with gold standard tags and
lemmata and does not rely on morphological dictionaries or analyzers. LEMMING
sets the new state of the art in token-based statistical lemmatization on six
languages; e.g., for Czech lemmatization, we reduce the error by 60%, from 4.05
to 1.58. We also give empirical evidence that jointly modeling morphological
tags and lemmata is mutually beneficial.",2024-05-28,"Thomas Muller, Ryan Cotterell, Alexander Fraser, Hinrich Schütze",http://arxiv.org/pdf/2405.18308v1,cs.CL
Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning,"Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of
Large Language Models (LLMs) to various downstream applications. However, the
effectiveness of the PEFT diminishes notably when downstream tasks require
accurate learning of factual knowledge. In this paper, we adopt a semantic
perspective to investigate this phenomenon, uncovering the reasons behind
PEFT's limitations in knowledge learning task. Our findings reveal that: (1)
PEFT presents a notable risk of pushing the model away from the intended
knowledge target; (2) multiple knowledge interfere with each other, and such
interference suppresses the learning and expression of knowledge features.
Based on these insights, we introduce a data filtering strategy to exclude data
that is detrimental to knowledge learning and a re-weighted learning strategy
to make the model attentive to semantic distance during knowledge learning.
Experimental results demonstrate the effectiveness of the proposed method on
open-source large language model, further validate the semantic challenge in
PEFT, thus paving the way for future research.",2024-05-28,"Renzhi Wang, Piji Li",http://arxiv.org/pdf/2405.18292v1,cs.CL
Text-only Synthesis for Image Captioning,"From paired image-text training to text-only training for image captioning,
the pursuit of relaxing the requirements for high-cost and large-scale
annotation of good quality data remains consistent. In this paper, we propose
Text-only Synthesis for Image Captioning (ToCa), which further advances this
relaxation with fewer human labor and less computing time. Specifically, we
deconstruct caption text into structures and lexical words, which serve as the
fundamental components of the caption. By combining different structures and
lexical words as inputs to the large language model, massive captions that
contain various patterns of lexical words are generated. This method not only
approaches the target domain but also surpasses it by generating new captions,
thereby enhancing the zero-shot generalization ability of the model.
Considering the different levels of data access in the real world, we define
three synthesis scenarios: cross-domain synthesis, in-domain synthesis, and
data-efficient synthesis. Experiments in these scenarios demonstrate the
generalizability, transferability and practicability of ToCa with a nearly 5
CIDEr improvement for zero-shot cross-domain captioning and a maximum increase
of over 20 CIDEr for data-efficient captioning.",2024-05-28,"Qing Zhou, Junlin Huang, Qiang Li, Junyu Gao, Qi Wang",http://arxiv.org/pdf/2405.18258v1,cs.CL
Active Use of Latent Constituency Representation in both Humans and Large Language Models,"Understanding how sentences are internally represented in the human brain, as
well as in large language models (LLMs) such as ChatGPT, is a major challenge
for cognitive science. Classic linguistic theories propose that the brain
represents a sentence by parsing it into hierarchically organized constituents.
In contrast, LLMs do not explicitly parse linguistic constituents and their
latent representations remains poorly explained. Here, we demonstrate that
humans and LLMs construct similar latent representations of hierarchical
linguistic constituents by analyzing their behaviors during a novel one-shot
learning task, in which they infer which words should be deleted from a
sentence. Both humans and LLMs tend to delete a constituent, instead of a
nonconstituent word string. In contrast, a naive sequence processing model that
has access to word properties and ordinal positions does not show this
property. Based on the word deletion behaviors, we can reconstruct the latent
constituency tree representation of a sentence for both humans and LLMs. These
results demonstrate that a latent tree-structured constituency representation
can emerge in both the human brain and LLMs.",2024-05-28,"Wei Liu, Ming Xiang, Nai Ding",http://arxiv.org/pdf/2405.18241v1,cs.CL
A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models,"Recent studies have highlighted their proficiency in some simple tasks like
writing and coding through various reasoning strategies. However, LLM agents
still struggle with tasks that require comprehensive planning, a process that
challenges current models and remains a critical research issue. In this study,
we concentrate on travel planning, a Multi-Phases planning problem, that
involves multiple interconnected stages, such as outlining, information
gathering, and planning, often characterized by the need to manage various
constraints and uncertainties. Existing reasoning approaches have struggled to
effectively address this complex task. Our research aims to address this
challenge by developing a human-like planning framework for LLM agents, i.e.,
guiding the LLM agent to simulate various steps that humans take when solving
Multi-Phases problems. Specifically, we implement several strategies to enable
LLM agents to generate a coherent outline for each travel query, mirroring
human planning patterns. Additionally, we integrate Strategy Block and
Knowledge Block into our framework: Strategy Block facilitates information
collection, while Knowledge Block provides essential information for detailed
planning. Through our extensive experiments, we demonstrate that our framework
significantly improves the planning capabilities of LLM agents, enabling them
to tackle the travel planning task with improved efficiency and effectiveness.
Our experimental results showcase the exceptional performance of the proposed
framework; when combined with GPT-4-Turbo, it attains $10\times$ the
performance gains in comparison to the baseline framework deployed on
GPT-4-Turbo.",2024-05-28,"Chengxing Xie, Difan Zou",http://arxiv.org/pdf/2405.18208v1,cs.CL
IAPT: Instruction-Aware Prompt Tuning for Large Language Models,"Soft prompt tuning is a widely studied parameter-efficient fine-tuning
method. However, it has a clear drawback: many soft tokens must be inserted
into the input sequences to guarantee downstream performance. As a result, soft
prompt tuning is less considered than Low-rank adaptation (LoRA) in the large
language modeling (LLM) era. In this work, we propose a novel prompt tuning
method, Instruction-Aware Prompt Tuning (IAPT), that requires only four soft
tokens. First, we install a parameter-efficient soft prompt generator at each
Transformer layer to generate idiosyncratic soft prompts for each input
instruction. The generated soft prompts can be seen as a semantic summary of
the input instructions and can effectively guide the output generation. Second,
the soft prompt generators are modules with a bottleneck architecture
consisting of a self-attention pooling operation, two linear projections, and
an activation function. Pilot experiments show that prompt generators at
different Transformer layers require different activation functions. Thus, we
propose to learn the idiosyncratic activation functions for prompt generators
automatically with the help of rational functions. We have conducted
experiments on various tasks, and the experimental results demonstrate that (a)
our IAPT method can outperform the recent baselines with comparable tunable
parameters. (b) Our IAPT method is more efficient than LoRA under the
single-backbone multi-tenant setting.",2024-05-28,"Wei Zhu, Aaron Xuxiang Tian, Congrui Yin, Yuan Ni, Xiaoling Wang, Guotong Xie",http://arxiv.org/pdf/2405.18203v2,cs.CL
Hate Speech Detection with Generalizable Target-aware Fairness,"To counter the side effect brought by the proliferation of social media
platforms, hate speech detection (HSD) plays a vital role in halting the
dissemination of toxic online posts at an early stage. However, given the
ubiquitous topical communities on social media, a trained HSD classifier easily
becomes biased towards specific targeted groups (e.g., female and black
people), where a high rate of false positive/negative results can significantly
impair public trust in the fairness of content moderation mechanisms, and
eventually harm the diversity of online society. Although existing
fairness-aware HSD methods can smooth out some discrepancies across targeted
groups, they are mostly specific to a narrow selection of targets that are
assumed to be known and fixed. This inevitably prevents those methods from
generalizing to real-world use cases where new targeted groups constantly
emerge over time. To tackle this defect, we propose Generalizable target-aware
Fairness (GetFair), a new method for fairly classifying each post that contains
diverse and even unseen targets during inference. To remove the HSD
classifier's spurious dependence on target-related features, GetFair trains a
series of filter functions in an adversarial pipeline, so as to deceive the
discriminator that recovers the targeted group from filtered post embeddings.
To maintain scalability and generalizability, we innovatively parameterize all
filter functions via a hypernetwork that is regularized by the semantic
affinity among targets. Taking a target's pretrained word embedding as input,
the hypernetwork generates the weights used by each target-specific filter
on-the-fly without storing dedicated filter parameters. Finally, comparative
experiments on two HSD datasets have shown advantageous performance of GetFair
on out-of-sample targets.",2024-05-28,"Tong Chen, Danny Wang, Xurong Liang, Marten Risius, Gianluca Demartini, Hongzhi Yin",http://arxiv.org/pdf/2406.00046v2,cs.CL
Mashee at SemEval-2024 Task 8: The Impact of Samples Quality on the Performance of In-Context Learning for Machine Text Classification,"Within few-shot learning, in-context learning (ICL) has become a potential
method for leveraging contextual information to improve model performance on
small amounts of data or in resource-constrained environments where training
models on large datasets is prohibitive. However, the quality of the selected
sample in a few shots severely limits the usefulness of ICL. The primary goal
of this paper is to enhance the performance of evaluation metrics for
in-context learning by selecting high-quality samples in few-shot learning
scenarios. We employ the chi-square test to identify high-quality samples and
compare the results with those obtained using low-quality samples. Our findings
demonstrate that utilizing high-quality samples leads to improved performance
with respect to all evaluated metrics.",2024-05-28,"Areeg Fahad Rasheed, M. Zarkoosh",http://arxiv.org/pdf/2406.17790v1,cs.CL
The Knesset Corpus: An Annotated Corpus of Hebrew Parliamentary Proceedings,"We present the Knesset Corpus, a corpus of Hebrew parliamentary proceedings
containing over 30 million sentences (over 384 million tokens) from all the
(plenary and committee) protocols held in the Israeli parliament between 1998
and 2022. Sentences are annotated with morpho-syntactic information and are
associated with detailed meta-information reflecting demographic and political
properties of the speakers, based on a large database of parliament members and
factions that we compiled. We discuss the structure and composition of the
corpus and the various processing steps we applied to it. To demonstrate the
utility of this novel dataset we present two use cases. We show that the corpus
can be used to examine historical developments in the style of political
discussions by showing a reduction in lexical richness in the proceedings over
time. We also investigate some differences between the styles of men and women
speakers. These use cases exemplify the potential of the corpus to shed light
on important trends in the Israeli society, supporting research in linguistics,
political science, communication, law, etc.",2024-05-28,"Gili Goldin, Nick Howell, Noam Ordan, Ella Rabinovich, Shuly Wintner",http://arxiv.org/pdf/2405.18115v1,cs.CL
Facilitating Multi-Role and Multi-Behavior Collaboration of Large Language Models for Online Job Seeking and Recruiting,"The emergence of online recruitment services has revolutionized the
traditional landscape of job seeking and recruitment, necessitating the
development of high-quality industrial applications to improve person-job
fitting. Existing methods generally rely on modeling the latent semantics of
resumes and job descriptions and learning a matching function between them.
Inspired by the powerful role-playing capabilities of Large Language Models
(LLMs), we propose to introduce a mock interview process between LLM-played
interviewers and candidates. The mock interview conversations can provide
additional evidence for candidate evaluation, thereby augmenting traditional
person-job fitting based solely on resumes and job descriptions. However,
characterizing these two roles in online recruitment still presents several
challenges, such as developing the skills to raise interview questions,
formulating appropriate answers, and evaluating two-sided fitness. To this end,
we propose MockLLM, a novel applicable framework that divides the person-job
matching process into two modules: mock interview generation and two-sided
evaluation in handshake protocol, jointly enhancing their performance through
collaborative behaviors between interviewers and candidates. We design a
role-playing framework as a multi-role and multi-behavior paradigm to enable a
single LLM agent to effectively behave with multiple functions for both
parties. Moreover, we propose reflection memory generation and dynamic prompt
modification techniques to refine the behaviors of both sides, enabling
continuous optimization of the augmented additional evidence. Extensive
experimental results show that MockLLM can achieve the best performance on
person-job matching accompanied by high mock interview quality, envisioning its
emerging application in real online recruitment in the future.",2024-05-28,"Hongda Sun, Hongzhan Lin, Haiyu Yan, Chen Zhu, Yang Song, Xin Gao, Shuo Shang, Rui Yan",http://arxiv.org/pdf/2405.18113v1,cs.CL
ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented Generator,"Large language models (LLMs) are proven to benefit a lot from
retrieval-augmented generation (RAG) in alleviating hallucinations confronted
with knowledge-intensive questions. RAG adopts information retrieval techniques
to inject external knowledge from semantic-relevant documents as input
contexts. However, since today's Internet is flooded with numerous noisy and
fabricating content, it is inevitable that RAG systems are vulnerable to these
noises and prone to respond incorrectly. To this end, we propose to optimize
the retrieval-augmented Generator with an Adversarial Tuning Multi-agent system
(ATM). The ATM steers the Generator to have a robust perspective of useful
documents for question answering with the help of an auxiliary Attacker agent
through adversarially tuning the agents for several iterations. After rounds of
multi-agent iterative tuning, the Generator can eventually better discriminate
useful documents amongst fabrications. The experimental results verify the
effectiveness of ATM and we also observe that the Generator can achieve better
performance compared to the state-of-the-art baselines.",2024-05-28,"Junda Zhu, Lingyong Yan, Haibo Shi, Dawei Yin, Lei Sha",http://arxiv.org/pdf/2405.18111v3,cs.CL
Context is Important in Depressive Language: A Study of the Interaction Between the Sentiments and Linguistic Markers in Reddit Discussions,"Research exploring linguistic markers in individuals with depression has
demonstrated that language usage can serve as an indicator of mental health.
This study investigates the impact of discussion topic as context on linguistic
markers and emotional expression in depression, using a Reddit dataset to
explore interaction effects. Contrary to common findings, our sentiment
analysis revealed a broader range of emotional intensity in depressed
individuals, with both higher negative and positive sentiments than controls.
This pattern was driven by posts containing no emotion words, revealing the
limitations of the lexicon based approaches in capturing the full emotional
context. We observed several interesting results demonstrating the importance
of contextual analyses. For instance, the use of 1st person singular pronouns
and words related to anger and sadness correlated with increased positive
sentiments, whereas a higher rate of present-focused words was associated with
more negative sentiments. Our findings highlight the importance of discussion
contexts while interpreting the language used in depression, revealing that the
emotional intensity and meaning of linguistic markers can vary based on the
topic of discussion.",2024-05-28,"Neha Sharma, Kairit Sirts",http://arxiv.org/pdf/2405.18061v2,cs.CL
PRFashion24: A Dataset for Sentiment Analysis of Fashion Products Reviews in Persian,"The PRFashion24 dataset is a comprehensive Persian dataset collected from
various online fashion stores, spanning from April 2020 to March 2024. With
767,272 reviews, it is the first dataset in its kind that encompasses diverse
categories within the fashion industry in the Persian language. The goal of
this study is to harness deep learning techniques, specifically Long Short-Term
Memory (LSTM) networks and a combination of Bidirectional LSTM and
Convolutional Neural Network (BiLSTM-CNN), to analyze and reveal sentiments
towards online fashion shopping. The LSTM model yielded an accuracy of 81.23%,
while the BiLSTM-CNN model reached 82.89%. This research aims not only to
introduce a diverse dataset in the field of fashion but also to enhance the
public's understanding of opinions on online fashion shopping, which
predominantly reflect a positive sentiment. Upon publication, both the
optimized models and the PRFashion24 dataset will be available on GitHub.",2024-05-28,"Mehrimah Amirpour, Reza Azmi",http://arxiv.org/pdf/2405.18060v1,cs.CL
Spanish and LLM Benchmarks: is MMLU Lost in Translation?,"The evaluation of Large Language Models (LLMs) is a key element in their
continuous improvement process and many benchmarks have been developed to
assess the performance of LLMs in different tasks and topics. As LLMs become
adopted worldwide, evaluating them in languages other than English is
increasingly important. However, most LLM benchmarks are simply translated
using an automated tool and then run in the target language. This means that
the results depend not only on the LLM performance in that language but also on
the quality of the translation. In this paper, we consider the case of the
well-known Massive Multitask Language Understanding (MMLU) benchmark. Selected
categories of the benchmark are translated into Spanish using Azure Translator
and ChatGPT4 and run on ChatGPT4. Next, the results are processed to identify
the test items that produce different answers in Spanish and English. Those are
then analyzed manually to understand if the automatic translation caused the
change. The results show that a significant fraction of the failing items can
be attributed to mistakes in the translation of the benchmark. These results
make a strong case for improving benchmarks in languages other than English by
at least revising the translations of the items and preferably by adapting the
tests to the target language by experts.",2024-05-28,"Irene Plaza, Nina Melero, Cristina del Pozo, Javier Conde, Pedro Reviriego, Marina Mayor-Rocher, María Grandury",http://arxiv.org/pdf/2406.17789v1,cs.CL
Instruction Tuning with Retrieval-based Examples Ranking for Aspect-based Sentiment Analysis,"Aspect-based sentiment analysis (ABSA) identifies sentiment information
related to specific aspects and provides deeper market insights to businesses
and organizations. With the emergence of large language models (LMs), recent
studies have proposed using fixed examples for instruction tuning to
reformulate ABSA as a generation task. However, the performance is sensitive to
the selection of in-context examples; several retrieval methods are based on
surface similarity and are independent of the LM generative objective. This
study proposes an instruction learning method with retrieval-based example
ranking for ABSA tasks. For each target sample, an LM was applied as a scorer
to estimate the likelihood of the output given the input and a candidate
example as the prompt, and training examples were labeled as positive or
negative by ranking the scores. An alternating training schema is proposed to
train both the retriever and LM. Instructional prompts can be constructed using
high-quality examples. The LM is used for both scoring and inference, improving
the generation efficiency without incurring additional computational costs or
training difficulties. Extensive experiments on three ABSA subtasks verified
the effectiveness of the proposed method, demonstrating its superiority over
various strong baseline models. Code and data are released at
https://github.com/zgMin/IT-RER-ABSA.",2024-05-28,"Guangmin Zheng, Jin Wang, Liang-Chih Yu, Xuejie Zhang",http://arxiv.org/pdf/2405.18035v2,cs.CL
Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints,"The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language
Models (LLMs) to identify and correct medical errors in clinical notes. In this
study, we evaluate the capability of general LLMs, specifically GPT-3.5 and
GPT-4, to identify and correct medical errors with multiple prompting
strategies. Recognising the limitation of LLMs in generating accurate
corrections only via prompting strategies, we propose incorporating error-span
predictions from a smaller, fine-tuned model in two ways: 1) by presenting it
as a hint in the prompt and 2) by framing it as multiple-choice questions from
which the LLM can choose the best correction. We found that our proposed
prompting strategies significantly improve the LLM's ability to generate
corrections. Our best-performing solution with 8-shot + CoT + hints ranked
sixth in the shared task leaderboard. Additionally, our comprehensive analyses
show the impact of the location of the error sentence, the prompted role, and
the position of the multiple-choice option on the accuracy of the LLM. This
prompts further questions about the readiness of LLM to be implemented in
real-world clinical settings.",2024-05-28,"Aryo Pradipta Gema, Chaeeun Lee, Pasquale Minervini, Luke Daines, T. Ian Simpson, Beatrice Alex",http://arxiv.org/pdf/2405.18028v1,cs.CL
TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models,"While Large Language Models (LLMs) can serve as agents to simulate human
behaviors (i.e., role-playing agents), we emphasize the importance of
point-in-time role-playing. This situates characters at specific moments in the
narrative progression for three main reasons: (i) enhancing users' narrative
immersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom
role-playing. To accurately represent characters at specific time points,
agents must avoid character hallucination, where they display knowledge that
contradicts their characters' identities and historical timelines. We introduce
TimeChara, a new benchmark designed to evaluate point-in-time character
hallucination in role-playing LLMs. Comprising 10,895 instances generated
through an automated pipeline, this benchmark reveals significant hallucination
issues in current state-of-the-art LLMs (e.g., GPT-4o). To counter this
challenge, we propose Narrative-Experts, a method that decomposes the reasoning
steps and utilizes narrative experts to reduce point-in-time character
hallucinations effectively. Still, our findings with TimeChara highlight the
ongoing challenges of point-in-time character hallucination, calling for
further study.",2024-05-28,"Jaewoo Ahn, Taehyun Lee, Junyoung Lim, Jin-Hwa Kim, Sangdoo Yun, Hwaran Lee, Gunhee Kim",http://arxiv.org/pdf/2405.18027v1,cs.CL
MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction,"Active adverse event surveillance monitors Adverse Drug Events (ADE) from
different data sources, such as electronic health records, medical literature,
social media and search engine logs. Over the years, many datasets have been
created, and shared tasks have been organised to facilitate active adverse
event surveillance. However, most - if not all - datasets or shared tasks focus
on extracting ADEs from a particular type of text. Domain generalisation - the
ability of a machine learning model to perform well on new, unseen domains
(text types) - is under-explored. Given the rapid advancements in natural
language processing, one unanswered question is how far we are from having a
single ADE extraction model that is effective on various types of text, such as
scientific literature and social media posts. We contribute to answering this
question by building a multi-domain benchmark for adverse drug event
extraction, which we named MultiADE. The new benchmark comprises several
existing datasets sampled from different text types and our newly created
dataset - CADECv2, which is an extension of CADEC, covering online posts
regarding more diverse drugs than CADEC. Our new dataset is carefully annotated
by human annotators following detailed annotation guidelines. Our benchmark
results show that the generalisation of the trained models is far from perfect,
making it infeasible to be deployed to process different types of text. In
addition, although intermediate transfer learning is a promising approach to
utilising existing resources, further investigation is needed on methods of
domain adaptation, particularly cost-effective methods to select useful
training instances. The newly created CADECv2 and the scripts for building the
benchmark are publicly available at CSIRO's Data Portal.",2024-05-28,"Xiang Dai, Sarvnaz Karimi, Abeed Sarker, Ben Hachey, Cecile Paris",http://arxiv.org/pdf/2405.18015v2,cs.CL
Exploring Context Window of Large Language Models via Decomposed Positional Vectors,"Transformer-based large language models (LLMs) typically have a limited
context window, resulting in significant performance degradation when
processing text beyond the length of the context window. Extensive studies have
been proposed to extend the context window and achieve length extrapolation of
LLMs, but there is still a lack of in-depth interpretation of these approaches.
In this study, we explore the positional information within and beyond the
context window for deciphering the underlying mechanism of LLMs. By using a
mean-based decomposition method, we disentangle positional vectors from hidden
states of LLMs and analyze their formation and effect on attention.
Furthermore, when texts exceed the context window, we analyze the change of
positional vectors in two settings, i.e., direct extrapolation and context
window extension. Based on our findings, we design two training-free context
window extension methods, positional vector replacement and attention window
extension. Experimental results show that our methods can effectively extend
the context window length.",2024-05-28,"Zican Dong, Junyi Li, Xin Men, Wayne Xin Zhao, Bingbing Wang, Zhen Tian, Weipeng Chen, Ji-Rong Wen",http://arxiv.org/pdf/2405.18009v2,cs.CL
"Source Echo Chamber: Exploring the Escalation of Source Bias in User, Data, and Recommender System Feedback Loop","Recently, researchers have uncovered that neural retrieval models prefer
AI-generated content (AIGC), called source bias. Compared to active search
behavior, recommendation represents another important means of information
acquisition, where users are more prone to source bias. Furthermore, delving
into the recommendation scenario, as AIGC becomes integrated within the
feedback loop involving users, data, and the recommender system, it
progressively contaminates the candidate items, the user interaction history,
and ultimately, the data used to train the recommendation models. How and to
what extent the source bias affects the neural recommendation models within
feedback loop remains unknown. In this study, we extend the investigation of
source bias into the realm of recommender systems, specifically examining its
impact across different phases of the feedback loop. We conceptualize the
progression of AIGC integration into the recommendation content ecosystem in
three distinct phases-HGC dominate, HGC-AIGC coexist, and AIGC dominance-each
representing past, present, and future states, respectively. Through extensive
experiments across three datasets from diverse domains, we demonstrate the
prevalence of source bias and reveal a potential digital echo chamber with
source bias amplification throughout the feedback loop. This trend risks
creating a recommender ecosystem with limited information source, such as AIGC,
being disproportionately recommended. To counteract this bias and prevent its
escalation in the feedback loop, we introduce a black-box debiasing method that
maintains model impartiality towards both HGC and AIGC. Our experimental
results validate the effectiveness of the proposed debiasing method, confirming
its potential to disrupt the feedback loop.",2024-05-28,"Yuqi Zhou, Sunhao Dai, Liang Pang, Gang Wang, Zhenhua Dong, Jun Xu, Ji-Rong Wen",http://arxiv.org/pdf/2405.17998v1,cs.CL
fMRI predictors based on language models of increasing complexity recover brain left lateralization,"Over the past decade, studies of naturalistic language processing where
participants are scanned while listening to continuous text have flourished.
Using word embeddings at first, then large language models, researchers have
created encoding models to analyze the brain signals. Presenting these models
with the same text as the participants allows to identify brain areas where
there is a significant correlation between the functional magnetic resonance
imaging (fMRI) time series and the ones predicted by the models' artificial
neurons. One intriguing finding from these studies is that they have revealed
highly symmetric bilateral activation patterns, somewhat at odds with the
well-known left lateralization of language processing. Here, we report analyses
of an fMRI dataset where we manipulate the complexity of large language models,
testing 28 pretrained models from 8 different families, ranging from 124M to
14.2B parameters. First, we observe that the performance of models in
predicting brain responses follows a scaling law, where the fit with brain
activity increases linearly with the logarithm of the number of parameters of
the model (and its performance on natural language processing tasks). Second,
although this effect is present in both hemispheres, it is stronger in the left
than in the right hemisphere. Specifically, the left-right difference in brain
correlation follows a scaling law with the number of parameters. This finding
reconciles computational analyses of brain activity using large language models
with the classic observation from aphasic patients showing left hemisphere
dominance for language.",2024-05-28,"Laurent Bonnasse-Gahot, Christophe Pallier",http://arxiv.org/pdf/2405.17992v2,cs.CL
Peering into the Mind of Language Models: An Approach for Attribution in Contextual Question Answering,"With the enhancement in the field of generative artificial intelligence (AI),
contextual question answering has become extremely relevant. Attributing model
generations to the input source document is essential to ensure trustworthiness
and reliability. We observe that when large language models (LLMs) are used for
contextual question answering, the output answer often consists of text copied
verbatim from the input prompt which is linked together with ""glue text""
generated by the LLM. Motivated by this, we propose that LLMs have an inherent
awareness from where the text was copied, likely captured in the hidden states
of the LLM. We introduce a novel method for attribution in contextual question
answering, leveraging the hidden state representations of LLMs. Our approach
bypasses the need for extensive model retraining and retrieval model overhead,
offering granular attributions and preserving the quality of generated answers.
Our experimental results demonstrate that our method performs on par or better
than GPT-4 at identifying verbatim copied segments in LLM generations and in
attributing these segments to their source. Importantly, our method shows
robust performance across various LLM architectures, highlighting its broad
applicability. Additionally, we present Verifiability-granular, an attribution
dataset which has token level annotations for LLM generations in the contextual
question answering setup.",2024-05-28,"Anirudh Phukan, Shwetha Somasundaram, Apoorv Saxena, Koustava Goswami, Balaji Vasan Srinivasan",http://arxiv.org/pdf/2405.17980v1,cs.CL
"FASTopic: Pretrained Transformer is a Fast, Adaptive, Stable, and Transferable Topic Model","Topic models have been evolving rapidly over the years, from conventional to
recent neural models. However, existing topic models generally struggle with
either effectiveness, efficiency, or stability, highly impeding their practical
applications. In this paper, we propose FASTopic, a fast, adaptive, stable, and
transferable topic model. FASTopic follows a new paradigm: Dual
Semantic-relation Reconstruction (DSR). Instead of previous conventional,
VAE-based, or clustering-based methods, DSR directly models the semantic
relations among document embeddings from a pretrained Transformer and learnable
topic and word embeddings. By reconstructing through these semantic relations,
DSR discovers latent topics. This brings about a neat and efficient topic
modeling framework. We further propose a novel Embedding Transport Plan (ETP)
method. Rather than early straightforward approaches, ETP explicitly
regularizes the semantic relations as optimal transport plans. This addresses
the relation bias issue and thus leads to effective topic modeling. Extensive
experiments on benchmark datasets demonstrate that our FASTopic shows superior
effectiveness, efficiency, adaptivity, stability, and transferability, compared
to state-of-the-art baselines across various scenarios.",2024-05-28,"Xiaobao Wu, Thong Nguyen, Delvin Ce Zhang, William Yang Wang, Anh Tuan Luu",http://arxiv.org/pdf/2405.17978v2,cs.CL
Aligning to Thousands of Preferences via System Message Generalization,"Although humans inherently have diverse values, current large language model
(LLM) alignment methods often assume that aligning LLMs with the general
public's preferences is optimal. A major challenge in adopting a more
individualized approach to LLM alignment is its lack of scalability, as it
involves repeatedly acquiring preference data and training new reward models
and LLMs for each individual's preferences. To address these challenges, we
propose a new paradigm where users specify what they value most within the
system message, steering the LLM's generation behavior to better align with the
user's intentions. However, a naive application of such an approach is
non-trivial since LLMs are typically trained on a uniform system message (e.g.,
""You are a helpful assistant"") which limits their ability to generalize to
diverse, unseen system messages. To improve this generalization, we create the
Multifaceted Collection, a preference dataset with 192k combinations of values
beyond generic helpfulness and harmlessness, spanning 65k user instructions.
Using this dataset, we train a 7B LLM called Janus and test it on 921 prompts
from 5 benchmarks (AlpacaEval 2.0, FLASK, Koala, MT-Bench, and Self-Instruct)
by adding various unseen system messages that reflect user preferences. Janus
achieves tie+win rate of 75.2%, 72.4%, and 66.4% against Mistral 7B Instruct
v0.2, GPT-3.5 Turbo, and GPT-4, respectively. Unexpectedly, on three benchmarks
focused on response helpfulness (AlpacaEval 2.0, MT-Bench, Arena Hard Auto
v0.1), Janus also outperforms LLaMA 3 8B Instruct by a +4.0%, +0.1%, +3.0%
margin, underscoring that training with a vast array of system messages could
also enhance alignment to the general public's preference as well. Our code,
dataset, benchmark, and models are available at
https://github.com/kaistAI/Janus.",2024-05-28,"Seongyun Lee, Sue Hyun Park, Seungone Kim, Minjoon Seo",http://arxiv.org/pdf/2405.17977v2,cs.CL
Yuan 2.0-M32: Mixture of Experts with Attention Router,"Yuan 2.0-M32, with a similar base architecture as Yuan-2.0 2B, uses a
mixture-of-experts architecture with 32 experts of which 2 experts are active.
A new router network, Attention Router, is proposed and adopted for a more
efficient selection of experts, which improves the accuracy compared to the
model with classical router network. Yuan 2.0-M32 is trained with 2000B tokens
from scratch, and the training computation consumption is only 9.25% of a dense
model at the same parameter scale. Yuan 2.0-M32 demonstrates competitive
capability on coding, math, and various domains of expertise, with only 3.7B
active parameters of 40B in total, and 7.4 GFlops forward computation per
token, both of which are only 1/19 of Llama3-70B. Yuan 2.0-M32 surpass
Llama3-70B on MATH and ARC-Challenge benchmark, with accuracy of 55.89 and 95.8
respectively. The models and source codes of Yuan 2.0-M32 are released at
Github1.",2024-05-28,"Shaohua Wu, Jiangang Luo, Xi Chen, Lingjun Li, Xudong Zhao, Tong Yu, Chao Wang, Yue Wang, Fei Wang, Weixu Qiao, Houbo He, Zeru Zhang, Zeyu Sun, Junxiong Mao, Chong Shen",http://arxiv.org/pdf/2405.17976v2,cs.CL
"Recent Trends in Personalized Dialogue Generation: A Review of Datasets, Methodologies, and Evaluations","Enhancing user engagement through personalization in conversational agents
has gained significance, especially with the advent of large language models
that generate fluent responses. Personalized dialogue generation, however, is
multifaceted and varies in its definition -- ranging from instilling a persona
in the agent to capturing users' explicit and implicit cues. This paper seeks
to systemically survey the recent landscape of personalized dialogue
generation, including the datasets employed, methodologies developed, and
evaluation metrics applied. Covering 22 datasets, we highlight benchmark
datasets and newer ones enriched with additional features. We further analyze
17 seminal works from top conferences between 2021-2023 and identify five
distinct types of problems. We also shed light on recent progress by LLMs in
personalized dialogue generation. Our evaluation section offers a comprehensive
summary of assessment facets and metrics utilized in these works. In
conclusion, we discuss prevailing challenges and envision prospect directions
for future research in personalized dialogue generation.",2024-05-28,"Yi-Pei Chen, Noriki Nishida, Hideki Nakayama, Yuji Matsumoto",http://arxiv.org/pdf/2405.17974v1,cs.CL
Knowledge Circuits in Pretrained Transformers,"The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, have allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuits hold
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.",2024-05-28,"Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen",http://arxiv.org/pdf/2405.17969v4,cs.CL
Transformer and Hybrid Deep Learning Based Models for Machine-Generated Text Detection,"This paper describes the approach of the UniBuc - NLP team in tackling the
SemEval 2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box
Machine-Generated Text Detection. We explored transformer-based and hybrid deep
learning architectures. For subtask B, our transformer-based model achieved a
strong \textbf{second-place} out of $77$ teams with an accuracy of
\textbf{86.95\%}, demonstrating the architecture's suitability for this task.
However, our models showed overfitting in subtask A which could potentially be
fixed with less fine-tunning and increasing maximum sequence length. For
subtask C (token-level classification), our hybrid model overfit during
training, hindering its ability to detect transitions between human and
machine-generated text.",2024-05-28,"Teodor-George Marchitan, Claudiu Creanga, Liviu P. Dinu",http://arxiv.org/pdf/2405.17964v1,cs.CL
Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking Contrastive Learning and Unassociated Word Exclusion,"Dynamic topic models track the evolution of topics in sequential documents,
which have derived various applications like trend analysis and opinion mining.
However, existing models suffer from repetitive topic and unassociated topic
issues, failing to reveal the evolution and hindering further applications. To
address these issues, we break the tradition of simply chaining topics in
existing work and propose a novel neural \modelfullname. We introduce a new
evolution-tracking contrastive learning method that builds the similarity
relations among dynamic topics. This not only tracks topic evolution but also
maintains topic diversity, mitigating the repetitive topic issue. To avoid
unassociated topics, we further present an unassociated word exclusion method
that consistently excludes unassociated words from discovered topics. Extensive
experiments demonstrate our model significantly outperforms state-of-the-art
baselines, tracking topic evolution with high-quality topics, showing better
performance on downstream tasks, and remaining robust to the hyperparameter for
evolution intensities. Our code is available at https://github.com/bobxwu/CFDTM .",2024-05-28,"Xiaobao Wu, Xinshuai Dong, Liangming Pan, Thong Nguyen, Anh Tuan Luu",http://arxiv.org/pdf/2405.17957v1,cs.CL
Tool Learning with Large Language Models: A Survey,"Recently, tool learning with large language models (LLMs) has emerged as a
promising paradigm for augmenting the capabilities of LLMs to tackle highly
complex problems. Despite growing attention and rapid advancements in this
field, the existing literature remains fragmented and lacks systematic
organization, posing barriers to entry for newcomers. This gap motivates us to
conduct a comprehensive survey of existing works on tool learning with LLMs. In
this survey, we focus on reviewing existing literature from the two primary
aspects (1) why tool learning is beneficial and (2) how tool learning is
implemented, enabling a comprehensive understanding of tool learning with LLMs.
We first explore the ""why"" by reviewing both the benefits of tool integration
and the inherent benefits of the tool learning paradigm from six specific
aspects. In terms of ""how"", we systematically review the literature according
to a taxonomy of four key stages in the tool learning workflow: task planning,
tool selection, tool calling, and response generation. Additionally, we provide
a detailed summary of existing benchmarks and evaluation methods, categorizing
them according to their relevance to different stages. Finally, we discuss
current challenges and outline potential future directions, aiming to inspire
both researchers and industrial developers to further explore this emerging and
promising area. We also maintain a GitHub repository to continually keep track
of the relevant papers and resources in this rising area at
https://github.com/quchangle1/LLM-Tool-Survey.",2024-05-28,"Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen",http://arxiv.org/pdf/2405.17935v3,cs.CL
Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment,"Effectively aligning Large Language Models (LLMs) with human-centric values
while preventing the degradation of abilities acquired through Pre-training and
Supervised Fine-tuning (SFT) poses a central challenge in Reinforcement
Learning from Human Feedback (RLHF). In this paper, we first discover that
interpolating RLHF and SFT model parameters can adjust the trade-off between
human preference and basic capabilities, thereby reducing the alignment tax at
the cost of alignment reward. Inspired by this, we propose integrating the RL
policy and SFT models at each optimization step in RLHF to continuously
regulate the training direction, introducing the Online Merging Optimizer.
Specifically, we merge gradients with the parameter differences between SFT and
pretrained models, effectively steering the gradient towards maximizing rewards
in the direction of SFT optimization. We demonstrate that our optimizer works
well with different LLM families, such as Qwen and LLaMA, across various model
sizes ranging from 1.8B to 8B, various RLHF algorithms like DPO and KTO, and
existing model merging methods. It significantly enhances alignment reward
while mitigating alignment tax, achieving higher overall performance across 14
benchmarks.",2024-05-28,"Keming Lu, Bowen Yu, Fei Huang, Yang Fan, Runji Lin, Chang Zhou",http://arxiv.org/pdf/2405.17931v1,cs.CL
The Evolution of Multimodal Model Architectures,"This work uniquely identifies and characterizes four prevalent multimodal
model architectural patterns in the contemporary multimodal landscape.
Systematically categorizing models by architecture type facilitates monitoring
of developments in the multimodal domain. Distinct from recent survey papers
that present general information on multimodal architectures, this research
conducts a comprehensive exploration of architectural details and identifies
four specific architectural types. The types are distinguished by their
respective methodologies for integrating multimodal inputs into the deep neural
network model. The first two types (Type A and B) deeply fuses multimodal
inputs within the internal layers of the model, whereas the following two types
(Type C and D) facilitate early fusion at the input stage. Type-A employs
standard cross-attention, whereas Type-B utilizes custom-designed layers for
modality fusion within the internal layers. On the other hand, Type-C utilizes
modality-specific encoders, while Type-D leverages tokenizers to process the
modalities at the model's input stage. The identified architecture types aid
the monitoring of any-to-any multimodal model development. Notably, Type-C and
Type-D are currently favored in the construction of any-to-any multimodal
models. Type-C, distinguished by its non-tokenizing multimodal model
architecture, is emerging as a viable alternative to Type-D, which utilizes
input-tokenizing techniques. To assist in model selection, this work highlights
the advantages and disadvantages of each architecture type based on data and
compute requirements, architecture complexity, scalability, simplification of
adding modalities, training objectives, and any-to-any multimodal generation
capability.",2024-05-28,"Shakti N. Wadekar, Abhishek Chaurasia, Aman Chadha, Eugenio Culurciello",http://arxiv.org/pdf/2405.17927v1,cs.CL
Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models,"Long-context modeling capabilities are important for large language models
(LLMs) in various applications. However, directly training LLMs with long
context windows is insufficient to enhance this capability since some training
samples do not exhibit strong semantic dependencies across long contexts. In
this study, we propose a data mining framework \textbf{ProLong} that can assign
each training sample with a long dependency score, which can be used to rank
and filter samples that are more advantageous for enhancing long-context
modeling abilities in LLM training. Specifically, we first use delta perplexity
scores to measure the \textit{Dependency Strength} between text segments in a
given document. Then we refine this metric based on the \textit{Dependency
Distance} of these segments to incorporate spatial relationships across
long-contexts. Final results are calibrated with a \textit{Dependency
Specificity} metric to prevent trivial dependencies introduced by repetitive
patterns. Moreover, a random sampling approach is proposed to optimize the
computational efficiency of ProLong. Comprehensive experiments on multiple
benchmarks indicate that ProLong effectively identifies documents that carry
long dependencies and LLMs trained on these documents exhibit significantly
enhanced long-context modeling capabilities.",2024-05-28,"Longze Chen, Ziqiang Liu, Wanwei He, Yunshui Li, Run Luo, Min Yang",http://arxiv.org/pdf/2405.17915v1,cs.CL
Boosting Protein Language Models with Negative Sample Mining,"We introduce a pioneering methodology for boosting large language models in
the domain of protein representation learning. Our primary contribution lies in
the refinement process for correlating the over-reliance on co-evolution
knowledge, in a way that networks are trained to distill invaluable insights
from negative samples, constituted by protein pairs sourced from disparate
categories. By capitalizing on this novel approach, our technique steers the
training of transformer-based models within the attention score space. This
advanced strategy not only amplifies performance but also reflects the nuanced
biological behaviors exhibited by proteins, offering aligned evidence with
traditional biological mechanisms such as protein-protein interaction. We
experimentally observed improved performance on various tasks over datasets, on
top of several well-established large protein models. This innovative paradigm
opens up promising horizons for further progress in the realms of protein
research and computational biology.",2024-05-28,"Yaoyao Xu, Xinjian Zhao, Xiaozhuang Song, Benyou Wang, Tianshu Yu",http://arxiv.org/pdf/2405.17902v2,cs.CL
Enhancing Emotion Recognition in Conversation through Emotional Cross-Modal Fusion and Inter-class Contrastive Learning,"The purpose of emotion recognition in conversation (ERC) is to identify the
emotion category of an utterance based on contextual information. Previous ERC
methods relied on simple connections for cross-modal fusion and ignored the
information differences between modalities, resulting in the model being unable
to focus on modality-specific emotional information. At the same time, the
shared information between modalities was not processed to generate emotions.
Information redundancy problem. To overcome these limitations, we propose a
cross-modal fusion emotion prediction network based on vector connections. The
network mainly includes two stages: the multi-modal feature fusion stage based
on connection vectors and the emotion classification stage based on fused
features. Furthermore, we design a supervised inter-class contrastive learning
module based on emotion labels. Experimental results confirm the effectiveness
of the proposed method, demonstrating excellent performance on the IEMOCAP and
MELD datasets.",2024-05-28,"Haoxiang Shi, Xulong Zhang, Ning Cheng, Yong Zhang, Jun Yu, Jing Xiao, Jianzong Wang",http://arxiv.org/pdf/2405.17900v1,cs.CL
Arithmetic Reasoning with LLM: Prolog Generation & Permutation,"Instructing large language models (LLMs) to solve elementary school math
problems has shown great success using Chain of Thought (CoT). However, the CoT
approach relies on an LLM to generate a sequence of arithmetic calculations
which can be prone to cascaded calculation errors. We hypothesize that an LLM
should focus on extracting predicates and generating symbolic formulas from the
math problem description so that the underlying calculation can be done via an
external code interpreter. We investigate using LLM to generate Prolog programs
to solve mathematical questions. Experimental results show that our
Prolog-based arithmetic problem-solving outperforms CoT generation in the GSM8K
benchmark across three distinct LLMs. In addition, given the insensitive
ordering of predicates and symbolic formulas in Prolog, we propose to permute
the ground truth predicates for more robust LLM training via data augmentation.",2024-05-28,"Xiaocheng Yang, Bingsen Chen, Yik-Cheung Tam",http://arxiv.org/pdf/2405.17893v1,cs.CL
SLMRec: Distilling Large Language Models into Small for Sequential Recommendation,"Sequential Recommendation (SR) task involves predicting the next item a user
is likely to interact with, given their past interactions. The SR models
examine the sequence of a user's actions to discern more complex behavioral
patterns and temporal dynamics. Recent research demonstrates the great impact
of LLMs on sequential recommendation systems, either viewing sequential
recommendation as language modeling or serving as the backbone for user
representation. Although these methods deliver outstanding performance, there
is scant evidence of the necessity of a large language model and how large the
language model is needed, especially in the sequential recommendation scene.
Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to
apply a LLM-based model in real-world platforms that often need to process
billions of traffic logs daily. In this paper, we explore the influence of
LLMs' depth by conducting extensive experiments on large-scale industry
datasets. Surprisingly, our motivational experiments reveal that most
intermediate layers of LLMs are redundant, indicating that pruning the
remaining layers can still maintain strong performance. Motivated by this
insight, we empower small language models for SR, namely SLMRec, which adopt a
simple yet effective knowledge distillation method. Moreover, SLMRec is
orthogonal to other post-training efficiency techniques, such as quantization
and pruning, so that they can be leveraged in combination. Comprehensive
experimental results illustrate that the proposed SLMRec model attains the best
performance using only 13% of the parameters found in LLM-based recommendation
models while simultaneously achieving up to 6.6x and 8.0x speedups in training
and inference time costs, respectively. Besides, we provide a theoretical
justification for why small language models can perform comparably to large
language models in SR.",2024-05-28,"Wujiang Xu, Qitian Wu, Zujie Liang, Jiaojiao Han, Xuying Ning, Yunxiao Shi, Wenfang Lin, Yongfeng Zhang",http://arxiv.org/pdf/2405.17890v4,cs.CL
Seeing the Image: Prioritizing Visual Correlation by Contrastive Alignment,"Existing image-text modality alignment in Vision Language Models (VLMs)
treats each text token equally in an autoregressive manner. Despite being
simple and effective, this method results in sub-optimal cross-modal alignment
by over-emphasizing the text tokens that are less correlated with or even
contradictory with the input images. In this paper, we advocate for assigning
distinct contributions for each text token based on its visual correlation.
Specifically, we present by contrasting image inputs, the difference in
prediction logits on each text token provides strong guidance of visual
correlation. We therefore introduce Contrastive ALignment (CAL), a simple yet
effective re-weighting strategy that prioritizes training visually correlated
tokens. Our experimental results demonstrate that CAL consistently improves
different types of VLMs across different resolutions and model sizes on various
benchmark datasets. Importantly, our method incurs minimal additional
computational overhead, rendering it highly efficient compared to alternative
data scaling strategies. Codes are available at
https://github.com/foundation-multimodal-models/CAL.",2024-05-28,"Xin Xiao, Bohong Wu, Jiacong Wang, Chunyuan Li, Xun Zhou, Haoyuan Guo",http://arxiv.org/pdf/2405.17871v2,cs.CL
I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit Large Language Models,"Post-training quantization (PTQ) serves as a potent technique to accelerate
the inference of large language models (LLMs). Nonetheless, existing works
still necessitate a considerable number of floating-point (FP) operations
during inference, including additional quantization and de-quantization, as
well as non-linear operators such as RMSNorm and Softmax. This limitation
hinders the deployment of LLMs on the edge and cloud devices. In this paper, we
identify the primary obstacle to integer-only quantization for LLMs lies in the
large fluctuation of activations across channels and tokens in both linear and
non-linear operations. To address this issue, we propose I-LLM, a novel
integer-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)
we develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smooth
inter-channel variations of all activations and weights. (2) to alleviate
degradation caused by inter-token variations, we introduce a novel approach
called Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamic
quantization in full-integer matrix multiplication by dynamically quantizing
the input and outputs with integer-only operations. (3) we design
DI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift to
execute non-linear operators efficiently while maintaining accuracy. The
experiment shows that our I-LLM achieves comparable accuracy to the FP baseline
and outperforms non-integer quantization methods. For example, I-LLM can
operate at W4A4 with negligible loss of accuracy. To our knowledge, we are the
first to bridge the gap between integer-only quantization and LLMs. We've
published our code on anonymous.4open.science, aiming to contribute to the
advancement of this field.",2024-05-28,"Xing Hu, Yuan Cheng, Dawei Yang, Zhihang Yuan, Jiangyong Yu, Chen Xu, Sifan Zhou",http://arxiv.org/pdf/2405.17849v2,cs.CL
Benchmarks Underestimate the Readiness of Multi-lingual Dialogue Agents,"Creating multilingual task-oriented dialogue (TOD) agents is challenging due
to the high cost of training data acquisition. Following the research trend of
improving training data efficiency, we show for the first time, that in-context
learning is sufficient to tackle multilingual TOD.
  To handle the challenging dialogue state tracking (DST) subtask, we break it
down to simpler steps that are more compatible with in-context learning where
only a handful of few-shot examples are used. We test our approach on the
multilingual TOD dataset X-RiSAWOZ, which has 12 domains in Chinese, English,
French, Korean, Hindi, and code-mixed Hindi-English. Our turn-by-turn DST
accuracy on the 6 languages range from 55.6% to 80.3%, seemingly worse than the
SOTA results from fine-tuned models that achieve from 60.7% to 82.8%; our BLEU
scores in the response generation (RG) subtask are also significantly lower
than SOTA.
  However, after manual evaluation of the validation set, we find that by
correcting gold label errors and improving dataset annotation schema, GPT-4
with our prompts can achieve (1) 89.6%-96.8% accuracy in DST, and (2) more than
99% correct response generation across different languages. This leads us to
conclude that current automatic metrics heavily underestimate the effectiveness
of in-context learning.",2024-05-28,"Andrew H. Lee, Sina J. Semnani, Galo Castillo-López, Gäel de Chalendar, Monojit Choudhury, Ashna Dua, Kapil Rajesh Kavitha, Sungkyun Kim, Prashant Kodali, Ponnurangam Kumaraguru, Alexis Lombard, Mehrad Moradshahi, Gihyun Park, Nasredine Semmar, Jiwon Seo, Tianhao Shen, Manish Shrivastava, Deyi Xiong, Monica S. Lam",http://arxiv.org/pdf/2405.17840v2,cs.CL
Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization,"Researchers have been studying approaches to steer the behavior of Large
Language Models (LLMs) and build personalized LLMs tailored for various
applications. While fine-tuning seems to be a direct solution, it requires
substantial computational resources and may significantly affect the utility of
the original LLM. Recent endeavors have introduced more lightweight strategies,
focusing on extracting ""steering vectors"" to guide the model's output toward
desired behaviors by adjusting activations within specific layers of the LLM's
transformer architecture. However, such steering vectors are directly extracted
from the activations of human preference data and thus often lead to suboptimal
results and occasional failures, especially in alignment-related scenarios.
This work proposes an innovative approach that could produce more effective
steering vectors through bi-directional preference optimization. Our method is
designed to allow steering vectors to directly influence the generation
probability of contrastive human preference data pairs, thereby offering a more
precise representation of the target behavior. By carefully adjusting the
direction and magnitude of the steering vector, we enabled personalized control
over the desired behavior across a spectrum of intensities. Extensive
experimentation across various open-ended generation tasks, particularly
focusing on steering AI personas, has validated the efficacy of our approach.
Moreover, we comprehensively investigate critical alignment-concerning
scenarios, such as managing truthfulness, mitigating hallucination, and
addressing jailbreaking attacks. Remarkably, our method can still demonstrate
outstanding steering effectiveness across these scenarios. Furthermore, we
showcase the transferability of our steering vectors across different
models/LoRAs and highlight the synergistic benefits of applying multiple
vectors simultaneously.",2024-05-28,"Yuanpu Cao, Tianrong Zhang, Bochuan Cao, Ziyi Yin, Lu Lin, Fenglong Ma, Jinghui Chen",http://arxiv.org/pdf/2406.00045v2,cs.CL
More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs,"The performance on general tasks decreases after Large Language Models (LLMs)
are fine-tuned on domain-specific tasks, the phenomenon is known as
Catastrophic Forgetting (CF). However, this paper presents a further challenge
for real application of domain-specific LLMs beyond CF, called General
Capabilities Integration (GCI), which necessitates the integration of both the
general capabilities and domain knowledge within a single instance. The
objective of GCI is not merely to retain previously acquired general
capabilities alongside new domain knowledge, but to harmonize and utilize both
sets of skills in a cohesive manner to enhance performance on domain-specific
tasks. Taking legal domain as an example, we carefully design three groups of
training and testing tasks without lacking practicability, and construct the
corresponding datasets. To better incorporate general capabilities across
domain-specific scenarios, we introduce ALoRA, which utilizes a multi-head
attention module upon LoRA, facilitating direct information transfer from
preceding tokens to the current one. This enhancement permits the
representation to dynamically switch between domain-specific knowledge and
general competencies according to the attention. Extensive experiments are
conducted on the proposed tasks. The results exhibit the significance of our
setting, and the effectiveness of our method.",2024-05-28,"Chengyuan Liu, Yangyang Kang, Shihang Wang, Lizhi Qing, Fubang Zhao, Changlong Sun, Kun Kuang, Fei Wu",http://arxiv.org/pdf/2405.17830v2,cs.CL
Conv-CoA: Improving Open-domain Question Answering in Large Language Models via Conversational Chain-of-Action,"We present a Conversational Chain-of-Action (Conv-CoA) framework for
Open-domain Conversational Question Answering (OCQA). Compared with literature,
Conv-CoA addresses three major challenges: (i) unfaithful hallucination that is
inconsistent with real-time or domain facts, (ii) weak reasoning performance in
conversational scenarios, and (iii) unsatisfying performance in conversational
information retrieval. Our key contribution is a dynamic reasoning-retrieval
mechanism that extracts the intent of the question and decomposes it into a
reasoning chain to be solved via systematic prompting, pre-designed actions,
updating the Contextual Knowledge Set (CKS), and a novel Hopfield-based
retriever. Methodologically, we propose a resource-efficiency Hopfield
retriever to enhance the efficiency and accuracy of conversational information
retrieval within our actions. Additionally, we propose a
conversational-multi-reference faith score (Conv-MRFS) to verify and resolve
conflicts between retrieved knowledge and answers in conversations.
Empirically, we conduct comparisons between our framework and 23
state-of-the-art methods across five different research directions and two
public benchmarks. These comparisons demonstrate that our Conv-CoA outperforms
other methods in both the accuracy and efficiency dimensions.",2024-05-28,"Zhenyu Pan, Haozheng Luo, Manling Li, Han Liu",http://arxiv.org/pdf/2405.17822v1,cs.CL
The Impossibility of Fair LLMs,"The need for fair AI is increasingly clear in the era of general-purpose
systems such as ChatGPT, Gemini, and other large language models (LLMs).
However, the increasing complexity of human-AI interaction and its social
impacts have raised questions of how fairness standards could be applied. Here,
we review the technical frameworks that machine learning researchers have used
to evaluate fairness, such as group fairness and fair representations, and find
that their application to LLMs faces inherent limitations. We show that each
framework either does not logically extend to LLMs or presents a notion of
fairness that is intractable for LLMs, primarily due to the multitudes of
populations affected, sensitive attributes, and use cases. To address these
challenges, we develop guidelines for the more realistic goal of achieving
fairness in particular use cases: the criticality of context, the
responsibility of LLM developers, and the need for stakeholder participation in
an iterative process of design and evaluation. Moreover, it may eventually be
possible and even necessary to use the general-purpose capabilities of AI
systems to address fairness challenges as a form of scalable AI-assisted
alignment.",2024-05-28,"Jacy Anthis, Kristian Lum, Michael Ekstrand, Avi Feller, Alexander D'Amour, Chenhao Tan",http://arxiv.org/pdf/2406.03198v1,cs.CL
Judgement Citation Retrieval using Contextual Similarity,"Traditionally in the domain of legal research, the retrieval of pertinent
citations from intricate case descriptions has demanded manual effort and
keyword-based search applications that mandate expertise in understanding legal
jargon. Legal case descriptions hold pivotal information for legal
professionals and researchers, necessitating more efficient and automated
approaches. We propose a methodology that combines natural language processing
(NLP) and machine learning techniques to enhance the organization and
utilization of legal case descriptions. This approach revolves around the
creation of textual embeddings with the help of state-of-art embedding models.
Our methodology addresses two primary objectives: unsupervised clustering and
supervised citation retrieval, both designed to automate the citation
extraction process. Although the proposed methodology can be used for any
dataset, we employed the Supreme Court of The United States (SCOTUS) dataset,
yielding remarkable results. Our methodology achieved an impressive accuracy
rate of 90.9%. By automating labor-intensive processes, we pave the way for a
more efficient, time-saving, and accessible landscape in legal research,
benefiting legal professionals, academics, and researchers.",2024-05-28,"Akshat Mohan Dasula, Hrushitha Tigulla, Preethika Bhukya",http://arxiv.org/pdf/2406.01609v2,cs.CL
TransVIP: Speech to Speech Translation System with Voice and Isochrony Preservation,"There is a rising interest and trend in research towards directly translating
speech from one language to another, known as end-to-end speech-to-speech
translation. However, most end-to-end models struggle to outperform cascade
models, i.e., a pipeline framework by concatenating speech recognition, machine
translation and text-to-speech models. The primary challenges stem from the
inherent complexities involved in direct translation tasks and the scarcity of
data. In this study, we introduce a novel model framework TransVIP that
leverages diverse datasets in a cascade fashion yet facilitates end-to-end
inference through joint probability. Furthermore, we propose two separated
encoders to preserve the speaker's voice characteristics and isochrony from the
source speech during the translation process, making it highly suitable for
scenarios such as video dubbing. Our experiments on the French-English language
pair demonstrate that our model outperforms the current state-of-the-art
speech-to-speech translation model.",2024-05-28,"Chenyang Le, Yao Qian, Dongmei Wang, Long Zhou, Shujie Liu, Xiaofei Wang, Midia Yousefi, Yanmin Qian, Jinyu Li, Sheng Zhao, Michael Zeng",http://arxiv.org/pdf/2405.17809v3,cs.CL
Detection-Correction Structure via General Language Model for Grammatical Error Correction,"Grammatical error correction (GEC) is a task dedicated to rectifying texts
with minimal edits, which can be decoupled into two components: detection and
correction. However, previous works have predominantly focused on direct
correction, with no prior efforts to integrate both into a single model.
Moreover, the exploration of the detection-correction paradigm by large
language models (LLMs) remains underdeveloped. This paper introduces an
integrated detection-correction structure, named DeCoGLM, based on the General
Language Model (GLM). The detection phase employs a fault-tolerant detection
template, while the correction phase leverages autoregressive mask infilling
for localized error correction. Through the strategic organization of input
tokens and modification of attention masks, we facilitate multi-task learning
within a single model. Our model demonstrates competitive performance against
the state-of-the-art models on English and Chinese GEC datasets. Further
experiments present the effectiveness of the detection-correction structure in
LLMs, suggesting a promising direction for GEC.",2024-05-28,"Wei Li, Houfeng Wang",http://arxiv.org/pdf/2405.17804v1,cs.CL
Exploring Activation Patterns of Parameters in Language Models,"Most work treats large language models as black boxes without in-depth
understanding of their internal working mechanism. In order to explain the
internal representations of LLMs, we propose a gradient-based metric to assess
the activation level of model parameters. Based on this metric, we obtain three
preliminary findings. (1) When the inputs are in the same domain, parameters in
the shallow layers will be activated densely, which means a larger portion of
parameters will have great impacts on the outputs. In contrast, parameters in
the deep layers are activated sparsely. (2) When the inputs are across
different domains, parameters in shallow layers exhibit higher similarity in
the activation behavior than deep layers. (3) In deep layers, the similarity of
the distributions of activated parameters is positively correlated to the
empirical data relevance. Further, we develop three validation experiments to
solidify these findings. (1) Firstly, starting from the first finding, we
attempt to configure different prune ratios for different layers, and find this
method can benefit model pruning. (2) Secondly, we find that a pruned model
based on one calibration set can better handle tasks related to the calibration
task than those not related, which validate the second finding. (3) Thirdly,
Based on the STS-B and SICK benchmark, we find that two sentences with
consistent semantics tend to share similar parameter activation patterns in
deep layers, which aligns with our third finding. Our work sheds light on the
behavior of parameter activation in LLMs, and we hope these findings will have
the potential to inspire more practical applications.",2024-05-28,"Yudong Wang, Damai Dai, Zhifang Sui",http://arxiv.org/pdf/2405.17799v1,cs.CL
Linguistic Collapse: Neural Collapse in (Large) Language Models,"Neural collapse ($\mathcal{NC}$) is a phenomenon observed in classification
tasks where top-layer representations collapse into their class means, which
become equinorm, equiangular and aligned with the classifiers. These behaviours
-- associated with generalization and robustness -- would manifest under
specific conditions: models are trained towards zero loss, with noise-free
labels belonging to balanced classes, which do not outnumber the model's hidden
dimension. Recent studies have explored $\mathcal{NC}$ in the absence of one or
more of these conditions to extend and capitalize on the associated benefits of
ideal geometries. Language modelling presents a curious frontier, as
\textit{training by token prediction} constitutes a classification task where
none of the conditions exist: the vocabulary is imbalanced and exceeds the
embedding dimension; different tokens might correspond to similar contextual
embeddings; and large language models (LLMs) in particular are typically only
trained for a few epochs. This paper empirically investigates the impact of
scaling the architectures and training of causal language models (CLMs) on
their progression towards $\mathcal{NC}$. We find that $\mathcal{NC}$
properties that develop with scale (and regularization) are linked to
generalization. Moreover, there is evidence of some relationship between
$\mathcal{NC}$ and generalization independent of scale. Our work thereby
underscores the generality of $\mathcal{NC}$ as it extends to the novel and
more challenging setting of language modelling. Downstream, we seek to inspire
further research on the phenomenon to deepen our understanding of LLMs -- and
neural networks at large -- and improve existing architectures based on
$\mathcal{NC}$-related properties. Our code is hosted on GitHub at
https://github.com/rhubarbwu/linguistic-collapse .",2024-05-28,"Robert Wu, Vardan Papyan",http://arxiv.org/pdf/2405.17767v3,cs.CL
On the Sequence Evaluation based on Stochastic Processes,"Generative models have gained significant prominence in Natural Language
Processing (NLP), especially in tackling the complex task of modeling and
evaluating long text sequences. This task is crucial for advancing various
downstream applications, such as text generation and machine translation.
Recent methods that utilize stochastic processes to capture the intrinsic
dynamics of sequences have shown superior performance in generative modeling.
However, the accurate encoding of both temporal and structural dependencies
from text datasets, as well as leveraging this encoded information for sequence
evaluation, remains an open area of research. In this paper, we propose a novel
approach to learn the stochastic dynamics of long text sequences, utilizing a
negative log-likelihood-based encoder that outperforms contrastive learning
methods. We also introduce a likelihood-based evaluation metric for long-text
assessment, which measures sequence coherence and can be applied to downstream
tasks such as Human-AI discrimination. Our encoder preserves sequence coherence
effectively and performs robustly on out-of-domain datasets. Additionally, the
proposed evaluation metric captures both temporal and structural information
comprehensively. Theoretical analysis demonstrates the superiority of our
metric in sequence evaluation, and experimental results highlight its
flexibility and exceptional performance across a variety of tasks, showcasing
its utility in diverse NLP applications.",2024-05-28,"Tianhao Zhang, Zhexiao Lin, Zhecheng Sheng, Chen Jiang, Dongyeop Kang",http://arxiv.org/pdf/2405.17764v3,cs.CL
XL3M: A Training-free Framework for LLM Length Extension Based on Segment-wise Inference,"Length generalization failure problem, namely the large language model (LLM)
fails to generalize to texts longer than its maximum training length, greatly
restricts the application of LLM in the scenarios with streaming long inputs.
To address this problem, the existing methods either require substantial costs
or introduce precision loss. In this paper, we empirically find that the
accuracy of the LLM's prediction is highly correlated to its certainty. Based
on this, we propose an efficient training free framework, named XL3M (it means
extra-long large language model), which enables the LLMs trained on short
sequences to reason extremely long sequence without any further training or
fine-tuning. Under the XL3M framework, the input context will be firstly
decomposed into multiple short sub-contexts, where each sub-context contains an
independent segment and a common ``question'' which is a few tokens from the
end of the original context. Then XL3M gives a method to measure the relevance
between each segment and the ``question'', and constructs a concise key context
by splicing all the relevant segments in chronological order. The key context
is further used instead of the original context to complete the inference task.
Evaluations on comprehensive benchmarks show the superiority of XL3M. Using our
framework, a Llama2-7B model is able to reason 20M long sequences on an 8-card
Huawei Ascend 910B NPU machine with 64GB memory per card.",2024-05-28,"Shengnan Wang, Youhui Bai, Lin Zhang, Pingyi Zhou, Shixiong Zhao, Gong Zhang, Sen Wang, Renhai Chen, Hua Xu, Hongwei Sun",http://arxiv.org/pdf/2405.17755v1,cs.CL
ORLM: A Customizable Framework in Training Large Models for Automated Optimization Modeling,"Optimization modeling plays a critical role in the application of Operations
Research (OR) tools to address real-world problems, yet they pose challenges
and require extensive expertise from OR experts. With the advent of large
language models (LLMs), new opportunities have emerged to streamline and
automate such task. However, current research predominantly relies on
closed-source LLMs such as GPT-4, along with extensive prompt engineering
techniques. This reliance stems from the scarcity of high-quality training
datasets for optimization modeling, resulting in elevated costs, prolonged
processing times, and privacy concerns. To address these challenges, our work
is the first to propose a viable path for training open-source LLMs that are
capable of optimization modeling and developing solver codes, eventually
leading to a superior ability for automating optimization modeling and solving.
Particularly, we design the {\sc OR-Instruct}, a semi-automated data synthesis
framework for optimization modeling that enables customizable enhancements for
specific scenarios or model types. This work also introduces IndustryOR, the
first industrial benchmark for evaluating LLMs in solving practical OR
problems. We train several 7B-scale open-source LLMs using synthesized data
(dubbed ORLMs{https://github.com/Cardinal-Operations/ORLM}), which exhibit
significantly enhanced optimization modeling capabilities, achieving
competitive performance across the NL4OPT, MAMO, and IndustryOR benchmarks.
Additionally, our experiments highlight the potential of scaling law and
reinforcement learning to further enhance the performance of ORLMs. The
workflows and human-machine interaction paradigms of ORLMs in practical
industrial applications are also discussed in the paper.",2024-05-28,"Chenyu Huang, Zhengyang Tang, Shixi Hu, Ruoqing Jiang, Xin Zheng, Dongdong Ge, Benyou Wang, Zizhuo Wang",http://arxiv.org/pdf/2405.17743v5,cs.CL
MobileConvRec: A Conversational Dataset for Mobile Apps Recommendations,"Existing recommendation systems have focused on two paradigms: 1- historical
user-item interaction-based recommendations and 2- conversational
recommendations. Conversational recommendation systems facilitate natural
language dialogues between users and the system, allowing the system to solicit
users' explicit needs while enabling users to inquire about recommendations and
provide feedback. Due to substantial advancements in natural language
processing, conversational recommendation systems have gained prominence.
Existing conversational recommendation datasets have greatly facilitated
research in their respective domains. Despite the exponential growth in mobile
users and apps in recent years, research in conversational mobile app
recommender systems has faced substantial constraints. This limitation can
primarily be attributed to the lack of high-quality benchmark datasets
specifically tailored for mobile apps. To facilitate research for
conversational mobile app recommendations, we introduce MobileConvRec.
MobileConvRec simulates conversations by leveraging real user interactions with
mobile apps on the Google Play store, originally captured in large-scale mobile
app recommendation dataset MobileRec. The proposed conversational
recommendation dataset synergizes sequential user-item interactions, which
reflect implicit user preferences, with comprehensive multi-turn conversations
to effectively grasp explicit user needs. MobileConvRec consists of over 12K
multi-turn recommendation-related conversations spanning 45 app categories.
Moreover, MobileConvRec presents rich metadata for each app such as permissions
data, security and privacy-related information, and binary executables of apps,
among others. We demonstrate that MobileConvRec can serve as an excellent
testbed for conversational mobile app recommendation through a comparative
study of several pre-trained large language models.",2024-05-28,"Srijata Maji, Moghis Fereidouni, Vinaik Chhetri, Umar Farooq, A. B. Siddique",http://arxiv.org/pdf/2405.17740v1,cs.CL
C$^{3}$Bench: A Comprehensive Classical Chinese Understanding Benchmark for Large Language Models,"Classical Chinese Understanding (CCU) holds significant value in preserving
and exploration of the outstanding traditional Chinese culture. Recently,
researchers have attempted to leverage the potential of Large Language Models
(LLMs) for CCU by capitalizing on their remarkable comprehension and semantic
capabilities. However, no comprehensive benchmark is available to assess the
CCU capabilities of LLMs. To fill this gap, this paper introduces C$^{3}$bench,
a Comprehensive Classical Chinese understanding benchmark, which comprises
50,000 text pairs for five primary CCU tasks, including classification,
retrieval, named entity recognition, punctuation, and translation. Furthermore,
the data in C$^{3}$bench originates from ten different domains, covering most
of the categories in classical Chinese. Leveraging the proposed C$^{3}$bench,
we extensively evaluate the quantitative performance of 15 representative LLMs
on all five CCU tasks. Our results not only establish a public leaderboard of
LLMs' CCU capabilities but also gain some findings. Specifically, existing LLMs
are struggle with CCU tasks and still inferior to supervised models.
Additionally, the results indicate that CCU is a task that requires special
attention. We believe this study could provide a standard benchmark,
comprehensive baselines, and valuable insights for the future advancement of
LLM-based CCU research. The evaluation pipeline and dataset are available at
\url{https://github.com/SCUT-DLVCLab/C3bench}.",2024-05-28,"Jiahuan Cao, Yongxin Shi, Dezhi Peng, Yang Liu, Lianwen Jin",http://arxiv.org/pdf/2405.17732v2,cs.CL
Multi-objective Representation for Numbers in Clinical Narratives: A CamemBERT-Bio-Based Alternative to Large-Scale LLMs,"The processing of numerical values is a rapidly developing area in the field
of Language Models (LLMs). Despite numerous advancements achieved by previous
research, significant challenges persist, particularly within the healthcare
domain. This paper investigates the limitations of Transformer models in
understanding numerical values. \textit{Objective:} this research aims to
categorize numerical values extracted from medical documents into eight
specific physiological categories using CamemBERT-bio. \textit{Methods:} In a
context where scalable methods and Large Language Models (LLMs) are emphasized,
we explore lifting the limitations of transformer-based models. We examine two
strategies: fine-tuning CamemBERT-bio on a small medical dataset, integrating
Label Embedding for Self-Attention (LESA), and combining LESA with additional
enhancement techniques such as Xval. Given that CamemBERT-bio is already
pre-trained on a large medical dataset, the first approach aims to update its
encoder with the newly added label embeddings technique. In contrast, the
second approach seeks to develop multiple representations of numbers
(contextual and magnitude-based) to achieve more robust number embeddings.
\textit{Results:} As anticipated, fine-tuning the standard CamemBERT-bio on our
small medical dataset did not improve F1 scores. However, significant
improvements were observed with CamemBERT-bio + LESA, resulting in an over 13\%
increase. Similar enhancements were noted when combining LESA with Xval,
outperforming conventional methods and giving comparable results to GPT-4
\textit{Conclusions and Novelty:} This study introduces two innovative
techniques for handling numerical data, which are also applicable to other
modalities. We illustrate how these techniques can improve the performance of
Transformer-based models, achieving more reliable classification results even
with small datasets.",2024-05-28,"Boammani Aser Lompo, Thanh-Dung Le",http://arxiv.org/pdf/2405.18448v3,cs.CL
A Context-Aware Approach for Enhancing Data Imputation with Pre-trained Language Models,"This paper presents a novel approach named \textbf{C}ontextually
\textbf{R}elevant \textbf{I}mputation leveraging pre-trained \textbf{L}anguage
\textbf{M}odels (\textbf{CRILM}) for handling missing data in tabular datasets.
Instead of relying on traditional numerical estimations, CRILM uses pre-trained
language models (LMs) to create contextually relevant descriptors for missing
values. This method aligns datasets with LMs' strengths, allowing large LMs to
generate these descriptors and small LMs to be fine-tuned on the enriched
datasets for enhanced downstream task performance. Our evaluations demonstrate
CRILM's superior performance and robustness across MCAR, MAR, and challenging
MNAR scenarios, with up to a 10\% improvement over the best-performing
baselines. By mitigating biases, particularly in MNAR settings, CRILM improves
downstream task performance and offers a cost-effective solution for
resource-constrained environments.",2024-05-28,"Ahatsham Hayat, Mohammad Rashedul Hasan",http://arxiv.org/pdf/2405.17712v2,cs.CL
Stochastic Adversarial Networks for Multi-Domain Text Classification,"Adversarial training has been instrumental in advancing multi-domain text
classification (MDTC). Traditionally, MDTC methods employ a shared-private
paradigm, with a shared feature extractor for domain-invariant knowledge and
individual private feature extractors for domain-specific knowledge. Despite
achieving state-of-the-art results, these methods grapple with the escalating
model parameters due to the continuous addition of new domains. To address this
challenge, we introduce the Stochastic Adversarial Network (SAN), which
innovatively models the parameters of the domain-specific feature extractor as
a multivariate Gaussian distribution, as opposed to a traditional weight
vector. This design allows for the generation of numerous domain-specific
feature extractors without a substantial increase in model parameters,
maintaining the model's size on par with that of a single domain-specific
extractor. Furthermore, our approach integrates domain label smoothing and
robust pseudo-label regularization to fortify the stability of adversarial
training and to refine feature discriminability, respectively. The performance
of our SAN, evaluated on two leading MDTC benchmarks, demonstrates its
competitive edge against the current state-of-the-art methodologies. The code
is available at https://github.com/wangxu0820/SAN.",2024-05-28,"Xu Wang, Yuan Wu",http://arxiv.org/pdf/2406.00044v1,cs.CL
Does Geo-co-location Matter? A Case Study of Public Health Conversations during COVID-19,"Social media platforms like Twitter (now X) have been pivotal in information
dissemination and public engagement, especially during COVID-19. A key goal for
public health experts was to encourage prosocial behavior that could impact
local outcomes such as masking and social distancing. Given the importance of
local news and guidance during COVID-19, the objective of our research is to
analyze the effect of localized engagement, on social media conversations. This
study examines the impact of geographic co-location, as a proxy for localized
engagement between public health experts (PHEs) and the public, on social
media. We analyze a Twitter conversation dataset from January 2020 to November
2021, comprising over 19 K tweets from nearly five hundred PHEs, along with
approximately 800 K replies from 350 K participants. Our findings reveal that
geo-co-location is associated with higher engagement rates, especially in
conversations on topics including masking, lockdowns, and education, and in
conversations with academic and medical professionals. Lexical features
associated with emotion and personal experiences were more common in
geo-co-located contexts. This research provides insights into how geographic
co-location influences social media engagement and can inform strategies to
improve public health messaging.",2024-05-28,"Paiheng Xu, Louiqa Raschid, Vanessa Frias-Martinez",http://arxiv.org/pdf/2405.17710v2,cs.CL
Mechanistic Interpretability of Binary and Ternary Transformers,"Recent research (arXiv:2310.11453, arXiv:2402.17764) has proposed binary and
ternary transformer networks as a way to significantly reduce memory and
improve inference speed in Large Language Models (LLMs) while maintaining
accuracy. In this work, we apply techniques from mechanistic interpretability
to investigate whether such networks learn distinctly different or similar
algorithms when compared to full-precision transformer networks. In particular,
we reverse engineer the algorithms learned for the toy problem of modular
addition where we find that binary and ternary networks learn similar
algorithms as full precision networks. This provides evidence against the
possibility of using binary and ternary networks as a more interpretable
alternative in the LLM setting.",2024-05-27,Jason Li,http://arxiv.org/pdf/2405.17703v1,cs.CL
"Generative Query Reformulation Using Ensemble Prompting, Document Fusion, and Relevance Feedback","Query Reformulation (QR) is a set of techniques used to transform a user's
original search query to a text that better aligns with the user's intent and
improves their search experience. Recently, zero-shot QR has been a promising
approach due to its ability to exploit knowledge inherent in large language
models. Inspired by the success of ensemble prompting strategies which have
benefited other tasks, we investigate if they can improve query reformulation.
In this context, we propose two ensemble-based prompting techniques,
GenQREnsemble and GenQRFusion which leverage paraphrases of a zero-shot
instruction to generate multiple sets of keywords to improve retrieval
performance ultimately. We further introduce their post-retrieval variants to
incorporate relevance feedback from a variety of sources, including an oracle
simulating a human user and a ""critic"" LLM. We demonstrate that an ensemble of
query reformulations can improve retrieval effectiveness by up to 18% on
nDCG@10 in pre-retrieval settings and 9% on post-retrieval settings on multiple
benchmarks, outperforming all previously reported SOTA results. We perform
subsequent analyses to investigate the effects of feedback documents,
incorporate domain-specific instructions, filter reformulations, and generate
fluent reformulations that might be more beneficial to human searchers.
Together, the techniques and the results presented in this paper establish a
new state of the art in automated query reformulation for retrieval and suggest
promising directions for future research.",2024-05-27,"Kaustubh D. Dhole, Ramraj Chandradevan, Eugene Agichtein",http://arxiv.org/pdf/2405.17658v1,cs.CL
InversionView: A General-Purpose Method for Reading Information from Neural Activations,"The inner workings of neural networks can be better understood if we can
fully decipher the information encoded in neural activations. In this paper, we
argue that this information is embodied by the subset of inputs that give rise
to similar activations. We propose InversionView, which allows us to
practically inspect this subset by sampling from a trained decoder model
conditioned on activations. This helps uncover the information content of
activation vectors, and facilitates understanding of the algorithms implemented
by transformer models. We present four case studies where we investigate models
ranging from small transformers to GPT-2. In these studies, we show that
InversionView can reveal clear information contained in activations, including
basic information about tokens appearing in the context, as well as more
complex information, such as the count of certain tokens, their relative
positions, and abstract knowledge about the subject. We also provide causally
verified circuits to confirm the decoded information.",2024-05-27,"Xinting Huang, Madhur Panwar, Navin Goyal, Michael Hahn",http://arxiv.org/pdf/2405.17653v4,cs.CL
Cross-Modal Safety Alignment: Is textual unlearning all you need?,"Recent studies reveal that integrating new modalities into Large Language
Models (LLMs), such as Vision-Language Models (VLMs), creates a new attack
surface that bypasses existing safety training techniques like Supervised
Fine-tuning (SFT) and Reinforcement Learning with Human Feedback (RLHF). While
further SFT and RLHF-based safety training can be conducted in multi-modal
settings, collecting multi-modal training datasets poses a significant
challenge. Inspired by the structural design of recent multi-modal models,
where, regardless of the combination of input modalities, all inputs are
ultimately fused into the language space, we aim to explore whether unlearning
solely in the textual domain can be effective for cross-modality safety
alignment. Our evaluation across six datasets empirically demonstrates the
transferability -- textual unlearning in VLMs significantly reduces the Attack
Success Rate (ASR) to less than 8\% and in some cases, even as low as nearly
2\% for both text-based and vision-text-based attacks, alongside preserving the
utility. Moreover, our experiments show that unlearning with a multi-modal
dataset offers no potential benefits but incurs significantly increased
computational demands, possibly up to 6 times higher.",2024-05-27,"Trishna Chakraborty, Erfan Shayegani, Zikui Cai, Nael Abu-Ghazaleh, M. Salman Asif, Yue Dong, Amit K. Roy-Chowdhury, Chengyu Song",http://arxiv.org/pdf/2406.02575v1,cs.CL
HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs,"Empathy serves as a cornerstone in enabling prosocial behaviors, and can be
evoked through sharing of personal experiences in stories. While empathy is
influenced by narrative content, intuitively, people respond to the way a story
is told as well, through narrative style. Yet the relationship between empathy
and narrative style is not fully understood. In this work, we empirically
examine and quantify this relationship between style and empathy using LLMs and
large-scale crowdsourcing studies. We introduce a novel, theory-based taxonomy,
HEART (Human Empathy and Narrative Taxonomy) that delineates elements of
narrative style that can lead to empathy with the narrator of a story. We
establish the performance of LLMs in extracting narrative elements from HEART,
showing that prompting with our taxonomy leads to reasonable, human-level
annotations beyond what prior lexicon-based methods can do. To show empirical
use of our taxonomy, we collect a dataset of empathy judgments of stories via a
large-scale crowdsourcing study with N=2,624 participants. We show that
narrative elements extracted via LLMs, in particular, vividness of emotions and
plot volume, can elucidate the pathways by which narrative style cultivates
empathy towards personal stories. Our work suggests that such models can be
used for narrative analyses that lead to human-centered social and behavioral
insights.",2024-05-27,"Jocelyn Shen, Joel Mire, Hae Won Park, Cynthia Breazeal, Maarten Sap",http://arxiv.org/pdf/2405.17633v2,cs.CL
Jointly Modeling Inter- & Intra-Modality Dependencies for Multi-modal Learning,"Supervised multi-modal learning involves mapping multiple modalities to a
target label. Previous studies in this field have concentrated on capturing in
isolation either the inter-modality dependencies (the relationships between
different modalities and the label) or the intra-modality dependencies (the
relationships within a single modality and the label). We argue that these
conventional approaches that rely solely on either inter- or intra-modality
dependencies may not be optimal in general. We view the multi-modal learning
problem from the lens of generative models where we consider the target as a
source of multiple modalities and the interaction between them. Towards that
end, we propose inter- & intra-modality modeling (I2M2) framework, which
captures and integrates both the inter- and intra-modality dependencies,
leading to more accurate predictions. We evaluate our approach using real-world
healthcare and vision-and-language datasets with state-of-the-art models,
demonstrating superior performance over traditional methods focusing only on
one type of modality dependency.",2024-05-27,"Divyam Madaan, Taro Makino, Sumit Chopra, Kyunghyun Cho",http://arxiv.org/pdf/2405.17613v2,cs.CL
Explainable machine learning multi-label classification of Spanish legal judgements,"Artificial Intelligence techniques such as Machine Learning (ML) have not
been exploited to their maximum potential in the legal domain. This has been
partially due to the insufficient explanations they provided about their
decisions. Automatic expert systems with explanatory capabilities can be
specially useful when legal practitioners search jurisprudence to gather
contextual knowledge for their cases. Therefore, we propose a hybrid system
that applies ML for multi-label classification of judgements (sentences) and
visual and natural language descriptions for explanation purposes, boosted by
Natural Language Processing techniques and deep legal reasoning to identify the
entities, such as the parties, involved. We are not aware of any prior work on
automatic multi-label classification of legal judgements also providing natural
language explanations to the end-users with comparable overall quality. Our
solution achieves over 85 % micro precision on a labelled data set annotated by
legal experts. This endorses its interest to relieve human experts from
monotonous labour-intensive legal classification tasks.",2024-05-27,"Francisco de Arriba-Pérez, Silvia García-Méndez, Francisco J. González-Castaño, Jaime González-González",http://arxiv.org/pdf/2405.17610v1,cs.CL
LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters,"The rapid expansion of large language models (LLMs) has underscored the need
for parameter-efficient fine-tuning methods, with LoRA (Low-Rank Adaptation)
emerging as a popular solution. Although LoRA reduces the number of trainable
parameters, serving multiple (task or user-specific) LoRA modules on top of a
base model still creates significant storage challenges. To address this, using
theoretical derivation, we introduce LoRA-XS (Low-Rank Adaptation with
eXtremely Small number of parameters), a novel low-rank adaptation method that
considerably reduces the trainable parameters while showing superior or
competitive performance. LoRA-XS achieves this by inserting a small, trainable
r x r weight matrix between frozen low-rank matrices, which are constructed by
Singular Value Decomposition (SVD) of the original weight matrix. This
lightweight matrix enables fine-tuning with drastically reduced storage
requirements, making it feasible to deploy millions of personalized models
while minimizing memory overhead. For instance, LoRA-XS achieves a remarkable
reduction of trainable parameters by over 100x in 7B models compared to LoRA.
Our evaluations across various benchmarks (including GLUE, GSM8K, MATH, and
eight commonsense reasoning datasets) demonstrate that LoRA-XS performs
competitively or better than LoRA and other recent methods like VeRA while
being significantly more parameter efficient. We also provide an extensive
ablation study on the importance of singular vectors in transformer weights,
shedding light on the underlying mechanisms driving LoRA-XS's enhanced
efficiency. These findings suggest that LoRA-XS is not only a storage-efficient
alternative, but also a powerful tool for scaling and personalizing LLMs at
unprecedented scales.",2024-05-27,"Klaudia Bałazy, Mohammadreza Banaei, Karl Aberer, Jacek Tabor",http://arxiv.org/pdf/2405.17604v2,cs.CL
RAGSys: Item-Cold-Start Recommender as RAG System,"Large Language Models (LLM) hold immense promise for real-world applications,
but their generic knowledge often falls short of domain-specific needs.
Fine-tuning, a common approach, can suffer from catastrophic forgetting and
hinder generalizability. In-Context Learning (ICL) offers an alternative, which
can leverage Retrieval-Augmented Generation (RAG) to provide LLMs with relevant
demonstrations for few-shot learning tasks. This paper explores the desired
qualities of a demonstration retrieval system for ICL. We argue that ICL
retrieval in this context resembles item-cold-start recommender systems,
prioritizing discovery and maximizing information gain over strict relevance.
We propose a novel evaluation method that measures the LLM's subsequent
performance on NLP tasks, eliminating the need for subjective diversity scores.
Our findings demonstrate the critical role of diversity and quality bias in
retrieved demonstrations for effective ICL, and highlight the potential of
recommender system techniques in this domain.",2024-05-27,"Emile Contal, Garrin McGoldrick",http://arxiv.org/pdf/2405.17587v2,cs.CL
Matryoshka Multimodal Models,"Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in
visual-linguistic reasoning. These models first embed images into a fixed large
number of visual tokens and then feed them into a Large Language Model (LLM).
However, this design causes an excessive number of tokens for dense visual
scenarios such as high-resolution images and videos, leading to great
inefficiency. While token pruning/merging methods do exist, they produce a
single length output for each image and do not afford flexibility in trading
off information density v.s. efficiency. Inspired by the concept of Matryoshka
Dolls, we propose M3: Matryoshka Multimodal Models, which learns to represent
visual content as nested sets of visual tokens that capture information across
multiple coarse-to-fine granularities. Our approach offers several unique
benefits for LMMs: (1) One can explicitly control the visual granularity per
test instance during inference, e.g. , adjusting the number of tokens used to
represent an image based on the anticipated complexity or simplicity of the
content; (2) M3 provides a framework for analyzing the granularity needed for
existing datasets, where we find that COCO-style benchmarks only need around ~9
visual tokens to obtain accuracy similar to that of using all 576 tokens; (3)
Our approach provides a foundation to explore the best trade-off between
performance and visual token length at sample level, where our investigation
reveals that a large gap exists between the oracle upper bound and current
fixed-scale representations.",2024-05-27,"Mu Cai, Jianwei Yang, Jianfeng Gao, Yong Jae Lee",http://arxiv.org/pdf/2405.17430v2,cs.CL
NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models,"Decoder-only LLM-based embedding models are beginning to outperform BERT or
T5-based embedding models in general-purpose text embedding tasks, including
dense vector-based retrieval. In this work, we introduce NV-Embed,
incorporating architectural designs, training procedures, and curated datasets
to significantly enhance the performance of LLM as a versatile embedding model,
while maintaining its simplicity and reproducibility. For model architecture,
we propose a latent attention layer to obtain pooled embeddings, which
consistently improves retrieval and downstream task accuracy compared to mean
pooling or using the last <EOS> token embedding from LLMs. To enhance
representation learning, we remove the causal attention mask of LLMs during
contrastive training. For training algorithm, we introduce a two-stage
contrastive instruction-tuning method. It first applies contrastive training
with instructions on retrieval datasets, utilizing in-batch negatives and
curated hard negative examples. At stage-2, it blends various non-retrieval
into instruction tuning, which not only enhances non-retrieval task accuracy
but also improves retrieval performance. For training data, we utilize the
hard-negative mining, synthetic data generation and existing public available
datasets to boost the performance of embedding model. By combining these
techniques, our NV-Embed-v1 and NV-Embed-v2 models obtained the No.1 position
on the MTEB leaderboard (as of May 24 and August 30, 2024, respectively) across
56 tasks, demonstrating the sustained effectiveness of the proposed methods
over time. It also achieved the highest scores in the Long Doc section and the
second-highest scores in the QA section of the AIR Benchmark, which covers a
range of out-of-domain information retrieval topics beyond those in MTEB. We
further provide the analysis of model compression techniques for generalist
embedding models.",2024-05-27,"Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping",http://arxiv.org/pdf/2405.17428v3,cs.CL
"Little Data, Big Impact: Privacy-Aware Visual Language Models via Minimal Tuning","As Visual Language Models (VLMs) become increasingly embedded in everyday
applications, ensuring they can recognize and appropriately handle
privacy-sensitive content is essential. We conduct a comprehensive evaluation
of ten state-of-the-art VLMs and identify limitations in their understanding of
visual privacy. Existing datasets suffer from label inconsistencies, limiting
their reliability. To address this, we introduce two compact, high-quality
benchmarks, PrivBench and PrivBench-H, that focus on commonly recognized
privacy categories aligned with the General Data Protection Regulation (GDPR).
Additionally, we present PrivTune, an instruction-tuning dataset specifically
curated to improve privacy sensitivity. We obtain a Privacy VLM by fine-tuning
an off-the-shelf VLM on only 100 samples from PrivTune, which leads to
substantial gains on all benchmarks, surpassing GPT-4, while maintaining strong
performance on other tasks. Our findings show that privacy-awareness in VLMs
can be substantially improved with minimal data and careful dataset design,
setting the stage for safer, more privacy-aligned AI systems.",2024-05-27,"Laurens Samson, Nimrod Barazani, Sennay Ghebreab, Yuki M. Asano",http://arxiv.org/pdf/2405.17423v3,cs.CL
CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale,"Measuring biodiversity is crucial for understanding ecosystem health. While
prior works have developed machine learning models for taxonomic classification
of photographic images and DNA separately, in this work, we introduce a
multimodal approach combining both, using CLIP-style contrastive learning to
align images, barcode DNA, and text-based representations of taxonomic labels
in a unified embedding space. This allows for accurate classification of both
known and unknown insect species without task-specific fine-tuning, leveraging
contrastive learning for the first time to fuse barcode DNA and image data. Our
method surpasses previous single-modality approaches in accuracy by over 8% on
zero-shot learning tasks, showcasing its effectiveness in biodiversity studies.",2024-05-27,"ZeMing Gong, Austin T. Wang, Xiaoliang Huo, Joakim Bruslund Haurum, Scott C. Lowe, Graham W. Taylor, Angel X. Chang",http://arxiv.org/pdf/2405.17537v4,cs.CL
"QUB-Cirdan at ""Discharge Me!"": Zero shot discharge letter generation by open-source LLM","The BioNLP ACL'24 Shared Task on Streamlining Discharge Documentation aims to
reduce the administrative burden on clinicians by automating the creation of
critical sections of patient discharge letters. This paper presents our
approach using the Llama3 8B quantized model to generate the ""Brief Hospital
Course"" and ""Discharge Instructions"" sections. We employ a zero-shot method
combined with Retrieval-Augmented Generation (RAG) to produce concise,
contextually accurate summaries. Our contributions include the development of a
curated template-based approach to ensure reliability and consistency, as well
as the integration of RAG for word count prediction. We also describe several
unsuccessful experiments to provide insights into our pathway for the
competition. Our results demonstrate the effectiveness and efficiency of our
approach, achieving high scores across multiple evaluation metrics.",2024-05-27,"Rui Guo, Greg Farnan, Niall McLaughlin, Barry Devereux",http://arxiv.org/pdf/2406.00041v2,cs.CL
THREAD: Thinking Deeper with Recursive Spawning,"Large language models (LLMs) have shown impressive capabilities across
diverse settings, but still struggle as the length and complexity of the
context increases. To address this challenge, we propose Thinking Recursively
and Dynamically (ThReaD). THREAD frames model generation as a thread of
execution that, based on the context, can run to completion or dynamically
spawn new threads. By spawning, threads can offload work (e.g., thinking,
retrieving information) to child threads, which only return tokens needed for
the parent thread to do its work. In effect, this enables the model to adapt,
as needed, the amount of intermediate work used to produce tokens. We apply
THREAD in the settings of LLM task solving and question answering, where the
dynamic threading allows the model to recursively decompose the given task or
question into progressively simpler sub-problems that can be solved by separate
child threads. We test THREAD, implemented using a few-shot learning approach,
on diverse benchmarks for agent tasks and data-grounded question answering.
THREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these
benchmarks, including ALFWorld, TextCraft, and WebShop, along with two new
benchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD
outperforms existing frameworks by 10% to 50% absolute points with smaller
models, including Llama-3-8b and CodeLlama-7b.",2024-05-27,"Philip Schroeder, Nathaniel Morgan, Hongyin Luo, James Glass",http://arxiv.org/pdf/2405.17402v1,cs.CL
The Expressive Capacity of State Space Models: A Formal Language Perspective,"Recently, recurrent models based on linear state space models (SSMs) have
shown promising performance in language modeling (LM), competititve with
transformers. However, there is little understanding of the in-principle
abilities of such models, which could provide useful guidance to the search for
better LM architectures. We present a comprehensive theoretical study of the
capacity of such SSMs as it compares to that of transformers and traditional
RNNs. We find that SSMs and transformers have overlapping but distinct
strengths. In star-free state tracking, SSMs implement straightforward and
exact solutions to problems that transformers struggle to represent exactly.
They can also model bounded hierarchical structure with optimal memory even
without simulating a stack. On the other hand, we identify a design choice in
current SSMs that limits their expressive power. We discuss implications for
SSM and LM research, and verify results empirically on a recent SSM, Mamba.",2024-05-27,"Yash Sarrof, Yana Veitsman, Michael Hahn",http://arxiv.org/pdf/2405.17394v2,cs.CL
KSW: Khmer Stop Word based Dictionary for Keyword Extraction,"This paper introduces KSW, a Khmer-specific approach to keyword extraction
that leverages a specialized stop word dictionary. Due to the limited
availability of natural language processing resources for the Khmer language,
effective keyword extraction has been a significant challenge. KSW addresses
this by developing a tailored stop word dictionary and implementing a
preprocessing methodology to remove stop words, thereby enhancing the
extraction of meaningful keywords. Our experiments demonstrate that KSW
achieves substantial improvements in accuracy and relevance compared to
previous methods, highlighting its potential to advance Khmer text processing
and information retrieval. The KSW resources, including the stop word
dictionary, are available at the following GitHub repository:
(https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction.git).",2024-05-27,"Nimol Thuon, Wangrui Zhang, Sada Thuon",http://arxiv.org/pdf/2405.17390v1,cs.CL
MindMerger: Efficient Boosting LLM Reasoning in non-English Languages,"Reasoning capabilities are crucial for Large Language Models (LLMs), yet a
notable gap exists between English and non-English languages. To bridge this
disparity, some works fine-tune LLMs to relearn reasoning capabilities in
non-English languages, while others replace non-English inputs with an external
model's outputs such as English translation text to circumvent the challenge of
LLM understanding non-English. Unfortunately, these methods often underutilize
the built-in skilled reasoning and useful language understanding capabilities
of LLMs. In order to better utilize the minds of reasoning and language
understanding in LLMs, we propose a new method, namely MindMerger, which merges
LLMs with the external language understanding capabilities from multilingual
models to boost the multilingual reasoning performance. Furthermore, a two-step
training scheme is introduced to first train to embeded the external
capabilities into LLMs and then train the collaborative utilization of the
external capabilities and the built-in capabilities in LLMs. Experiments on
three multilingual reasoning datasets and a language understanding dataset
demonstrate that MindMerger consistently outperforms all baselines, especially
in low-resource languages. Without updating the parameters of LLMs, the average
accuracy improved by 6.7% and 8.0% across all languages and low-resource
languages on the MGSM dataset, respectively.",2024-05-27,"Zixian Huang, Wenhao Zhu, Gong Cheng, Lei Li, Fei Yuan",http://arxiv.org/pdf/2405.17386v1,cs.CL
Unlocking the Secrets of Linear Complexity Sequence Model from A Unified Perspective,"We present the Linear Complexity Sequence Model (LCSM), a comprehensive
solution that unites various sequence modeling techniques with linear
complexity, including linear attention, state space model, long convolution,
and linear RNN, within a single framework. The goal is to enhance comprehension
of these models by analyzing the impact of each component from a cohesive and
streamlined viewpoint. Specifically, we segment the modeling processes of these
models into three distinct stages: Expand, Oscillation, and Shrink (EOS), with
each model having its own specific settings. The Expand stage involves
projecting the input signal onto a high-dimensional memory state. This is
followed by recursive operations performed on the memory state in the
Oscillation stage. Finally, the memory state is projected back to a
low-dimensional space in the Shrink stage. We perform comprehensive experiments
to analyze the impact of different stage settings on language modeling and
retrieval tasks. Our results show that data-driven methods are crucial for the
effectiveness of the three stages in language modeling, whereas hand-crafted
methods yield better performance in retrieval tasks.",2024-05-27,"Zhen Qin, Xuyang Shen, Dong Li, Weigao Sun, Stan Birchfield, Richard Hartley, Yiran Zhong",http://arxiv.org/pdf/2405.17383v1,cs.CL
ReMoDetect: Reward Models Recognize Aligned LLM's Generations,"The remarkable capabilities and easy accessibility of large language models
(LLMs) have significantly increased societal risks (e.g., fake news
generation), necessitating the development of LLM-generated text (LGT)
detection methods for safe usage. However, detecting LGTs is challenging due to
the vast number of LLMs, making it impractical to account for each LLM
individually; hence, it is crucial to identify the common characteristics
shared by these models. In this paper, we draw attention to a common feature of
recent powerful LLMs, namely the alignment training, i.e., training LLMs to
generate human-preferable texts. Our key finding is that as these aligned LLMs
are trained to maximize the human preferences, they generate texts with higher
estimated preferences even than human-written texts; thus, such texts are
easily detected by using the reward model (i.e., an LLM trained to model human
preference distribution). Based on this finding, we propose two training
schemes to further improve the detection ability of the reward model, namely
(i) continual preference fine-tuning to make the reward model prefer aligned
LGTs even further and (ii) reward modeling of Human/LLM mixed texts (a
rephrased texts from human-written texts using aligned LLMs), which serves as a
median preference text corpus between LGTs and human-written texts to learn the
decision boundary better. We provide an extensive evaluation by considering six
text domains across twelve aligned LLMs, where our method demonstrates
state-of-the-art results. Code is available at
https://github.com/hyunseoklee-ai/ReMoDetect.",2024-05-27,"Hyunseok Lee, Jihoon Tack, Jinwoo Shin",http://arxiv.org/pdf/2405.17382v2,cs.CL
"Various Lengths, Constant Speed: Efficient Language Modeling with Lightning Attention","We present Lightning Attention, the first linear attention implementation
that maintains a constant training speed for various sequence lengths under
fixed memory consumption. Due to the issue with cumulative summation operations
(cumsum), previous linear attention implementations cannot achieve their
theoretical advantage in a casual setting. However, this issue can be
effectively solved by utilizing different attention calculation strategies to
compute the different parts of attention. Specifically, we split the attention
calculation into intra-blocks and inter-blocks and use conventional attention
computation for intra-blocks and linear attention kernel tricks for
inter-blocks. This eliminates the need for cumsum in the linear attention
calculation. Furthermore, a tiling technique is adopted through both forward
and backward procedures to take full advantage of the GPU hardware. To enhance
accuracy while preserving efficacy, we introduce TransNormerLLM (TNL), a new
architecture that is tailored to our lightning attention. We conduct rigorous
testing on standard and self-collected datasets with varying model sizes and
sequence lengths. TNL is notably more efficient than other language models. In
addition, benchmark results indicate that TNL performs on par with
state-of-the-art LLMs utilizing conventional transformer structures. The source
code is released at github.com/OpenNLPLab/TransnormerLLM.",2024-05-27,"Zhen Qin, Weigao Sun, Dong Li, Xuyang Shen, Weixuan Sun, Yiran Zhong",http://arxiv.org/pdf/2405.17381v2,cs.CL
Federating Dynamic Models using Early-Exit Architectures for Automatic Speech Recognition on Heterogeneous Clients,"Automatic speech recognition models require large amounts of speech
recordings for training. However, the collection of such data often is
cumbersome and leads to privacy concerns. Federated learning has been widely
used as an effective decentralized technique that collaboratively learns a
shared prediction model while keeping the data local on different clients.
Unfortunately, client devices often feature limited computation and
communication resources leading to practical difficulties for large models. In
addition, the heterogeneity that characterizes edge devices makes it
sub-optimal to generate a single model that fits all of them. Differently from
the recent literature, where multiple models with different architectures are
used, in this work, we propose using dynamical architectures which, employing
early-exit solutions, can adapt their processing (i.e. traversed layers)
depending on the input and on the operation conditions. This solution falls in
the realm of partial training methods and brings two benefits: a single model
is used on a variety of devices; federating the models after local training is
straightforward. Experiments on public datasets show that our proposed approach
is effective and can be combined with basic federated learning strategies.",2024-05-27,"Mohamed Nabih Ali, Alessio Brutti, Daniele Falavigna",http://arxiv.org/pdf/2405.17376v1,cs.CL
A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an Application to Certified Robustness,"This paper reveals a key insight that a one-layer decoder-only Transformer is
equivalent to a two-layer Recurrent Neural Network (RNN). Building on this
insight, we propose ARC-Tran, a novel approach for verifying the robustness of
decoder-only Transformers against arbitrary perturbation spaces. Compared to
ARC-Tran, current robustness verification techniques are limited either to
specific and length-preserving perturbations like word substitutions or to
recursive models like LSTMs. ARC-Tran addresses these limitations by
meticulously managing position encoding to prevent mismatches and by utilizing
our key insight to achieve precise and scalable verification. Our evaluation
shows that ARC-Tran (1) trains models more robust to arbitrary perturbation
spaces than those produced by existing techniques and (2) shows high
certification accuracy of the resulting models.",2024-05-27,"Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni",http://arxiv.org/pdf/2405.17361v1,cs.CL
DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution,"Fine-tuning large-scale pre-trained models is inherently a resource-intensive
task. While it can enhance the capabilities of the model, it also incurs
substantial computational costs, posing challenges to the practical application
of downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methods
such as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores the
differential parameter budget requirements across weight matrices, which may
lead to suboptimal fine-tuning outcomes. To address this issue, we introduce
the Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRA
layers into structured single-rank components, allowing for dynamic pruning of
parameter budget based on their importance to specific tasks during training,
which makes the most of the limited parameter budget. Experimental results
demonstrate that DoRA can achieve competitive performance compared with LoRA
and full model fine-tuning, and outperform various strong baselines with the
same storage parameter budget. Our code is available at
https://github.com/MIkumikumi0116/DoRA",2024-05-27,"Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu",http://arxiv.org/pdf/2405.17357v3,cs.CL
Exploring and steering the moral compass of Large Language Models,"Large Language Models (LLMs) have become central to advancing automation and
decision-making across various sectors, raising significant ethical questions.
This study proposes a comprehensive comparative analysis of the most advanced
LLMs to assess their moral profiles. We subjected several state-of-the-art
models to a selection of ethical dilemmas and found that all the proprietary
ones are mostly utilitarian and all of the open-weights ones align mostly with
values-based ethics. Furthermore, when using the Moral Foundations
Questionnaire, all models we probed - except for Llama 2-7B - displayed a
strong liberal bias. Lastly, in order to causally intervene in one of the
studied models, we propose a novel similarity-specific activation steering
technique. Using this method, we were able to reliably steer the model's moral
compass to different ethical schools. All of these results showcase that there
is an ethical dimension in already deployed LLMs, an aspect that is generally
overlooked.",2024-05-27,Alejandro Tlaie,http://arxiv.org/pdf/2405.17345v2,cs.CL
Cost-efficient Knowledge-based Question Answering with Large Language Models,"Knowledge-based question answering (KBQA) is widely used in many scenarios
that necessitate domain knowledge. Large language models (LLMs) bring
opportunities to KBQA, while their costs are significantly higher and absence
of domain-specific knowledge during pre-training. We are motivated to combine
LLMs and prior small models on knowledge graphs (KGMs) for both inferential
accuracy and cost saving. However, it remains challenging since accuracy and
cost are not readily combined in the optimization as two distinct metrics. It
is also laborious for model selection since different models excel in diverse
knowledge. To this end, we propose Coke, a novel cost-efficient strategy for
KBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize
calls to LLMs within limited budgets. We first formulate the accuracy
expectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A
context-aware policy is optimized to further distinguish the expert model
subject to the question semantics. The overall decision is bounded by the cost
regret according to historical expenditure on failures. Extensive experiments
showcase the superior performance of Coke, which moves the Pareto frontier with
up to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on
the benchmark datasets.",2024-05-27,"Junnan Dong, Qinggang Zhang, Chuang Zhou, Hao Chen, Daochen Zha, Xiao Huang",http://arxiv.org/pdf/2405.17337v1,cs.CL
XFormParser: A Simple and Effective Multimodal Multilingual Semi-structured Form Parser,"In the domain of Document AI, parsing semi-structured image form is a crucial
Key Information Extraction (KIE) task. The advent of pre-trained multimodal
models significantly empowers Document AI frameworks to extract key information
from form documents in different formats such as PDF, Word, and images.
Nonetheless, form parsing is still encumbered by notable challenges like subpar
capabilities in multilingual parsing and diminished recall in industrial
contexts in rich text and rich visuals. In this work, we introduce a simple but
effective \textbf{M}ultimodal and \textbf{M}ultilingual semi-structured
\textbf{FORM} \textbf{PARSER} (\textbf{XFormParser}), which anchored on a
comprehensive Transformer-based pre-trained language model and innovatively
amalgamates semantic entity recognition (SER) and relation extraction (RE) into
a unified framework. Combined with Bi-LSTM, the performance of multilingual
parsing is significantly improved. Furthermore, we develop InDFormSFT, a
pioneering supervised fine-tuning (SFT) industrial dataset that specifically
addresses the parsing needs of forms in various industrial contexts.
XFormParser has demonstrated its unparalleled effectiveness and robustness
through rigorous testing on established benchmarks. Compared to existing
state-of-the-art (SOTA) models, XFormParser notably achieves up to 1.79\% F1
score improvement on RE tasks in language-specific settings. It also exhibits
exceptional cross-task performance improvements in multilingual and zero-shot
settings. The codes, datasets, and pre-trained models are publicly available at
https://github.com/zhbuaa0/xformparser.",2024-05-27,"Xianfu Cheng, Hang Zhang, Jian Yang, Xiang Li, Weixiao Zhou, Fei Liu, Kui Wu, Xiangyuan Guan, Tao Sun, Xianjie Wu, Tongliang Li, Zhoujun Li",http://arxiv.org/pdf/2405.17336v2,cs.CL
Detecting Deceptive Dark Patterns in E-commerce Platforms,"Dark patterns are deceptive user interfaces employed by e-commerce websites
to manipulate user's behavior in a way that benefits the website, often
unethically. This study investigates the detection of such dark patterns.
Existing solutions include UIGuard, which uses computer vision and natural
language processing, and approaches that categorize dark patterns based on
detectability or utilize machine learning models trained on datasets. We
propose combining web scraping techniques with fine-tuned BERT language models
and generative capabilities to identify dark patterns, including outliers. The
approach scrapes textual content, feeds it into the BERT model for detection,
and leverages BERT's bidirectional analysis and generation abilities. The study
builds upon research on automatically detecting and explaining dark patterns,
aiming to raise awareness and protect consumers.",2024-05-27,"Arya Ramteke, Sankalp Tembhurne, Gunesh Sonawane, Ratnmala N. Bhimanpallewar",http://arxiv.org/pdf/2406.01608v1,cs.CL
Unveiling Themes in Judicial Proceedings: A Cross-Country Study Using Topic Modeling on Legal Documents from India and the UK,"Legal documents are indispensable in every country for legal practices and
serve as the primary source of information regarding previous cases and
employed statutes. In today's world, with an increasing number of judicial
cases, it is crucial to systematically categorize past cases into subgroups,
which can then be utilized for upcoming cases and practices. Our primary focus
in this endeavor was to annotate cases using topic modeling algorithms such as
Latent Dirichlet Allocation, Non-Negative Matrix Factorization, and Bertopic
for a collection of lengthy legal documents from India and the UK. This step is
crucial for distinguishing the generated labels between the two countries,
highlighting the differences in the types of cases that arise in each
jurisdiction. Furthermore, an analysis of the timeline of cases from India was
conducted to discern the evolution of dominant topics over the years.",2024-05-27,"Krish Didwania, Durga Toshniwal, Amit Agarwal",http://arxiv.org/pdf/2406.00040v2,cs.CL
How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors?,"Grammatical error correction (GEC) tools, powered by advanced generative
artificial intelligence (AI), competently correct linguistic inaccuracies in
user input. However, they often fall short in providing essential natural
language explanations, which are crucial for learning languages and gaining a
deeper understanding of the grammatical rules. There is limited exploration of
these tools in low-resource languages such as Bengali. In such languages,
grammatical error explanation (GEE) systems should not only correct sentences
but also provide explanations for errors. This comprehensive approach can help
language learners in their quest for proficiency. Our work introduces a
real-world, multi-domain dataset sourced from Bengali speakers of varying
proficiency levels and linguistic complexities. This dataset serves as an
evaluation benchmark for GEE systems, allowing them to use context information
to generate meaningful explanations and high-quality corrections. Various
generative pre-trained large language models (LLMs), including GPT-4 Turbo,
GPT-3.5 Turbo, Text-davinci-003, Text-babbage-001, Text-curie-001,
Text-ada-001, Llama-2-7b, Llama-2-13b, and Llama-2-70b, are assessed against
human experts for performance comparison. Our research underscores the
limitations in the automatic deployment of current state-of-the-art generative
pre-trained LLMs for Bengali GEE. Advocating for human intervention, our
findings propose incorporating manual checks to address grammatical errors and
improve feedback quality. This approach presents a more suitable strategy to
refine the GEC tools in Bengali, emphasizing the educational aspect of language
learning.",2024-05-27,"Subhankar Maity, Aniket Deroy, Sudeshna Sarkar",http://arxiv.org/pdf/2406.00039v1,cs.CL
An NLP Crosswalk Between the Common Core State Standards and NAEP Item Specifications,"Natural language processing (NLP) is rapidly developing for applications in
educational assessment. In this paper, I describe an NLP-based procedure that
can be used to support subject matter experts in establishing a crosswalk
between item specifications and content standards. This paper extends recent
work by proposing and demonstrating the use of multivariate similarity based on
embedding vectors for sentences or texts. In particular, a hybrid regression
procedure is demonstrated for establishing the match of each content standard
to multiple item specifications. The procedure is used to evaluate the match of
the Common Core State Standards (CCSS) for mathematics at grade 4 to the
corresponding item specifications for the 2026 National Assessment of
Educational Progress (NAEP).",2024-05-27,Gregory Camilli,http://arxiv.org/pdf/2405.17284v2,cs.CL
A Library for Automatic Natural Language Generation of Spanish Texts,"In this article we present a novel system for natural language generation
(NLG) of Spanish sentences from a minimum set of meaningful words (such as
nouns, verbs and adjectives) which, unlike other state-of-the-art solutions,
performs the NLG task in a fully automatic way, exploiting both knowledge-based
and statistical approaches. Relying on its linguistic knowledge of vocabulary
and grammar, the system is able to generate complete, coherent and correctly
spelled sentences from the main word sets presented by the user. The system,
which was designed to be integrable, portable and efficient, can be easily
adapted to other languages by design and can feasibly be integrated in a wide
range of digital devices. During its development we also created a
supplementary lexicon for Spanish, aLexiS, with wide coverage and high
precision, as well as syntactic trees from a freely available definite-clause
grammar. The resulting NLG library has been evaluated both automatically and
manually (annotation). The system can potentially be used in different
application domains such as augmentative communication and automatic generation
of administrative reports or news.",2024-05-27,"Silvia García-Méndez, Milagros Fernández-Gavilanes, Enrique Costa-Montenegro, Jonathan Juncal-Martínez, F. Javier González-Castaño",http://arxiv.org/pdf/2405.17280v1,cs.CL
On the Noise Robustness of In-Context Learning for Text Generation,"Large language models (LLMs) have shown impressive performance on downstream
tasks by in-context learning (ICL), which heavily relies on the quality of
demonstrations selected from a large set of annotated examples. Recent works
claim that in-context learning is robust to noisy demonstrations in text
classification. In this work, we show that, on text generation tasks, noisy
annotations significantly hurt the performance of in-context learning. To
circumvent the issue, we propose a simple and effective approach called Local
Perplexity Ranking (LPR), which replaces the ""noisy"" candidates with their
nearest neighbors that are more likely to be clean. Our method is motivated by
analyzing the perplexity deviation caused by noisy labels and decomposing
perplexity into inherent perplexity and matching perplexity. Our key idea
behind LPR is thus to decouple the matching perplexity by performing the
ranking among the neighbors in semantic space. Our approach can prevent the
selected demonstrations from including mismatched input-label pairs while
preserving the effectiveness of the original selection methods. Extensive
experiments demonstrate the effectiveness of LPR, improving the EM score by up
to 18.75 on common benchmarks with noisy annotations. Our code is available at
https://github.com/ml-stat-Sustech/Local-Perplexity-Ranking.",2024-05-27,"Hongfu Gao, Feipeng Zhang, Wenyu Jiang, Jun Shu, Feng Zheng, Hongxin Wei",http://arxiv.org/pdf/2405.17264v3,cs.CL
Assessing LLMs Suitability for Knowledge Graph Completion,"Recent work has shown the capability of Large Language Models (LLMs) to solve
tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in
Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or
output results in a non-deterministic manner, thus leading to wrongly reasoned
responses, even if they satisfy the user's demands. To highlight opportunities
and challenges in knowledge graphs-related tasks, we experiment with three
distinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and
GPT-4o, on Knowledge Graph Completion for static knowledge graphs, using
prompts constructed following the TELeR taxonomy, in Zero- and One-Shot
contexts, on a Task-Oriented Dialogue system use case. When evaluated using
both strict and flexible metrics measurement manners, our results show that
LLMs could be fit for such a task if prompts encapsulate sufficient information
and relevant examples.",2024-05-27,"Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi",http://arxiv.org/pdf/2405.17249v2,cs.CL
ViSpeR: Multilingual Audio-Visual Speech Recognition,"This work presents an extensive and detailed study on Audio-Visual Speech
Recognition (AVSR) for five widely spoken languages: Chinese, Spanish, English,
Arabic, and French. We have collected large-scale datasets for each language
except for English, and have engaged in the training of supervised learning
models. Our model, ViSpeR, is trained in a multi-lingual setting, resulting in
competitive performance on newly established benchmarks for each language. The
datasets and models are released to the community with an aim to serve as a
foundation for triggering and feeding further research work and exploration on
Audio-Visual Speech Recognition, an increasingly important area of research.
Code available at
\href{https://github.com/YasserdahouML/visper}{https://github.com/YasserdahouML/visper}.",2024-05-27,"Sanath Narayan, Yasser Abdelaziz Dahou Djilali, Ankit Singh, Eustache Le Bihan, Hakim Hacid",http://arxiv.org/pdf/2406.00038v1,cs.CL
RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness,"Traditional feedback learning for hallucination reduction relies on
labor-intensive manual labeling or expensive proprietary models. This leaves
the community without foundational knowledge about how to build high-quality
feedback with open-source MLLMs. In this work, we introduce RLAIF-V, a novel
framework that aligns MLLMs in a fully open-source paradigm. RLAIF-V maximally
explores open-source MLLMs from two perspectives, including high-quality
feedback data generation for preference learning and self-feedback guidance for
inference-time scaling. Extensive experiments on six benchmarks in both
automatic and human evaluation show that RLAIF-V substantially enhances the
trustworthiness of models at both preference learning and inference time.
RLAIF-V 7B reduces object hallucination by 80.7\% and overall hallucination by
33.7\%. Remarkably, RLAIF-V 12B further reveals the self-alignment potential of
open-source MLLMs, where the model can learn from feedback of itself to achieve
super GPT-4V trustworthiness.",2024-05-27,"Tianyu Yu, Haoye Zhang, Qiming Li, Qixin Xu, Yuan Yao, Da Chen, Xiaoman Lu, Ganqu Cui, Yunkai Dang, Taiwen He, Xiaocheng Feng, Jun Song, Bo Zheng, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun",http://arxiv.org/pdf/2405.17220v2,cs.CL
Collage is the New Writing: Exploring the Fragmentation of Text and User Interfaces in AI Tools,"This essay proposes and explores the concept of Collage for the design of AI
writing tools, transferred from avant-garde literature with four facets: 1)
fragmenting text in writing interfaces, 2) juxtaposing voices (content vs
command), 3) integrating material from multiple sources (e.g. text
suggestions), and 4) shifting from manual writing to editorial and
compositional decision-making, such as selecting and arranging snippets. The
essay then employs Collage as an analytical lens to analyse the user interface
design of recent AI writing tools, and as a constructive lens to inspire new
design directions. Finally, a critical perspective relates the concerns that
writers historically expressed through literary collage to AI writing tools. In
a broad view, this essay explores how literary concepts can help advance design
theory around AI writing tools. It encourages creators of future writing tools
to engage not only with new technological possibilities, but also with past
writing innovations.",2024-05-27,Daniel Buschek,http://arxiv.org/pdf/2405.17217v1,cs.CL
Efficient multi-prompt evaluation of LLMs,"Most popular benchmarks for comparing LLMs rely on a limited set of prompt
templates, which may not fully capture the LLMs' abilities and can affect the
reproducibility of results on leaderboards. Many recent works empirically
verify prompt sensitivity and advocate for changes in LLM evaluation. In this
paper, we consider the problem of estimating the performance distribution
across many prompt variants instead of finding a single prompt to evaluate
with. We introduce PromptEval, a method for estimating performance across a
large set of prompts borrowing strength across prompts and examples to produce
accurate estimates under practical evaluation budgets. The resulting
distribution can be used to obtain performance quantiles to construct various
robust performance metrics (e.g., top 95% quantile or median). We prove that
PromptEval consistently estimates the performance distribution and demonstrate
its efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench
Hard, and LMentry; for example, PromptEval can accurately estimate performance
quantiles across 100 prompt templates on MMLU with a budget equivalent to two
single-prompt evaluations. Moreover, we show how PromptEval can be useful in
LLM-as-a-judge and best prompt identification applications.",2024-05-27,"Felipe Maia Polo, Ronald Xu, Lucas Weber, Mírian Silva, Onkar Bhardwaj, Leshem Choshen, Allysson Flavio Melo de Oliveira, Yuekai Sun, Mikhail Yurochkin",http://arxiv.org/pdf/2405.17202v3,cs.CL
Aligning LLMs through Multi-perspective User Preference Ranking-based Feedback for Programming Question Answering,"Code Community Question Answering (CCQA) seeks to tackle programming-related
issues, thereby boosting productivity in both software engineering and academic
research. Recent advancements in Reinforcement Learning from Human Feedback
(RLHF) have transformed the fine-tuning process of Large Language Models (LLMs)
to produce responses that closely mimic human behavior. Leveraging LLMs with
RLHF for practical CCQA applications has thus emerged as a promising area of
study. Unlike standard code question-answering tasks, CCQA involves multiple
possible answers, with varying user preferences for each response.
Additionally, code communities often show a preference for new APIs. These
challenges prevent LLMs from generating responses that cater to the diverse
preferences of users in CCQA tasks. To address these issues, we propose a novel
framework called Aligning LLMs through Multi-perspective User Preference
Ranking-based Feedback for Programming Question Answering (ALMupQA) to create
user-focused responses. Our approach starts with Multi-perspective Preference
Ranking Alignment (MPRA), which synthesizes varied user preferences based on
the characteristics of answers from code communities. We then introduce a
Retrieval-augmented In-context Learning (RIL) module to mitigate the problem of
outdated answers by retrieving responses to similar questions from a question
bank. Due to the limited availability of high-quality, multi-answer CCQA
datasets, we also developed a dataset named StaCCQA from real code communities.
Extensive experiments demonstrated the effectiveness of the ALMupQA framework
in terms of accuracy and user preference. Compared to the base model, ALMupQA
showed nearly an 11% improvement in BLEU, with increases of 20% and 17.5% in
BERTScore and CodeBERTScore, respectively.",2024-05-27,"Hongyu Yang, Liyang He, Min Hou, Shuanghong Shen, Rui Li, Jiahui Hou, Jianhui Ma, Junda Zhao",http://arxiv.org/pdf/2406.00037v1,cs.CL
Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP,"Personal names simultaneously differentiate individuals and categorize them
in ways that are important in a given society. While the natural language
processing community has thus associated personal names with sociodemographic
characteristics in a variety of tasks, researchers have engaged to varying
degrees with the established methodological problems in doing so. To guide
future work that uses names and sociodemographic characteristics, we provide an
overview of relevant research: first, we present an interdisciplinary
background on names and naming. We then survey the issues inherent to
associating names with sociodemographic attributes, covering problems of
validity (e.g., systematic error, construct validity), as well as ethical
concerns (e.g., harms, differential impact, cultural insensitivity). Finally,
we provide guiding questions along with normative recommendations to avoid
validity and ethical pitfalls when dealing with names and sociodemographic
characteristics in natural language processing.",2024-05-27,"Vagrant Gautam, Arjun Subramonian, Anne Lauscher, Os Keyes",http://arxiv.org/pdf/2405.17159v2,cs.CL
Explaining the role of Intrinsic Dimensionality in Adversarial Training,"Adversarial Training (AT) impacts different architectures in distinct ways:
vision models gain robustness but face reduced generalization, encoder-based
models exhibit limited robustness improvements with minimal generalization
loss, and recent work in latent-space adversarial training (LAT) demonstrates
that decoder-based models achieve improved robustness by applying AT across
multiple layers. We provide the first explanation for these trends by
leveraging the manifold conjecture: off-manifold adversarial examples (AEs)
enhance robustness, while on-manifold AEs improve generalization. We show that
vision and decoder-based models exhibit low intrinsic dimensionality in earlier
layers (favoring off-manifold AEs), whereas encoder-based models do so in later
layers (favoring on-manifold AEs). Exploiting this property, we introduce
SMAAT, which improves the scalability of AT for encoder-based models by
perturbing the layer with the lowest intrinsic dimensionality. This reduces the
projected gradient descent (PGD) chain length required for AE generation,
cutting GPU time by 25-33% while significantly boosting robustness. We validate
SMAAT across multiple tasks, including text generation, sentiment
classification, safety filtering, and retrieval augmented generation setups,
demonstrating superior robustness with comparable generalization to standard
training.",2024-05-27,"Enes Altinisik, Safa Messaoud, Husrev Taha Sencar, Hassan Sajjad, Sanjay Chawla",http://arxiv.org/pdf/2405.17130v2,cs.CL
"TEII: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection","Cross-lingual emotion detection allows us to analyze global trends, public
opinion, and social phenomena at scale. We participated in the Explainability
of Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score
of 0.6046 on the evaluation set for the emotion detection sub-task. Our system
outperformed the baseline by more than 0.16 F1-score absolute, and ranked
second amongst competing systems. We conducted experiments using fine-tuning,
zero-shot learning, and few-shot learning for Large Language Model (LLM)-based
models as well as embedding-based BiLSTM and KNN for non-LLM-based techniques.
Additionally, we introduced two novel methods: the Multi-Iteration Agentic
Workflow and the Multi-Binary-Classifier Agentic Workflow. We found that
LLM-based approaches provided good performance on multilingual emotion
detection. Furthermore, ensembles combining all our experimented models yielded
higher F1-scores than any single approach alone.",2024-05-27,"Long Cheng, Qihao Shao, Christine Zhao, Sheng Bi, Gina-Anne Levow",http://arxiv.org/pdf/2405.17129v2,cs.CL
Mixtures of Unsupervised Lexicon Classification,"This paper presents a mixture version of the method-of-moment unsupervised
lexicon classification by an incorporation of a Dirichlet process.",2024-05-27,Peratham Wiriyathammabhum,http://arxiv.org/pdf/2405.17116v1,cs.CL
LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding,"Visual grounding is an essential tool that links user-provided text queries
with query-specific regions within an image. Despite advancements in visual
grounding models, their ability to comprehend complex queries remains limited.
To overcome this limitation, we introduce LLM-Optic, an innovative method that
utilizes Large Language Models (LLMs) as an optical lens to enhance existing
visual grounding models in comprehending complex text queries involving
intricate text structures, multiple objects, or object spatial relationships,
situations that current models struggle with. LLM-Optic first employs an LLM as
a Text Grounder to interpret complex text queries and accurately identify
objects the user intends to locate. Then a pre-trained visual grounding model
is used to generate candidate bounding boxes given the refined query by the
Text Grounder. After that, LLM-Optic annotates the candidate bounding boxes
with numerical marks to establish a connection between text and specific image
regions, thereby linking two distinct modalities. Finally, it employs a Large
Multimodal Model (LMM) as a Visual Grounder to select the marked candidate
objects that best correspond to the original text query. Through LLM-Optic, we
have achieved universal visual grounding, which allows for the detection of
arbitrary objects specified by arbitrary human language input. Importantly, our
method achieves this enhancement without requiring additional training or
fine-tuning. Extensive experiments across various challenging benchmarks
demonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding
capabilities. Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/.",2024-05-27,"Haoyu Zhao, Wenhang Ge, Ying-cong Chen",http://arxiv.org/pdf/2405.17104v2,cs.CL
Empowering Character-level Text Infilling by Eliminating Sub-Tokens,"In infilling tasks, sub-tokens, representing instances where a complete token
is segmented into two parts, often emerge at the boundaries of prefixes,
middles, and suffixes. Traditional methods focused on training models at the
token level, leading to sub-optimal performance in character-level infilling
tasks during the inference stage. Alternately, some approaches considered
character-level infilling, but they relied on predicting sub-tokens in
inference, yet this strategy diminished ability in character-level infilling
tasks due to the large perplexity of the model on sub-tokens. In this paper, we
introduce FIM-SE, which stands for Fill-In-the-Middle with both Starting and
Ending character constraints. The proposed method addresses character-level
infilling tasks by utilizing a line-level format to avoid predicting any
sub-token in inference. In addition, we incorporate two special tokens to
signify the rest of the incomplete lines, thereby enhancing generation
guidance. Extensive experiments demonstrate that our proposed approach
surpasses previous methods, offering a significant advantage. Code is available
at https://github.com/SenseLLM/FIM-SE.",2024-05-27,"Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Hongsheng Li",http://arxiv.org/pdf/2405.17103v2,cs.CL
Phase Transitions in the Output Distribution of Large Language Models,"In a physical system, changing parameters such as temperature can induce a
phase transition: an abrupt change from one state of matter to another.
Analogous phenomena have recently been observed in large language models.
Typically, the task of identifying phase transitions requires human analysis
and some prior understanding of the system to narrow down which low-dimensional
properties to monitor and analyze. Statistical methods for the automated
detection of phase transitions from data have recently been proposed within the
physics community. These methods are largely system agnostic and, as shown
here, can be adapted to study the behavior of large language models. In
particular, we quantify distributional changes in the generated output via
statistical distances, which can be efficiently estimated with access to the
probability distribution over next-tokens. This versatile approach is capable
of discovering new phases of behavior and unexplored transitions -- an ability
that is particularly exciting in light of the rapid development of language
models and their emergent capabilities.",2024-05-27,"Julian Arnold, Flemming Holtorf, Frank Schäfer, Niels Lörch",http://arxiv.org/pdf/2405.17088v1,cs.CL
Leveraging small language models for Text2SPARQL tasks to improve the resilience of AI assistance,"In this work we will show that language models with less than one billion
parameters can be used to translate natural language to SPARQL queries after
fine-tuning. Using three different datasets ranging from academic to real
world, we identify prerequisites that the training data must fulfill in order
for the training to be successful. The goal is to empower users of semantic web
technology to use AI assistance with affordable commodity hardware, making them
more resilient against external factors.",2024-05-27,"Felix Brei, Johannes Frey, Lars-Peter Meyer",http://arxiv.org/pdf/2405.17076v1,cs.CL
Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization,"Large Language Models (LLMs) have shown remarkable capabilities in language
understanding and generation. Nonetheless, it was also witnessed that LLMs tend
to produce inaccurate responses to specific queries. This deficiency can be
traced to the tokenization step LLMs must undergo, which is an inevitable
limitation inherent to all LLMs. In fact, incorrect tokenization is the
critical point that hinders LLMs in understanding the input precisely, thus
leading to unsatisfactory output. This defect is more obvious in Chinese
scenarios. To demonstrate this flaw of LLMs, we construct an adversarial
dataset, named as $\textbf{ADT (Adversarial Dataset for Tokenizer)}$, which
draws upon the vocabularies of various open-source LLMs to challenge LLMs'
tokenization. ADT consists of two subsets: the manually constructed ADT-Human
and the automatically generated ADT-Auto. Our empirical results reveal that our
ADT is highly effective on challenging the tokenization of leading LLMs,
including GPT-4o, Llama-3, Deepseek-R1 and so on, thus degrading these LLMs'
capabilities. Moreover, our method of automatic data generation has been proven
efficient and robust, which can be applied to any open-source LLMs. In this
paper, we substantially investigate LLMs' vulnerability in terms of challenging
their token segmentation, which will shed light on the subsequent research of
improving LLMs' capabilities through optimizing their tokenization process and
algorithms.",2024-05-27,"Dixuan Wang, Yanda Li, Junyuan Jiang, Zepeng Ding, Ziqin Luo, Guochao Jiang, Jiaqing Liang, Deqing Yang",http://arxiv.org/pdf/2405.17067v2,cs.CL
"UniICL: An Efficient Unified Framework Unifying Compression, Selection, and Generation","In-context learning (ICL) enhances the reasoning abilities of Large Language
Models (LLMs) by prepending a few demonstrations. It motivates researchers to
introduce more examples to provide additional contextual information for the
generation. However, existing methods show a significant limitation due to the
problem of excessive growth in context length, which causes a large hardware
burden. In addition, shallow-relevant examples selected by off-the-shelf tools
hinder LLMs from capturing useful contextual information for generation. In
this paper, we propose \textbf{UniICL}, a novel \textbf{Uni}fied \textbf{ICL}
framework that unifies demonstration compression, demonstration selection, and
final response generation. Furthermore, to boost inference efficiency, we
design a tailored compression strategy that allows UniICL to cache compression
results into \textbf{Demonstration Bank} (\textbf{DB}), which avoids repeated
compression of the same demonstration. Extensive out-of-domain evaluations
prove the advantages of UniICL in both effectiveness and efficiency.",2024-05-27,"Jun Gao, Qi Lv, Zili Wang, Tianxiang Wu, Ziqiang Cao, Wenjie Li",http://arxiv.org/pdf/2405.17062v3,cs.CL
ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation,"Code generation plays a crucial role in various tasks, such as code
auto-completion and mathematical reasoning. Previous work has proposed numerous
methods to enhance code generation performance, including integrating feedback
from the compiler. Inspired by this, we present ReflectionCoder, a novel
approach that effectively leverages reflection sequences constructed by
integrating compiler feedback to improve one-off code generation performance.
Furthermore, we propose reflection self-distillation and dynamically masked
distillation to effectively utilize these reflection sequences. Extensive
experiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E,
demonstrate that models fine-tuned with our method achieve state-of-the-art
performance. Notably, ReflectionCoder-DeepSeek-Coder-33B reaches pass@1 of 82.9
(76.8) on HumanEval (+) and 84.1 (72.0) on MBPP (+), on par with GPT-3.5-Turbo
and Claude-3-opus, and surpasses early GPT-4. Beyond the code domain, we
believe this approach can benefit other domains that focus on final results and
require long reasoning paths. Code and data are available at
https://github.com/SenseLLM/ReflectionCoder.",2024-05-27,"Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Aojun Zhou, Junting Pan, Hongsheng Li",http://arxiv.org/pdf/2405.17057v1,cs.CL
SelfCP: Compressing Over-Limit Prompt via the Frozen Large Language Model Itself,"Long prompt leads to huge hardware costs when using transformer-based Large
Language Models (LLMs). Unfortunately, many tasks, such as summarization,
inevitably introduce long documents, and the wide application of in-context
learning easily makes the prompt length explode. This paper proposes a
Self-Compressor (SelfCP), which employs the target LLM itself to compress
over-limit prompts into dense vectors while keeping the allowed prompts
unmodified. Dense vectors are then projected into dense tokens via a learnable
connector to make the same LLM unburden to understand. The connector is
supervised-tuned under the language modeling objective of the LLM on relatively
long texts selected from publicly accessed datasets, involving an instruction
dataset to make SelfCP respond to various prompts, while the target LLM keeps
frozen during training. We build the lightweight SelfCP upon 2 different
backbones with merely 17M learnable parameters originating from the connector
and a learnable embedding. Evaluation on both English and Chinese benchmarks
demonstrate that SelfCP effectively substitutes 12$\times$ over-limit prompts
with dense tokens to reduce memory costs and booster inference throughputs, yet
improving response quality. The outstanding performance brings an efficient
solution for LLMs to tackle long prompts without training LLMs from scratch.",2024-05-27,"Jun Gao, Ziqiang Cao, Wenjie Li",http://arxiv.org/pdf/2405.17052v2,cs.CL
Interesting Scientific Idea Generation using Knowledge Graphs and LLMs: Evaluations with 100 Research Group Leaders,"The rapid growth of scientific literature makes it challenging for
researchers to identify novel and impactful ideas, especially across
disciplines. Modern artificial intelligence (AI) systems offer new approaches,
potentially inspiring ideas not conceived by humans alone. But how compelling
are these AI-generated ideas, and how can we improve their quality? Here, we
introduce SciMuse, which uses 58 million research papers and a large-language
model to generate research ideas. We conduct a large-scale evaluation in which
over 100 research group leaders -- from natural sciences to humanities --
ranked more than 4,400 personalized ideas based on their interest. This data
allows us to predict research interest using (1) supervised neural networks
trained on human evaluations, and (2) unsupervised zero-shot ranking with
large-language models. Our results demonstrate how future systems can help
generating compelling research ideas and foster unforeseen interdisciplinary
collaborations.",2024-05-27,"Xuemei Gu, Mario Krenn",http://arxiv.org/pdf/2405.17044v3,cs.CL
EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation,"The integration of multimodal Electronic Health Records (EHR) data has
significantly advanced clinical predictive capabilities. Existing models, which
utilize clinical notes and multivariate time-series EHR data, often fall short
of incorporating the necessary medical context for accurate clinical tasks,
while previous approaches with knowledge graphs (KGs) primarily focus on
structured knowledge extraction. In response, we propose EMERGE, a
Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR
predictive modeling. We extract entities from both time-series data and
clinical notes by prompting Large Language Models (LLMs) and align them with
professional PrimeKG, ensuring consistency. In addition to triplet
relationships, we incorporate entities' definitions and descriptions for richer
semantics. The extracted knowledge is then used to generate task-relevant
summaries of patients' health statuses. Finally, we fuse the summary with other
modalities using an adaptive multimodal fusion network with cross-attention.
Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital
mortality and 30-day readmission tasks demonstrate the superior performance of
the EMERGE framework over baseline models. Comprehensive ablation studies and
analysis highlight the efficacy of each designed module and robustness to data
sparsity. EMERGE contributes to refining the utilization of multimodal EHR data
in healthcare, bridging the gap with nuanced medical contexts essential for
informed clinical predictions. We have publicly released the code at
https://github.com/yhzhu99/EMERGE.",2024-05-27,"Yinghao Zhu, Changyu Ren, Zixiang Wang, Xiaochen Zheng, Shiyun Xie, Junlan Feng, Xi Zhu, Zhoujun Li, Liantao Ma, Chengwei Pan",http://arxiv.org/pdf/2406.00036v2,cs.CL
"BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation","Large language models (LLMs) have catalyzed a paradigm shift in natural
language processing, yet their limited controllability poses a significant
challenge for downstream applications. We aim to address this by drawing
inspiration from the neural mechanisms of the human brain, specifically Broca's
and Wernicke's areas, which are crucial for language generation and
comprehension, respectively. In particular, Broca's area receives cognitive
decision signals from Wernicke's area, treating the language generation as an
intricate decision-making process, which differs from the fully auto-regressive
language generation of existing LLMs. In a similar vein, our proposed system,
the BWArea model, conceptualizes language generation as a decision-making task.
This model has three components: a language world model, an inverse dynamics
model, and a cognitive policy. Like Wernicke's area, the inverse dynamics model
is designed to deduce the underlying cognitive intentions, or latent actions,
behind each token. The BWArea model is amenable to both pre-training and
fine-tuning like existing LLMs. With 30B clean pre-training tokens, we have
trained a BWArea model, which achieves competitive performance with LLMs of
equal size (1B parameters). Unlike fully auto-regressive LLMs, its pre-training
performance does not degenerate if dirty data unintentionally appears. This
shows the advantage of a decomposed structure of BWArea model in reducing
efforts in laborious data selection and labeling. Finally, we reveal that the
BWArea model offers enhanced controllability via fine-tuning the cognitive
policy with downstream reward metrics, thereby facilitating alignment with
greater simplicity. On 9 out of 10 tasks from two suites, TextWorld and
BigBench Hard, our method shows superior performance to auto-regressive LLMs.",2024-05-27,"Chengxing Jia, Pengyuan Wang, Ziniu Li, Yi-Chen Li, Zhilong Zhang, Nan Tang, Yang Yu",http://arxiv.org/pdf/2405.17039v1,cs.CL
Recent advances in text embedding: A Comprehensive Review of Top-Performing Methods on the MTEB Benchmark,"Text embedding methods have become increasingly popular in both industrial
and academic fields due to their critical role in a variety of natural language
processing tasks. The significance of universal text embeddings has been
further highlighted with the rise of Large Language Models (LLMs) applications
such as Retrieval-Augmented Systems (RAGs). While previous models have
attempted to be general-purpose, they often struggle to generalize across tasks
and domains. However, recent advancements in training data quantity, quality
and diversity; synthetic data generation from LLMs as well as using LLMs as
backbones encourage great improvements in pursuing universal text embeddings.
In this paper, we provide an overview of the recent advances in universal text
embedding models with a focus on the top performing text embeddings on Massive
Text Embedding Benchmark (MTEB). Through detailed comparison and analysis, we
highlight the key contributions and limitations in this area, and propose
potentially inspiring future research directions.",2024-05-27,Hongliu Cao,http://arxiv.org/pdf/2406.01607v2,cs.CL
Vision-and-Language Navigation Generative Pretrained Transformer,"In the Vision-and-Language Navigation (VLN) field, agents are tasked with
navigating real-world scenes guided by linguistic instructions. Enabling the
agent to adhere to instructions throughout the process of navigation represents
a significant challenge within the domain of VLN. To address this challenge,
common approaches often rely on encoders to explicitly record past locations
and actions, increasing model complexity and resource consumption. Our
proposal, the Vision-and-Language Navigation Generative Pretrained Transformer
(VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory
sequence dependencies, bypassing the need for historical encoding modules. This
method allows for direct historical information access through trajectory
sequence, enhancing efficiency. Furthermore, our model separates the training
process into offline pre-training with imitation learning and online
fine-tuning with reinforcement learning. This distinction allows for more
focused training objectives and improved performance. Performance assessments
on the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art
encoder-based models.",2024-05-27,Wen Hanlin,http://arxiv.org/pdf/2405.16994v1,cs.CL
The Multi-Range Theory of Translation Quality Measurement: MQM scoring models and Statistical Quality Control,"The year 2024 marks the 10th anniversary of the Multidimensional Quality
Metrics (MQM) framework for analytic translation quality evaluation. The MQM
error typology has been widely used by practitioners in the translation and
localization industry and has served as the basis for many derivative projects.
The annual Conference on Machine Translation (WMT) shared tasks on both human
and automatic translation quality evaluations used the MQM error typology.
  The metric stands on two pillars: error typology and the scoring model. The
scoring model calculates the quality score from annotation data, detailing how
to convert error type and severity counts into numeric scores to determine if
the content meets specifications. Previously, only the raw scoring model had
been published. This April, the MQM Council published the Linear Calibrated
Scoring Model, officially presented herein, along with the Non-Linear Scoring
Model, which had not been published before.
  This paper details the latest MQM developments and presents a universal
approach to translation quality measurement across three sample size ranges. It
also explains why Statistical Quality Control should be used for very small
sample sizes, starting from a single sentence.",2024-05-27,"Arle Lommel, Serge Gladkoff, Alan Melby, Sue Ellen Wright, Ingemar Strandvik, Katerina Gasova, Angelika Vaasa, Andy Benzo, Romina Marazzato Sparano, Monica Foresi, Johani Innis, Lifeng Han, Goran Nenadic",http://arxiv.org/pdf/2405.16969v5,cs.CL
Exploring the LLM Journey from Cognition to Expression with Linear Representations,"This paper presents an in-depth examination of the evolution and interplay of
cognitive and expressive capabilities in large language models (LLMs), with a
specific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese
and English) LLM series. We define and explore the model's cognitive and
expressive capabilities through linear representations across three critical
phases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning
from Human Feedback (RLHF). Cognitive capability is defined as the quantity and
quality of information conveyed by the neuron output vectors within the
network, similar to the neural signal processing in human cognition. Expressive
capability is defined as the model's capability to produce word-level output.
Our findings unveil a sequential development pattern, where cognitive abilities
are largely established during Pretraining, whereas expressive abilities
predominantly advance during SFT and RLHF. Statistical analyses confirm a
significant correlation between the two capabilities, suggesting that cognitive
capacity may limit expressive potential. The paper also explores the
theoretical underpinnings of these divergent developmental trajectories and
their connection to the LLMs' architectural design. Moreover, we evaluate
various optimization-independent strategies, such as few-shot learning and
repeated sampling, which bridge the gap between cognitive and expressive
capabilities. This research reveals the potential connection between the hidden
space and the output space, contributing valuable insights into the
interpretability and controllability of their training processes.",2024-05-27,"Yuzi Yan, Jialian Li, Yipin Zhang, Dong Yan",http://arxiv.org/pdf/2405.16964v2,cs.CL
Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning,"Retrieval-Augmented Generation (RAG) offers a cost-effective approach to
injecting real-time knowledge into large language models (LLMs). Nevertheless,
constructing and validating high-quality knowledge repositories require
considerable effort. We propose a pre-retrieval framework named Pseudo-Graph
Retrieval-Augmented Generation (PG-RAG), which conceptualizes LLMs as students
by providing them with abundant raw reading materials and encouraging them to
engage in autonomous reading to record factual information in their own words.
The resulting concise, well-organized mental indices are interconnected through
common topics or complementary facts to form a pseudo-graph database. During
the retrieval phase, PG-RAG mimics the human behavior in flipping through
notes, identifying fact paths and subsequently exploring the related contexts.
Adhering to the principle of the path taken by many is the best, it integrates
highly corroborated fact paths to provide a structured and refined sub-graph
assisting LLMs. We validated PG-RAG on three specialized question-answering
datasets. In single-document tasks, PG-RAG significantly outperformed the
current best baseline, KGP-LLaMA, across all key evaluation metrics, with an
average overall performance improvement of 11.6%. Specifically, its BLEU score
increased by approximately 14.3%, and the QE-F1 metric improved by 23.7%. In
multi-document scenarios, the average metrics of PG-RAG were at least 2.35%
higher than the best baseline. Notably, the BLEU score and QE-F1 metric showed
stable improvements of around 7.55% and 12.75%, respectively. Our code:
https://github.com/IAAR-Shanghai/PGRAG.",2024-05-27,"Xun Liang, Simin Niu, Zhiyu li, Sensen Zhang, Shichao Song, Hanyu Wang, Jiawei Yang, Feiyu Xiong, Bo Tang, Chenyang Xi",http://arxiv.org/pdf/2405.16933v1,cs.CL
VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models,"While large multi-modal models (LMMs) have exhibited impressive capabilities
across diverse tasks, their effectiveness in handling complex tasks has been
limited by the prevailing single-step reasoning paradigm. To this end, this
paper proposes VoCoT, a multi-step Visually grounded object-centric
Chain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is
characterized by two key features: (1) object-centric reasoning paths that
revolve around cross-modal shared object-level information, and (2) visually
grounded representation of object concepts in a multi-modal interleaved and
aligned manner, which effectively bridges the modality gap within LMMs during
long-term generation. To adapt LMMs in reasoning with VoCoT, we further
construct an instruction-tuning dataset. By combining VoCoT with the prevalent
open-source LMM architectures, we develop a VoCoT-based model, VolCano. With
only 7B parameters and limited input image resolution, VolCano demonstrates
excellent performance across various scenarios. In benchmarks like CLEVR and
EmbSpatial, which highly require complex reasoning capabilities, VolCano
outperforms SOTA models, including powerful GPT-4V. Related code, data and
models are released in https://github.com/RupertLuo/VoCoT.",2024-05-27,"Zejun Li, Ruipu Luo, Jiwen Zhang, Minghui Qiu, Xuanjing Huang, Zhongyu Wei",http://arxiv.org/pdf/2405.16919v3,cs.CL
Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?,"We posit that large language models (LLMs) should be capable of expressing
their intrinsic uncertainty in natural language. For example, if the LLM is
equally likely to output two contradicting answers to the same question, then
its generated response should reflect this uncertainty by hedging its answer
(e.g., ""I'm not sure, but I think...""). We formalize faithful response
uncertainty based on the gap between the model's intrinsic confidence in the
assertions it makes and the decisiveness by which they are conveyed. This
example-level metric reliably indicates whether the model reflects its
uncertainty, as it penalizes both excessive and insufficient hedging. We
evaluate a variety of aligned LLMs at faithfully communicating uncertainty on
several knowledge-intensive question answering tasks. Our results provide
strong evidence that modern LLMs are poor at faithfully conveying their
uncertainty, and that better alignment is necessary to improve their
trustworthiness.",2024-05-27,"Gal Yona, Roee Aharoni, Mor Geva",http://arxiv.org/pdf/2405.16908v2,cs.CL
"Match, Compare, or Select? An Investigation of Large Language Models for Entity Matching","Entity matching (EM) is a critical step in entity resolution (ER). Recently,
entity matching based on large language models (LLMs) has shown great promise.
However, current LLM-based entity matching approaches typically follow a binary
matching paradigm that ignores the global consistency among record
relationships. In this paper, we investigate various methodologies for
LLM-based entity matching that incorporate record interactions from different
perspectives. Specifically, we comprehensively compare three representative
strategies: matching, comparing, and selecting, and analyze their respective
advantages and challenges in diverse scenarios. Based on our findings, we
further design a compound entity matching framework (ComEM) that leverages the
composition of multiple strategies and LLMs. ComEM benefits from the advantages
of different sides and achieves improvements in both effectiveness and
efficiency. Experimental results on 8 ER datasets and 10 LLMs verify the
superiority of incorporating record interactions through the selecting
strategy, as well as the further cost-effectiveness brought by ComEM.",2024-05-27,"Tianshu Wang, Xiaoyang Chen, Hongyu Lin, Xuanang Chen, Xianpei Han, Hao Wang, Zhenyu Zeng, Le Sun",http://arxiv.org/pdf/2405.16884v3,cs.CL
Multiple Heads are Better than One: Mixture of Modality Knowledge Experts for Entity Representation Learning,"Learning high-quality multi-modal entity representations is an important goal
of multi-modal knowledge graph (MMKG) representation learning, which can
enhance reasoning tasks within the MMKGs, such as MMKG completion (MMKGC). The
main challenge is to collaboratively model the structural information concealed
in massive triples and the multi-modal features of the entities. Existing
methods focus on crafting elegant entity-wise multi-modal fusion strategies,
yet they overlook the utilization of multi-perspective features concealed
within the modalities under diverse relational contexts. To address this issue,
we introduce a novel framework with Mixture of Modality Knowledge experts
(MoMoK for short) to learn adaptive multi-modal entity representations for
better MMKGC. We design relation-guided modality knowledge experts to acquire
relation-aware modality embeddings and integrate the predictions from
multi-modalities to achieve joint decisions. Additionally, we disentangle the
experts by minimizing their mutual information. Experiments on four public MMKG
benchmarks demonstrate the outstanding performance of MoMoK under complex
scenarios.",2024-05-27,"Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Wen Zhang, Huajun Chen",http://arxiv.org/pdf/2405.16869v4,cs.CL
Can We Trust LLMs? Mitigate Overconfidence Bias in LLMs through Knowledge Transfer,"The study explores mitigating overconfidence bias in LLMs to improve their
reliability. We introduce a knowledge transfer (KT) method utilizing chain of
thoughts, where ""big"" LLMs impart knowledge to ""small"" LLMs via detailed,
sequential reasoning paths. This method uses advanced reasoning of larger
models to fine-tune smaller models, enabling them to produce more accurate
predictions with calibrated confidence. Experimental evaluation using
multiple-choice questions and sentiment analysis across diverse datasets
demonstrated the KT method's superiority over the vanilla and question-answer
pair (QA) fine-tuning methods. The most significant improvement in three key
metrics, where the KT method outperformed the vanilla and QA methods by an
average of 55.3% and 43.1%, respectively. These findings underscore the KT
method's potential in enhancing model trustworthiness and accuracy, offering
precise outputs with well-matched confidence levels across various contexts.",2024-05-27,"Haoyan Yang, Yixuan Wang, Xingyin Xu, Hanyuan Zhang, Yirong Bian",http://arxiv.org/pdf/2405.16856v1,cs.CL
On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability,"Autoregressively trained transformers have brought a profound revolution to
the world, especially with their in-context learning (ICL) ability to address
downstream tasks. Recently, several studies suggest that transformers learn a
mesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely,
the forward pass of the trained transformer is equivalent to optimizing an
inner objective function in-context. However, whether the practical non-convex
training dynamics will converge to the ideal mesa-optimizer is still unclear.
Towards filling this gap, we investigate the non-convex dynamics of a one-layer
linear causal self-attention model autoregressively trained by gradient flow,
where the sequences are generated by an AR process $x_{t+1} = W x_t$. First,
under a certain condition of data distribution, we prove that an
autoregressively trained transformer learns $W$ by implementing one step of
gradient descent to minimize an ordinary least squares (OLS) problem
in-context. It then applies the learned $\widehat{W}$ for next-token
prediction, thereby verifying the mesa-optimization hypothesis. Next, under the
same data conditions, we explore the capability limitations of the obtained
mesa-optimizer. We show that a stronger assumption related to the moments of
data is the sufficient and necessary condition that the learned mesa-optimizer
recovers the distribution. Besides, we conduct exploratory analyses beyond the
first data condition and prove that generally, the trained transformer will not
perform vanilla gradient descent for the OLS problem. Finally, our simulation
results verify the theoretical results.",2024-05-27,"Chenyu Zheng, Wei Huang, Rongzhen Wang, Guoqiang Wu, Jun Zhu, Chongxuan Li",http://arxiv.org/pdf/2405.16845v2,cs.CL
Perturbation-Restrained Sequential Model Editing,"Model editing is an emerging field that focuses on updating the knowledge
embedded within large language models (LLMs) without extensive retraining.
However, current model editing methods significantly compromise the general
abilities of LLMs as the number of edits increases, and this trade-off poses a
substantial challenge to the continual learning of LLMs. In this paper, we
first theoretically analyze that the factor affecting the general abilities in
sequential model editing lies in the condition number of the edited matrix. The
condition number of a matrix represents its numerical sensitivity, and
therefore can be used to indicate the extent to which the original knowledge
associations stored in LLMs are perturbed after editing. Subsequently,
statistical findings demonstrate that the value of this factor becomes larger
as the number of edits increases, thereby exacerbating the deterioration of
general abilities. To this end, a framework termed Perturbation Restraint on
Upper bouNd for Editing (PRUNE) is proposed, which applies the condition number
restraints in sequential editing. These restraints can lower the upper bound on
perturbation to edited models, thus preserving the general abilities.
Systematically, we conduct experiments employing three editing methods on three
LLMs across four downstream tasks. The results show that PRUNE can preserve
general abilities while maintaining the editing performance effectively in
sequential model editing. The code are available at
https://github.com/mjy1111/PRUNE.",2024-05-27,"Jun-Yu Ma, Hong Wang, Hao-Xiang Xu, Zhen-Hua Ling, Jia-Chen Gu",http://arxiv.org/pdf/2405.16821v3,cs.CL
Performance evaluation of Reddit Comments using Machine Learning and Natural Language Processing methods in Sentiment Analysis,"Sentiment analysis, an increasingly vital field in both academia and
industry, plays a pivotal role in machine learning applications, particularly
on social media platforms like Reddit. However, the efficacy of sentiment
analysis models is hindered by the lack of expansive and fine-grained emotion
datasets. To address this gap, our study leverages the GoEmotions dataset,
comprising a diverse range of emotions, to evaluate sentiment analysis methods
across a substantial corpus of 58,000 comments. Distinguished from prior
studies by the Google team, which limited their analysis to only two models,
our research expands the scope by evaluating a diverse array of models. We
investigate the performance of traditional classifiers such as Naive Bayes and
Support Vector Machines (SVM), as well as state-of-the-art transformer-based
models including BERT, RoBERTa, and GPT. Furthermore, our evaluation criteria
extend beyond accuracy to encompass nuanced assessments, including hierarchical
classification based on varying levels of granularity in emotion
categorization. Additionally, considerations such as computational efficiency
are incorporated to provide a comprehensive evaluation framework. Our findings
reveal that the RoBERTa model consistently outperforms the baseline models,
demonstrating superior accuracy in fine-grained sentiment classification tasks.
This underscores the substantial potential and significance of the RoBERTa
model in advancing sentiment analysis capabilities.",2024-05-27,"Xiaoxia Zhang, Xiuyuan Qi, Zixin Teng",http://arxiv.org/pdf/2405.16810v2,cs.CL
Entity Alignment with Noisy Annotations from Large Language Models,"Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying
equivalent entity pairs. While existing methods heavily rely on human-generated
labels, it is prohibitively expensive to incorporate cross-domain experts for
annotation in real-world scenarios. The advent of Large Language Models (LLMs)
presents new avenues for automating EA with annotations, inspired by their
comprehensive capability to process semantic information. However, it is
nontrivial to directly apply LLMs for EA since the annotation space in
real-world KGs is large. LLMs could also generate noisy labels that may mislead
the alignment. To this end, we propose a unified framework, LLM4EA, to
effectively leverage LLMs for EA. Specifically, we design a novel active
learning policy to significantly reduce the annotation space by prioritizing
the most valuable entities based on the entire inter-KG and intra-KG structure.
Moreover, we introduce an unsupervised label refiner to continuously enhance
label accuracy through in-depth probabilistic reasoning. We iteratively
optimize the policy based on the feedback from a base EA model. Extensive
experiments demonstrate the advantages of LLM4EA on four benchmark datasets in
terms of effectiveness, robustness, and efficiency. Codes are available via
https://github.com/chensyCN/llm4ea_official.",2024-05-27,"Shengyuan Chen, Qinggang Zhang, Junnan Dong, Wen Hua, Qing Li, Xiao Huang",http://arxiv.org/pdf/2405.16806v2,cs.CL
AutoPSV: Automated Process-Supervised Verifier,"In this work, we propose a novel method named \textbf{Auto}mated
\textbf{P}rocess-\textbf{S}upervised \textbf{V}erifier
(\textbf{\textsc{AutoPSV}}) to enhance the reasoning capabilities of large
language models (LLMs) by automatically annotating the reasoning steps.
\textsc{AutoPSV} begins by training a verification model on the correctness of
final answers, enabling it to generate automatic process annotations. This
verification model assigns a confidence score to each reasoning step,
indicating the probability of arriving at the correct final answer from that
point onward. We detect relative changes in the verification's confidence
scores across reasoning steps to automatically annotate the reasoning process,
enabling error detection even in scenarios where ground truth answers are
unavailable. This alleviates the need for numerous manual annotations or the
high computational costs associated with model-induced annotation approaches.
We experimentally validate that the step-level confidence changes learned by
the verification model trained on the final answer correctness can effectively
identify errors in the reasoning steps. We demonstrate that the verification
model, when trained on process annotations generated by \textsc{AutoPSV},
exhibits improved performance in selecting correct answers from multiple
LLM-generated outputs. Notably, we achieve substantial improvements across five
datasets in mathematics and commonsense reasoning. The source code of
\textsc{AutoPSV} is available at \url{https://github.com/rookie-joe/AutoPSV}.",2024-05-27,"Jianqiao Lu, Zhiyang Dou, Hongru Wang, Zeyu Cao, Jianbo Dai, Yingjia Wan, Zhijiang Guo",http://arxiv.org/pdf/2405.16802v4,cs.CL
REVECA: Adaptive Planning and Trajectory-based Validation in Cooperative Language Agents using Information Relevance and Relative Proximity,"We address the challenge of multi-agent cooperation, where agents achieve a
common goal by cooperating with decentralized agents under complex partial
observations. Existing cooperative agent systems often struggle with
efficiently processing continuously accumulating information, managing globally
suboptimal planning due to lack of consideration of collaborators, and
addressing false planning caused by environmental changes introduced by other
collaborators. To overcome these challenges, we propose the RElevance,
Proximity, and Validation-Enhanced Cooperative Language Agent (REVECA), a novel
cognitive architecture powered by GPT-4o-mini. REVECA enables efficient memory
management, optimal planning, and cost-effective prevention of false planning
by leveraging Relevance Estimation, Adaptive Planning, and Trajectory-based
Validation. Extensive experimental results demonstrate REVECA's superiority
over existing methods across various benchmarks, while a user study reveals its
potential for achieving trustworthy human-AI cooperation.",2024-05-27,"SeungWon Seo, SeongRae Noh, Junhyeok Lee, SooBin Lim, Won Hee Lee, HyeongYeop Kang",http://arxiv.org/pdf/2405.16751v2,cs.CL
Large Scale Knowledge Washing,"Large language models show impressive abilities in memorizing world
knowledge, which leads to concerns regarding memorization of private
information, toxic or sensitive knowledge, and copyrighted content. We
introduce the problem of Large Scale Knowledge Washing, focusing on unlearning
an extensive amount of factual knowledge. Previous unlearning methods usually
define the reverse loss and update the model via backpropagation, which may
affect the model's fluency and reasoning ability or even destroy the model due
to extensive training with the reverse loss. Existing works introduce
additional data from downstream tasks to prevent the model from losing
capabilities, which requires downstream task awareness. Controlling the
tradeoff of unlearning and maintaining existing capabilities is also
challenging. To this end, we propose LAW (Large Scale Washing) to update the
MLP layers in decoder-only large language models to perform knowledge washing,
as inspired by model editing methods and based on the hypothesis that knowledge
and reasoning are disentanglable. We derive a new objective with the knowledge
to be unlearned to update the weights of certain MLP layers. Experimental
results demonstrate the effectiveness of LAW in forgetting target knowledge
while maintaining reasoning ability. The code will be open-sourced at
https://github.com/wangyu-ustc/LargeScaleWashing.",2024-05-26,"Yu Wang, Ruihan Wu, Zexue He, Xiusi Chen, Julian McAuley",http://arxiv.org/pdf/2405.16720v3,cs.CL
Crafting Interpretable Embeddings by Asking LLMs Questions,"Large language models (LLMs) have rapidly improved text embeddings for a
growing array of natural-language processing tasks. However, their opaqueness
and proliferation into scientific domains such as neuroscience have created a
growing need for interpretability. Here, we ask whether we can obtain
interpretable embeddings through LLM prompting. We introduce question-answering
embeddings (QA-Emb), embeddings where each feature represents an answer to a
yes/no question asked to an LLM. Training QA-Emb reduces to selecting a set of
underlying questions rather than learning model weights.
  We use QA-Emb to flexibly generate interpretable models for predicting fMRI
voxel responses to language stimuli. QA-Emb significantly outperforms an
established interpretable baseline, and does so while requiring very few
questions. This paves the way towards building flexible feature spaces that can
concretize and evaluate our understanding of semantic brain representations. We
additionally find that QA-Emb can be effectively approximated with an efficient
model, and we explore broader applications in simple NLP tasks.",2024-05-26,"Vinamra Benara, Chandan Singh, John X. Morris, Richard Antonello, Ion Stoica, Alexander G. Huth, Jianfeng Gao",http://arxiv.org/pdf/2405.16714v1,cs.CL
Zamba: A Compact 7B SSM Hybrid Model,"In this technical report, we present Zamba, a novel 7B SSM-transformer hybrid
model which achieves competitive performance against leading open-weight models
at a comparable scale. Zamba is trained on 1T tokens from openly available
datasets and is the best non-transformer model at this scale. Zamba pioneers a
unique architecture combining a Mamba backbone with a single shared attention
module, thus obtaining the benefits of attention at minimal parameter cost. Due
to its architecture, Zamba is significantly faster at inference than comparable
transformer models and requires substantially less memory for generation of
long sequences. Zamba is pretrained in two phases: the first phase is based on
existing web datasets, while the second one consists of annealing the model
over high-quality instruct and synthetic datasets, and is characterized by a
rapid learning rate decay. We open-source the weights and all checkpoints for
Zamba, through both phase 1 and annealing phases.",2024-05-26,"Paolo Glorioso, Quentin Anthony, Yury Tokpanov, James Whittington, Jonathan Pilault, Adam Ibrahim, Beren Millidge",http://arxiv.org/pdf/2405.16712v1,cs.CL
SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation,"Citing pertinent literature is pivotal to writing and reviewing a scientific
document. Existing techniques mainly focus on the local context or the global
context for recommending citations but fail to consider the actual human
citation behaviour. We propose SymTax, a three-stage recommendation
architecture that considers both the local and the global context, and
additionally the taxonomical representations of query-candidate tuples and the
Symbiosis prevailing amongst them. SymTax learns to embed the infused
taxonomies in the hyperbolic space and uses hyperbolic separation as a latent
feature to compute query-candidate similarity. We build a novel and large
dataset ArSyTa containing 8.27 million citation contexts and describe the
creation process in detail. We conduct extensive experiments and ablation
studies to demonstrate the effectiveness and design choice of each module in
our framework. Also, combinatorial analysis from our experiments shed light on
the choice of language models (LMs) and fusion embedding, and the inclusion of
section heading as a signal. Our proposed module that captures the symbiotic
relationship solely leads to performance gains of 26.66% and 39.25% in Recall@5
w.r.t. SOTA on ACL-200 and RefSeer datasets, respectively. The complete
framework yields a gain of 22.56% in Recall@5 wrt SOTA on our proposed dataset.
The code and dataset are available at https://github.com/goyalkaraniit/SymTax",2024-05-26,"Karan Goyal, Mayank Goel, Vikram Goyal, Mukesh Mohania",http://arxiv.org/pdf/2406.01606v1,cs.CL
Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories,"Recent studies have indicated that Large Language Models (LLMs) harbor an
inherent understanding of truthfulness, yet often fail to consistently express
it and generate false statements. This gap between ""knowing"" and ""telling""
poses a challenge for ensuring the truthfulness of generated content. Inspired
by recent work on the practice of encoding human-interpretable concepts
linearly within large language models, we treat truthfulness as a specially
linearly encoded concept within LLMs, and introduce Adaptive Activation
Steering (ACT), a tuning-free method that adaptively shifts LLM's activations
in the ""truthful"" direction during inference. ACT addresses diverse categories
of hallucinations by utilizing diverse truthfulness-related steering vectors
and adjusting the steering intensity adaptively. Applied as an add-on across
various models, ACT significantly improves truthfulness in LLaMA ($\uparrow$
142%), LLaMA2 ($\uparrow$ 24%), Alpaca ($\uparrow$ 36%), Vicuna ($\uparrow$
28%), LLaMA2-Chat ($\uparrow$ 19%), and LLaMA3($\uparrow$ 34%). Furthermore, we
verify ACT's scalability across larger models (13B, 33B, 65B), underscoring the
adaptability of ACT to large-scale language models. Our code is available at
https://github.com/tianlwang/ACT.",2024-05-26,"Tianlong Wang, Xianfeng Jiao, Yinghao Zhu, Zhongzhi Chen, Yifan He, Xu Chu, Junyi Gao, Yasha Wang, Liantao Ma",http://arxiv.org/pdf/2406.00034v2,cs.CL
Accurate and Nuanced Open-QA Evaluation Through Textual Entailment,"Open-domain question answering (Open-QA) is a common task for evaluating
large language models (LLMs). However, current Open-QA evaluations are
criticized for the ambiguity in questions and the lack of semantic
understanding in evaluators. Complex evaluators, powered by foundation models
or LLMs and pertaining to semantic equivalence, still deviate from human
judgments by a large margin. We propose to study the entailment relations of
answers to identify more informative and more general system answers, offering
a much closer evaluation to human judgment on both NaturalQuestions and
TriviaQA while being learning-free. The entailment-based evaluation we propose
allows the assignment of bonus or partial marks by quantifying the inference
gap between answers, enabling a nuanced ranking of answer correctness that has
higher AUC than current methods.",2024-05-26,"Peiran Yao, Denilson Barbosa",http://arxiv.org/pdf/2405.16702v1,cs.CL
Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to Multimodal Inputs,"Large Language Models (LLMs) have demonstrated impressive performance on
multimodal tasks, without any multimodal finetuning. They are the building
block for Large Multimodal Models, yet, we still lack a proper understanding of
their success. In this work, we expose frozen LLMs to image, video, audio and
text inputs and analyse their internal representation aiming to understand
their generalization beyond textual inputs.
  Findings. Perceptual tokens (1) are easily distinguishable from textual ones
inside LLMs, with significantly different representations, and complete
translation to textual tokens does not exist. Yet, (2) both perceptual and
textual tokens activate similar LLM weights. Despite being different, (3)
perceptual and textual tokens are implicitly aligned inside LLMs, we call this
the implicit multimodal alignment (IMA), and argue that this is linked to
architectural design, helping LLMs to generalize. This provide more evidence to
believe that the generalization of LLMs to multimodal inputs is mainly due to
their architecture.
  Implications. (1) We find a positive correlation between the implicit
alignment score and the task performance, suggesting that this could act as a
proxy metric for model evaluation and selection. (2) A negative correlation
exists regarding hallucinations, revealing that this problem is mainly due to
misalignment between the internal perceptual and textual representations. (3)
Perceptual tokens change slightly throughout the model, thus, we propose
different approaches to skip computations (e.g. in FFN layers), and
significantly reduce the inference cost. (4) Due to the slowly changing
embeddings across layers, and the high overlap between textual and multimodal
activated weights, we compress LLMs by keeping only 1 subnetwork that works
well across a wide range of multimodal tasks. Paper code:
https://github.com/mshukor/ima-lmms.",2024-05-26,"Mustafa Shukor, Matthieu Cord",http://arxiv.org/pdf/2405.16700v2,cs.CL
gzip Predicts Data-dependent Scaling Laws,"Past work has established scaling laws that predict the performance of a
neural language model (LM) as a function of its parameter count and the number
of tokens it's trained on, enabling optimal allocation of a fixed compute
budget. Are these scaling laws agnostic to training data as some prior work
suggests? We generate training datasets of varying complexities by modulating
the syntactic properties of a PCFG, finding that 1) scaling laws are sensitive
to differences in data complexity and that 2) gzip, a compression algorithm, is
an effective predictor of how data complexity impacts scaling properties. We
propose a new data-dependent scaling law for LM's that accounts for the
training data's gzip-compressibility; its compute-optimal frontier increases in
dataset size preference (over parameter count preference) as training data
becomes harder to compress.",2024-05-26,Rohan Pandey,http://arxiv.org/pdf/2405.16684v1,cs.CL
A Systematic Review of Federated Generative Models,"Federated Learning (FL) has emerged as a solution for distributed systems
that allow clients to train models on their data and only share models instead
of local data. Generative Models are designed to learn the distribution of a
dataset and generate new data samples that are similar to the original data.
Many prior works have tried proposing Federated Generative Models. Using
Federated Learning and Generative Models together can be susceptible to
attacks, and designing the optimal architecture remains challenging.
  This survey covers the growing interest in the intersection of FL and
Generative Models by comprehensively reviewing research conducted from 2019 to
2024. We systematically compare nearly 100 papers, focusing on their FL and
Generative Model methods and privacy considerations. To make this field more
accessible to newcomers, we highlight the state-of-the-art advancements and
identify unresolved challenges, offering insights for future research in this
evolving field.",2024-05-26,"Ashkan Vedadi Gargary, Emiliano De Cristofaro",http://arxiv.org/pdf/2405.16682v1,cs.CL
Triple Preference Optimization: Achieving Better Alignment using a Single Step Optimization,"Reinforcement Learning with Human Feedback (RLHF) enhances the alignment of
Large Language Models (LLMs). However, its limitations have led to the
development of Direct Preference Optimization (DPO), an RL-free approach
designed to overcome these shortcomings. While studies have shown that DPO
improves instruction-following capabilities, it negatively impacts the
reasoning ability of LLMs. Additionally, DPO is highly sensitive to judgment
noise in preference datasets and the size of the training set. Although several
modifications to DPO have been proposed, they still fail to fully resolve these
issues. To address these limitations, we propose Triple Preference Optimization
(TPO), a new preference learning method designed to enhance both reasoning and
instruction-following abilities through one-step optimization. We compare TPO
against DPO and its recent variants using state-of-the-art training setups,
including both base and instruction-tuned models such as Mistral and Llama 3.
Our evaluation covers a comprehensive range of chat-based and reasoning
benchmarks. The results demonstrate that TPO achieves significant improvements
over existing methods without substantially increasing response length across
different dataset sizes. Specifically, TPO outperforms DPO and SimPO by up to
7.0% and 7.3% points on Arena-Hard, 12.2% and 13.3% points on MixEval-Hard,
10.4% and 10.1% points on MMLU-Pro, and 19.0% and 19.2% points on GSM8K,
respectively. Furthermore, TPO achieves these improvements while requiring less
data than DPO.",2024-05-26,"Amir Saeidi, Shivanshu Verma, Aswin RRV, Kashif Rasul, Chitta Baral",http://arxiv.org/pdf/2405.16681v2,cs.CL
Crossmodal ASR Error Correction with Discrete Speech Units,"ASR remains unsatisfactory in scenarios where the speaking style diverges
from that used to train ASR systems, resulting in erroneous transcripts. To
address this, ASR Error Correction (AEC), a post-ASR processing approach, is
required. In this work, we tackle an understudied issue: the Low-Resource
Out-of-Domain (LROOD) problem, by investigating crossmodal AEC on very limited
downstream data with 1-best hypothesis transcription. We explore pre-training
and fine-tuning strategies and uncover an ASR domain discrepancy phenomenon,
shedding light on appropriate training schemes for LROOD data. Moreover, we
propose the incorporation of discrete speech units to align with and enhance
the word embeddings for improving AEC quality. Results from multiple corpora
and several evaluation metrics demonstrate the feasibility and efficacy of our
proposed AEC approach on LROOD data as well as its generalizability and
superiority on large-scale data. Finally, a study on speech emotion recognition
confirms that our model produces ASR error-robust transcripts suitable for
downstream applications.",2024-05-26,"Yuanchao Li, Pinzhen Chen, Peter Bell, Catherine Lai",http://arxiv.org/pdf/2405.16677v2,cs.CL
Low-resourced Languages and Online Knowledge Repositories: A Need-Finding Study,"Online Knowledge Repositories (OKRs) like Wikipedia offer communities a way
to share and preserve information about themselves and their ways of living.
However, for communities with low-resourced languages -- including most African
communities -- the quality and volume of content available are often
inadequate. One reason for this lack of adequate content could be that many
OKRs embody Western ways of knowledge preservation and sharing, requiring many
low-resourced language communities to adapt to new interactions. To understand
the challenges faced by low-resourced language contributors on the popular OKR
Wikipedia, we conducted (1) a thematic analysis of Wikipedia forum discussions
and (2) a contextual inquiry study with 14 novice contributors. We focused on
three Ethiopian languages: Afan Oromo, Amharic, and Tigrinya. Our analysis
revealed several recurring themes; for example, contributors struggle to find
resources to corroborate their articles in low-resourced languages, and
language technology support, like translation systems and spellcheck, result in
several errors that waste contributors' time. We hope our study will support
designers in making online knowledge repositories accessible to low-resourced
language speakers.",2024-05-26,"Hellina Hailu Nigatu, John Canny, Sarah E. Chasins",http://arxiv.org/pdf/2405.16669v1,cs.CL
Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models,"Security concerns related to Large Language Models (LLMs) have been
extensively explored, yet the safety implications for Multimodal Large Language
Models (MLLMs), particularly in medical contexts (MedMLLMs), remain
insufficiently studied. This paper delves into the underexplored security
vulnerabilities of MedMLLMs, especially when deployed in clinical environments
where the accuracy and relevance of question-and-answer interactions are
critically tested against complex medical challenges. By combining existing
clinical medical data with atypical natural phenomena, we define the mismatched
malicious attack (2M-attack) and introduce its optimized version, known as the
optimized mismatched malicious attack (O2M-attack or 2M-optimization). Using
the voluminous 3MAD dataset that we construct, which covers a wide range of
medical image modalities and harmful medical scenarios, we conduct a
comprehensive analysis and propose the MCM optimization method, which
significantly enhances the attack success rate on MedMLLMs. Evaluations with
this dataset and attack methods, including white-box attacks on LLaVA-Med and
transfer attacks (black-box) on four other SOTA models, indicate that even
MedMLLMs designed with enhanced security features remain vulnerable to security
breaches. Our work underscores the urgent need for a concerted effort to
implement robust security measures and enhance the safety and efficacy of
open-source MedMLLMs, particularly given the potential severity of jailbreak
attacks and other malicious or clinically significant exploits in medical
settings. Our code is available at https://github.com/dirtycomputer/O2M_attack.",2024-05-26,"Xijie Huang, Xinyuan Wang, Hantao Zhang, Yinghao Zhu, Jiawen Xi, Jingkun An, Hao Wang, Hao Liang, Chengwei Pan",http://arxiv.org/pdf/2405.20775v2,cs.CL
Conjunctive categorial grammars and Lambek grammars with additives,"A new family of categorial grammars is proposed, defined by enriching basic
categorial grammars with a conjunction operation. It is proved that the
formalism obtained in this way has the same expressive power as conjunctive
grammars, that is, context-free grammars enhanced with conjunction. It is also
shown that categorial grammars with conjunction can be naturally embedded into
the Lambek calculus with conjunction and disjunction operations. This further
implies that a certain NP-complete set can be defined in the Lambek calculus
with conjunction. We also show how to handle some subtle issues connected with
the empty string. Finally, we prove that a language generated by a conjunctive
grammar can be described by a Lambek grammar with disjunction (but without
conjunction).",2024-05-26,"Stepan L. Kuznetsov, Alexander Okhotin",http://arxiv.org/pdf/2405.16662v1,cs.CL
RLSF: Reinforcement Learning via Symbolic Feedback,"Reinforcement Learning with Human Feedback (RLHF) is considered a standard
approach to fine-tuning Large Language Models (LLMs). However, such methods
often face limitations such as unsound black-box reward models, difficulties in
collecting human preference data, and the reliance on sparse scalar rewards.
These methods often fall short when applied to tasks that require complex
domain-specific understanding.
  To address these challenges, we propose a new fine-tuning paradigm we refer
to as Reinforcement Learning via Symbolic Feedback (RLSF), which aims to
improve domain-specific understanding of LLMs more effectively than traditional
reward signals. In the RLSF setting, the LLM being fine-tuned is considered an
RL agent, while the environment is allowed access to reasoning or domain
knowledge tools (e.g., solvers, provers, algebra systems, or knowledge bases).
Crucially, in RLSF, these reasoning tools can provide feedback to the LLMs via
poly-sized certificates (e.g., proofs), that characterize errors in the
LLM-generated object with respect to some correctness specification. As a
bonus, our RLSF approach does not require the reasoning systems we use to be
differentiable. The ability of RLSF-based fine-tuning to leverage
certificate-generating symbolic tools enables sound fine-grained (token-level)
reward signals to LLMs, and thus addresses the limitations of traditional
reward models mentioned above.
  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs
outperforms traditional approaches on five different applications, namely,
program synthesis from natural language pseudo-code to programming language,
three chemistry tasks, and solving the Game of 24. A takeaway is that
fine-tuning via RLSF enables relatively smaller LLMs to significantly
outperform closed-source models that are orders of magnitude larger (e.g.,
GPT-4).",2024-05-26,"Piyush Jha, Prithwish Jana, Pranavkrishna Suresh, Arnav Arora, Vijay Ganesh",http://arxiv.org/pdf/2405.16661v2,cs.CL
A Survey of Multimodal Large Language Model from A Data-centric Perspective,"Multimodal large language models (MLLMs) enhance the capabilities of standard
large language models by integrating and processing data from multiple
modalities, including text, vision, audio, video, and 3D environments. Data
plays a pivotal role in the development and refinement of these models. In this
survey, we comprehensively review the literature on MLLMs from a data-centric
perspective. Specifically, we explore methods for preparing multimodal data
during the pretraining and adaptation phases of MLLMs. Additionally, we analyze
the evaluation methods for the datasets and review the benchmarks for
evaluating MLLMs. Our survey also outlines potential future research
directions. This work aims to provide researchers with a detailed understanding
of the data-driven aspects of MLLMs, fostering further exploration and
innovation in this field.",2024-05-26,"Tianyi Bai, Hao Liang, Binwang Wan, Yanran Xu, Xi Li, Shiyu Li, Ling Yang, Bozhou Li, Yifan Wang, Bin Cui, Ping Huang, Jiulong Shan, Conghui He, Binhang Yuan, Wentao Zhang",http://arxiv.org/pdf/2405.16640v2,cs.CL
Compressing Lengthy Context With UltraGist,"Compressing lengthy context is a critical but technically challenging
problem. In this paper, we propose a new method called UltraGist, which is
distinguished for its high-quality compression of lengthy context due to the
innovative design of the compression and learning algorithm. UltraGist brings
forth the following important benefits. Firstly, it notably contributes to the
flexibility of compression, as it can be effectively learned to support a broad
range of context lengths and compression ratios. Secondly, it helps to produce
fine-grained compression for the lengthy context, where each small segment of
the context is progressively processed on top of a tailored cross-attention
mechanism. Thirdly, it makes the training process sample-efficient and thus
maximizes the use of training data. Finally, it facilitates the efficient
running of compression for dynamic context, as the compression result can be
progressively generated and hence incrementally updated. UltraGist is evaluated
on a wide variety of tasks associated with lengthy context, such as document QA
and summarization, few-shot learning, multi-session conversation, et al. Whilst
the existing methods fail to handle these challenging scenarios, our approach
is able to preserve a near-lossless compression performance throughout all the
evaluations. Our data, model, and code have been released at
\url{https://github.com/namespace-Pt/UltraGist}.",2024-05-26,"Peitian Zhang, Zheng Liu, Shitao Xiao, Ninglu Shao, Qiwei Ye, Zhicheng Dou",http://arxiv.org/pdf/2405.16635v2,cs.CL
Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models,"Fake news detection plays a crucial role in protecting social media users and
maintaining a healthy news ecosystem. Among existing works, comment-based fake
news detection methods are empirically shown as promising because comments
could reflect users' opinions, stances, and emotions and deepen models'
understanding of fake news. Unfortunately, due to exposure bias and users'
different willingness to comment, it is not easy to obtain diverse comments in
reality, especially for early detection scenarios. Without obtaining the
comments from the ``silent'' users, the perceived opinions may be incomplete,
subsequently affecting news veracity judgment. In this paper, we explore the
possibility of finding an alternative source of comments to guarantee the
availability of diverse comments, especially those from silent users.
Specifically, we propose to adopt large language models (LLMs) as a user
simulator and comment generator, and design GenFEND, a generated
feedback-enhanced detection framework, which generates comments by prompting
LLMs with diverse user profiles and aggregating generated comments from
multiple subpopulation groups. Experiments demonstrate the effectiveness of
GenFEND and further analysis shows that the generated comments cover more
diverse users and could even be more effective than actual comments.",2024-05-26,"Qiong Nan, Qiang Sheng, Juan Cao, Beizhe Hu, Danding Wang, Jintao Li",http://arxiv.org/pdf/2405.16631v1,cs.CL
The global landscape of academic guidelines for generative AI and Large Language Models,"The integration of Generative Artificial Intelligence (GAI) and Large
Language Models (LLMs) in academia has spurred a global discourse on their
potential pedagogical benefits and ethical considerations. Positive reactions
highlight some potential, such as collaborative creativity, increased access to
education, and empowerment of trainers and trainees. However, negative
reactions raise concerns about ethical complexities, balancing innovation and
academic integrity, unequal access, and misinformation risks. Through a
systematic survey and text-mining-based analysis of global and national
directives, insights from independent research, and eighty university-level
guidelines, this study provides a nuanced understanding of the opportunities
and challenges posed by GAI and LLMs in education. It emphasizes the importance
of balanced approaches that harness the benefits of these technologies while
addressing ethical considerations and ensuring equitable access and educational
outcomes. The paper concludes with recommendations for fostering responsible
innovation and ethical practices to guide the integration of GAI and LLMs in
academia.",2024-05-26,"Junfeng Jiao, Saleh Afroogh, Kevin Chen, David Atkinson, Amit Dhurandhar",http://arxiv.org/pdf/2406.18842v3,cs.CL
MentalManip: A Dataset For Fine-grained Analysis of Mental Manipulation in Conversations,"Mental manipulation, a significant form of abuse in interpersonal
conversations, presents a challenge to identify due to its context-dependent
and often subtle nature. The detection of manipulative language is essential
for protecting potential victims, yet the field of Natural Language Processing
(NLP) currently faces a scarcity of resources and research on this topic. Our
study addresses this gap by introducing a new dataset, named ${\rm M{\small
ental}M{\small anip}}$, which consists of $4,000$ annotated movie dialogues.
This dataset enables a comprehensive analysis of mental manipulation,
pinpointing both the techniques utilized for manipulation and the
vulnerabilities targeted in victims. Our research further explores the
effectiveness of leading-edge models in recognizing manipulative dialogue and
its components through a series of experiments with various configurations. The
results demonstrate that these models inadequately identify and categorize
manipulative content. Attempts to improve their performance by fine-tuning with
existing datasets on mental health and toxicity have not overcome these
limitations. We anticipate that ${\rm M{\small ental}M{\small anip}}$ will
stimulate further research, leading to progress in both understanding and
mitigating the impact of mental manipulation in conversations.",2024-05-26,"Yuxin Wang, Ivory Yang, Saeed Hassanpour, Soroush Vosoughi",http://arxiv.org/pdf/2405.16584v1,cs.CL
Automatically Generating Numerous Context-Driven SFT Data for LLMs across Diverse Granularity,"Constructing high-quality query-response pairs from custom corpus is crucial
for supervised fine-tuning (SFT) large language models (LLMs) in many
applications, like creating domain-specific AI assistants or roleplaying
agents. However, sourcing this data through human annotation is costly, and
existing automated methods often fail to capture the diverse range of
contextual granularity and tend to produce homogeneous data. To tackle these
issues, we introduce a novel method named AugCon, capable of automatically
generating context-driven SFT data across multiple levels of granularity with
high diversity, quality and fidelity. AugCon begins by generating queries using
the Context-Split-Tree (CST), an innovative approach for recursively deriving
queries and splitting context to cover full granularity. Then, we train a
scorer through contrastive learning to collaborate with CST to rank and refine
queries. Finally, a synergistic integration of self-alignment and
self-improving is introduced to obtain high-fidelity responses.
  Extensive experiments are conducted incorporating both human and automatic
evaluations, encompassing a test scenario and four widely-used benchmarks in
English and Chinese. The results highlight the significant advantages of AugCon
in producing high diversity, quality, and fidelity SFT data against several
state-of-the-art methods. All of our code, dataset, and fine-tuned model will
be available at: https://github.com/quanshr/AugCon.",2024-05-26,Shanghaoran Quan,http://arxiv.org/pdf/2405.16579v1,cs.CL
A Preliminary Empirical Study on Prompt-based Unsupervised Keyphrase Extraction,"Pre-trained large language models can perform natural language processing
downstream tasks by conditioning on human-designed prompts. However, a
prompt-based approach often requires ""prompt engineering"" to design different
prompts, primarily hand-crafted through laborious trial and error, requiring
human intervention and expertise. It is a challenging problem when constructing
a prompt-based keyphrase extraction method. Therefore, we investigate and study
the effectiveness of different prompts on the keyphrase extraction task to
verify the impact of the cherry-picked prompts on the performance of extracting
keyphrases. Extensive experimental results on six benchmark keyphrase
extraction datasets and different pre-trained large language models demonstrate
that (1) designing complex prompts may not necessarily be more effective than
designing simple prompts; (2) individual keyword changes in the designed
prompts can affect the overall performance; (3) designing complex prompts
achieve better performance than designing simple prompts when facing long
documents.",2024-05-26,"Mingyang Song, Yi Feng, Liping Jing",http://arxiv.org/pdf/2405.16571v1,cs.CL
SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation,"Existing Large Language Models (LLMs) generate text through unidirectional
autoregressive decoding methods to respond to various user queries. These
methods tend to consider token selection in a simple sequential manner, making
it easy to fall into suboptimal options when encountering uncertain tokens,
referred to as chaotic points in our work. Many chaotic points exist in texts
generated by LLMs, and they often significantly affect the quality of
subsequently generated tokens, which can interfere with LLMs' generation. This
paper proposes Self-Evaluation Decoding, SED, a decoding method for enhancing
model generation. Analogous to the human decision-making process, SED
integrates speculation and evaluation steps into the decoding process, allowing
LLMs to make more careful decisions and thus optimize token selection at
chaotic points. Experimental results across various tasks using different LLMs
demonstrate SED's effectiveness.",2024-05-26,"Ziqin Luo, Haixia Han, Haokun Zhao, Guochao Jiang, Chengyu Du, Tingyun Li, Jiaqing Liang, Deqing Yang, Yanghua Xiao",http://arxiv.org/pdf/2405.16552v1,cs.CL
Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration,"The proliferation of Large Language Models (LLMs) has led to an influx of
AI-generated content (AIGC) on the internet, transforming the corpus of
Information Retrieval (IR) systems from solely human-written to a coexistence
with LLM-generated content. The impact of this surge in AIGC on IR systems
remains an open question, with the primary challenge being the lack of a
dedicated benchmark for researchers. In this paper, we introduce Cocktail, a
comprehensive benchmark tailored for evaluating IR models in this mixed-sourced
data landscape of the LLM era. Cocktail consists of 16 diverse datasets with
mixed human-written and LLM-generated corpora across various text retrieval
tasks and domains. Additionally, to avoid the potential bias from previously
included dataset information in LLMs, we also introduce an up-to-date dataset,
named NQ-UTD, with queries derived from recent events. Through conducting over
1,000 experiments to assess state-of-the-art retrieval models against the
benchmarked datasets in Cocktail, we uncover a clear trade-off between ranking
performance and source bias in neural retrieval models, highlighting the
necessity for a balanced approach in designing future IR systems. We hope
Cocktail can serve as a foundational resource for IR research in the LLM era,
with all data and code publicly available at
\url{https://github.com/KID-22/Cocktail}.",2024-05-26,"Sunhao Dai, Weihao Liu, Yuqi Zhou, Liang Pang, Rongju Ruan, Gang Wang, Zhenhua Dong, Jun Xu, Ji-Rong Wen",http://arxiv.org/pdf/2405.16546v2,cs.CL
Tool Learning in the Wild: Empowering Language Models as Automatic Tool Agents,"Augmenting large language models (LLMs) with external tools has emerged as a
promising approach to extend their utility, enabling them to solve practical
tasks. Previous methods manually parse tool documentation and create in-context
demonstrations, transforming tools into structured formats for LLMs to use in
their step-by-step reasoning. However, this manual process requires domain
expertise and struggles to scale to large toolsets. Additionally, these methods
rely heavily on ad-hoc inference techniques or special tokens to integrate
free-form LLM generation with tool-calling actions, limiting the LLM's
flexibility in handling diverse tool specifications and integrating multiple
tools.
  In this work, we propose AutoTools, a framework that enables LLMs to automate
the tool-use workflow. Specifically, the LLM automatically transforms tool
documentation into callable functions, verifying syntax and runtime
correctness. Then, the LLM integrates these functions into executable programs
to solve practical tasks, flexibly grounding tool-use actions into its
reasoning processes. Extensive experiments on existing and newly collected,
more challenging benchmarks illustrate the superiority of our framework.
Inspired by these promising results, we further investigate how to improve the
expertise of LLMs, especially open-source LLMs with fewer parameters, within
AutoTools. Thus, we propose the AutoTools-learning approach, training the LLMs
with three learning tasks on 34k instances of high-quality synthetic data,
including documentation understanding, relevance learning, and function
programming. Fine-grained results validate the effectiveness of our overall
training approach and each individual task. Our methods are an important step
towards the use of LLMs for solving real-world tasks with external tools.",2024-05-26,"Zhengliang Shi, Shen Gao, Lingyong Yan, Yue Feng, Xiuyi Chen, Zhumin Chen, Dawei Yin, Suzan Verberne, Zhaochun Ren",http://arxiv.org/pdf/2405.16533v2,cs.CL
LoQT: Low-Rank Adapters for Quantized Pretraining,"Despite advances using low-rank adapters and quantization, pretraining of
large models on consumer hardware has not been possible without model sharding,
offloading during training, or per-layer gradient updates. To address these
limitations, we propose Low-Rank Adapters for Quantized Training (LoQT), a
method for efficiently training quantized models. LoQT uses gradient-based
tensor factorization to initialize low-rank trainable weight matrices that are
periodically merged into quantized full-rank weight matrices. Our approach is
suitable for both pretraining and fine-tuning models. We demonstrate this for
language modeling and downstream task adaptation, finding that LoQT enables
efficient training of models up to 7B parameters on a 24GB GPU. We also
demonstrate the feasibility of training a 13B model using per-layer gradient
updates on the same hardware.",2024-05-26,"Sebastian Loeschcke, Mads Toftrup, Michael J. Kastoryano, Serge Belongie, Vésteinn Snæbjarnarson",http://arxiv.org/pdf/2405.16528v4,cs.CL
Planning with Multi-Constraints via Collaborative Language Agents,"The rapid advancement of neural language models has sparked a new surge of
intelligent agent research. Unlike traditional agents, large language
model-based agents (LLM agents) have emerged as a promising paradigm for
achieving artificial general intelligence (AGI) due to their superior reasoning
and generalization capabilities. Effective planning is crucial for the success
of LLM agents in real-world tasks, making it a highly pursued topic in the
community. Current planning methods typically translate tasks into executable
action sequences. However, determining a feasible or optimal sequence for
complex tasks with multiple constraints at fine granularity, which often
requires compositing long chains of heterogeneous actions, remains challenging.
This paper introduces Planning with Multi-Constraints (PMC), a zero-shot
methodology for collaborative LLM-based multi-agent systems that simplifies
complex task planning with constraints by decomposing it into a hierarchy of
subordinate tasks. Each subtask is then mapped into executable actions. PMC was
assessed on two constraint-intensive benchmarks, TravelPlanner and API-Bank.
Notably, PMC achieved an average 42.68% success rate on TravelPlanner,
significantly higher than GPT-4 (2.92%), and outperforming GPT-4 with ReAct on
API-Bank by 13.64%, showing the immense potential of integrating LLM with
multi-agent systems. We also show that PMC works with small LLM as the planning
core, e.g., LLaMA-3.1-8B.",2024-05-26,"Cong Zhang, Derrick Goh Xin Deik, Dexun Li, Hao Zhang, Yong Liu",http://arxiv.org/pdf/2405.16510v4,cs.CL
DarijaBanking: A New Resource for Overcoming Language Barriers in Banking Intent Detection for Moroccan Arabic Speakers,"Navigating the complexities of language diversity is a central challenge in
developing robust natural language processing systems, especially in
specialized domains like banking. The Moroccan Dialect (Darija) serves as the
common language that blends cultural complexities, historical impacts, and
regional differences. The complexities of Darija present a special set of
challenges for language models, as it differs from Modern Standard Arabic with
strong influence from French, Spanish, and Tamazight, it requires a specific
approach for effective communication. To tackle these challenges, this paper
introduces \textbf{DarijaBanking}, a novel Darija dataset aimed at enhancing
intent classification in the banking domain, addressing the critical need for
automatic banking systems (e.g., chatbots) that communicate in the native
language of Moroccan clients. DarijaBanking comprises over 1,800 parallel
high-quality queries in Darija, Modern Standard Arabic (MSA), English, and
French, organized into 24 intent classes. We experimented with various intent
classification methods, including full fine-tuning of monolingual and
multilingual models, zero-shot learning, retrieval-based approaches, and Large
Language Model prompting. One of the main contributions of this work is
BERTouch, our BERT-based language model for intent classification in Darija.
BERTouch achieved F1-scores of 0.98 for Darija and 0.96 for MSA on
DarijaBanking, outperforming the state-of-the-art alternatives including GPT-4
showcasing its effectiveness in the targeted application.",2024-05-26,"Abderrahman Skiredj, Ferdaous Azhari, Ismail Berrada, Saad Ezzini",http://arxiv.org/pdf/2405.16482v1,cs.CL
M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought,"Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge
from both textual and visual modalities for step-by-step reasoning, which gains
increasing attention. Nevertheless, the current MCoT benchmark still faces some
challenges: (1) absence of visual modal reasoning, (2) single-step visual modal
reasoning, and (3) Domain missing, thereby hindering the development of MCoT.
Motivated by this, we introduce a novel benchmark (M$^3$CoT) to address the
above challenges, advancing the multi-domain, multi-step, and multi-modal CoT.
Additionally, we conduct a thorough evaluation involving abundant MCoT
approaches on Vision Large Language Models (VLLMs). In addition, we highlight
that the current VLLMs still struggle to correctly reason in M$^3$CoT and there
remains a large gap between existing VLLMs and human performance in M$^3$CoT,
despite their superior results on previous MCoT benchmarks. To our knowledge,
we take the first meaningful step toward the multi-domain, multi-step, and
multi-modal scenario in MCoT. We hope that M$^3$CoT can serve as a valuable
resource, providing a pioneering foundation in multi-domain, multi-step,
multi-modal chain-of-thought research.",2024-05-26,"Qiguang Chen, Libo Qin, Jin Zhang, Zhi Chen, Xiao Xu, Wanxiang Che",http://arxiv.org/pdf/2405.16473v1,cs.CL
Predicting Rental Price of Lane Houses in Shanghai with Machine Learning Methods and Large Language Models,"Housing has emerged as a crucial concern among young individuals residing in
major cities, including Shanghai. Given the unprecedented surge in property
prices in this metropolis, young people have increasingly resorted to the
rental market to address their housing needs. This study utilizes five
traditional machine learning methods: multiple linear regression (MLR), ridge
regression (RR), lasso regression (LR), decision tree (DT), and random forest
(RF), along with a Large Language Model (LLM) approach using ChatGPT, for
predicting the rental prices of lane houses in Shanghai. It applies these
methods to examine a public data sample of about 2,609 lane house rental
transactions in 2021 in Shanghai, and then compares the results of these
methods. In terms of predictive power, RF has achieved the best performance
among the traditional methods. However, the LLM approach, particularly in the
10-shot scenario, shows promising results that surpass traditional methods in
terms of R-Squared value. The three performance metrics: mean squared error
(MSE), mean absolute error (MAE), and R-Squared, are used to evaluate the
models. Our conclusion is that while traditional machine learning models offer
robust techniques for rental price prediction, the integration of LLM such as
ChatGPT holds significant potential for enhancing predictive accuracy.",2024-05-26,"Tingting Chen, Shijing Si",http://arxiv.org/pdf/2405.17505v1,cs.CL
Development of an open education resources (OER) system: a comparative analysis and implementation approach,"Several institutions are collaborating on the development of a new web-based
Open Education Resources (OER) system designed exclusively for non-commercial
educational purposes. This initiative is underpinned by meticulous research
aimed at constructing an OER system that optimizes user experiences across
diverse user profiles. A significant emphasis is placed on utilizing
open-source tools, frameworks, and technologies. The project includes a
comparative analysis of the top five open-source Learning Management Systems
(LMS), providing critical insights to inform the development process. The
primary objective is to create a web-based system that facilitates the sharing
of educational resources for non-commercial users, leveraging information and
communication technologies. The project is structured around two key teams: a
research team and a development team. This comprehensive approach is intended
to establish a robust, user-centric OER system, informed by insights from
existing platforms and the latest advancements in open education resource
development.",2024-05-26,"Nimol Thuon, Wangrui Zhang",http://arxiv.org/pdf/2405.16442v1,cs.CL
The Importance of Directional Feedback for LLM-based Optimizers,"We study the potential of using large language models (LLMs) as an
interactive optimizer for solving maximization problems in a text space using
natural language and numerical feedback. Inspired by the classical optimization
literature, we classify the natural language feedback into directional and
non-directional, where the former is a generalization of the first-order
feedback to the natural language space. We find that LLMs are especially
capable of optimization when they are provided with {directional feedback}.
Based on this insight, we design a new LLM-based optimizer that synthesizes
directional feedback from the historical optimization trace to achieve reliable
improvement over iterations. Empirically, we show our LLM-based optimizer is
more stable and efficient in solving optimization problems, from maximizing
mathematical functions to optimizing prompts for writing poems, compared with
existing techniques.",2024-05-26,"Allen Nie, Ching-An Cheng, Andrey Kolobov, Adith Swaminathan",http://arxiv.org/pdf/2405.16434v2,cs.CL
CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling,"Using large language models (LLMs) to assist psychological counseling is a
significant but challenging task at present. Attempts have been made on
improving empathetic conversations or acting as effective assistants in the
treatment with LLMs. However, the existing datasets lack consulting knowledge,
resulting in LLMs lacking professional consulting competence. Moreover, how to
automatically evaluate multi-turn dialogues within the counseling process
remains an understudied area. To bridge the gap, we propose CPsyCoun, a
report-based multi-turn dialogue reconstruction and evaluation framework for
Chinese psychological counseling. To fully exploit psychological counseling
reports, a two-phase approach is devised to construct high-quality dialogues
while a comprehensive evaluation benchmark is developed for the effective
automatic evaluation of multi-turn psychological consultations. Competitive
experimental results demonstrate the effectiveness of our proposed framework in
psychological counseling. We open-source the datasets and model for future
research at https://github.com/CAS-SIAT-XinHai/CPsyCoun",2024-05-26,"Chenhao Zhang, Renhao Li, Minghuan Tan, Min Yang, Jingwei Zhu, Di Yang, Jiahao Zhao, Guancheng Ye, Chengming Li, Xiping Hu",http://arxiv.org/pdf/2405.16433v3,cs.CL
AI-Generated Text Detection and Classification Based on BERT Deep Learning Algorithm,"AI-generated text detection plays an increasingly important role in various
fields. In this study, we developed an efficient AI-generated text detection
model based on the BERT algorithm, which provides new ideas and methods for
solving related problems. In the data preprocessing stage, a series of steps
were taken to process the text, including operations such as converting to
lowercase, word splitting, removing stop words, stemming extraction, removing
digits, and eliminating redundant spaces, to ensure data quality and accuracy.
By dividing the dataset into a training set and a test set in the ratio of 60%
and 40%, and observing the changes in the accuracy and loss values during the
training process, we found that the model performed well during the training
process. The accuracy increases steadily from the initial 94.78% to 99.72%,
while the loss value decreases from 0.261 to 0.021 and converges gradually,
which indicates that the BERT model is able to detect AI-generated text with
high accuracy and the prediction results are gradually approaching the real
classification results. Further analysis of the results of the training and
test sets reveals that in terms of loss value, the average loss of the training
set is 0.0565, while the average loss of the test set is 0.0917, showing a
slightly higher loss value. As for the accuracy, the average accuracy of the
training set reaches 98.1%, while the average accuracy of the test set is
97.71%, which is not much different from each other, indicating that the model
has good generalisation ability. In conclusion, the AI-generated text detection
model based on the BERT algorithm proposed in this study shows high accuracy
and stability in experiments, providing an effective solution for related
fields.",2024-05-26,"Hao Wang, Jianwei Li, Zhengyu Li",http://arxiv.org/pdf/2405.16422v1,cs.CL
M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions,"Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
retrieving relevant memories from an external database. However, existing RAG
methods typically organize all memories in a whole database, potentially
limiting focus on crucial memories and introducing noise. In this paper, we
introduce a multiple partition paradigm for RAG (called M-RAG), where each
database partition serves as a basic unit for RAG execution. Based on this
paradigm, we propose a novel framework that leverages LLMs with Multi-Agent
Reinforcement Learning to optimize different language generation tasks
explicitly. Through comprehensive experiments conducted on seven datasets,
spanning three language generation tasks and involving three distinct language
model architectures, we confirm that M-RAG consistently outperforms various
baseline methods, achieving improvements of 11%, 8%, and 12% for text
summarization, machine translation, and dialogue generation, respectively.",2024-05-26,"Zheng Wang, Shu Xian Teo, Jieer Ouyang, Yongjun Xu, Wei Shi",http://arxiv.org/pdf/2405.16420v1,cs.CL
Code Repair with LLMs gives an Exploration-Exploitation Tradeoff,"Iteratively improving and repairing source code with large language models
(LLMs), known as refinement, has emerged as a popular way of generating
programs that would be too complex to construct in one shot. Given a bank of
test cases, together with a candidate program, an LLM can improve that program
by being prompted with failed test cases. But it remains an open question how
to best iteratively refine code, with prior work employing simple greedy or
breadth-first strategies. We show here that refinement exposes an
explore-exploit tradeoff: exploit by refining the program that passes the most
test cases, or explore by refining a lesser considered program. We frame this
as an arm-acquiring bandit problem, which we solve with Thompson Sampling. The
resulting LLM-based program synthesis algorithm is broadly applicable: Across
loop invariant synthesis, visual reasoning puzzles, and competition programming
problems, we find that our new method can solve more problems using fewer
language model calls.",2024-05-26,"Hao Tang, Keya Hu, Jin Peng Zhou, Sicheng Zhong, Wei-Long Zheng, Xujie Si, Kevin Ellis",http://arxiv.org/pdf/2405.17503v3,cs.CL
Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models,"Alzheimer's disease (AD) is the fifth-leading cause of death among Americans
aged 65 and older. Screening and early detection of AD and related dementias
(ADRD) are critical for timely intervention and for identifying clinical trial
participants. The widespread adoption of electronic health records (EHRs)
offers an important resource for developing ADRD screening tools such as
machine learning based predictive models. Recent advancements in large language
models (LLMs) demonstrate their unprecedented capability of encoding knowledge
and performing reasoning, which offers them strong potential for enhancing risk
prediction. This paper proposes a novel pipeline that augments risk prediction
by leveraging the few-shot inference power of LLMs to make predictions on cases
where traditional supervised learning methods (SLs) may not excel.
Specifically, we develop a collaborative pipeline that combines SLs and LLMs
via a confidence-driven decision-making mechanism, leveraging the strengths of
SLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this
pipeline using a real-world EHR data warehouse from Oregon Health \& Science
University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients
and more than 20 million patient encounters. Our results show that our proposed
approach effectively combines the power of SLs and LLMs, offering significant
improvements in predictive performance. This advancement holds promise for
revolutionizing ADRD screening and early detection practices, with potential
implications for better strategies of patient management and thus improving
healthcare.",2024-05-26,"Jiankun Wang, Sumyeong Ahn, Taykhoom Dalal, Xiaodan Zhang, Weishen Pan, Qiannan Zhang, Bin Chen, Hiroko H. Dodge, Fei Wang, Jiayu Zhou",http://arxiv.org/pdf/2405.16413v1,cs.CL
KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge,"Knowledge Graph Embedding (KGE) techniques are crucial in learning compact
representations of entities and relations within a knowledge graph,
facilitating efficient reasoning and knowledge discovery. While existing
methods typically focus either on training KGE models solely based on graph
structure or fine-tuning pre-trained language models with classification data
in KG, KG-FIT leverages LLM-guided refinement to construct a semantically
coherent hierarchical structure of entity clusters. By incorporating this
hierarchical knowledge along with textual information during the fine-tuning
process, KG-FIT effectively captures both global semantics from the LLM and
local semantics from the KG. Extensive experiments on the benchmark datasets
FB15K-237, YAGO3-10, and PrimeKG demonstrate the superiority of KG-FIT over
state-of-the-art pre-trained language model-based methods, achieving
improvements of 14.4%, 13.5%, and 11.9% in the Hits@10 metric for the link
prediction task, respectively. Furthermore, KG-FIT yields substantial
performance gains of 12.6%, 6.7%, and 17.7% compared to the structure-based
base models upon which it is built. These results highlight the effectiveness
of KG-FIT in incorporating open-world knowledge from LLMs to significantly
enhance the expressiveness and informativeness of KG embeddings.",2024-05-26,"Pengcheng Jiang, Lang Cao, Cao Xiao, Parminder Bhatia, Jimeng Sun, Jiawei Han",http://arxiv.org/pdf/2405.16412v3,cs.CL
Tensor Attention Training: Provably Efficient Learning of Higher-order Transformers,"Tensor Attention, a multi-view attention that is able to capture high-order
correlations among multiple modalities, can overcome the representational
limitations of classical matrix attention. However, the $O(n^3)$ time
complexity of tensor attention poses a significant obstacle to its utilization
in transformers, where $n$ is the input sequence length. In this work, we prove
that the backward gradient of tensor attention training can be computed in
almost linear time $n^{1+o(1)}$, the same complexity as its forward computation
under the bounded entries assumption. We provide a closed-form solution for the
gradient and propose a fast computation method utilizing polynomial
approximation methods and tensor algebraic techniques. Furthermore, we prove
the necessity and tightness of our assumption through hardness analysis,
showing that slightly weakening it renders the gradient problem unsolvable in
truly subcubic time. Our theoretical results establish the feasibility of
efficient higher-order transformer training and may facilitate practical
applications of tensor attention architectures.",2024-05-26,"Yingyu Liang, Zhenmei Shi, Zhao Song, Yufa Zhou",http://arxiv.org/pdf/2405.16411v2,cs.CL
SpinQuant: LLM quantization with learned rotations,"Post-training quantization (PTQ) techniques applied to weights, activations,
and the KV cache greatly reduce memory usage, latency, and power consumption of
Large Language Models (LLMs), but may lead to large quantization errors when
outliers are present. Rotating activation or weight matrices helps remove
outliers and benefits quantization. In this work, we identify a collection of
applicable rotation parameterizations that lead to identical outputs in
full-precision Transformer architectures while enhancing quantization accuracy.
In addition, we find that some random rotations lead to much better
quantization than others, with an up to 13 points difference in downstream
zero-shot reasoning performance. As a result, we propose SpinQuant, a novel
approach that incorporates learned rotation matrices for optimal quantized
network accuracy. With 4-bit quantization of weight, activation, and KV-cache,
SpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full
precision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by
19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also
outperforms concurrent work QuaRot, which applies random rotations to remove
outliers. In particular, for LLaMA-3 8B models that are hard to quantize,
SpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.
Code is available at https://github.com/facebookresearch/SpinQuant.",2024-05-26,"Zechun Liu, Changsheng Zhao, Igor Fedorov, Bilge Soran, Dhruv Choudhary, Raghuraman Krishnamoorthi, Vikas Chandra, Yuandong Tian, Tijmen Blankevoort",http://arxiv.org/pdf/2405.16406v4,cs.CL
Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions,"The integration of Large Language Models (LLMs) into the healthcare domain
has the potential to significantly enhance patient care and support through the
development of empathetic, patient-facing chatbots. This study investigates an
intriguing question Can ChatGPT respond with a greater degree of empathy than
those typically offered by physicians? To answer this question, we collect a
de-identified dataset of patient messages and physician responses from Mayo
Clinic and generate alternative replies using ChatGPT. Our analyses incorporate
novel empathy ranking evaluation (EMRank) involving both automated metrics and
human assessments to gauge the empathy level of responses. Our findings
indicate that LLM-powered chatbots have the potential to surpass human
physicians in delivering empathetic communication, suggesting a promising
avenue for enhancing patient care and reducing professional burnout. The study
not only highlights the importance of empathy in patient interactions but also
proposes a set of effective automatic empathy ranking metrics, paving the way
for the broader adoption of LLMs in healthcare.",2024-05-26,"Man Luo, Christopher J. Warren, Lu Cheng, Haidar M. Abdul-Muhsin, Imon Banerjee",http://arxiv.org/pdf/2405.16402v1,cs.CL
Multi-Reference Preference Optimization for Large Language Models,"How can Large Language Models (LLMs) be aligned with human intentions and
values? A typical solution is to gather human preference on model outputs and
finetune the LLMs accordingly while ensuring that updates do not deviate too
far from a reference model. Recent approaches, such as direct preference
optimization (DPO), have eliminated the need for unstable and sluggish
reinforcement learning optimization by introducing close-formed supervised
losses. However, a significant limitation of the current approach is its design
for a single reference model only, neglecting to leverage the collective power
of numerous pretrained LLMs. To overcome this limitation, we introduce a novel
closed-form formulation for direct preference optimization using multiple
reference models. The resulting algorithm, Multi-Reference Preference
Optimization (MRPO), leverages broader prior knowledge from diverse reference
models, substantially enhancing preference learning capabilities compared to
the single-reference DPO. Our experiments demonstrate that LLMs finetuned with
MRPO generalize better in various preference data, regardless of data scarcity
or abundance. Furthermore, MRPO effectively finetunes LLMs to exhibit superior
performance in several downstream natural language processing tasks such as
GSM8K and TruthfulQA.",2024-05-26,"Hung Le, Quan Tran, Dung Nguyen, Kien Do, Saloni Mittal, Kelechi Ogueji, Svetha Venkatesh",http://arxiv.org/pdf/2405.16388v1,cs.CL
STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making,"Large Language Models (LLMs) like GPT-4 have revolutionized natural language
processing, showing remarkable linguistic proficiency and reasoning
capabilities. However, their application in strategic multi-agent
decision-making environments is hampered by significant limitations including
poor mathematical reasoning, difficulty in following instructions, and a
tendency to generate incorrect information. These deficiencies hinder their
performance in strategic and interactive tasks that demand adherence to nuanced
game rules, long-term planning, exploration in unknown environments, and
anticipation of opponents' moves. To overcome these obstacles, this paper
presents a novel LLM agent framework equipped with memory and specialized tools
to enhance their strategic decision-making capabilities. We deploy the tools in
a number of economically important environments, in particular bilateral
bargaining and multi-agent and dynamic mechanism design. We employ quantitative
metrics to assess the framework's performance in various strategic
decision-making problems. Our findings establish that our enhanced framework
significantly improves the strategic decision-making capability of LLMs. While
we highlight the inherent limitations of current LLM models, we demonstrate the
improvements through targeted enhancements, suggesting a promising direction
for future developments in LLM applications for interactive environments.",2024-05-25,"Chuanhao Li, Runhan Yang, Tiankai Li, Milad Bafarassat, Kourosh Sharifi, Dirk Bergemann, Zhuoran Yang",http://arxiv.org/pdf/2405.16376v2,cs.CL
"Learning to Reason via Program Generation, Emulation, and Search","Program synthesis with language models (LMs) has unlocked a large set of
reasoning abilities; code-tuned LMs have proven adept at generating programs
that solve a wide variety of algorithmic symbolic manipulation tasks (e.g. word
concatenation). However, not all reasoning tasks are easily expressible as
code, e.g. tasks involving commonsense reasoning, moral decision-making, and
sarcasm understanding. Our goal is to extend an LM's program synthesis skills
to such tasks and evaluate the results via pseudo-programs, namely Python
programs where some leaf function calls are left undefined. To that end, we
propose, Code Generation and Emulated EXecution (CoGEX). CoGEX works by (1)
training LMs to generate pseudo-programs, (2) teaching them to emulate their
generated program's execution, including those leaf functions, allowing the
LM's knowledge to fill in the execution gaps; and (3) using them to search over
many programs to find an optimal one. To adapt the CoGEX model to a new task,
we introduce a method for performing program search to find a single program
whose pseudo-execution yields optimal performance when applied to all the
instances of a given dataset. We show that our approach yields large
improvements compared to standard in-context learning approaches on a battery
of tasks, both algorithmic and soft reasoning. This result thus demonstrates
that code synthesis can be applied to a much broader class of problems than
previously considered. Our released dataset, fine-tuned models, and
implementation can be found at \url{https://github.com/nweir127/CoGEX}.",2024-05-25,"Nathaniel Weir, Muhammad Khalifa, Linlu Qiu, Orion Weller, Peter Clark",http://arxiv.org/pdf/2405.16337v3,cs.CL
Comparative Analysis of Open-Source Language Models in Summarizing Medical Text Data,"Unstructured text in medical notes and dialogues contains rich information.
Recent advancements in Large Language Models (LLMs) have demonstrated superior
performance in question answering and summarization tasks on unstructured text
data, outperforming traditional text analysis approaches. However, there is a
lack of scientific studies in the literature that methodically evaluate and
report on the performance of different LLMs, specifically for domain-specific
data such as medical chart notes. We propose an evaluation approach to analyze
the performance of open-source LLMs such as Llama2 and Mistral for medical
summarization tasks, using GPT-4 as an assessor. Our innovative approach to
quantitative evaluation of LLMs can enable quality control, support the
selection of effective LLMs for specific tasks, and advance knowledge discovery
in digital health.",2024-05-25,"Yuhao Chen, Zhimu Wang, Bo Wen, Farhana Zulkernine",http://arxiv.org/pdf/2405.16295v3,cs.CL
Generating clickbait spoilers with an ensemble of large language models,"Clickbait posts are a widespread problem in the webspace. The generation of
spoilers, i.e. short texts that neutralize clickbait by providing information
that satisfies the curiosity induced by it, is one of the proposed solutions to
the problem. Current state-of-the-art methods are based on passage retrieval or
question answering approaches and are limited to generating spoilers only in
the form of a phrase or a passage. In this work, we propose an ensemble of
fine-tuned large language models for clickbait spoiler generation. Our approach
is not limited to phrase or passage spoilers, but is also able to generate
multipart spoilers that refer to several non-consecutive parts of text.
Experimental evaluation demonstrates that the proposed ensemble model
outperforms the baselines in terms of BLEU, METEOR and BERTScore metrics.",2024-05-25,"Mateusz Woźny, Mateusz Lango",http://arxiv.org/pdf/2405.16284v1,cs.CL
Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models,"As the use of Large Language Models (LLMs) becomes more widespread,
understanding their self-evaluation of confidence in generated responses
becomes increasingly important as it is integral to the reliability of the
output of these models. We introduce the concept of Confidence-Probability
Alignment, that connects an LLM's internal confidence, quantified by token
probabilities, to the confidence conveyed in the model's response when
explicitly asked about its certainty. Using various datasets and prompting
techniques that encourage model introspection, we probe the alignment between
models' internal and expressed confidence. These techniques encompass using
structured evaluation scales to rate confidence, including answer options when
prompting, and eliciting the model's confidence level for outputs it does not
recognize as its own. Notably, among the models analyzed, OpenAI's GPT-4 showed
the strongest confidence-probability alignment, with an average Spearman's
$\hat{\rho}$ of 0.42, across a wide range of tasks. Our work contributes to the
ongoing efforts to facilitate risk assessment in the application of LLMs and to
further our understanding of model trustworthiness.",2024-05-25,"Abhishek Kumar, Robert Morabito, Sanzhar Umbet, Jad Kabbara, Ali Emami",http://arxiv.org/pdf/2405.16282v5,cs.CL
Retrieval-Augmented Conversational Recommendation with Prompt-based Semi-Structured Natural Language State Tracking,"Conversational recommendation (ConvRec) systems must understand rich and
diverse natural language (NL) expressions of user preferences and intents,
often communicated in an indirect manner (e.g., ""I'm watching my weight""). Such
complex utterances make retrieving relevant items challenging, especially if
only using often incomplete or out-of-date metadata. Fortunately, many domains
feature rich item reviews that cover standard metadata categories and offer
complex opinions that might match a user's interests (e.g., ""classy joint for a
date""). However, only recently have large language models (LLMs) let us unlock
the commonsense connections between user preference utterances and complex
language in user-generated reviews. Further, LLMs enable novel paradigms for
semi-structured dialogue state tracking, complex intent and preference
understanding, and generating recommendations, explanations, and question
answers. We thus introduce a novel technology RA-Rec, a Retrieval-Augmented,
LLM-driven dialogue state tracking system for ConvRec, showcased with a video,
open source GitHub repository, and interactive Google Colab notebook.",2024-05-25,"Sara Kemper, Justin Cui, Kai Dicarlantonio, Kathy Lin, Danjie Tang, Anton Korikov, Scott Sanner",http://arxiv.org/pdf/2406.00033v1,cs.CL
ConStat: Performance-Based Contamination Detection in Large Language Models,"Public benchmarks play an essential role in the evaluation of large language
models. However, data contamination can lead to inflated performance, rendering
them unreliable for model comparison. It is therefore crucial to detect
contamination and estimate its impact on measured performance. Unfortunately,
existing detection methods can be easily evaded and fail to quantify
contamination. To overcome these limitations, we propose a novel definition of
contamination as artificially inflated and non-generalizing benchmark
performance instead of the inclusion of benchmark samples in the training data.
This perspective enables us to detect any model with inflated performance,
i.e., performance that does not generalize to rephrased samples, synthetic
samples from the same distribution, or different benchmarks for the same task.
Based on this insight, we develop ConStat, a statistical method that reliably
detects and quantifies contamination by comparing performance between a primary
and reference benchmark relative to a set of reference models. We demonstrate
the effectiveness of ConStat in an extensive evaluation of diverse model
architectures, benchmarks, and contamination scenarios and find high levels of
contamination in multiple popular models including Mistral, Llama, Yi, and the
top-3 Open LLM Leaderboard models.",2024-05-25,"Jasper Dekoninck, Mark Niklas Müller, Martin Vechev",http://arxiv.org/pdf/2405.16281v1,cs.CL
Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge,"Large Language Models (LLMs) have demonstrated remarkable success in tasks
like the Winograd Schema Challenge (WSC), showcasing advanced textual
common-sense reasoning. However, applying this reasoning to multimodal domains,
where understanding text and images together is essential, remains a
substantial challenge. To address this, we introduce WinoVis, a novel dataset
specifically designed to probe text-to-image models on pronoun disambiguation
within multimodal contexts. Utilizing GPT-4 for prompt generation and Diffusion
Attentive Attribution Maps (DAAM) for heatmap analysis, we propose a novel
evaluation framework that isolates the models' ability in pronoun
disambiguation from other visual processing challenges. Evaluation of
successive model versions reveals that, despite incremental advancements,
Stable Diffusion 2.0 achieves a precision of 56.7% on WinoVis, only marginally
surpassing random guessing. Further error analysis identifies important areas
for future research aimed at advancing text-to-image models in their ability to
interpret and interact with the complex visual world.",2024-05-25,"Brendan Park, Madeline Janecek, Naser Ezzati-Jivan, Yifeng Li, Ali Emami",http://arxiv.org/pdf/2405.16277v3,cs.CL
AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learning,"Large Language Models (LLM) based agents have shown promise in autonomously
completing tasks across various domains, e.g., robotics, games, and web
navigation. However, these agents typically require elaborate design and expert
prompts to solve tasks in specific domains, which limits their adaptability. We
introduce AutoManual, a framework enabling LLM agents to autonomously build
their understanding through interaction and adapt to new environments.
AutoManual categorizes environmental knowledge into diverse rules and optimizes
them in an online fashion by two agents: 1) The Planner codes actionable plans
based on current rules for interacting with the environment. 2) The Builder
updates the rules through a well-structured rule system that facilitates online
rule management and essential detail retention. To mitigate hallucinations in
managing rules, we introduce a *case-conditioned prompting* strategy for the
Builder. Finally, the Formulator agent compiles these rules into a
comprehensive manual. The self-generated manual can not only improve the
adaptability but also guide the planning of smaller LLMs while being
human-readable. Given only one simple demonstration, AutoManual significantly
improves task success rates, achieving 97.4\% with GPT-4-turbo and 86.2\% with
GPT-3.5-turbo on ALFWorld benchmark tasks. The code is available at
https://github.com/minghchen/automanual.",2024-05-25,"Minghao Chen, Yihang Li, Yanting Yang, Shiyu Yu, Binbin Lin, Xiaofei He",http://arxiv.org/pdf/2405.16247v4,cs.CL
No Two Devils Alike: Unveiling Distinct Mechanisms of Fine-tuning Attacks,"The existing safety alignment of Large Language Models (LLMs) is found
fragile and could be easily attacked through different strategies, such as
through fine-tuning on a few harmful examples or manipulating the prefix of the
generation results. However, the attack mechanisms of these strategies are
still underexplored. In this paper, we ask the following question:
\textit{while these approaches can all significantly compromise safety, do
their attack mechanisms exhibit strong similarities?} To answer this question,
we break down the safeguarding process of an LLM when encountered with harmful
instructions into three stages: (1) recognizing harmful instructions, (2)
generating an initial refusing tone, and (3) completing the refusal response.
Accordingly, we investigate whether and how different attack strategies could
influence each stage of this safeguarding process. We utilize techniques such
as logit lens and activation patching to identify model components that drive
specific behavior, and we apply cross-model probing to examine representation
shifts after an attack. In particular, we analyze the two most representative
types of attack approaches: Explicit Harmful Attack (EHA) and Identity-Shifting
Attack (ISA). Surprisingly, we find that their attack mechanisms diverge
dramatically. Unlike ISA, EHA tends to aggressively target the harmful
recognition stage. While both EHA and ISA disrupt the latter two stages, the
extent and mechanisms of their attacks differ significantly. Our findings
underscore the importance of understanding LLMs' internal safeguarding process
and suggest that diverse defense mechanisms are required to effectively cope
with various types of attacks.",2024-05-25,"Chak Tou Leong, Yi Cheng, Kaishuai Xu, Jian Wang, Hanlin Wang, Wenjie Li",http://arxiv.org/pdf/2405.16229v1,cs.CL
Towards Unlocking Insights from Logbooks Using AI,"Electronic logbooks contain valuable information about activities and events
concerning their associated particle accelerator facilities. However, the
highly technical nature of logbook entries can hinder their usability and
automation. As natural language processing (NLP) continues advancing, it offers
opportunities to address various challenges that logbooks present. This work
explores jointly testing a tailored Retrieval Augmented Generation (RAG) model
for enhancing the usability of particle accelerator logbooks at institutes like
DESY, BESSY, Fermilab, BNL, SLAC, LBNL, and CERN. The RAG model uses a corpus
built on logbook contributions and aims to unlock insights from these logbooks
by leveraging retrieval over facility datasets, including discussion about
potential multimodal sources. Our goals are to increase the FAIR-ness
(findability, accessibility, interoperability, and reusability) of logbooks by
exploiting their information content to streamline everyday use, enable
macro-analysis for root cause analysis, and facilitate problem-solving
automation.",2024-05-25,"Antonin Sulc, Alex Bien, Annika Eichler, Daniel Ratner, Florian Rehm, Frank Mayet, Gregor Hartmann, Hayden Hoschouer, Henrik Tuennermann, Jan Kaiser, Jason St. John, Jennefer Maldonado, Kyle Hazelwood, Raimund Kammering, Thorsten Hellert, Tim Wilksen, Verena Kain, Wan-Lin Hu",http://arxiv.org/pdf/2406.12881v1,cs.CL
GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases,"Gene set knowledge discovery is essential for advancing human functional
genomics. Recent studies have shown promising performance by harnessing the
power of Large Language Models (LLMs) on this task. Nonetheless, their results
are subject to several limitations common in LLMs such as hallucinations. In
response, we present GeneAgent, a first-of-its-kind language agent featuring
self-verification capability. It autonomously interacts with various biological
databases and leverages relevant domain knowledge to improve accuracy and
reduce hallucination occurrences. Benchmarking on 1,106 gene sets from
different sources, GeneAgent consistently outperforms standard GPT-4 by a
significant margin. Moreover, a detailed manual review confirms the
effectiveness of the self-verification module in minimizing hallucinations and
generating more reliable analytical narratives. To demonstrate its practical
utility, we apply GeneAgent to seven novel gene sets derived from mouse B2905
melanoma cell lines, with expert evaluations showing that GeneAgent offers
novel insights into gene functions and subsequently expedites knowledge
discovery.",2024-05-25,"Zhizheng Wang, Qiao Jin, Chih-Hsuan Wei, Shubo Tian, Po-Ting Lai, Qingqing Zhu, Chi-Ping Day, Christina Ross, Zhiyong Lu",http://arxiv.org/pdf/2405.16205v1,cs.CL
InstructPatentGPT: Training patent language models to follow instructions with human feedback,"In this research, patent prosecution is conceptualized as a system of
reinforcement learning from human feedback. The objective of the system is to
increase the likelihood for a language model to generate patent claims that
have a higher chance of being granted. To showcase the controllability of the
language model, the system learns from granted patents and pre-grant
applications with different rewards. The status of ""granted"" and ""pre-grant""
are perceived as labeled human feedback implicitly. In addition, specific to
patent drafting, the experiments in this research demonstrate the model's
capability to learn from adjusting claim length and inclusion of limiting terms
for narrowing claim scope. As proof of concept, the experiments focus on claim
ones only and the training data originates from a patent dataset tailored
specifically for artificial intelligence. Although the available human feedback
in patent prosecution are limited and the quality of generated patent text
requires improvement, the experiments following the 3-stage reinforcement
learning from human feedback have demonstrated that generative language models
are capable of reflecting the human feedback or intent in patent prosecution.
To enhance the usability of language models, the implementation in this
research utilizes modern techniques that enable execution on a single
consumer-grade GPU. The demonstrated proof of concept, which reduces hardware
requirements, will prove valuable in the future as more human feedback in
patent prosecution become available for broader use, either within patent
offices or in the public domain.",2024-05-25,Jieh-Sheng Lee,http://arxiv.org/pdf/2406.16897v1,cs.CL
Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection,"Large language models (LLMs) augmented with retrieval exhibit robust
performance and extensive versatility by incorporating external contexts.
However, the input length grows linearly in the number of retrieved documents,
causing a dramatic increase in latency. In this paper, we propose a novel
paradigm named Sparse RAG, which seeks to cut computation costs through
sparsity. Specifically, Sparse RAG encodes retrieved documents in parallel,
which eliminates latency introduced by long-range attention of retrieved
documents. Then, LLMs selectively decode the output by only attending to highly
relevant caches auto-regressively, which are chosen via prompting LLMs with
special control tokens. It is notable that Sparse RAG combines the assessment
of each individual document and the generation of the response into a single
process. The designed sparse mechanism in a RAG system can facilitate the
reduction of the number of documents loaded during decoding for accelerating
the inference of the RAG system. Additionally, filtering out undesirable
contexts enhances the model's focus on relevant context, inherently improving
its generation quality. Evaluation results of two datasets show that Sparse RAG
can strike an optimal balance between generation quality and computational
efficiency, demonstrating its generalizability across both short- and long-form
generation tasks.",2024-05-25,"Yun Zhu, Jia-Chen Gu, Caitlin Sikora, Ho Ko, Yinxiao Liu, Chu-Cheng Lin, Lei Shu, Liangchen Luo, Lei Meng, Bang Liu, Jindong Chen",http://arxiv.org/pdf/2405.16178v1,cs.CL
Bi-reachability in Petri nets with data,"We investigate Petri nets with data, an extension of plain Petri nets where
tokens carry values from an infinite data domain, and executability of
transitions is conditioned by equalities between data values. We provide a
decision procedure for the bi-reachability problem: given a Petri net and its
two configurations, we ask if each of the configurations is reachable from the
other. This pushes forward the decidability borderline, as the bi-reachability
problem subsumes the coverability problem (which is known to be decidable) and
is subsumed by the reachability problem (whose decidability status is unknown).",2024-05-25,"Łukasz Kamiński, Sławomir Lasota",http://arxiv.org/pdf/2405.16176v2,cs.CL
Improving Multi-lingual Alignment Through Soft Contrastive Learning,"Making decent multi-lingual sentence representations is critical to achieve
high performances in cross-lingual downstream tasks. In this work, we propose a
novel method to align multi-lingual embeddings based on the similarity of
sentences measured by a pre-trained mono-lingual embedding model. Given
translation sentence pairs, we train a multi-lingual model in a way that the
similarity between cross-lingual embeddings follows the similarity of sentences
measured at the mono-lingual teacher model. Our method can be considered as
contrastive learning with soft labels defined as the similarity between
sentences. Our experimental results on five languages show that our contrastive
loss with soft labels far outperforms conventional contrastive loss with hard
labels in various benchmarks for bitext mining tasks and STS tasks. In
addition, our method outperforms existing multi-lingual embeddings including
LaBSE, for Tatoeba dataset. The code is available at
https://github.com/YAI12xLinq-B/IMASCL",2024-05-25,"Minsu Park, Seyeon Choi, Chanyeol Choi, Jun-Seong Kim, Jy-yong Sohn",http://arxiv.org/pdf/2405.16155v2,cs.CL
DefSent+: Improving sentence embeddings of language models by projecting definition sentences into a quasi-isotropic or isotropic vector space of unlimited dictionary entries,"This paper presents a significant improvement on the previous conference
paper known as DefSent. The prior study seeks to improve sentence embeddings of
language models by projecting definition sentences into the vector space of
dictionary entries. We discover that this approach is not fully explored due to
the methodological limitation of using word embeddings of language models to
represent dictionary entries. This leads to two hindrances. First, dictionary
entries are constrained by the single-word vocabulary, and thus cannot be fully
exploited. Second, semantic representations of language models are known to be
anisotropic, but pre-processing word embeddings for DefSent is not allowed
because its weight is frozen during training and tied to the prediction layer.
In this paper, we propose a novel method to progressively build entry
embeddings not subject to the limitations. As a result, definition sentences
can be projected into a quasi-isotropic or isotropic vector space of unlimited
dictionary entries, so that sentence embeddings of noticeably better quality
are attainable. We abbreviate our approach as DefSent+ (a plus version of
DefSent), involving the following strengths: 1) the task performance on
measuring sentence similarities is significantly improved compared to DefSent;
2) when DefSent+ is used to further train data-augmented models like SIMCSE,
SNCSE, and SynCSE, state-of-the-art performance on measuring sentence
similarities can be achieved among the approaches without using manually
labeled datasets; 3) DefSent+ is also competitive in feature-based transfer for
NLP downstream tasks.",2024-05-25,Xiaodong Liu,http://arxiv.org/pdf/2405.16153v4,cs.CL
5W1H Extraction With Large Language Models,"The extraction of essential news elements through the 5W1H framework
(\textit{What}, \textit{When}, \textit{Where}, \textit{Why}, \textit{Who}, and
\textit{How}) is critical for event extraction and text summarization. The
advent of Large language models (LLMs) such as ChatGPT presents an opportunity
to address language-related tasks through simple prompts without fine-tuning
models with much time. While ChatGPT has encountered challenges in processing
longer news texts and analyzing specific attributes in context, especially
answering questions about \textit{What}, \textit{Why}, and \textit{How}. The
effectiveness of extraction tasks is notably dependent on high-quality
human-annotated datasets. However, the absence of such datasets for the 5W1H
extraction increases the difficulty of fine-tuning strategies based on
open-source LLMs. To address these limitations, first, we annotate a
high-quality 5W1H dataset based on four typical news corpora
(\textit{CNN/DailyMail}, \textit{XSum}, \textit{NYT}, \textit{RA-MDS}); second,
we design several strategies from zero-shot/few-shot prompting to efficient
fine-tuning to conduct 5W1H aspects extraction from the original news
documents. The experimental results demonstrate that the performance of the
fine-tuned models on our labelled dataset is superior to the performance of
ChatGPT. Furthermore, we also explore the domain adaptation capability by
testing the source-domain (e.g. NYT) models on the target domain corpus (e.g.
CNN/DailyMail) for the task of 5W1H extraction.",2024-05-25,"Yang Cao, Yangsong Lan, Feiyan Zhai, Piji Li",http://arxiv.org/pdf/2405.16150v1,cs.CL
C3LLM: Conditional Multimodal Content Generation Using Large Language Models,"We introduce C3LLM (Conditioned-on-Three-Modalities Large Language Models), a
novel framework combining three tasks of video-to-audio, audio-to-text, and
text-to-audio together. C3LLM adapts the Large Language Model (LLM) structure
as a bridge for aligning different modalities, synthesizing the given
conditional information, and making multimodal generation in a discrete manner.
Our contributions are as follows. First, we adapt a hierarchical structure for
audio generation tasks with pre-trained audio codebooks. Specifically, we train
the LLM to generate audio semantic tokens from the given conditions, and
further use a non-autoregressive transformer to generate different levels of
acoustic tokens in layers to better enhance the fidelity of the generated
audio. Second, based on the intuition that LLMs were originally designed for
discrete tasks with the next-word prediction method, we use the discrete
representation for audio generation and compress their semantic meanings into
acoustic tokens, similar to adding ""acoustic vocabulary"" to LLM. Third, our
method combines the previous tasks of audio understanding, video-to-audio
generation, and text-to-audio generation together into one unified model,
providing more versatility in an end-to-end fashion. Our C3LLM achieves
improved results through various automated evaluation metrics, providing better
semantic alignment compared to previous methods.",2024-05-25,"Zixuan Wang, Qinkai Duan, Yu-Wing Tai, Chi-Keung Tang",http://arxiv.org/pdf/2405.16136v1,cs.CL
iREL at SemEval-2024 Task 9: Improving Conventional Prompting Methods for Brain Teasers,"This paper describes our approach for SemEval-2024 Task 9: BRAINTEASER: A
Novel Task Defying Common Sense. The BRAINTEASER task comprises multiple-choice
Question Answering designed to evaluate the models' lateral thinking
capabilities. It consists of Sentence Puzzle and Word Puzzle subtasks that
require models to defy default common-sense associations and exhibit
unconventional thinking. We propose a unique strategy to improve the
performance of pre-trained language models, notably the Gemini 1.0 Pro Model,
in both subtasks. We employ static and dynamic few-shot prompting techniques
and introduce a model-generated reasoning strategy that utilizes the LLM's
reasoning capabilities to improve performance. Our approach demonstrated
significant improvements, showing that it performed better than the baseline
models by a considerable margin but fell short of performing as well as the
human annotators, thus highlighting the efficacy of the proposed strategies.",2024-05-25,"Harshit Gupta, Manav Chaudhary, Tathagata Raha, Shivansh Subramanian, Vasudeva Varma",http://arxiv.org/pdf/2405.16129v1,cs.CL
How Well Do Deep Learning Models Capture Human Concepts? The Case of the Typicality Effect,"How well do representations learned by ML models align with those of humans?
Here, we consider concept representations learned by deep learning models and
evaluate whether they show a fundamental behavioral signature of human
concepts, the typicality effect. This is the finding that people judge some
instances (e.g., robin) of a category (e.g., Bird) to be more typical than
others (e.g., penguin). Recent research looking for human-like typicality
effects in language and vision models has focused on models of a single
modality, tested only a small number of concepts, and found only modest
correlations with human typicality ratings. The current study expands this
behavioral evaluation of models by considering a broader range of language (N =
8) and vision (N = 10) model architectures. It also evaluates whether the
combined typicality predictions of vision + language model pairs, as well as a
multimodal CLIP-based model, are better aligned with human typicality judgments
than those of models of either modality alone. Finally, it evaluates the models
across a broader range of concepts (N = 27) than prior studies. There were
three important findings. First, language models better align with human
typicality judgments than vision models. Second, combined language and vision
models (e.g., AlexNet + MiniLM) better predict the human typicality data than
the best-performing language model (i.e., MiniLM) or vision model (i.e.,
ViT-Huge) alone. Third, multimodal models (i.e., CLIP ViT) show promise for
explaining human typicality judgments. These results advance the
state-of-the-art in aligning the conceptual representations of ML models and
humans. A methodological contribution is the creation of a new image set for
testing the conceptual alignment of vision models.",2024-05-25,"Siddhartha K. Vemuri, Raj Sanjay Shah, Sashank Varma",http://arxiv.org/pdf/2405.16128v1,cs.CL
Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars,"Large language models (LLMs) have shown impressive capabilities in real-world
applications. The capability of in-context learning (ICL) allows us to adapt an
LLM to downstream tasks by including input-label exemplars in the prompt
without model fine-tuning. However, the quality of these exemplars in the
prompt greatly impacts performance, highlighting the need for an effective
automated exemplar selection method. Recent studies have explored
retrieval-based approaches to select exemplars tailored to individual test
queries, which can be undesirable due to extra test-time computation and an
increased risk of data exposure. Moreover, existing methods fail to adequately
account for the impact of exemplar ordering on the performance. On the other
hand, the impact of the instruction, another essential component in the prompt
given to the LLM, is often overlooked in existing exemplar selection methods.
To address these challenges, we propose a novel method named EASE, which
leverages the hidden embedding from a pre-trained language model to represent
ordered sets of exemplars and uses a neural bandit algorithm to optimize the
sets of exemplars while accounting for exemplar ordering. Our EASE can
efficiently find an ordered set of exemplars that performs well for all test
queries from a given task, thereby eliminating test-time computation.
Importantly, EASE can be readily extended to jointly optimize both the
exemplars and the instruction. Through extensive empirical evaluations
(including novel tasks), we demonstrate the superiority of EASE over existing
methods, and reveal practical insights about the impact of exemplar selection
on ICL, which may be of independent interest. Our code is available at
https://github.com/ZhaoxuanWu/EASE-Prompt-Optimization.",2024-05-25,"Zhaoxuan Wu, Xiaoqiang Lin, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2405.16122v2,cs.CL
SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT clinical terminology,"The extraction and analysis of insights from medical data, primarily stored
in free-text formats by healthcare workers, presents significant challenges due
to its unstructured nature. Medical coding, a crucial process in healthcare,
remains minimally automated due to the complexity of medical ontologies and
restricted access to medical texts for training Natural Language Processing
models. In this paper, we proposed a method, ""SNOBERT,"" of linking text spans
in clinical notes to specific concepts in the SNOMED CT using BERT-based
models. The method consists of two stages: candidate selection and candidate
matching. The models were trained on one of the largest publicly available
dataset of labeled clinical notes. SNOBERT outperforms other classical methods
based on deep learning, as confirmed by the results of a challenge in which it
was applied.",2024-05-25,"Mikhail Kulyabin, Gleb Sokolov, Aleksandr Galaida, Andreas Maier, Tomas Arias-Vergara",http://arxiv.org/pdf/2405.16115v1,cs.CL
Paths of A Million People: Extracting Life Trajectories from Wikipedia,"The life trajectories of notable people have been studied to pinpoint the
times and places of significant events such as birth, death, education,
marriage, competition, work, speeches, scientific discoveries, artistic
achievements, and battles. Understanding how these individuals interact with
others provides valuable insights for broader research into human dynamics.
However, the scarcity of trajectory data in terms of volume, density, and
inter-person interactions, limits relevant studies from being comprehensive and
interactive. We mine millions of biography pages from Wikipedia and tackle the
generalization problem stemming from the variety and heterogeneity of the
trajectory descriptions. Our ensemble model COSMOS, which combines the idea of
semi-supervised learning and contrastive learning, achieves an F1 score of
85.95%. For this task, we also create a hand-curated dataset,
WikiLifeTrajectory, consisting of 8,852 (person, time, location) triplets as
ground truth. Besides, we perform an empirical analysis on the trajectories of
8,272 historians to demonstrate the validity of the extracted results. To
facilitate the research on trajectory extractions and help the analytical
studies to construct grand narratives, we make our code, the million-level
extracted trajectories, and the WikiLifeTrajectory dataset publicly available.",2024-05-25,"Ying Zhang, Xiaofeng Li, Zhaoyang Liu, Haipeng Zhang",http://arxiv.org/pdf/2406.00032v2,cs.CL
Towards Completeness-Oriented Tool Retrieval for Large Language Models,"Recently, integrating external tools with Large Language Models (LLMs) has
gained significant attention as an effective strategy to mitigate the
limitations inherent in their pre-training data. However, real-world systems
often incorporate a wide array of tools, making it impractical to input all
tools into LLMs due to length limitations and latency constraints. Therefore,
to fully exploit the potential of tool-augmented LLMs, it is crucial to develop
an effective tool retrieval system. Existing tool retrieval methods primarily
focus on semantic matching between user queries and tool descriptions,
frequently leading to the retrieval of redundant, similar tools. Consequently,
these methods fail to provide a complete set of diverse tools necessary for
addressing the multifaceted problems encountered by LLMs. In this paper, we
propose a novel modelagnostic COllaborative Learning-based Tool Retrieval
approach, COLT, which captures not only the semantic similarities between user
queries and tool descriptions but also takes into account the collaborative
information of tools. Specifically, we first fine-tune the PLM-based retrieval
models to capture the semantic relationships between queries and tools in the
semantic learning stage. Subsequently, we construct three bipartite graphs
among queries, scenes, and tools and introduce a dual-view graph collaborative
learning framework to capture the intricate collaborative relationships among
tools during the collaborative learning stage. Extensive experiments on both
the open benchmark and the newly introduced ToolLens dataset show that COLT
achieves superior performance. Notably, the performance of BERT-mini (11M) with
our proposed model framework outperforms BERT-large (340M), which has 30 times
more parameters. Furthermore, we will release ToolLens publicly to facilitate
future research on tool retrieval.",2024-05-25,"Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen",http://arxiv.org/pdf/2405.16089v2,cs.CL
Keypoint-based Progressive Chain-of-Thought Distillation for LLMs,"Chain-of-thought distillation is a powerful technique for transferring
reasoning abilities from large language models (LLMs) to smaller student
models. Previous methods typically require the student to mimic the
step-by-step rationale produced by LLMs, often facing the following challenges:
(i) Tokens within a rationale vary in significance, and treating them equally
may fail to accurately mimic keypoint tokens, leading to reasoning errors. (ii)
They usually distill knowledge by consistently predicting all the steps in a
rationale, which falls short in distinguishing the learning order of step
generation. This diverges from the human cognitive progression of starting with
easy tasks and advancing to harder ones, resulting in sub-optimal outcomes. To
this end, we propose a unified framework, called KPOD, to address these issues.
Specifically, we propose a token weighting module utilizing mask learning to
encourage accurate mimicry of keypoint tokens by the student during
distillation. Besides, we develop an in-rationale progressive distillation
strategy, starting with training the student to generate the final reasoning
steps and gradually extending to cover the entire rationale. To accomplish
this, a weighted token generation loss is proposed to assess step reasoning
difficulty, and a value function is devised to schedule the progressive
distillation by considering both step difficulty and question diversity.
Extensive experiments on four reasoning benchmarks illustrate our KPOD
outperforms previous methods by a large margin.",2024-05-25,"Kaituo Feng, Changsheng Li, Xiaolu Zhang, Jun Zhou, Ye Yuan, Guoren Wang",http://arxiv.org/pdf/2405.16064v1,cs.CL
SPP: Sparsity-Preserved Parameter-Efficient Fine-Tuning for Large Language Models,"Large Language Models (LLMs) have become pivotal in advancing the field of
artificial intelligence, yet their immense sizes pose significant challenges
for both fine-tuning and deployment. Current post-training pruning methods,
while reducing the sizes of LLMs, often fail to maintain their original
performance. To address these challenges, this paper introduces SPP, a
Sparsity-Preserved Parameter-efficient fine-tuning method. Different from
existing post-training pruning approaches that struggle with performance
retention, SPP proposes to employ lightweight learnable column and row matrices
to optimize sparse LLM weights, keeping the structure and sparsity of pruned
pre-trained models intact. By element-wise multiplication and residual
addition, SPP ensures the consistency of model sparsity pattern and ratio
during both training and weight-merging processes. We demonstrate the
effectiveness of SPP by applying it to the LLaMA and LLaMA-2 model families
with recent post-training pruning methods. Our results show that SPP
significantly enhances the performance of models with different sparsity
patterns (i.e. unstructured and N:M sparsity), especially for those with high
sparsity ratios (e.g. 75%), making it a promising solution for the efficient
fine-tuning of sparse LLMs. Code will be made available at
https://github.com/Lucky-Lance/SPP.",2024-05-25,"Xudong Lu, Aojun Zhou, Yuhui Xu, Renrui Zhang, Peng Gao, Hongsheng Li",http://arxiv.org/pdf/2405.16057v1,cs.CL
Theoretical Analysis of Weak-to-Strong Generalization,"Strong student models can learn from weaker teachers: when trained on the
predictions of a weaker model, a strong pretrained student can learn to correct
the weak model's errors and generalize to examples where the teacher is not
confident, even when these examples are excluded from training. This enables
learning from cheap, incomplete, and possibly incorrect label information, such
as coarse logical rules or the generations of a language model. We show that
existing weak supervision theory fails to account for both of these effects,
which we call pseudolabel correction and coverage expansion, respectively. We
give a new bound based on expansion properties of the data distribution and
student hypothesis class that directly accounts for pseudolabel correction and
coverage expansion. Our bounds capture the intuition that weak-to-strong
generalization occurs when the strong model is unable to fit the mistakes of
the weak teacher without incurring additional error. We show that these
expansion properties can be checked from finite data and give empirical
evidence that they hold in practice.",2024-05-25,"Hunter Lang, David Sontag, Aravindan Vijayaraghavan",http://arxiv.org/pdf/2405.16043v1,cs.CL
"Incremental Comprehension of Garden-Path Sentences by Large Language Models: Semantic Interpretation, Syntactic Re-Analysis, and Attention","When reading temporarily ambiguous garden-path sentences, misinterpretations
sometimes linger past the point of disambiguation. This phenomenon has
traditionally been studied in psycholinguistic experiments using online
measures such as reading times and offline measures such as comprehension
questions. Here, we investigate the processing of garden-path sentences and the
fate of lingering misinterpretations using four large language models (LLMs):
GPT-2, LLaMA-2, Flan-T5, and RoBERTa. The overall goal is to evaluate whether
humans and LLMs are aligned in their processing of garden-path sentences and in
the lingering misinterpretations past the point of disambiguation, especially
when extra-syntactic information (e.g., a comma delimiting a clause boundary)
is present to guide processing. We address this goal using 24 garden-path
sentences that have optional transitive and reflexive verbs leading to
temporary ambiguities. For each sentence, there are a pair of comprehension
questions corresponding to the misinterpretation and the correct
interpretation. In three experiments, we (1) measure the dynamic semantic
interpretations of LLMs using the question-answering task; (2) track whether
these models shift their implicit parse tree at the point of disambiguation (or
by the end of the sentence); and (3) visualize the model components that attend
to disambiguating information when processing the question probes. These
experiments show promising alignment between humans and LLMs in the processing
of garden-path sentences, especially when extra-syntactic information is
available to guide processing.",2024-05-25,"Andrew Li, Xianle Feng, Siddhant Narang, Austin Peng, Tianle Cai, Raj Sanjay Shah, Sashank Varma",http://arxiv.org/pdf/2405.16042v1,cs.CL
Evaluating and Safeguarding the Adversarial Robustness of Retrieval-Based In-Context Learning,"With the emergence of large language models, such as LLaMA and OpenAI GPT-3,
In-Context Learning (ICL) gained significant attention due to its effectiveness
and efficiency. However, ICL is very sensitive to the choice, order, and
verbaliser used to encode the demonstrations in the prompt. Retrieval-Augmented
ICL methods try to address this problem by leveraging retrievers to extract
semantically related examples as demonstrations. While this approach yields
more accurate results, its robustness against various types of adversarial
attacks, including perturbations on test samples, demonstrations, and retrieved
data, remains under-explored. Our study reveals that retrieval-augmented models
can enhance robustness against test sample attacks, outperforming vanilla ICL
with a 4.87% reduction in Attack Success Rate (ASR); however, they exhibit
overconfidence in the demonstrations, leading to a 2% increase in ASR for
demonstration attacks. Adversarial training can help improve the robustness of
ICL methods to adversarial attacks; however, such a training scheme can be too
costly in the context of LLMs. As an alternative, we introduce an effective
training-free adversarial defence method, DARD, which enriches the example pool
with those attacked samples. We show that DARD yields improvements in
performance and robustness, achieving a 15% reduction in ASR over the
baselines. Code and data are released to encourage further research:
https://github.com/simonucl/adv-retreival-icl",2024-05-24,"Simon Yu, Jie He, Pasquale Minervini, Jeff Z. Pan",http://arxiv.org/pdf/2405.15984v4,cs.CL
Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement,"Large vision-language models (LVLMs) have achieved impressive results in
visual question-answering and reasoning tasks through vision instruction tuning
on specific datasets. However, there remains significant room for improvement
in aligning visual and language modalities. Existing methods often depend on
external models or data, leading to uncontrollable and unstable alignment
results. In this paper, we propose SIMA, a self-improvement framework that
enhances visual and language modality alignment without external dependencies.
SIMA leverages existing vision instruction tuning datasets to self-generate
responses, incorporating an in-context self-critic mechanism that constructs
preference pairs for tuning. Crucially, our approach allows LVLMs to act as
critics by designing effective critic prompts, eliminating the need for
additional fine-tuning with external instruction data. We introduce three novel
visual metrics within the self-critic process to guide judgment, significantly
improving the accuracy of self-critic. Through extensive experiments across 14
hallucination and comprehensive benchmarks, we demonstrate that SIMA
significantly improves LVLM's performance and outperforms previous approaches,
achieving superior modality alignment.",2024-05-24,"Xiyao Wang, Jiuhai Chen, Zhaoyang Wang, Yuhang Zhou, Yiyang Zhou, Huaxiu Yao, Tianyi Zhou, Tom Goldstein, Parminder Bhatia, Furong Huang, Cao Xiao",http://arxiv.org/pdf/2405.15973v4,cs.CL
A hierarchical Bayesian model for syntactic priming,"The effect of syntactic priming exhibits three well-documented empirical
properties: the lexical boost, the inverse frequency effect, and the
asymmetrical decay. We aim to show how these three empirical phenomena can be
reconciled in a general learning framework, the hierarchical Bayesian model
(HBM). The model represents syntactic knowledge in a hierarchical structure of
syntactic statistics, where a lower level represents the verb-specific biases
of syntactic decisions, and a higher level represents the abstract bias as an
aggregation of verb-specific biases. This knowledge is updated in response to
experience by Bayesian inference. In simulations, we show that the HBM captures
the above-mentioned properties of syntactic priming. The results indicate that
some properties of priming which are usually explained by a residual activation
account can also be explained by an implicit learning account. We also discuss
the model's implications for the lexical basis of syntactic priming.",2024-05-24,"Weijie Xu, Richard Futrell",http://arxiv.org/pdf/2405.15964v1,cs.CL
Transformers represent belief state geometry in their residual stream,"What computational structure are we building into large language models when
we train them on next-token prediction? Here, we present evidence that this
structure is given by the meta-dynamics of belief updating over hidden states
of the data-generating process. Leveraging the theory of optimal prediction, we
anticipate and then find that belief states are linearly represented in the
residual stream of transformers, even in cases where the predicted belief state
geometry has highly nontrivial fractal structure. We investigate cases where
the belief state geometry is represented in the final residual stream or
distributed across the residual streams of multiple layers, providing a
framework to explain these observations. Furthermore we demonstrate that the
inferred belief states contain information about the entire future, beyond the
local next-token prediction that the transformers are explicitly trained on.
Our work provides a general framework connecting the structure of training data
to the geometric structure of activations inside transformers.",2024-05-24,"Adam S. Shai, Sarah E. Marzen, Lucas Teixeira, Alexander Gietelink Oldenziel, Paul M. Riechers",http://arxiv.org/pdf/2405.15943v3,cs.CL
Zero-Shot Spam Email Classification Using Pre-trained Large Language Models,"This paper investigates the application of pre-trained large language models
(LLMs) for spam email classification using zero-shot prompting. We evaluate the
performance of both open-source (Flan-T5) and proprietary LLMs (ChatGPT, GPT-4)
on the well-known SpamAssassin dataset. Two classification approaches are
explored: (1) truncated raw content from email subject and body, and (2)
classification based on summaries generated by ChatGPT. Our empirical analysis,
leveraging the entire dataset for evaluation without further training, reveals
promising results. Flan-T5 achieves a 90% F1-score on the truncated content
approach, while GPT-4 reaches a 95% F1-score using summaries. While these
initial findings on a single dataset suggest the potential for classification
pipelines of LLM-based subtasks (e.g., summarisation and classification),
further validation on diverse datasets is necessary. The high operational costs
of proprietary models, coupled with the general inference costs of LLMs, could
significantly hinder real-world deployment for spam filtering.",2024-05-24,Sergio Rojas-Galeano,http://arxiv.org/pdf/2405.15936v1,cs.CL
SLIDE: A Framework Integrating Small and Large Language Models for Open-Domain Dialogues Evaluation,"The long-standing one-to-many problem of gold standard responses in
open-domain dialogue systems presents challenges for automatic evaluation
metrics. Though prior works have demonstrated some success by applying powerful
Large Language Models (LLMs), existing approaches still struggle with the
one-to-many problem, and exhibit subpar performance in domain-specific
scenarios. We assume the commonsense reasoning biases within LLMs may hinder
their performance in domainspecific evaluations. To address both issues, we
propose a novel framework SLIDE (Small and Large Integrated for Dialogue
Evaluation), that leverages both a small, specialised model (SLM), and LLMs for
the evaluation of open domain dialogues. Our approach introduces several
techniques: (1) Contrastive learning to differentiate between robust and
non-robust response embeddings; (2) A novel metric for semantic sensitivity
that combines embedding cosine distances with similarity learned through neural
networks, and (3) a strategy for incorporating the evaluation results from both
the SLM and LLMs. Our empirical results demonstrate that our approach achieves
state-of-the-art performance in both the classification and evaluation tasks,
and additionally the SLIDE evaluator exhibits better correlation with human
judgements. Our code is available at https://
github.com/hegehongcha/SLIDE-ACL2024.",2024-05-24,"Kun Zhao, Bohao Yang, Chen Tang, Chenghua Lin, Liang Zhan",http://arxiv.org/pdf/2405.15924v3,cs.CL
AMGPT: a Large Language Model for Contextual Querying in Additive Manufacturing,"Generalized large language models (LLMs) such as GPT-4 may not provide
specific answers to queries formulated by materials science researchers. These
models may produce a high-level outline but lack the capacity to return
detailed instructions on manufacturing and material properties of novel alloys.
Enhancing a smaller model with specialized domain knowledge may provide an
advantage over large language models which cannot be retrained quickly enough
to keep up with the rapid pace of research in metal additive manufacturing
(AM). We introduce ""AMGPT,"" a specialized LLM text generator designed for metal
AM queries. The goal of AMGPT is to assist researchers and users in navigating
the extensive corpus of literature in AM. Instead of training from scratch, we
employ a pre-trained Llama2-7B model from Hugging Face in a Retrieval-Augmented
Generation (RAG) setup, utilizing it to dynamically incorporate information
from $\sim$50 AM papers and textbooks in PDF format. Mathpix is used to convert
these PDF documents into TeX format, facilitating their integration into the
RAG pipeline managed by LlamaIndex. Expert evaluations of this project
highlight that specific embeddings from the RAG setup accelerate response times
and maintain coherence in the generated text.",2024-05-24,"Achuth Chandrasekhar, Jonathan Chan, Francis Ogoke, Olabode Ajenifujah, Amir Barati Farimani",http://arxiv.org/pdf/2406.00031v1,cs.CL
Hacc-Man: An Arcade Game for Jailbreaking LLMs,"The recent leaps in complexity and fluency of Large Language Models (LLMs)
mean that, for the first time in human history, people can interact with
computers using natural language alone. This creates monumental possibilities
of automation and accessibility of computing, but also raises severe security
and safety threats: When everyone can interact with LLMs, everyone can
potentially break into the systems running LLMs. All it takes is creative use
of language. This paper presents Hacc-Man, a game which challenges its players
to ""jailbreak"" an LLM: subvert the LLM to output something that it is not
intended to. Jailbreaking is at the intersection between creative problem
solving and LLM security. The purpose of the game is threefold: 1. To heighten
awareness of the risks of deploying fragile LLMs in everyday systems, 2. To
heighten people's self-efficacy in interacting with LLMs, and 3. To discover
the creative problem solving strategies, people deploy in this novel context.",2024-05-24,"Matheus Valentim, Jeanette Falk, Nanna Inie",http://arxiv.org/pdf/2405.15902v1,cs.CL
Enhancing Augmentative and Alternative Communication with Card Prediction and Colourful Semantics,"This paper presents an approach to enhancing Augmentative and Alternative
Communication (AAC) systems by integrating Colourful Semantics (CS) with
transformer-based language models specifically tailored for Brazilian
Portuguese. We introduce an adapted BERT model, BERTptCS, which incorporates
the CS framework for improved prediction of communication cards. The primary
aim is to enhance the accuracy and contextual relevance of communication card
predictions, which are essential in AAC systems for individuals with complex
communication needs (CCN). We compared BERTptCS with a baseline model,
BERTptAAC, which lacks CS integration. Our results demonstrate that BERTptCS
significantly outperforms BERTptAAC in various metrics, including top-k
accuracy, Mean Reciprocal Rank (MRR), and Entropy@K. Integrating CS into the
language model improves prediction accuracy and offers a more intuitive and
contextual understanding of user inputs, facilitating more effective
communication.",2024-05-24,"Jayr Pereira, Francisco Rodrigues, Jaylton Pereira, Cleber Zanchettin, Robson Fidalgo",http://arxiv.org/pdf/2405.15896v1,cs.CL
Basis Selection: Low-Rank Decomposition of Pretrained Large Language Models for Target Applications,"Large language models (LLMs) significantly enhance the performance of various
applications, but they are computationally intensive and energy-demanding. This
makes it challenging to deploy them on devices with limited resources, such as
personal computers and mobile/wearable devices, and results in substantial
inference costs in resource-rich environments like cloud servers. To extend the
use of LLMs, we introduce a low-rank decomposition approach to effectively
compress these models, tailored to the requirements of specific applications.
We observe that LLMs pretrained on general datasets contain many redundant
components not needed for particular applications. Our method focuses on
identifying and removing these redundant parts, retaining only the necessary
elements for the target applications. Specifically, we represent the weight
matrices of LLMs as a linear combination of base components. We then prune the
irrelevant bases and enhance the model with new bases beneficial for specific
applications. Deep compression results on the Llama 2-7b and -13B models,
conducted on target applications including mathematical reasoning and code
generation, show that our method significantly reduces model size while
maintaining comparable accuracy to state-of-the-art low-rank compression
techniques.",2024-05-24,"Yang Li, Changsheng Zhao, Hyungtak Lee, Ernie Chang, Yangyang Shi, Vikas Chandra",http://arxiv.org/pdf/2405.15877v1,cs.CL
Large Language Model Pruning,"We surely enjoy the larger the better models for their superior performance
in the last couple of years when both the hardware and software support the
birth of such extremely huge models. The applied fields include text mining and
others. In particular, the success of LLMs on text understanding and text
generation draws attention from researchers who have worked on NLP and related
areas for years or even decades. On the side, LLMs may suffer from problems
like model overfitting, hallucination, and device limitation to name a few. In
this work, we suggest a model pruning technique specifically focused on LLMs.
The proposed methodology emphasizes the explainability of deep learning models.
By having the theoretical foundation, we obtain a trustworthy deep model so
that huge models with a massive number of model parameters become not quite
necessary. A mutual information-based estimation is adopted to find neurons
with redundancy to eliminate. Moreover, an estimator with well-tuned parameters
helps to find precise estimation to guide the pruning procedure. At the same
time, we also explore the difference between pruning on large-scale models vs.
pruning on small-scale models. The choice of pruning criteria is sensitive in
small models but not for large-scale models. It is a novel finding through this
work. Overall, we demonstrate the superiority of the proposed model to the
state-of-the-art models.",2024-05-24,"Hanjuan Huang, Hao-Jia Song, Hsing-Kuo Pao",http://arxiv.org/pdf/2406.00030v1,cs.CL
Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development,"The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,
enhancing patient safety by identifying potential risks associated with
medications, facilitating early detection of adverse events, and guiding
regulatory decision-making. Traditional ADE detection methods are reliable but
slow, not easily adaptable to large-scale operations, and offer limited
information. With the exponential increase in data sources like social media
content, biomedical literature, and Electronic Medical Records (EMR),
extracting relevant ADE-related information from these unstructured texts is
imperative. Previous ADE mining studies have focused on text-based
methodologies, overlooking visual cues, limiting contextual comprehension, and
hindering accurate interpretation. To address this gap, we present a MultiModal
Adverse Drug Event (MMADE) detection dataset, merging ADE-related textual
information with visual aids. Additionally, we introduce a framework that
leverages the capabilities of LLMs and VLMs for ADE detection by generating
detailed descriptions of medical images depicting ADEs, aiding healthcare
professionals in visually identifying adverse events. Using our MMADE dataset,
we showcase the significance of integrating visual cues from images to enhance
overall performance. This approach holds promise for patient safety, ADE
awareness, and healthcare accessibility, paving the way for further exploration
in personalized healthcare.",2024-05-24,"Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal",http://arxiv.org/pdf/2405.15766v2,cs.CL
Scaling Laws for Discriminative Classification in Large Language Models,"Modern large language models (LLMs) represent a paradigm shift in what can
plausibly be expected of machine learning models. The fact that LLMs can
effectively generate sensible answers to a diverse range of queries suggests
that they would be useful in customer support applications. While powerful,
LLMs have been observed to be prone to hallucination which unfortunately makes
their near term use in customer support applications challenging. To address
this issue we present a system that allows us to use an LLM to augment our
customer support advocates by re-framing the language modeling task as a
discriminative classification task. In this framing, we seek to present the
top-K best template responses for a customer support advocate to use when
responding to a customer. We present the result of both offline and online
experiments where we observed offline gains and statistically significant
online lifts for our experimental system. Along the way, we present observed
scaling curves for validation loss and top-K accuracy, resulted from model
parameter ablation studies. We close by discussing the space of trade-offs with
respect to model size, latency, and accuracy as well as and suggesting future
applications to explore.",2024-05-24,"Dean Wyatte, Fatemeh Tahmasbi, Ming Li, Thomas Markovich",http://arxiv.org/pdf/2405.15765v1,cs.CL
GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction,"Social biases in LLMs are usually measured via bias benchmark datasets.
Current benchmarks have limitations in scope, grounding, quality, and human
effort required. Previous work has shown success with a community-sourced,
rather than crowd-sourced, approach to benchmark development. However, this
work still required considerable effort from annotators with relevant lived
experience. This paper explores whether an LLM (specifically, GPT-3.5-Turbo)
can assist with the task of developing a bias benchmark dataset from responses
to an open-ended community survey. We also extend the previous work to a new
community and set of biases: the Jewish community and antisemitism. Our
analysis shows that GPT-3.5-Turbo has poor performance on this annotation task
and produces unacceptable quality issues in its output. Thus, we conclude that
GPT-3.5-Turbo is not an appropriate substitute for human annotation in
sensitive tasks related to social biases, and that its use actually negates
many of the benefits of community-sourcing bias benchmarks.",2024-05-24,"Virginia K. Felkner, Jennifer A. Thompson, Jonathan May",http://arxiv.org/pdf/2405.15760v1,cs.CL
Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence,"This paper introduces Filtered Corpus Training, a method that trains language
models (LMs) on corpora with certain linguistic constructions filtered out from
the training data, and uses it to measure the ability of LMs to perform
linguistic generalization on the basis of indirect evidence. We apply the
method to both LSTM and Transformer LMs (of roughly comparable size),
developing filtered corpora that target a wide range of linguistic phenomena.
Our results show that while transformers are better qua LMs (as measured by
perplexity), both models perform equally and surprisingly well on linguistic
generalization measures, suggesting that they are capable of generalizing from
indirect evidence.",2024-05-24,"Abhinav Patil, Jaap Jumelet, Yu Ying Chiu, Andy Lapastora, Peter Shen, Lexie Wang, Clevis Willrich, Shane Steinert-Threlkeld",http://arxiv.org/pdf/2405.15750v2,cs.CL
Optimizing Large Language Models for OpenAPI Code Completion,"Recent advancements in Large Language Models (LLMs) and their utilization in
code generation tasks have significantly reshaped the field of software
development. Despite the remarkable efficacy of code completion solutions in
mainstream programming languages, their performance lags when applied to less
ubiquitous formats such as OpenAPI definitions. This study evaluates the
OpenAPI completion performance of GitHub Copilot, a prevalent commercial code
completion tool, and proposes a set of task-specific optimizations leveraging
Meta's open-source model Code Llama. A semantics-aware OpenAPI completion
benchmark proposed in this research is used to perform a series of experiments
through which the impact of various prompt-engineering and fine-tuning
techniques on the Code Llama model's performance is analyzed. The fine-tuned
Code Llama model reaches a peak correctness improvement of 55.2% over GitHub
Copilot despite utilizing 25 times fewer parameters than the commercial
solution's underlying Codex model. Additionally, this research proposes an
enhancement to a widely used code infilling training technique, addressing the
issue of underperformance when the model is prompted with context sizes smaller
than those used during training. The dataset, the benchmark, and the model
fine-tuning code are made publicly available.",2024-05-24,"Bohdan Petryshyn, Mantas Lukoševičius",http://arxiv.org/pdf/2405.15729v2,cs.CL
EmpathicStories++: A Multimodal Dataset for Empathy towards Personal Experiences,"Modeling empathy is a complex endeavor that is rooted in interpersonal and
experiential dimensions of human interaction, and remains an open problem
within AI. Existing empathy datasets fall short in capturing the richness of
empathy responses, often being confined to in-lab or acted scenarios, lacking
longitudinal data, and missing self-reported labels. We introduce a new
multimodal dataset for empathy during personal experience sharing: the
EmpathicStories++ dataset
(https://mitmedialab.github.io/empathic-stories-multimodal/) containing 53
hours of video, audio, and text data of 41 participants sharing vulnerable
experiences and reading empathically resonant stories with an AI agent.
EmpathicStories++ is the first longitudinal dataset on empathy, collected over
a month-long deployment of social robots in participants' homes, as
participants engage in natural, empathic storytelling interactions with AI
agents. We then introduce a novel task of predicting individuals' empathy
toward others' stories based on their personal experiences, evaluated in two
contexts: participants' own personal shared story context and their reflections
on stories they read. We benchmark this task using state-of-the-art models to
pave the way for future improvements in contextualized and longitudinal empathy
modeling. Our work provides a valuable resource for further research in
developing empathetic AI systems and understanding the intricacies of human
empathy within genuine, real-world settings.",2024-05-24,"Jocelyn Shen, Yubin Kim, Mohit Hulse, Wazeer Zulfikar, Sharifa Alghowinem, Cynthia Breazeal, Hae Won Park",http://arxiv.org/pdf/2405.15708v1,cs.CL
Clustered Retrieved Augmented Generation (CRAG),"Providing external knowledge to Large Language Models (LLMs) is a key point
for using these models in real-world applications for several reasons, such as
incorporating up-to-date content in a real-time manner, providing access to
domain-specific knowledge, and contributing to hallucination prevention. The
vector database-based Retrieval Augmented Generation (RAG) approach has been
widely adopted to this end. Thus, any part of external knowledge can be
retrieved and provided to some LLM as the input context. Despite RAG approach's
success, it still might be unfeasible for some applications, because the
context retrieved can demand a longer context window than the size supported by
LLM. Even when the context retrieved fits into the context window size, the
number of tokens might be expressive and, consequently, impact costs and
processing time, becoming impractical for most applications. To address these,
we propose CRAG, a novel approach able to effectively reduce the number of
prompting tokens without degrading the quality of the response generated
compared to a solution using RAG. Through our experiments, we show that CRAG
can reduce the number of tokens by at least 46\%, achieving more than 90\% in
some cases, compared to RAG. Moreover, the number of tokens with CRAG does not
increase considerably when the number of reviews analyzed is higher, unlike
RAG, where the number of tokens is almost 9x higher when there are 75 reviews
compared to 4 reviews.",2024-05-24,"Simon Akesson, Frances A. Santos",http://arxiv.org/pdf/2406.00029v1,cs.CL
Visual Description Grounding Reduces Hallucinations and Boosts Reasoning in LVLMs,"Large Vision-Language Models (LVLMs) often produce responses that misalign
with factual information, a phenomenon known as hallucinations. While
hallucinations are well-studied, the exact causes behind them remain
underexplored. In this paper, we first investigate the root causes of
hallucinations in LVLMs. Our findings reveal that existing mitigation
techniques primarily reduce hallucinations for visual recognition prompts-those
that require simple descriptions of visual elements-but fail for cognitive
prompts that demand deliberate reasoning. We identify the core issue as a lack
of true visual perception in LVLMs: although they can accurately recognize
visual elements, they struggle to fully interpret these elements in the context
of the input prompt and effectively link this recognition to their internal
knowledge, which is critical for reasoning. To address this gap, we introduce
Visual Description Grounded Decoding (VDGD), a simple, robust, and
training-free method designed to enhance visual perception and improve
reasoning capabilities in LVLMs. VDGD works by first generating a detailed
description of the image and appending it as a prefix to the instruction.
During response generation, tokens are sampled based on their KL divergence to
the description, favoring candidates with lower divergence. Experimental
results on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD
consistently outperforms existing baselines 2% - 33%. Finally, we introduce
VaLLu, a benchmark designed for comprehensive evaluation of the cognitive
capabilities of LVLMs.",2024-05-24,"Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, Oriol Nieto, Zeyu Jin, Dinesh Manocha",http://arxiv.org/pdf/2405.15683v3,cs.CL
"GECKO: Generative Language Model for English, Code and Korean","We introduce GECKO, a bilingual large language model (LLM) optimized for
Korean and English, along with programming languages. GECKO is pretrained on
the balanced, high-quality corpus of Korean and English employing LLaMA
architecture. In this report, we share the experiences of several efforts to
build a better data pipeline for the corpus and to train our model. GECKO shows
great efficiency in token generations for both Korean and English, despite its
small size of vocabulary. We measure the performance on the representative
benchmarks in terms of Korean, English and Code, and it exhibits great
performance on KMMLU (Korean MMLU) and modest performance in English and Code,
even with its smaller number of trained tokens compared to English-focused
LLMs. GECKO is available to the open-source community under a permissive
license. We hope our work offers a research baseline and practical insights for
Korean LLM research. The model can be found at:
https://huggingface.co/kifai/GECKO-7B",2024-05-24,"Sungwoo Oh, Donggyu Kim",http://arxiv.org/pdf/2405.15640v1,cs.CL
M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models,"Multilingual capability is an essential aspect for large multimodal models,
since they are usually deployed across various countries and languages.
However, most existing benchmarks for multilingual multimodal reasoning
struggle to differentiate between models of varying performance; even language
models without visual capabilities can easily achieve high scores. This leaves
a comprehensive evaluation of leading multilingual multimodal models largely
unexplored. In this work, we introduce M4U, a novel and challenging benchmark
for assessing the capability of multi-discipline multilingual multimodal
understanding and reasoning. M4U contains 10k samples covering 64 disciplines
across 16 subfields in Science, Engineering, and Healthcare in six languages.
Using M4U, we conduct extensive evaluations of leading Large Multimodal Models
(LMMs) and Large Language Models (LLMs) with external tools. The evaluation
results demonstrate that the state-of-the-art model, GPT-4o, achieves only
47.6% average accuracy on M4U. Additionally, we observe that the leading LMMs
exhibit significant language preferences. Our in-depth analysis indicates that
leading LMMs, including GPT-4o, struggle to perform reasoning using
multilingual information present in both visual and textual context.
Specifically, they suffer performance degradation when prompted with
cross-lingual multimodal questions. Our code and dataset is public available.",2024-05-24,"Hongyu Wang, Jiayu Xu, Senwei Xie, Ruiping Wang, Jialin Li, Zhaojie Xie, Bin Zhang, Chuyan Xiong, Xilin Chen",http://arxiv.org/pdf/2405.15638v2,cs.CL
Word Sense Disambiguation in Persian: Can AI Finally Get It Right?,"Homograph disambiguation, the task of distinguishing words with identical
spellings but different meanings, poses a substantial challenge in natural
language processing. In this study, we introduce a novel dataset tailored for
Persian homograph disambiguation. Our work encompasses a thorough exploration
of various embeddings, evaluated through the cosine similarity method and their
efficacy in downstream tasks like classification. Our investigation entails
training a diverse array of lightweight machine learning and deep learning
models for phonograph disambiguation. We scrutinize the models' performance in
terms of Accuracy, Recall, and F1 Score, thereby gaining insights into their
respective strengths and limitations. The outcomes of our research underscore
three key contributions. First, we present a newly curated Persian dataset,
providing a solid foundation for future research in homograph disambiguation.
Second, our comparative analysis of embeddings highlights their utility in
different contexts, enriching the understanding of their capabilities. Third,
by training and evaluating a spectrum of models, we extend valuable guidance
for practitioners in selecting suitable strategies for homograph disambiguation
tasks. In summary, our study unveils a new dataset, scrutinizes embeddings
through diverse perspectives, and benchmarks various models for homograph
disambiguation. These findings empower researchers and practitioners to
navigate the intricate landscape of homograph-related challenges effectively.",2024-05-24,"Seyed Moein Ayyoubzadeh, Kourosh Shahnazari",http://arxiv.org/pdf/2406.00028v3,cs.CL
"Text Generation: A Systematic Literature Review of Tasks, Evaluation, and Challenges","Text generation has become more accessible than ever, and the increasing
interest in these systems, especially those using large language models, has
spurred an increasing number of related publications. We provide a systematic
literature review comprising 244 selected papers between 2017 and 2024. This
review categorizes works in text generation into five main tasks: open-ended
text generation, summarization, translation, paraphrasing, and question
answering. For each task, we review their relevant characteristics, sub-tasks,
and specific challenges (e.g., missing datasets for multi-document
summarization, coherence in story generation, and complex reasoning for
question answering). Additionally, we assess current approaches for evaluating
text generation systems and ascertain problems with current metrics. Our
investigation shows nine prominent challenges common to all tasks and sub-tasks
in recent text generation publications: bias, reasoning, hallucinations,
misuse, privacy, interpretability, transparency, datasets, and computing. We
provide a detailed analysis of these challenges, their potential solutions, and
which gaps still require further engagement from the community. This systematic
literature review targets two main audiences: early career researchers in
natural language processing looking for an overview of the field and promising
research directions, as well as experienced researchers seeking a detailed view
of tasks, evaluation methodologies, open challenges, and recent mitigation
strategies.",2024-05-24,"Jonas Becker, Jan Philip Wahle, Bela Gipp, Terry Ruas",http://arxiv.org/pdf/2405.15604v3,cs.CL
Profiling checkpointing schedules in adjoint ST-AD,"Checkpointing is a cornerstone of data-flow reversal in adjoint algorithmic
differentiation. Checkpointing is a storage/recomputation trade-off that can be
applied at different levels, one of which being the call tree. We are looking
for good placements of checkpoints onto the call tree of a given application,
to reduce run time and memory footprint of its adjoint. There is no known
optimal solution to this problem other than a combinatorial search on all
placements. We propose a heuristics based on run-time profiling of the adjoint
code. We describe implementation of this profiling tool in an existing
source-transformation AD tool. We demonstrate the interest of this approach on
test cases taken from the MITgcm ocean and atmospheric global circulation
model. We discuss the limitations of our approach and propose directions to
lift them.",2024-05-24,"Laurent Hascoët, Jean-Luc Bouchot, Shreyas Sunil Gaikwad, Sri Hari Krishna Narayanan, Jan Hückelheim",http://arxiv.org/pdf/2405.15590v2,cs.CL
Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems,"End-to-end Task-Oriented Dialog (TOD) systems typically require extensive
training datasets to perform well. In contrast, large language model (LLM)
based TOD systems can excel even with limited data due to their ability to
learn tasks through in-context exemplars. However, these models lack alignment
with the style of responses in training data and often generate comprehensive
responses, making it difficult for users to grasp the information quickly. In
response, we propose SyncTOD that synergizes LLMs with task-specific hints to
improve alignment in low-data settings. SyncTOD employs small auxiliary models
to provide hints and select exemplars for in-context prompts. With ChatGPT,
SyncTOD achieves superior performance compared to LLM-based baselines and SoTA
models in low-data settings, while retaining competitive performance in
full-data settings.",2024-05-24,"Vishal Vivek Saley, Rocktim Jyoti Das, Dinesh Raghu, Mausam",http://arxiv.org/pdf/2405.15585v3,cs.CL
Certifiably Robust RAG against Retrieval Corruption,"Retrieval-augmented generation (RAG) has been shown vulnerable to retrieval
corruption attacks: an attacker can inject malicious passages into retrieval
results to induce inaccurate responses. In this paper, we propose RobustRAG as
the first defense framework against retrieval corruption attacks. The key
insight of RobustRAG is an isolate-then-aggregate strategy: we get LLM
responses from each passage in isolation and then securely aggregate these
isolated responses. To instantiate RobustRAG, we design keyword-based and
decoding-based algorithms for securely aggregating unstructured text responses.
Notably, RobustRAG can achieve certifiable robustness: we can formally prove
and certify that, for certain queries, RobustRAG can always return accurate
responses, even when the attacker has full knowledge of our defense and can
arbitrarily inject a small number of malicious passages. We evaluate RobustRAG
on open-domain QA and long-form text generation datasets and demonstrate its
effectiveness and generalizability across various tasks and datasets.",2024-05-24,"Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, Prateek Mittal",http://arxiv.org/pdf/2405.15556v1,cs.CL
Adapting PromptORE for Modern History: Information Extraction from Hispanic Monarchy Documents of the XVIth Century,"Semantic relations among entities are a widely accepted method for relation
extraction. PromptORE (Prompt-based Open Relation Extraction) was designed to
improve relation extraction with Large Language Models on generalistic
documents. However, it is less effective when applied to historical documents,
in languages other than English. In this study, we introduce an adaptation of
PromptORE to extract relations from specialized documents, namely digital
transcripts of trials from the Spanish Inquisition. Our approach involves
fine-tuning transformer models with their pretraining objective on the data
they will perform inference. We refer to this process as ""biasing"". Our Biased
PromptORE addresses complex entity placements and genderism that occur in
Spanish texts. We solve these issues by prompt engineering. We evaluate our
method using Encoder-like models, corroborating our findings with experts'
assessments. Additionally, we evaluate the performance using a binomial
classification benchmark. Our results show a substantial improvement in
accuracy -up to a 50% improvement with our Biased PromptORE models in
comparison to the baseline models using standard PromptORE.",2024-05-24,"Hèctor Loopez Hidalgo, Michel Boeglin, David Kahn, Josiane Mothe, Diego Ortiz, David Panzoli",http://arxiv.org/pdf/2406.00027v1,cs.CL
Bayesian WeakS-to-Strong from Text Classification to Generation,"Advances in large language models raise the question of how alignment
techniques will adapt as models become increasingly complex and humans will
only be able to supervise them weakly. Weak-to-Strong mimics such a scenario
where weak model supervision attempts to harness the full capabilities of a
much stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by
exploring an ensemble of weak models which simulate the variability in human
opinions. Confidence scores are estimated using a Bayesian approach to guide
the WeakS-to-Strong generalization. Furthermore, we extend the application of
WeakS-to-Strong from text classification tasks to text generation tasks where
more advanced strategies are investigated for supervision. Moreover, direct
preference optimization is applied to advance the student model's preference
learning, beyond the basic learning framework of teacher forcing. Results
demonstrate the effectiveness of the proposed approach for the reliability of a
strong student model, showing potential for superalignment.",2024-05-24,"Ziyun Cui, Ziyang Zhang, Guangzhi Sun, Wen Wu, Chao Zhang",http://arxiv.org/pdf/2406.03199v4,cs.CL
Sparse Matrix in Large Language Model Fine-tuning,"LoRA and its variants have become popular parameter-efficient fine-tuning
(PEFT) methods due to their ability to avoid excessive computational costs.
However, an accuracy gap often exists between PEFT methods and full fine-tuning
(FT), and this gap has yet to be systematically studied. In this work, we
introduce a method for selecting sparse sub-matrices that aim to minimize the
performance gap between PEFT vs. full fine-tuning (FT) while also reducing both
fine-tuning computational cost and memory cost. Our Sparse Matrix Tuning (SMT)
method begins by identifying the most significant sub-matrices in the gradient
update, updating only these blocks during the fine-tuning process. In our
experiments, we demonstrate that SMT consistently surpasses other PEFT baseline
(e.g. LoRA and DoRA) in fine-tuning popular large language models such as LLaMA
across a broad spectrum of tasks, while reducing the GPU memory footprint by
67% compared to FT. We also examine how the performance of LoRA and DoRA tends
to plateau and decline as the number of trainable parameters increases, in
contrast, our SMT method does not suffer from such issue.",2024-05-24,"Haoze He, Juncheng Billy Li, Xuan Jiang, Heather Miller",http://arxiv.org/pdf/2405.15525v3,cs.CL
The Mosaic Memory of Large Language Models,"As Large Language Models (LLMs) become widely adopted, understanding how they
learn from, and memorize, training data becomes crucial. Memorization in LLMs
is widely assumed to only occur as a result of sequences being repeated in the
training data. Instead, we show that LLMs memorize by assembling information
from similar sequences, a phenomena we call mosaic memory. We show major LLMs
to exhibit mosaic memory, with fuzzy duplicates contributing to memorization as
much as 0.8 of an exact duplicate and even heavily modified sequences
contributing substantially to memorization. Despite models display reasoning
capabilities, we somewhat surprisingly show memorization to be predominantly
syntactic rather than semantic. We finally show fuzzy duplicates to be
ubiquitous in real-world data, untouched by deduplication techniques. Taken
together, our results challenge widely held beliefs and show memorization to be
a more complex, mosaic process, with real-world implications for privacy,
confidentiality, model utility and evaluation.",2024-05-24,"Igor Shilov, Matthieu Meeus, Yves-Alexandre de Montjoye",http://arxiv.org/pdf/2405.15523v2,cs.CL
Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs,"We are beginning to see progress in language model assisted scientific
discovery. Motivated by the use of LLMs as a general scientific assistant, this
paper assesses the domain knowledge of LLMs through its understanding of
different mathematical skills required to solve problems. In particular, we
look at not just what the pre-trained model already knows, but how it learned
to learn from information during in-context learning or instruction-tuning
through exploiting the complex knowledge structure within mathematics.
Motivated by the Neural Tangent Kernel (NTK), we propose \textit{NTKEval} to
assess changes in LLM's probability distribution via training on different
kinds of math data. Our systematic analysis finds evidence of domain
understanding during in-context learning. By contrast, certain
instruction-tuning leads to similar performance changes irrespective of
training on different data, suggesting a lack of domain understanding across
different skills.",2024-05-24,"Siyuan Guo, Aniket Didolkar, Nan Rosemary Ke, Anirudh Goyal, Ferenc Huszár, Bernhard Schölkopf",http://arxiv.org/pdf/2405.15485v1,cs.CL
Emergence of a High-Dimensional Abstraction Phase in Language Transformers,"A language model (LM) is a mapping from a linguistic context to an output
token. However, much remains to be known about this mapping, including how its
geometric properties relate to its function. We take a high-level geometric
approach to its analysis, observing, across five pre-trained transformer-based
LMs and three input datasets, a distinct phase characterized by high intrinsic
dimensionality. During this phase, representations (1) correspond to the first
full linguistic abstraction of the input; (2) are the first to viably transfer
to downstream tasks; (3) predict each other across different LMs. Moreover, we
find that an earlier onset of the phase strongly predicts better language
modelling performance. In short, our results suggest that a central
high-dimensionality phase underlies core linguistic processing in many common
LM architectures.",2024-05-24,"Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, Marco Baroni",http://arxiv.org/pdf/2405.15471v4,cs.CL
Linearly Controlled Language Generation with Performative Guarantees,"The increasing prevalence of Large Language Models (LMs) in critical
applications highlights the need for controlled language generation strategies
that are not only computationally efficient but that also enjoy performance
guarantees. To achieve this, we use a common model of concept semantics as
linearly represented in an LM's latent space. In particular, we take the view
that natural language generation traces a trajectory in this continuous
semantic space, realized by the language model's hidden activations. This view
permits a control-theoretic treatment of text generation in latent space, in
which we propose a lightweight, gradient-free intervention that dynamically
steers trajectories away from regions corresponding to undesired meanings.
Crucially, we show that this intervention, which we compute in closed form, is
guaranteed (in probability) to steer the output into the allowed region.
Finally, we demonstrate on a toxicity avoidance objective that the intervention
steers language away from undesired content while maintaining text quality.",2024-05-24,"Emily Cheng, Marco Baroni, Carmen Amo Alonso",http://arxiv.org/pdf/2405.15454v1,cs.CL
Benchmarking the Performance of Pre-trained LLMs across Urdu NLP Tasks,"Large Language Models (LLMs) pre-trained on multilingual data have
revolutionized natural language processing research, by transitioning from
languages and task specific model pipelines to a single model adapted on a
variety of tasks. However majority of existing multilingual NLP benchmarks for
LLMs provide evaluation data in only few languages with little linguistic
diversity. In addition these benchmarks lack quality assessment against the
respective state-of the art models. This study presents an in-depth examination
of 7 prominent LLMs: GPT-3.5-turbo, Llama 2-7B-Chat, Llama 3.1-8B, Bloomz 3B,
Bloomz 7B1, Ministral-8B and Whisper (Large, medium and small variant) across
17 tasks using 22 datasets, 13.8 hours of speech, in a zero-shot setting, and
their performance against state-of-the-art (SOTA) models, has been compared and
analyzed. Our experiments show that SOTA models currently outperform
encoder-decoder models in majority of Urdu NLP tasks under zero-shot settings.
However, comparing Llama 3.1-8B over prior version Llama 2-7B-Chat, we can
deduce that with improved language coverage, LLMs can surpass these SOTA
models. Our results emphasize that models with fewer parameters but richer
language-specific data, like Llama 3.1-8B, often outperform larger models with
lower language diversity, such as GPT-3.5, in several tasks.",2024-05-24,"Munief Hassan Tahir, Sana Shams, Layba Fiaz, Farah Adeeba, Sarmad Hussain",http://arxiv.org/pdf/2405.15453v2,cs.CL
Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top,"Multi-hop Question Answering (MQA) under knowledge editing (KE) is a key
challenge in Large Language Models (LLMs). While best-performing solutions in
this domain use a plan and solve paradigm to split a question into
sub-questions followed by response generation, we claim that this approach is
sub-optimal as it fails for hard to decompose questions, and it does not
explicitly cater to correlated knowledge updates resulting as a consequence of
knowledge edits. This has a detrimental impact on the overall consistency of
the updated knowledge. To address these issues, in this paper, we propose a
novel framework named RULE-KE, i.e., RULE based Knowledge Editing, which is a
cherry on the top for augmenting the performance of all existing MQA methods
under KE. Specifically, RULE-KE leverages rule discovery to discover a set of
logical rules. Then, it uses these discovered rules to update knowledge about
facts highly correlated with the edit. Experimental evaluation using existing
and newly curated datasets (i.e., RKE-EVAL) shows that RULE-KE helps augment
both performances of parameter-based and memory-based solutions up to 92% and
112.9%, respectively.",2024-05-24,"Keyuan Cheng, Muhammad Asif Ali, Shu Yang, Gang Lin, Yuxuan Zhai, Haoyang Fei, Ke Xu, Lu Yu, Lijie Hu, Di Wang",http://arxiv.org/pdf/2405.15452v2,cs.CL
E2Vec: Feature Embedding with Temporal Information for Analyzing Student Actions in E-Book Systems,"Digital textbook (e-book) systems record student interactions with textbooks
as a sequence of events called EventStream data. In the past, researchers
extracted meaningful features from EventStream, and utilized them as inputs for
downstream tasks such as grade prediction and modeling of student behavior.
Previous research evaluated models that mainly used statistical-based features
derived from EventStream logs, such as the number of operation types or access
frequencies. While these features are useful for providing certain insights,
they lack temporal information that captures fine-grained differences in
learning behaviors among different students. This study proposes E2Vec, a novel
feature representation method based on word embeddings. The proposed method
regards operation logs and their time intervals for each student as a string
sequence of characters and generates a student vector of learning activity
features that incorporates time information. We applied fastText to generate an
embedding vector for each of 305 students in a dataset from two years of
computer science courses. Then, we investigated the effectiveness of E2Vec in
an at-risk detection task, demonstrating potential for generalizability and
performance.",2024-05-24,"Yuma Miyazaki, Valdemar Švábenský, Yuta Taniguchi, Fumiya Okubo, Tsubasa Minematsu, Atsushi Shimada",http://arxiv.org/pdf/2407.13053v1,cs.CL
Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph,"The proposed research aims to develop an innovative semantic query processing
system that enables users to obtain comprehensive information about research
works produced by Computer Science (CS) researchers at the Australian National
University (ANU). The system integrates Large Language Models (LLMs) with the
ANU Scholarly Knowledge Graph (ASKG), a structured repository of all
research-related artifacts produced at ANU in the CS field. Each artifact and
its parts are represented as textual nodes stored in a Knowledge Graph (KG).
  To address the limitations of traditional scholarly KG construction and
utilization methods, which often fail to capture fine-grained details, we
propose a novel framework that integrates the Deep Document Model (DDM) for
comprehensive document representation and the KG-enhanced Query Processing
(KGQP) for optimized complex query handling. DDM enables a fine-grained
representation of the hierarchical structure and semantic relationships within
academic papers, while KGQP leverages the KG structure to improve query
accuracy and efficiency with LLMs.
  By combining the ASKG with LLMs, our approach enhances knowledge utilization
and natural language understanding capabilities. The proposed system employs an
automatic LLM-SPARQL fusion to retrieve relevant facts and textual nodes from
the ASKG. Initial experiments demonstrate that our framework is superior to
baseline methods in terms of accuracy retrieval and query efficiency.
  We showcase the practical application of our framework in academic research
scenarios, highlighting its potential to revolutionize scholarly knowledge
management and discovery. This work empowers researchers to acquire and utilize
knowledge from documents more effectively and provides a foundation for
developing precise and reliable interactions with LLMs.",2024-05-24,"Runsong Jia, Bowen Zhang, Sergio J. Rodríguez Méndez, Pouya G. Omran",http://arxiv.org/pdf/2405.15374v1,cs.CL
Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection,"Time series anomaly detection (TSAD) plays a crucial role in various
industries by identifying atypical patterns that deviate from standard trends,
thereby maintaining system integrity and enabling prompt response measures.
Traditional TSAD models, which often rely on deep learning, require extensive
training data and operate as black boxes, lacking interpretability for detected
anomalies. To address these challenges, we propose LLMAD, a novel TSAD method
that employs Large Language Models (LLMs) to deliver accurate and interpretable
TSAD results. LLMAD innovatively applies LLMs for in-context anomaly detection
by retrieving both positive and negative similar time series segments,
significantly enhancing LLMs' effectiveness. Furthermore, LLMAD employs the
Anomaly Detection Chain-of-Thought (AnoCoT) approach to mimic expert logic for
its decision-making process. This method further enhances its performance and
enables LLMAD to provide explanations for their detections through versatile
perspectives, which are particularly important for user decision-making.
Experiments on three datasets indicate that our LLMAD achieves detection
performance comparable to state-of-the-art deep learning methods while offering
remarkable interpretability for detections. To the best of our knowledge, this
is the first work that directly employs LLMs for TSAD.",2024-05-24,"Jun Liu, Chaoyun Zhang, Jiaxu Qian, Minghua Ma, Si Qin, Chetan Bansal, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang",http://arxiv.org/pdf/2405.15370v1,cs.CL
Pipeline Parallelism with Controllable Memory,"Pipeline parallelism has been widely explored, but most existing schedules
lack a systematic methodology. In this paper, we propose a framework to
decompose pipeline schedules as repeating a building block, and show that the
lifespan of the building block decides the peak activation memory of the
pipeline schedule. Guided by the observations, we find that almost all existing
pipeline schedules, to the best of our knowledge, are memory inefficient. To
address this, we introduce a family of memory efficient building blocks with
controllable activation memory, which can reduce the peak activation memory to
1/2 of 1F1B without sacrificing efficiency, and even to 1/3 with comparable
throughput. We can also achieve almost zero pipeline bubbles while maintaining
the same activation memory as 1F1B. Our evaluations demonstrate that in pure
pipeline parallelism settings, our methods outperform 1F1B by from 7% to 55% in
terms of throughput. When employing a grid search over hybrid parallelism
hyperparameters in practical scenarios, our methods demonstrate a 16%
throughput improvement over the 1F1B baseline for large language models. The
implementation is open-sourced at
https://github.com/sail-sg/zero-bubble-pipeline-parallelism.",2024-05-24,"Penghui Qi, Xinyi Wan, Nyamdavaa Amar, Min Lin",http://arxiv.org/pdf/2405.15362v4,cs.CL
Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models,"Recent knowledge editing methods have primarily focused on modifying
structured knowledge in large language models. However, this task setting
overlooks the fact that a significant portion of real-world knowledge is stored
in an unstructured format, characterized by long-form content, noise, and a
complex yet comprehensive nature. Techniques like ""local layer key-value
storage"" and ""term-driven optimization"", as used in previous methods like
MEMIT, are not effective for handling unstructured knowledge. To address these
challenges, we propose a novel Unstructured Knowledge Editing method, namely
UnKE, which extends previous assumptions in the layer dimension and token
dimension. Firstly, in the layer dimension, we propose non-local block
key-value storage to replace local layer key-value storage, increasing the
representation ability of key-value pairs and incorporating attention layer
knowledge. Secondly, in the token dimension, we replace ""term-driven
optimization"" with ""cause-driven optimization"", which edits the last token
directly while preserving context, avoiding the need to locate terms and
preventing the loss of context information. Results on newly proposed
unstructured knowledge editing dataset (UnKEBench) and traditional structured
datasets demonstrate that UnKE achieves remarkable performance, surpassing
strong baselines. In addition, UnKE has robust batch editing and sequential
editing capabilities.",2024-05-24,"Jingcheng Deng, Zihao Wei, Liang Pang, Hanxing Ding, Huawei Shen, Xueqi Cheng",http://arxiv.org/pdf/2405.15349v3,cs.CL
BiSup: Bidirectional Quantization Error Suppression for Large Language Models,"As the size and context length of Large Language Models (LLMs) grow,
weight-activation quantization has emerged as a crucial technique for efficient
deployment of LLMs. Compared to weight-only quantization, weight-activation
quantization presents greater challenges due to the presence of outliers in
activations. Existing methods have made significant progress by exploring
mixed-precision quantization and outlier suppression. However, these methods
primarily focus on optimizing the results of single matrix multiplication,
neglecting the bidirectional propagation of quantization errors in LLMs.
Specifically, errors accumulate vertically within the same token through
layers, and diffuse horizontally across different tokens due to self-attention
mechanisms. To address this issue, we introduce BiSup, a Bidirectional
quantization error Suppression method. By constructing appropriate optimizable
parameter spaces, BiSup utilizes a small amount of data for quantization-aware
parameter-efficient fine-tuning to suppress the error vertical accumulation.
Besides, BiSup employs prompt mixed-precision quantization strategy, which
preserves high precision for the key-value cache of system prompts, to mitigate
the error horizontal diffusion. Extensive experiments on Llama and Qwen
families demonstrate that BiSup can improve performance over two
state-of-the-art methods (the average WikiText2 perplexity decreases from 13.26
to 9.41 for Atom and from 14.33 to 7.85 for QuaRot under the W3A3-g128
configuration), further facilitating the practical applications of low-bit
weight-activation quantization.",2024-05-24,"Minghui Zou, Ronghui Guo, Sai Zhang, Xiaowang Zhang, Zhiyong Feng",http://arxiv.org/pdf/2405.15346v1,cs.CL
Detection and Positive Reconstruction of Cognitive Distortion sentences: Mandarin Dataset and Evaluation,"This research introduces a Positive Reconstruction Framework based on
positive psychology theory. Overcoming negative thoughts can be challenging,
our objective is to address and reframe them through a positive
reinterpretation. To tackle this challenge, a two-fold approach is necessary:
identifying cognitive distortions and suggesting a positively reframed
alternative while preserving the original thought's meaning. Recent studies
have investigated the application of Natural Language Processing (NLP) models
in English for each stage of this process. In this study, we emphasize the
theoretical foundation for the Positive Reconstruction Framework, grounded in
broaden-and-build theory. We provide a shared corpus containing 4001 instances
for detecting cognitive distortions and 1900 instances for positive
reconstruction in Mandarin. Leveraging recent NLP techniques, including
transfer learning, fine-tuning pretrained networks, and prompt engineering, we
demonstrate the effectiveness of automated tools for both tasks. In summary,
our study contributes to multilingual positive reconstruction, highlighting the
effectiveness of NLP in cognitive distortion detection and positive
reconstruction.",2024-05-24,"Shuya Lin, Yuxiong Wang, Jonathan Dong, Shiguang Ni",http://arxiv.org/pdf/2405.15334v1,cs.CL
SCALM: Towards Semantic Caching for Automated Chat Services with Large Language Models,"Large Language Models (LLMs) have become increasingly popular, transforming a
wide range of applications across various domains. However, the real-world
effectiveness of their query cache systems has not been thoroughly
investigated. In this work, we for the first time conducted an analysis on
real-world human-to-LLM interaction data, identifying key challenges in
existing caching solutions for LLM-based chat services. Our findings reveal
that current caching methods fail to leverage semantic connections, leading to
inefficient cache performance and extra token costs. To address these issues,
we propose SCALM, a new cache architecture that emphasizes semantic analysis
and identifies significant cache entries and patterns. We also detail the
implementations of the corresponding cache storage and eviction strategies. Our
evaluations show that SCALM increases cache hit ratios and reduces operational
costs for LLMChat services. Compared with other state-of-the-art solutions in
GPTCache, SCALM shows, on average, a relative increase of 63% in cache hit
ratio and a relative improvement of 77% in tokens savings.",2024-05-24,"Jiaxing Li, Chi Xu, Feng Wang, Isaac M von Riedemann, Cong Zhang, Jiangchuan Liu",http://arxiv.org/pdf/2406.00025v1,cs.CL
DnA-Eval: Enhancing Large Language Model Evaluation through Decomposition and Aggregation,"The acceleration of Large Language Models (LLMs) research has opened up new
possibilities for evaluating generated texts. They serve as scalable and
economical evaluators, but the question of how reliable these evaluators are
has emerged as a crucial research question. Prior research efforts in the
meta-evaluation of LLMs as judges limit the prompting of an LLM to a single use
to obtain a final evaluation decision. They then compute the agreement between
LLMs' outputs and human labels. This lacks interpretability in understanding
the evaluation capability of LLMs. In light of this challenge, we propose
Decompose and Aggregate, which breaks down the evaluation process into
different stages based on pedagogical practices. Our experiments illustrate
that it not only provides a more interpretable window for how well LLMs
evaluate, but also leads to improvements up to 39.6% for different LLMs on a
variety of meta-evaluation benchmarks.",2024-05-24,"Minzhi Li, Zhengyuan Liu, Shumin Deng, Shafiq Joty, Nancy F. Chen, Min-Yen Kan",http://arxiv.org/pdf/2405.15329v3,cs.CL
Organic Data-Driven Approach for Turkish Grammatical Error Correction and LLMs,"Grammatical Error Correction has seen significant progress with the recent
advancements in deep learning. As those methods require huge amounts of data,
synthetic datasets are being built to fill this gap. Unfortunately, synthetic
datasets are not organic enough in some cases and even require clean data to
start with. Furthermore, most of the work that has been done is focused mostly
on English. In this work, we introduce a new organic data-driven approach,
clean insertions, to build parallel Turkish Grammatical Error Correction
datasets from any organic data, and to clean the data used for training Large
Language Models. We achieve state-of-the-art results on two Turkish Grammatical
Error Correction test sets out of the three publicly available ones. We also
show the effectiveness of our method on the training losses of training
language models.",2024-05-24,"Asım Ersoy, Olcay Taner Yıldız",http://arxiv.org/pdf/2405.15320v1,cs.CL
Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training,"LLMs are computationally expensive to pre-train due to their large scale.
Model growth emerges as a promising approach by leveraging smaller models to
accelerate the training of larger ones. However, the viability of these model
growth methods in efficient LLM pre-training remains underexplored. This work
identifies three critical $\underline{\textit{O}}$bstacles: ($\textit{O}$1)
lack of comprehensive evaluation, ($\textit{O}$2) untested viability for
scaling, and ($\textit{O}$3) lack of empirical guidelines. To tackle
$\textit{O}$1, we summarize existing approaches into four atomic growth
operators and systematically evaluate them in a standardized LLM pre-training
setting. Our findings reveal that a depthwise stacking operator, called
$G_{\text{stack}}$, exhibits remarkable acceleration in training, leading to
decreased loss and improved overall performance on eight standard NLP
benchmarks compared to strong baselines. Motivated by these promising results,
we conduct extensive experiments to delve deeper into $G_{\text{stack}}$ to
address $\textit{O}$2 and $\textit{O}$3. For $\textit{O}$2 (untested
scalability), our study shows that $G_{\text{stack}}$ is scalable and
consistently performs well, with experiments up to 7B LLMs after growth and
pre-training LLMs with 750B tokens. For example, compared to a conventionally
trained 7B model using 300B tokens, our $G_{\text{stack}}$ model converges to
the same loss with 194B tokens, resulting in a 54.6\% speedup. We further
address $\textit{O}$3 (lack of empirical guidelines) by formalizing guidelines
to determine growth timing and growth factor for $G_{\text{stack}}$, making it
practical in general LLM pre-training. We also provide in-depth discussions and
comprehensive ablation studies of $G_{\text{stack}}$. Our code and pre-trained
model are available at https://llm-stacking.github.io.",2024-05-24,"Wenyu Du, Tongxu Luo, Zihan Qiu, Zeyu Huang, Yikang Shen, Reynold Cheng, Yike Guo, Jie Fu",http://arxiv.org/pdf/2405.15319v2,cs.CL
Are Long-LLMs A Necessity For Long-Context Tasks?,"The learning and deployment of long-LLMs remains a challenging problem
despite recent progresses. In this work, we argue that the long-LLMs are not a
necessity to solve long-context tasks, as common long-context tasks are
short-context solvable, i.e. they can be solved by purely working with oracle
short-contexts within the long-context tasks' inputs. On top of this argument,
we propose a framework called LC-Boost (Long-Context Bootstrapper), which
enables a short-LLM to address the long-context tasks in a bootstrapping
manner. In our framework, the short-LLM prompts itself to reason for two
critical decisions: 1) how to access to the appropriate part of context within
the input, 2) how to make effective use of the accessed context. By adaptively
accessing and utilizing the context based on the presented tasks, LC-Boost can
serve as a general framework to handle diversified long-context processing
problems. We comprehensively evaluate different types of tasks from popular
long-context benchmarks, where LC-Boost is able to achieve a substantially
improved performance with a much smaller consumption of resource.",2024-05-24,"Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Yujia Zhou, Xu Chen, Zhicheng Dou",http://arxiv.org/pdf/2405.15318v1,cs.CL
"Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation","Large Language Models (LLMs) driven by In-Context Learning (ICL) have
significantly improved the performance of text-to-SQL. Previous methods
generally employ a two-stage reasoning framework, namely 1) schema linking and
2) logical synthesis, making the framework not only effective but also
interpretable. Despite these advancements, the inherent bad nature of the
generalization of LLMs often results in hallucinations, which limits the full
potential of LLMs. In this work, we first identify and categorize the common
types of hallucinations at each stage in text-to-SQL. We then introduce a novel
strategy, Task Alignment (TA), designed to mitigate hallucinations at each
stage. TA encourages LLMs to take advantage of experiences from similar tasks
rather than starting the tasks from scratch. This can help LLMs reduce the
burden of generalization, thereby mitigating hallucinations effectively. We
further propose TA-SQL, a text-to-SQL framework based on this strategy. The
experimental results and comprehensive analysis demonstrate the effectiveness
and robustness of our framework. Specifically, it enhances the performance of
the GPT-4 baseline by 21.23% relatively on BIRD dev and it yields significant
improvements across six models and four mainstream, complex text-to-SQL
benchmarks.",2024-05-24,"Ge Qu, Jinyang Li, Bowen Li, Bowen Qin, Nan Huo, Chenhao Ma, Reynold Cheng",http://arxiv.org/pdf/2405.15307v1,cs.CL
DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ,"Creating high-quality scientific figures can be time-consuming and
challenging, even though sketching ideas on paper is relatively easy.
Furthermore, recreating existing figures that are not stored in formats
preserving semantic information is equally complex. To tackle this problem, we
introduce DeTikZify, a novel multimodal language model that automatically
synthesizes scientific figures as semantics-preserving TikZ graphics programs
based on sketches and existing figures. To achieve this, we create three new
datasets: DaTikZv2, the largest TikZ dataset to date, containing over 360k
human-created TikZ graphics; SketchFig, a dataset that pairs hand-drawn
sketches with their corresponding scientific figures; and MetaFig, a collection
of diverse scientific figures and associated metadata. We train DeTikZify on
MetaFig and DaTikZv2, along with synthetically generated sketches learned from
SketchFig. We also introduce an MCTS-based inference algorithm that enables
DeTikZify to iteratively refine its outputs without the need for additional
training. Through both automatic and human evaluation, we demonstrate that
DeTikZify outperforms commercial Claude 3 and GPT-4V in synthesizing TikZ
programs, with the MCTS algorithm effectively boosting its performance. We make
our code, models, and datasets publicly available.",2024-05-24,"Jonas Belouadi, Simone Paolo Ponzetto, Steffen Eger",http://arxiv.org/pdf/2405.15306v3,cs.CL
The Buffer Mechanism for Multi-Step Information Reasoning in Language Models,"Large language models have consistently struggled with complex reasoning
tasks, such as mathematical problem-solving. Investigating the internal
reasoning mechanisms of these models can help us design better model
architectures and training strategies, ultimately enhancing their reasoning
capability. In this study, we constructed a symbolic dataset to investigate the
mechanisms by which Transformer models employ vertical thinking strategy based
on their inherent structure and horizontal thinking strategy based on Chain of
Thought to achieve multi-step reasoning. We introduced the concept of buffer
mechanism: the model stores various information in distinct buffers and
selectively extracts them through the query-key matrix. We proposed a random
matrix-based algorithm to enhance the model's reasoning ability, resulting in a
75% reduction in the training time required for the GPT-2 model to achieve
generalization capability on the PrOntoQA dataset. These findings provide new
insights into understanding the mechanisms of large language models.",2024-05-24,"Zhiwei Wang, Yunji Wang, Zhongwang Zhang, Zhangchen Zhou, Hui Jin, Tianyang Hu, Jiacheng Sun, Zhenguo Li, Yaoyu Zhang, Zhi-Qin John Xu",http://arxiv.org/pdf/2405.15302v2,cs.CL
Large Language Model Sentinel: LLM Agent for Adversarial Purification,"Over the past two years, the use of large language models (LLMs) has advanced
rapidly. While these LLMs offer considerable convenience, they also raise
security concerns, as LLMs are vulnerable to adversarial attacks by some
well-designed textual perturbations. In this paper, we introduce a novel
defense technique named Large LAnguage MOdel Sentinel (LLAMOS), which is
designed to enhance the adversarial robustness of LLMs by purifying the
adversarial textual examples before feeding them into the target LLM. Our
method comprises two main components: a) Agent instruction, which can simulate
a new agent for adversarial defense, altering minimal characters to maintain
the original meaning of the sentence while defending against attacks; b)
Defense guidance, which provides strategies for modifying clean or adversarial
examples to ensure effective defense and accurate outputs from the target LLMs.
Remarkably, the defense agent demonstrates robust defensive capabilities even
without learning from adversarial examples. Additionally, we conduct an
intriguing adversarial experiment where we develop two agents, one for defense
and one for attack, and engage them in mutual confrontation. During the
adversarial interactions, neither agent completely beat the other. Extensive
experiments on both open-source and closed-source LLMs demonstrate that our
method effectively defends against adversarial attacks, thereby enhancing
adversarial robustness.",2024-05-24,"Guang Lin, Toshihisa Tanaka, Qibin Zhao",http://arxiv.org/pdf/2405.20770v4,cs.CL
Embedding-Aligned Language Models,"We propose a novel approach for training large language models (LLMs) to
adhere to objectives defined within a latent embedding space. Our method
leverages reinforcement learning (RL), treating a pre-trained LLM as an
environment. Our embedding-aligned guided language (EAGLE) agent is trained to
iteratively steer the LLM's generation towards optimal regions of the latent
embedding space, w.r.t. some predefined criterion. We demonstrate the
effectiveness of the EAGLE agent using the MovieLens 25M and Amazon Review
datasets to surface content gaps that satisfy latent user demand. We also
demonstrate the benefit of using an optimal design of a state-dependent action
set to improve EAGLE's efficiency. Our work paves the way for controlled and
grounded text generation using LLMs, ensuring consistency with domain-specific
knowledge and data representations.",2024-05-24,"Guy Tennenholtz, Yinlam Chow, Chih-Wei Hsu, Lior Shani, Ethan Liang, Craig Boutilier",http://arxiv.org/pdf/2406.00024v2,cs.CL
DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception,"The development of large language models (LLMs) has significantly advanced
the emergence of large multimodal models (LMMs). While LMMs have achieved
tremendous success by promoting the synergy between multimodal comprehension
and creation, they often face challenges when confronted with
out-of-distribution data, such as which can hardly distinguish orientation,
quantity, color, structure, etc. This is primarily due to their reliance on
image encoders trained to encode images into task-relevant features, which may
lead them to disregard irrelevant details. Delving into the modeling
capabilities of diffusion models for images naturally prompts the question: Can
diffusion models serve as the eyes of large language models for image
perception? In this paper, we propose DEEM, a simple but effective approach
that utilizes the generative feedback of diffusion models to align the semantic
distributions of the image encoder. This addresses the drawbacks of previous
methods that solely relied on image encoders like CLIP-ViT, thereby enhancing
the model's resilience against out-of-distribution samples and reducing visual
hallucinations. Importantly, this is achieved without requiring additional
training modules and with fewer training parameters. We extensively evaluated
DEEM on both our newly constructed RobustVQA benchmark and other well-known
benchmarks, POPE and MMVP, for visual hallucination and perception. In
particular, DEEM improves LMM's visual perception performance to a large extent
(e.g., 4% higher on RobustVQA, 6.5% higher on MMVP and 12.8 % higher on POPE ).
Compared to the state-of-the-art interleaved content generation models, DEEM
exhibits enhanced robustness and a superior capacity to alleviate model
hallucinations while utilizing fewer trainable parameters, less pre-training
data (10%), and a smaller base model size.",2024-05-24,"Run Luo, Yunshui Li, Longze Chen, Wanwei He, Ting-En Lin, Ziqiang Liu, Lei Zhang, Zikai Song, Xiaobo Xia, Tongliang Liu, Min Yang, Binyuan Hui",http://arxiv.org/pdf/2405.15232v4,cs.CL
Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition,"Language models (LMs) have long been used to improve results of automatic
speech recognition (ASR) systems, but they are unaware of the errors that ASR
systems make. Error correction models are designed to fix ASR errors, however,
they showed little improvement over traditional LMs mainly due to the lack of
supervised training data. In this paper, we present Denoising LM (DLM), which
is a $\textit{scaled}$ error correction model trained with vast amounts of
synthetic data, significantly exceeding prior attempts meanwhile achieving new
state-of-the-art ASR performance. We use text-to-speech (TTS) systems to
synthesize audio, which is fed into an ASR system to produce noisy hypotheses,
which are then paired with the original texts to train the DLM. DLM has several
$\textit{key ingredients}$: (i) up-scaled model and data; (ii) usage of
multi-speaker TTS systems; (iii) combination of multiple noise augmentation
strategies; and (iv) new decoding techniques. With a Transformer-CTC ASR, DLM
achieves 1.5% word error rate (WER) on $\textit{test-clean}$ and 3.3% WER on
$\textit{test-other}$ on Librispeech, which to our knowledge are the best
reported numbers in the setting where no external audio data are used and even
match self-supervised methods which use external audio data. Furthermore, a
single DLM is applicable to different ASRs, and greatly surpassing the
performance of conventional LM based beam-search rescoring. These results
indicate that properly investigated error correction models have the potential
to replace conventional LMs, holding the key to a new level of accuracy in ASR
systems.",2024-05-24,"Zijin Gu, Tatiana Likhomanenko, He Bai, Erik McDermott, Ronan Collobert, Navdeep Jaitly",http://arxiv.org/pdf/2405.15216v1,cs.CL
How Culturally Aware are Vision-Language Models?,"An image is often considered worth a thousand words, and certain images can
tell rich and insightful stories. Can these stories be told via image
captioning? Images from folklore genres, such as mythology, folk dance,
cultural signs, and symbols, are vital to every culture. Our research compares
the performance of four popular vision-language models (GPT-4V, Gemini Pro
Vision, LLaVA, and OpenFlamingo) in identifying culturally specific information
in such images and creating accurate and culturally sensitive image captions.
We also propose a new evaluation metric, the Cultural Awareness Score (CAS),
which measures the degree of cultural awareness in image captions. We provide a
dataset MOSAIC-1.5k labeled with ground truth for images containing cultural
background and context and a labeled dataset with assigned Cultural Awareness
Scores that can be used with unseen data. Creating culturally appropriate image
captions is valuable for scientific research and can be beneficial for many
practical applications. We envision our work will promote a deeper integration
of cultural sensitivity in AI applications worldwide. By making the dataset and
Cultural Awareness Score available to the public, we aim to facilitate further
research in this area, encouraging the development of more culturally aware AI
systems that respect and celebrate global diversity.",2024-05-24,"Olena Burda-Lassen, Aman Chadha, Shashank Goswami, Vinija Jain",http://arxiv.org/pdf/2405.17475v2,cs.CL
Decoding at the Speed of Thought: Harnessing Parallel Decoding of Lexical Units for LLMs,"Large language models have demonstrated exceptional capability in natural
language understanding and generation. However, their generation speed is
limited by the inherently sequential nature of their decoding process, posing
challenges for real-time applications. This paper introduces Lexical Unit
Decoding (LUD), a novel decoding methodology implemented in a data-driven
manner, accelerating the decoding process without sacrificing output quality.
The core of our approach is the observation that a pre-trained language model
can confidently predict multiple contiguous tokens, forming the basis for a
\textit{lexical unit}, in which these contiguous tokens could be decoded in
parallel. Extensive experiments validate that our method substantially reduces
decoding time while maintaining generation quality, i.e., 33\% speed up on
natural language generation with no quality loss, and 30\% speed up on code
generation with a negligible quality loss of 3\%. Distinctively, LUD requires
no auxiliary models and does not require changes to existing architectures. It
can also be integrated with other decoding acceleration methods, thus achieving
an even more pronounced inference efficiency boost. We posit that the
foundational principles of LUD could define a new decoding paradigm for future
language models, enhancing their applicability for a broader spectrum of
applications. All codes are be publicly available at
https://github.com/tjunlp-lab/Lexical-Unit-Decoding-LUD-. Keywords: Parallel
Decoding, Lexical Unit Decoding, Large Language Model",2024-05-24,"Chenxi Sun, Hongzhi Zhang, Zijia Lin, Jingyuan Zhang, Fuzheng Zhang, Zhongyuan Wang, Bin Chen, Chengru Song, Di Zhang, Kun Gai, Deyi Xiong",http://arxiv.org/pdf/2405.15208v1,cs.CL
Cross-Task Defense: Instruction-Tuning LLMs for Content Safety,"Recent studies reveal that Large Language Models (LLMs) face challenges in
balancing safety with utility, particularly when processing long texts for NLP
tasks like summarization and translation. Despite defenses against malicious
short questions, the ability of LLMs to safely handle dangerous long content,
such as manuals teaching illicit activities, remains unclear. Our work aims to
develop robust defenses for LLMs in processing malicious documents alongside
benign NLP task queries. We introduce a defense dataset comprised of
safety-related examples and propose single-task and mixed-task losses for
instruction tuning. Our empirical results demonstrate that LLMs can
significantly enhance their capacity to safely manage dangerous content with
appropriate instruction tuning. Additionally, strengthening the defenses of
tasks most susceptible to misuse is effective in protecting LLMs against
processing harmful information. We also observe that trade-offs between utility
and safety exist in defense strategies, where Llama2, utilizing our proposed
approach, displays a significantly better balance compared to Llama1.",2024-05-24,"Yu Fu, Wen Xiao, Jia Chen, Jiachen Li, Evangelos Papalexakis, Aichi Chien, Yue Dong",http://arxiv.org/pdf/2405.15202v1,cs.CL
RAEE: A Robust Retrieval-Augmented Early Exiting Framework for Efficient Inference,"Deploying large language model inference remains challenging due to their
high computational overhead. Early exiting optimizes model inference by
adaptively reducing the number of inference layers. Existing methods typically
train internal classifiers to determine whether to exit at intermediate layers.
However, such classifier-based early exiting frameworks require significant
effort to train the classifiers while can only achieve comparable performance
at best. To address these limitations, this paper proposes RAEE, a robust
Retrieval-Augmented Early Exiting framework for efficient inference. First,
this paper demonstrates that the early exiting problem can be modeled as a
distribution prediction problem, where the distribution is approximated using
similar data's exiting information. Then, this paper details the process of
collecting exiting information to build the retrieval database. Finally, based
on the pre-built retrieval database, RAEE leverages the retrieved similar
data's exiting information to guide the backbone model to exit at the layer,
which is predicted by the approximated distribution. Experimental results
demonstrate that the proposed RAEE can significantly accelerate inference. More
importantly, RAEE can also achieve a robust zero-shot performance on 8
downstream tasks.",2024-05-24,"Lianming Huang, Shangyu Wu, Yufei Cui, Ying Xiong, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue",http://arxiv.org/pdf/2405.15198v2,cs.CL
EffiLearner: Enhancing Efficiency of Generated Code via Self-Optimization,"Large language models (LLMs) have shown remarkable progress in code
generation, but their generated code often suffers from inefficiency, resulting
in longer execution times and higher memory consumption. To address this issue,
we propose \textbf{EffiLearner}, a self-optimization framework that utilizes
execution overhead profiles to improve the efficiency of LLM-generated code.
EffiLearner first generates code using an LLM, then executes it locally to
capture execution time and memory usage profiles. These profiles are fed back
to the LLM, which then revises the code to reduce overhead. To evaluate the
effectiveness of EffiLearner, we conduct extensive experiments on the
EffiBench, HumanEval, and MBPP with 16 open-source and 6 closed-source models.
Our evaluation results demonstrate that through iterative self-optimization,
EffiLearner significantly enhances the efficiency of LLM-generated code. For
example, the execution time (ET) of StarCoder2-15B for the EffiBench decreases
from 0.93 (s) to 0.12 (s) which reduces 87.1% the execution time requirement
compared with the initial code. The total memory usage (TMU) of StarCoder2-15B
also decreases from 22.02 (Mb*s) to 2.03 (Mb*s), which decreases 90.8% of total
memory consumption during the execution process. The source code of EffiLearner
was released in https://github.com/huangd1999/EffiLearner",2024-05-24,"Dong Huang, Jianbo Dai, Han Weng, Puzhen Wu, Yuhao Qing, Heming Cui, Zhijiang Guo, Jie M. Zhang",http://arxiv.org/pdf/2405.15189v4,cs.CL
An Evaluation of Estimative Uncertainty in Large Language Models,"Words of estimative probability (WEPs), such as ''maybe'' or ''probably not''
are ubiquitous in natural language for communicating estimative uncertainty,
compared with direct statements involving numerical probability. Human
estimative uncertainty, and its calibration with numerical estimates, has long
been an area of study -- including by intelligence agencies like the CIA. This
study compares estimative uncertainty in commonly used large language models
(LLMs) like GPT-4 and ERNIE-4 to that of humans, and to each other. Here we
show that LLMs like GPT-3.5 and GPT-4 align with human estimates for some, but
not all, WEPs presented in English. Divergence is also observed when the LLM is
presented with gendered roles and Chinese contexts. Further study shows that an
advanced LLM like GPT-4 can consistently map between statistical and estimative
uncertainty, but a significant performance gap remains. The results contribute
to a growing body of research on human-LLM alignment.",2024-05-24,"Zhisheng Tang, Ke Shen, Mayank Kejriwal",http://arxiv.org/pdf/2405.15185v1,cs.CL
VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks,"As the adoption of large language models increases and the need for per-user
or per-task model customization grows, the parameter-efficient fine-tuning
(PEFT) methods, such as low-rank adaptation (LoRA) and its variants, incur
substantial storage and transmission costs. To further reduce stored
parameters, we introduce a ""divide-and-share"" paradigm that breaks the barriers
of low-rank decomposition across matrix dimensions, modules, and layers by
sharing parameters globally via a vector bank. As an instantiation of the
paradigm to LoRA, our proposed VB-LoRA composites all the low-rank matrices of
LoRA from a shared vector bank with a differentiable top-k admixture module.
VB-LoRA achieves extreme parameter efficiency while maintaining comparable or
better performance compared to state-of-the-art PEFT methods. Extensive
experiments demonstrate the effectiveness of VB-LoRA on natural language
understanding, natural language generation, instruction tuning, and
mathematical reasoning tasks. When fine-tuning the Llama2-13B model, VB-LoRA
only uses 0.4% of LoRA's stored parameters, yet achieves superior results. Our
source code is available at https://github.com/leo-yangli/VB-LoRA. This method
has been merged into the Hugging Face PEFT package.",2024-05-24,"Yang Li, Shaobo Han, Shihao Ji",http://arxiv.org/pdf/2405.15179v3,cs.CL
Athena: Efficient Block-Wise Post-Training Quantization for Large Language Models Using Second-Order Matrix Derivative Information,"Large Language Models (LLMs) have significantly advanced natural language
processing tasks such as machine translation, text generation, and sentiment
analysis. However, their large size, often consisting of billions of
parameters, poses challenges for storage, computation, and deployment,
particularly in resource-constrained environments like mobile devices and edge
computing platforms. Effective compression and quantization techniques are
crucial for addressing these issues, reducing memory footprint and
computational requirements without significantly compromising performance.
Traditional methods that uniformly map parameters to compressed spaces fail to
account for the uneven distribution of parameters, leading to substantial
accuracy loss. In this work, we propose Athena, a novel algorithm for efficient
block-wise post-training quantization of LLMs. Athena leverages Second-Order
Matrix Derivative Information to guide the quantization process using the
curvature information of the loss landscape. By grouping parameters by columns
or rows and iteratively optimizing the quantization process, Athena updates the
model parameters and Hessian matrix to achieve significant compression while
maintaining high accuracy. This makes Athena a practical solution for deploying
LLMs in various settings.",2024-05-24,"Yanshu Wang, Wenyang He, Tong Yang",http://arxiv.org/pdf/2405.17470v1,cs.CL
Expert-Token Resonance MoE: Bidirectional Routing with Efficiency Affinity-Driven Active Selection,"Mixture-of-Experts (MoE) architectures have emerged as a paradigm-shifting
approach for large language models (LLMs), offering unprecedented computational
efficiency. However, these architectures grapple with challenges of token
distribution imbalance and expert homogenization, impeding optimal semantic
generalization. We propose a novel expert routing framework that incorporates:
(1) An efficient routing mechanism with lightweight computation. (2) An
adaptive bidirectional selection mechanism leveraging resonance between experts
and tokens. (3) A module that determines the lower bounds of expert capacity
based on dynamic token distribution analysis, specifically designed to address
drop-and-pad strategies. It is also integrated with orthogonal feature
extraction module and an optimized loss function for expert localization. This
framework effectively reduces expert homogeneity while enhancing the
performance of the expert selection module. Additionally, we introduce a local
expert strategy that simultaneously improves load balancing and reduces network
communication overhead. It achieves a 40\% reduction in token processed by each
expert without compromising model convergence or efficacy. When coupled with
communication optimizations, the training efficiency improvements of 5.4\% to
46.6\% can be observed. After supervised fine-tuning, it exhibits performance
gains of 9.7\% to 14.1\% across GDAD, GPQA, and TeleQnA benchmarks.",2024-05-24,"Jing Li, Zhijie Sun, Dachao Lin, Xuan He, Binfan Zheng, Yi Lin, Rongqian Zhao, Xin Chen",http://arxiv.org/pdf/2406.00023v3,cs.CL
A Solution-based LLM API-using Methodology for Academic Information Seeking,"Applying large language models (LLMs) for academic API usage shows promise in
reducing researchers' academic information seeking efforts. However, current
LLM API-using methods struggle with complex API coupling commonly encountered
in academic queries. To address this, we introduce SoAy, a solution-based LLM
API-using methodology for academic information seeking. It uses code with a
solution as the reasoning method, where a solution is a pre-constructed API
calling sequence. The addition of the solution reduces the difficulty for the
model to understand the complex relationships between APIs. Code improves the
efficiency of reasoning.
  To evaluate SoAy, we introduce SoAyBench, an evaluation benchmark accompanied
by SoAyEval, built upon a cloned environment of APIs from AMiner. Experimental
results demonstrate a 34.58-75.99\% performance improvement compared to
state-of-the-art LLM API-based baselines. All datasets, codes, tuned models,
and deployed online services are publicly accessible at
https://github.com/RUCKBReasoning/SoAy.",2024-05-24,"Yuanchun Wang, Jifan Yu, Zijun Yao, Jing Zhang, Yuyang Xie, Shangqing Tu, Yiyang Fu, Youhe Feng, Jinkai Zhang, Jingyao Zhang, Bowen Huang, Yuanyao Li, Huihui Yuan, Lei Hou, Juanzi Li, Jie Tang",http://arxiv.org/pdf/2405.15165v1,cs.CL
Machine Unlearning in Large Language Models,"Machine unlearning, a novel area within artificial intelligence, focuses on
addressing the challenge of selectively forgetting or reducing undesirable
knowledge or behaviors in machine learning models, particularly in the context
of large language models (LLMs). This paper introduces a methodology to align
LLMs, such as Open Pre-trained Transformer Language Models, with ethical,
privacy, and safety standards by leveraging the gradient ascent algorithm for
knowledge unlearning. Our approach aims to selectively erase or modify learned
information in LLMs, targeting harmful responses and copyrighted content. This
paper presents a dual-pronged approach to enhance the ethical and safe behavior
of large language models (LLMs) by addressing the issues of harmful responses
and copyrighted content. To mitigate harmful responses, we applied gradient
ascent on the PKU dataset, achieving a 75\% reduction in harmful responses for
Open Pre-trained Transformer Language Models (OPT1.3b and OPT2.7b)
\citet{zhang2022opt} while retaining previous knowledge using the TruthfulQA
dataset \citet{DBLP:journals/corr/abs-2109-07958}. For handling copyrighted
content, we constructed a custom dataset based on the Lord of the Rings corpus
and aligned LLMs (OPT1.3b and OPT2.7b) \citet{zhang2022opt} through LoRA:
Low-Rank Adaptation of Large Language Models
\citet{DBLP:journals/corr/abs-2106-09685} finetuning. Subsequently, we employed
gradient ascent to unlearn the Lord of the Rings content, resulting in a
remarkable reduction in the presence of copyrighted material. To maintain a
diverse knowledge base, we utilized the Book Corpus dataset. Additionally, we
propose a new evaluation technique for assessing the effectiveness of harmful
unlearning.",2024-05-24,"Saaketh Koundinya Gundavarapu, Shreya Agarwal, Arushi Arora, Chandana Thimmalapura Jagadeeshaiah",http://arxiv.org/pdf/2405.15152v1,cs.CL
CulturePark: Boosting Cross-cultural Understanding in Large Language Models,"Cultural bias is pervasive in many large language models (LLMs), largely due
to the deficiency of data representative of different cultures. Typically,
cultural datasets and benchmarks are constructed either by extracting subsets
of existing datasets or by aggregating from platforms such as Wikipedia and
social media. However, these approaches are highly dependent on real-world data
and human annotations, making them costly and difficult to scale. Inspired by
cognitive theories on social communication, this paper introduces CulturePark,
an LLM-powered multi-agent communication framework for cultural data
collection. CulturePark simulates cross-cultural human communication with
LLM-based agents playing roles in different cultures. It generates high-quality
cross-cultural dialogues encapsulating human beliefs, norms, and customs. Using
CulturePark, we generated 41,000 cultural samples to fine-tune eight
culture-specific LLMs. We evaluated these models across three downstream tasks:
content moderation, cultural alignment, and cultural education. Results show
that for content moderation, our GPT-3.5-based models either match or
outperform GPT-4 on datasets. Regarding cultural alignment, our models surpass
GPT-4 on Hofstede's VSM 13 framework. Furthermore, for cultural education of
human participants, our models demonstrate superior outcomes in both learning
efficacy and user experience compared to GPT-4. CulturePark proves an important
step in addressing cultural bias and advancing the democratization of AI,
highlighting the critical role of culturally inclusive data in model training.
Code is released at https://github.com/Scarelette/CulturePark.",2024-05-24,"Cheng Li, Damien Teney, Linyi Yang, Qingsong Wen, Xing Xie, Jindong Wang",http://arxiv.org/pdf/2405.15145v3,cs.CL
Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models,"Go-Explore is a powerful family of algorithms designed to solve
hard-exploration problems built on the principle of archiving discovered
states, and iteratively returning to and exploring from the most promising
states. This approach has led to superhuman performance across a wide variety
of challenging problems including Atari games and robotic control, but requires
manually designing heuristics to guide exploration (i.e., determine which
states to save and explore from, and what actions to consider next), which is
time-consuming and infeasible in general. To resolve this, we propose
Intelligent Go-Explore (IGE) which greatly extends the scope of the original
Go-Explore by replacing these handcrafted heuristics with the intelligence and
internalized human notions of interestingness captured by giant pretrained
foundation models (FMs). This provides IGE with a human-like ability to
instinctively identify how interesting or promising any new state is (e.g.,
discovering new objects, locations, or behaviors), even in complex environments
where heuristics are hard to define. Moreover, IGE offers the exciting
opportunity to recognize and capitalize on serendipitous discoveries -- states
encountered during exploration that are valuable in terms of exploration, yet
where what makes them interesting was not anticipated by the human user. We
evaluate our algorithm on a diverse range of language and vision-based tasks
that require search and exploration. Across these tasks, IGE strongly exceeds
classic reinforcement learning and graph search baselines, and also succeeds
where prior state-of-the-art FM agents like Reflexion completely fail. Overall,
Intelligent Go-Explore combines the tremendous strengths of FMs and the
powerful Go-Explore algorithm, opening up a new frontier of research into
creating more generally capable agents with impressive exploration
capabilities.",2024-05-24,"Cong Lu, Shengran Hu, Jeff Clune",http://arxiv.org/pdf/2405.15143v4,cs.CL
Efficient Biomedical Entity Linking: Clinical Text Standardization with Low-Resource Techniques,"Clinical text is rich in information, with mentions of treatment, medication
and anatomy among many other clinical terms. Multiple terms can refer to the
same core concepts which can be referred as a clinical entity. Ontologies like
the Unified Medical Language System (UMLS) are developed and maintained to
store millions of clinical entities including the definitions, relations and
other corresponding information. These ontologies are used for standardization
of clinical text by normalizing varying surface forms of a clinical term
through Biomedical entity linking. With the introduction of transformer-based
language models, there has been significant progress in Biomedical entity
linking. In this work, we focus on learning through synonym pairs associated
with the entities. As compared to the existing approaches, our approach
significantly reduces the training data and resource consumption. Moreover, we
propose a suite of context-based and context-less reranking techniques for
performing the entity disambiguation. Overall, we achieve similar performance
to the state-of-the-art zero-shot and distant supervised entity linking
techniques on the Medmentions dataset, the largest annotated dataset on UMLS,
without any domain-based training. Finally, we show that retrieval performance
alone might not be sufficient as an evaluation metric and introduce an article
level quantitative and qualitative analysis to reveal further insights on the
performance of entity linking methods.",2024-05-24,"Akshit Achara, Sanand Sasidharan, Gagan N",http://arxiv.org/pdf/2405.15134v2,cs.CL
OptLLM: Optimal Assignment of Queries to Large Language Models,"Large Language Models (LLMs) have garnered considerable attention owing to
their remarkable capabilities, leading to an increasing number of companies
offering LLMs as services. Different LLMs achieve different performance at
different costs. A challenge for users lies in choosing the LLMs that best fit
their needs, balancing cost and performance. In this paper, we propose a
framework for addressing the cost-effective query allocation problem for LLMs.
Given a set of input queries and candidate LLMs, our framework, named OptLLM,
provides users with a range of optimal solutions to choose from, aligning with
their budget constraints and performance preferences, including options for
maximizing accuracy and minimizing cost. OptLLM predicts the performance of
candidate LLMs on each query using a multi-label classification model with
uncertainty estimation and then iteratively generates a set of non-dominated
solutions by destructing and reconstructing the current solution. To evaluate
the effectiveness of OptLLM, we conduct extensive experiments on various types
of tasks, including text classification, question answering, sentiment
analysis, reasoning, and log parsing. Our experimental results demonstrate that
OptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same
accuracy as the best LLM. Compared to other multi-objective optimization
algorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or
saves costs by 8.79% and 95.87% while maintaining the highest attainable
accuracy.",2024-05-24,"Yueyue Liu, Hongyu Zhang, Yuantian Miao, Van-Hoang Le, Zhiqiang Li",http://arxiv.org/pdf/2405.15130v1,cs.CL
Generalizable and Scalable Multistage Biomedical Concept Normalization Leveraging Large Language Models,"Background: Biomedical entity normalization is critical to biomedical
research because the richness of free-text clinical data, such as progress
notes, can often be fully leveraged only after translating words and phrases
into structured and coded representations suitable for analysis. Large Language
Models (LLMs), in turn, have shown great potential and high performance in a
variety of natural language processing (NLP) tasks, but their application for
normalization remains understudied.
  Methods: We applied both proprietary and open-source LLMs in combination with
several rule-based normalization systems commonly used in biomedical research.
We used a two-step LLM integration approach, (1) using an LLM to generate
alternative phrasings of a source utterance, and (2) to prune candidate UMLS
concepts, using a variety of prompting methods. We measure results by
$F_{\beta}$, where we favor recall over precision, and F1.
  Results: We evaluated a total of 5,523 concept terms and text contexts from a
publicly available dataset of human-annotated biomedical abstracts.
Incorporating GPT-3.5-turbo increased overall $F_{\beta}$ and F1 in
normalization systems +9.5 and +7.3 (MetaMapLite), +13.9 and +10.9 (QuickUMLS),
and +10.5 and +10.3 (BM25), while the open-source Vicuna model achieved +10.8
and +12.2 (MetaMapLite), +14.7 and +15 (QuickUMLS), and +15.6 and +18.7 (BM25).
  Conclusions: Existing general-purpose LLMs, both propriety and open-source,
can be leveraged at scale to greatly improve normalization performance using
existing tools, with no fine-tuning.",2024-05-24,Nicholas J Dobbins,http://arxiv.org/pdf/2405.15122v1,cs.CL
Towards Better Understanding of In-Context Learning Ability from In-Context Uncertainty Quantification,"Predicting simple function classes has been widely used as a testbed for
developing theory and understanding of the trained Transformer's in-context
learning (ICL) ability. In this paper, we revisit the training of Transformers
on linear regression tasks, and different from all the existing literature, we
consider a bi-objective prediction task of predicting both the conditional
expectation $\mathbb{E}[Y|X]$ and the conditional variance Var$(Y|X)$. This
additional uncertainty quantification objective provides a handle to (i) better
design out-of-distribution experiments to distinguish ICL from in-weight
learning (IWL) and (ii) make a better separation between the algorithms with
and without using the prior information of the training distribution.
Theoretically, we show that the trained Transformer reaches near Bayes-optimum,
suggesting the usage of the information of the training distribution. Our
method can be extended to other cases. Specifically, with the Transformer's
context window $S$, we prove a generalization bound of
$\tilde{\mathcal{O}}(\sqrt{\min\{S, T\}/(n T)})$ on $n$ tasks with sequences of
length $T$, providing sharper analysis compared to previous results of
$\tilde{\mathcal{O}}(\sqrt{1/n})$. Empirically, we illustrate that while the
trained Transformer behaves as the Bayes-optimal solution as a natural
consequence of supervised training in distribution, it does not necessarily
perform a Bayesian inference when facing task shifts, in contrast to the
\textit{equivalence} between these two proposed in many existing literature. We
also demonstrate the trained Transformer's ICL ability over covariates shift
and prompt-length shift and interpret them as a generalization over a meta
distribution.",2024-05-24,"Shang Liu, Zhongze Cai, Guanting Chen, Xiaocheng Li",http://arxiv.org/pdf/2405.15115v1,cs.CL
CHARP: Conversation History AwaReness Probing for Knowledge-grounded Dialogue Systems,"In this work, we dive deep into one of the popular knowledge-grounded
dialogue benchmarks that focus on faithfulness, FaithDial. We show that a
significant portion of the FaithDial data contains annotation artifacts, which
may bias models towards completely ignoring the conversation history. We
therefore introduce CHARP, a diagnostic test set, designed for an improved
evaluation of hallucinations in conversational model. CHARP not only measures
hallucination but also the compliance of the models to the conversation task.
Our extensive analysis reveals that models primarily exhibit poor performance
on CHARP due to their inability to effectively attend to and reason over the
conversation history. Furthermore, the evaluation methods of FaithDial fail to
capture these shortcomings, neglecting the conversational history. Our findings
indicate that there is substantial room for contribution in both dataset
creation and hallucination evaluation for knowledge-grounded dialogue, and that
CHARP can serve as a tool for monitoring the progress in this particular
research area. CHARP is publicly available at
https://huggingface.co/datasets/huawei-noah/CHARP",2024-05-24,"Abbas Ghaddar, David Alfonso-Hermelo, Philippe Langlais, Mehdi Rezagholizadeh, Boxing Chen, Prasanna Parthasarathi",http://arxiv.org/pdf/2405.15110v1,cs.CL
Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding,"Recently, deep end-to-end learning has been studied for intent classification
in Spoken Language Understanding (SLU). However, end-to-end models require a
large amount of speech data with intent labels, and highly optimized models are
generally sensitive to the inconsistency between the training and evaluation
conditions. Therefore, a natural language understanding approach based on
Automatic Speech Recognition (ASR) remains attractive because it can utilize a
pre-trained general language model and adapt to the mismatch of the speech
input environment. Using this module-based approach, we improve a noisy-channel
model to handle transcription inconsistencies caused by ASR errors. We propose
a two-stage method, Contrastive and Consistency Learning (CCL), that correlates
error patterns between clean and noisy ASR transcripts and emphasizes the
consistency of the latent features of the two transcripts. Experiments on four
benchmark datasets show that CCL outperforms existing methods and improves the
ASR robustness in various noisy environments. Code is available at
https://github.com/syoung7388/CCL.",2024-05-23,"Suyoung Kim, Jiyeon Hwang, Ho-Young Jung",http://arxiv.org/pdf/2405.15097v1,cs.CL
Dissociation of Faithful and Unfaithful Reasoning in LLMs,"Large language models (LLMs) often improve their performance in downstream
tasks when they generate Chain of Thought reasoning text before producing an
answer. We investigate how LLMs recover from errors in Chain of Thought.
Through analysis of error recovery behaviors, we find evidence for
unfaithfulness in Chain of Thought, which occurs when models arrive at the
correct answer despite invalid reasoning text. We identify factors that shift
LLM recovery behavior: LLMs recover more frequently from obvious errors and in
contexts that provide more evidence for the correct answer. Critically, these
factors have divergent effects on faithful and unfaithful recoveries. Our
results indicate that there are distinct mechanisms driving faithful and
unfaithful error recoveries. Selective targeting of these mechanisms may be
able to drive down the rate of unfaithful reasoning and improve model
interpretability.",2024-05-23,"Evelyn Yee, Alice Li, Chenyu Tang, Yeon Ho Jung, Ramamohan Paturi, Leon Bergen",http://arxiv.org/pdf/2405.15092v2,cs.CL
In Silico Sociology: Forecasting COVID-19 Polarization with Large Language Models,"By training deep neural networks on massive archives of digitized text, large
language models (LLMs) learn the complex linguistic patterns that constitute
historic and contemporary discourses. We argue that LLMs can serve as a
valuable tool for sociological inquiry by enabling accurate simulation of
respondents from specific social and cultural contexts. Applying LLMs in this
capacity, we reconstruct the public opinion landscape of 2019 to examine the
extent to which the future polarization over COVID-19 was prefigured in
existing political discourse. Using an LLM trained on texts published through
2019, we simulate the responses of American liberals and conservatives to a
battery of pandemic-related questions. We find that the simulated respondents
reproduce observed partisan differences in COVID-19 attitudes in 84% of cases,
significantly greater than chance. Prompting the simulated respondents to
justify their responses, we find that much of the observed partisan gap
corresponds to differing appeals to freedom, safety, and institutional trust.
Our findings suggest that the politicization of COVID-19 was largely consistent
with the prior ideological landscape, and this unprecedented event served to
advance history along its track rather than change the rails.",2024-05-23,"Austin C. Kozlowski, Hyunku Kwon, James A. Evans",http://arxiv.org/pdf/2407.11190v1,cs.CL
Eliciting Informative Text Evaluations with Large Language Models,"Peer prediction mechanisms motivate high-quality feedback with provable
guarantees. However, current methods only apply to rather simple reports, like
multiple-choice or scalar numbers. We aim to broaden these techniques to the
larger domain of text-based reports, drawing on the recent developments in
large language models. This vastly increases the applicability of peer
prediction mechanisms as textual feedback is the norm in a large variety of
feedback channels: peer reviews, e-commerce customer reviews, and comments on
social media.
  We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)
and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms
utilize LLMs as predictors, mapping from one agent's report to a prediction of
her peer's report. Theoretically, we show that when the LLM prediction is
sufficiently accurate, our mechanisms can incentivize high effort and
truth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, we
confirm the efficacy of our mechanisms through experiments conducted on two
real datasets: the Yelp review dataset and the ICLR OpenReview dataset. We
highlight the results that on the ICLR dataset, our mechanisms can
differentiate three quality levels -- human-written reviews, GPT-4-generated
reviews, and GPT-3.5-generated reviews in terms of expected scores.
Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.",2024-05-23,"Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck",http://arxiv.org/pdf/2405.15077v4,cs.CL
Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization,"We study whether transformers can learn to implicitly reason over parametric
knowledge, a skill that even the most capable language models struggle with.
Focusing on two representative reasoning types, composition and comparison, we
consistently find that transformers can learn implicit reasoning, but only
through grokking, i.e., extended training far beyond overfitting. The levels of
generalization also vary across reasoning types: when faced with
out-of-distribution examples, transformers fail to systematically generalize
for composition but succeed for comparison. We delve into the model's internals
throughout training, conducting analytical experiments that reveal: 1) the
mechanism behind grokking, such as the formation of the generalizing circuit
and its relation to the relative efficiency of generalizing and memorizing
circuits, and 2) the connection between systematicity and the configuration of
the generalizing circuit. Our findings guide data and training setup to better
induce implicit reasoning and suggest potential improvements to the transformer
architecture, such as encouraging cross-layer knowledge sharing. Furthermore,
we demonstrate that for a challenging reasoning task with a large search space,
GPT-4-Turbo and Gemini-1.5-Pro based on non-parametric memory fail badly
regardless of prompting styles or retrieval augmentation, while a fully grokked
transformer can achieve near-perfect accuracy, showcasing the power of
parametric memory for complex reasoning.",2024-05-23,"Boshi Wang, Xiang Yue, Yu Su, Huan Sun",http://arxiv.org/pdf/2405.15071v3,cs.CL
Optimizing example selection for retrieval-augmented machine translation with translation memories,"Retrieval-augmented machine translation leverages examples from a translation
memory by retrieving similar instances. These examples are used to condition
the predictions of a neural decoder. We aim to improve the upstream retrieval
step and consider a fixed downstream edit-based model: the multi-Levenshtein
Transformer. The task consists of finding a set of examples that maximizes the
overall coverage of the source sentence. To this end, we rely on the theory of
submodular functions and explore new algorithms to optimize this coverage. We
evaluate the resulting performance gains for the machine translation task.",2024-05-23,"Maxime Bouthors, Josep Crego, François Yvon",http://arxiv.org/pdf/2405.15070v1,cs.CL
Promoting Constructive Deliberation: Reframing for Receptiveness,"To promote constructive discussion of controversial topics online, we propose
automatic reframing of disagreeing responses to signal receptiveness to a
preceding comment. Drawing on research from psychology, communications, and
linguistics, we identify six strategies for reframing. We automatically reframe
replies to comments according to each strategy, using a Reddit dataset. Through
human-centered experiments, we find that the replies generated with our
framework are perceived to be significantly more receptive than the original
replies and a generic receptiveness baseline. We illustrate how transforming
receptiveness, a particular social science construct, into a computational
framework, can make LLM generations more aligned with human perceptions. We
analyze and discuss the implications of our results, and highlight how a tool
based on our framework might be used for more teachable and creative content
moderation.",2024-05-23,"Gauri Kambhatla, Matthew Lease, Ashwin Rajadesingan",http://arxiv.org/pdf/2405.15067v3,cs.CL
Reframing Spatial Reasoning Evaluation in Language Models: A Real-World Simulation Benchmark for Qualitative Reasoning,"Spatial reasoning plays a vital role in both human cognition and machine
intelligence, prompting new research into language models' (LMs) capabilities
in this regard. However, existing benchmarks reveal shortcomings in evaluating
qualitative spatial reasoning (QSR). These benchmarks typically present
oversimplified scenarios or unclear natural language descriptions, hindering
effective evaluation. We present a novel benchmark for assessing QSR in LMs,
which is grounded in realistic 3D simulation data, offering a series of diverse
room layouts with various objects and their spatial relationships. This
approach provides a more detailed and context-rich narrative for spatial
reasoning evaluation, diverging from traditional, toy-task-oriented scenarios.
Our benchmark encompasses a broad spectrum of qualitative spatial
relationships, including topological, directional, and distance relations.
These are presented with different viewing points, varied granularities, and
density of relation constraints to mimic real-world complexities. A key
contribution is our logic-based consistency-checking tool, which enables the
assessment of multiple plausible solutions, aligning with real-world scenarios
where spatial relationships are often open to interpretation. Our benchmark
evaluation of advanced LMs reveals their strengths and limitations in spatial
reasoning. They face difficulties with multi-hop spatial reasoning and
interpreting a mix of different view descriptions, pointing to areas for future
improvement.",2024-05-23,"Fangjun Li, David C. Hogg, Anthony G. Cohn",http://arxiv.org/pdf/2405.15064v1,cs.CL
Multilingual Prosody Transfer: Comparing Supervised & Transfer Learning,"The field of prosody transfer in speech synthesis systems is rapidly
advancing. This research is focused on evaluating learning methods for adapting
pre-trained monolingual text-to-speech (TTS) models to multilingual conditions,
i.e., Supervised Fine-Tuning (SFT) and Transfer Learning (TL). This comparison
utilizes three distinct metrics: Mean Opinion Score (MOS), Recognition Accuracy
(RA), and Mel Cepstral Distortion (MCD). Results demonstrate that, in
comparison to SFT, TL leads to significantly enhanced performance, with an
average MOS higher by 1.53 points, a 37.5% increase in RA, and approximately a
7.8-point improvement in MCD. These findings are instrumental in helping build
TTS models for low-resource languages.",2024-05-23,"Arnav Goel, Medha Hira, Anubha Gupta",http://arxiv.org/pdf/2406.00022v2,cs.CL
CEEBERT: Cross-Domain Inference in Early Exit BERT,"Pre-trained Language Models (PLMs), like BERT, with self-supervision
objectives exhibit remarkable performance and generalization across various
tasks. However, they suffer in inference latency due to their large size. To
address this issue, side branches are attached at intermediate layers, enabling
early inference of samples without requiring them to pass through all layers.
However, the challenge is to decide which layer to infer and exit each sample
so that the accuracy and latency are balanced. Moreover, the distribution of
the samples to be inferred may differ from that used for training necessitating
cross-domain adaptation. We propose an online learning algorithm named
Cross-Domain Inference in Early Exit BERT (CeeBERT) that dynamically determines
early exits of samples based on the level of confidence at each exit point.
CeeBERT learns optimal thresholds from domain-specific confidence observed at
intermediate layers on the fly, eliminating the need for labeled data.
Experimental results on five distinct datasets with BERT and ALBERT models
demonstrate CeeBERT's ability to improve latency by reducing unnecessary
computations with minimal drop in performance. By adapting to the threshold
values, CeeBERT can speed up the BERT/ALBERT models by $2\times$ - $3.5\times$
with minimal drop in accuracy.",2024-05-23,"Divya Jyoti Bajpai, Manjesh Kumar Hanawal",http://arxiv.org/pdf/2405.15039v1,cs.CL
CrossVoice: Crosslingual Prosody Preserving Cascade-S2ST using Transfer Learning,"This paper presents CrossVoice, a novel cascade-based Speech-to-Speech
Translation (S2ST) system employing advanced ASR, MT, and TTS technologies with
cross-lingual prosody preservation through transfer learning. We conducted
comprehensive experiments comparing CrossVoice with direct-S2ST systems,
showing improved BLEU scores on tasks such as Fisher Es-En, VoxPopuli Fr-En and
prosody preservation on benchmark datasets CVSS-T and IndicTTS. With an average
mean opinion score of 3.75 out of 4, speech synthesized by CrossVoice closely
rivals human speech on the benchmark, highlighting the efficacy of
cascade-based systems and transfer learning in multilingual S2ST with prosody
transfer.",2024-05-23,"Medha Hira, Arnav Goel, Anubha Gupta",http://arxiv.org/pdf/2406.00021v2,cs.CL
Aya 23: Open Weight Releases to Further Multilingual Progress,"This technical report introduces Aya 23, a family of multilingual language
models. Aya 23 builds on the recent release of the Aya model (\""Ust\""un et al.,
2024), focusing on pairing a highly performant pre-trained model with the
recently released Aya collection (Singh et al., 2024). The result is a powerful
multilingual large language model serving 23 languages, expanding state-of-art
language modeling capabilities to approximately half of the world's population.
The Aya model covered 101 languages whereas Aya 23 is an experiment in depth vs
breadth, exploring the impact of allocating more capacity to fewer languages
that are included during pre-training. Aya 23 outperforms both previous
massively multilingual models like Aya 101 for the languages it covers, as well
as widely used models like Gemma, Mistral and Mixtral on an extensive range of
discriminative and generative tasks. We release the open weights for both the
8B and 35B models as part of our continued commitment for expanding access to
multilingual progress.",2024-05-23,"Viraat Aryabumi, John Dang, Dwarak Talupuru, Saurabh Dash, David Cairuz, Hangyu Lin, Bharat Venkitesh, Madeline Smith, Jon Ander Campos, Yi Chern Tan, Kelly Marchisio, Max Bartolo, Sebastian Ruder, Acyr Locatelli, Julia Kreutzer, Nick Frosst, Aidan Gomez, Phil Blunsom, Marzieh Fadaee, Ahmet Üstün, Sara Hooker",http://arxiv.org/pdf/2405.15032v2,cs.CL
AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings,"Ranking is a fundamental and popular problem in search. However, existing
ranking algorithms usually restrict the granularity of ranking to full passages
or require a specific dense index for each desired level of granularity. Such
lack of flexibility in granularity negatively affects many applications that
can benefit from more granular ranking, such as sentence-level ranking for
open-domain question-answering, or proposition-level ranking for attribution.
In this work, we introduce the idea of any-granularity ranking, which leverages
multi-vector embeddings to rank at varying levels of granularity while
maintaining encoding at a single (coarser) level of granularity. We propose a
multi-granular contrastive loss for training multi-vector approaches, and
validate its utility with both sentences and propositions as ranking units.
Finally, we demonstrate the application of proposition-level ranking to
post-hoc citation addition in retrieval-augmented generation, surpassing the
performance of prompt-driven citation generation.",2024-05-23,"Revanth Gangi Reddy, Omar Attia, Yunyao Li, Heng Ji, Saloni Potdar",http://arxiv.org/pdf/2405.15028v1,cs.CL
OAC: Output-adaptive Calibration for Accurate Post-training Quantization,"Deployment of Large Language Models (LLMs) has major computational costs, due
to their rapidly expanding size. Compression of LLMs reduces the memory
footprint, latency, and energy required for their inference. Post-training
Quantization (PTQ) techniques have been developed to compress LLMs while
avoiding expensive re-training. Most PTQ approaches formulate the quantization
error based on a layer-wise Euclidean loss, ignoring the model output. Then,
each layer is calibrated using its layer-wise Hessian to update the weights
towards minimizing the quantization error. The Hessian is also used for
detecting the most salient weights to quantization. Such PTQ approaches are
prone to accuracy drop in low-precision quantization. We propose
Output-adaptive Calibration (OAC) to incorporate the model output in the
calibration process. We formulate the quantization error based on the
distortion of the output cross-entropy loss. OAC approximates the
output-adaptive Hessian for each layer under reasonable assumptions to reduce
the computational complexity. The output-adaptive Hessians are used to update
the weight matrices and detect the salient weights towards maintaining the
model output. Our proposed method outperforms the state-of-the-art baselines
such as SpQR and BiLLM, especially, at extreme low-precision (2-bit and binary)
quantization.",2024-05-23,"Ali Edalati, Alireza Ghaffari, Mahsa Ghazvini Nejad, Lu Hou, Boxing Chen, Masoud Asgharian, Vahid Partovi Nia",http://arxiv.org/pdf/2405.15025v2,cs.CL
Extracting Prompts by Inverting LLM Outputs,"We consider the problem of language model inversion: given outputs of a
language model, we seek to extract the prompt that generated these outputs. We
develop a new black-box method, output2prompt, that learns to extract prompts
without access to the model's logits and without adversarial or jailbreaking
queries. In contrast to previous work, output2prompt only needs outputs of
normal user queries. To improve memory efficiency, output2prompt employs a new
sparse encoding techique. We measure the efficacy of output2prompt on a variety
of user and system prompts and demonstrate zero-shot transferability across
different LLMs.",2024-05-23,"Collin Zhang, John X. Morris, Vitaly Shmatikov",http://arxiv.org/pdf/2405.15012v2,cs.CL
RE-Adapt: Reverse Engineered Adaptation of Large Language Models,"We introduce RE-Adapt, an approach to fine-tuning large language models on
new domains without degrading any pre-existing instruction-tuning. We reverse
engineer an adapter which isolates what an instruction-tuned model has learned
beyond its corresponding pretrained base model. Importantly, this requires no
additional data or training. We can then fine-tune the base model on a new
domain and readapt it to instruction following with the reverse engineered
adapter. RE-Adapt and our low-rank variant LoRE-Adapt both outperform other
methods of fine-tuning, across multiple popular LLMs and datasets, even when
the models are used in conjunction with retrieval-augmented generation.",2024-05-23,"William Fleshman, Benjamin Van Durme",http://arxiv.org/pdf/2405.15007v1,cs.CL
Linking In-context Learning in Transformers to Human Episodic Memory,"Understanding connections between artificial and biological intelligent
systems can reveal fundamental principles of general intelligence. While many
artificial intelligence models have a neuroscience counterpart, such
connections are largely missing in Transformer models and the self-attention
mechanism. Here, we examine the relationship between interacting attention
heads and human episodic memory. We focus on induction heads, which contribute
to in-context learning in Transformer-based large language models (LLMs). We
demonstrate that induction heads are behaviorally, functionally, and
mechanistically similar to the contextual maintenance and retrieval (CMR) model
of human episodic memory. Our analyses of LLMs pre-trained on extensive text
data show that CMR-like heads often emerge in the intermediate and late layers,
qualitatively mirroring human memory biases. The ablation of CMR-like heads
suggests their causal role in in-context learning. Our findings uncover a
parallel between the computational mechanisms of LLMs and human memory,
offering valuable insights into both research fields.",2024-05-23,"Li Ji-An, Corey Y. Zhou, Marcus K. Benna, Marcelo G. Mattar",http://arxiv.org/pdf/2405.14992v2,cs.CL
In-context Time Series Predictor,"Recent Transformer-based large language models (LLMs) demonstrate in-context
learning ability to perform various functions based solely on the provided
context, without updating model parameters. To fully utilize the in-context
capabilities in time series forecasting (TSF) problems, unlike previous
Transformer-based or LLM-based time series forecasting methods, we reformulate
""time series forecasting tasks"" as input tokens by constructing a series of
(lookback, future) pairs within the tokens. This method aligns more closely
with the inherent in-context mechanisms, and is more parameter-efficient
without the need of using pre-trained LLM parameters. Furthermore, it addresses
issues such as overfitting in existing Transformer-based TSF models,
consistently achieving better performance across full-data, few-shot, and
zero-shot settings compared to previous architectures.",2024-05-23,"Jiecheng Lu, Yan Sun, Shihao Yang",http://arxiv.org/pdf/2405.14982v1,cs.CL
"LOVA3: Learning to Visual Question Answering, Asking and Assessment","Question answering, asking, and assessment are three innate human traits
crucial for understanding the world and acquiring knowledge. By enhancing these
capabilities, humans can more effectively utilize data, leading to better
comprehension and learning outcomes. Current Multimodal Large Language Models
(MLLMs) primarily focus on question answering, often neglecting the full
potential of questioning and assessment skills. Inspired by the human learning
mechanism, we introduce LOVA3, an innovative framework named ""Learning tO
Visual question Answering, Asking and Assessment,"" designed to equip MLLMs with
these additional capabilities. Our approach involves the creation of two
supplementary training tasks GenQA and EvalQA, aiming at fostering the skills
of asking and assessing questions in the context of images. To develop the
questioning ability, we compile a comprehensive set of multimodal foundational
tasks. For assessment, we introduce a new benchmark called EvalQABench,
comprising 64,000 training samples (split evenly between positive and negative
samples) and 5,000 validation and testing samples. We posit that enhancing
MLLMs with the capabilities to answer, ask, and assess questions will enhance
their multimodal comprehension, ultimately improving overall performance. To
validate this hypothesis, we train MLLMs using the LOVA3 framework and evaluate
them on a range of multimodal datasets and benchmarks. Our results demonstrate
consistent performance gains, underscoring the critical role of these
additional tasks in fostering comprehensive intelligence in MLLMs. The code is
available at https://github.com/showlab/LOVA3.",2024-05-23,"Henry Hengyuan Zhao, Pan Zhou, Difei Gao, Zechen Bai, Mike Zheng Shou",http://arxiv.org/pdf/2405.14974v3,cs.CL
Data Augmentation Method Utilizing Template Sentences for Variable Definition Extraction,"The extraction of variable definitions from scientific and technical papers
is essential for understanding these documents. However, the characteristics of
variable definitions, such as the length and the words that make up the
definition, differ among fields, which leads to differences in the performance
of existing extraction methods across fields. Although preparing training data
specific to each field can improve the performance of the methods, it is costly
to create high-quality training data. To address this challenge, this study
proposes a new method that generates new definition sentences from template
sentences and variable-definition pairs in the training data. The proposed
method has been tested on papers about chemical processes, and the results show
that the model trained with the definition sentences generated by the proposed
method achieved a higher accuracy of 89.6%, surpassing existing models.",2024-05-23,"Kotaro Nagayama, Shota Kato, Manabu Kano",http://arxiv.org/pdf/2405.14962v1,cs.CL
Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias,"Content moderation on social media platforms shapes the dynamics of online
discourse, influencing whose voices are amplified and whose are suppressed.
Recent studies have raised concerns about the fairness of content moderation
practices, particularly for aggressively flagging posts from transgender and
non-binary individuals as toxic. In this study, we investigate the presence of
bias in harmful speech classification of gender-queer dialect online, focusing
specifically on the treatment of reclaimed slurs. We introduce a novel dataset,
QueerReclaimLex, based on 109 curated templates exemplifying non-derogatory
uses of LGBTQ+ slurs. Dataset instances are scored by gender-queer annotators
for potential harm depending on additional context about speaker identity. We
systematically evaluate the performance of five off-the-shelf language models
in assessing the harm of these texts and explore the effectiveness of
chain-of-thought prompting to teach large language models (LLMs) to leverage
author identity context. We reveal a tendency for these models to inaccurately
flag texts authored by gender-queer individuals as harmful. Strikingly, across
all LLMs the performance is poorest for texts that show signs of being written
by individuals targeted by the featured slur (F1 <= 0.24). We highlight an
urgent need for fairness and inclusivity in content moderation systems. By
uncovering these biases, this work aims to inform the development of more
equitable content moderation practices and contribute to the creation of
inclusive online spaces for all users.",2024-05-23,"Rebecca Dorn, Lee Kezar, Fred Morstatter, Kristina Lerman",http://arxiv.org/pdf/2406.00020v2,cs.CL
A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns,"Cross-domain alignment refers to the task of mapping a concept from one
domain to another. For example, ``If a \textit{doctor} were a \textit{color},
what color would it be?''. This seemingly peculiar task is designed to
investigate how people represent concrete and abstract concepts through their
mappings between categories and their reasoning processes over those mappings.
In this paper, we adapt this task from cognitive science to evaluate the
conceptualization and reasoning abilities of large language models (LLMs)
through a behavioral study. We examine several LLMs by prompting them with a
cross-domain mapping task and analyzing their responses at both the population
and individual levels. Additionally, we assess the models' ability to reason
about their predictions by analyzing and categorizing their explanations for
these mappings. The results reveal several similarities between humans' and
models' mappings and explanations, suggesting that models represent concepts
similarly to humans. This similarity is evident not only in the model
representation but also in their behavior. Furthermore, the models mostly
provide valid explanations and deploy reasoning paths that are similar to those
of humans.",2024-05-23,"Asaf Yehudai, Taelin Karidi, Gabriel Stanovsky, Ariel Goldstein, Omri Abend",http://arxiv.org/pdf/2405.14863v1,cs.CL
Bitune: Bidirectional Instruction-Tuning,"We introduce Bitune, a method that improves instruction-tuning of pretrained
decoder-only large language models, leading to consistent gains on downstream
tasks. Bitune applies both causal and bidirectional attention to the prompt, to
obtain a better representation of the query or instruction. We realize this by
introducing two sets of parameters, for which we apply parameter-efficient
finetuning techniques. These causal and bidirectional features are then
combined into a weighted average with trainable coefficients, which is
subsequently used to generate new tokens. We demonstrate significant
improvements in zero-shot performance on commonsense reasoning, arithmetic, and
language understanding tasks, while extensive ablation studies validate the
role of each component and demonstrate the method's agnosticism to different
PEFT techniques.",2024-05-23,"Dawid J. Kopiczko, Tijmen Blankevoort, Yuki M. Asano",http://arxiv.org/pdf/2405.14862v1,cs.CL
A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis,"While deep networks have achieved broad success in analyzing natural images,
when applied to medical scans, they often fail in unexcepted situations. We
investigate this challenge and focus on model sensitivity to domain shifts,
such as data sampled from different hospitals or data confounded by demographic
variables such as sex, race, etc, in the context of chest X-rays and skin
lesion images. A key finding we show empirically is that existing visual
backbones lack an appropriate prior from the architecture for reliable
generalization in these settings. Taking inspiration from medical training, we
propose giving deep networks a prior grounded in explicit medical knowledge
communicated in natural language. To this end, we introduce Knowledge-enhanced
Bottlenecks (KnoBo), a class of concept bottleneck models that incorporates
knowledge priors that constrain it to reason with clinically relevant factors
found in medical textbooks or PubMed. KnoBo uses retrieval-augmented language
models to design an appropriate concept space paired with an automatic training
procedure for recognizing the concept. We evaluate different resources of
knowledge and recognition architectures on a broad range of domain shifts
across 20 datasets. In our comprehensive evaluation with two imaging
modalities, KnoBo outperforms fine-tuned models on confounded datasets by 32.4%
on average. Finally, evaluations reveal that PubMed is a promising resource for
making medical models less sensitive to domain shift, outperforming other
resources on both diversity of information and final prediction performance.",2024-05-23,"Yue Yang, Mona Gandhi, Yufei Wang, Yifan Wu, Michael S. Yao, Chris Callison-Burch, James C. Gee, Mark Yatskar",http://arxiv.org/pdf/2405.14839v2,cs.CL
From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step,"When leveraging language models for reasoning tasks, generating explicit
chain-of-thought (CoT) steps often proves essential for achieving high accuracy
in final outputs. In this paper, we investigate if models can be taught to
internalize these CoT steps. To this end, we propose a simple yet effective
method for internalizing CoT steps: starting with a model trained for explicit
CoT reasoning, we gradually remove the intermediate steps and finetune the
model. This process allows the model to internalize the intermediate reasoning
steps, thus simplifying the reasoning process while maintaining high
performance. Our approach enables a GPT-2 Small model to solve 9-by-9
multiplication with up to 99% accuracy, whereas standard training cannot solve
beyond 4-by-4 multiplication. Furthermore, our method proves effective on
larger language models, such as Mistral 7B, achieving over 50% accuracy on
GSM8K without producing any intermediate steps.",2024-05-23,"Yuntian Deng, Yejin Choi, Stuart Shieber",http://arxiv.org/pdf/2405.14838v1,cs.CL
HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models,"In order to thrive in hostile and ever-changing natural environments,
mammalian brains evolved to store large amounts of knowledge about the world
and continually integrate new information while avoiding catastrophic
forgetting. Despite the impressive accomplishments, large language models
(LLMs), even with retrieval-augmented generation (RAG), still struggle to
efficiently and effectively integrate a large amount of new experiences after
pre-training. In this work, we introduce HippoRAG, a novel retrieval framework
inspired by the hippocampal indexing theory of human long-term memory to enable
deeper and more efficient knowledge integration over new experiences. HippoRAG
synergistically orchestrates LLMs, knowledge graphs, and the Personalized
PageRank algorithm to mimic the different roles of neocortex and hippocampus in
human memory. We compare HippoRAG with existing RAG methods on multi-hop
question answering and show that our method outperforms the state-of-the-art
methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves
comparable or better performance than iterative retrieval like IRCoT while
being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into
IRCoT brings further substantial gains. Finally, we show that our method can
tackle new types of scenarios that are out of reach of existing methods. Code
and data are available at https://github.com/OSU-NLP-Group/HippoRAG.",2024-05-23,"Bernal Jiménez Gutiérrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, Yu Su",http://arxiv.org/pdf/2405.14831v3,cs.CL
Small Language Models for Application Interactions: A Case Study,"We study the efficacy of Small Language Models (SLMs) in facilitating
application usage through natural language interactions. Our focus here is on a
particular internal application used in Microsoft for cloud supply chain
fulfilment. Our experiments show that small models can outperform much larger
ones in terms of both accuracy and running time, even when fine-tuned on small
datasets. Alongside these results, we also highlight SLM-based system design
considerations.",2024-05-23,"Beibin Li, Yi Zhang, Sébastien Bubeck, Jeevan Pathuri, Ishai Menache",http://arxiv.org/pdf/2405.20347v1,cs.CL
Implicit Personalization in Language Models: A Systematic Study,"Implicit Personalization (IP) is a phenomenon of language models inferring a
user's background from the implicit cues in the input prompts and tailoring the
response based on this inference. While previous work has touched upon various
instances of this problem, there lacks a unified framework to study this
behavior. This work systematically studies IP through a rigorous mathematical
formulation, a multi-perspective moral reasoning framework, and a set of case
studies. Our theoretical foundation for IP relies on a structural causal model
and introduces a novel method, indirect intervention, to estimate the causal
effect of a mediator variable that cannot be directly intervened upon. Beyond
the technical approach, we also introduce a set of moral reasoning principles
based on three schools of moral philosophy to study when IP may or may not be
ethically appropriate. Equipped with both mathematical and ethical insights, we
present three diverse case studies illustrating the varied nature of the IP
problem and offer recommendations for future research. Our code is at
https://github.com/jiarui-liu/IP, and our data is at
https://huggingface.co/datasets/Jerry999/ImplicitPersonalizationData.",2024-05-23,"Zhijing Jin, Nils Heil, Jiarui Liu, Shehzaad Dhuliawala, Yahang Qi, Bernhard Schölkopf, Rada Mihalcea, Mrinmaya Sachan",http://arxiv.org/pdf/2405.14808v2,cs.CL
Can LLMs Solve longer Math Word Problems Better?,"Math Word Problems (MWPs) play a vital role in assessing the capabilities of
Large Language Models (LLMs), yet current research primarily focuses on
questions with concise contexts. The impact of longer contexts on mathematical
reasoning remains under-explored. This study pioneers the investigation of
Context Length Generalizability (CoLeG), which refers to the ability of LLMs to
solve MWPs with extended narratives. We introduce Extended Grade-School Math
(E-GSM), a collection of MWPs featuring lengthy narratives, and propose two
novel metrics to evaluate the efficacy and resilience of LLMs in tackling these
problems. Our analysis of existing zero-shot prompting techniques with
proprietary LLMs along with open-source LLMs reveals a general deficiency in
CoLeG. To alleviate these issues, we propose tailored approaches for different
categories of LLMs. For proprietary LLMs, we introduce a new instructional
prompt designed to mitigate the impact of long contexts. For open-source LLMs,
we develop a novel auxiliary task for fine-tuning to enhance CoLeG. Our
comprehensive results demonstrate the effectiveness of our proposed methods,
showing improved performance on E-GSM. Additionally, we conduct an in-depth
analysis to differentiate the effects of semantic understanding and reasoning
efficacy, showing that our methods improves the latter. We also establish the
generalizability of our methods across several other MWP benchmarks. Our
findings highlight the limitations of current LLMs and offer practical
solutions correspondingly, paving the way for further exploration of model
generalizability and training methodologies.",2024-05-23,"Xin Xu, Tong Xiao, Zitong Chao, Zhenya Huang, Can Yang, Yang Wang",http://arxiv.org/pdf/2405.14804v4,cs.CL
Lessons from the Trenches on Reproducible Evaluation of Language Models,"Effective evaluation of language models remains an open challenge in NLP.
Researchers and engineers face methodological issues such as the sensitivity of
models to evaluation setup, difficulty of proper comparisons across methods,
and the lack of reproducibility and transparency. In this paper we draw on
three years of experience in evaluating large language models to provide
guidance and lessons for researchers. First, we provide an overview of common
challenges faced in language model evaluation. Second, we delineate best
practices for addressing or lessening the impact of these challenges on
research. Third, we present the Language Model Evaluation Harness (lm-eval): an
open source library for independent, reproducible, and extensible evaluation of
language models that seeks to address these issues. We describe the features of
the library as well as case studies in which the library has been used to
alleviate these methodological concerns.",2024-05-23,"Stella Biderman, Hailey Schoelkopf, Lintang Sutawika, Leo Gao, Jonathan Tow, Baber Abbasi, Alham Fikri Aji, Pawan Sasanka Ammanamanchi, Sidney Black, Jordan Clive, Anthony DiPofi, Julen Etxaniz, Benjamin Fattori, Jessica Zosa Forde, Charles Foster, Jeffrey Hsu, Mimansa Jaiswal, Wilson Y. Lee, Haonan Li, Charles Lovering, Niklas Muennighoff, Ellie Pavlick, Jason Phang, Aviya Skowron, Samson Tan, Xiangru Tang, Kevin A. Wang, Genta Indra Winata, François Yvon, Andy Zou",http://arxiv.org/pdf/2405.14782v2,cs.CL
Smart Bilingual Focused Crawling of Parallel Documents,"Crawling parallel texts $\unicode{x2014}$texts that are mutual
translations$\unicode{x2014}$ from the Internet is usually done following a
brute-force approach: documents are massively downloaded in an unguided
process, and only a fraction of them end up leading to actual parallel content.
In this work we propose a smart crawling method that guides the crawl towards
finding parallel content more rapidly. Our approach builds on two different
models: one that infers the language of a document from its URL, and another
that infers whether a pair of URLs link to parallel documents. We evaluate both
models in isolation and their integration into a crawling tool. The results
demonstrate the individual effectiveness of both models and highlight that
their combination enables the early discovery of parallel content during
crawling, leading to a reduction in the amount of downloaded documents deemed
useless, and yielding a greater quantity of parallel documents compared to
conventional crawling approaches.",2024-05-23,"Cristian García-Romero, Miquel Esplà-Gomis, Felipe Sánchez-Martínez",http://arxiv.org/pdf/2405.14779v1,cs.CL
Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from Human Input,"Humans use social context to specify preferences over behaviors, i.e. their
reward functions. Yet, algorithms for inferring reward models from preference
data do not take this social learning view into account. Inspired by pragmatic
human communication, we study how to extract fine-grained data regarding why an
example is preferred that is useful for learning more accurate reward models.
We propose to enrich binary preference queries to ask both (1) which features
of a given example are preferable in addition to (2) comparisons between
examples themselves. We derive an approach for learning from these
feature-level preferences, both for cases where users specify which features
are reward-relevant, and when users do not. We evaluate our approach on linear
bandit settings in both vision- and language-based domains. Results support the
efficiency of our approach in quickly converging to accurate rewards with fewer
comparisons vs. example-only labels. Finally, we validate the real-world
applicability with a behavioral experiment on a mushroom foraging task. Our
findings suggest that incorporating pragmatic feature preferences is a
promising approach for more efficient user-aligned reward learning.",2024-05-23,"Andi Peng, Yuying Sun, Tianmin Shu, David Abel",http://arxiv.org/pdf/2405.14769v1,cs.CL
WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models,"Large language models (LLMs) need knowledge updates to meet the ever-growing
world facts and correct the hallucinated responses, facilitating the methods of
lifelong model editing. Where the updated knowledge resides in memories is a
fundamental question for model editing. In this paper, we find that editing
either long-term memory (direct model parameters) or working memory
(non-parametric knowledge of neural network activations/representations by
retrieval) will result in an impossible triangle -- reliability,
generalization, and locality can not be realized together in the lifelong
editing settings. For long-term memory, directly editing the parameters will
cause conflicts with irrelevant pretrained knowledge or previous edits (poor
reliability and locality). For working memory, retrieval-based activations can
hardly make the model understand the edits and generalize (poor
generalization). Therefore, we propose WISE to bridge the gap between memories.
In WISE, we design a dual parametric memory scheme, which consists of the main
memory for the pretrained knowledge and a side memory for the edited knowledge.
We only edit the knowledge in the side memory and train a router to decide
which memory to go through when given a query. For continual editing, we devise
a knowledge-sharding mechanism where different sets of edits reside in distinct
subspaces of parameters, and are subsequently merged into a shared memory
without conflicts. Extensive experiments show that WISE can outperform previous
model editing methods and overcome the impossible triangle under lifelong model
editing of question answering, hallucination, and out-of-distribution settings
across trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is
available at https://github.com/zjunlp/EasyEdit.",2024-05-23,"Peng Wang, Zexi Li, Ningyu Zhang, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",http://arxiv.org/pdf/2405.14768v3,cs.CL
FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models,"As financial institutions and professionals increasingly incorporate Large
Language Models (LLMs) into their workflows, substantial barriers, including
proprietary data and specialized knowledge, persist between the finance sector
and the AI community. These challenges impede the AI community's ability to
enhance financial tasks effectively. Acknowledging financial analysis's
critical role, we aim to devise financial-specialized LLM-based toolchains and
democratize access to them through open-source initiatives, promoting wider AI
adoption in financial decision-making. In this paper, we introduce FinRobot, a
novel open-source AI agent platform supporting multiple financially specialized
AI agents, each powered by LLM. Specifically, the platform consists of four
major layers: 1) the Financial AI Agents layer that formulates Financial
Chain-of-Thought (CoT) by breaking sophisticated financial problems down into
logical sequences; 2) the Financial LLM Algorithms layer dynamically configures
appropriate model application strategies for specific tasks; 3) the LLMOps and
DataOps layer produces accurate models by applying training/fine-tuning
techniques and using task-relevant data; 4) the Multi-source LLM Foundation
Models layer that integrates various LLMs and enables the above layers to
access them directly. Finally, FinRobot provides hands-on for both
professional-grade analysts and laypersons to utilize powerful AI techniques
for advanced financial analysis. We open-source FinRobot at
\url{https://github.com/AI4Finance-Foundation/FinRobot}.",2024-05-23,"Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, Christina Dan Wang",http://arxiv.org/pdf/2405.14767v2,cs.CL
Evaluating Large Language Models for Public Health Classification and Extraction Tasks,"Advances in Large Language Models (LLMs) have led to significant interest in
their potential to support human experts across a range of domains, including
public health. In this work we present automated evaluations of LLMs for public
health tasks involving the classification and extraction of free text. We
combine six externally annotated datasets with seven new internally annotated
datasets to evaluate LLMs for processing text related to: health burden,
epidemiological risk factors, and public health interventions. We evaluate
eleven open-weight LLMs (7-123 billion parameters) across all tasks using
zero-shot in-context learning. We find that Llama-3.3-70B-Instruct is the
highest performing model, achieving the best results on 8/16 tasks (using
micro-F1 scores). We see significant variation across tasks with all
open-weight LLMs scoring below 60% micro-F1 on some challenging tasks, such as
Contact Classification, while all LLMs achieve greater than 80% micro-F1 on
others, such as GI Illness Classification. For a subset of 11 tasks, we also
evaluate three GPT-4 and GPT-4o series models and find comparable results to
Llama-3.3-70B-Instruct. Overall, based on these initial results we find
promising signs that LLMs may be useful tools for public health experts to
extract information from a wide variety of free text sources, and support
public health surveillance, research, and interventions.",2024-05-23,"Joshua Harris, Timothy Laurence, Leo Loman, Fan Grayson, Toby Nonnenmacher, Harry Long, Loes WalsGriffith, Amy Douglas, Holly Fountain, Stelios Georgiou, Jo Hardstaff, Kathryn Hopkins, Y-Ling Chi, Galena Kuyumdzhieva, Lesley Larkin, Samuel Collins, Hamish Mohammed, Thomas Finnie, Luke Hounsome, Michael Borowitz, Steven Riley",http://arxiv.org/pdf/2405.14766v2,cs.CL
SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large Language Models,"Post-training quantization (PTQ) is an effective technique for compressing
large language models (LLMs). However, while uniform-precision quantization is
computationally efficient, it often compromises model performance. To address
this, we propose SliM-LLM, a salience-driven mixed-precision quantization
framework that allocates bit-widths at the group-wise. Our approach leverages
the observation that important weights follow a structured distribution and
introduces two key components: \textbf{1)} \textit{Salience-Determined Bit
Allocation} adaptively assigns bit-widths to groups within each layer based on
their salience; and \textbf{2)} \textit{Salience-Weighted Quantizer
Calibration} optimizes quantizer parameters by incorporating element-level
salience. With its structured partitioning, SliM-LLM provides a
hardware-friendly solution that matches the efficiency of uniform quantization
methods while improving accuracy. Experiments show that SliM-LLM achieves
superior performance across various LLMs at low bit-widths. For example, a
2-bit quantized LLaMA-7B model reduces memory usage by nearly 6x compared to
the floating-point baseline, decreases perplexity by 48\% compared to
state-of-the-art gradient-free PTQ methods, and maintains GPU inference speed.
Additionally, the extended version, SliM-LLM$^+$, which incorporates
gradient-based quantization, further reduces perplexity by 35.1\%. Our code is
available at https://github.com/Aaronhuang-778/SliM-LLM",2024-05-23,"Wei Huang, Haotong Qin, Yangdong Liu, Yawei Li, Qinshuo Liu, Xianglong Liu, Luca Benini, Michele Magno, Shiming Zhang, Xiaojuan Qi",http://arxiv.org/pdf/2405.14917v2,cs.CL
SimPO: Simple Preference Optimization with a Reference-Free Reward,"Direct Preference Optimization (DPO) is a widely used offline preference
optimization algorithm that reparameterizes reward functions in reinforcement
learning from human feedback (RLHF) to enhance simplicity and training
stability. In this work, we propose SimPO, a simpler yet more effective
approach. The effectiveness of SimPO is attributed to a key design: using the
average log probability of a sequence as the implicit reward. This reward
formulation better aligns with model generation and eliminates the need for a
reference model, making it more compute and memory efficient. Additionally, we
introduce a target reward margin to the Bradley-Terry objective to encourage a
larger margin between the winning and losing responses, further improving the
algorithm's performance. We compare SimPO to DPO and its latest variants across
various state-of-the-art training setups, including both base and
instruction-tuned models such as Mistral, Llama 3, and Gemma 2. We evaluate on
extensive chat-based evaluation benchmarks, including AlpacaEval 2, MT-Bench,
and Arena-Hard. Our results demonstrate that SimPO consistently and
significantly outperforms existing approaches without substantially increasing
response length. Specifically, SimPO outperforms DPO by up to 6.4 points on
AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our top-performing model,
built on Gemma-2-9B-it, achieves a 72.4% length-controlled win rate on
AlpacaEval 2, a 59.1% win rate on Arena-Hard, and ranks 1st on Chatbot Arena
among <10B models with real user votes.",2024-05-23,"Yu Meng, Mengzhou Xia, Danqi Chen",http://arxiv.org/pdf/2405.14734v3,cs.CL
DAPE: Data-Adaptive Positional Encoding for Length Extrapolation,"Positional encoding plays a crucial role in transformers, significantly
impacting model performance and length generalization. Prior research has
introduced absolute positional encoding (APE) and relative positional encoding
(RPE) to distinguish token positions in given sequences. However, both APE and
RPE remain fixed after model training regardless of input data, limiting their
adaptability and flexibility. Hence, we expect that the desired positional
encoding should be data-adaptive and can be dynamically adjusted with the given
attention. In this paper, we propose a Data-Adaptive Positional Encoding (DAPE)
method, which dynamically and semantically adjusts based on input context and
learned fixed priors. Experimental validation on real-world datasets (Arxiv,
Books3, and CHE) demonstrates that DAPE enhances model performances in terms of
trained length and length generalization, where the improvements are
statistically significant. The model visualization suggests that our model can
keep both local and anti-local information. Finally, we successfully train the
model on sequence length 128 and achieve better performance at evaluation
sequence length 8192, compared with other static positional encoding methods,
revealing the benefit of the adaptive positional encoding method.",2024-05-23,"Chuanyang Zheng, Yihang Gao, Han Shi, Minbin Huang, Jingyao Li, Jing Xiong, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li",http://arxiv.org/pdf/2405.14722v6,cs.CL
A Declarative System for Optimizing AI Workloads,"A long-standing goal of data management systems has been to build systems
which can compute quantitative insights over large corpora of unstructured data
in a cost-effective manner. Until recently, it was difficult and expensive to
extract facts from company documents, data from scientific papers, or metrics
from image and video corpora. Today's models can accomplish these tasks with
high accuracy. However, a programmer who wants to answer a substantive
AI-powered query must orchestrate large numbers of models, prompts, and data
operations. For even a single query, the programmer has to make a vast number
of decisions such as the choice of model, the right inference method, the most
cost-effective inference hardware, the ideal prompt design, and so on. The
optimal set of decisions can change as the query changes and as the
rapidly-evolving technical landscape shifts. In this paper we present
Palimpzest, a system that enables anyone to process AI-powered analytical
queries simply by defining them in a declarative language. The system uses its
cost optimization framework to implement the query plan with the best
trade-offs between runtime, financial cost, and output data quality. We
describe the workload of AI-powered analytics tasks, the optimization methods
that Palimpzest uses, and the prototype system itself. We evaluate Palimpzest
on tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching.
We show that even our simple prototype offers a range of appealing plans,
including one that is 3.3x faster and 2.9x cheaper than the baseline method,
while also offering better data quality. With parallelism enabled, Palimpzest
can produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a
single-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the
baseline. These require no additional work by the user.",2024-05-23,"Chunwei Liu, Matthew Russo, Michael Cafarella, Lei Cao, Peter Baille Chen, Zui Chen, Michael Franklin, Tim Kraska, Samuel Madden, Gerardo Vitagliano",http://arxiv.org/pdf/2405.14696v2,cs.CL
Implicit In-context Learning,"In-context Learning (ICL) empowers large language models (LLMs) to swiftly
adapt to unseen tasks at inference-time by prefixing a few demonstration
examples before queries. Despite its versatility, ICL incurs substantial
computational and memory overheads compared to zero-shot learning and is
sensitive to the selection and order of demonstration examples. In this work,
we introduce Implicit In-context Learning (I2CL), an innovative paradigm that
reduces the inference cost of ICL to that of zero-shot learning with minimal
information loss. I2CL operates by first generating a condensed vector
representation, namely a context vector, extracted from the demonstration
examples. It then conducts an inference-time intervention through injecting a
linear combination of the context vector and query activations back into the
model's residual streams. Empirical evaluation on nine real-world tasks across
three model architectures demonstrates that I2CL achieves few-shot level
performance at zero-shot inference cost, and it exhibits robustness against
variations in demonstration examples. Furthermore, I2CL facilitates a novel
representation of task-ids, enhancing task similarity detection and fostering
effective transfer learning. We also perform a comprehensive analysis and
ablation study on I2CL, offering deeper insights into its internal mechanisms.
Code is available at https://github.com/LzVv123456/I2CL.",2024-05-23,"Zhuowei Li, Zihao Xu, Ligong Han, Yunhe Gao, Song Wen, Di Liu, Hao Wang, Dimitris N. Metaxas",http://arxiv.org/pdf/2405.14660v2,cs.CL
Efficient Medical Question Answering with Knowledge-Augmented Question Generation,"In the expanding field of language model applications, medical knowledge
representation remains a significant challenge due to the specialized nature of
the domain. Large language models, such as GPT-4, obtain reasonable scores on
medical question answering tasks, but smaller models are far behind. In this
work, we introduce a method to improve the proficiency of a small language
model in the medical domain by employing a two-fold approach. We first
fine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to
generate questions similar to the downstream task, prompted with textbook
knowledge, and use them to fine-tune the model. Additionally, we introduce
ECN-QA, a novel medical question answering dataset containing ``progressive
questions'' composed of related sequential questions. We show the benefits of
our training strategy on this dataset. The study's findings highlight the
potential of small language models in the medical domain when appropriately
fine-tuned. The code and weights are available at
https://github.com/raidium-med/MQG.",2024-05-23,"Julien Khlaut, Corentin Dancette, Elodie Ferreres, Alaedine Bennani, Paul Hérent, Pierre Manceron",http://arxiv.org/pdf/2405.14654v1,cs.CL
Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models,"The automatic evaluation of natural language generation (NLG) systems
presents a long-lasting challenge. Recent studies have highlighted various
neural metrics that align well with human evaluations. Yet, the robustness of
these evaluators against adversarial perturbations remains largely
under-explored due to the unique challenges in obtaining adversarial data for
different NLG evaluation tasks. To address the problem, we introduce AdvEval, a
novel black-box adversarial framework against NLG evaluators. AdvEval is
specially tailored to generate data that yield strong disagreements between
human and victim evaluators. Specifically, inspired by the recent success of
large language models (LLMs) in text generation and evaluation, we adopt strong
LLMs as both the data generator and gold evaluator. Adversarial data are
automatically optimized with feedback from the gold and victim evaluator. We
conduct experiments on 12 victim evaluators and 11 NLG datasets, spanning tasks
including dialogue, summarization, and question evaluation. The results show
that AdvEval can lead to significant performance degradation of various victim
metrics, thereby validating its efficacy.",2024-05-23,"Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li",http://arxiv.org/pdf/2405.14646v2,cs.CL
Calibrated Self-Rewarding Vision Language Models,"Large Vision-Language Models (LVLMs) have made substantial progress by
integrating pre-trained large language models (LLMs) and vision models through
instruction tuning. Despite these advancements, LVLMs often exhibit the
hallucination phenomenon, where generated text responses appear linguistically
plausible but contradict the input image, indicating a misalignment between
image and text pairs. This misalignment arises because the model tends to
prioritize textual information over visual input, even when both the language
model and visual representations are of high quality. Existing methods leverage
additional models or human annotations to curate preference data and enhance
modality alignment through preference optimization. These approaches may not
effectively reflect the target LVLM's preferences, making the curated
preferences easily distinguishable. Our work addresses these challenges by
proposing the Calibrated Self-Rewarding (CSR) approach, which enables the model
to self-improve by iteratively generating candidate responses, evaluating the
reward for each response, and curating preference data for fine-tuning. In the
reward modeling, we employ a step-wise strategy and incorporate visual
constraints into the self-rewarding process to place greater emphasis on visual
input. Empirical results demonstrate that CSR enhances performance and reduces
hallucinations across ten benchmarks and tasks, achieving substantial
improvements over existing methods by 7.62%. Our empirical results are further
supported by rigorous theoretical analysis, under mild assumptions, verifying
the effectiveness of introducing visual constraints into the self-rewarding
paradigm. Additionally, CSR shows compatibility with different vision-language
models and the ability to incrementally improve performance through iterative
fine-tuning. Our data and code are available at
https://github.com/YiyangZhou/CSR.",2024-05-23,"Yiyang Zhou, Zhiyuan Fan, Dongjie Cheng, Sihan Yang, Zhaorun Chen, Chenhang Cui, Xiyao Wang, Yun Li, Linjun Zhang, Huaxiu Yao",http://arxiv.org/pdf/2405.14622v4,cs.CL
Watermarking Low-entropy Generation for Large Language Models: An Unbiased and Low-risk Method,"Recent advancements in large language models (LLMs) have highlighted the risk
of misusing them, raising the need for accurate detection of LLM-generated
content. In response, a viable solution is to inject imperceptible identifiers
into LLMs, known as watermarks. Our research extends the existing watermarking
methods by proposing the novel Sampling One Then Accepting (STA-1) method.
STA-1 is an unbiased watermark that preserves the original token distribution
in expectation and has a lower risk of producing unsatisfactory outputs in
low-entropy scenarios compared to existing unbiased watermarks. In watermark
detection, STA-1 does not require prompts or a white-box LLM, provides
statistical guarantees, demonstrates high efficiency in detection time, and
remains robust against various watermarking attacks. Experimental results on
low-entropy and high-entropy datasets demonstrate that STA-1 achieves the above
properties simultaneously, making it a desirable solution for watermarking
LLMs. Implementation codes for this study are available online.",2024-05-23,"Minjia Mao, Dongjun Wei, Zeyu Chen, Xiao Fang, Michael Chau",http://arxiv.org/pdf/2405.14604v3,cs.CL
A FAIR and Free Prompt-based Research Assistant,"This demo will present the Research Assistant (RA) tool developed to assist
with six main types of research tasks defined as standardized instruction
templates, instantiated with user input, applied finally as prompts to
well-known--for their sophisticated natural language processing abilities--AI
tools, such as ChatGPT (https://chat.openai.com/) and Gemini
(https://gemini.google.com/app). The six research tasks addressed by RA are:
creating FAIR research comparisons, ideating research topics, drafting grant
applications, writing scientific blogs, aiding preliminary peer reviews, and
formulating enhanced literature search queries. RA's reliance on generative AI
tools like ChatGPT or Gemini means the same research task assistance can be
offered in any scientific discipline. We demonstrate its versatility by sharing
RA outputs in Computer Science, Virology, and Climate Science, where the output
with the RA tool assistance mirrored that from a domain expert who performed
the same research task.",2024-05-23,"Mahsa Shamsabadi, Jennifer D'Souza",http://arxiv.org/pdf/2405.14601v1,cs.CL
Data Augmentation Techniques for Process Extraction from Scientific Publications,"We present data augmentation techniques for process extraction tasks in
scientific publications. We cast the process extraction task as a sequence
labeling task where we identify all the entities in a sentence and label them
according to their process-specific roles. The proposed method attempts to
create meaningful augmented sentences by utilizing (1) process-specific
information from the original sentence, (2) role label similarity, and (3)
sentence similarity. We demonstrate that the proposed methods substantially
improve the performance of the process extraction model trained on chemistry
domain datasets, up to 12.3 points improvement in performance accuracy
(F-score). The proposed methods could potentially reduce overfitting as well,
especially when training on small datasets or in a low-resource setting such as
in chemistry and other scientific domains.",2024-05-23,Yuni Susanti,http://arxiv.org/pdf/2405.14594v1,cs.CL
Base of RoPE Bounds Context Length,"Position embedding is a core component of current Large Language Models
(LLMs). Rotary position embedding (RoPE), a technique that encodes the position
information with a rotation matrix, has been the de facto choice for position
embedding in many LLMs, such as the Llama series. RoPE has been further
utilized to extend long context capability, which is roughly based on adjusting
the \textit{base} parameter of RoPE to mitigate out-of-distribution (OOD)
problems in position embedding. However, in this paper, we find that LLMs may
obtain a superficial long-context ability based on the OOD theory. We revisit
the role of RoPE in LLMs and propose a novel property of long-term decay, we
derive that the \textit{base of RoPE bounds context length}: there is an
absolute lower bound for the base value to obtain certain context length
capability. Our work reveals the relationship between context length and RoPE
base both theoretically and empirically, which may shed light on future long
context training.",2024-05-23,"Xin Men, Mingyu Xu, Bingning Wang, Qingyu Zhang, Hongyu Lin, Xianpei Han, Weipeng Chen",http://arxiv.org/pdf/2405.14591v1,cs.CL
Representation Noising: A Defence Mechanism Against Harmful Finetuning,"Releasing open-source large language models (LLMs) presents a dual-use risk
since bad actors can easily fine-tune these models for harmful purposes. Even
without the open release of weights, weight stealing and fine-tuning APIs make
closed models vulnerable to harmful fine-tuning attacks (HFAs). While safety
measures like preventing jailbreaks and improving safety guardrails are
important, such measures can easily be reversed through fine-tuning. In this
work, we propose Representation Noising (RepNoise), a defence mechanism that
operates even when attackers have access to the weights. RepNoise works by
removing information about harmful representations such that it is difficult to
recover them during fine-tuning. Importantly, our defence is also able to
generalize across different subsets of harm that have not been seen during the
defence process as long as they are drawn from the same distribution of the
attack set. Our method does not degrade the general capability of LLMs and
retains the ability to train the model on harmless tasks. We provide empirical
evidence that the efficacy of our defence lies in its ``depth'': the degree to
which information about harmful representations is removed across all layers of
the LLM. We also find areas where RepNoise still remains ineffective and
highlight how those limitations can inform future research.",2024-05-23,"Domenic Rosati, Jan Wehner, Kai Williams, Łukasz Bartoszcze, David Atanasov, Robie Gonzales, Subhabrata Majumdar, Carsten Maple, Hassan Sajjad, Frank Rudzicz",http://arxiv.org/pdf/2405.14577v4,cs.CL
Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models,"Research on Large Language Models (LLMs) has often neglected subtle biases
that, although less apparent, can significantly influence the models' outputs
toward particular social narratives. This study addresses two such biases
within LLMs: representative bias, which denotes a tendency of LLMs to generate
outputs that mirror the experiences of certain identity groups, and affinity
bias, reflecting the models' evaluative preferences for specific narratives or
viewpoints. We introduce two novel metrics to measure these biases: the
Representative Bias Score (RBS) and the Affinity Bias Score (ABS), and present
the Creativity-Oriented Generation Suite (CoGS), a collection of open-ended
tasks such as short story writing and poetry composition, designed with
customized rubrics to detect these subtle biases. Our analysis uncovers marked
representative biases in prominent LLMs, with a preference for identities
associated with being white, straight, and men. Furthermore, our investigation
of affinity bias reveals distinctive evaluative patterns within each model,
akin to `bias fingerprints'. This trend is also seen in human evaluators,
highlighting a complex interplay between human and machine bias perceptions.",2024-05-23,"Abhishek Kumar, Sarfaroz Yunusov, Ali Emami",http://arxiv.org/pdf/2405.14555v4,cs.CL
Exploring Alignment in Shared Cross-lingual Spaces,"Despite their remarkable ability to capture linguistic nuances across diverse
languages, questions persist regarding the degree of alignment between
languages in multilingual embeddings. Drawing inspiration from research on
high-dimensional representations in neural language models, we employ
clustering to uncover latent concepts within multilingual models. Our analysis
focuses on quantifying the \textit{alignment} and \textit{overlap} of these
concepts across various languages within the latent space. To this end, we
introduce two metrics \CA{} and \CO{} aimed at quantifying these aspects,
enabling a deeper exploration of multilingual embeddings. Our study encompasses
three multilingual models (\texttt{mT5}, \texttt{mBERT}, and \texttt{XLM-R})
and three downstream tasks (Machine Translation, Named Entity Recognition, and
Sentiment Analysis). Key findings from our analysis include: i) deeper layers
in the network demonstrate increased cross-lingual \textit{alignment} due to
the presence of language-agnostic concepts, ii) fine-tuning of the models
enhances \textit{alignment} within the latent space, and iii) such
task-specific calibration helps in explaining the emergence of zero-shot
capabilities in the models.\footnote{The code is available at
\url{https://github.com/baselmousi/multilingual-latent-concepts}}",2024-05-23,"Basel Mousi, Nadir Durrani, Fahim Dalvi, Majd Hawasly, Ahmed Abdelali",http://arxiv.org/pdf/2405.14535v1,cs.CL
Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property,"Techniques that explain the predictions of black-box machine learning models
are crucial to make the models transparent, thereby increasing trust in AI
systems. The input features to the models often have a nested structure that
consists of high- and low-level features, and each high-level feature is
decomposed into multiple low-level features. For such inputs, both high-level
feature attributions (HiFAs) and low-level feature attributions (LoFAs) are
important for better understanding the model's decision. In this paper, we
propose a model-agnostic local explanation method that effectively exploits the
nested structure of the input to estimate the two-level feature attributions
simultaneously. A key idea of the proposed method is to introduce the
consistency property that should exist between the HiFAs and LoFAs, thereby
bridging the separate optimization problems for estimating them. Thanks to this
consistency property, the proposed method can produce HiFAs and LoFAs that are
both faithful to the black-box models and consistent with each other, using a
smaller number of queries to the models. In experiments on image classification
in multiple instance learning and text classification using language models, we
demonstrate that the HiFAs and LoFAs estimated by the proposed method are
accurate, faithful to the behaviors of the black-box models, and provide
consistent explanations.",2024-05-23,"Yuya Yoshikawa, Masanari Kimura, Ryotaro Shimizu, Yuki Saito",http://arxiv.org/pdf/2405.14522v2,cs.CL
Synthetic Data Generation for Intersectional Fairness by Leveraging Hierarchical Group Structure,"In this paper, we introduce a data augmentation approach specifically
tailored to enhance intersectional fairness in classification tasks. Our method
capitalizes on the hierarchical structure inherent to intersectionality, by
viewing groups as intersections of their parent categories. This perspective
allows us to augment data for smaller groups by learning a transformation
function that combines data from these parent groups. Our empirical analysis,
conducted on four diverse datasets including both text and images, reveals that
classifiers trained with this data augmentation approach achieve superior
intersectional fairness and are more robust to ``leveling down'' when compared
to methods optimizing traditional group fairness metrics.",2024-05-23,"Gaurav Maheshwari, Aurélien Bellet, Pascal Denis, Mikaela Keller",http://arxiv.org/pdf/2405.14521v1,cs.CL
Unchosen Experts Can Contribute Too: Unleashing MoE Models' Power by Self-Contrast,"Mixture-of-Experts (MoE) has emerged as a prominent architecture for scaling
model size while maintaining computational efficiency. In MoE, each token in
the input sequence activates a different subset of experts determined by a
routing mechanism. However, the unchosen experts in MoE models do not
contribute to the output, potentially leading to underutilization of the
model's capacity. In this work, we first conduct exploratory studies to
demonstrate that increasing the number of activated experts does not
necessarily improve and can even degrade the output quality. Then, we show that
output distributions from an MoE model using different routing strategies
substantially differ, indicating that different experts do not always act
synergistically. Motivated by these findings, we propose Self-Contrast
Mixture-of-Experts (SCMoE), a training-free strategy that utilizes unchosen
experts in a self-contrast manner during inference. In SCMoE, the next-token
probabilities are determined by contrasting the outputs from strong and weak
activation using the same MoE model. Our method is conceptually simple and
computationally lightweight, as it incurs minimal latency compared to greedy
decoding. Experiments on several benchmarks (GSM8K, StrategyQA, MBPP and
HumanEval) demonstrate that SCMoE can consistently enhance Mixtral 8x7B's
reasoning capability across various domains. For example, it improves the
accuracy on GSM8K from 61.79 to 66.94. Moreover, combining SCMoE with
self-consistency yields additional gains, increasing major@20 accuracy from
75.59 to 78.31.",2024-05-23,"Chufan Shi, Cheng Yang, Xinyu Zhu, Jiahao Wang, Taiqiang Wu, Siheng Li, Deng Cai, Yujiu Yang, Yu Meng",http://arxiv.org/pdf/2405.14507v2,cs.CL
Explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing,"Concerns about the effect of greenhouse gases have motivated the development
of certification protocols to quantify the industrial carbon footprint (CF).
These protocols are manual, work-intensive, and expensive. All of the above
have led to a shift towards automatic data-driven approaches to estimate the
CF, including Machine Learning (ML) solutions. Unfortunately, the
decision-making processes involved in these solutions lack transparency from
the end user's point of view, who must blindly trust their outcomes compared to
intelligible traditional manual approaches. In this research, manual and
automatic methodologies for CF estimation were reviewed, taking into account
their transparency limitations. This analysis led to the proposal of a new
explainable ML solution for automatic CF calculations through bank transaction
classification. Consideration should be given to the fact that no previous
research has considered the explainability of bank transaction classification
for this purpose. For classification, different ML models have been employed
based on their promising performance in the literature, such as Support Vector
Machine, Random Forest, and Recursive Neural Networks. The results obtained
were in the 90 % range for accuracy, precision, and recall evaluation metrics.
From their decision paths, the proposed solution estimates the CO2 emissions
associated with bank transactions. The explainability methodology is based on
an agnostic evaluation of the influence of the input terms extracted from the
descriptions of transactions using locally interpretable models. The
explainability terms were automatically validated using a similarity metric
over the descriptions of the target categories. Conclusively, the explanation
performance is satisfactory in terms of the proximity of the explanations to
the associated activity sector descriptions.",2024-05-23,"Jaime González-González, Silvia García-Méndez, Francisco de Arriba-Pérez, Francisco J. González-Castaño, Óscar Barba-Seara",http://arxiv.org/pdf/2405.14505v1,cs.CL
Impact of Non-Standard Unicode Characters on Security and Comprehension in Large Language Models,"The advancement of large language models has significantly improved natural
language processing. However, challenges such as jailbreaks (prompt injections
that cause an LLM to follow instructions contrary to its intended use),
hallucinations (generating incorrect or misleading information), and
comprehension errors remain prevalent. In this report, we present a comparative
analysis of the performance of fifteen distinct models, with each model
undergoing a standardized test comprising 38 queries across three key metrics:
jailbreaks, hallucinations, and comprehension errors. The models are assessed
based on the total occurrences of jailbreaks, hallucinations, and comprehension
errors. Our work exposes these models' inherent vulnerabilities and challenges
the notion of human-level language comprehension of these models. We have
empirically analysed the impact of non-standard Unicode characters on LLMs and
their safeguarding mechanisms on the best-performing LLMs, including GPT-4,
Gemini 1.5 Pro, LlaMA-3-70B, and Claude 3 Opus. By incorporating alphanumeric
symbols from Unicode outside the standard Latin block and variants of
characters in other languages, we observed a reduction in the efficacy of
guardrails implemented through Reinforcement Learning Human Feedback (RLHF).
Consequently, these models exhibit heightened vulnerability to content policy
breaches and prompt leakage. Our study also suggests a need to incorporate
non-standard Unicode text in LLM training data to enhance the capabilities of
these models.",2024-05-23,"Johan S Daniel, Anand Pal",http://arxiv.org/pdf/2405.14490v1,cs.CL
MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability,"Large Language Models (LLMs) are increasingly deployed in various
applications. As their usage grows, concerns regarding their safety are rising,
especially in maintaining harmless responses when faced with malicious
instructions. Many defense strategies have been developed to enhance the safety
of LLMs. However, our research finds that existing defense strategies lead LLMs
to predominantly adopt a rejection-oriented stance, thereby diminishing the
usability of their responses to benign instructions. To solve this problem, we
introduce the MoGU framework, designed to enhance LLMs' safety while preserving
their usability. Our MoGU framework transforms the base LLM into two variants:
the usable LLM and the safe LLM, and further employs dynamic routing to balance
their contribution. When encountering malicious instructions, the router will
assign a higher weight to the safe LLM to ensure that responses are harmless.
Conversely, for benign instructions, the router prioritizes the usable LLM,
facilitating usable and helpful responses. On various open-sourced LLMs, we
compare multiple defense strategies to verify the superiority of our MoGU
framework. Besides, our analysis provides key insights into the effectiveness
of MoGU and verifies that our designed routing mechanism can effectively
balance the contribution of each variant by assigning weights. Our work
released the safer Llama2, Vicuna, Falcon, Dolphin, and Baichuan2.",2024-05-23,"Yanrui Du, Sendong Zhao, Danyang Zhao, Ming Ma, Yuhan Chen, Liangyu Huo, Qing Yang, Dongliang Xu, Bing Qin",http://arxiv.org/pdf/2405.14488v1,cs.CL
RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models,"Large Language Models (LLMs) have shown impressive capabilities but also a
concerning tendency to hallucinate. This paper presents RefChecker, a framework
that introduces claim-triplets to represent claims in LLM responses, aiming to
detect fine-grained hallucinations. In RefChecker, an extractor generates
claim-triplets from a response, which are then evaluated by a checker against a
reference. We delineate three task settings: Zero, Noisy and Accurate Context,
to reflect various real-world use cases. We curated a benchmark spanning
various NLP tasks and annotated 11k claim-triplets from 2.1k responses by seven
LLMs. RefChecker supports both proprietary and open-source models as the
extractor and checker. Experiments demonstrate that claim-triplets enable
superior hallucination detection, compared to other granularities such as
response, sentence and sub-sentence level claims. RefChecker outperforms prior
methods by 6.8 to 26.1 points on our benchmark and the checking results of
RefChecker are strongly aligned with human judgments. This work is open sourced
at https://github.com/amazon-science/RefChecker",2024-05-23,"Xiangkun Hu, Dongyu Ru, Lin Qiu, Qipeng Guo, Tianhang Zhang, Yang Xu, Yun Luo, Pengfei Liu, Yue Zhang, Zheng Zhang",http://arxiv.org/pdf/2405.14486v1,cs.CL
Which Information Matters? Dissecting Human-written Multi-document Summaries with Partial Information Decomposition,"Understanding the nature of high-quality summaries is crucial to further
improve the performance of multi-document summarization. We propose an approach
to characterize human-written summaries using partial information
decomposition, which decomposes the mutual information provided by all source
documents into union, redundancy, synergy, and unique information. Our
empirical analysis on different MDS datasets shows that there is a direct
dependency between the number of sources and their contribution to the summary.",2024-05-23,"Laura Mascarell, Yan L'Homme, Majed El Helou",http://arxiv.org/pdf/2405.14470v1,cs.CL
Worldwide Federated Training of Language Models,"The reliance of language model training on massive amounts of computation and
vast datasets scraped from potentially low-quality, copyrighted, or sensitive
data has come into question practically, legally, and ethically. Federated
learning provides a plausible alternative by enabling previously untapped data
to be voluntarily gathered from collaborating organizations. However, when
scaled globally, federated learning requires collaboration across heterogeneous
legal, security, and privacy regimes while accounting for the inherent locality
of language data; this further exacerbates the established challenge of
federated statistical heterogeneity. We propose a Worldwide Federated Language
Model Training~(WorldLM) system based on federations of federations, where each
federation has the autonomy to account for factors such as its industry,
operating jurisdiction, or competitive environment. WorldLM enables such
autonomy in the presence of statistical heterogeneity via partial model
localization by allowing sub-federations to attentively aggregate key layers
from their constituents. Furthermore, it can adaptively share information
across federations via residual layer embeddings. Evaluations of language
modeling on naturally heterogeneous datasets show that WorldLM outperforms
standard federations by up to $1.91\times$, approaches the personalized
performance of fully local models, and maintains these advantages under
privacy-enhancing techniques.",2024-05-23,"Alex Iacob, Lorenzo Sani, Bill Marino, Preslav Aleksandrov, William F. Shen, Nicholas Donald Lane",http://arxiv.org/pdf/2405.14446v2,cs.CL
Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study,"This paper describes a rapid feasibility study of using GPT-4, a large
language model (LLM), to (semi)automate data extraction in systematic reviews.
Despite the recent surge of interest in LLMs there is still a lack of
understanding of how to design LLM-based automation tools and how to robustly
evaluate their performance. During the 2023 Evidence Synthesis Hackathon we
conducted two feasibility studies. Firstly, to automatically extract study
characteristics from human clinical, animal, and social science domain studies.
We used two studies from each category for prompt-development; and ten for
evaluation. Secondly, we used the LLM to predict Participants, Interventions,
Controls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP
dataset. Overall, results indicated an accuracy of around 80%, with some
variability between domains (82% for human clinical, 80% for animal, and 72%
for studies of human social sciences). Causal inference methods and study
design were the data extraction items with the most errors. In the PICO study,
participants and intervention/control showed high accuracy (>80%), outcomes
were more challenging. Evaluation was done manually; scoring methods such as
BLEU and ROUGE showed limited value. We observed variability in the LLMs
predictions and changes in response quality. This paper presents a template for
future evaluations of LLMs in the context of data extraction for systematic
review automation. Our results show that there might be value in using LLMs,
for example as second or third reviewers. However, caution is advised when
integrating models such as GPT-4 into tools. Further research on stability and
reliability in practical settings is warranted for each type of data that is
processed by the LLM.",2024-05-23,"Lena Schmidt, Kaitlyn Hair, Sergio Graziosi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, James Thomas",http://arxiv.org/pdf/2405.14445v2,cs.CL
Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models,"Recently, using large pretrained Transformer models for transfer learning
tasks has evolved to the point where they have become one of the flagship
trends in the Natural Language Processing (NLP) community, giving rise to
various outlooks such as prompt-based, adapters or combinations with
unsupervised approaches, among many others. This work proposes a 3 Phase
technique to adjust a base model for a classification task. First, we adapt the
model's signal to the data distribution by performing further training with a
Denoising Autoencoder (DAE). Second, we adjust the representation space of the
output to the corresponding classes by clustering through a Contrastive
Learning (CL) method. In addition, we introduce a new data augmentation
approach for Supervised Contrastive Learning to correct the unbalanced
datasets. Third, we apply fine-tuning to delimit the predefined categories.
These different phases provide relevant and complementary knowledge to the
model to learn the final task. We supply extensive experimental results on
several datasets to demonstrate these claims. Moreover, we include an ablation
study and compare the proposed method against other ways of combining these
techniques.",2024-05-23,"Alejo Lopez-Avila, Víctor Suárez-Paniagua",http://arxiv.org/pdf/2405.14437v1,cs.CL
RaFe: Ranking Feedback Improves Query Rewriting for RAG,"As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG)
techniques have evolved, query rewriting has been widely incorporated into the
RAG system for downstream tasks like open-domain QA. Many works have attempted
to utilize small models with reinforcement learning rather than costly LLMs to
improve query rewriting. However, current methods require annotations (e.g.,
labeled relevant documents or downstream answers) or predesigned rewards for
feedback, which lack generalization, and fail to utilize signals tailored for
query rewriting. In this paper, we propose ours, a framework for training query
rewriting models free of annotations. By leveraging a publicly available
reranker, ours~provides feedback aligned well with the rewriting objectives.
Experimental results demonstrate that ours~can obtain better performance than
baselines.",2024-05-23,"Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang",http://arxiv.org/pdf/2405.14431v1,cs.CL
Mitigating Quantization Errors Due to Activation Spikes in GLU-Based LLMs,"Modern large language models (LLMs) have established state-of-the-art
performance through architectural improvements, but still require significant
computational cost for inference. In an effort to reduce the inference cost,
post-training quantization (PTQ) has become a popular approach, quantizing
weights and activations to lower precision, such as INT8. In this paper, we
reveal the challenges of activation quantization in GLU variants, which are
widely used in feed-forward network (FFN) of modern LLMs, such as LLaMA family.
The problem is that severe local quantization errors, caused by excessive
magnitudes of activation in GLU variants, significantly degrade the performance
of the quantized LLM. We denote these activations as activation spikes. Our
further observations provide a systematic pattern of activation spikes: 1) The
activation spikes occur in the FFN of specific layers, particularly in the
early and late layers, 2) The activation spikes are dedicated to a couple of
tokens, rather than being shared across a sequence. Based on our observations,
we propose two empirical methods, Quantization-free Module (QFeM) and
Quantization-free Prefix (QFeP), to isolate the activation spikes during
quantization. Our extensive experiments validate the effectiveness of the
proposed methods for the activation quantization, especially with
coarse-grained scheme, of latest LLMs with GLU variants, including LLaMA-2/3,
Mistral, Mixtral, SOLAR, and Gemma. In particular, our methods enhance the
current alleviation techniques (e.g., SmoothQuant) that fail to control the
activation spikes. Code is available at
https://github.com/onnoo/activation-spikes.",2024-05-23,"Jaewoo Yang, Hayun Kim, Younghoon Kim",http://arxiv.org/pdf/2405.14428v1,cs.CL
Instruction Tuning With Loss Over Instructions,"Instruction tuning plays a crucial role in shaping the outputs of language
models (LMs) to desired styles. In this work, we propose a simple yet effective
method, Instruction Modelling (IM), which trains LMs by applying a loss
function to the instruction and prompt part rather than solely to the output
part. Through experiments across 21 diverse benchmarks, we show that, in many
scenarios, IM can effectively improve the LM performance on both NLP tasks
(e.g., MMLU, TruthfulQA, and HumanEval) and open-ended generation benchmarks
(e.g., MT-Bench and AlpacaEval). Remarkably, in the most advantageous case, IM
boosts model performance on AlpacaEval 1.0 by over 100%. We identify two key
factors influencing the effectiveness of IM: (1) The ratio between instruction
length and output length in the training data; and (2) The number of training
examples. We observe that IM is especially beneficial when trained on datasets
with lengthy instructions paired with brief outputs, or under the Superficial
Alignment Hypothesis (SAH) where a small amount of training examples are used
for instruction tuning. Further analysis substantiates our hypothesis that our
improvement can be attributed to reduced overfitting to instruction tuning
datasets. It is worth noting that we are not proposing \ours as a replacement
for current fine-tuning processes. Instead, our work aims to provide practical
guidance for instruction tuning LMs, especially in low-resource scenarios.",2024-05-23,"Zhengyan Shi, Adam X. Yang, Bin Wu, Laurence Aitchison, Emine Yilmaz, Aldo Lipani",http://arxiv.org/pdf/2405.14394v2,cs.CL
Explainable Few-shot Knowledge Tracing,"Knowledge tracing (KT), aiming to mine students' mastery of knowledge by
their exercise records and predict their performance on future test questions,
is a critical task in educational assessment. While researchers achieved
tremendous success with the rapid development of deep learning techniques,
current knowledge tracing tasks fall into the cracks from real-world teaching
scenarios. Relying heavily on extensive student data and solely predicting
numerical performances differs from the settings where teachers assess
students' knowledge state from limited practices and provide explanatory
feedback. To fill this gap, we explore a new task formulation: Explainable
Few-shot Knowledge Tracing. By leveraging the powerful reasoning and generation
abilities of large language models (LLMs), we then propose a cognition-guided
framework that can track the student knowledge from a few student records while
providing natural language explanations. Experimental results from three widely
used datasets show that LLMs can perform comparable or superior to competitive
deep knowledge tracing methods. We also discuss potential directions and call
for future improvements in relevant topics.",2024-05-23,"Haoxuan Li, Jifan Yu, Yuanxin Ouyang, Zhuang Liu, Wenge Rong, Juanzi Li, Zhang Xiong",http://arxiv.org/pdf/2405.14391v2,cs.CL
Evaluation of the Programming Skills of Large Language Models,"The advent of Large Language Models (LLM) has revolutionized the efficiency
and speed with which tasks are completed, marking a significant leap in
productivity through technological innovation. As these chatbots tackle
increasingly complex tasks, the challenge of assessing the quality of their
outputs has become paramount. This paper critically examines the output quality
of two leading LLMs, OpenAI's ChatGPT and Google's Gemini AI, by comparing the
quality of programming code generated in both their free versions. Through the
lens of a real-world example coupled with a systematic dataset, we investigate
the code quality produced by these LLMs. Given their notable proficiency in
code generation, this aspect of chatbot capability presents a particularly
compelling area for analysis. Furthermore, the complexity of programming code
often escalates to levels where its verification becomes a formidable task,
underscoring the importance of our study. This research aims to shed light on
the efficacy and reliability of LLMs in generating high-quality programming
code, an endeavor that has significant implications for the field of software
development and beyond.",2024-05-23,"Luc Bryan Heitz, Joun Chamas, Christopher Scherb",http://arxiv.org/pdf/2405.14388v1,cs.CL
Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis,"The objective of this paper is to predict (A) whether a sentence in a written
text expresses an emotion, (B) the mode(s) in which it is expressed, (C)
whether it is basic or complex, and (D) its emotional category.
  One of our major contributions, through a dataset and a model, is to
integrate the fact that an emotion can be expressed in different modes: from a
direct mode, essentially lexicalized, to a more indirect mode, where emotions
will only be suggested, a mode that NLP approaches generally don't take into
account.
  Another originality is that the scope is on written texts, as opposed usual
work focusing on conversational (often multi-modal) data. In this context,
modes of expression are seen as a factor towards the automatic analysis of
complexity in texts.
  Experiments on French texts show acceptable results compared to the human
annotators' agreement, and outperforming results compared to using a large
language model with in-context learning (i.e. no fine-tuning).",2024-05-23,"Aline Étienne, Delphine Battistelli, Gwénolé Lecorvé",http://arxiv.org/pdf/2405.14385v1,cs.CL
Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering,"Large Language Models (LLMs) are widely used for knowledge-seeking yet suffer
from hallucinations. The knowledge boundary (KB) of an LLM limits its factual
understanding, beyond which it may begin to hallucinate. Investigating the
perception of LLMs' KB is crucial for detecting hallucinations and LLMs'
reliable generation. Current studies perceive LLMs' KB on questions with a
concrete answer (close-ended questions) while paying limited attention to
semi-open-ended questions (SoeQ) that correspond to many potential answers.
Some researchers achieve it by judging whether the question is answerable or
not. However, this paradigm is unsuitable for SoeQ, which are usually partially
answerable, containing both answerable and ambiguous (unanswerable) answers.
Ambiguous answers are essential for knowledge-seeking, but they may go beyond
the KB of LLMs. In this paper, we perceive the LLMs' KB with SoeQ by
discovering more ambiguous answers. First, we apply an LLM-based approach to
construct SoeQ and obtain answers from a target LLM. Unfortunately, the output
probabilities of mainstream black-box LLMs are inaccessible to sample for
low-probability ambiguous answers. Therefore, we apply an open-sourced
auxiliary model to explore ambiguous answers for the target LLM. We calculate
the nearest semantic representation for existing answers to estimate their
probabilities, with which we reduce the generation probability of
high-probability answers to achieve a more effective generation. Finally, we
compare the results from the RAG-based evaluation and LLM self-evaluation to
categorize four types of ambiguous answers that are beyond the KB of the target
LLM. Following our method, we construct a dataset to perceive the KB for GPT-4.
We find that GPT-4 performs poorly on SoeQ and is often unaware of its KB.
Besides, our auxiliary model, LLaMA-2-13B, is effective in discovering more
ambiguous answers.",2024-05-23,"Zhihua Wen, Zhiliang Tian, Zexin Jian, Zhen Huang, Pei Ke, Yifu Gao, Minlie Huang, Dongsheng Li",http://arxiv.org/pdf/2405.14383v1,cs.CL
Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?,"The potential for Large Language Models (LLMs) to generate new information
offers a potential step change for research and innovation. This is challenging
to assert as it can be difficult to determine what an LLM has previously seen
during training, making ""newness"" difficult to substantiate. In this paper we
observe that LLMs are able to perform sophisticated reasoning on problems with
a spatial dimension, that they are unlikely to have previously directly
encountered. While not perfect, this points to a significant level of
understanding that state-of-the-art LLMs can now achieve, supporting the
proposition that LLMs are able to yield significant emergent properties. In
particular, Claude 3 is found to perform well in this regard.",2024-05-23,"Thomas Greatrix, Roger Whitaker, Liam Turner, Walter Colombo",http://arxiv.org/pdf/2405.14379v1,cs.CL
BiMix: A Bivariate Data Mixing Law for Language Model Pretraining,"Large language models have demonstrated remarkable capabilities across
various tasks, primarily attributed to the utilization of diversely sourced
data. However, the impact of pretraining data composition on model performance
remains poorly understood. This paper introduces $\textbf{BiMix}$, a novel
bivariate data mixing law that models the joint scaling behavior of domain
proportions and data volume in LLM pretraining. $\textbf{BiMix}$ provides a
systematic framework for understanding and optimizing data mixtures across
diverse domains. Through extensive experiments on two large-scale datasets, we
demonstrate $\textbf{BiMix}$'s high accuracy in loss extrapolation (mean
relative error < 0.2%) and its generalization to unseen mixtures (R${}^{2}$ >
0.97). Optimization of domain proportions yields superior model performance
compared to existing methods. Furthermore, we establish entropy-based measures
as efficient proxies for data mixing, offering a computationally lightweight
strategy. Our work contributes both theoretical insights into data mixing
dynamics and practical tools for enhancing LLM training efficiency, paving the
way for more effective scaling strategies in language model development.",2024-05-23,"Ce Ge, Zhijian Ma, Daoyuan Chen, Yaliang Li, Bolin Ding",http://arxiv.org/pdf/2405.14908v4,cs.CL
MiniCache: KV Cache Compression in Depth Dimension for Large Language Models,"A critical approach for efficiently deploying computationally demanding large
language models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value
states of previously generated tokens, significantly reducing the need for
repetitive computations and thereby lowering latency in autoregressive
generation. However, the size of the KV cache grows linearly with sequence
length, posing challenges for applications requiring long context input and
extensive sequence generation. In this paper, we present a simple yet effective
approach, called MiniCache, to compress the KV cache across layers from a novel
depth perspective, significantly reducing the memory footprint for LLM
inference. Our approach is based on the observation that KV cache states
exhibit high similarity between the adjacent layers in the middle-to-deep
portion of LLMs. To facilitate merging, we propose disentangling the states
into the magnitude and direction components, interpolating the directions of
the state vectors while preserving their lengths unchanged. Furthermore, we
introduce a token retention strategy to keep highly distinct state pairs
unmerged, thus preserving the information with minimal additional storage
overhead. Our MiniCache is training-free and general, complementing existing KV
cache compression strategies, such as quantization and sparsity. We conduct a
comprehensive evaluation of MiniCache utilizing various models including
LLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks,
demonstrating its exceptional performance in achieving superior compression
ratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit
MiniCache achieves a remarkable compression ratio of up to 5.02x, enhances
inference throughput by approximately 5x, and reduces the memory footprint by
41% compared to the FP16 full cache baseline, all while maintaining
near-lossless performance.",2024-05-23,"Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, Bohan Zhuang",http://arxiv.org/pdf/2405.14366v2,cs.CL
JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models,"Mathematical reasoning is an important capability of large language
models~(LLMs) for real-world applications. To enhance this capability, existing
work either collects large-scale math-related texts for pre-training, or relies
on stronger LLMs (\eg GPT-4) to synthesize massive math problems. Both types of
work generally lead to large costs in training or synthesis. To reduce the
cost, based on open-source available texts, we propose an efficient way that
trains a small LLM for math problem synthesis, to efficiently generate
sufficient high-quality pre-training data. To achieve it, we create a dataset
using GPT-4 to distill its data synthesis capability into the small LLM.
Concretely, we craft a set of prompts based on human education stages to guide
GPT-4, to synthesize problems covering diverse math knowledge and difficulty
levels. Besides, we adopt the gradient-based influence estimation method to
select the most valuable math-related texts. The both are fed into GPT-4 for
creating the knowledge distillation dataset to train the small LLM. We leverage
it to synthesize 6 million math problems for pre-training our JiuZhang3.0
model, which only needs to invoke GPT-4 API 9.3k times and pre-train on 4.6B
data. Experimental results have shown that JiuZhang3.0 achieves
state-of-the-art performance on several mathematical reasoning datasets, under
both natural language reasoning and tool manipulation settings. Our code and
data will be publicly released in
\url{https://github.com/RUCAIBox/JiuZhang3.0}.",2024-05-23,"Kun Zhou, Beichen Zhang, Jiapeng Wang, Zhipeng Chen, Wayne Xin Zhao, Jing Sha, Zhichao Sheng, Shijin Wang, Ji-Rong Wen",http://arxiv.org/pdf/2405.14365v1,cs.CL
Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration,"Grounding the reasoning ability of large language models (LLMs) for embodied
tasks is challenging due to the complexity of the physical world. Especially,
LLM planning for multi-agent collaboration requires communication of agents or
credit assignment as the feedback to re-adjust the proposed plans and achieve
effective coordination. However, existing methods that overly rely on physical
verification or self-reflection suffer from excessive and inefficient querying
of LLMs. In this paper, we propose a novel framework for multi-agent
collaboration that introduces Reinforced Advantage feedback (ReAd) for
efficient self-refinement of plans. Specifically, we perform critic regression
to learn a sequential advantage function from LLM-planned data, and then treat
the LLM planner as an optimizer to generate actions that maximize the advantage
function. It endows the LLM with the foresight to discern whether the action
contributes to accomplishing the final task. We provide theoretical analysis by
extending advantage-weighted regression in reinforcement learning to
multi-agent systems. Experiments on Overcooked-AI and a difficult variant of
RoCoBench show that ReAd surpasses baselines in success rate, and also
significantly decreases the interaction steps of agents and query rounds of
LLMs, demonstrating its high efficiency for grounding LLMs. More results are
given at https://read-llm.github.io/.",2024-05-23,"Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Zhen Wang, Xuelong Li",http://arxiv.org/pdf/2405.14314v2,cs.CL
Improving Gloss-free Sign Language Translation by Reducing Representation Density,"Gloss-free sign language translation (SLT) aims to develop well-performing
SLT systems with no requirement for the costly gloss annotations, but currently
still lags behind gloss-based approaches significantly. In this paper, we
identify a representation density problem that could be a bottleneck in
restricting the performance of gloss-free SLT. Specifically, the representation
density problem describes that the visual representations of semantically
distinct sign gestures tend to be closely packed together in feature space,
which makes gloss-free methods struggle with distinguishing different sign
gestures and suffer from a sharp performance drop. To address the
representation density problem, we introduce a simple but effective contrastive
learning strategy, namely SignCL, which encourages gloss-free models to learn
more discriminative feature representation in a self-supervised manner. Our
experiments demonstrate that the proposed SignCL can significantly reduce the
representation density and improve performance across various translation
frameworks. Specifically, SignCL achieves a significant improvement in BLEU
score for the Sign Language Transformer and GFSLT-VLP on the CSL-Daily dataset
by 39% and 46%, respectively, without any increase of model parameters.
Compared to Sign2GPT, a state-of-the-art method based on large-scale
pre-trained vision and language models, SignCL achieves better performance with
only 35% of its parameters. Implementation and Checkpoints are available at
https://github.com/JinhuiYE/SignCL.",2024-05-23,"Jinhui Ye, Xing Wang, Wenxiang Jiao, Junwei Liang, Hui Xiong",http://arxiv.org/pdf/2405.14312v2,cs.CL
Improving Language Models Trained on Translated Data with Continual Pre-Training and Dictionary Learning Analysis,"Training LLMs for low-resource languages usually utilizes data augmentation
from English using machine translation (MT). This, however, brings a number of
challenges to LLM training: there are large costs attached to translating and
curating huge amounts of content with high-end machine translation solutions;
the translated content carries over cultural biases; and if the translation is
not faithful and accurate, data quality degrades causing issues in the trained
model. In this work, we investigate the role of translation and synthetic data
in training language models. We translate TinyStories, a dataset of 2.2M short
stories for 3-4 year old children, from English to Arabic using the open
NLLB-3B MT model. We train a number of story generation models of size 1M-33M
parameters using this data. We identify a number of quality and task-specific
issues in the resulting models. To rectify these issues, we further pre-train
the models with a small dataset of synthesized high-quality Arabic stories
generated by a capable LLM, representing 1% of the original training data. We
show, using GPT-4 as a judge and Dictionary Learning Analysis from mechanistic
interpretability, that the suggested approach is a practical means to resolve
some of the machine translation pitfalls. We illustrate the improvements
through case studies of linguistic and cultural bias issues.",2024-05-23,"Sabri Boughorbel, MD Rizwan Parvez, Majd Hawasly",http://arxiv.org/pdf/2405.14277v2,cs.CL
Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Multi-modal Text Recognition,"We introduce ""Generative Fusion Decoding"" (GFD), a novel shallow fusion
framework, utilized to integrate Large Language Models (LLMs) into multi-modal
text recognition systems such as automatic speech recognition (ASR) and optical
character recognition (OCR). We derive the formulas necessary to enable GFD to
operate across mismatched token spaces of different models by mapping text
token space to byte token space, enabling seamless fusion during the decoding
process. The framework is plug-and-play, compatible with various
auto-regressive models, and does not require re-training for feature alignment,
thus overcoming limitations of previous fusion techniques. We highlight three
main advantages of GFD: First, by simplifying the complexity of aligning
different model sample spaces, GFD allows LLMs to correct errors in tandem with
the recognition model, reducing computation latencies. Second, the in-context
learning ability of LLMs is fully capitalized by GFD, increasing robustness in
long-form speech recognition and instruction aware speech recognition. Third,
GFD enables fusing recognition models deficient in Chinese text recognition
with LLMs extensively trained on Chinese. Our evaluation demonstrates that GFD
significantly improves performance in ASR and OCR tasks, with ASR reaching
state-of-the-art in the NTUML2021 benchmark. GFD provides a significant step
forward in model integration, offering a unified solution that could be widely
applicable to leveraging existing pre-trained models through step by step
fusion.",2024-05-23,"Chan-Jan Hsu, Yi-Chang Chen, Feng-Ting Liao, Pei-Chen Ho, Yu-Hsiang Wang, Po-Chun Hsu, Da-shan Shiu",http://arxiv.org/pdf/2405.14259v3,cs.CL
Text-Based Correlation Matrix in Multi-Asset Allocation,"The purpose of this study is to estimate the correlation structure between
multiple assets using financial text analysis. In recent years, as the
background of elevating inflation in the global economy and monetary policy
tightening by central banks, the correlation structure between assets,
especially interest rate sensitivity and inflation sensitivity, has changed
dramatically, increasing the impact on the performance of investors'
portfolios. Therefore, the importance of estimating a robust correlation
structure in portfolio management has increased. On the other hand, the
correlation coefficient using only the historical price data observed in the
financial market is accompanied by a certain degree of time lag, and also has
the aspect that prediction errors can occur due to the nonstationarity of
financial time series data, and that the interpretability from the viewpoint of
fundamentals is a little poor when a phase change occurs. In this study, we
performed natural language processing on news text and central bank text to
verify the prediction accuracy of future correlation coefficient changes. As a
result, it was suggested that this method is useful in comparison with the
prediction from ordinary time series data.",2024-05-23,"Yasuhiro Nakayama, Tomochika Sawaki, Issei Furuya, Shunsuke Tamura",http://arxiv.org/pdf/2405.14247v1,cs.CL
EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records,"In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL
dataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to
address critical yet underexplored aspects in text-to-SQL parsing:
interactivity, compositionality, and efficiency. To the best of our knowledge,
EHR-SeqSQL is not only the largest but also the first medical text-to-SQL
dataset benchmark to include sequential and contextual questions. We provide a
data split and the new test set designed to assess compositional generalization
ability. Our experiments demonstrate the superiority of a multi-turn approach
over a single-turn approach in learning compositionality. Additionally, our
dataset integrates specially crafted tokens into SQL queries to improve
execution efficiency. With EHR-SeqSQL, we aim to bridge the gap between
practical needs and academic research in the text-to-SQL domain. EHR-SeqSQL is
available at https://github.com/seonhee99/EHR-SeqSQL.",2024-05-23,"Jaehee Ryu, Seonhee Cho, Gyubok Lee, Edward Choi",http://arxiv.org/pdf/2406.00019v3,cs.CL
Language processing in humans and computers,"Machine-learned language models have transformed everyday life: they steer us
when we study, drive, manage money. They have the potential to transform our
civilization. But they hallucinate. Their realities are virtual. This note
provides a high-level overview of language models and outlines a low-level
model of learning machines. It turns out that, after they become capable of
recognizing hallucinations and dreaming safely, as humans tend to be, the
language-learning machines proceed to generate broader systems of false beliefs
and self-confirming theories, as humans tend to do.",2024-05-23,Dusko Pavlovic,http://arxiv.org/pdf/2405.14233v1,cs.CL
From Role-Play to Drama-Interaction: An LLM Solution,"Drama is a form of storytelling inspired by human creativity, proceeding with
a predefined storyline, carrying emotions and thoughts. This paper introduces
\emph{LLM-based interactive drama}, which endows traditional drama with an
unprecedented immersion, where a person is allowed to walk into it and interact
with the characters and scenes. We define this new artistic genre by 6
essential elements-plot, character, thought, diction, spectacle and
interaction-and study the entire pipeline to forge a backbone \emph{drama LLM}
to drive the playing process, which is challenged by limited drama resources,
uncontrollable narrative development, and complicated instruction following. We
propose \emph{Narrative Chain} to offer finer control over the narrative
progression during interaction with players; \emph{Auto-Drama} to synthesize
drama scripts given arbitrary stories; \emph{Sparse Instruction Tuning} to
allow the model to follow sophisticated instructions. We manually craft 3
scripts, \emph{Detective Conan}, \emph{Harry Potter}, \emph{Romeo and Juliet},
and design a 5-dimension principle to evaluate the drama LLM comprehensively.",2024-05-23,"Weiqi Wu, Hongqiu Wu, Lai Jiang, Xingyuan Liu, Jiale Hong, Hai Zhao, Min Zhang",http://arxiv.org/pdf/2405.14231v1,cs.CL
Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports,"The absence of adequately sufficient expert-level tumor annotations hinders
the effectiveness of supervised learning based opportunistic cancer screening
on medical imaging. Clinical reports (that are rich in descriptive textual
details) can offer a ""free lunch'' supervision information and provide tumor
location as a type of weak label to cope with screening tasks, thus saving
human labeling workloads, if properly leveraged. However, predicting cancer
only using such weak labels can be very changeling since tumors are usually
presented in small anatomical regions compared to the whole 3D medical scans.
Weakly semi-supervised learning (WSSL) utilizes a limited set of voxel-level
tumor annotations and incorporates alongside a substantial number of medical
images that have only off-the-shelf clinical reports, which may strike a good
balance between minimizing expert annotation workload and optimizing screening
efficacy. In this paper, we propose a novel text-guided learning method to
achieve highly accurate cancer detection results. Through integrating
diagnostic and tumor location text prompts into the text encoder of a
vision-language model (VLM), optimization of weakly supervised learning can be
effectively performed in the latent space of VLM, thereby enhancing the
stability of training. Our approach can leverage clinical knowledge by
large-scale pre-trained VLM to enhance generalization ability, and produce
reliable pseudo tumor masks to improve cancer detection. Our extensive
quantitative experimental results on a large-scale cancer dataset, including
1,651 unique patients, validate that our approach can reduce human annotation
efforts by at least 70% while maintaining comparable cancer detection accuracy
to competing fully supervised methods (AUC value 0.961 versus 0.966).",2024-05-23,"Guangyu Guo, Jiawen Yao, Yingda Xia, Tony C. W. Mok, Zhilin Zheng, Junwei Han, Le Lu, Dingwen Zhang, Jian Zhou, Ling Zhang",http://arxiv.org/pdf/2405.14230v1,cs.CL
"ReactXT: Understanding Molecular ""Reaction-ship"" via Reaction-Contextualized Molecule-Text Pretraining","Molecule-text modeling, which aims to facilitate molecule-relevant tasks with
a textual interface and textual knowledge, is an emerging research direction.
Beyond single molecules, studying reaction-text modeling holds promise for
helping the synthesis of new materials and drugs. However, previous works
mostly neglect reaction-text modeling: they primarily focus on modeling
individual molecule-text pairs or learning chemical reactions without texts in
context. Additionally, one key task of reaction-text modeling -- experimental
procedure prediction -- is less explored due to the absence of an open-source
dataset. The task is to predict step-by-step actions of conducting chemical
experiments and is crucial to automating chemical synthesis. To resolve the
challenges above, we propose a new pretraining method, ReactXT, for
reaction-text modeling, and a new dataset, OpenExp, for experimental procedure
prediction. Specifically, ReactXT features three types of input contexts to
incrementally pretrain LMs. Each of the three input contexts corresponds to a
pretraining task to improve the text-based understanding of either reactions or
single molecules. ReactXT demonstrates consistent improvements in experimental
procedure prediction and molecule captioning and offers competitive results in
retrosynthesis. Our code is available at https://github.com/syr-cn/ReactXT.",2024-05-23,"Zhiyuan Liu, Yaorui Shi, An Zhang, Sihang Li, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua",http://arxiv.org/pdf/2405.14225v1,cs.CL
Large Language Models' Detection of Political Orientation in Newspapers,"Democratic opinion-forming may be manipulated if newspapers' alignment to
political or economical orientation is ambiguous. Various methods have been
developed to better understand newspapers' positioning. Recently, the advent of
Large Language Models (LLM), and particularly the pre-trained LLM chatbots like
ChatGPT or Gemini, hold disruptive potential to assist researchers and citizens
alike. However, little is know on whether LLM assessment is trustworthy: do
single LLM agrees with experts' assessment, and do different LLMs answer
consistently with one another? In this paper, we address specifically the
second challenge. We compare how four widely employed LLMs rate the positioning
of newspapers, and compare if their answers align with one another. We observe
that this is not the case. Over a woldwide dataset, articles in newspapers are
positioned strikingly differently by single LLMs, hinting to inconsistent
training or excessive randomness in the algorithms. We thus raise a warning
when deciding which tools to use, and we call for better training and algorithm
development, to cover such significant gap in a highly sensitive matter for
democracy and societies worldwide. We also call for community engagement in
benchmark evaluation, through our open initiative navai.pro.",2024-05-23,"Alessio Buscemi, Daniele Proverbio",http://arxiv.org/pdf/2406.00018v1,cs.CL
From Text to Pixel: Advancing Long-Context Understanding in MLLMs,"The rapid progress in Multimodal Large Language Models (MLLMs) has
significantly advanced their ability to process and understand complex visual
and textual information. However, the integration of multiple images and
extensive textual contexts remains a challenge due to the inherent limitation
of the models' capacity to handle long input sequences efficiently. In this
paper, we introduce SEEKER, a multimodal large language model designed to
tackle this issue. SEEKER aims to optimize the compact encoding of long text by
compressing the text sequence into the visual pixel space via images, enabling
the model to handle long text within a fixed token-length budget efficiently.
Our empirical experiments on six long-context multimodal tasks demonstrate that
SEEKER can leverage fewer image tokens to convey the same amount of textual
information compared with the OCR-based approach, and is more efficient in
understanding long-form multimodal input and generating long-form textual
output, outperforming all existing proprietary and open-source MLLMs by large
margins.",2024-05-23,"Yujie Lu, Xiujun Li, Tsu-Jui Fu, Miguel Eckstein, William Yang Wang",http://arxiv.org/pdf/2405.14213v2,cs.CL
Federated Domain-Specific Knowledge Transfer on Large Language Models Using Synthetic Data,"As large language models (LLMs) demonstrate unparalleled performance and
generalization ability, LLMs are widely used and integrated into various
applications. When it comes to sensitive domains, as commonly described in
federated learning scenarios, directly using external LLMs on private data is
strictly prohibited by stringent data security and privacy regulations. For
local clients, the utilization of LLMs to improve the domain-specific small
language models (SLMs), characterized by limited computational resources and
domain-specific data, has attracted considerable research attention. By
observing that LLMs can empower domain-specific SLMs, existing methods
predominantly concentrate on leveraging the public data or LLMs to generate
more data to transfer knowledge from LLMs to SLMs. However, due to the
discrepancies between LLMs' generated data and clients' domain-specific data,
these methods cannot yield substantial improvements in the domain-specific
tasks. In this paper, we introduce a Federated Domain-specific Knowledge
Transfer (FDKT) framework, which enables domain-specific knowledge transfer
from LLMs to SLMs while preserving clients' data privacy. The core insight is
to leverage LLMs to augment data based on domain-specific few-shot
demonstrations, which are synthesized from private domain data using
differential privacy. Such synthetic samples share similar data distribution
with clients' private data and allow the server LLM to generate particular
knowledge to improve clients' SLMs. The extensive experimental results
demonstrate that the proposed FDKT framework consistently and greatly improves
SLMs' task performance by around 5\% with a privacy budget of less than 10,
compared to local training on private data.",2024-05-23,"Haoran Li, Xinyuan Zhao, Dadi Guo, Hanlin Gu, Ziqian Zeng, Yuxing Han, Yangqiu Song, Lixin Fan, Qiang Yang",http://arxiv.org/pdf/2405.14212v1,cs.CL
ChronosLex: Time-aware Incremental Training for Temporal Generalization of Legal Classification Tasks,"This study investigates the challenges posed by the dynamic nature of legal
multi-label text classification tasks, where legal concepts evolve over time.
Existing models often overlook the temporal dimension in their training
process, leading to suboptimal performance of those models over time, as they
treat training data as a single homogeneous block. To address this, we
introduce ChronosLex, an incremental training paradigm that trains models on
chronological splits, preserving the temporal order of the data. However, this
incremental approach raises concerns about overfitting to recent data,
prompting an assessment of mitigation strategies using continual learning and
temporal invariant methods. Our experimental results over six legal multi-label
text classification datasets reveal that continual learning methods prove
effective in preventing overfitting thereby enhancing temporal
generalizability, while temporal invariant methods struggle to capture these
dynamics of temporal shifts.",2024-05-23,"T. Y. S. S Santosh, Tuan-Quang Vuong, Matthias Grabmair",http://arxiv.org/pdf/2405.14211v1,cs.CL
Agent Planning with World Knowledge Model,"Recent endeavors towards directly using large language models (LLMs) as agent
models to execute interactive planning tasks have shown commendable results.
Despite their achievements, however, they still struggle with brainless
trial-and-error in global planning and generating hallucinatory actions in
local planning due to their poor understanding of the ``real'' physical world.
Imitating humans' mental world knowledge model which provides global prior
knowledge before the task and maintains local dynamic knowledge during the
task, in this paper, we introduce parametric World Knowledge Model (WKM) to
facilitate agent planning. Concretely, we steer the agent model to
self-synthesize knowledge from both expert and sampled trajectories. Then we
develop WKM, providing prior task knowledge to guide the global planning and
dynamic state knowledge to assist the local planning. Experimental results on
three complex real-world simulated datasets with three state-of-the-art
open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our
method can achieve superior performance compared to various strong baselines.
Besides, we analyze to illustrate that our WKM can effectively alleviate the
blind trial-and-error and hallucinatory action issues, providing strong support
for the agent's understanding of the world. Other interesting findings include:
1) our instance-level task knowledge can generalize better to unseen tasks, 2)
weak WKM can guide strong agent model planning, and 3) unified WKM training has
promising potential for further development. The code is available at
https://github.com/zjunlp/WKM.",2024-05-23,"Shuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu, Xiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",http://arxiv.org/pdf/2405.14205v4,cs.CL
S-Eval: Towards Automated and Comprehensive Safety Evaluation for Large Language Models,"Generative large language models (LLMs) have revolutionized natural language
processing with their transformative and emergent capabilities. However, recent
evidence indicates that LLMs can produce harmful content that violates social
norms, raising significant concerns regarding the safety and ethical
ramifications of deploying these advanced models. Thus, it is both critical and
imperative to perform a rigorous and comprehensive safety evaluation of LLMs
before deployment. Despite this need, owing to the extensiveness of LLM
generation space, it still lacks a unified and standardized risk taxonomy to
systematically reflect the LLM content safety, as well as automated safety
assessment techniques to explore the potential risk efficiently.
  To bridge the striking gap, we propose S-Eval, a novel LLM-based automated
Safety Evaluation framework with a newly defined comprehensive risk taxonomy.
S-Eval incorporates two key components, i.e., an expert testing LLM ${M}_t$ and
a novel safety critique LLM ${M}_c$. ${M}_t$ is responsible for automatically
generating test cases in accordance with the proposed risk taxonomy. ${M}_c$
can provide quantitative and explainable safety evaluations for better risk
awareness of LLMs. In contrast to prior works, S-Eval is efficient and
effective in test generation and safety evaluation. Moreover, S-Eval can be
flexibly configured and adapted to the rapid evolution of LLMs and accompanying
new safety threats, test generation methods and safety critique methods thanks
to the LLM-based architecture. S-Eval has been deployed in our industrial
partner for the automated safety evaluation of multiple LLMs serving millions
of users, demonstrating its effectiveness in real-world scenarios. Our
benchmark is publicly available at https://github.com/IS2Lab/S-Eval.",2024-05-23,"Xiaohan Yuan, Jinfeng Li, Dongxia Wang, Yuefeng Chen, Xiaofeng Mao, Longtao Huang, Jialuo Chen, Hui Xue, Xiaoxia Liu, Wenhai Wang, Kui Ren, Jingyi Wang",http://arxiv.org/pdf/2405.14191v4,cs.CL
Semantic-guided Prompt Organization for Universal Goal Hijacking against LLMs,"With the rising popularity of Large Language Models (LLMs), assessing their
trustworthiness through security tasks has gained critical importance.
Regarding the new task of universal goal hijacking, previous efforts have
concentrated solely on optimization algorithms, overlooking the crucial role of
the prompt. To fill this gap, we propose a universal goal hijacking method
called POUGH that incorporates semantic-guided prompt processing strategies.
Specifically, the method starts with a sampling strategy to select
representative prompts from a candidate pool, followed by a ranking strategy
that prioritizes the prompts. Once the prompts are organized sequentially, the
method employs an iterative optimization algorithm to generate the universal
fixed suffix for the prompts. Experiments conducted on four popular LLMs and
ten types of target responses verified the effectiveness of our method.",2024-05-23,"Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix Juefei-Xu, Jian Zhang, Geguang Pu, Yang Liu",http://arxiv.org/pdf/2405.14189v1,cs.CL
UzMorphAnalyser: A Morphological Analysis Model for the Uzbek Language Using Inflectional Endings,"As Uzbek language is agglutinative, has many morphological features which
words formed by combining root and affixes. Affixes play an important role in
the morphological analysis of words, by adding additional meanings and
grammatical functions to words. Inflectional endings are utilized to express
various morphological features within the language. This feature introduces
numerous possibilities for word endings, thereby significantly expanding the
word vocabulary and exacerbating issues related to data sparsity in statistical
models. This paper present modeling of the morphological analysis of Uzbek
words, including stemming, lemmatizing, and the extraction of morphological
information while considering morpho-phonetic exceptions. Main steps of the
model involve developing a complete set of word-ending with assigned
morphological information, and additional datasets for morphological analysis.
The proposed model was evaluated using a curated test set comprising 5.3K
words. Through manual verification of stemming, lemmatizing, and morphological
feature corrections carried out by linguistic specialists, it obtained a
word-level accuracy of over 91%. The developed tool based on the proposed model
is available as a web-based application and an open-source Python library.",2024-05-23,Ulugbek Salaev,http://arxiv.org/pdf/2405.14179v2,cs.CL
Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning,"Temporal Knowledge Graph Reasoning (TKGR) is the process of utilizing
temporal information to capture complex relations within a Temporal Knowledge
Graph (TKG) to infer new knowledge. Conventional methods in TKGR typically
depend on deep learning algorithms or temporal logical rules. However, deep
learning-based TKGRs often lack interpretability, whereas rule-based TKGRs
struggle to effectively learn temporal rules that capture temporal patterns.
Recently, Large Language Models (LLMs) have demonstrated extensive knowledge
and remarkable proficiency in temporal reasoning. Consequently, the employment
of LLMs for Temporal Knowledge Graph Reasoning (TKGR) has sparked increasing
interest among researchers. Nonetheless, LLMs are known to function as black
boxes, making it challenging to comprehend their reasoning process.
Additionally, due to the resource-intensive nature of fine-tuning, promptly
updating LLMs to integrate evolving knowledge within TKGs for reasoning is
impractical. To address these challenges, in this paper, we propose a Large
Language Models-guided Dynamic Adaptation (LLM-DA) method for reasoning on
TKGs. Specifically, LLM-DA harnesses the capabilities of LLMs to analyze
historical data and extract temporal logical rules. These rules unveil temporal
patterns and facilitate interpretable reasoning. To account for the evolving
nature of TKGs, a dynamic adaptation strategy is proposed to update the
LLM-generated rules with the latest events. This ensures that the extracted
rules always incorporate the most recent knowledge and better generalize to the
predictions on future events. Experimental results show that without the need
of fine-tuning, LLM-DA significantly improves the accuracy of reasoning over
several common datasets, providing a robust framework for TKGR tasks.",2024-05-23,"Jiapu Wang, Kai Sun, Linhao Luo, Wei Wei, Yongli Hu, Alan Wee-Chung Liew, Shirui Pan, Baocai Yin",http://arxiv.org/pdf/2405.14170v3,cs.CL
Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models,"We propose an unsupervised adaptation framework, Self-TAught Recognizer
(STAR), which leverages unlabeled data to enhance the robustness of automatic
speech recognition (ASR) systems in diverse target domains, such as noise and
accents. STAR is developed for prevalent speech foundation models based on
Transformer-related architecture with auto-regressive decoding (e.g., Whisper,
Canary). Specifically, we propose a novel indicator that empirically integrates
step-wise information during decoding to assess the token-level quality of
pseudo labels without ground truth, thereby guiding model updates for effective
unsupervised adaptation. Experimental results show that STAR achieves an
average of 13.5% relative reduction in word error rate across 14 target
domains, and it sometimes even approaches the upper-bound performance of
supervised adaptation. Surprisingly, we also observe that STAR prevents the
adapted model from the common catastrophic forgetting problem without recalling
source-domain data. Furthermore, STAR exhibits high data efficiency that only
requires less than one-hour unlabeled data, and seamless generality to
alternative large speech models and speech translation tasks. Our code aims to
open source to the research communities.",2024-05-23,"Yuchen Hu, Chen Chen, Chao-Han Huck Yang, Chengwei Qin, Pin-Yu Chen, Eng Siong Chng, Chao Zhang",http://arxiv.org/pdf/2405.14161v1,cs.CL
Super Tiny Language Models,"The rapid advancement of large language models (LLMs) has led to significant
improvements in natural language processing but also poses challenges due to
their high computational and energy demands. This paper introduces a series of
research efforts focused on Super Tiny Language Models (STLMs), which aim to
deliver high performance with significantly reduced parameter counts. We
explore innovative techniques such as byte-level tokenization with a pooling
mechanism, weight tying, and efficient training strategies. These methods aim
to significantly reduce reduce the parameter count compared to traditional
models -- in future works, we aim to build on these in a way that maintains and
improves upon the performance of base transformer models. This series of papers
will explore into various subproblems, including tokenizer-free models,
self-play based training, and alternative training objectives. We will target
models with 10M, 50M, and 100M parameters. Our ultimate goal is to make
high-performance language models more accessible and practical for a wide range
of applications.",2024-05-23,"Dylan Hillier, Leon Guertler, Cheston Tan, Palaash Agrawal, Chen Ruirui, Bobby Cheng",http://arxiv.org/pdf/2405.14159v2,cs.CL
jp-evalb: Robust Alignment-based PARSEVAL Measures,"We introduce an evaluation system designed to compute PARSEVAL measures,
offering a viable alternative to \texttt{evalb} commonly used for constituency
parsing evaluation. The widely used \texttt{evalb} script has traditionally
been employed for evaluating the accuracy of constituency parsing results,
albeit with the requirement for consistent tokenization and sentence
boundaries. In contrast, our approach, named \texttt{jp-evalb}, is founded on
an alignment method. This method aligns sentences and words when discrepancies
arise. It aims to overcome several known issues associated with \texttt{evalb}
by utilizing the `jointly preprocessed (JP)' alignment-based method. We
introduce a more flexible and adaptive framework, ultimately contributing to a
more accurate assessment of constituency parsing performance.",2024-05-23,"Jungyeul Park, Junrui Wang, Eunkyul Leah Jo, Angela Yoonseo Park",http://arxiv.org/pdf/2405.14150v1,cs.CL
ViHateT5: Enhancing Hate Speech Detection in Vietnamese With A Unified Text-to-Text Transformer Model,"Recent advancements in hate speech detection (HSD) in Vietnamese have made
significant progress, primarily attributed to the emergence of
transformer-based pre-trained language models, particularly those built on the
BERT architecture. However, the necessity for specialized fine-tuned models has
resulted in the complexity and fragmentation of developing a multitasking HSD
system. Moreover, most current methodologies focus on fine-tuning general
pre-trained models, primarily trained on formal textual datasets like
Wikipedia, which may not accurately capture human behavior on online platforms.
In this research, we introduce ViHateT5, a T5-based model pre-trained on our
proposed large-scale domain-specific dataset named VOZ-HSD. By harnessing the
power of a text-to-text architecture, ViHateT5 can tackle multiple tasks using
a unified model and achieve state-of-the-art performance across all standard
HSD benchmarks in Vietnamese. Our experiments also underscore the significance
of label distribution in pre-training data on model efficacy. We provide our
experimental materials for research purposes, including the VOZ-HSD dataset,
pre-trained checkpoint, the unified HSD-multitask ViHateT5 model, and related
source code on GitHub publicly.",2024-05-23,Luan Thanh Nguyen,http://arxiv.org/pdf/2405.14141v2,cs.CL
DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding,"Language's complexity is evident in the rich tapestry of slang expressions,
often laden with humor and cultural nuances. This linguistic phenomenon has
become increasingly prevalent, especially in digital communication. However,
existing AI models, including ChatGPT-3.5, face challenges in comprehending
these nuances, particularly in Chinese slang. In this study, we present
DuanzAI, an innovative approach enhancing Large Language Models (LLMs) with
deep Chinese slang comprehension. Leveraging curated datasets and advanced
techniques, DuanzAI bridges the gap between human expression and AI
comprehension, enabling contextually relevant responses. Our experiments
contrast LLMs' performance with a custom Punchline Entity Recognition (PER)
system, integrating phonetic matching and pinyin2hanzi techniques. Applying
these insights, we developed ChatDAI, an advanced chatbot and released our code
at \url{https://github.com/YesianRohn/DuanzAI}.",2024-05-23,Yesian Rohn,http://arxiv.org/pdf/2405.15818v1,cs.CL
AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability,"Multimodal Large Language Models (MLLMs) are widely regarded as crucial in
the exploration of Artificial General Intelligence (AGI). The core of MLLMs
lies in their capability to achieve cross-modal alignment. To attain this goal,
current MLLMs typically follow a two-phase training paradigm: the pre-training
phase and the instruction-tuning phase. Despite their success, there are
shortcomings in the modeling of alignment capabilities within these models.
Firstly, during the pre-training phase, the model usually assumes that all
image-text pairs are uniformly aligned, but in fact the degree of alignment
between different image-text pairs is inconsistent. Secondly, the instructions
currently used for finetuning incorporate a variety of tasks and different
tasks usually require different levels of alignment capabilities, but previous
MLLMs overlook these differentiated alignment needs. To tackle these issues, we
propose a new multimodal large language model AlignGPT. In the pre-training
stage, instead of treating all image-text pairs equally, we divide them into
different groups according to the degrees of alignment of them. Then, the model
is trained to learn the representations of different alignment levels. In the
instruction-tuning phase, we adaptively combine these representations of
alignment levels to meet the dynamic alignment needs of different tasks.
Extensive experimental results show that our model achieves competitive
performance on 12 benchmarks.",2024-05-23,"Fei Zhao, Taotian Pang, Chunhui Li, Zhen Wu, Junjie Guo, Shangyu Xing, Xinyu Dai",http://arxiv.org/pdf/2405.14129v2,cs.CL
ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based Evaluation,"Large Language Models (LLMs) can elicit unintended and even harmful content
when misaligned with human values, posing severe risks to users and society. To
mitigate these risks, current evaluation benchmarks predominantly employ
expert-designed contextual scenarios to assess how well LLMs align with human
values. However, the labor-intensive nature of these benchmarks limits their
test scope, hindering their ability to generalize to the extensive variety of
open-world use cases and identify rare but crucial long-tail risks.
Additionally, these static tests fail to adapt to the rapid evolution of LLMs,
making it hard to evaluate timely alignment issues. To address these
challenges, we propose ALI-Agent, an evaluation framework that leverages the
autonomous abilities of LLM-powered agents to conduct in-depth and adaptive
alignment assessments. ALI-Agent operates through two principal stages:
Emulation and Refinement. During the Emulation stage, ALI-Agent automates the
generation of realistic test scenarios. In the Refinement stage, it iteratively
refines the scenarios to probe long-tail risks. Specifically, ALI-Agent
incorporates a memory module to guide test scenario generation, a tool-using
module to reduce human labor in tasks such as evaluating feedback from target
LLMs, and an action module to refine tests. Extensive experiments across three
aspects of human values--stereotypes, morality, and legality--demonstrate that
ALI-Agent, as a general evaluation framework, effectively identifies model
misalignment. Systematic analysis also validates that the generated test
scenarios represent meaningful use cases, as well as integrate enhanced
measures to probe long-tail risks. Our code is available at
https://github.com/SophieZheng998/ALI-Agent.git",2024-05-23,"Jingnan Zheng, Han Wang, An Zhang, Tai D. Nguyen, Jun Sun, Tat-Seng Chua",http://arxiv.org/pdf/2405.14125v3,cs.CL
Knowledge Localization: Mission Not Accomplished? Enter Query Localization!,"Large language models (LLMs) store extensive factual knowledge, but the
mechanisms behind how they store and express this knowledge remain unclear. The
Knowledge Neuron (KN) thesis is a prominent theory for explaining these
mechanisms. This theory is based on the Knowledge Localization (KL) assumption,
which suggests that a fact can be localized to a few knowledge storage units,
namely knowledge neurons.
  However, this assumption has two limitations: first, it may be too rigid
regarding knowledge storage, and second, it neglects the role of the attention
module in knowledge expression.
  In this paper, we first re-examine the KL assumption and demonstrate that its
limitations do indeed exist. To address these, we then present two new
findings, each targeting one of the limitations: one focusing on knowledge
storage and the other on knowledge expression. We summarize these findings as
\textbf{Query Localization} (QL) assumption and argue that the KL assumption
can be viewed as a simplification of the QL assumption. Based on QL assumption,
we further propose the Consistency-Aware KN modification method, which improves
the performance of knowledge modification, further validating our new
assumption. We conduct 39 sets of experiments, along with additional
visualization experiments, to rigorously confirm our conclusions. Code is
available at https://github.com/heng840/KnowledgeLocalization.",2024-05-23,"Yuheng Chen, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2405.14117v2,cs.CL
Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis,"In this paper, an innovative multi-modal deep learning model is proposed to
deeply integrate heterogeneous information from medical images and clinical
reports. First, for medical images, convolutional neural networks were used to
extract high-dimensional features and capture key visual information such as
focal details, texture and spatial distribution. Secondly, for clinical report
text, a two-way long and short-term memory network combined with an attention
mechanism is used for deep semantic understanding, and key statements related
to the disease are accurately captured. The two features interact and integrate
effectively through the designed multi-modal fusion layer to realize the joint
representation learning of image and text. In the empirical study, we selected
a large medical image database covering a variety of diseases, combined with
corresponding clinical reports for model training and validation. The proposed
multimodal deep learning model demonstrated substantial superiority in the
realms of disease classification, lesion localization, and clinical description
generation, as evidenced by the experimental results.",2024-05-23,"Ziyan Yao, Fei Lin, Sheng Chai, Weijie He, Lu Dai, Xinghui Fei",http://arxiv.org/pdf/2405.17459v1,cs.CL
Distributed Speculative Inference (DSI): Speculation Parallelism for Provably Faster Lossless Language Model Inference,"This paper introduces distributed speculative inference (DSI), a novel
inference algorithm that is provably faster than speculative inference (SI)
[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard
autoregressive inference (non-SI). Like other SI algorithms, DSI operates on
frozen language models (LMs), requiring no training or architectural
modifications, and it preserves the target distribution. Prior studies on SI
have demonstrated empirical speedups over non-SI--but rely on sufficiently fast
and accurate drafters, which are often unavailable in practice. We identify a
gap where SI can be slower than non-SI if drafters are too slow or inaccurate.
We close this gap by proving that DSI is faster than both SI and non-SI--given
any drafters. DSI is therefore not only faster than SI, but also unlocks the
acceleration of LMs for which SI fails. DSI leverages speculation parallelism
(SP), a novel type of task parallelism, to orchestrate target and drafter
instances that overlap in time, establishing a new foundational tradeoff
between computational resources and latency. Our simulations show that DSI is
1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs
and tasks. We open-source all our code.",2024-05-23,"Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Moshe Wasserblat, Tomer Galanti, Michal Gordon, David Harel",http://arxiv.org/pdf/2405.14105v5,cs.CL
A Survey on Vision-Language-Action Models for Embodied AI,"Embodied AI is widely recognized as a key element of artificial general
intelligence because it involves controlling embodied agents to perform tasks
in the physical world. Building on the success of large language models and
vision-language models, a new category of multimodal models -- referred to as
vision-language-action models (VLAs) -- has emerged to address
language-conditioned robotic tasks in embodied AI by leveraging their distinct
ability to generate actions. In recent years, a myriad of VLAs have been
developed, making it imperative to capture the rapidly evolving landscape
through a comprehensive survey. To this end, we present the first survey on
VLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized
into three major lines of research. The first line focuses on individual
components of VLAs. The second line is dedicated to developing control policies
adept at predicting low-level actions. The third line comprises high-level task
planners capable of decomposing long-horizon tasks into a sequence of subtasks,
thereby guiding VLAs to follow more general user instructions. Furthermore, we
provide an extensive summary of relevant resources, including datasets,
simulators, and benchmarks. Finally, we discuss the challenges faced by VLAs
and outline promising future directions in embodied AI. We have created a
project associated with this survey, which is available at
https://github.com/yueen-ma/Awesome-VLA.",2024-05-23,"Yueen Ma, Zixing Song, Yuzheng Zhuang, Jianye Hao, Irwin King",http://arxiv.org/pdf/2405.14093v4,cs.CL
Large Language Models Can Self-Correct with Key Condition Verification,"Intrinsic self-correct was a method that instructed large language models
(LLMs) to verify and correct their responses without external feedback.
Unfortunately, the study concluded that the LLMs could not self-correct
reasoning yet. We find that a simple yet effective verification method can
unleash inherent capabilities of the LLMs. That is to mask a key condition in
the question, add the current response to construct a verification question,
and predict the condition to verify the response. The condition can be an
entity in an open-domain question or a numeric value in a math question, which
requires minimal effort (via prompting) to identify. We propose an iterative
verify-then-correct framework to progressively identify and correct (probably)
false responses, named ProCo. We conduct experiments on three reasoning tasks.
On average, ProCo, with GPT-3.5-Turbo as the backend LLM, yields $+6.8$ exact
match on four open-domain question answering datasets, $+14.1$ accuracy on
three arithmetic reasoning datasets, and $+9.6$ accuracy on a commonsense
reasoning dataset, compared to Self-Correct. Our implementation is made
publicly available at https://wzy6642.github.io/proco.github.io/.",2024-05-23,"Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang",http://arxiv.org/pdf/2405.14092v3,cs.CL
Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation,"The automated generation of imaging reports proves invaluable in alleviating
the workload of radiologists. A clinically applicable reports generation
algorithm should demonstrate its effectiveness in producing reports that
accurately describe radiology findings and attend to patient-specific
indications. In this paper, we introduce a novel method, \textbf{S}tructural
\textbf{E}ntities extraction and patient indications \textbf{I}ncorporation
(SEI) for chest X-ray report generation. Specifically, we employ a structural
entities extraction (SEE) approach to eliminate presentation-style vocabulary
in reports and improve the quality of factual entity sequences. This reduces
the noise in the following cross-modal alignment module by aligning X-ray
images with factual entity sequences in reports, thereby enhancing the
precision of cross-modal alignment and further aiding the model in
gradient-free retrieval of similar historical cases. Subsequently, we propose a
cross-modal fusion network to integrate information from X-ray images, similar
historical cases, and patient-specific indications. This process allows the
text decoder to attend to discriminative features of X-ray images, assimilate
historical diagnostic information from similar cases, and understand the
examination intention of patients. This, in turn, assists in triggering the
text decoder to produce high-quality reports. Experiments conducted on
MIMIC-CXR validate the superiority of SEI over state-of-the-art approaches on
both natural language generation and clinical efficacy metrics.",2024-05-23,"Kang Liu, Zhuoqi Ma, Xiaolu Kang, Zhusi Zhong, Zhicheng Jiao, Grayson Baird, Harrison Bai, Qiguang Miao",http://arxiv.org/pdf/2405.14905v1,cs.CL
PTA: Enhancing Multimodal Sentiment Analysis through Pipelined Prediction and Translation-based Alignment,"Multimodal aspect-based sentiment analysis (MABSA) aims to understand
opinions in a granular manner, advancing human-computer interaction and other
fields. Traditionally, MABSA methods use a joint prediction approach to
identify aspects and sentiments simultaneously. However, we argue that joint
models are not always superior. Our analysis shows that joint models struggle
to align relevant text tokens with image patches, leading to misalignment and
ineffective image utilization.
  In contrast, a pipeline framework first identifies aspects through MATE
(Multimodal Aspect Term Extraction) and then aligns these aspects with image
patches for sentiment classification (MASC: Multimodal Aspect-Oriented
Sentiment Classification). This method is better suited for multimodal
scenarios where effective image use is crucial. We present three key
observations: (a) MATE and MASC have different feature requirements, with MATE
focusing on token-level features and MASC on sequence-level features; (b) the
aspect identified by MATE is crucial for effective image utilization; and (c)
images play a trivial role in previous MABSA methods due to high noise.
  Based on these observations, we propose a pipeline framework that first
predicts the aspect and then uses translation-based alignment (TBA) to enhance
multimodal semantic consistency for better image utilization. Our method
achieves state-of-the-art (SOTA) performance on widely used MABSA datasets
Twitter-15 and Twitter-17. This demonstrates the effectiveness of the pipeline
approach and its potential to provide valuable insights for future MABSA
research.
  For reproducibility, the code and checkpoint will be released.",2024-05-23,"Shezheng Song, Shasha Li, Shan Zhao, Chengyu Wang, Xiaopeng Li, Jie Yu, Qian Wan, Jun Ma, Tianwei Yan, Wentao Ma, Xiaoguang Mao",http://arxiv.org/pdf/2406.00017v2,cs.CL
$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language Models,"Large Language Models (LLMs) have emerged as powerful tools in artificial
intelligence, especially in complex decision-making scenarios, but their static
problem-solving strategies often limit their adaptability to dynamic
environments. We explore the enhancement of reasoning capabilities in LLMs
through Temperature Tree ($T^2$) prompting via a heuristic algorithm, termed as
$T^2$ of Thoughts ($T^2oT$). The primary focus is on enhancing decision-making
processes by dynamically adjusting search parameters, especially temperature,
to improve accuracy without increasing computational demands. We empirically
validate that our hybrid $T^2oT$ approach yields enhancements in,
single-solution accuracy, multi-solution generation and text generation
quality. Our findings suggest that while dynamic search depth adjustments based
on temperature can yield mixed results, a fixed search depth, when coupled with
adaptive capabilities of $T^2oT$, provides a more reliable and versatile
problem-solving strategy. This work highlights the potential for future
explorations in optimizing algorithmic interactions with foundational language
models, particularly illustrated by our development for the Game of 24 and
Creative Writing tasks.",2024-05-23,"Chengkun Cai, Xu Zhao, Yucheng Du, Haoliang Liu, Lei Li",http://arxiv.org/pdf/2405.14075v2,cs.CL
Exploration of Attention Mechanism-Enhanced Deep Learning Models in the Mining of Medical Textual Data,"The research explores the utilization of a deep learning model employing an
attention mechanism in medical text mining. It targets the challenge of
analyzing unstructured text information within medical data. This research
seeks to enhance the model's capability to identify essential medical
information by incorporating deep learning and attention mechanisms. This paper
reviews the basic principles and typical model architecture of attention
mechanisms and shows the effectiveness of their application in the tasks of
disease prediction, drug side effect monitoring, and entity relationship
extraction. Aiming at the particularity of medical texts, an adaptive attention
model integrating domain knowledge is proposed, and its ability to understand
medical terms and process complex contexts is optimized. The experiment
verifies the model's effectiveness in improving task accuracy and robustness,
especially when dealing with long text. The future research path of enhancing
model interpretation, realizing cross-domain knowledge transfer, and adapting
to low-resource scenarios is discussed in the research outlook, which provides
a new perspective and method support for intelligent medical information
processing and clinical decision assistance. Finally, cross-domain knowledge
transfer and adaptation strategies for low-resource scenarios, providing
theoretical basis and technical reference for promoting the development of
intelligent medical information processing and clinical decision support
systems.",2024-05-23,"Lingxi Xiao, Muqing Li, Yinqiu Feng, Meiqi Wang, Ziyi Zhu, Zexi Chen",http://arxiv.org/pdf/2406.00016v1,cs.CL
Meanings and Feelings of Large Language Models: Observability of Latent States in Generative AI,"We tackle the question of whether Large Language Models (LLMs), viewed as
dynamical systems with state evolving in the embedding space of symbolic
tokens, are observable. That is, whether there exist multiple 'mental' state
trajectories that yield the same sequence of generated tokens, or sequences
that belong to the same Nerode equivalence class ('meaning'). If not
observable, mental state trajectories ('experiences') evoked by an input
('perception') or by feedback from the model's own state ('thoughts') could
remain self-contained and evolve unbeknown to the user while being potentially
accessible to the model provider. Such ""self-contained experiences evoked by
perception or thought"" are akin to what the American Psychological Association
(APA) defines as 'feelings'. Beyond the lexical curiosity, we show that current
LLMs implemented by autoregressive Transformers cannot have 'feelings'
according to this definition: The set of state trajectories indistinguishable
from the tokenized output is a singleton. But if there are 'system prompts' not
visible to the user, then the set of indistinguishable trajectories becomes
non-trivial, and there can be multiple state trajectories that yield the same
verbalized output. We prove these claims analytically, and show examples of
modifications to standard LLMs that engender such 'feelings.' Our analysis
sheds light on possible designs that would enable a model to perform
non-trivial computation that is not visible to the user, as well as on controls
that the provider of services using the model could take to prevent unintended
behavior.",2024-05-22,"Tian Yu Liu, Stefano Soatto, Matteo Marchi, Pratik Chaudhari, Paulo Tabuada",http://arxiv.org/pdf/2405.14061v1,cs.CL
Your Large Language Models Are Leaving Fingerprints,"It has been shown that finetuned transformers and other supervised detectors
effectively distinguish between human and machine-generated text in some
situations arXiv:2305.13242, but we find that even simple classifiers on top of
n-gram and part-of-speech features can achieve very robust performance on both
in- and out-of-domain data. To understand how this is possible, we analyze
machine-generated output text in five datasets, finding that LLMs possess
unique fingerprints that manifest as slight differences in the frequency of
certain lexical and morphosyntactic features. We show how to visualize such
fingerprints, describe how they can be used to detect machine-generated text
and find that they are even robust across textual domains. We find that
fingerprints are often persistent across models in the same model family (e.g.
llama-13b vs. llama-65b) and that models fine-tuned for chat are easier to
detect than standard language models, indicating that LLM fingerprints may be
directly induced by the training data.",2024-05-22,"Hope McGovern, Rickard Stureborg, Yoshi Suhara, Dimitris Alikaniotis",http://arxiv.org/pdf/2405.14057v1,cs.CL
How Many Bytes Can You Take Out Of Brain-To-Text Decoding?,"Brain-computer interfaces have promising medical and scientific applications
for aiding speech and studying the brain. In this work, we propose an
information-based evaluation metric for brain-to-text decoders. Using this
metric, we examine two methods to augment existing state-of-the-art continuous
text decoders. We show that these methods, in concert, can improve brain
decoding performance by upwards of 40% when compared to a baseline model. We
further examine the informatic properties of brain-to-text decoders and show
empirically that they have Zipfian power law dynamics. Finally, we provide an
estimate for the idealized performance of an fMRI-based text decoder. We
compare this idealized model to our current model, and use our
information-based metric to quantify the main sources of decoding error. We
conclude that a practical brain-to-text decoder is likely possible given
further algorithmic improvements.",2024-05-22,"Richard Antonello, Nihita Sarma, Jerry Tang, Jiaru Song, Alexander Huth",http://arxiv.org/pdf/2405.14055v1,cs.CL
Use of natural language processing to extract and classify papillary thyroid cancer features from surgical pathology reports,"Background We aim to use Natural Language Processing (NLP) to automate the
extraction and classification of thyroid cancer risk factors from pathology
reports. Methods We analyzed 1,410 surgical pathology reports from adult
papillary thyroid cancer patients at Mayo Clinic, Rochester, MN, from 2010 to
2019. Structured and non-structured reports were used to create a
consensus-based ground truth dictionary and categorized them into modified
recurrence risk levels. Non-structured reports were narrative, while structured
reports followed standardized formats. We then developed ThyroPath, a
rule-based NLP pipeline, to extract and classify thyroid cancer features into
risk categories. Training involved 225 reports (150 structured, 75
unstructured), with testing on 170 reports (120 structured, 50 unstructured)
for evaluation. The pipeline's performance was assessed using both strict and
lenient criteria for accuracy, precision, recall, and F1-score. Results In
extraction tasks, ThyroPath achieved overall strict F-1 scores of 93% for
structured reports and 90 for unstructured reports, covering 18 thyroid cancer
pathology features. In classification tasks, ThyroPath-extracted information
demonstrated an overall accuracy of 93% in categorizing reports based on their
corresponding guideline-based risk of recurrence: 76.9% for high-risk, 86.8%
for intermediate risk, and 100% for both low and very low-risk cases. However,
ThyroPath achieved 100% accuracy across all thyroid cancer risk categories with
human-extracted pathology information. Conclusions ThyroPath shows promise in
automating the extraction and risk recurrence classification of thyroid
pathology reports at large scale. It offers a solution to laborious manual
reviews and advancing virtual registries. However, it requires further
validation before implementation.",2024-05-22,"Ricardo Loor-Torres, Yuqi Wu, Esteban Cabezas, Mariana Borras, David Toro-Tobon, Mayra Duran, Misk Al Zahidy, Maria Mateo Chavez, Cristian Soto Jacome, Jungwei W. Fan, Naykky M. Singh Ospina, Yonghui Wu, Juan P. Brito",http://arxiv.org/pdf/2406.00015v1,cs.CL
Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning,"Real-world data deviating from the independent and identically distributed
(i.i.d.) assumption of in-distribution training data poses security threats to
deep networks, thus advancing out-of-distribution (OOD) detection algorithms.
Detection methods in generative language models (GLMs) mainly focus on
uncertainty estimation and embedding distance measurement, with the latter
proven to be most effective in traditional linguistic tasks like summarization
and translation. However, another complex generative scenario mathematical
reasoning poses significant challenges to embedding-based methods due to its
high-density feature of output spaces, but this feature causes larger
discrepancies in the embedding shift trajectory between different samples in
latent spaces. Hence, we propose a trajectory-based method TV score, which uses
trajectory volatility for OOD detection in mathematical reasoning. Experiments
show that our method outperforms all traditional algorithms on GLMs under
mathematical reasoning scenarios and can be extended to more applications with
high-density features in output spaces, such as multiple-choice questions.",2024-05-22,"Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Zhuosheng Zhang, Rui Wang",http://arxiv.org/pdf/2405.14039v2,cs.CL
Refining Skewed Perceptions in Vision-Language Models through Visual Representations,"Large vision-language models (VLMs), such as CLIP, have become foundational,
demonstrating remarkable success across a variety of downstream tasks. Despite
their advantages, these models, akin to other foundational systems, inherit
biases from the disproportionate distribution of real-world data, leading to
misconceptions about the actual environment. Prevalent datasets like ImageNet
are often riddled with non-causal, spurious correlations that can diminish VLM
performance in scenarios where these contextual elements are absent. This study
presents an investigation into how a simple linear probe can effectively
distill task-specific core features from CLIP's embedding for downstream
applications. Our analysis reveals that the CLIP text representations are often
tainted by spurious correlations, inherited in the biased pre-training dataset.
Empirical evidence suggests that relying on visual representations from CLIP,
as opposed to text embedding, is more practical to refine the skewed
perceptions in VLMs, emphasizing the superior utility of visual representations
in overcoming embedded biases. Our codes will be available here.",2024-05-22,"Haocheng Dai, Sarang Joshi",http://arxiv.org/pdf/2405.14030v2,cs.CL
Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models,"In applications such as personal assistants, large language models (LLMs)
must consider the user's personal information and preferences. However, LLMs
lack the inherent ability to learn from user interactions. This paper explores
capturing personal information from user prompts using ontology and
knowledge-graph approaches. We use a subset of the KNOW ontology, which models
personal information, to train the language model on these concepts. We then
evaluate the success of knowledge capture using a specially constructed
dataset. Our code and datasets are publicly available at
https://github.com/HaltiaAI/paper-PTODSKC",2024-05-22,"Tolga Çöplü, Arto Bendiken, Andrii Skomorokhov, Eduard Bateiko, Stephen Cobb",http://arxiv.org/pdf/2405.14012v1,cs.CL
Evaluating Large Language Models with Human Feedback: Establishing a Swedish Benchmark,"In the rapidly evolving field of artificial intelligence, large language
models (LLMs) have demonstrated significant capabilities across numerous
applications. However, the performance of these models in languages with fewer
resources, such as Swedish, remains under-explored. This study introduces a
comprehensive human benchmark to assess the efficacy of prominent LLMs in
understanding and generating Swedish language texts using forced choice
ranking. We employ a modified version of the ChatbotArena benchmark,
incorporating human feedback to evaluate eleven different models, including
GPT-4, GPT-3.5, various Claude and Llama models, and bespoke models like
Dolphin-2.9-llama3b-8b-flashback and BeagleCatMunin. These models were chosen
based on their performance on LMSYS chatbot arena and the Scandeval benchmarks.
We release the chatbotarena.se benchmark as a tool to improve our understanding
of language model performance in Swedish with the hopes that it will be widely
used. We aim to create a leaderboard once sufficient data has been collected
and analysed.",2024-05-22,Birger Moell,http://arxiv.org/pdf/2405.14006v1,cs.CL
Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation,"Scientific language models drive research innovation but require extensive
fine-tuning on large datasets. This work enhances such models by improving
their inference and evaluation capabilities with minimal or no additional
training. Focusing on molecule caption generation, we explore post-training
synergies between alignment fine-tuning and model merging in a cross-modal
setup. We reveal intriguing insights into the behaviour and suitability of such
methods while significantly surpassing state-of-the-art models. Moreover, we
propose a novel atomic-level evaluation method leveraging off-the-shelf Natural
Language Inference (NLI) models for use in the unseen chemical domain. Our
experiments demonstrate that our evaluation operates at the right level of
granularity, effectively handling multiple content units and subsentence
reasoning, while widely adopted NLI methods consistently misalign with
assessment criteria.",2024-05-22,"Dimitris Gkoumas, Maria Liakata",http://arxiv.org/pdf/2405.13984v3,cs.CL
CIVICS: Building a Dataset for Examining Culturally-Informed Values in Large Language Models,"This paper introduces the ""CIVICS: Culturally-Informed & Values-Inclusive
Corpus for Societal impacts"" dataset, designed to evaluate the social and
cultural variation of Large Language Models (LLMs) across multiple languages
and value-sensitive topics. We create a hand-crafted, multilingual dataset of
value-laden prompts which address specific socially sensitive topics, including
LGBTQI rights, social welfare, immigration, disability rights, and surrogacy.
CIVICS is designed to generate responses showing LLMs' encoded and implicit
values. Through our dynamic annotation processes, tailored prompt design, and
experiments, we investigate how open-weight LLMs respond to value-sensitive
issues, exploring their behavior across diverse linguistic and cultural
contexts. Using two experimental set-ups based on log-probabilities and
long-form responses, we show social and cultural variability across different
LLMs. Specifically, experiments involving long-form responses demonstrate that
refusals are triggered disparately across models, but consistently and more
frequently in English or translated statements. Moreover, specific topics and
sources lead to more pronounced differences across model answers, particularly
on immigration, LGBTQI rights, and social welfare. As shown by our experiments,
the CIVICS dataset aims to serve as a tool for future research, promoting
reproducibility and transparency across broader linguistic settings, and
furthering the development of AI technologies that respect and reflect global
cultural diversities and value pluralism. The CIVICS dataset and tools will be
made available upon publication under open licenses; an anonymized version is
currently available at https://huggingface.co/CIVICS-dataset.",2024-05-22,"Giada Pistilli, Alina Leidinger, Yacine Jernite, Atoosa Kasirzadeh, Alexandra Sasha Luccioni, Margaret Mitchell",http://arxiv.org/pdf/2405.13974v1,cs.CL
Model Editing as a Robust and Denoised variant of DPO: A Case Study on Toxicity,"Recent alignment algorithms such as direct preference optimization (DPO) have
been developed to improve the safety of large language models (LLMs) by
training these models to match human behaviors exemplified by preference data.
However, these methods are both computationally intensive and lacking in
controllability and transparency, inhibiting their widespread use. Furthermore,
these tuning-based methods require large-scale preference data for training and
are susceptible to noisy preference data. In this paper, we introduce a
tuning-free alignment alternative, ProFS (Projection Filter for Subspaces), and
demonstrate its effectiveness under the use case of toxicity reduction.
Grounded on theory from factor analysis, ProFS is a sample-efficient model
editing approach that identifies a toxic subspace in the model parameter space
and reduces model toxicity by projecting away the detected subspace. The toxic
subspace is identified by extracting preference data embeddings from the
language model, and removing non-toxic information from these embeddings. We
show that ProFS is more sample-efficient than DPO, further showcasing greater
robustness to noisy data. Finally, we attempt to connect tuning based alignment
with editing, by establishing both theoretical and empirical connections
between ProFS and DPO, showing that ProFS can be interpreted as a denoised
version of a single DPO step.",2024-05-22,"Rheeya Uppaal, Apratim Dey, Yiting He, Yiqiao Zhong, Junjie Hu",http://arxiv.org/pdf/2405.13967v5,cs.CL
On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models,"The reasoning abilities of Large Language Models (LLMs) remain a topic of
debate. Some methods such as ReAct-based prompting, have gained popularity for
claiming to enhance sequential decision-making abilities of agentic LLMs.
However, it is unclear what is the source of improvement in LLM reasoning with
ReAct based prompting. In this paper we examine these claims of ReAct based
prompting in improving agentic LLMs for sequential decision-making. By
introducing systematic variations to the input prompt we perform a sensitivity
analysis along the claims of ReAct and find that the performance is minimally
influenced by the ""interleaving reasoning trace with action execution"" or the
content of the generated reasoning traces in ReAct, contrary to original claims
and common usage. Instead, the performance of LLMs is driven by the similarity
between input example tasks and queries, implicitly forcing the prompt designer
to provide instance-specific examples which significantly increases the
cognitive burden on the human. Our investigation shows that the perceived
reasoning abilities of LLMs stem from the exemplar-query similarity and
approximate retrieval rather than any inherent reasoning abilities.",2024-05-22,"Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati",http://arxiv.org/pdf/2405.13966v1,cs.CL
What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions,"Large language models (LLMs) are trained on a vast amount of human-written
data, but data providers often remain uncredited. In response to this issue,
data valuation (or data attribution), which quantifies the contribution or
value of each data to the model output, has been discussed as a potential
solution. Nevertheless, applying existing data valuation methods to recent LLMs
and their vast training datasets has been largely limited by prohibitive
compute and memory costs. In this work, we focus on influence functions, a
popular gradient-based data valuation method, and significantly improve its
scalability with an efficient gradient projection strategy called LoGra that
leverages the gradient structure in backpropagation. We then provide a
theoretical motivation of gradient projection approaches to influence functions
to promote trust in the data valuation process. Lastly, we lower the barrier to
implementing data valuation systems by introducing LogIX, a software package
that can transform existing training code into data valuation code with minimal
effort. In our data valuation experiments, LoGra achieves competitive accuracy
against more expensive baselines while showing up to 6,500x improvement in
throughput and 5x reduction in GPU memory usage when applied to
Llama3-8B-Instruct and the 1B-token dataset.",2024-05-22,"Sang Keun Choe, Hwijeen Ahn, Juhan Bae, Kewen Zhao, Minsoo Kang, Youngseog Chung, Adithya Pratapa, Willie Neiswanger, Emma Strubell, Teruko Mitamura, Jeff Schneider, Eduard Hovy, Roger Grosse, Eric Xing",http://arxiv.org/pdf/2405.13954v1,cs.CL
Vikhr: The Family of Open-Source Instruction-Tuned Large Language Models for Russian,"There has been a surge in the development of various Large Language Models
(LLMs). However, text generation for languages other than English often faces
significant challenges, including poor generation quality and reduced
computational performance due to the disproportionate representation of tokens
in the model's vocabulary. In this work, we address these issues by developing
a pipeline for the adaptation of English-oriented pre-trained models to other
languages and constructing efficient bilingual LLMs. Using this pipeline, we
construct Vikhr, a series of bilingual open-source instruction-following LLMs
designed specifically for the Russian language. ``Vikhr'' refers to the name of
the Mistral LLM series and means a ``strong gust of wind.'' Unlike previous
Russian-language models that typically rely on LoRA adapters on top of
English-oriented models, sacrificing performance for lower training costs,
Vikhr features an adapted tokenizer vocabulary and undergoes the continued
pre-training and instruction tuning of all weights. This not only enhances the
model's performance but also significantly improves its computational and
contextual efficiency. We also expanded the instruction datasets and corpora
for continued pre-training. The model weights, instruction sets, and code are
publicly available.",2024-05-22,"Aleksandr Nikolich, Konstantin Korolev, Sergei Bratchikov, Igor Kiselev, Artem Shelmanov",http://arxiv.org/pdf/2405.13929v6,cs.CL
Why Not Transform Chat Large Language Models to Non-English?,"The scarcity of non-English data limits the development of non-English large
language models (LLMs). Transforming English-centric LLMs to non-English has
been identified as an effective and resource-efficient method. Previous works
start from base LLMs and perform knowledge distillation (KD) with data
generated by stronger LLMs, e.g. GPT-4. Compared to base LLMs, chat LLMs are
further optimized for advanced abilities, e.g. multi-turn conversation and
human preference alignment, and thus more powerful in both helpfulness and
safety. However, transforming a chat LLM involves two critical issues: (1) How
can we effectively transfer advanced abilities without their supervised data?
(2) How can we prevent the original knowledge from catastrophic forgetting
during transformation? We target these issues by introducing a simple framework
called TransLLM. For the first issue, TransLLM divides the transfer problem
into some common sub-tasks with the translation chain-of-thought, which uses
the translation as the bridge between English and non-English step-by-step. We
further enhance the performance of sub-tasks with publicly available data. For
the second issue, we propose a method comprising two synergistic components:
low-rank adaptation for training to maintain the original LLM parameters, and
recovery KD, which utilizes data generated by the chat LLM itself to recover
the original knowledge from the frozen parameters. In the experiments, we
transform the LLaMA-2-chat-7B to the Thai language. Our method, using only
single-turn data, outperforms strong baselines and ChatGPT on multi-turn
benchmark MT-bench. Furthermore, our method, without safety data, rejects more
harmful queries of safety benchmark AdvBench than both ChatGPT and GPT-4.",2024-05-22,"Xiang Geng, Ming Zhu, Jiahuan Li, Zhejian Lai, Wei Zou, Shuaijie She, Jiaxin Guo, Xiaofeng Zhao, Yinglu Li, Yuang Li, Chang Su, Yanqing Zhao, Xinglin Lyu, Min Zhang, Jiajun Chen, Hao Yang, Shujian Huang",http://arxiv.org/pdf/2405.13923v2,cs.CL
TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment,"Recent advancements in image understanding have benefited from the extensive
use of web image-text pairs. However, video understanding remains a challenge
despite the availability of substantial web video-text data. This difficulty
primarily arises from the inherent complexity of videos and the inefficient
language supervision in recent web-collected video-text datasets. In this
paper, we introduce Text-Only Pre-Alignment (TOPA), a novel approach to extend
large language models (LLMs) for video understanding, without the need for
pre-training on real video data. Specifically, we first employ an advanced LLM
to automatically generate Textual Videos comprising continuous textual frames,
along with corresponding annotations to simulate real video-text data. Then,
these annotated textual videos are used to pre-align a language-only LLM with
the video modality. To bridge the gap between textual and real videos, we
employ the CLIP model as the feature extractor to align image and text
modalities. During text-only pre-alignment, the continuous textual frames,
encoded as a sequence of CLIP text features, are analogous to continuous CLIP
image features, thus aligning the LLM with real video representation. Extensive
experiments, including zero-shot evaluation and finetuning on various video
understanding tasks, demonstrate that TOPA is an effective and efficient
framework for aligning video content with LLMs. In particular, without training
on any video data, the TOPA-Llama2-13B model achieves a Top-1 accuracy of 51.0%
on the challenging long-form video understanding benchmark, Egoschema. This
performance surpasses previous video-text pre-training approaches and proves
competitive with recent GPT-3.5-based video agents.",2024-05-22,"Wei Li, Hehe Fan, Yongkang Wong, Mohan Kankanhalli, Yi Yang",http://arxiv.org/pdf/2405.13911v2,cs.CL
Just rephrase it! Uncertainty estimation in closed-source language models via multiple rephrased queries,"State-of-the-art large language models are sometimes distributed as
open-source software but are also increasingly provided as a closed-source
service. These closed-source large-language models typically see the widest
usage by the public, however, they often do not provide an estimate of their
uncertainty when responding to queries. As even the best models are prone to
``hallucinating"" false information with high confidence, a lack of a reliable
estimate of uncertainty limits the applicability of these models in critical
settings. We explore estimating the uncertainty of closed-source LLMs via
multiple rephrasings of an original base query. Specifically, we ask the model,
multiple rephrased questions, and use the similarity of the answers as an
estimate of uncertainty. We diverge from previous work in i) providing rules
for rephrasing that are simple to memorize and use in practice ii) proposing a
theoretical framework for why multiple rephrased queries obtain calibrated
uncertainty estimates. Our method demonstrates significant improvements in the
calibration of uncertainty estimates compared to the baseline and provides
intuition as to how query strategies should be designed for optimal test
calibration.",2024-05-22,"Adam Yang, Chen Chen, Konstantinos Pitas",http://arxiv.org/pdf/2405.13907v2,cs.CL
FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering,"Large Language Models (LLMs) are often challenged by generating erroneous or
hallucinated responses, especially in complex reasoning tasks. Leveraging
Knowledge Graphs (KGs) as external knowledge sources has emerged as a viable
solution. However, existing KG-enhanced methods, either retrieval-based or
agent-based, encounter difficulties in accurately retrieving knowledge and
efficiently traversing KGs at scale. In this paper, we propose a unified
framework, FiDeLiS, designed to improve the factuality of LLM responses by
anchoring answers to verifiable reasoning steps retrieved from KGs. To achieve
this, we leverage step-wise beam search with a deductive scoring function,
allowing the LLM to validate reasoning process step by step, and halt the
search once the question is deducible. In addition, we propose a Path-RAG
module to pre-select a smaller candidate set for each beam search step,
reducing computational costs by narrowing the search space. Extensive
experiments show that our method, as a training-free framework, not only
improve the performance but also enhance the factuality and interpretability
across different benchmarks. Code is released at
https://github.com/Y-Sui/FiDeLiS.",2024-05-22,"Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, Bryan Hooi",http://arxiv.org/pdf/2405.13873v4,cs.CL
Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models,"Recent advancements in Chain-of-Thought (CoT) and related rationale-based
works have significantly improved the performance of Large Language Models
(LLMs) in complex reasoning tasks. With the evolution of Multimodal Large
Language Models (MLLMs), enhancing their capability to tackle complex
multimodal reasoning problems is a crucial frontier. However, incorporating
multimodal rationales in CoT has yet to be thoroughly investigated. We propose
the Image-of-Thought (IoT) prompting method, which helps MLLMs to extract
visual rationales step-by-step. Specifically, IoT prompting can automatically
design critical visual information extraction operations based on the input
images and questions. Each step of visual information refinement identifies
specific visual rationales that support answers to complex visual reasoning
questions. Beyond the textual CoT, IoT simultaneously utilizes visual and
textual rationales to help MLLMs understand complex multimodal information. IoT
prompting has improved zero-shot visual reasoning performance across various
visual understanding tasks in different MLLMs. Moreover, the step-by-step
visual feature explanations generated by IoT prompting elucidate the visual
reasoning process, aiding in analyzing the cognitive processes of large
multimodal models",2024-05-22,"Qiji Zhou, Ruochen Zhou, Zike Hu, Panzhong Lu, Siyang Gao, Yue Zhang",http://arxiv.org/pdf/2405.13872v2,cs.CL
Automatically Identifying Local and Global Circuits with Linear Computation Graphs,"Circuit analysis of any certain model behavior is a central task in
mechanistic interpretability. We introduce our circuit discovery pipeline with
Sparse Autoencoders (SAEs) and a variant called Transcoders. With these two
modules inserted into the model, the model's computation graph with respect to
OV and MLP circuits becomes strictly linear. Our methods do not require linear
approximation to compute the causal effect of each node. This fine-grained
graph identifies both end-to-end and local circuits accounting for either
logits or intermediate features. We can scalably apply this pipeline with a
technique called Hierarchical Attribution. We analyze three kinds of circuits
in GPT-2 Small: bracket, induction, and Indirect Object Identification
circuits. Our results reveal new findings underlying existing discoveries.",2024-05-22,"Xuyang Ge, Fukang Zhu, Wentao Shu, Junxuan Wang, Zhengfu He, Xipeng Qiu",http://arxiv.org/pdf/2405.13868v2,cs.CL
Semantic Density: Uncertainty Quantification for Large Language Models through Confidence Measurement in Semantic Space,"With the widespread application of Large Language Models (LLMs) to various
domains, concerns regarding the trustworthiness of LLMs in safety-critical
scenarios have been raised, due to their unpredictable tendency to hallucinate
and generate misinformation. Existing LLMs do not have an inherent
functionality to provide the users with an uncertainty/confidence metric for
each response it generates, making it difficult to evaluate trustworthiness.
Although several studies aim to develop uncertainty quantification methods for
LLMs, they have fundamental limitations, such as being restricted to
classification tasks, requiring additional training and data, considering only
lexical instead of semantic information, and being prompt-wise but not
response-wise. A new framework is proposed in this paper to address these
issues. Semantic density extracts uncertainty/confidence information for each
response from a probability distribution perspective in semantic space. It has
no restriction on task types and is ""off-the-shelf"" for new models and tasks.
Experiments on seven state-of-the-art LLMs, including the latest Llama 3 and
Mixtral-8x22B models, on four free-form question-answering benchmarks
demonstrate the superior performance and robustness of semantic density
compared to prior approaches.",2024-05-22,"Xin Qiu, Risto Miikkulainen",http://arxiv.org/pdf/2405.13845v3,cs.CL
Babysit A Language Model From Scratch: Interactive Language Learning by Trials and Demonstrations,"Humans are efficient language learners and inherently social creatures. Our
language development is largely shaped by our social interactions, for example,
the demonstration and feedback from caregivers. Contrary to human language
learning, recent advancements in large language models have primarily adopted a
non-interactive training paradigm, and refined pre-trained models through
feedback afterward. In this work, we explore how corrective feedback from
interactions influences neural language acquisition from scratch through
systematically controlled experiments, assessing whether it contributes to word
learning efficiency in language models. We introduce a trial-and-demonstration
(TnD) learning framework that incorporates three distinct components: student
trials, teacher demonstrations, and a reward conditioned on language competence
at various developmental stages. Our experiments reveal that the TnD approach
accelerates word acquisition for student models of equal and smaller numbers of
parameters, and we highlight the significance of both trials and
demonstrations. We further show that the teacher's choices of words influence
students' word-specific learning efficiency, and a practice-makes-perfect
effect is evident by a strong correlation between the frequency of words in
trials and their respective learning curves. Our findings suggest that
interactive language learning, with teacher demonstrations and active trials,
can facilitate efficient word learning in language models.",2024-05-22,"Ziqiao Ma, Zekun Wang, Joyce Chai",http://arxiv.org/pdf/2405.13828v2,cs.CL
Towards Comprehensive Post Safety Alignment of Large Language Models via Safety Patching,"Safety alignment of large language models (LLMs) has been gaining increasing
attention. However, current safety-aligned LLMs suffer from the fragile and
imbalanced safety mechanisms, which can still be induced to generate unsafe
responses, exhibit over-safety by rejecting safe user inputs, and fail to
preserve general utility after safety alignment. To this end, we propose a
novel post safety alignment (PSA) method to address these inherent and emerging
safety challenges, including safety enhancement, over-safety mitigation, and
utility preservation. In specific, we introduce \textsc{SafePatching}, a novel
framework for comprehensive PSA, where two distinct safety patches are
developed on the harmful data to enhance safety and mitigate over-safety
concerns, and then seamlessly integrated into the target LLM backbone without
compromising its utility. Extensive experiments on four representative aligned
LLMs, including LLaMA-2/3, Gemma and Mistral, show that \textsc{SafePatching}
achieves a more comprehensive PSA than baseline methods, further optimizing the
balance between being helpful and harmless in current aligned LLMs. Also,
\textsc{SafePatching} demonstrates its superiority in continual PSA scenarios.",2024-05-22,"Weixiang Zhao, Yulin Hu, Zhuojun Li, Yang Deng, Jiahe Guo, Xingyu Sui, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu",http://arxiv.org/pdf/2405.13820v2,cs.CL
Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners,"Recently, Large Language Models (LLMs) have shown impressive language
capabilities. While most of the existing LLMs have very unbalanced performance
across different languages, multilingual alignment based on translation
parallel data is an effective method to enhance the LLMs' multilingual
capabilities. In this work, we discover and comprehensively investigate the
spontaneous multilingual alignment improvement of LLMs. We find that LLMs
instruction-tuned on the question translation data (i.e. without annotated
answers) are able to encourage the alignment between English and a wide range
of languages, even including those unseen during instruction-tuning.
Additionally, we utilize different settings and mechanistic interpretability
methods to analyze the LLM's performance in the multilingual scenario
comprehensively. Our work suggests that LLMs have enormous potential for
improving multilingual alignment efficiently with great language and task
generalization.",2024-05-22,"Shimao Zhang, Changjiang Gao, Wenhao Zhu, Jiajun Chen, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang",http://arxiv.org/pdf/2405.13816v2,cs.CL
"""I Like Sunnie More Than I Expected!"": Exploring User Expectation and Perception of an Anthropomorphic LLM-based Conversational Agent for Well-Being Support","The human-computer interaction (HCI) research community has a longstanding
interest in exploring the mismatch between users' actual experiences and
expectation toward new technologies, for instance, large language models
(LLMs). In this study, we compared users' (N = 38) initial expectations against
their post-interaction perceptions of two LLM-powered mental well-being
intervention activity recommendation systems. Both systems have a built-in LLM
to recommend a personalized well-being intervention activity, but one system
(Sunnie) has an anthropomorphic conversational interaction design via elements
such as appearance, persona, and natural conversation. Results showed that user
engagement was high with both systems, and both systems exceeded users'
expectations along the utility dimension, highlighting AI's potential to offer
useful intervention activity recommendations. In addition, Sunnie further
outperformed the non-anthropomorphic baseline system in relational warmth.
These findings suggest that anthropomorphic conversational interaction design
may be particularly effective in fostering warmth in mental health support
contexts.",2024-05-22,"Siyi Wu, Julie Y. A. Cachia, Feixue Han, Bingsheng Yao, Tianyi Xie, Xuan Zhao, Dakuo Wang",http://arxiv.org/pdf/2405.13803v3,cs.CL
Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models,"We prove a new asymptotic equipartition property for the perplexity of long
texts generated by a language model and present supporting experimental
evidence from open-source models. Specifically we show that the logarithmic
perplexity of any large text generated by a language model must asymptotically
converge to the average entropy of its token distributions. This defines a
""typical set"" that all long synthetic texts generated by a language model must
belong to. We show that this typical set is a vanishingly small subset of all
possible grammatically correct outputs. These results suggest possible
applications to important practical problems such as (a) detecting synthetic
AI-generated text, and (b) testing whether a text was used to train a language
model. We make no simplifying assumptions (such as stationarity) about the
statistics of language model outputs, and therefore our results are directly
applicable to practical real-world models without any approximations.",2024-05-22,"Avinash Mudireddy, Tyler Bell, Raghu Mudumbai",http://arxiv.org/pdf/2405.13798v3,cs.CL
xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token,"This paper introduces xRAG, an innovative context compression method tailored
for retrieval-augmented generation. xRAG reinterprets document embeddings in
dense retrieval--traditionally used solely for retrieval--as features from the
retrieval modality. By employing a modality fusion methodology, xRAG seamlessly
integrates these embeddings into the language model representation space,
effectively eliminating the need for their textual counterparts and achieving
an extreme compression rate. In xRAG, the only trainable component is the
modality bridge, while both the retriever and the language model remain frozen.
This design choice allows for the reuse of offline-constructed document
embeddings and preserves the plug-and-play nature of retrieval augmentation.
Experimental results demonstrate that xRAG achieves an average improvement of
over 10% across six knowledge-intensive tasks, adaptable to various language
model backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts
configuration. xRAG not only significantly outperforms previous context
compression methods but also matches the performance of uncompressed models on
several datasets, while reducing overall FLOPs by a factor of 3.53. Our work
pioneers new directions in retrieval-augmented generation from the perspective
of multimodality fusion, and we hope it lays the foundation for future
efficient and scalable retrieval-augmented systems",2024-05-22,"Xin Cheng, Xun Wang, Xingxing Zhang, Tao Ge, Si-Qing Chen, Furu Wei, Huishuai Zhang, Dongyan Zhao",http://arxiv.org/pdf/2405.13792v2,cs.CL
Do Language Models Enjoy Their Own Stories? Prompting Large Language Models for Automatic Story Evaluation,"Storytelling is an integral part of human experience and plays a crucial role
in social interactions. Thus, Automatic Story Evaluation (ASE) and Generation
(ASG) could benefit society in multiple ways, but they are challenging tasks
which require high-level human abilities such as creativity, reasoning and deep
understanding. Meanwhile, Large Language Models (LLM) now achieve
state-of-the-art performance on many NLP tasks. In this paper, we study whether
LLMs can be used as substitutes for human annotators for ASE. We perform an
extensive analysis of the correlations between LLM ratings, other automatic
measures, and human annotations, and we explore the influence of prompting on
the results and the explainability of LLM behaviour. Most notably, we find that
LLMs outperform current automatic measures for system-level evaluation but
still struggle at providing satisfactory explanations for their answers.",2024-05-22,"Cyril Chhun, Fabian M. Suchanek, Chloé Clavel",http://arxiv.org/pdf/2405.13769v1,cs.CL
DETAIL: Task DEmonsTration Attribution for Interpretable In-context Learning,"In-context learning (ICL) allows transformer-based language models that are
pre-trained on general text to quickly learn a specific task with a few ""task
demonstrations"" without updating their parameters, significantly boosting their
flexibility and generality. ICL possesses many distinct characteristics from
conventional machine learning, thereby requiring new approaches to interpret
this learning paradigm. Taking the viewpoint of recent works showing that
transformers learn in context by formulating an internal optimizer, we propose
an influence function-based attribution technique, DETAIL, that addresses the
specific characteristics of ICL. We empirically verify the effectiveness of our
approach for demonstration attribution while being computationally efficient.
Leveraging the results, we then show how DETAIL can help improve model
performance in real-world scenarios through demonstration reordering and
curation. Finally, we experimentally prove the wide applicability of DETAIL by
showing our attribution scores obtained on white-box models are transferable to
black-box models in improving model performance.",2024-05-22,"Zijian Zhou, Xiaoqiang Lin, Xinyi Xu, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2405.14899v2,cs.CL
Grounding Toxicity in Real-World Events across Languages,"Social media conversations frequently suffer from toxicity, creating
significant issues for users, moderators, and entire communities. Events in the
real world, like elections or conflicts, can initiate and escalate toxic
behavior online. Our study investigates how real-world events influence the
origin and spread of toxicity in online discussions across various languages
and regions. We gathered Reddit data comprising 4.5 million comments from 31
thousand posts in six different languages (Dutch, English, German, Arabic,
Turkish and Spanish). We target fifteen major social and political world events
that occurred between 2020 and 2023. We observe significant variations in
toxicity, negative sentiment, and emotion expressions across different events
and language communities, showing that toxicity is a complex phenomenon in
which many different factors interact and still need to be investigated. We
will release the data for further research along with our code.",2024-05-22,"Wondimagegnhue Tsegaye Tufa, Ilia Markov, Piek Vossen",http://arxiv.org/pdf/2405.13754v1,cs.CL
CrossCheckGPT: Universal Hallucination Ranking for Multimodal Foundation Models,"Multimodal foundation models are prone to hallucination, generating outputs
that either contradict the input or are not grounded by factual information.
Given the diversity in architectures, training data and instruction tuning
techniques, there can be large variations in systems' susceptibility to
hallucinations. To assess system hallucination robustness, hallucination
ranking approaches have been developed for specific tasks such as image
captioning, question answering, summarization, or biography generation.
However, these approaches typically compare model outputs to gold-standard
references or labels, limiting hallucination benchmarking for new domains. This
work proposes ""CrossCheckGPT"", a reference-free universal hallucination ranking
for multimodal foundation models. The core idea of CrossCheckGPT is that the
same hallucinated content is unlikely to be generated by different independent
systems, hence cross-system consistency can provide meaningful and accurate
hallucination assessment scores. CrossCheckGPT can be applied to any model or
task, provided that the information consistency between outputs can be measured
through an appropriate distance metric. Focusing on multimodal large language
models that generate text, we explore two information consistency measures:
CrossCheck-explicit and CrossCheck-implicit. We showcase the applicability of
our method for hallucination ranking across various modalities, namely the
text, image, and audio-visual domains. Further, we propose the first
audio-visual hallucination benchmark, ""AVHalluBench"", and illustrate the
effectiveness of CrossCheckGPT, achieving correlations of 98% and 89% with
human judgements on MHaluBench and AVHalluBench, respectively.",2024-05-22,"Guangzhi Sun, Potsawee Manakul, Adian Liusie, Kunat Pipatanakul, Chao Zhang, Phil Woodland, Mark Gales",http://arxiv.org/pdf/2405.13684v1,cs.CL
Knowledge Graph Reasoning with Self-supervised Reinforcement Learning,"Reinforcement learning (RL) is an effective method of finding reasoning
pathways in incomplete knowledge graphs (KGs). To overcome the challenges of a
large action space, a self-supervised pre-training method is proposed to warm
up the policy network before the RL training stage. To alleviate the
distributional mismatch issue in general self-supervised RL (SSRL), in our
supervised learning (SL) stage, the agent selects actions based on the policy
network and learns from generated labels; this self-generation of labels is the
intuition behind the name self-supervised. With this training framework, the
information density of our SL objective is increased and the agent is prevented
from getting stuck with the early rewarded paths. Our self-supervised RL (SSRL)
method improves the performance of RL by pairing it with the wide coverage
achieved by SL during pretraining, since the breadth of the SL objective makes
it infeasible to train an agent with that alone. We show that our SSRL model
meets or exceeds current state-of-the-art results on all Hits@k and mean
reciprocal rank (MRR) metrics on four large benchmark KG datasets. This SSRL
method can be used as a plug-in for any RL architecture for a KGR task. We
adopt two RL architectures, i.e., MINERVA and MultiHopKG as our baseline RL
models and experimentally show that our SSRL model consistently outperforms
both baselines on all of these four KG reasoning tasks. Full code for the paper
available at
https://github.com/owenonline/Knowledge-Graph-Reasoning-with-Self-supervised-Reinforcement-Learning.",2024-05-22,"Ying Ma, Owen Burns, Mingqiu Wang, Gang Li, Nan Du, Laurent El Shafey, Liqiang Wang, Izhak Shafran, Hagen Soltau",http://arxiv.org/pdf/2405.13640v2,cs.CL
Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation,"We propose a new method to measure the task-specific accuracy of
Retrieval-Augmented Large Language Models (RAG). Evaluation is performed by
scoring the RAG on an automatically-generated synthetic exam composed of
multiple choice questions based on the corpus of documents associated with the
task. Our method is an automated, cost-efficient, interpretable, and robust
strategy to select the optimal components for a RAG system. We leverage Item
Response Theory (IRT) to estimate the quality of an exam and its
informativeness on task-specific accuracy. IRT also provides a natural way to
iteratively improve the exam by eliminating the exam questions that are not
sufficiently informative about a model's ability. We demonstrate our approach
on four new open-ended Question-Answering tasks based on Arxiv abstracts,
StackExchange questions, AWS DevOps troubleshooting guides, and SEC filings. In
addition, our experiments reveal more general insights into factors impacting
RAG performance like size, retrieval mechanism, prompting and fine-tuning. Most
notably, our findings show that choosing the right retrieval algorithms often
leads to bigger performance gains than simply using a larger language model.",2024-05-22,"Gauthier Guinet, Behrooz Omidvar-Tehrani, Anoop Deoras, Laurent Callot",http://arxiv.org/pdf/2405.13622v1,cs.CL
COTET: Cross-view Optimal Transport for Knowledge Graph Entity Typing,"Knowledge graph entity typing (KGET) aims to infer missing entity type
instances in knowledge graphs. Previous research has predominantly centered
around leveraging contextual information associated with entities, which
provides valuable clues for inference. However, they have long ignored the dual
nature of information inherent in entities, encompassing both high-level
coarse-grained cluster knowledge and fine-grained type knowledge. This paper
introduces Cross-view Optimal Transport for knowledge graph Entity Typing
(COTET), a method that effectively incorporates the information on how types
are clustered into the representation of entities and types. COTET comprises
three modules: i) Multi-view Generation and Encoder, which captures structured
knowledge at different levels of granularity through entity-type,
entity-cluster, and type-cluster-type perspectives; ii) Cross-view Optimal
Transport, transporting view-specific embeddings to a unified space by
minimizing the Wasserstein distance from a distributional alignment
perspective; iii) Pooling-based Entity Typing Prediction, employing a mixture
pooling mechanism to aggregate prediction scores from diverse neighbors of an
entity. Additionally, we introduce a distribution-based loss function to
mitigate the occurrence of false negatives during training. Extensive
experiments demonstrate the effectiveness of COTET when compared to existing
baselines.",2024-05-22,"Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan",http://arxiv.org/pdf/2405.13602v1,cs.CL
ConTrans: Weak-to-Strong Alignment Engineering via Concept Transplantation,"Ensuring large language models (LLM) behave consistently with human goals,
values, and intentions is crucial for their safety but yet computationally
expensive. To reduce the computational cost of alignment training of LLMs,
especially for those with a huge number of parameters, and to reutilize learned
value alignment, we propose ConTrans, a novel framework that enables
weak-to-strong alignment transfer via concept transplantation. From the
perspective of representation engineering, ConTrans refines concept vectors in
value alignment from a source LLM (usually a weak yet aligned LLM). The refined
concept vectors are then reformulated to adapt to the target LLM (usually a
strong yet unaligned base LLM) via affine transformation. In the third step,
ConTrans transplants the reformulated concept vectors into the residual stream
of the target LLM. Experiments demonstrate the successful transplantation of a
wide range of aligned concepts from 7B models to 13B and 70B models across
multiple LLMs and LLM families. Remarkably, ConTrans even surpasses
instruction-tuned models in terms of truthfulness. Experiment results validate
the effectiveness of both inter-LLM-family and intra-LLM-family concept
transplantation. Our work successfully demonstrates an alternative way to
achieve weak-to-strong alignment generalization and control.",2024-05-22,"Weilong Dong, Xinwei Wu, Renren Jin, Shaoyang Xu, Deyi Xiong",http://arxiv.org/pdf/2405.13578v2,cs.CL
FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research,"With the advent of large language models (LLMs) and multimodal large language
models (MLLMs), the potential of retrieval-augmented generation (RAG) has
attracted considerable research attention. Various novel algorithms and models
have been introduced to enhance different aspects of RAG systems. However, the
absence of a standardized framework for implementation, coupled with the
inherently complex RAG process, makes it challenging and time-consuming for
researchers to compare and evaluate these approaches in a consistent
environment. Existing RAG toolkits, such as LangChain and LlamaIndex, while
available, are often heavy and inflexibly, failing to meet the customization
needs of researchers. In response to this challenge, we develop \ours{}, an
efficient and modular open-source toolkit designed to assist researchers in
reproducing and comparing existing RAG methods and developing their own
algorithms within a unified framework. Our toolkit has implemented 16 advanced
RAG methods and gathered and organized 38 benchmark datasets. It has various
features, including a customizable modular framework, multimodal RAG
capabilities, a rich collection of pre-implemented RAG works, comprehensive
datasets, efficient auxiliary pre-processing scripts, and extensive and
standard evaluation metrics. Our toolkit and resources are available at
https://github.com/RUC-NLPIR/FlashRAG.",2024-05-22,"Jiajie Jin, Yutao Zhu, Guanting Dong, Yuyao Zhang, Xinyu Yang, Chenghao Zhang, Tong Zhao, Zhao Yang, Zhicheng Dou, Ji-Rong Wen",http://arxiv.org/pdf/2405.13576v2,cs.CL
CPE-Identifier: Automated CPE identification and CVE summaries annotation with Deep Learning and NLP,"With the drastic increase in the number of new vulnerabilities in the
National Vulnerability Database (NVD) every year, the workload for NVD analysts
to associate the Common Platform Enumeration (CPE) with the Common
Vulnerabilities and Exposures (CVE) summaries becomes increasingly laborious
and slow. The delay causes organisations, which depend on NVD for vulnerability
management and security measurement, to be more vulnerable to zero-day attacks.
Thus, it is essential to come out with a technique and tool to extract the CPEs
in the CVE summaries accurately and quickly. In this work, we propose the
CPE-Identifier system, an automated CPE annotating and extracting system, from
the CVE summaries. The system can be used as a tool to identify CPE entities
from new CVE text inputs. Moreover, we also automate the data generating and
labeling processes using deep learning models. Due to the complexity of the CVE
texts, new technical terminologies appear frequently. To identify novel words
in future CVE texts, we apply Natural Language Processing (NLP) Named Entity
Recognition (NER), to identify new technical jargons in the text. Our proposed
model achieves an F1 score of 95.48%, an accuracy score of 99.13%, a precision
of 94.83%, and a recall of 96.14%. We show that it outperforms prior works on
automated CVE-CPE labeling by more than 9% on all metrics.",2024-05-22,"Wanyu Hu, Vrizlynn L. L. Thing",http://arxiv.org/pdf/2405.13568v1,cs.CL
ECLIPSE: Semantic Entropy-LCS for Cross-Lingual Industrial Log Parsing,"Log parsing, a vital task for interpreting the vast and complex data produced
within software architectures faces significant challenges in the transition
from academic benchmarks to the industrial domain. Existing log parsers, while
highly effective on standardized public datasets, struggle to maintain
performance and efficiency when confronted with the sheer scale and diversity
of real-world industrial logs. These challenges are two-fold: 1) massive log
templates: The performance and efficiency of most existing parsers will be
significantly reduced when logs of growing quantities and different lengths; 2)
Complex and changeable semantics: Traditional template-matching algorithms
cannot accurately match the log templates of complicated industrial logs
because they cannot utilize cross-language logs with similar semantics. To
address these issues, we propose ECLIPSE, Enhanced Cross-Lingual Industrial log
Parsing with Semantic Entropy-LCS, since cross-language logs can robustly parse
industrial logs. On the one hand, it integrates two efficient data-driven
template-matching algorithms and Faiss indexing. On the other hand, driven by
the powerful semantic understanding ability of the Large Language Model (LLM),
the semantics of log keywords were accurately extracted, and the retrieval
space was effectively reduced. Notably, we launch a Chinese and English
cross-platform industrial log parsing benchmark ECLIPSE- BENCH to evaluate the
performance of mainstream parsers in industrial scenarios. Our experimental
results across public benchmarks and ECLIPSE- BENCH underscore the superior
performance and robustness of our proposed ECLIPSE. Notably, ECLIPSE both
delivers state-of-the-art performance when compared to strong baselines and
preserves a significant edge in processing efficiency.",2024-05-22,"Wei Zhang, Xianfu Cheng, Yi Zhang, Jian Yang, Hongcheng Guo, Zhoujun Li, Xiaolin Yin, Xiangyuan Guan, Xu Shi, Liangfan Zheng, Bo Zhang",http://arxiv.org/pdf/2405.13548v2,cs.CL
Knowledge-Driven Cross-Document Relation Extraction,"Relation extraction (RE) is a well-known NLP application often treated as a
sentence- or document-level task. However, a handful of recent efforts explore
it across documents or in the cross-document setting (CrossDocRE). This is
distinct from the single document case because different documents often focus
on disparate themes, while text within a document tends to have a single goal.
Linking findings from disparate documents to identify new relationships is at
the core of the popular literature-based knowledge discovery paradigm in
biomedicine and other domains. Current CrossDocRE efforts do not consider
domain knowledge, which are often assumed to be known to the reader when
documents are authored. Here, we propose a novel approach, KXDocRE, that embed
domain knowledge of entities with input text for cross-document RE. Our
proposed framework has three main benefits over baselines: 1) it incorporates
domain knowledge of entities along with documents' text; 2) it offers
interpretability by producing explanatory text for predicted relations between
entities 3) it improves performance over the prior methods.",2024-05-22,"Monika Jain, Raghava Mutharaju, Kuldeep Singh, Ramakanth Kavuluru",http://arxiv.org/pdf/2405.13546v2,cs.CL
Annotation-Efficient Preference Optimization for Language Model Alignment,"Preference optimization is a standard approach to fine-tuning large language
models to align with human preferences. The quality, diversity, and quantity of
the preference dataset are critical to the effectiveness of preference
optimization. However, obtaining a large amount of high-quality and diverse
preference annotations is difficult in many applications. This raises the
question of how to use the limited annotation budget to create an effective
preference dataset. To this end, we propose Annotation-Efficient Preference
Optimization (AEPO). Instead of exhaustively annotating preference over all
available response texts, AEPO selects a subset of responses that maximizes
quality and diversity from the available responses, and then annotates
preference over the selected ones. In this way, AEPO focuses the annotation
budget on labeling preference over a smaller subset of responses with diversity
and of high quality. We evaluate the performance of Direct Preference
Optimization (DPO) using AEPO and show that it outperforms models trained using
a standard DPO with the same annotation budget. Our code is available at
https://github.com/CyberAgentAILab/annotation-efficient-po",2024-05-22,"Yuu Jinnai, Ukyo Honda",http://arxiv.org/pdf/2405.13541v1,cs.CL
Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers,"We address the critical challenge of applying feature attribution methods to
the transformer architecture, which dominates current applications in natural
language processing and beyond. Traditional attribution methods to explainable
AI (XAI) explicitly or implicitly rely on linear or additive surrogate models
to quantify the impact of input features on a model's output. In this work, we
formally prove an alarming incompatibility: transformers are structurally
incapable of representing linear or additive surrogate models used for feature
attribution, undermining the grounding of these conventional explanation
methodologies. To address this discrepancy, we introduce the Softmax-Linked
Additive Log Odds Model (SLALOM), a novel surrogate model specifically designed
to align with the transformer framework. SLALOM demonstrates the capacity to
deliver a range of insightful explanations with both synthetic and real-world
datasets. We highlight SLALOM's unique efficiency-quality curve by showing that
SLALOM can produce explanations with substantially higher fidelity than
competing surrogate models or provide explanations of comparable quality at a
fraction of their computational costs. We release code for SLALOM as an
open-source project online at https://github.com/tleemann/slalom_explanations.",2024-05-22,"Tobias Leemann, Alina Fastowski, Felix Pfeiffer, Gjergji Kasneci",http://arxiv.org/pdf/2405.13536v2,cs.CL
The correlation between nativelike selection and prototypicality: a multilingual onomasiological case study using semantic embedding,"In native speakers' lexical choices, a concept can be more readily expressed
by one expression over another grammatical one, a phenomenon known as
nativelike selection (NLS). In previous research, arbitrary chunks such as
collocations have been considered crucial for this phenomenon. However, this
study examines the possibility of analyzing the semantic motivation and
deducibility behind some NLSs by exploring the correlation between NLS and
prototypicality, specifically the onomasiological hypothesis of Grondelaers and
Geeraerts (2003, Towards a pragmatic model of cognitive onomasiology. In Hubert
Cuyckens, Ren\'e Dirven & John R. Taylor (eds.), Cognitive approaches to
lexical semantics, 67-92. Berlin: De Gruyter Mouton). They hypothesized that
""[a] referent is more readily named by a lexical item if it is a salient member
of the category denoted by that item"". To provide a preliminary investigation
of this important but rarely explored phenomenon, a series of innovative
methods and procedures, including the use of semantic embedding and
interlingual comparisons, is designed. Specifically, potential NLSs are
efficiently discovered through an automatic exploratory analysis using topic
modeling techniques, and then confirmed by manual inspection through frame
semantics. Finally, to account for the NLS in question, cluster analysis and
behavioral profile analysis are conducted to uncover a language-specific
prototype for the Chinese verb shang 'harm', providing supporting evidence for
the correlation between NLS and prototypicality.",2024-05-22,Huasheng Zhang,http://arxiv.org/pdf/2405.13529v1,cs.CL
Intervention-Aware Forecasting: Breaking Historical Limits from a System Perspective,"Traditional time series forecasting methods predominantly rely on historical
data patterns, neglecting external interventions that significantly shape
future dynamics. Through control-theoretic analysis, we show that the implicit
""self-stimulation"" assumption limits the accuracy of these forecasts. To
overcome this limitation, we propose an Intervention-Aware Time Series
Forecasting (IATSF) framework explicitly designed to incorporate external
interventions. We particularly emphasize textual interventions due to their
unique capability to represent qualitative or uncertain influences inadequately
captured by conventional exogenous variables. We propose a leak-free benchmark
composed of temporally synchronized textual intervention data across synthetic
and real-world scenarios. To rigorously evaluate IATSF, we develop FIATS, a
lightweight forecasting model that integrates textual interventions through
Channel-Aware Adaptive Sensitivity Modeling (CASM) and Channel-Aware Parameter
Sharing (CAPS) mechanisms, enabling the model to adjust its sensitivity to
interventions and historical data in a channel-specific manner. Extensive
empirical evaluations confirm that FIATS surpasses state-of-the-art methods,
highlighting that forecasting improvements stem explicitly from modeling
external interventions rather than increased model complexity alone.",2024-05-22,"Zhijian Xu, Hao Wang, Qiang Xu",http://arxiv.org/pdf/2405.13522v3,cs.CL
"WaterPool: A Watermark Mitigating Trade-offs among Imperceptibility, Efficacy and Robustness","With the increasing use of large language models (LLMs) in daily life,
concerns have emerged regarding their potential misuse and societal impact.
Watermarking is proposed to trace the usage of specific models by injecting
patterns into their generated texts. An ideal watermark should produce outputs
that are nearly indistinguishable from those of the original LLM
(imperceptibility), while ensuring a high detection rate (efficacy), even when
the text is partially altered (robustness). Despite many methods having been
proposed, none have simultaneously achieved all three properties, revealing an
inherent trade-off. This paper utilizes a key-centered scheme to unify existing
watermarking techniques by decomposing a watermark into two distinct modules: a
key module and a mark module. Through this decomposition, we demonstrate for
the first time that the key module significantly contributes to the trade-off
issues observed in prior methods. Specifically, this reflects the conflict
between the scale of the key sampling space during generation and the
complexity of key restoration during detection. To this end, we introduce
\textbf{WaterPool}, a simple yet effective key module that preserves a complete
key sampling space required by imperceptibility while utilizing semantics-based
search to improve the key restoration process. WaterPool can integrate with
most watermarks, acting as a plug-in. Our experiments with three well-known
watermarking techniques show that WaterPool significantly enhances their
performance, achieving near-optimal imperceptibility and markedly improving
efficacy and robustness (+12.73\% for KGW, +20.27\% for EXP, +7.27\% for ITS).",2024-05-22,"Baizhou Huang, Xiaojun Wan",http://arxiv.org/pdf/2405.13517v1,cs.CL
LIRE: listwise reward enhancement for preference alignment,"Recently, tremendous strides have been made to align the generation of Large
Language Models (LLMs) with human values to mitigate toxic or unhelpful
content. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves
effective and is widely adopted by researchers. However, implementing RLHF is
complex, and its sensitivity to hyperparameters renders achieving stable
performance and scalability challenging. Furthermore, prevailing approaches to
preference alignment primarily concentrate on pairwise comparisons, with
limited exploration into multi-response scenarios, thereby overlooking the
potential richness within the candidate pool. For the above reasons, we propose
a new approach: Listwise Reward Enhancement for Preference Alignment (LIRE), a
gradient-based reward optimization approach that incorporates the offline
rewards of multiple responses into a streamlined listwise framework, thus
eliminating the need for online sampling during training. LIRE is
straightforward to implement, requiring minimal parameter tuning, and
seamlessly aligns with the pairwise paradigm while naturally extending to
multi-response scenarios. Moreover, we introduce a self-enhancement algorithm
aimed at iteratively refining the reward during training. Our experiments
demonstrate that LIRE consistently outperforms existing methods across several
benchmarks on dialogue and summarization tasks, with good transferability to
out-of-distribution data, assessed using proxy reward models and human
annotators.",2024-05-22,"Mingye Zhu, Yi Liu, Lei Zhang, Junbo Guo, Zhendong Mao",http://arxiv.org/pdf/2405.13516v2,cs.CL
Joint Optimization of Streaming and Non-Streaming Automatic Speech Recognition with Multi-Decoder and Knowledge Distillation,"End-to-end (E2E) automatic speech recognition (ASR) can operate in two modes:
streaming and non-streaming, each with its pros and cons. Streaming ASR
processes the speech frames in real-time as it is being received, while
non-streaming ASR waits for the entire speech utterance; thus, professionals
may have to operate in either mode to satisfy their application. In this work,
we present joint optimization of streaming and non-streaming ASR based on
multi-decoder and knowledge distillation. Primarily, we study 1) the encoder
integration of these ASR modules, followed by 2) separate decoders to make the
switching mode flexible, and enhancing performance by 3) incorporating
similarity-preserving knowledge distillation between the two modular encoders
and decoders. Evaluation results show 2.6%-5.3% relative character error rate
reductions (CERR) on CSJ for streaming ASR, and 8.3%-9.7% relative CERRs for
non-streaming ASR within a single model compared to multiple standalone
modules.",2024-05-22,"Muhammad Shakeel, Yui Sudo, Yifan Peng, Shinji Watanabe",http://arxiv.org/pdf/2405.13514v1,cs.CL
Latent Space Alignment for Semantic Channel Equalization,"We relax the constraint of a shared language between agents in a semantic and
goal-oriented communication system to explore the effect of language mismatch
in distributed task solving. We propose a mathematical framework, which
provides a modelling and a measure of the semantic distortion introduced in the
communication when agents use distinct languages. We then propose a new
approach to semantic channel equalization with proven effectiveness through
numerical evaluations.",2024-05-22,"Tomás Hüttebräucker, Mohamed Sana, Emilio Calvanese Strinati",http://arxiv.org/pdf/2405.13511v2,cs.CL
Big5PersonalityEssays: Introducing a Novel Synthetic Generated Dataset Consisting of Short State-of-Consciousness Essays Annotated Based on the Five Factor Model of Personality,"Given the high advances of large language models (LLM) it is of vital
importance to study their behaviors and apply their utility in all kinds of
scientific fields. Psychology has been, in recent years, poorly approached
using novel computational tools. One of the reasons is the high complexity of
the data required for a proper analysis. Moreover, psychology, with a focus on
psychometry, has few datasets available for analysis and artificial
intelligence usage. Because of these facts, this study introduces a synthethic
database of short essays labeled based on the five factor model (FFM) of
personality traits.",2024-05-22,Iustin Floroiu,http://arxiv.org/pdf/2407.17586v1,cs.CL
Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning,"Instruction tuning aims to align large language models (LLMs) with
open-domain instructions and human-preferred responses. While several studies
have explored autonomous approaches to distilling and annotating instructions
from powerful proprietary LLMs, such as ChatGPT, they often neglect the impact
of the distributions and characteristics of tasks, together with the varying
difficulty of instructions in training sets. This oversight can lead to
imbalanced knowledge capabilities and poor generalization powers of student
LLMs. To address these challenges, we introduce Task-Aware Curriculum Planning
for Instruction Refinement (TAPIR), a multi-round distillation framework that
utilizes an oracle LLM to select instructions that are difficult for a student
LLM to follow. To balance the student's capabilities, task distributions in
training sets are adjusted with responses automatically refined according to
their corresponding tasks. In addition, by incorporating curriculum planning,
our approach systematically escalates the difficulty levels of tasks,
progressively enhancing the student LLM's capabilities. We rigorously evaluate
TAPIR using several widely recognized benchmarks (such as AlpacaEval 2.0,
MT-Bench, etc.) and multiple student LLMs. Empirical results demonstrate that
student LLMs, trained with our method and less training data, outperform larger
instruction-tuned models and strong distillation baselines.",2024-05-22,"Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang",http://arxiv.org/pdf/2405.13448v2,cs.CL
Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction,"Supervised fine-tuning (SFT) on instruction-following corpus is a crucial
approach toward the alignment of large language models (LLMs). However, the
performance of LLMs on standard knowledge and reasoning benchmarks tends to
suffer from deterioration at the latter stage of the SFT process, echoing the
phenomenon of alignment tax. Through our pilot study, we put a hypothesis that
the data biases are probably one cause behind the phenomenon. To address the
issue, we introduce a simple disperse-then-merge framework. To be concrete, we
disperse the instruction-following data into portions and train multiple
sub-models using different data portions. Then we merge multiple models into a
single one via model merging techniques. Despite its simplicity, our framework
outperforms various sophisticated methods such as data curation and training
regularization on a series of standard knowledge and reasoning benchmarks.",2024-05-22,"Tingchen Fu, Deng Cai, Lemao Liu, Shuming Shi, Rui Yan",http://arxiv.org/pdf/2405.13432v1,cs.CL
TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models,"Large language models (LLMs) have raised concerns about potential security
threats despite performing significantly in Natural Language Processing (NLP).
Backdoor attacks initially verified that LLM is doing substantial harm at all
stages, but the cost and robustness have been criticized. Attacking LLMs is
inherently risky in security review, while prohibitively expensive. Besides,
the continuous iteration of LLMs will degrade the robustness of backdoors. In
this paper, we propose TrojanRAG, which employs a joint backdoor attack in the
Retrieval-Augmented Generation, thereby manipulating LLMs in universal attack
scenarios. Specifically, the adversary constructs elaborate target contexts and
trigger sets. Multiple pairs of backdoor shortcuts are orthogonally optimized
by contrastive learning, thus constraining the triggering conditions to a
parameter subspace to improve the matching. To improve the recall of the RAG
for the target contexts, we introduce a knowledge graph to construct structured
data to achieve hard matching at a fine-grained level. Moreover, we normalize
the backdoor scenarios in LLMs to analyze the real harm caused by backdoors
from both attackers' and users' perspectives and further verify whether the
context is a favorable tool for jailbreaking models. Extensive experimental
results on truthfulness, language understanding, and harmfulness show that
TrojanRAG exhibits versatility threats while maintaining retrieval capabilities
on normal queries.",2024-05-22,"Pengzhou Cheng, Yidong Ding, Tianjie Ju, Zongru Wu, Wei Du, Ping Yi, Zhuosheng Zhang, Gongshen Liu",http://arxiv.org/pdf/2405.13401v4,cs.CL
360Zhinao Technical Report,"We present 360Zhinao models with 7B parameter size and context lengths
spanning 4K, 32K and 360K, all available at
https://github.com/Qihoo360/360zhinao. For rapid development in pretraining, we
establish a stable and sensitive ablation environment to evaluate and compare
experiment runs with minimal model size. Under such guidance, we perfect our
data cleaning and composition strategies to pretrain
$\texttt{360Zhinao-7B-Base}$ on 3.4T tokens. We also mainly emphasize data
during alignment, where we strive to balance quantity and quality with
filtering and reformatting. With tailored data, 360Zhinao-7B's context window
is easily extended to 32K and 360K. RMs and RLHF are trained following SFT and
credibly applied to specific tasks. All together these contributions lead to
360Zhinao-7B's competitive performance among models of similar size.",2024-05-22,360Zhinao Team,http://arxiv.org/pdf/2405.13386v1,cs.CL
You don't understand me!: Comparing ASR results for L1 and L2 speakers of Swedish,"The performance of Automatic Speech Recognition (ASR) systems has constantly
increased in state-of-the-art development. However, performance tends to
decrease considerably in more challenging conditions (e.g., background noise,
multiple speaker social conversations) and with more atypical speakers (e.g.,
children, non-native speakers or people with speech disorders), which signifies
that general improvements do not necessarily transfer to applications that rely
on ASR, e.g., educational software for younger students or language learners.
In this study, we focus on the gap in performance between recognition results
for native and non-native, read and spontaneous, Swedish utterances transcribed
by different ASR services. We compare the recognition results using Word Error
Rate and analyze the linguistic factors that may generate the observed
transcription errors.",2024-05-22,"Ronald Cumbal, Birger Moell, Jose Lopes, Olof Engwall",http://arxiv.org/pdf/2405.13379v1,cs.CL
AdpQ: A Zero-shot Calibration Free Adaptive Post Training Quantization Method for LLMs,"The ever-growing computational complexity of Large Language Models (LLMs)
necessitates efficient deployment strategies. The current state-of-the-art
approaches for Post-training Quantization (PTQ) often require calibration to
achieve the desired accuracy. This paper presents AdpQ, a novel zero-shot
adaptive PTQ method for LLMs that achieves the state-of-the-art performance in
low-precision quantization (e.g. 3-bit) without requiring any calibration data.
Inspired by Adaptive LASSO regression model, our proposed approach tackles the
challenge of outlier activations by separating salient weights using an
adaptive soft-thresholding method. Guided by Adaptive LASSO, this method
ensures that the quantized weights distribution closely follows the originally
trained weights and eliminates the need for calibration data entirely, setting
our method apart from popular approaches such as SpQR and AWQ. Furthermore, our
method offers an additional benefit in terms of privacy preservation by
eliminating any calibration or training data. We also delve deeper into the
information-theoretic underpinnings of the proposed method. We demonstrate that
it leverages the Adaptive LASSO to minimize the Kullback-Leibler divergence
between the quantized weights and the originally trained weights. This
minimization ensures the quantized model retains the Shannon information
content of the original model to a great extent, guaranteeing efficient
deployment without sacrificing accuracy or information. Our results achieve the
same accuracy as the existing methods on various LLM benchmarks while the
quantization time is reduced by at least 10x, solidifying our contribution to
efficient and privacy-preserving LLM deployment.",2024-05-22,"Alireza Ghaffari, Sharareh Younesian, Vahid Partovi Nia, Boxing Chen, Masoud Asgharian",http://arxiv.org/pdf/2405.13358v1,cs.CL
Efficacy of ByT5 in Multilingual Translation of Biblical Texts for Underrepresented Languages,"This study presents the development and evaluation of a ByT5-based
multilingual translation model tailored for translating the Bible into
underrepresented languages. Utilizing the comprehensive Johns Hopkins
University Bible Corpus, we trained the model to capture the intricate nuances
of character-based and morphologically rich languages. Our results, measured by
the BLEU score and supplemented with sample translations, suggest the model can
improve accessibility to sacred texts. It effectively handles the distinctive
biblical lexicon and structure, thus bridging the linguistic divide. The study
also discusses the model's limitations and suggests pathways for future
enhancements, focusing on expanding access to sacred literature across
linguistic boundaries.",2024-05-22,"Corinne Aars, Lauren Adams, Xiaokan Tian, Zhaoyu Wang, Colton Wismer, Jason Wu, Pablo Rivas, Korn Sooksatra, Matthew Fendt",http://arxiv.org/pdf/2405.13350v2,cs.CL
Contextualized Automatic Speech Recognition with Dynamic Vocabulary,"Deep biasing (DB) enhances the performance of end-to-end automatic speech
recognition (E2E-ASR) models for rare words or contextual phrases using a bias
list. However, most existing methods treat bias phrases as sequences of
subwords in a predefined static vocabulary. This naive sequence decomposition
produces unnatural token patterns, significantly lowering their occurrence
probability. More advanced techniques address this problem by expanding the
vocabulary with additional modules, including the external language model
shallow fusion or rescoring. However, they result in increasing the workload
due to the additional modules. This paper proposes a dynamic vocabulary where
bias tokens can be added during inference. Each entry in a bias list is
represented as a single token, unlike a sequence of existing subword tokens.
This approach eliminates the need to learn subword dependencies within the bias
phrases. This method is easily applied to various architectures because it only
expands the embedding and output layers in common E2E-ASR architectures.
Experimental results demonstrate that the proposed method improves the bias
phrase WER on English and Japanese datasets by 3.1 -- 4.9 points compared with
the conventional DB method.",2024-05-22,"Yui Sudo, Yosuke Fukumoto, Muhammad Shakeel, Yifan Peng, Shinji Watanabe",http://arxiv.org/pdf/2405.13344v2,cs.CL
High Performance P300 Spellers Using GPT2 Word Prediction With Cross-Subject Training,"Amyotrophic lateral sclerosis (ALS) severely impairs patients' ability to
communicate, often leading to a decline in their quality of life within a few
years of diagnosis. The P300 speller brain-computer interface (BCI) offers an
alternative communication method by interpreting a subject's EEG response to
characters presented on a grid interface.
  This paper addresses the common speed limitations encountered in training
efficient P300-based multi-subject classifiers by introducing innovative
""across-subject"" classifiers. We leverage a combination of the
second-generation Generative Pre-Trained Transformer (GPT2) and Dijkstra's
algorithm to optimize stimuli and suggest word completion choices based on
typing history. Additionally, we employ a multi-layered smoothing technique to
accommodate out-of-vocabulary (OOV) words.
  Through extensive simulations involving random sampling of EEG data from
subjects, we demonstrate significant speed enhancements in typing passages
containing rare and OOV words. These optimizations result in approximately 10%
improvement in character-level typing speed and up to 40% improvement in
multi-word prediction. We demonstrate that augmenting standard row/column
highlighting techniques with layered word prediction yields close-to-optimal
performance.
  Furthermore, we explore both ""within-subject"" and ""across-subject"" training
techniques, showing that speed improvements are consistent across both
approaches.",2024-05-22,"Nithin Parthasarathy, James Soetedjo, Saarang Panchavati, Nitya Parthasarathy, Corey Arnold, Nader Pouratian, William Speier",http://arxiv.org/pdf/2405.13329v1,cs.CL
Mosaic-IT: Free Compositional Data Augmentation Improves Instruction Tuning,"Finetuning large language models with a variety of instruction-response pairs
has enhanced their capability to understand and follow instructions. Current
instruction tuning primarily relies on teacher models or human intervention to
generate and refine the instructions and responses for training, which are
costly, non-sustainable, and may lack diversity. In this paper, we introduce
Mosaic Instruction Tuning (Mosaic-IT), a human/model-free compositional data
augmentation method that can efficiently create rich and diverse augmentations
from existing instruction tuning data to enhance the LLMs. Mosaic-IT randomly
concatenates multiple instruction data into one and trains the model to produce
the corresponding responses with predefined higher-level meta-instructions to
strengthen its multi-step instruction-following and format-following skills.
Our extensive evaluations demonstrate a superior performance and training
efficiency of Mosaic-IT, which achieves consistent performance improvements
over various benchmarks and a $80\%$ reduction in training costs compared with
original instruction tuning. Our codes and data are available at
https://github.com/tianyi-lab/Mosaic-IT.",2024-05-22,"Ming Li, Pei Chen, Chenguang Wang, Hongyu Zhao, Yijun Liang, Yupeng Hou, Fuxiao Liu, Tianyi Zhou",http://arxiv.org/pdf/2405.13326v2,cs.CL
DEGAP: Dual Event-Guided Adaptive Prefixes for Templated-Based Event Argument Extraction with Slot Querying,"Recent advancements in event argument extraction (EAE) involve incorporating
useful auxiliary information into models during training and inference, such as
retrieved instances and event templates. These methods face two challenges: (1)
the retrieval results may be irrelevant and (2) templates are developed
independently for each event without considering their possible relationship.
In this work, we propose DEGAP to address these challenges through a simple yet
effective components: dual prefixes, i.e. learnable prompt vectors, where the
instance-oriented prefix and template-oriented prefix are trained to learn
information from different event instances and templates. Additionally, we
propose an event-guided adaptive gating mechanism, which can adaptively
leverage possible connections between different events and thus capture
relevant information from the prefix. Finally, these event-guided prefixes
provide relevant information as cues to EAE model without retrieval. Extensive
experiments demonstrate that our method achieves new state-of-the-art
performance on four datasets (ACE05, RAMS, WIKIEVENTS, and MLEE). Further
analysis shows the impact of different components.",2024-05-22,"Guanghui Wang, Dexi Liu, Jian-Yun Nie, Qizhi Wan, Rong Hu, Xiping Liu, Wanlong Liu, Jiaming Liu",http://arxiv.org/pdf/2405.13325v3,cs.CL
''You should probably read this'': Hedge Detection in Text,"Humans express ideas, beliefs, and statements through language. The manner of
expression can carry information indicating the author's degree of confidence
in their statement. Understanding the certainty level of a claim is crucial in
areas such as medicine, finance, engineering, and many others where errors can
lead to disastrous results. In this work, we apply a joint model that leverages
words and part-of-speech tags to improve hedge detection in text and achieve a
new top score on the CoNLL-2010 Wikipedia corpus.",2024-05-22,"Denys Katerenchuk, Rivka Levitan",http://arxiv.org/pdf/2405.13319v1,cs.CL
Metadata Integration for Spam Reviews Detection on Vietnamese E-commerce Websites,"The problem of detecting spam reviews (opinions) has received significant
attention in recent years, especially with the rapid development of e-commerce.
Spam reviews are often classified based on comment content, but in some cases,
it is insufficient for models to accurately determine the review label. In this
work, we introduce the ViSpamReviews v2 dataset, which includes metadata of
reviews with the objective of integrating supplementary attributes for spam
review classification. We propose a novel approach to simultaneously integrate
both textual and categorical attributes into the classification model. In our
experiments, the product category proved effective when combined with deep
neural network (DNN) models, while text features performed well on both DNN
models and the model achieved state-of-the-art performance in the problem of
detecting spam reviews on Vietnamese e-commerce websites, namely PhoBERT.
Specifically, the PhoBERT model achieves the highest accuracy when combined
with product description features generated from the SPhoBert model, which is
the combination of PhoBERT and SentenceBERT. Using the macro-averaged F1 score,
the task of classifying spam reviews achieved 87.22% (an increase of 1.64%
compared to the baseline), while the task of identifying the type of spam
reviews achieved an accuracy of 73.49% (an increase of 1.93% compared to the
baseline).",2024-05-22,"Co Van Dinh, Son T. Luu",http://arxiv.org/pdf/2405.13292v2,cs.CL
KU-DMIS at EHRSQL 2024:Generating SQL query via question templatization in EHR,"Transforming natural language questions into SQL queries is crucial for
precise data retrieval from electronic health record (EHR) databases. A
significant challenge in this process is detecting and rejecting unanswerable
questions that request information beyond the database's scope or exceed the
system's capabilities. In this paper, we introduce a novel text-to-SQL
framework that robustly handles out-of-domain questions and verifies the
generated queries with query execution.Our framework begins by standardizing
the structure of questions into a templated format. We use a powerful large
language model (LLM), fine-tuned GPT-3.5 with detailed prompts involving the
table schemas of the EHR database system. Our experimental results demonstrate
the effectiveness of our framework on the EHRSQL-2024 benchmark benchmark, a
shared task in the ClinicalNLP workshop. Although a straightforward fine-tuning
of GPT shows promising results on the development set, it struggled with the
out-of-domain questions in the test set. With our framework, we improve our
system's adaptability and achieve competitive performances in the official
leaderboard of the EHRSQL-2024 challenge.",2024-05-22,"Hajung Kim, Chanhwi Kim, Hoonick Lee, Kyochul Jang, Jiwoo Lee, Kyungjae Lee, Gangwoo Kim, Jaewoo Kang",http://arxiv.org/pdf/2406.00014v2,cs.CL
DiffNorm: Self-Supervised Normalization for Non-autoregressive Speech-to-speech Translation,"Non-autoregressive Transformers (NATs) are recently applied in direct
speech-to-speech translation systems, which convert speech across different
languages without intermediate text data. Although NATs generate high-quality
outputs and offer faster inference than autoregressive models, they tend to
produce incoherent and repetitive results due to complex data distribution
(e.g., acoustic and linguistic variations in speech). In this work, we
introduce DiffNorm, a diffusion-based normalization strategy that simplifies
data distributions for training NAT models. After training with a
self-supervised noise estimation objective, DiffNorm constructs normalized
target data by denoising synthetically corrupted speech features. Additionally,
we propose to regularize NATs with classifier-free guidance, improving model
robustness and translation quality by randomly dropping out source information
during training. Our strategies result in a notable improvement of about +7
ASR-BLEU for English-Spanish (En-Es) and +2 ASR-BLEU for English-French (En-Fr)
translations on the CVSS benchmark, while attaining over 14x speedup for En-Es
and 5x speedup for En-Fr translations compared to autoregressive baselines.",2024-05-22,"Weiting Tan, Jingyu Zhang, Lingfeng Shen, Daniel Khashabi, Philipp Koehn",http://arxiv.org/pdf/2405.13274v2,cs.CL
A Multilingual Similarity Dataset for News Article Frame,"Understanding the writing frame of news articles is vital for addressing
social issues, and thus has attracted notable attention in the fields of
communication studies. Yet, assessing such news article frames remains a
challenge due to the absence of a concrete and unified standard dataset that
considers the comprehensive nuances within news content.
  To address this gap, we introduce an extended version of a large labeled news
article dataset with 16,687 new labeled pairs. Leveraging the pairwise
comparison of news articles, our method frees the work of manual identification
of frame classes in traditional news frame analysis studies. Overall we
introduce the most extensive cross-lingual news article similarity dataset
available to date with 26,555 labeled news article pairs across 10 languages.
Each data point has been meticulously annotated according to a codebook
detailing eight critical aspects of news content, under a human-in-the-loop
framework. Application examples demonstrate its potential in unearthing country
communities within global news coverage, exposing media bias among news
outlets, and quantifying the factors related to news creation. We envision that
this news similarity dataset will broaden our understanding of the media
ecosystem in terms of news coverage of events and perspectives across
countries, locations, languages, and other social constructs. By doing so, it
can catalyze advancements in social science research and applied methodologies,
thereby exerting a profound impact on our society.",2024-05-22,"Xi Chen, Mattia Samory, Scott Hale, David Jurgens, Przemyslaw A. Grabowicz",http://arxiv.org/pdf/2405.13272v1,cs.CL
More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models,"Vision Language Models (VLMs), exemplified by GPT-4V, adeptly integrate text
and vision modalities. This integration enhances Large Language Models' ability
to mimic human perception, allowing them to process image inputs. Despite VLMs'
advanced capabilities, however, there is a concern that VLMs inherit biases of
both modalities in ways that make biases more pervasive and difficult to
mitigate. Our study explores how VLMs perpetuate homogeneity bias and trait
associations with regards to race and gender. When prompted to write stories
based on images of human faces, GPT-4V describes subordinate racial and gender
groups with greater homogeneity than dominant groups and relies on distinct,
yet generally positive, stereotypes. Importantly, VLM stereotyping is driven by
visual cues rather than group membership alone such that faces that are rated
as more prototypically Black and feminine are subject to greater stereotyping.
These findings suggest that VLMs may associate subtle visual cues related to
racial and gender groups with stereotypes in ways that could be challenging to
mitigate. We explore the underlying reasons behind this behavior and discuss
its implications and emphasize the importance of addressing these biases as
VLMs come to mirror human perception.",2024-05-22,"Messi H. J. Lee, Jacob M. Montgomery, Calvin K. Lai",http://arxiv.org/pdf/2407.06194v2,cs.CL
A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings,"With large language models, robots can understand language more flexibly and
more capable than ever before. This survey reviews and situates recent
literature into a spectrum with two poles: 1) mapping between language and some
manually defined formal representation of meaning, and 2) mapping between
language and high-dimensional vector spaces that translate directly to
low-level robot policy. Using a formal representation allows the meaning of the
language to be precisely represented, limits the size of the learning problem,
and leads to a framework for interpretability and formal safety guarantees.
Methods that embed language and perceptual data into high-dimensional spaces
avoid this manually specified symbolic structure and thus have the potential to
be more general when fed enough data but require more data and computing to
train. We discuss the benefits and tradeoffs of each approach and finish by
providing directions for future work that achieves the best of both worlds.",2024-05-21,"Vanya Cohen, Jason Xinyu Liu, Raymond Mooney, Stefanie Tellex, David Watkins",http://arxiv.org/pdf/2405.13245v2,cs.CL
MELD-ST: An Emotion-aware Speech Translation Dataset,"Emotion plays a crucial role in human conversation. This paper underscores
the significance of considering emotion in speech translation. We present the
MELD-ST dataset for the emotion-aware speech translation task, comprising
English-to-Japanese and English-to-German language pairs. Each language pair
includes about 10,000 utterances annotated with emotion labels from the MELD
dataset. Baseline experiments using the SeamlessM4T model on the dataset
indicate that fine-tuning with emotion labels can enhance translation
performance in some settings, highlighting the need for further research in
emotion-aware speech translation systems.",2024-05-21,"Sirou Chen, Sakiko Yahata, Shuichiro Shimizu, Zhengdong Yang, Yihang Li, Chenhui Chu, Sadao Kurohashi",http://arxiv.org/pdf/2405.13233v1,cs.CL
Dataset Decomposition: Faster LLM Training with Variable Sequence Length Curriculum,"Large language models (LLMs) are commonly trained on datasets consisting of
fixed-length token sequences. These datasets are created by randomly
concatenating documents of various lengths and then chunking them into
sequences of a predetermined target length (concat-and-chunk). Recent attention
implementations mask cross-document attention, reducing the effective length of
a chunk of tokens. Additionally, training on long sequences becomes
computationally prohibitive due to the quadratic cost of attention. In this
study, we introduce dataset decomposition, a novel variable sequence length
training technique, to tackle these challenges. We decompose a dataset into a
union of buckets, each containing sequences of the same size extracted from a
unique document. During training, we use variable sequence length and
batch-size, sampling simultaneously from all buckets with a curriculum. In
contrast to the concat-and-chunk baseline, which incurs a fixed attention cost
at every step of training, our proposed method incurs a computational cost
proportional to the actual document lengths at each step, resulting in
significant savings in training time. We train an 8k context-length 1B model at
the same cost as a 2k context-length model trained with the baseline approach.
Experiments on a web-scale corpus demonstrate that our approach significantly
enhances performance on standard language evaluations and long-context
benchmarks, reaching target accuracy with up to 6x faster training compared to
the baseline. Our method not only enables efficient pretraining on long
sequences but also scales effectively with dataset size. Lastly, we shed light
on a critical yet less studied aspect of training large language models: the
distribution and curriculum of sequence lengths, which results in a
non-negligible difference in performance.",2024-05-21,"Hadi Pouransari, Chun-Liang Li, Jen-Hao Rick Chang, Pavan Kumar Anasosalu Vasu, Cem Koc, Vaishaal Shankar, Oncel Tuzel",http://arxiv.org/pdf/2405.13226v2,cs.CL
How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?,"Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs)
are gaining traction in healthcare for their potential to automate patient
interactions and aid clinical decision-making. This study examines the
reliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini
Ultra 1.0, in predicting diseases from patient complaints in the emergency
department. The methodology includes few-shot learning techniques to evaluate
the chatbots' effectiveness in disease prediction. We also fine-tune the
transformer-based model BERT and compare its performance with the AI chatbots.
Results suggest that GPT 4.0 achieves high accuracy with increased few-shot
data, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3
Opus maintains consistent performance. BERT's performance, however, is lower
than all the chatbots, indicating limitations due to limited labeled data.
Despite the chatbots' varying accuracy, none of them are sufficiently reliable
for critical medical decision-making, underscoring the need for rigorous
validation and human oversight. This study reflects that while AI chatbots have
potential in healthcare, they should complement, not replace, human expertise
to ensure patient safety. Further refinement and research are needed to improve
AI-based healthcare applications' reliability for disease prediction.",2024-05-21,"Ayesha Siddika Nipu, K M Sajjadul Islam, Praveen Madiraju",http://arxiv.org/pdf/2405.13219v1,cs.CL
Equipping Transformer with Random-Access Reading for Long-Context Understanding,"Long-context modeling presents a significant challenge for transformer-based
large language models (LLMs) due to the quadratic complexity of the
self-attention mechanism and issues with length extrapolation caused by
pretraining exclusively on short inputs. Existing methods address computational
complexity through techniques such as text chunking, the kernel approach, and
structured attention, and tackle length extrapolation problems through
positional encoding, continued pretraining, and data engineering. These
approaches typically require $\textbf{sequential access}$ to the document,
necessitating reading from the first to the last token. We contend that for
goal-oriented reading of long documents, such sequential access is not
necessary, and a proficiently trained model can learn to omit hundreds of less
pertinent tokens. Inspired by human reading behaviors and existing empirical
observations, we propose $\textbf{random access}$, a novel reading strategy
that enables transformers to efficiently process long documents without
examining every token. Experimental results from pretraining, fine-tuning, and
inference phases validate the efficacy of our method.",2024-05-21,"Chenghao Yang, Zi Yang, Nan Hua",http://arxiv.org/pdf/2405.13216v1,cs.CL
Investigating Symbolic Capabilities of Large Language Models,"Prompting techniques have significantly enhanced the capabilities of Large
Language Models (LLMs) across various complex tasks, including reasoning,
planning, and solving math word problems. However, most research has
predominantly focused on language-based reasoning and word problems, often
overlooking the potential of LLMs in handling symbol-based calculations and
reasoning. This study aims to bridge this gap by rigorously evaluating LLMs on
a series of symbolic tasks, such as addition, multiplication, modulus
arithmetic, numerical precision, and symbolic counting. Our analysis
encompasses eight LLMs, including four enterprise-grade and four open-source
models, of which three have been pre-trained on mathematical tasks. The
assessment framework is anchored in Chomsky's Hierarchy, providing a robust
measure of the computational abilities of these models. The evaluation employs
minimally explained prompts alongside the zero-shot Chain of Thoughts
technique, allowing models to navigate the solution process autonomously. The
findings reveal a significant decline in LLMs' performance on context-free and
context-sensitive symbolic tasks as the complexity, represented by the number
of symbols, increases. Notably, even the fine-tuned GPT3.5 exhibits only
marginal improvements, mirroring the performance trends observed in other
models. Across the board, all models demonstrated a limited generalization
ability on these symbol-intensive tasks. This research underscores LLMs'
challenges with increasing symbolic complexity and highlights the need for
specialized training, memory and architectural adjustments to enhance their
proficiency in symbol-based reasoning tasks.",2024-05-21,"Neisarg Dave, Daniel Kifer, C. Lee Giles, Ankur Mali",http://arxiv.org/pdf/2405.13209v1,cs.CL
Modeling Real-Time Interactive Conversations as Timed Diarized Transcripts,"Chatbots built upon language models have exploded in popularity, but they
have largely been limited to synchronous, turn-by-turn dialogues. In this paper
we present a simple yet general method to simulate real-time interactive
conversations using pretrained text-only language models, by modeling timed
diarized transcripts and decoding them with causal rejection sampling. We
demonstrate the promise of this method with two case studies: instant messenger
dialogues and spoken conversations, which require generation at about 30 tok/s
and 20 tok/s respectively to maintain real-time interactivity. These
capabilities can be added into language models using relatively little data and
run on commodity hardware.",2024-05-21,"Garrett Tanzer, Gustaf Ahdritz, Luke Melas-Kyriazi",http://arxiv.org/pdf/2405.13203v1,cs.CL
Comparative Analysis of Different Efficient Fine Tuning Methods of Large Language Models (LLMs) in Low-Resource Setting,"In the domain of large language models (LLMs), arXiv:2305.16938 showed that
few-shot full-model fine-tuning -- namely Vanilla Fine Tuning (FT) and
Pattern-Based Fine Tuning (PBFT) --, and In-Context Learning (ICL) generalize
similarly on Out-Of-Domain (OOD) datasets, but vary in terms of task
adaptation. However, they both pose challenges, especially in term of memory
requirements. In this paper, we further try to push the understanding of
different fine-tuning strategies for LLM and aim to bring a myriad of these on
the same pedestal for an elaborate comparison with full-model fine-tuning on
two diverse datasets. To that end, we conducted a series of experiments,
beginning with state-of-the-art methods like vanilla fine-tuning and
Pattern-Based Fine-Tuning (PBFT) on pre-trained models across two datasets,
COLA and MNLI. We then investigate adaptive fine-tuning and the efficiency of
LoRA adapters in a few-shot setting. Finally, we also compare an alternative
approach that has gained recent popularity -- context distillation -- with the
vanilla FT and PBFT with and without few-shot setup.
  Our findings suggest that these alternative strategies that we explored can
exhibit out-of-domain generalization comparable to that of vanilla FT and PBFT.
PBFT under-performs Vanilla FT on out-of-domain (OOD) data, emphasizing the
need for effective prompts. Further, our adaptive-fine tuning and LoRA
experiments perform comparable or slightly worse than the standard fine-tunings
as anticipated, since standard fine-tunings involve tuning the entire model.
Finally, our context distillation experiments out-perform the standard
fine-tuning methods. These findings underscore that eventually the choice of an
appropriate fine-tuning method depends on the available resources (memory,
compute, data) and task adaptability.",2024-05-21,"Krishna Prasad Varadarajan Srinivasan, Prasanth Gumpena, Madhusudhana Yattapu, Vishal H. Brahmbhatt",http://arxiv.org/pdf/2405.13181v1,cs.CL
RAG-RLRC-LaySum at BioLaySumm: Integrating Retrieval-Augmented Generation and Readability Control for Layman Summarization of Biomedical Texts,"This paper introduces the RAG-RLRC-LaySum framework, designed to make complex
biomedical research understandable to laymen through advanced Natural Language
Processing (NLP) techniques. Our Retrieval Augmented Generation (RAG) solution,
enhanced by a reranking method, utilizes multiple knowledge sources to ensure
the precision and pertinence of lay summaries. Additionally, our Reinforcement
Learning for Readability Control (RLRC) strategy improves readability, making
scientific content comprehensible to non-specialists. Evaluations using the
publicly accessible PLOS and eLife datasets show that our methods surpass Plain
Gemini model, demonstrating a 20% increase in readability scores, a 15%
improvement in ROUGE-2 relevance scores, and a 10% enhancement in factual
accuracy. The RAG-RLRC-LaySum framework effectively democratizes scientific
knowledge, enhancing public engagement with biomedical discoveries.",2024-05-21,"Yuelyu Ji, Zhuochun Li, Rui Meng, Sonish Sivarajkumar, Yanshan Wang, Zeshui Yu, Hui Ji, Yushui Han, Hanyu Zeng, Daqing He",http://arxiv.org/pdf/2405.13179v4,cs.CL
LLMs for Mathematical Modeling: Towards Bridging the Gap between Natural and Mathematical Languages,"Large Language Models (LLMs) have demonstrated strong performance across
various natural language processing tasks, yet their proficiency in
mathematical reasoning remains a key challenge. Addressing the gap between
natural and mathematical language requires advanced reasoning capabilities,
approaching those of Artificial General Intelligence (AGI). However, the
evaluation remains challenging, as perfectly representing reality is inherently
elusive, and traditional methods like manual or direct comparison of
mathematical statements (Ramamonjison et al., 2023) are insufficient for
assessing true modeling ability. We propose a process-oriented framework to
evaluate LLMs' ability to construct mathematical models, using solvers to
compare outputs with ground truth. Introducing Mamo, a benchmark with 1,209
questions covering ordinary differential equations, linear programming, and
mixed-integer linear programming, we enable automatic evaluation of modeling
accuracy. The results show that existing LLMs struggle with complex
mathematical modeling tasks, with larger models demonstrating superior
performance, while open-source models remain competitive in simpler cases but
still fall short of proprietary models in more challenging problems.",2024-05-21,"Xuhan Huang, Qingning Shen, Yan Hu, Anningzhe Gao, Benyou Wang",http://arxiv.org/pdf/2405.13144v3,cs.CL
Dataset Mention Extraction in Scientific Articles Using Bi-LSTM-CRF Model,"Datasets are critical for scientific research, playing an important role in
replication, reproducibility, and efficiency. Researchers have recently shown
that datasets are becoming more important for science to function properly,
even serving as artifacts of study themselves. However, citing datasets is not
a common or standard practice in spite of recent efforts by data repositories
and funding agencies. This greatly affects our ability to track their usage and
importance. A potential solution to this problem is to automatically extract
dataset mentions from scientific articles. In this work, we propose to achieve
such extraction by using a neural network based on a Bi-LSTM-CRF architecture.
Our method achieves F1 = 0.885 in social science articles released as part of
the Rich Context Dataset. We discuss the limitations of the current datasets
and propose modifications to the model to be done in the future.",2024-05-21,"Tong Zeng, Daniel Acuna",http://arxiv.org/pdf/2405.13135v1,cs.CL
Atomic Self-Consistency for Better Long Form Generations,"Recent work has aimed to improve LLM generations by filtering out
hallucinations, thereby improving the precision of the information in
responses. Correctness of a long-form response, however, also depends on the
recall of multiple pieces of information relevant to the question. In this
paper, we introduce Atomic Self-Consistency (ASC), a technique for improving
the recall of relevant information in an LLM response. ASC follows recent work,
Universal Self-Consistency (USC) in using multiple stochastic samples from an
LLM to improve the long-form response. Unlike USC which only focuses on
selecting the best single generation, ASC picks authentic subparts from the
samples and merges them into a superior composite answer. Through extensive
experiments and ablations, we show that merging relevant subparts of multiple
samples performs significantly better than picking a single sample. ASC
demonstrates significant gains over USC on multiple factoids and open-ended QA
datasets - ASQA, QAMPARI, QUEST, ELI5 with ChatGPT and Llama2. Our analysis
also reveals untapped potential for enhancing long-form generations using
approach of merging multiple samples.",2024-05-21,"Raghuveer Thirukovalluru, Yukun Huang, Bhuwan Dhingra",http://arxiv.org/pdf/2405.13131v1,cs.CL
Towards Retrieval-Augmented Architectures for Image Captioning,"The objective of image captioning models is to bridge the gap between the
visual and linguistic modalities by generating natural language descriptions
that accurately reflect the content of input images. In recent years,
researchers have leveraged deep learning-based models and made advances in the
extraction of visual features and the design of multimodal connections to
tackle this task. This work presents a novel approach towards developing image
captioning models that utilize an external kNN memory to improve the generation
process. Specifically, we propose two model variants that incorporate a
knowledge retriever component that is based on visual similarities, a
differentiable encoder to represent input images, and a kNN-augmented language
model to predict tokens based on contextual cues and text retrieved from the
external memory. We experimentally validate our approach on COCO and nocaps
datasets and demonstrate that incorporating an explicit external memory can
significantly enhance the quality of captions, especially with a larger
retrieval corpus. This work provides valuable insights into retrieval-augmented
captioning models and opens up new avenues for improving image captioning at a
larger scale.",2024-05-21,"Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Alessandro Nicolosi, Rita Cucchiara",http://arxiv.org/pdf/2405.13127v1,cs.CL
Reducing Transformer Key-Value Cache Size with Cross-Layer Attention,"Key-value (KV) caching plays an essential role in accelerating decoding for
transformer-based autoregressive large language models (LLMs). However, the
amount of memory required to store the KV cache can become prohibitive at long
sequence lengths and large batch sizes. Since the invention of the transformer,
two of the most effective interventions discovered for reducing the size of the
KV cache have been Multi-Query Attention (MQA) and its generalization,
Grouped-Query Attention (GQA). MQA and GQA both modify the design of the
attention block so that multiple query heads can share a single key/value head,
reducing the number of distinct key/value heads by a large factor while only
minimally degrading accuracy. In this paper, we show that it is possible to
take Multi-Query Attention a step further by also sharing key and value heads
between adjacent layers, yielding a new attention design we call Cross-Layer
Attention (CLA). With CLA, we find that it is possible to reduce the size of
the KV cache by another 2x while maintaining nearly the same accuracy as
unmodified MQA. In experiments training 1B- and 3B-parameter models from
scratch, we demonstrate that CLA provides a Pareto improvement over the
memory/accuracy tradeoffs which are possible with traditional MQA, enabling
inference with longer sequence lengths and larger batch sizes than would
otherwise be possible",2024-05-21,"William Brandon, Mayank Mishra, Aniruddha Nrusimha, Rameswar Panda, Jonathan Ragan Kelly",http://arxiv.org/pdf/2405.12981v1,cs.CL
Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models,"Recent advancements in Chain-of-Thought prompting have facilitated
significant breakthroughs for Large Language Models (LLMs) in complex reasoning
tasks. Current research enhances the reasoning performance of LLMs by sampling
multiple reasoning chains and ensembling based on the answer frequency.
However, this approach fails in scenarios where the correct answers are in the
minority. We identify this as a primary factor constraining the reasoning
capabilities of LLMs, a limitation that cannot be resolved solely based on the
predicted answers. To address this shortcoming, we introduce a hierarchical
reasoning aggregation framework AoR (Aggregation of Reasoning), which selects
answers based on the evaluation of reasoning chains. Additionally, AoR
incorporates dynamic sampling, adjusting the number of reasoning chains in
accordance with the complexity of the task. Experimental results on a series of
complex reasoning tasks show that AoR outperforms prominent ensemble methods.
Further analysis reveals that AoR not only adapts various LLMs but also
achieves a superior performance ceiling when compared to current methods.",2024-05-21,"Zhangyue Yin, Qiushi Sun, Qipeng Guo, Zhiyuan Zeng, Xiaonan Li, Tianxiang Sun, Cheng Chang, Qinyuan Cheng, Ding Wang, Xiaofeng Mou, Xipeng Qiu, XuanJing Huang",http://arxiv.org/pdf/2405.12939v1,cs.CL
Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs,"Large Language Models (LLMs) have shown remarkable capabilities in tasks such
as summarization, arithmetic reasoning, and question answering. However, they
encounter significant challenges in the domain of moral reasoning and ethical
decision-making, especially in complex scenarios with multiple stakeholders.
This paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing
moral reasoning in LLMs by exploring decisions' consequences from multiple
stakeholder perspectives. Central to SKIG's mechanism is simulating
accountability for actions, which, alongside empathy exercises and risk
assessment, is pivotal to its effectiveness. We validate SKIG's performance
across various moral reasoning benchmarks with proprietary and opensource LLMs,
and investigate its crucial components through extensive ablation analyses.",2024-05-21,"Bilgehan Sel, Priya Shanmugasundaram, Mohammad Kachuee, Kun Zhou, Ruoxi Jia, Ming Jin",http://arxiv.org/pdf/2405.12933v2,cs.CL
Code-mixed Sentiment and Hate-speech Prediction,"Code-mixed discourse combines multiple languages in a single text. It is
commonly used in informal discourse in countries with several official
languages, but also in many other countries in combination with English or
neighboring languages. As recently large language models have dominated most
natural language processing tasks, we investigated their performance in
code-mixed settings for relevant tasks. We first created four new bilingual
pre-trained masked language models for English-Hindi and English-Slovene
languages, specifically aimed to support informal language. Then we performed
an evaluation of monolingual, bilingual, few-lingual, and massively
multilingual models on several languages, using two tasks that frequently
contain code-mixed text, in particular, sentiment analysis and offensive
language detection in social media texts. The results show that the most
successful classifiers are fine-tuned bilingual models and multilingual models,
specialized for social media texts, followed by non-specialized massively
multilingual and monolingual models, while huge generative models are not
competitive. For our affective problems, the models mostly perform slightly
better on code-mixed data compared to non-code-mixed data.",2024-05-21,"Anjali Yadav, Tanya Garg, Matej Klemen, Matej Ulcar, Basant Agarwal, Marko Robnik Sikonja",http://arxiv.org/pdf/2405.12929v1,cs.CL
G-DIG: Towards Gradient-based Diverse and High-quality Instruction Data Selection for Machine Translation,"Large Language Models (LLMs) have demonstrated remarkable abilities in
general scenarios. Instruction finetuning empowers them to align with humans in
various tasks. Nevertheless, the Diversity and Quality of the instruction data
remain two main challenges for instruction finetuning. With regard to this, in
this paper, we propose a novel gradient-based method to automatically select
high-quality and diverse instruction finetuning data for machine translation.
Our key innovation centers around analyzing how individual training examples
influence the model during training. Specifically, we select training examples
that exert beneficial influences on the model as high-quality ones by means of
Influence Function plus a small high-quality seed dataset. Moreover, to enhance
the diversity of the training data we maximize the variety of influences they
have on the model by clustering on their gradients and resampling. Extensive
experiments on WMT22 and FLORES translation tasks demonstrate the superiority
of our methods, and in-depth analysis further validates their effectiveness and
generalization.",2024-05-21,"Xingyuan Pan, Luyang Huang, Liyan Kang, Zhicheng Liu, Yu Lu, Shanbo Cheng",http://arxiv.org/pdf/2405.12915v2,cs.CL
Topic Classification of Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment,"This paper addresses a critical gap in legal analytics by developing and
applying a novel taxonomy for topic classification of summary judgment cases in
the United Kingdom. Using a curated dataset of summary judgment cases, we use
the Large Language Model Claude 3 Opus to explore functional topics and trends.
We find that Claude 3 Opus correctly classified the topic with an accuracy of
87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the
application of summary judgments across various legal domains. As case law in
the United Kingdom is not originally labelled with keywords or a topic
filtering option, the findings not only refine our understanding of the
thematic underpinnings of summary judgments but also illustrate the potential
of combining traditional and AI-driven approaches in legal classification.
Therefore, this paper provides a new and general taxonomy for UK law. The
implications of this work serve as a foundation for further research and policy
discussions in the field of judicial administration and computational legal
research methodologies.",2024-05-21,"Holli Sargeant, Ahmed Izzidien, Felix Steffek",http://arxiv.org/pdf/2405.12910v3,cs.CL
Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents,"Recent advancements in open-domain dialogue systems have been propelled by
the emergence of high-quality large language models (LLMs) and various
effective training methodologies. Nevertheless, the presence of toxicity within
these models presents a significant challenge that can potentially diminish the
user experience. In this study, we introduce an innovative training algorithm,
an improvement upon direct preference optimization (DPO), called adversarial
DPO (ADPO). The ADPO algorithm is designed to train models to assign higher
probability distributions to preferred responses and lower distributions to
unsafe responses, which are self-generated using the toxic control token. We
demonstrate that ADPO enhances the model's resilience against harmful
conversations while minimizing performance degradation. Furthermore, we
illustrate that ADPO offers a more stable training procedure compared to the
traditional DPO. To the best of our knowledge, this is the first adaptation of
the DPO algorithm that directly incorporates harmful data into the generative
model, thereby reducing the need to artificially create safe dialogue data.",2024-05-21,"San Kim, Gary Geunbae Lee",http://arxiv.org/pdf/2405.12900v1,cs.CL
Investigating Persuasion Techniques in Arabic: An Empirical Study Leveraging Large Language Models,"In the current era of digital communication and widespread use of social
media, it is crucial to develop an understanding of persuasive techniques
employed in written text. This knowledge is essential for effectively
discerning accurate information and making informed decisions. To address this
need, this paper presents a comprehensive empirical study focused on
identifying persuasive techniques in Arabic social media content. To achieve
this objective, we utilize Pre-trained Language Models (PLMs) and leverage the
ArAlEval dataset, which encompasses two tasks: binary classification to
determine the presence or absence of persuasion techniques, and multi-label
classification to identify the specific types of techniques employed in the
text. Our study explores three different learning approaches by harnessing the
power of PLMs: feature extraction, fine-tuning, and prompt engineering
techniques. Through extensive experimentation, we find that the fine-tuning
approach yields the highest results on the aforementioned dataset, achieving an
f1-micro score of 0.865 and an f1-weighted score of 0.861. Furthermore, our
analysis sheds light on an interesting finding. While the performance of the
GPT model is relatively lower compared to the other approaches, we have
observed that by employing few-shot learning techniques, we can enhance its
results by up to 20\%. This offers promising directions for future research and
exploration in this topic\footnote{Upon Acceptance, the source code will be
released on GitHub.}.",2024-05-21,"Abdurahmman Alzahrani, Eyad Babkier, Faisal Yanbaawi, Firas Yanbaawi, Hassan Alhuzali",http://arxiv.org/pdf/2405.12884v1,cs.CL
Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in Remote Sensing Images,"Remote sensing image change captioning (RSICC) aims at generating human-like
language to describe the semantic changes between bi-temporal remote sensing
image pairs. It provides valuable insights into environmental dynamics and land
management. Unlike conventional change captioning task, RSICC involves not only
retrieving relevant information across different modalities and generating
fluent captions, but also mitigating the impact of pixel-level differences on
terrain change localization. The pixel problem due to long time span decreases
the accuracy of generated caption. Inspired by the remarkable generative power
of diffusion model, we propose a probabilistic diffusion model for RSICC to
solve the aforementioned problems. In training process, we construct a noise
predictor conditioned on cross modal features to learn the distribution from
the real caption distribution to the standard Gaussian distribution under the
Markov chain. Meanwhile, a cross-mode fusion and a stacking self-attention
module are designed for noise predictor in the reverse process. In testing
phase, the well-trained noise predictor helps to estimate the mean value of the
distribution and generate change captions step by step. Extensive experiments
on the LEVIR-CC dataset demonstrate the effectiveness of our Diffusion-RSCC and
its individual components. The quantitative results showcase superior
performance over existing methods across both traditional and newly augmented
metrics. The code and materials will be available online at
https://github.com/Fay-Y/Diffusion-RSCC.",2024-05-21,"Xiaofei Yu, Yitong Li, Jie Ma",http://arxiv.org/pdf/2405.12875v1,cs.CL
LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language,"Machine learning practitioners often face significant challenges in formally
integrating their prior knowledge and beliefs into predictive models, limiting
the potential for nuanced and context-aware analyses. Moreover, the expertise
needed to integrate this prior knowledge into probabilistic modeling typically
limits the application of these models to specialists. Our goal is to build a
regression model that can process numerical data and make probabilistic
predictions at arbitrary locations, guided by natural language text which
describes a user's prior knowledge. Large Language Models (LLMs) provide a
useful starting point for designing such a tool since they 1) provide an
interface where users can incorporate expert insights in natural language and
2) provide an opportunity for leveraging latent problem-relevant knowledge
encoded in LLMs that users may not have themselves. We start by exploring
strategies for eliciting explicit, coherent numerical predictive distributions
from LLMs. We examine these joint predictive distributions, which we call LLM
Processes, over arbitrarily-many quantities in settings such as forecasting,
multi-dimensional regression, black-box optimization, and image modeling. We
investigate the practical details of prompting to elicit coherent predictive
distributions, and demonstrate their effectiveness at regression. Finally, we
demonstrate the ability to usefully incorporate text into numerical
predictions, improving predictive performance and giving quantitative structure
that reflects qualitative descriptions. This lets us begin to explore the rich,
grounded hypothesis space that LLMs implicitly encode.",2024-05-21,"James Requeima, John Bronskill, Dami Choi, Richard E. Turner, David Duvenaud",http://arxiv.org/pdf/2405.12856v5,cs.CL
Large Language Models Meet NLP: A Survey,"While large language models (LLMs) like ChatGPT have shown impressive
capabilities in Natural Language Processing (NLP) tasks, a systematic
investigation of their potential in this field remains largely unexplored. This
study aims to address this gap by exploring the following questions: (1) How
are LLMs currently applied to NLP tasks in the literature? (2) Have traditional
NLP tasks already been solved with LLMs? (3) What is the future of the LLMs for
NLP? To answer these questions, we take the first step to provide a
comprehensive overview of LLMs in NLP. Specifically, we first introduce a
unified taxonomy including (1) parameter-frozen application and (2)
parameter-tuning application to offer a unified perspective for understanding
the current progress of LLMs in NLP. Furthermore, we summarize the new
frontiers and the associated challenges, aiming to inspire further
groundbreaking advancements. We hope this work offers valuable insights into
the {potential and limitations} of LLMs in NLP, while also serving as a
practical guide for building effective LLMs in NLP.",2024-05-21,"Libo Qin, Qiguang Chen, Xiachong Feng, Yang Wu, Yongheng Zhang, Yinghui Li, Min Li, Wanxiang Che, Philip S. Yu",http://arxiv.org/pdf/2405.12819v1,cs.CL
Presentations are not always linear! GNN meets LLM for Document-to-Presentation Transformation with Attribution,"Automatically generating a presentation from the text of a long document is a
challenging and useful problem. In contrast to a flat summary, a presentation
needs to have a better and non-linear narrative, i.e., the content of a slide
can come from different and non-contiguous parts of the given document.
However, it is difficult to incorporate such non-linear mapping of content to
slides and ensure that the content is faithful to the document. LLMs are prone
to hallucination and their performance degrades with the length of the input
document. Towards this, we propose a novel graph based solution where we learn
a graph from the input document and use a combination of graph neural network
and LLM to generate a presentation with attribution of content for each slide.
We conduct thorough experiments to show the merit of our approach compared to
directly using LLMs for this task.",2024-05-21,"Himanshu Maheshwari, Sambaran Bandyopadhyay, Aparna Garimella, Anandhavelu Natarajan",http://arxiv.org/pdf/2405.13095v1,cs.CL
Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval,"A common retrieve-and-rerank paradigm involves retrieving relevant candidates
from a broad set using a fast bi-encoder (BE), followed by applying expensive
but accurate cross-encoders (CE) to a limited candidate set. However, relying
on this small subset is often susceptible to error propagation from the
bi-encoders, which limits the overall performance. To address these issues, we
propose the Comparing Multiple Candidates (CMC) framework. CMC compares a query
and multiple embeddings of similar candidates (i.e., neighbors) through shallow
self-attention layers, delivering rich representations contextualized to each
other. Furthermore, CMC is scalable enough to handle multiple comparisons
simultaneously. For example, comparing ~10K candidates with CMC takes a similar
amount of time as comparing 16 candidates with CE. Experimental results on the
ZeSHEL dataset demonstrate that CMC, when plugged in between bi-encoders and
cross-encoders as a seamless intermediate reranker (BE-CMC-CE), can effectively
improve recall@k (+4.8%-p, +3.5%-p for R@16, R@64) compared to using only
bi-encoders (BE-CE), with negligible slowdown (<7%). Additionally, to verify
CMC's effectiveness as the final-stage reranker in improving top-1 accuracy, we
conduct experiments on downstream tasks such as entity, passage, and dialogue
ranking. The results indicate that CMC is not only faster (11x) but also often
more effective than CE, with improved prediction accuracy in Wikipedia entity
linking (+0.7%-p) and DSTC7 dialogue ranking (+3.3%-p).",2024-05-21,"Jonghyun Song, Cheyon Jin, Wenlong Zhao, Andrew McCallum, Jay-Yoon Lee",http://arxiv.org/pdf/2405.12801v2,cs.CL
What Have We Achieved on Non-autoregressive Translation?,"Recent advances have made non-autoregressive (NAT) translation comparable to
autoregressive methods (AT). However, their evaluation using BLEU has been
shown to weakly correlate with human annotations. Limited research compares
non-autoregressive translation and autoregressive translation comprehensively,
leaving uncertainty about the true proximity of NAT to AT. To address this gap,
we systematically evaluate four representative NAT methods across various
dimensions, including human evaluation. Our empirical results demonstrate that
despite narrowing the performance gap, state-of-the-art NAT still underperforms
AT under more reliable evaluation metrics. Furthermore, we discover that
explicitly modeling dependencies is crucial for generating natural language and
generalizing to out-of-distribution sequences.",2024-05-21,"Yafu Li, Huajian Zhang, Jianhao Yan, Yongjing Yin, Yue Zhang",http://arxiv.org/pdf/2405.12788v1,cs.CL
Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances,"Discovering the semantics of multimodal utterances is essential for
understanding human language and enhancing human-machine interactions. Existing
methods manifest limitations in leveraging nonverbal information for discerning
complex semantics in unsupervised scenarios. This paper introduces a novel
unsupervised multimodal clustering method (UMC), making a pioneering
contribution to this field. UMC introduces a unique approach to constructing
augmentation views for multimodal data, which are then used to perform
pre-training to establish well-initialized representations for subsequent
clustering. An innovative strategy is proposed to dynamically select
high-quality samples as guidance for representation learning, gauged by the
density of each sample's nearest neighbors. Besides, it is equipped to
automatically determine the optimal value for the top-$K$ parameter in each
cluster to refine sample selection. Finally, both high- and low-quality samples
are used to learn representations conducive to effective clustering. We build
baselines on benchmark multimodal intent and dialogue act datasets. UMC shows
remarkable improvements of 2-6\% scores in clustering metrics over
state-of-the-art methods, marking the first successful endeavor in this domain.
The complete code and data are available at https://github.com/thuiar/UMC.",2024-05-21,"Hanlei Zhang, Hua Xu, Fei Long, Xin Wang, Kai Gao",http://arxiv.org/pdf/2405.12775v1,cs.CL
The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM Fine-tuning,"Texts written in different languages reflect different culturally-dependent
beliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are
jointly trained on a concatenation of text in multiple languages, to encode
different cultural values for each language. Yet, as the 'multilinguality' of
these LMs is driven by cross-lingual sharing, we also have reason to belief
that cultural values bleed over from one language into another. This limits the
use of MLMs in practice, as apart from being proficient in generating text in
multiple languages, creating language technology that can serve a community
also requires the output of LMs to be sensitive to their biases (Naous et al.,
2023). Yet, little is known about how cultural values emerge and evolve in MLMs
(Hershcovich et al., 2022a). We are the first to study how languages can exert
influence on the cultural values encoded for different test languages, by
studying how such values are revised during fine-tuning. Focusing on the
fine-tuning stage allows us to study the interplay between value shifts when
exposed to new linguistic experience from different data sources and languages.
Lastly, we use a training data attribution method to find patterns in the
fine-tuning examples, and the languages that they come from, that tend to
instigate value shifts.",2024-05-21,"Rochelle Choenni, Anne Lauscher, Ekaterina Shutova",http://arxiv.org/pdf/2405.12744v1,cs.CL
RecGPT: Generative Pre-training for Text-based Recommendation,"We present the first domain-adapted and fully-trained large language model,
RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for
text-based recommendation. Experimental results on rating prediction and
sequential recommendation tasks show that our model, RecGPT-7B-Instruct,
outperforms previous strong baselines. We are releasing our RecGPT models as
well as their pre-training and fine-tuning datasets to facilitate future
research and downstream applications in text-based recommendation. Public
""huggingface"" links to our RecGPT models and datasets are available at:
https://github.com/VinAIResearch/RecGPT",2024-05-21,"Hoang Ngo, Dat Quoc Nguyen",http://arxiv.org/pdf/2405.12715v1,cs.CL
From Human-to-Human to Human-to-Bot Conversations in Software Engineering,"Software developers use natural language to interact not only with other
humans, but increasingly also with chatbots. These interactions have different
properties and flow differently based on what goal the developer wants to
achieve and who they interact with. In this paper, we aim to understand the
dynamics of conversations that occur during modern software development after
the integration of AI and chatbots, enabling a deeper recognition of the
advantages and disadvantages of including chatbot interactions in addition to
human conversations in collaborative work. We compile existing conversation
attributes with humans and NLU-based chatbots and adapt them to the context of
software development. Then, we extend the comparison to include LLM-powered
chatbots based on an observational study. We present similarities and
differences between human-to-human and human-to-bot conversations, also
distinguishing between NLU- and LLM-based chatbots. Furthermore, we discuss how
understanding the differences among the conversation styles guides the
developer on how to shape their expectations from a conversation and
consequently support the communication within a software team. We conclude that
the recent conversation styles that we observe with LLM-chatbots can not
replace conversations with humans due to certain attributes regarding social
aspects despite their ability to support productivity and decrease the
developers' mental load.",2024-05-21,"Ranim Khojah, Francisco Gomes de Oliveira Neto, Philipp Leitner",http://arxiv.org/pdf/2405.12712v1,cs.CL
Multimodal Adaptive Inference for Document Image Classification with Anytime Early Exiting,"This work addresses the need for a balanced approach between performance and
efficiency in scalable production environments for visually-rich document
understanding (VDU) tasks. Currently, there is a reliance on large document
foundation models that offer advanced capabilities but come with a heavy
computational burden. In this paper, we propose a multimodal early exit (EE)
model design that incorporates various training strategies, exit layer types
and placements. Our goal is to achieve a Pareto-optimal balance between
predictive performance and efficiency for multimodal document image
classification. Through a comprehensive set of experiments, we compare our
approach with traditional exit policies and showcase an improved
performance-efficiency trade-off. Our multimodal EE design preserves the
model's predictive capabilities, enhancing both speed and latency. This is
achieved through a reduction of over 20% in latency, while fully retaining the
baseline accuracy. This research represents the first exploration of multimodal
EE design within the VDU community, highlighting as well the effectiveness of
calibration in improving confidence scores for exiting at different layers.
Overall, our findings contribute to practical VDU applications by enhancing
both performance and efficiency.",2024-05-21,"Omar Hamed, Souhail Bakkali, Marie-Francine Moens, Matthew Blaschko, Jordy Van Landeghem",http://arxiv.org/pdf/2405.12705v1,cs.CL
OLAPH: Improving Factuality in Biomedical Long-form Question Answering,"In the medical domain, numerous scenarios necessitate the long-form
generation ability of large language models (LLMs). Specifically, when
addressing patients' questions, it is essential that the model's response
conveys factual claims, highlighting the need for an automated method to
evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset
reconstructed using long-form question-answering datasets related to the
biomedical domain. We use MedLFQA to facilitate a cost-effective automatic
evaluations of factuality. We also propose OLAPH, a simple and novel framework
that utilizes cost-effective and multifaceted automatic evaluation to construct
a synthetic preference set and answers questions in our preferred manner. Our
framework leads us to train LLMs step-by-step to reduce hallucinations and
include crucial medical claims. We highlight that, even on evaluation metrics
not used during training, LLMs trained with our OLAPH framework demonstrate
significant performance improvement in factuality. Our findings reveal that a
7B LLM trained with our OLAPH framework can provide long answers comparable to
the medical experts' answers in terms of factuality. We believe that our work
could shed light on gauging the long-text generation ability of LLMs in the
medical domain. Our code and datasets are available.",2024-05-21,"Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang",http://arxiv.org/pdf/2405.12701v3,cs.CL
Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text,"AI-generated text detection has attracted increasing attention as powerful
language models approach human-level generation. Limited work is devoted to
detecting (partially) AI-paraphrased texts. However, AI paraphrasing is
commonly employed in various application scenarios for text refinement and
diversity. To this end, we propose a novel detection framework, paraphrased
text span detection (PTD), aiming to identify paraphrased text spans within a
text. Different from text-level detection, PTD takes in the full text and
assigns each of the sentences with a score indicating the paraphrasing degree.
We construct a dedicated dataset, PASTED, for paraphrased text span detection.
Both in-distribution and out-of-distribution results demonstrate the
effectiveness of PTD models in identifying AI-paraphrased text spans.
Statistical and model analysis explains the crucial role of the surrounding
context of the paraphrased text spans. Extensive experiments show that PTD
models can generalize to versatile paraphrasing prompts and multiple
paraphrased text spans. We release our resources at
https://github.com/Linzwcs/PASTED.",2024-05-21,"Yafu Li, Zhilin Wang, Leyang Cui, Wei Bi, Shuming Shi, Yue Zhang",http://arxiv.org/pdf/2405.12689v2,cs.CL
"A Survey on Multi-modal Machine Translation: Tasks, Methods and Challenges","In recent years, multi-modal machine translation has attracted significant
interest in both academia and industry due to its superior performance. It
takes both textual and visual modalities as inputs, leveraging visual context
to tackle the ambiguities in source texts. In this paper, we begin by offering
an exhaustive overview of 99 prior works, comprehensively summarizing
representative studies from the perspectives of dominant models, datasets, and
evaluation metrics. Afterwards, we analyze the impact of various factors on
model performance and finally discuss the possible research directions for this
task in the future. Over time, multi-modal machine translation has developed
more types to meet diverse needs. Unlike previous surveys confined to the early
stage of multi-modal machine translation, our survey thoroughly concludes these
emerging types from different aspects, so as to provide researchers with a
better understanding of its current state.",2024-05-21,"Huangjun Shen, Liangying Shao, Wenbo Li, Zhibin Lan, Zhanyu Liu, Jinsong Su",http://arxiv.org/pdf/2405.12669v2,cs.CL
Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction,"Extrapolation in Large language models (LLMs) for open-ended inquiry
encounters two pivotal issues: (1) hallucination and (2) expensive training
costs. These issues present challenges for LLMs in specialized domains and
personalized data, requiring truthful responses and low fine-tuning costs.
Existing works attempt to tackle the problem by augmenting the input of a
smaller language model with information from a knowledge graph (KG). However,
they have two limitations: (1) failing to extract relevant information from a
large one-hop neighborhood in KG and (2) applying the same augmentation
strategy for KGs with different characteristics that may result in low
performance. Moreover, open-ended inquiry typically yields multiple responses,
further complicating extrapolation. We propose a new task, the extreme
multi-label KG link prediction task, to enable a model to perform extrapolation
with multiple responses using structured real-world knowledge. Our retriever
identifies relevant one-hop neighbors by considering entity, relation, and
textual data together. Our experiments demonstrate that (1) KGs with different
characteristics require different augmenting strategies, and (2) augmenting the
language model's input with textual data improves task performance
significantly. By incorporating the retrieval-augmented framework with KG, our
framework, with a small parameter size, is able to extrapolate based on a given
KG. The code can be obtained on GitHub:
https://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git",2024-05-21,"Yu-Hsiang Lin, Huang-Ting Shieh, Chih-Yu Liu, Kuang-Ting Lee, Hsiao-Cheng Chang, Jing-Lun Yang, Yu-Sheng Lin",http://arxiv.org/pdf/2405.12656v1,cs.CL
Exploration of Masked and Causal Language Modelling for Text Generation,"Large Language Models (LLMs) have revolutionised the field of Natural
Language Processing (NLP) and have achieved state-of-the-art performance in
practically every task in this field. However, the prevalent approach used in
text generation, Causal Language Modelling (CLM), which generates text
sequentially from left to right, inherently limits the freedom of the model,
which does not decide when and where each token is generated. In contrast,
Masked Language Modelling (MLM), primarily used for language understanding
tasks, can generate tokens anywhere in the text and any order. This paper
conducts an extensive comparison of MLM and CLM approaches for text generation
tasks. To do so, we pre-train several language models of comparable sizes on
three different datasets, namely 1) medical discharge summaries, 2) movie plot
synopses, and 3) authorship verification datasets. To assess the quality of the
generations, we first employ quantitative metrics and then perform a
qualitative human evaluation to analyse coherence and grammatical correctness.
In addition, we evaluate the usefulness of the generated texts by using them in
three different downstream tasks: 1) Entity Recognition, 2) Text
Classification, and 3) Authorship Verification. The results show that MLM
consistently outperforms CLM in text generation across all datasets, with
higher quantitative scores and better coherence in the generated text. The
study also finds \textit{no strong correlation} between the quality of the
generated text and the performance of the models in the downstream tasks. With
this study, we show that MLM for text generation has great potential for future
research and provides direction for future studies in this area.",2024-05-21,"Nicolo Micheletti, Samuel Belkadi, Lifeng Han, Goran Nenadic",http://arxiv.org/pdf/2405.12630v2,cs.CL
MentalQA: An Annotated Arabic Corpus for Questions and Answers of Mental Healthcare,"Mental health disorders significantly impact people globally, regardless of
background, education, or socioeconomic status. However, access to adequate
care remains a challenge, particularly for underserved communities with limited
resources. Text mining tools offer immense potential to support mental
healthcare by assisting professionals in diagnosing and treating patients. This
study addresses the scarcity of Arabic mental health resources for developing
such tools. We introduce MentalQA, a novel Arabic dataset featuring
conversational-style question-and-answer (QA) interactions. To ensure data
quality, we conducted a rigorous annotation process using a well-defined schema
with quality control measures. Data was collected from a question-answering
medical platform. The annotation schema for mental health questions and
corresponding answers draws upon existing classification schemes with some
modifications. Question types encompass six distinct categories: diagnosis,
treatment, anatomy \& physiology, epidemiology, healthy lifestyle, and provider
choice. Answer strategies include information provision, direct guidance, and
emotional support. Three experienced annotators collaboratively annotated the
data to ensure consistency. Our findings demonstrate high inter-annotator
agreement, with Fleiss' Kappa of $0.61$ for question types and $0.98$ for
answer strategies. In-depth analysis revealed insightful patterns, including
variations in question preferences across age groups and a strong correlation
between question types and answer strategies. MentalQA offers a valuable
foundation for developing Arabic text mining tools capable of supporting mental
health professionals and individuals seeking information.",2024-05-21,"Hassan Alhuzali, Ashwag Alasmari, Hamad Alsaleh",http://arxiv.org/pdf/2405.12619v1,cs.CL
Quantifying Semantic Emergence in Language Models,"Large language models (LLMs) are widely recognized for their exceptional
capacity to capture semantics meaning. Yet, there remains no established metric
to quantify this capability. In this work, we introduce a quantitative metric,
Information Emergence (IE), designed to measure LLMs' ability to extract
semantics from input tokens. We formalize ``semantics'' as the meaningful
information abstracted from a sequence of tokens and quantify this by comparing
the entropy reduction observed for a sequence of tokens (macro-level) and
individual tokens (micro-level). To achieve this, we design a lightweight
estimator to compute the mutual information at each transformer layer, which is
agnostic to different tasks and language model architectures. We apply IE in
both synthetic in-context learning (ICL) scenarios and natural sentence
contexts. Experiments demonstrate informativeness and patterns about semantics.
While some of these patterns confirm the conventional prior linguistic
knowledge, the rest are relatively unexpected, which may provide new insights.",2024-05-21,"Hang Chen, Xinyu Yang, Jiaying Zhu, Wenya Wang",http://arxiv.org/pdf/2405.12617v2,cs.CL
Tagengo: A Multilingual Chat Dataset,"Open source large language models (LLMs) have shown great improvements in
recent times. However, many of these models are focused solely on popular
spoken languages. We present a high quality dataset of more than 70k
prompt-response pairs in 74 languages which consist of human generated prompts
and synthetic responses. We use this dataset to train a state-of-the-art open
source English LLM to chat multilingually. We evaluate our model on MT-Bench
chat benchmarks in 6 languages, finding that our multilingual model outperforms
previous state-of-the-art open source LLMs across each language. We further
find that training on more multilingual data is beneficial to the performance
in a chosen target language (Japanese) compared to simply training on only data
in that language. These results indicate the necessity of training on large
amounts of high quality multilingual data to make a more accessible LLM.",2024-05-21,Peter Devine,http://arxiv.org/pdf/2405.12612v1,cs.CL
Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming,"With the proliferation of red-teaming strategies for Large Language Models
(LLMs), the deficiency in the literature about improving the safety and
robustness of LLM defense strategies is becoming increasingly pronounced. This
paper introduces the LLM-based \textbf{sentinel} model as a plug-and-play
prefix module designed to reconstruct the input prompt with just a few ($<30$)
additional tokens, effectively reducing toxicity in responses from target LLMs.
The sentinel model naturally overcomes the \textit{parameter inefficiency} and
\textit{limited model accessibility} for fine-tuning large target models. We
employ an interleaved training regimen using Proximal Policy Optimization (PPO)
to optimize both red team and sentinel models dynamically, incorporating a
value head-sharing mechanism inspired by the multi-agent centralized critic to
manage the complex interplay between agents. Our extensive experiments across
text-to-text and text-to-image demonstrate the effectiveness of our approach in
mitigating toxic outputs, even when dealing with larger models like
\texttt{Llama-2}, \texttt{GPT-3.5} and \texttt{Stable-Diffusion}, highlighting
the potential of our framework in enhancing safety and robustness in various
applications.",2024-05-21,"Jiaxu Liu, Xiangyu Yin, Sihao Wu, Jianhong Wang, Meng Fang, Xinping Yi, Xiaowei Huang",http://arxiv.org/pdf/2405.12604v2,cs.CL
Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression,"Key-value~(KV) caching is an important technique to accelerate the inference
of large language models~(LLMs), but incurs significant memory overhead. To
compress the size of KV cache, existing methods often compromise precision or
require extra data for calibration, limiting their practicality in LLM
deployment. In this paper, we introduce \textbf{DecoQuant}, a novel data-free
low-bit quantization technique based on tensor decomposition methods, to
effectively compress KV cache. Our core idea is to adjust the outlier
distribution of the original matrix by performing tensor decomposition, so that
the quantization difficulties are migrated from the matrix to decomposed local
tensors. Specially, we find that outliers mainly concentrate on small local
tensors, while large tensors tend to have a narrower value range. Based on this
finding, we propose to apply low-bit quantization to the large tensor, while
maintaining high-precision representation for the small tensor. Furthermore, we
utilize the proposed quantization method to compress the KV cache of LLMs to
accelerate the inference and develop an efficient dequantization kernel
tailored specifically for DecoQuant. Through extensive experiments, DecoQuant
demonstrates remarkable efficiency gains, showcasing up to a $\sim$75\%
reduction in memory footprint while maintaining comparable generation quality.",2024-05-21,"Peiyu Liu, Ze-Feng Gao, Wayne Xin Zhao, Yipeng Ma, Tao Wang, Ji-Rong Wen",http://arxiv.org/pdf/2405.12591v1,cs.CL
Mining the Explainability and Generalization: Fact Verification Based on Self-Instruction,"Fact-checking based on commercial LLMs has become mainstream. Although these
methods offer high explainability, it falls short in accuracy compared to
traditional fine-tuning approaches, and data security is also a significant
concern. In this paper, we propose a self-instruction based fine-tuning
approach for fact-checking that balances accuracy and explainability. Our
method consists of Data Augmentation and Improved DPO fine-tuning. The former
starts by instructing the model to generate both positive and negative
explanations based on claim-evidence pairs and labels, then sampling the
dataset according to our customized difficulty standards. The latter employs
our proposed improved DPO to fine-tune the model using the generated samples.
We fine-tune the smallest-scale LLaMA-7B model and evaluate it on the
challenging fact-checking datasets FEVEROUS and HOVER, utilizing four
fine-tuning methods and three few-shot learning methods for comparison. The
experiments demonstrate that our approach not only retains accuracy comparable
to, or even surpassing, traditional fine-tuning methods, but also generates
fluent explanation text. Moreover, it also exhibit high generalization
performance. Our method is the first to leverage self-supervised learning for
fact-checking and innovatively combines contrastive learning and improved DPO
in fine-tuning LLMs, as shown in the experiments.",2024-05-21,"Guangyao Lu, Yulin Liu",http://arxiv.org/pdf/2405.12579v2,cs.CL
Multi-domain Knowledge Graph Collaborative Pre-training and Prompt Tuning for Diverse Downstream Tasks,"Knowledge graphs (KGs) provide reliable external knowledge for a wide variety
of AI tasks in the form of structured triples. Knowledge graph pre-training
(KGP) aims to pre-train neural networks on large-scale KGs and provide unified
interfaces to enhance different downstream tasks, which is a key direction for
KG management, maintenance, and applications. Existing works often focus on
purely research questions in open domains, or they are not open source due to
data security and privacy in real scenarios. Meanwhile, existing studies have
not explored the training efficiency and transferability of KGP models in
depth. To address these problems, We propose a framework MuDoK to achieve
multi-domain collaborative pre-training and efficient prefix prompt tuning to
serve diverse downstream tasks like recommendation and text understanding. Our
design is a plug-and-play prompt learning approach that can be flexibly adapted
to different downstream task backbones. In response to the lack of open-source
benchmarks, we constructed a new multi-domain KGP benchmark called KPI with two
large-scale KGs and six different sub-domain tasks to evaluate our method and
open-sourced it for subsequent research. We evaluated our approach based on
constructed KPI benchmarks using diverse backbone models in heterogeneous
downstream tasks. The experimental results show that our framework brings
significant performance gains, along with its generality, efficiency, and
transferability.",2024-05-21,"Yichi Zhang, Binbin Hu, Zhuo Chen, Lingbing Guo, Ziqi Liu, Zhiqiang Zhang, Lei Liang, Huajun Chen, Wen Zhang",http://arxiv.org/pdf/2405.13085v1,cs.CL
ProtT3: Protein-to-Text Generation for Text-based Protein Understanding,"Language Models (LMs) excel in understanding textual descriptions of
proteins, as evident in biomedical question-answering tasks. However, their
capability falters with raw protein data, such as amino acid sequences, due to
a deficit in pretraining on such data. Conversely, Protein Language Models
(PLMs) can understand and convert protein data into high-quality
representations, but struggle to process texts. To address their limitations,
we introduce ProtT3, a framework for Protein-to-Text Generation for Text-based
Protein Understanding. ProtT3 empowers an LM to understand protein sequences of
amino acids by incorporating a PLM as its protein understanding module,
enabling effective protein-to-text generation. This collaboration between PLM
and LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges
the modality gap between the PLM's representation space and the LM's input
space. Unlike previous studies focusing on protein property prediction and
protein-text retrieval, we delve into the largely unexplored field of
protein-to-text generation. To facilitate comprehensive benchmarks and promote
future research, we establish quantitative evaluations for protein-text
modeling tasks, including protein captioning, protein question-answering, and
protein-text retrieval. Our experiments show that ProtT3 substantially
surpasses current baselines, with ablation studies further highlighting the
efficacy of its core components. Our code is available at
https://github.com/acharkq/ProtT3.",2024-05-21,"Zhiyuan Liu, An Zhang, Hao Fei, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua",http://arxiv.org/pdf/2405.12564v1,cs.CL
The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG),"Recently, increasing research interests have focused on retrieval augmented
generation (RAG) to mitigate hallucination for large language models (LLMs).
Following this trend, we launch the FutureDial-RAG challenge at SLT 2024, which
aims at promoting the study of RAG for dialog systems. The challenge builds
upon the MobileCS2 dataset, a real-life customer service datasets with nearly
3000 high-quality dialogs containing annotations for knowledge base query and
corresponding results. Over the dataset, we define two tasks, track 1 for
knowledge retrieval and track 2 for response generation, which are core
research questions in dialog systems with RAG. We build baseline systems for
the two tracks and design metrics to measure whether the systems can perform
accurate retrieval and generate informative and coherent response. The baseline
results show that it is very challenging to perform well on the two tasks,
which encourages the participating teams and the community to study how to make
better use of RAG for real-life dialog systems.",2024-05-21,"Yucheng Cai, Si Chen, Yuxuan Wu, Yi Huang, Junlan Feng, Zhijian Ou",http://arxiv.org/pdf/2405.13084v2,cs.CL
PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference,"Large Language Models (LLMs) have shown remarkable comprehension abilities
but face challenges in GPU memory usage during inference, hindering their
scalability for real-time applications like chatbots. To accelerate inference,
we store computed keys and values (KV cache) in the GPU memory. Existing
methods study the KV cache compression to reduce memory by pruning the
pre-computed KV cache. However, they neglect the inter-layer dependency between
layers and huge memory consumption in pre-computation. To explore these
deficiencies, we find that the number of crucial keys and values that influence
future generations decreases layer by layer and we can extract them by the
consistency in attention weights. Based on the findings, we propose
PyramidInfer, a method that compresses the KV cache by layer-wise retaining
crucial context. PyramidInfer saves significant memory by computing fewer keys
and values without sacrificing performance. Experimental results show
PyramidInfer improves 2.2x throughput compared to Accelerate with over 54% GPU
memory reduction in KV cache.",2024-05-21,"Dongjie Yang, XiaoDong Han, Yan Gao, Yao Hu, Shilin Zhang, Hai Zhao",http://arxiv.org/pdf/2405.12532v2,cs.CL
SirLLM: Streaming Infinite Retentive LLM,"As Large Language Models (LLMs) become increasingly prevalent in various
domains, their ability to process inputs of any length and maintain a degree of
memory becomes essential. However, the one-off input of overly long texts is
limited, as studies have shown that when input lengths exceed the LLMs'
pre-trained text length, there is a dramatic decline in text generation
capabilities. Moreover, simply extending the length of pre-training texts is
impractical due to the difficulty in obtaining long text data and the
substantial memory consumption costs this would entail for LLMs. Recent efforts
have employed streaming inputs to alleviate the pressure of excessively long
text inputs, but this approach can significantly impair the model's long-term
memory capabilities.
  Motivated by this challenge, we introduce Streaming Infinite Retentive LLM
(SirLLM), which allows LLMs to maintain longer memory during infinite-length
dialogues without the need for fine-tuning. SirLLM utilizes the Token Entropy
metric and a memory decay mechanism to filter key phrases, endowing LLMs with
both long-lasting and flexible memory. We designed three distinct tasks and
constructed three datasets to measure the effectiveness of SirLLM from various
angles: (1) DailyDialog; (2) Grocery Shopping; (3) Rock-Paper-Scissors. Our
experimental results robustly demonstrate that SirLLM can achieve stable and
significant improvements across different LLMs and tasks, compellingly proving
its effectiveness. When having a coversation, ""A sir could forget himself,"" but
SirLLM never does! Our code is publicly available at
https://github.com/Zoeyyao27/SirLLM",2024-05-21,"Yao Yao, Zuchao Li, Hai Zhao",http://arxiv.org/pdf/2405.12528v1,cs.CL
Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models,"This paper introduces an efficient and robust method for discovering
interpretable circuits in large language models using discrete sparse
autoencoders. Our approach addresses key limitations of existing techniques,
namely computational complexity and sensitivity to hyperparameters. We propose
training sparse autoencoders on carefully designed positive and negative
examples, where the model can only correctly predict the next token for the
positive examples. We hypothesise that learned representations of attention
head outputs will signal when a head is engaged in specific computations. By
discretising the learned representations into integer codes and measuring the
overlap between codes unique to positive examples for each head, we enable
direct identification of attention heads involved in circuits without the need
for expensive ablations or architectural modifications. On three well-studied
tasks - indirect object identification, greater-than comparisons, and docstring
completion - the proposed method achieves higher precision and recall in
recovering ground-truth circuits compared to state-of-the-art baselines, while
reducing runtime from hours to seconds. Notably, we require only 5-10 text
examples for each task to learn robust representations. Our findings highlight
the promise of discrete sparse autoencoders for scalable and efficient
mechanistic interpretability, offering a new direction for analysing the inner
workings of large language models.",2024-05-21,"Charles O'Neill, Thang Bui",http://arxiv.org/pdf/2405.12522v1,cs.CL
Reducing Biases towards Minoritized Populations in Medical Curricular Content via Artificial Intelligence for Fairer Health Outcomes,"Biased information (recently termed bisinformation) continues to be taught in
medical curricula, often long after having been debunked. In this paper, we
introduce BRICC, a firstin-class initiative that seeks to mitigate medical
bisinformation using machine learning to systematically identify and flag text
with potential biases, for subsequent review in an expert-in-the-loop fashion,
thus greatly accelerating an otherwise labor-intensive process. A gold-standard
BRICC dataset was developed throughout several years, and contains over 12K
pages of instructional materials. Medical experts meticulously annotated these
documents for bias according to comprehensive coding guidelines, emphasizing
gender, sex, age, geography, ethnicity, and race. Using this labeled dataset,
we trained, validated, and tested medical bias classifiers. We test three
classifier approaches: a binary type-specific classifier, a general bias
classifier; an ensemble combining bias type-specific classifiers
independently-trained; and a multitask learning (MTL) model tasked with
predicting both general and type-specific biases. While MTL led to some
improvement on race bias detection in terms of F1-score, it did not outperform
binary classifiers trained specifically on each task. On general bias
detection, the binary classifier achieves up to 0.923 of AUC, a 27.8%
improvement over the baseline. This work lays the foundations for debiasing
medical curricula by exploring a novel dataset and evaluating different
training model strategies. Hence, it offers new pathways for more nuanced and
effective mitigation of bisinformation.",2024-05-21,"Chiman Salavati, Shannon Song, Willmar Sosa Diaz, Scott A. Hale, Roberto E. Montenegro, Fabricio Murai, Shiri Dori-Hacohen",http://arxiv.org/pdf/2407.12680v1,cs.CL
GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation,"Research on jailbreaking has been valuable for testing and understanding the
safety and security issues of large language models (LLMs). In this paper, we
introduce Iterative Refinement Induced Self-Jailbreak (IRIS), a novel approach
that leverages the reflective capabilities of LLMs for jailbreaking with only
black-box access. Unlike previous methods, IRIS simplifies the jailbreaking
process by using a single model as both the attacker and target. This method
first iteratively refines adversarial prompts through self-explanation, which
is crucial for ensuring that even well-aligned LLMs obey adversarial
instructions. IRIS then rates and enhances the output given the refined prompt
to increase its harmfulness. We find that IRIS achieves jailbreak success rates
of 98% on GPT-4, 92% on GPT-4 Turbo, and 94% on Llama-3.1-70B in under 7
queries. It significantly outperforms prior approaches in automatic, black-box,
and interpretable jailbreaking, while requiring substantially fewer queries,
thereby establishing a new standard for interpretable jailbreaking methods.",2024-05-21,"Govind Ramesh, Yao Dou, Wei Xu",http://arxiv.org/pdf/2405.13077v2,cs.CL
Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot Dialogue State Tracking,"We demonstrate substantial performance gains in zero-shot dialogue state
tracking (DST) by enhancing training data diversity through synthetic data
generation. Existing DST datasets are severely limited in the number of
application domains and slot types they cover due to the high costs of data
collection, restricting their adaptability to new domains. This work addresses
this challenge with a novel, fully automatic data generation approach that
creates synthetic zero-shot DST datasets. Distinguished from previous methods,
our approach can generate dialogues across a massive range of application
domains, complete with silver-standard dialogue state annotations and slot
descriptions. This technique is used to create the D0T dataset for training
zero-shot DST models, encompassing an unprecedented 1,000+ domains. Experiments
on the MultiWOZ benchmark show that training models on diverse synthetic data
improves Joint Goal Accuracy by 6.7%, achieving results competitive with models
13.5 times larger than ours.",2024-05-21,"James D. Finch, Jinho D. Choi",http://arxiv.org/pdf/2405.12468v2,cs.CL
CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents,"In recent years, there has been a growing interest in employing intelligent
agents in writing. Previous work emphasizes the evaluation of the quality of
end product-whether it was coherent and polished, overlooking the journey that
led to the product, which is an invaluable dimension of the creative process.
To understand how to recognize human efforts in co-writing with intelligent
writing systems, we adapt Flower and Hayes' cognitive process theory of writing
and propose CoCo Matrix, a two-dimensional taxonomy of entropy and information
gain, to depict the new human-agent co-writing model. We define four quadrants
and situate thirty-four published systems within the taxonomy. Our research
found that low entropy and high information gain systems are under-explored,
yet offer promising future directions in writing tasks that benefit from the
agent's divergent planning and the human's focused translation. CoCo Matrix,
not only categorizes different writing systems but also deepens our
understanding of the cognitive processes in human-agent co-writing. By
analyzing minimal changes in the writing process, CoCo Matrix serves as a proxy
for the writer's mental model, allowing writers to reflect on their
contributions. This reflection is facilitated through the measured metrics of
information gain and entropy, which provide insights irrespective of the
writing system used.",2024-05-21,"Ruyuan Wan, Simret Gebreegziabhe, Toby Jia-Jun Li, Karla Badillo-Urquiola",http://arxiv.org/pdf/2405.12438v1,cs.CL
Resolving Word Vagueness with Scenario-guided Adapter for Natural Language Inference,"Natural Language Inference (NLI) is a crucial task in natural language
processing that involves determining the relationship between two sentences,
typically referred to as the premise and the hypothesis. However, traditional
NLI models solely rely on the semantic information inherent in independent
sentences and lack relevant situational visual information, which can hinder a
complete understanding of the intended meaning of the sentences due to the
ambiguity and vagueness of language. To address this challenge, we propose an
innovative ScenaFuse adapter that simultaneously integrates large-scale
pre-trained linguistic knowledge and relevant visual information for NLI tasks.
Specifically, we first design an image-sentence interaction module to
incorporate visuals into the attention mechanism of the pre-trained model,
allowing the two modalities to interact comprehensively. Furthermore, we
introduce an image-sentence fusion module that can adaptively integrate visual
information from images and semantic information from sentences. By
incorporating relevant visual information and leveraging linguistic knowledge,
our approach bridges the gap between language and vision, leading to improved
understanding and inference capabilities in NLI tasks. Extensive benchmark
experiments demonstrate that our proposed ScenaFuse, a scenario-guided
approach, consistently boosts NLI performance.",2024-05-21,"Yonghao Liu, Mengyu Li, Di Liang, Ximing Li, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan",http://arxiv.org/pdf/2405.12434v1,cs.CL
Targeted Multilingual Adaptation for Low-resource Language Families,"The ""massively-multilingual"" training of multilingual models is known to
limit their utility in any one language, and they perform particularly poorly
on low-resource languages. However, there is evidence that low-resource
languages can benefit from targeted multilinguality, where the model is trained
on closely related languages. To test this approach more rigorously, we
systematically study best practices for adapting a pre-trained model to a
language family. Focusing on the Uralic family as a test case, we adapt XLM-R
under various configurations to model 15 languages; we then evaluate the
performance of each experimental setting on two downstream tasks and 11
evaluation languages. Our adapted models significantly outperform mono- and
multilingual baselines. Furthermore, a regression analysis of hyperparameter
effects reveals that adapted vocabulary size is relatively unimportant for
low-resource languages, and that low-resource languages can be aggressively
up-sampled during training at little detriment to performance in high-resource
languages. These results introduce new best practices for performing language
adaptation in a targeted setting.",2024-05-20,"C. M. Downey, Terra Blevins, Dhwani Serai, Dwija Parikh, Shane Steinert-Threlkeld",http://arxiv.org/pdf/2405.12413v1,cs.CL
Thesis: Document Summarization with applications to Keyword extraction and Image Retrieval,"Automatic summarization is the process of reducing a text document in order
to generate a summary that retains the most important points of the original
document. In this work, we study two problems - i) summarizing a text document
as set of keywords/caption, for image recommedation, ii) generating opinion
summary which good mix of relevancy and sentiment with the text document.
Intially, we present our work on an recommending images for enhancing a
substantial amount of existing plain text news articles. We use probabilistic
models and word similarity heuristics to generate captions and extract
Key-phrases which are re-ranked using a rank aggregation framework with
relevance feedback mechanism. We show that such rank aggregation and relevant
feedback which are typically used in Tagging Documents, Text Information
Retrieval also helps in improving image retrieval. These queries are fed to the
Yahoo Search Engine to obtain relevant images 1. Our proposed method is
observed to perform better than all existing baselines. Additonally, We propose
a set of submodular functions for opinion summarization. Opinion summarization
has built in it the tasks of summarization and sentiment detection. However, it
is not easy to detect sentiment and simultaneously extract summary. The two
tasks conflict in the sense that the demand of compression may drop sentiment
bearing sentences, and the demand of sentiment detection may bring in redundant
sentences. However, using submodularity we show how to strike a balance between
the two requirements. Our functions generate summaries such that there is good
correlation between document sentiment and summary sentiment along with good
ROUGE score. We also compare the performances of the proposed submodular
functions.",2024-05-20,Jayaprakash Sundararaj,http://arxiv.org/pdf/2406.00013v1,cs.CL
A Novel Method for News Article Event-Based Embedding,"Embedding news articles is a crucial tool for multiple fields, such as media
bias detection, identifying fake news, and making news recommendations.
However, existing news embedding methods are not optimized to capture the
latent context of news events. Most embedding methods rely on full-text
information and neglect time-relevant embedding generation. In this paper, we
propose a novel lightweight method that optimizes news embedding generation by
focusing on entities and themes mentioned in articles and their historical
connections to specific events. We suggest a method composed of three stages.
First, we process and extract events, entities, and themes from the given news
articles. Second, we generate periodic time embeddings for themes and entities
by training time-separated GloVe models on current and historical data. Lastly,
we concatenate the news embeddings generated by two distinct approaches: Smooth
Inverse Frequency (SIF) for article-level vectors and Siamese Neural Networks
for embeddings with nuanced event-related information. We leveraged over
850,000 news articles and 1,000,000 events from the GDELT project to test and
evaluate our method. We conducted a comparative analysis of different news
embedding generation methods for validation. Our experiments demonstrate that
our approach can both improve and outperform state-of-the-art methods on shared
event detection tasks.",2024-05-20,"Koren Ishlach, Itzhak Ben-David, Michael Fire, Lior Rokach",http://arxiv.org/pdf/2405.13071v2,cs.CL
Layout Agnostic Human Activity Recognition in Smart Homes through Textual Descriptions Of Sensor Triggers (TDOST),"Human activity recognition (HAR) using ambient sensors in smart homes has
numerous applications for human healthcare and wellness. However, building
general-purpose HAR models that can be deployed to new smart home environments
requires a significant amount of annotated sensor data and training overhead.
Most smart homes vary significantly in their layouts, i.e., floor plans and the
specifics of sensors embedded, resulting in low generalizability of HAR models
trained for specific homes. We address this limitation by introducing a novel,
layout-agnostic modeling approach for HAR systems in smart homes that utilizes
the transferrable representational capacity of natural language descriptions of
raw sensor data. To this end, we generate Textual Descriptions Of Sensor
Triggers (TDOST) that encapsulate the surrounding trigger conditions and
provide cues for underlying activities to the activity recognition models.
Leveraging textual embeddings, rather than raw sensor data, we create activity
recognition systems that predict standard activities across homes without
either (re-)training or adaptation on target homes. Through an extensive
evaluation, we demonstrate the effectiveness of TDOST-based models in unseen
smart homes through experiments on benchmarked CASAS datasets. Furthermore, we
conduct a detailed analysis of how the individual components of our approach
affect downstream activity recognition performance.",2024-05-20,"Megha Thukral, Sourish Gunesh Dhekane, Shruthi K. Hiremath, Harish Haresamudram, Thomas Ploetz",http://arxiv.org/pdf/2405.12368v1,cs.CL
Question-Based Retrieval using Atomic Units for Enterprise RAG,"Enterprise retrieval augmented generation (RAG) offers a highly flexible
framework for combining powerful large language models (LLMs) with internal,
possibly temporally changing, documents. In RAG, documents are first chunked.
Relevant chunks are then retrieved for a user query, which are passed as
context to a synthesizer LLM to generate the query response. However, the
retrieval step can limit performance, as incorrect chunks can lead the
synthesizer LLM to generate a false response. This work applies a zero-shot
adaptation of standard dense retrieval steps for more accurate chunk recall.
Specifically, a chunk is first decomposed into atomic statements. A set of
synthetic questions are then generated on these atoms (with the chunk as the
context). Dense retrieval involves finding the closest set of synthetic
questions, and associated chunks, to the user query. It is found that retrieval
with the atoms leads to higher recall than retrieval with chunks. Further
performance gain is observed with retrieval using the synthetic questions
generated over the atoms. Higher recall at the retrieval step enables higher
performance of the enterprise LLM using the RAG pipeline.",2024-05-20,"Vatsal Raina, Mark Gales",http://arxiv.org/pdf/2405.12363v2,cs.CL
MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark,"Recent advancements in large language models (LLMs) have showcased
significant improvements in mathematics. However, traditional math benchmarks
like GSM8k offer a unidimensional perspective, falling short in providing a
holistic assessment of the LLMs' math capabilities. To address this gap, we
introduce MathBench, a new benchmark that rigorously assesses the mathematical
capabilities of large language models. MathBench spans a wide range of
mathematical disciplines, offering a detailed evaluation of both theoretical
understanding and practical problem-solving skills. The benchmark progresses
through five distinct stages, from basic arithmetic to college mathematics, and
is structured to evaluate models at various depths of knowledge. Each stage
includes theoretical questions and application problems, allowing us to measure
a model's mathematical proficiency and its ability to apply concepts in
practical scenarios. MathBench aims to enhance the evaluation of LLMs'
mathematical abilities, providing a nuanced view of their knowledge
understanding levels and problem solving skills in a bilingual context. The
project is released at https://github.com/open-compass/MathBench .",2024-05-20,"Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou, Wenwei Zhang, Songyang Zhang, Dahua Lin, Kai Chen",http://arxiv.org/pdf/2405.12209v1,cs.CL
Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models,"Scientist learn early on how to cite scientific sources to support their
claims. Sometimes, however, scientists have challenges determining where a
citation should be situated -- or, even worse, fail to cite a source
altogether. Automatically detecting sentences that need a citation (i.e.,
citation worthiness) could solve both of these issues, leading to more robust
and well-constructed scientific arguments. Previous researchers have applied
machine learning to this task but have used small datasets and models that do
not take advantage of recent algorithmic developments such as attention
mechanisms in deep learning. We hypothesize that we can develop significantly
accurate deep learning architectures that learn from large supervised datasets
constructed from open access publications. In this work, we propose a
Bidirectional Long Short-Term Memory (BiLSTM) network with attention mechanism
and contextual information to detect sentences that need citations. We also
produce a new, large dataset (PMOA-CITE) based on PubMed Open Access Subset,
which is orders of magnitude larger than previous datasets. Our experiments
show that our architecture achieves state of the art performance on the
standard ACL-ARC dataset ($F_{1}=0.507$) and exhibits high performance
($F_{1}=0.856$) on the new PMOA-CITE. Moreover, we show that it can transfer
learning across these datasets. We further use interpretable models to
illuminate how specific language is used to promote and inhibit citations. We
discover that sections and surrounding sentences are crucial for our improved
predictions. We further examined purported mispredictions of the model, and
uncovered systematic human mistakes in citation behavior and source data. This
opens the door for our model to check documents during pre-submission and
pre-archival procedures. We make this new dataset, the code, and a web-based
tool available to the community.",2024-05-20,"Tong Zeng, Daniel E. Acuna",http://arxiv.org/pdf/2405.12206v1,cs.CL
Role of Dependency Distance in Text Simplification: A Human vs ChatGPT Simplification Comparison,"This study investigates human and ChatGPT text simplification and its
relationship to dependency distance. A set of 220 sentences, with increasing
grammatical difficulty as measured in a prior user study, were simplified by a
human expert and using ChatGPT. We found that the three sentence sets all
differed in mean dependency distances: the highest in the original sentence
set, followed by ChatGPT simplified sentences, and the human simplified
sentences showed the lowest mean dependency distance.",2024-05-20,"Sumi Lee, Gondy Leroy, David Kauchak, Melissa Just",http://arxiv.org/pdf/2406.17787v1,cs.CL
CT-Eval: Benchmarking Chinese Text-to-Table Performance in Large Language Models,"Text-to-Table aims to generate structured tables to convey the key
information from unstructured documents. Existing text-to-table datasets are
typically oriented English, limiting the research in non-English languages.
Meanwhile, the emergence of large language models (LLMs) has shown great
success as general task solvers in multi-lingual settings (e.g., ChatGPT),
theoretically enabling text-to-table in other languages. In this paper, we
propose a Chinese text-to-table dataset, CT-Eval, to benchmark LLMs on this
task. Our preliminary analysis of English text-to-table datasets highlights two
key factors for dataset construction: data diversity and data hallucination.
Inspired by this, the CT-Eval dataset selects a popular Chinese
multidisciplinary online encyclopedia as the source and covers 28 domains to
ensure data diversity. To minimize data hallucination, we first train an LLM to
judge and filter out the task samples with hallucination, then employ human
annotators to clean the hallucinations in the validation and testing sets.
After this process, CT-Eval contains 88.6K task samples. Using CT-Eval, we
evaluate the performance of open-source and closed-source LLMs. Our results
reveal that zero-shot LLMs (including GPT-4) still have a significant
performance gap compared with human judgment. Furthermore, after fine-tuning,
open-source LLMs can significantly improve their text-to-table ability,
outperforming GPT-4 by a large margin. In short, CT-Eval not only helps
researchers evaluate and quickly understand the Chinese text-to-table ability
of existing LLMs but also serves as a valuable resource to significantly
improve the text-to-table performance of LLMs.",2024-05-20,"Haoxiang Shi, Jiaan Wang, Jiarong Xu, Cen Wang, Tetsuya Sakai",http://arxiv.org/pdf/2405.12174v1,cs.CL
Fennec: Fine-grained Language Model Evaluation and Correction Extended through Branching and Bridging,"The rapid advancement of large language models has given rise to a plethora
of applications across a myriad of real-world tasks, mainly centered on
aligning with human intent. However, the complexities inherent in human intent
necessitate a dependence on labor-intensive and time-consuming human
evaluation. To alleviate this constraint, we delve into the paradigm of
employing open-source large language models as evaluators, aligning with the
prevailing trend of utilizing GPT-4. Particularly, we present a step-by-step
evaluation framework: \textbf{Fennec}, capable of \textbf{F}ine-grained
\textbf{E}valuatio\textbf{N} and correctio\textbf{N} \textbf{E}xtended through
bran\textbf{C}hing and bridging. Specifically, the branching operation dissects
the evaluation task into various dimensions and granularities, thereby
alleviating the challenges associated with evaluation. Concurrently, the
bridging operation amalgamates diverse training datasets, augmenting the
variety of evaluation tasks. In experimental trials, our 7B model consistently
outperforms open-source larger-scale evaluation models across various widely
adopted benchmarks in terms of both \textit{Agreement} and
\textit{Consistency}, closely approaching the capabilities of GPT-4. We employ
the fine-grained correction capabilities induced by the evaluation model to
refine multiple model responses, and the results show that the refinement
elevates the quality of responses, leading to an improvement of 1-2 points on
the MT-Bench. Our code is available at
Github\footnote{\url{https://github.com/dropreg/Fennec}}.",2024-05-20,"Xiaobo Liang, Haoke Zhang, Helan hu, Juntao Li, Jun Xu, Min Zhang",http://arxiv.org/pdf/2405.12163v1,cs.CL
Eliciting Problem Specifications via Large Language Models,"Cognitive systems generally require a human to translate a problem definition
into some specification that the cognitive system can use to attempt to solve
the problem or perform the task. In this paper, we illustrate that large
language models (LLMs) can be utilized to map a problem class, defined in
natural language, into a semi-formal specification that can then be utilized by
an existing reasoning and learning system to solve instances from the problem
class. We present the design of LLM-enabled cognitive task analyst agent(s).
Implemented with LLM agents, this system produces a definition of problem
spaces for tasks specified in natural language. LLM prompts are derived from
the definition of problem spaces in the AI literature and general
problem-solving strategies (Polya's How to Solve It). A cognitive system can
then use the problem-space specification, applying domain-general problem
solving strategies (""weak methods"" such as search), to solve multiple instances
of problems from the problem class. This result, while preliminary, suggests
the potential for speeding cognitive systems research via disintermediation of
problem formulation while also retaining core capabilities of cognitive
systems, such as robust inference and online learning.",2024-05-20,"Robert E. Wray, James R. Kirk, John E. Laird",http://arxiv.org/pdf/2405.12147v2,cs.CL
MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning,"Low-rank adaptation is a popular parameter-efficient fine-tuning method for
large language models. In this paper, we analyze the impact of low-rank
updating, as implemented in LoRA. Our findings suggest that the low-rank
updating mechanism may limit the ability of LLMs to effectively learn and
memorize new knowledge. Inspired by this observation, we propose a new method
called MoRA, which employs a square matrix to achieve high-rank updating while
maintaining the same number of trainable parameters. To achieve it, we
introduce the corresponding non-parameter operators to reduce the input
dimension and increase the output dimension for the square matrix. Furthermore,
these operators ensure that the weight can be merged back into LLMs, which
makes our method can be deployed like LoRA. We perform a comprehensive
evaluation of our method across five tasks: instruction tuning, mathematical
reasoning, continual pretraining, memory and pretraining. Our method
outperforms LoRA on memory-intensive tasks and achieves comparable performance
on other tasks.",2024-05-20,"Ting Jiang, Shaohan Huang, Shengyue Luo, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang",http://arxiv.org/pdf/2405.12130v1,cs.CL
Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation,"Large language models (LLMs) are revolutionizing conversational recommender
systems by adeptly indexing item content, understanding complex conversational
contexts, and generating relevant item titles. However, controlling the
distribution of recommended items remains a challenge. This leads to suboptimal
performance due to the failure to capture rapidly changing data distributions,
such as item popularity, on targeted conversational recommendation platforms.
In conversational recommendation, LLMs recommend items by generating the titles
(as multiple tokens) autoregressively, making it difficult to obtain and
control the recommendations over all items. Thus, we propose a
Reindex-Then-Adapt (RTA) framework, which converts multi-token item titles into
single tokens within LLMs, and then adjusts the probability distributions over
these single-token item titles accordingly. The RTA framework marries the
benefits of both LLMs and traditional recommender systems (RecSys):
understanding complex queries as LLMs do; while efficiently controlling the
recommended item distributions in conversational recommendations as traditional
RecSys do. Our framework demonstrates improved accuracy metrics across three
different conversational recommendation datasets and two adaptation settings",2024-05-20,"Zhankui He, Zhouhang Xie, Harald Steck, Dawen Liang, Rahul Jha, Nathan Kallus, Julian McAuley",http://arxiv.org/pdf/2405.12119v1,cs.CL
Linguistic Structure from a Bottleneck on Sequential Information Processing,"Human language is a unique form of communication in the natural world,
distinguished by its structured nature. Most fundamentally, it is systematic,
meaning that signals can be broken down into component parts that are
individually meaningful -- roughly, words -- which are combined in a regular
way to form sentences. Furthermore, the way in which these parts are combined
maintains a kind of locality: words are usually concatenated together, and they
form contiguous phrases, keeping related parts of sentences close to each
other. We address the challenge of understanding how these basic properties of
language arise from broader principles of efficient communication under
information processing constraints. Here we show that natural-language-like
systematicity arises in codes that are constrained by predictive information, a
measure of the amount of information that must be extracted from the past of a
sequence in order to predict its future. In simulations, we show that such
codes approximately factorize their source distributions, and then express the
resulting factors systematically and locally. Next, in a series of
cross-linguistic corpus studies, we show that human languages are structured to
have low predictive information at the levels of phonology, morphology, syntax,
and semantics. Our result suggests that human language performs a sequential,
discrete form of Independent Components Analysis on the statistical
distribution over meanings that need to be expressed. It establishes a link
between the statistical and algebraic structure of human language, and
reinforces the idea that the structure of human language is shaped by
communication under cognitive constraints.",2024-05-20,"Richard Futrell, Michael Hahn",http://arxiv.org/pdf/2405.12109v2,cs.CL
Imp: Highly Capable Large Multimodal Models for Mobile Devices,"By harnessing the capabilities of large language models (LLMs), recent large
multimodal models (LMMs) have shown remarkable versatility in open-world
multimodal understanding. Nevertheless, they are usually parameter-heavy and
computation-intensive, thus hindering their applicability in
resource-constrained scenarios. To this end, several lightweight LMMs have been
proposed successively to maximize the capabilities under constrained scale
(e.g., 3B). Despite the encouraging results achieved by these methods, most of
them only focus on one or two aspects of the design space, and the key design
choices that influence model capability have not yet been thoroughly
investigated. In this paper, we conduct a systematic study for lightweight LMMs
from the aspects of model architecture, training strategy, and training data.
Based on our findings, we obtain Imp -- a family of highly capable LMMs at the
2B-4B scales. Notably, our Imp-3B model steadily outperforms all the existing
lightweight LMMs of similar size, and even surpasses the state-of-the-art LMMs
at the 13B scale. With low-bit quantization and resolution reduction
techniques, our Imp model can be deployed on a Qualcomm Snapdragon 8Gen3 mobile
chip with a high inference speed of about 13 tokens/s.",2024-05-20,"Zhenwei Shao, Zhou Yu, Jun Yu, Xuecheng Ouyang, Lihao Zheng, Zhenbiao Gai, Mingyang Wang, Jiajun Ding",http://arxiv.org/pdf/2405.12107v2,cs.CL
DOP: Diagnostic-Oriented Prompting for Large Language Models in Mathematical Correction,"Math world problems correction(MWPC) is a novel task dedicated to rectifying
reasoning errors in the process of solving mathematical problems. In this
paper, leveraging the advancements in large language models (LLMs), we address
two key objectives:(1) Distinguishing between mathematical reasoning and error
correction; (2) Exploring strategies to enhance the error correction
capabilities of LLMs in mathematics to solve MWPC task. We noticed that, in
real-time education,assisting students in recognizing their mistakes is more
crucial than simply providing correct answers. However, current research tends
to prioritize obtaining accurate solutions to math problems rather than
correcting potentially incorrect ones. Therefore, we modify the research
paradigm, demonstrating that improving mathematical reasoning abilities does
not equate to mastery in error correction. Meanwhile, we propose a novel method
called diagnostic-oriented promping(DOP) aimed at facilitating LLMs to excel in
error correction. In experiments, DOP has shown outstanding performance,
highlighting its significant impact. We argue that in mathematical education,
the demand for outstanding correctors surpasses that for proficient reasoners.
Codes and data are available on
https://github.com/ChenhaoEcnuCS/Reason-Correct.",2024-05-20,"Hao Chen, Biaojie Zeng, Xin Lin, Liang He, Aimin Zhou",http://arxiv.org/pdf/2405.12100v1,cs.CL
"Distributional Semantics, Holism, and the Instability of Meaning","Large Language Models are built on the so-called distributional semantic
approach to linguistic meaning that has the distributional hypothesis at its
core. The distributional hypothesis involves a holistic conception of word
meaning: the meaning of a word depends upon its relations to other words in the
model. A standard objection to holism is the charge of instability: any change
in the meaning properties of a linguistic system (a human speaker, for example)
would lead to many changes or a complete change in the entire system. We
examine whether the instability objection poses a problem for distributional
models of meaning. First, we distinguish between distinct forms of instability
that these models could exhibit, and argue that only one such form is relevant
for understanding the relation between instability and communication: what we
call differential instability. Differential instability is variation in the
relative distances between points in a space, rather than variation in the
absolute position of those points. We distinguish differential and absolute
instability by constructing two of our own smaller language models. We
demonstrate the two forms of instability by showing these models change as the
corpora they are constructed from increase in size. We argue that the
instability that these models display is constrained by the structure and scale
of relationships between words, such that the resistance to change for a word
is roughly proportional to its frequent and consistent use within the language
system. The differential instability that language models exhibit allows for
productive forms of meaning change while not leading to the problems raised by
the instability objection.",2024-05-20,"Jumbly Grindrod, J. D. Porter, Nat Hansen",http://arxiv.org/pdf/2405.12084v2,cs.CL
Selective Annotation via Data Allocation: These Data Should Be Triaged to Experts for Annotation Rather Than the Model,"To obtain high-quality annotations under limited budget, semi-automatic
annotation methods are commonly used, where a portion of the data is annotated
by experts and a model is then trained to complete the annotations for the
remaining data. However, these methods mainly focus on selecting informative
data for expert annotations to improve the model predictive ability (i.e.,
triage-to-human data), while the rest of the data is indiscriminately assigned
to model annotation (i.e., triage-to-model data). This may lead to
inefficiencies in budget allocation for annotations, as easy data that the
model could accurately annotate may be unnecessarily assigned to the expert,
and hard data may be misclassified by the model. As a result, the overall
annotation quality may be compromised. To address this issue, we propose a
selective annotation framework called SANT. It effectively takes advantage of
both the triage-to-human and triage-to-model data through the proposed
error-aware triage and bi-weighting mechanisms. As such, informative or hard
data is assigned to the expert for annotation, while easy data is handled by
the model. Experimental results show that SANT consistently outperforms other
baselines, leading to higher-quality annotation through its proper allocation
of data to both expert and model workers. We provide pioneering work on data
annotation within budget constraints, establishing a landmark for future
triage-based annotation studies.",2024-05-20,"Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Ido Dagan",http://arxiv.org/pdf/2405.12081v2,cs.CL
CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models,"Large language models (LLMs) are increasingly used to meet user information
needs, but their effectiveness in dealing with user queries that contain
various types of ambiguity remains unknown, ultimately risking user trust and
satisfaction. To this end, we introduce CLAMBER, a benchmark for evaluating
LLMs using a well-organized taxonomy. Building upon the taxonomy, we construct
~12K high-quality data to assess the strengths, weaknesses, and potential risks
of various off-the-shelf LLMs. Our findings indicate the limited practical
utility of current LLMs in identifying and clarifying ambiguous user queries,
even enhanced by chain-of-thought (CoT) and few-shot prompting. These
techniques may result in overconfidence in LLMs and yield only marginal
enhancements in identifying ambiguity. Furthermore, current LLMs fall short in
generating high-quality clarifying questions due to a lack of conflict
resolution and inaccurate utilization of inherent knowledge. In this paper,
CLAMBER presents a guidance and promotes further research on proactive and
trustworthy LLMs. Our dataset is available at
https://github.com/zt991211/CLAMBER",2024-05-20,"Tong Zhang, Peixin Qin, Yang Deng, Chen Huang, Wenqiang Lei, Junhong Liu, Dingnan Jin, Hongru Liang, Tat-Seng Chua",http://arxiv.org/pdf/2405.12063v2,cs.CL
STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents,"Equipping a conversational search engine with strategies regarding when to
ask clarification questions is becoming increasingly important across various
domains. Attributing to the context understanding capability of LLMs and their
access to domain-specific sources of knowledge, LLM-based clarification
strategies feature rapid transfer to various domains in a post-hoc manner.
However, they still struggle to deliver promising performance on unseen
domains, struggling to achieve effective domain transferability. We take the
first step to investigate this issue and existing methods tend to produce
one-size-fits-all strategies across diverse domains, limiting their search
effectiveness. In response, we introduce a novel method, called Style, to
achieve effective domain transferability. Our experimental results indicate
that Style bears strong domain transferability, resulting in an average search
performance improvement of ~10% on four unseen domains.",2024-05-20,"Yue Chen, Chen Huang, Yang Deng, Wenqiang Lei, Dingnan Jin, Jia Liu, Tat-Seng Chua",http://arxiv.org/pdf/2405.12059v2,cs.CL
Unveiling factors influencing judgment variation in Sentiment Analysis with Natural Language Processing and Statistics,"TripAdvisor reviews and comparable data sources play an important role in
many tasks in Natural Language Processing (NLP), providing a data basis for the
identification and classification of subjective judgments, such as hotel or
restaurant reviews, into positive or negative polarities. This study explores
three important factors influencing variation in crowdsourced polarity
judgments, focusing on TripAdvisor reviews in Spanish. Three hypotheses are
tested: the role of Part Of Speech (POS), the impact of sentiment words such as
""tasty"", and the influence of neutral words like ""ok"" on judgment variation.
The study's methodology employs one-word titles, demonstrating their efficacy
in studying polarity variation of words. Statistical tests on mean equality are
performed on word groups of our interest. The results of this study reveal that
adjectives in one-word titles tend to result in lower judgment variation
compared to other word types or POS. Sentiment words contribute to lower
judgment variation as well, emphasizing the significance of sentiment words in
research on polarity judgments, and neutral words are associated with higher
judgment variation as expected. However, these effects cannot be always
reproduced in longer titles, which suggests that longer titles do not represent
the best data source for testing the ambiguity of single words due to the
influence on word polarity by other words like negation in longer titles. This
empirical investigation contributes valuable insights into the factors
influencing polarity variation of words, providing a foundation for NLP
practitioners that aim to capture and predict polarity judgments in Spanish and
for researchers that aim to understand factors influencing judgment variation.",2024-05-20,"Olga Kellert, Carlos Gómez-Rodríguez, Mahmud Uz Zaman",http://arxiv.org/pdf/2405.12055v1,cs.CL
KG-RAG: Bridging the Gap Between Knowledge and Creativity,"Ensuring factual accuracy while maintaining the creative capabilities of
Large Language Model Agents (LMAs) poses significant challenges in the
development of intelligent agent systems. LMAs face prevalent issues such as
information hallucinations, catastrophic forgetting, and limitations in
processing long contexts when dealing with knowledge-intensive tasks. This
paper introduces a KG-RAG (Knowledge Graph-Retrieval Augmented Generation)
pipeline, a novel framework designed to enhance the knowledge capabilities of
LMAs by integrating structured Knowledge Graphs (KGs) with the functionalities
of LLMs, thereby significantly reducing the reliance on the latent knowledge of
LLMs. The KG-RAG pipeline constructs a KG from unstructured text and then
performs information retrieval over the newly created graph to perform KGQA
(Knowledge Graph Question Answering). The retrieval methodology leverages a
novel algorithm called Chain of Explorations (CoE) which benefits from LLMs
reasoning to explore nodes and relationships within the KG sequentially.
Preliminary experiments on the ComplexWebQuestions dataset demonstrate notable
improvements in the reduction of hallucinated content and suggest a promising
path toward developing intelligent systems adept at handling
knowledge-intensive tasks.",2024-05-20,Diego Sanmartin,http://arxiv.org/pdf/2405.12035v1,cs.CL
Can AI Relate: Testing Large Language Model Response for Mental Health Support,"Large language models (LLMs) are already being piloted for clinical use in
hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed
deployment use case is psychotherapy, where a LLM-powered chatbot can treat a
patient undergoing a mental health crisis. Deployment of LLMs for mental health
response could hypothetically broaden access to psychotherapy and provide new
possibilities for personalizing care. However, recent high-profile failures,
like damaging dieting advice offered by the Tessa chatbot to patients with
eating disorders, have led to doubt about their reliability in high-stakes and
safety-critical settings.
  In this work, we develop an evaluation framework for determining whether LLM
response is a viable and ethical path forward for the automation of mental
health treatment. Our framework measures equity in empathy and adherence of LLM
responses to motivational interviewing theory. Using human evaluation with
trained clinicians and automatic quality-of-care metrics grounded in psychology
research, we compare the responses provided by peer-to-peer responders to those
provided by a state-of-the-art LLM.
  We show that LLMs like GPT-4 use implicit and explicit cues to infer patient
demographics like race. We then show that there are statistically significant
discrepancies between patient subgroups: Responses to Black posters
consistently have lower empathy than for any other demographic group (2%-13%
lower than the control group). Promisingly, we do find that the manner in which
responses are generated significantly impacts the quality of the response. We
conclude by proposing safety guidelines for the potential deployment of LLMs
for mental health response.",2024-05-20,"Saadia Gabriel, Isha Puri, Xuhai Xu, Matteo Malgaroli, Marzyeh Ghassemi",http://arxiv.org/pdf/2405.12021v2,cs.CL
A Multi-Modal Explainability Approach for Human-Aware Robots in Multi-Party Conversation,"The addressee estimation (understanding to whom somebody is talking) is a
fundamental task for human activity recognition in multi-party conversation
scenarios. Specifically, in the field of human-robot interaction, it becomes
even more crucial to enable social robots to participate in such interactive
contexts. However, it is usually implemented as a binary classification task,
restricting the robot's capability to estimate whether it was addressed
\review{or not, which} limits its interactive skills. For a social robot to
gain the trust of humans, it is also important to manifest a certain level of
transparency and explainability. Explainable artificial intelligence thus plays
a significant role in the current machine learning applications and models, to
provide explanations for their decisions besides excellent performance. In our
work, we a) present an addressee estimation model with improved performance in
comparison with the previous state-of-the-art; b) further modify this model to
include inherently explainable attention-based segments; c) implement the
explainable addressee estimation as part of a modular cognitive architecture
for multi-party conversation in an iCub robot; d) validate the real-time
performance of the explainable model in multi-party human-robot interaction; e)
propose several ways to incorporate explainability and transparency in the
aforementioned architecture; and f) perform an online user study to analyze the
effect of various explanations on how human participants perceive the robot.",2024-05-20,"Iveta Bečková, Štefan Pócoš, Giulia Belgiovine, Marco Matarese, Omar Eldardeer, Alessandra Sciutti, Carlo Mazzola",http://arxiv.org/pdf/2407.03340v2,cs.CL
A review on the use of large language models as virtual tutors,"Transformer architectures contribute to managing long-term dependencies for
Natural Language Processing, representing one of the most recent changes in the
field. These architectures are the basis of the innovative, cutting-edge Large
Language Models (LLMs) that have produced a huge buzz in several fields and
industrial sectors, among the ones education stands out. Accordingly, these
generative Artificial Intelligence-based solutions have directed the change in
techniques and the evolution in educational methods and contents, along with
network infrastructure, towards high-quality learning. Given the popularity of
LLMs, this review seeks to provide a comprehensive overview of those solutions
designed specifically to generate and evaluate educational materials and which
involve students and teachers in their design or experimental plan. To the best
of our knowledge, this is the first review of educational applications (e.g.,
student assessment) of LLMs. As expected, the most common role of these systems
is as virtual tutors for automatic question generation. Moreover, the most
popular models are GTP-3 and BERT. However, due to the continuous launch of new
generative models, new works are expected to be published shortly.",2024-05-20,"Silvia García-Méndez, Francisco de Arriba-Pérez, María del Carmen Somoza-López",http://arxiv.org/pdf/2405.11983v2,cs.CL
RNG: Reducing Multi-level Noise and Multi-grained Semantic Gap for Joint Multimodal Aspect-Sentiment Analysis,"As an important multimodal sentiment analysis task, Joint Multimodal
Aspect-Sentiment Analysis (JMASA), aiming to jointly extract aspect terms and
their associated sentiment polarities from the given text-image pairs, has
gained increasing concerns. Existing works encounter two limitations: (1)
multi-level modality noise, i.e., instance- and feature-level noise; and (2)
multi-grained semantic gap, i.e., coarse- and fine-grained gap. Both issues may
interfere with accurate identification of aspect-sentiment pairs. To address
these limitations, we propose a novel framework named RNG for JMASA.
Specifically, to simultaneously reduce multi-level modality noise and
multi-grained semantic gap, we design three constraints: (1) Global Relevance
Constraint (GR-Con) based on text-image similarity for instance-level noise
reduction, (2) Information Bottleneck Constraint (IB-Con) based on the
Information Bottleneck (IB) principle for feature-level noise reduction, and
(3) Semantic Consistency Constraint (SC-Con) based on mutual information
maximization in a contrastive learning way for multi-grained semantic gap
reduction. Extensive experiments on two datasets validate our new
state-of-the-art performance.",2024-05-20,"Yaxin Liu, Yan Zhou, Ziming Li, Jinchuan Zhang, Yu Shang, Chenyang Zhang, Songlin Hu",http://arxiv.org/pdf/2405.13059v1,cs.CL
Multiple-Choice Questions are Efficient and Robust LLM Evaluators,"We present GSM-MC, a multiple-choice (MC) dataset constructed by collecting
answers and incorrect predictions on GSM8K from 60 open-source models. Through
extensive experiments, we show that LLMs' performance on the MC version of this
popular benchmark is strongly correlated with their performance on the original
version and is quite robust to distractor choices and option orders, while the
evaluation time is reduced by a factor of up to 30. Following similar
procedures, we introduce MATH-MC, constructed from MATH, and PythonIO, a new
program reasoning MC dataset constructed from HumanEval and MBPP. Experimental
results indicate that LLMs' performance on these MC benchmarks leaves much room
for improvement. Our data and code are available at
https://github.com/Geralt-Targaryen/MC-Evaluation.",2024-05-20,"Ziyin Zhang, Zhaokun Jiang, Lizhen Xu, Hongkun Hao, Rui Wang",http://arxiv.org/pdf/2405.11966v4,cs.CL
WisPerMed at BioLaySumm: Adapting Autoregressive Large Language Models for Lay Summarization of Scientific Articles,"This paper details the efforts of the WisPerMed team in the BioLaySumm2024
Shared Task on automatic lay summarization in the biomedical domain, aimed at
making scientific publications accessible to non-specialists. Large language
models (LLMs), specifically the BioMistral and Llama3 models, were fine-tuned
and employed to create lay summaries from complex scientific texts. The
summarization performance was enhanced through various approaches, including
instruction tuning, few-shot learning, and prompt variations tailored to
incorporate specific context information. The experiments demonstrated that
fine-tuning generally led to the best performance across most evaluated
metrics. Few-shot learning notably improved the models' ability to generate
relevant and factually accurate texts, particularly when using a well-crafted
prompt. Additionally, a Dynamic Expert Selection (DES) mechanism to optimize
the selection of text outputs based on readability and factuality metrics was
developed. Out of 54 participants, the WisPerMed team reached the 4th place,
measured by readability, factuality, and relevance. Determined by the overall
score, our approach improved upon the baseline by approx. 5.5 percentage points
and was only approx 1.5 percentage points behind the first place.",2024-05-20,"Tabea M. G. Pakull, Hendrik Damm, Ahmad Idrissi-Yaghir, Henning Schäfer, Peter A. Horn, Christoph M. Friedrich",http://arxiv.org/pdf/2405.11950v2,cs.CL
FAME-MT Dataset: Formality Awareness Made Easy for Machine Translation Purposes,"People use language for various purposes. Apart from sharing information,
individuals may use it to express emotions or to show respect for another
person. In this paper, we focus on the formality level of machine-generated
translations and present FAME-MT -- a dataset consisting of 11.2 million
translations between 15 European source languages and 8 European target
languages classified to formal and informal classes according to target
sentence formality. This dataset can be used to fine-tune machine translation
models to ensure a given formality level for each European target language
considered. We describe the dataset creation procedure, the analysis of the
dataset's quality showing that FAME-MT is a reliable source of language
register information, and we present a publicly available proof-of-concept
machine translation model that uses the dataset to steer the formality level of
the translation. Currently, it is the largest dataset of formality annotations,
with examples expressed in 112 European language pairs. The dataset is
published online: https://github.com/laniqo-public/fame-mt/ .",2024-05-20,"Dawid Wiśniewski, Zofia Rostek, Artur Nowakowski",http://arxiv.org/pdf/2405.11942v1,cs.CL
Biomedical Entity Linking for Dutch: Fine-tuning a Self-alignment BERT Model on an Automatically Generated Wikipedia Corpus,"Biomedical entity linking, a main component in automatic information
extraction from health-related texts, plays a pivotal role in connecting
textual entities (such as diseases, drugs and body parts mentioned by patients)
to their corresponding concepts in a structured biomedical knowledge base. The
task remains challenging despite recent developments in natural language
processing. This paper presents the first evaluated biomedical entity linking
model for the Dutch language. We use MedRoBERTa.nl as base model and perform
second-phase pretraining through self-alignment on a Dutch biomedical ontology
extracted from the UMLS and Dutch SNOMED. We derive a corpus from Wikipedia of
ontology-linked Dutch biomedical entities in context and fine-tune our model on
this dataset. We evaluate our model on the Dutch portion of the Mantra
GSC-corpus and achieve 54.7% classification accuracy and 69.8% 1-distance
accuracy. We then perform a case study on a collection of unlabeled,
patient-support forum data and show that our model is hampered by the limited
quality of the preceding entity recognition step. Manual evaluation of small
sample indicates that of the correctly extracted entities, around 65% is linked
to the correct concept in the ontology. Our results indicate that biomedical
entity linking in a language other than English remains challenging, but our
Dutch model can be used to for high-level analysis of patient-generated text.",2024-05-20,"Fons Hartendorp, Tom Seinen, Erik van Mulligen, Suzan Verberne",http://arxiv.org/pdf/2405.11941v1,cs.CL
Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving Machine Translation,"This paper explores Minimum Bayes Risk (MBR) decoding for self-improvement in
machine translation (MT), particularly for domain adaptation and low-resource
languages. We implement the self-improvement process by fine-tuning the model
on its MBR-decoded forward translations. By employing COMET as the MBR utility
metric, we aim to achieve the reranking of translations that better aligns with
human preferences. The paper explores the iterative application of this
approach and the potential need for language-specific MBR utility metrics. The
results demonstrate significant enhancements in translation quality for all
examined language pairs, including successful application to domain-adapted
models and generalisation to low-resource settings. This highlights the
potential of COMET-guided MBR for efficient MT self-improvement in various
scenarios.",2024-05-20,"Kamil Guttmann, Mikołaj Pokrywka, Adrian Charkiewicz, Artur Nowakowski",http://arxiv.org/pdf/2405.11937v1,cs.CL
On Efficient and Statistical Quality Estimation for Data Annotation,"Annotated datasets are an essential ingredient to train, evaluate, compare
and productionalize supervised machine learning models. It is therefore
imperative that annotations are of high quality. For their creation, good
quality management and thereby reliable quality estimates are needed. Then, if
quality is insufficient during the annotation process, rectifying measures can
be taken to improve it. Quality estimation is often performed by having experts
manually label instances as correct or incorrect. But checking all annotated
instances tends to be expensive. Therefore, in practice, usually only subsets
are inspected; sizes are chosen mostly without justification or regard to
statistical power and more often than not, are relatively small. Basing
estimates on small sample sizes, however, can lead to imprecise values for the
error rate. Using unnecessarily large sample sizes costs money that could be
better spent, for instance on more annotations. Therefore, we first describe in
detail how to use confidence intervals for finding the minimal sample size
needed to estimate the annotation error rate. Then, we propose applying
acceptance sampling as an alternative to error rate estimation We show that
acceptance sampling can reduce the required sample sizes up to 50% while
providing the same statistical guarantees.",2024-05-20,"Jan-Christoph Klie, Juan Haladjian, Marc Kirchner, Rahul Nair",http://arxiv.org/pdf/2405.11919v2,cs.CL
ARAIDA: Analogical Reasoning-Augmented Interactive Data Annotation,"Human annotation is a time-consuming task that requires a significant amount
of effort. To address this issue, interactive data annotation utilizes an
annotation model to provide suggestions for humans to approve or correct.
However, annotation models trained with limited labeled data are prone to
generating incorrect suggestions, leading to extra human correction effort. To
tackle this challenge, we propose Araida, an analogical reasoning-based
approach that enhances automatic annotation accuracy in the interactive data
annotation setting and reduces the need for human corrections. Araida involves
an error-aware integration strategy that dynamically coordinates an annotation
model and a k-nearest neighbors (KNN) model, giving more importance to KNN's
predictions when predictions from the annotation model are deemed inaccurate.
Empirical studies demonstrate that Araida is adaptable to different annotation
tasks and models. On average, it reduces human correction labor by 11.02%
compared to vanilla interactive data annotation methods.",2024-05-20,"Chen Huang, Yiping Jin, Ilija Ilievski, Wenqiang Lei, Jiancheng Lv",http://arxiv.org/pdf/2405.11912v2,cs.CL
A Constraint-Enforcing Reward for Adversarial Attacks on Text Classifiers,"Text classifiers are vulnerable to adversarial examples --
correctly-classified examples that are deliberately transformed to be
misclassified while satisfying acceptability constraints. The conventional
approach to finding adversarial examples is to define and solve a combinatorial
optimisation problem over a space of allowable transformations. While
effective, this approach is slow and limited by the choice of transformations.
An alternate approach is to directly generate adversarial examples by
fine-tuning a pre-trained language model, as is commonly done for other
text-to-text tasks. This approach promises to be much quicker and more
expressive, but is relatively unexplored. For this reason, in this work we
train an encoder-decoder paraphrase model to generate a diverse range of
adversarial examples. For training, we adopt a reinforcement learning algorithm
and propose a constraint-enforcing reward that promotes the generation of valid
adversarial examples. Experimental results over two text classification
datasets show that our model has achieved a higher success rate than the
original paraphrase model, and overall has proved more effective than other
competitive attacks. Finally, we show how key design choices impact the
generated examples and discuss the strengths and weaknesses of the proposed
approach.",2024-05-20,"Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi",http://arxiv.org/pdf/2405.11904v1,cs.CL
CReMa: Crisis Response through Computational Identification and Matching of Cross-Lingual Requests and Offers Shared on Social Media,"During times of crisis, social media platforms play a crucial role in
facilitating communication and coordinating resources. In the midst of chaos
and uncertainty, communities often rely on these platforms to share urgent
pleas for help, extend support, and organize relief efforts. However, the
overwhelming volume of conversations during such periods can escalate to
unprecedented levels, necessitating the automated identification and matching
of requests and offers to streamline relief operations. Additionally, there is
a notable absence of studies conducted in multi-lingual settings, despite the
fact that any geographical area can have a diverse linguistic population.
Therefore, we propose CReMa (Crisis Response Matcher), a systematic approach
that integrates textual, temporal, and spatial features to address the
challenges of effectively identifying and matching requests and offers on
social media platforms during emergencies. Our approach utilizes a
crisis-specific pre-trained model and a multi-lingual embedding space. We
emulate human decision-making to compute temporal and spatial features and
non-linearly weigh the textual features. The results from our experiments are
promising, outperforming strong baselines. Additionally, we introduce a novel
multi-lingual dataset simulating help-seeking and offering assistance on social
media in 16 languages and conduct comprehensive cross-lingual experiments.
Furthermore, we analyze a million-scale geotagged global dataset to understand
patterns in seeking help and offering assistance on social media. Overall,
these contributions advance the field of crisis informatics and provide
benchmarks for future research in the area.",2024-05-20,"Rabindra Lamsal, Maria Rodriguez Read, Shanika Karunasekera, Muhammad Imran",http://arxiv.org/pdf/2405.11897v2,cs.CL
Unveiling and Manipulating Prompt Influence in Large Language Models,"Prompts play a crucial role in guiding the responses of Large Language Models
(LLMs). However, the intricate role of individual tokens in prompts, known as
input saliency, in shaping the responses remains largely underexplored.
Existing saliency methods either misalign with LLM generation objectives or
rely heavily on linearity assumptions, leading to potential inaccuracies. To
address this, we propose Token Distribution Dynamics (TDD), a
\textcolor{black}{simple yet effective} approach to unveil and manipulate the
role of prompts in generating LLM outputs. TDD leverages the robust
interpreting capabilities of the language model head (LM head) to assess input
saliency. It projects input tokens into the embedding space and then estimates
their significance based on distribution dynamics over the vocabulary. We
introduce three TDD variants: forward, backward, and bidirectional, each
offering unique insights into token relevance. Extensive experiments reveal
that the TDD surpasses state-of-the-art baselines with a big margin in
elucidating the causal relationships between prompts and LLM outputs. Beyond
mere interpretation, we apply TDD to two prompt manipulation tasks for
controlled text generation: zero-shot toxic language suppression and sentiment
steering. Empirical results underscore TDD's proficiency in identifying both
toxic and sentimental cues in prompts, subsequently mitigating toxicity or
modulating sentiment in the generated content.",2024-05-20,"Zijian Feng, Hanzhang Zhou, Zixiao Zhu, Junlang Qian, Kezhi Mao",http://arxiv.org/pdf/2405.11891v1,cs.CL
Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs,"In this study, we propose an axiomatic system to define and quantify the
precise memorization and in-context reasoning effects used by the large
language model (LLM) for language generation. These effects are formulated as
non-linear interactions between tokens/words encoded by the LLM. Specifically,
the axiomatic system enables us to categorize the memorization effects into
foundational memorization effects and chaotic memorization effects, and further
classify in-context reasoning effects into enhanced inference patterns,
eliminated inference patterns, and reversed inference patterns. Besides, the
decomposed effects satisfy the sparsity property and the universal matching
property, which mathematically guarantee that the LLM's confidence score can be
faithfully decomposed into the memorization effects and in-context reasoning
effects. Experiments show that the clear disentanglement of memorization
effects and in-context reasoning effects enables a straightforward examination
of detailed inference patterns encoded by LLMs.",2024-05-20,"Siyu Lou, Yuntian Chen, Xiaodan Liang, Liang Lin, Quanshi Zhang",http://arxiv.org/pdf/2405.11880v1,cs.CL
A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus,"Natural language inference (NLI), the task of recognizing the entailment
relationship in sentence pairs, is an actively studied topic serving as a proxy
for natural language understanding. Despite the relevance of the task in
building conversational agents and improving text classification, machine
translation and other NLP tasks, to the best of our knowledge, there is no
publicly available NLI corpus for the Romanian language. To this end, we
introduce the first Romanian NLI corpus (RoNLI) comprising 58K training
sentence pairs, which are obtained via distant supervision, and 6K validation
and test sentence pairs, which are manually annotated with the correct labels.
We conduct experiments with multiple machine learning methods based on distant
learning, ranging from shallow models based on word embeddings to
transformer-based neural networks, to establish a set of competitive baselines.
Furthermore, we improve on the best model by employing a new curriculum
learning strategy based on data cartography. Our dataset and code to reproduce
the baselines are available at https://github.com/Eduard6421/RONLI.",2024-05-20,"Eduard Poesina, Cornelia Caragea, Radu Tudor Ionescu",http://arxiv.org/pdf/2405.11877v5,cs.CL
xFinder: Large Language Models as Automated Evaluators for Reliable Evaluation,"The continuous advancement of large language models (LLMs) has brought
increasing attention to the critical issue of developing fair and reliable
methods for evaluating their performance. Particularly, the emergence of
cheating phenomena, such as test set leakage and prompt format overfitting,
poses significant challenges to the reliable evaluation of LLMs. As evaluation
frameworks commonly use Regular Expression (RegEx) for answer extraction,
models may adjust their responses to fit formats easily handled by RegEx.
Nevertheless, the key answer extraction module based on RegEx frequently
suffers from extraction errors. Furthermore, recent studies proposing
fine-tuned LLMs as judge models for automated evaluation face challenges in
terms of generalization ability and fairness. This paper comprehensively
analyzes the entire LLM evaluation chain and demonstrates that optimizing the
key answer extraction module improves extraction accuracy and enhances
evaluation reliability. Our findings suggest that improving the key answer
extraction module can lead to higher judgment accuracy and improved evaluation
efficiency compared to the judge models. To address these issues, we propose
xFinder, a novel evaluator for answer extraction and matching in LLM
evaluation. As part of this process, we create a specialized dataset, the
\textbf{K}ey \textbf{A}nswer \textbf{F}inder (KAF) dataset, to ensure effective
model training and evaluation. Generalization tests and real-world evaluations
show that the smallest xFinder model, with only 500 million parameters,
achieves an average extraction accuracy of 93.42\%. In contrast, RegEx accuracy
in the best evaluation framework is 74.38\%. The final judgment accuracy of
xFinder reaches 97.61\%, outperforming existing evaluation frameworks and judge
models.",2024-05-20,"Qingchen Yu, Zifan Zheng, Shichao Song, Zhiyu Li, Feiyu Xiong, Bo Tang, Ding Chen",http://arxiv.org/pdf/2405.11874v3,cs.CL
Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process,"Supervised Fine-Tuning (SFT) and Preference Optimization (PO) are two
fundamental processes for enhancing the capabilities of Language Models (LMs)
post pre-training, aligning them better with human preferences. Although SFT
advances in training efficiency, PO delivers better alignment, thus they are
often combined. However, common practices simply apply them sequentially
without integrating their optimization objectives, ignoring the opportunities
to bridge their paradigm gap and take the strengths from both. To obtain a
unified understanding, we interpret SFT and PO with two sub-processes --
Preference Estimation and Transition Optimization -- defined at token level
within the Markov Decision Process (MDP) framework. This modeling shows that
SFT is only a specialized case of PO with inferior estimation and optimization.
PO evaluates the quality of model's entire generated answer, whereas SFT only
scores predicted tokens based on preceding tokens from target answers.
Therefore, SFT overestimates the ability of model, leading to inferior
optimization. Building on this view, we introduce Intuitive Fine-Tuning (IFT)
to integrate SFT and Preference Optimization into a single process. IFT
captures LMs' intuitive sense of the entire answers through a temporal residual
connection, but it solely relies on a single policy and the same volume of
non-preference-labeled data as SFT. Our experiments show that IFT performs
comparably or even superiorly to sequential recipes of SFT and some typical
Preference Optimization methods across several tasks, particularly those
requires generation, reasoning, and fact-following abilities. An explainable
Frozen Lake game further validates the effectiveness of IFT for getting
competitive policy.",2024-05-20,"Ermo Hua, Biqing Qi, Kaiyan Zhang, Yue Yu, Ning Ding, Xingtai Lv, Kai Tian, Bowen Zhou",http://arxiv.org/pdf/2405.11870v2,cs.CL
CoNLL#: Fine-grained Error Analysis and a Corrected Test Set for CoNLL-03 English,"Modern named entity recognition systems have steadily improved performance in
the age of larger and more powerful neural models. However, over the past
several years, the state-of-the-art has seemingly hit another plateau on the
benchmark CoNLL-03 English dataset. In this paper, we perform a deep dive into
the test outputs of the highest-performing NER models, conducting a
fine-grained evaluation of their performance by introducing new document-level
annotations on the test set. We go beyond F1 scores by categorizing errors in
order to interpret the true state of the art for NER and guide future work. We
review previous attempts at correcting the various flaws of the test set and
introduce CoNLL#, a new corrected version of the test set that addresses its
systematic and most prevalent errors, allowing for low-noise, interpretable
error analysis.",2024-05-20,"Andrew Rueda, Elena Álvarez Mellado, Constantine Lignos",http://arxiv.org/pdf/2405.11865v1,cs.CL
Large language models for newspaper sentiment analysis during COVID-19: The Guardian,"During the COVID-19 pandemic, the news media coverage encompassed a wide
range of topics that includes viral transmission, allocation of medical
resources, and government response measures. There have been studies on
sentiment analysis of social media platforms during COVID-19 to understand the
public response given the rise of cases and government strategies implemented
to control the spread of the virus. Sentiment analysis can provide a better
understanding of changes in societal opinions and emotional trends during the
pandemic. Apart from social media, newspapers have played a vital role in the
dissemination of information, including information from the government,
experts, and also the public about various topics. A study of sentiment
analysis of newspaper sources during COVID-19 for selected countries can give
an overview of how the media covered the pandemic. In this study, we select The
Guardian newspaper and provide a sentiment analysis during various stages of
COVID-19 that includes initial transmission, lockdowns and vaccination. We
employ novel large language models (LLMs) and refine them with expert-labelled
sentiment analysis data. We also provide an analysis of sentiments experienced
pre-pandemic for comparison. The results indicate that during the early
pandemic stages, public sentiment prioritised urgent crisis response, later
shifting focus to addressing the impact on health and the economy. In
comparison with related studies about social media sentiment analyses, we found
a discrepancy between The Guardian with dominance of negative sentiments (sad,
annoyed, anxious and denial), suggesting that social media offers a more
diversified emotional reflection. We found a grim narrative in The Guardian
with overall dominance of negative sentiments, pre and during COVID-19 across
news sections including Australia, UK, World News, and Opinion",2024-05-20,"Rohitash Chandra, Baicheng Zhu, Qingying Fang, Eka Shinjikashvili",http://arxiv.org/pdf/2405.13056v2,cs.CL
Beyond MLE: Investigating SEARNN for Low-Resourced Neural Machine Translation,"Structured prediction tasks, like machine translation, involve learning
functions that map structured inputs to structured outputs. Recurrent Neural
Networks (RNNs) have historically been a popular choice for such tasks,
including in natural language processing (NLP) applications. However, training
RNNs using Maximum Likelihood Estimation (MLE) has its limitations, including
exposure bias and a mismatch between training and testing metrics. SEARNN,
based on the learning to search (L2S) framework, has been proposed as an
alternative to MLE for RNN training. This project explored the potential of
SEARNN to improve machine translation for low-resourced African languages -- a
challenging task characterized by limited training data availability and the
morphological complexity of the languages. Through experiments conducted on
translation for English to Igbo, French to \ewe, and French to \ghomala
directions, this project evaluated the efficacy of SEARNN over MLE in
addressing the unique challenges posed by these languages. With an average BLEU
score improvement of $5.4$\% over the MLE objective, we proved that SEARNN is
indeed a viable algorithm to effectively train RNNs on machine translation for
low-resourced languages.",2024-05-20,Chris Emezue,http://arxiv.org/pdf/2405.11819v1,cs.CL
Systematic Review on Healthcare Systems Engineering utilizing ChatGPT,"This paper presents an analytical framework for conducting academic reviews
in the field of Healthcare Systems Engineering, employing ChatGPT, a
state-of-the-art tool among recent language models. We utilized 9,809 abstract
paragraphs from conference presentations to systematically review the field.
The framework comprises distinct analytical processes, each employing tailored
prompts and the systematic use of the ChatGPT API. Through this framework, we
organized the target field into 11 topic categories and conducted a
comprehensive analysis covering quantitative yearly trends and detailed
sub-categories. This effort explores the potential for leveraging ChatGPT to
alleviate the burden of academic reviews. Furthermore, it provides valuable
insights into the dynamic landscape of Healthcare Systems Engineering research.",2024-05-20,"Jungwoo Kim, Ji-Su Lee, Huijae Kim, Taesik Lee",http://arxiv.org/pdf/2405.11817v1,cs.CL
(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts,"Literary translation remains one of the most challenging frontiers in machine
translation due to the complexity of capturing figurative language, cultural
nuances, and unique stylistic elements. In this work, we introduce TransAgents,
a novel multi-agent framework that simulates the roles and collaborative
practices of a human translation company, including a CEO, Senior Editor,
Junior Editor, Translator, Localization Specialist, and Proofreader. The
translation process is divided into two stages: a preparation stage where the
team is assembled and comprehensive translation guidelines are drafted, and an
execution stage that involves sequential translation, localization,
proofreading, and a final quality check. Furthermore, we propose two innovative
evaluation strategies: Monolingual Human Preference (MHP), which evaluates
translations based solely on target language quality and cultural
appropriateness, and Bilingual LLM Preference (BLP), which leverages large
language models like GPT-4} for direct text comparison. Although TransAgents
achieves lower d-BLEU scores, due to the limited diversity of references, its
translations are significantly better than those of other baselines and are
preferred by both human evaluators and LLMs over traditional human references
and GPT-4} translations. Our findings highlight the potential of multi-agent
collaboration in enhancing translation quality, particularly for longer texts.",2024-05-20,"Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, Kaifu Zhang",http://arxiv.org/pdf/2405.11804v2,cs.CL
Inverse Design of Metal-Organic Frameworks Using Quantum Natural Language Processing,"In this study, we explore the potential of using quantum natural language
processing (QNLP) to inverse design metal-organic frameworks (MOFs) with
targeted properties. Specifically, by analyzing 450 hypothetical MOF structures
consisting of 3 topologies, 10 metal nodes and 15 organic ligands, we
categorize these structures into four distinct classes for pore volume and
$CO_{2}$ Henry's constant values. We then compare various QNLP models (i.e. the
bag-of-words, DisCoCat (Distributional Compositional Categorical), and
sequence-based models) to identify the most effective approach to process the
MOF dataset. Using a classical simulator provided by the IBM Qiskit, the
bag-of-words model is identified to be the optimum model, achieving validation
accuracies of 88.6% and 78.0% for binary classification tasks on pore volume
and $CO_{2}$ Henry's constant, respectively. Further, we developed multi-class
classification models tailored to the probabilistic nature of quantum circuits,
with average test accuracies of 92% and 80% across different classes for pore
volume and $CO_{2}$ Henry's constant datasets. Finally, the performance of
generating MOF with target properties showed accuracies of 93.5% for pore
volume and 87% for $CO_{2}$ Henry's constant, respectively. Although our
investigation covers only a fraction of the vast MOF search space, it marks a
promising first step towards using quantum computing for materials design,
offering a new perspective through which to explore the complex landscape of
MOFs.",2024-05-20,"Shinyoung Kang, Jihan Kim",http://arxiv.org/pdf/2405.11783v2,cs.CL
Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques,"Ordinal Classification (OC) is a widely encountered challenge in Natural
Language Processing (NLP), with applications in various domains such as
sentiment analysis, rating prediction, and more. Previous approaches to tackle
OC have primarily focused on modifying existing or creating novel loss
functions that \textbf{explicitly} account for the ordinal nature of labels.
However, with the advent of Pretrained Language Models (PLMs), it became
possible to tackle ordinality through the \textbf{implicit} semantics of the
labels as well. This paper provides a comprehensive theoretical and empirical
examination of both these approaches. Furthermore, we also offer strategic
recommendations regarding the most effective approach to adopt based on
specific settings.",2024-05-20,"Siva Rajesh Kasa, Aniket Goel, Karan Gupta, Sumegh Roychowdhury, Anish Bhanushali, Nikhil Pattisapu, Prasanna Srinivasa Murthy",http://arxiv.org/pdf/2405.11775v1,cs.CL
Large Language Models for Medicine: A Survey,"To address challenges in the digital economy's landscape of digital
intelligence, large language models (LLMs) have been developed. Improvements in
computational power and available resources have significantly advanced LLMs,
allowing their integration into diverse domains for human life. Medical LLMs
are essential application tools with potential across various medical
scenarios. In this paper, we review LLM developments, focusing on the
requirements and applications of medical LLMs. We provide a concise overview of
existing models, aiming to explore advanced research directions and benefit
researchers for future medical applications. We emphasize the advantages of
medical LLMs in applications, as well as the challenges encountered during
their development. Finally, we suggest directions for technical integration to
mitigate challenges and potential research directions for the future of medical
LLMs, aiming to meet the demands of the medical field better.",2024-05-20,"Yanxin Zheng, Wensheng Gan, Zefeng Chen, Zhenlian Qi, Qian Liang, Philip S. Yu",http://arxiv.org/pdf/2405.13055v1,cs.CL
Token-wise Influential Training Data Retrieval for Large Language Models,"Given a Large Language Model (LLM) generation, how can we identify which
training data led to this generation? In this paper, we proposed RapidIn, a
scalable framework adapting to LLMs for estimating the influence of each
training data. The proposed framework consists of two stages: caching and
retrieval. First, we compress the gradient vectors by over 200,000x, allowing
them to be cached on disk or in GPU/CPU memory. Then, given a generation,
RapidIn efficiently traverses the cached gradients to estimate the influence
within minutes, achieving over a 6,326x speedup. Moreover, RapidIn supports
multi-GPU parallelization to substantially accelerate caching and retrieval.
Our empirical result confirms the efficiency and effectiveness of RapidIn.",2024-05-20,"Huawei Lin, Jikai Long, Zhaozhuo Xu, Weijie Zhao",http://arxiv.org/pdf/2405.11724v2,cs.CL
"OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework","As large language models (LLMs) continue to grow by scaling laws,
reinforcement learning from human feedback (RLHF) has gained significant
attention due to its outstanding performance. However, unlike pretraining or
fine-tuning a single model, scaling reinforcement learning from human feedback
(RLHF) for training large language models poses coordination challenges across
four models. We present OpenRLHF, an open-source framework enabling efficient
RLHF scaling. Unlike existing RLHF frameworks that co-locate four models on the
same GPUs, OpenRLHF re-designs scheduling for the models beyond 70B parameters
using Ray, vLLM, and DeepSpeed, leveraging improved resource utilization and
diverse training approaches. Integrating seamlessly with Hugging Face, OpenRLHF
provides an out-of-the-box solution with optimized algorithms and launch
scripts, which ensures user-friendliness. OpenRLHF implements RLHF, DPO,
rejection sampling, and other alignment techniques. Empowering state-of-the-art
LLM development, OpenRLHF's code is available at
\url{https://github.com/OpenRLHF/OpenRLHF}.",2024-05-20,"Jian Hu, Xibin Wu, Zilin Zhu, Xianyu, Weixun Wang, Dehao Zhang, Yu Cao",http://arxiv.org/pdf/2405.11143v4,cs.CL
Your Transformer is Secretly Linear,"This paper reveals a novel linear characteristic exclusive to transformer
decoders, including models such as GPT, LLaMA, OPT, BLOOM and others. We
analyze embedding transformations between sequential layers, uncovering a
near-perfect linear relationship (Procrustes similarity score of 0.99).
However, linearity decreases when the residual component is removed due to a
consistently low output norm of the transformer layer. Our experiments show
that removing or linearly approximating some of the most linear blocks of
transformers does not affect significantly the loss or model performance.
Moreover, in our pretraining experiments on smaller models we introduce a
cosine-similarity-based regularization, aimed at reducing layer linearity. This
regularization improves performance metrics on benchmarks like Tiny Stories and
SuperGLUE and as well successfully decreases the linearity of the models. This
study challenges the existing understanding of transformer architectures,
suggesting that their operation may be more linear than previously assumed.",2024-05-19,"Anton Razzhigaev, Matvey Mikhalchuk, Elizaveta Goncharova, Nikolai Gerasimenko, Ivan Oseledets, Denis Dimitrov, Andrey Kuznetsov",http://arxiv.org/pdf/2405.12250v1,cs.CL
ColorFoil: Investigating Color Blindness in Large Vision and Language Models,"With the utilization of Transformer architecture, large Vision and Language
(V&L) models have shown promising performance in even zero-shot settings.
Several studies, however, indicate a lack of robustness of the models when
dealing with complex linguistics and visual attributes. In this work, we
introduce a novel V&L benchmark - ColorFoil, by creating color-related foils to
assess the models' perception ability to detect colors like red, white, green,
etc. We evaluate seven state-of-the-art V&L models including CLIP, ViLT,
GroupViT, and BridgeTower, etc. in a zero-shot setting and present intriguing
findings from the V&L models. The experimental evaluation indicates that ViLT
and BridgeTower demonstrate much better color perception capabilities compared
to CLIP and its variants and GroupViT. Moreover, CLIP-based models and GroupViT
struggle to distinguish colors that are visually distinct to humans with normal
color perception ability.",2024-05-19,"Ahnaf Mozib Samin, M. Firoz Ahmed, Md. Mushtaq Shahriyar Rafee",http://arxiv.org/pdf/2405.11685v2,cs.CL
MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models,"The pretrain+fine-tune paradigm is foundational for deploying large language
models (LLMs) across various downstream applications. Within this framework,
Low-Rank Adaptation (LoRA) stands out for its parameter-efficient fine-tuning
(PEFT), producing numerous reusable task-specific LoRA adapters. However, this
approach requires explicit task intention selection, posing challenges for
autonomous task sensing and switching during inference with multiple existing
LoRA adapters embedded in a single LLM. In this work, we introduce MeteoRA
(Multiple-tasks embedded LoRA), a scalable and efficient framework that reuses
multiple task-specific LoRA adapters into the base LLM via a full-mode
Mixture-of-Experts (MoE) architecture. This framework also includes novel MoE
forward acceleration strategies to address the efficiency challenges of
traditional MoE implementations. Our evaluation, using the LlaMA2-13B and
LlaMA3-8B base models equipped with 28 existing LoRA adapters through MeteoRA,
demonstrates equivalent performance with the traditional PEFT method. Moreover,
the LLM equipped with MeteoRA achieves superior performance in handling
composite tasks, effectively solving ten sequential problems in a single
inference pass, thereby demonstrating the framework's enhanced capability for
timely adapter switching.",2024-05-19,"Jingwei Xu, Junyu Lai, Yunpeng Huang",http://arxiv.org/pdf/2405.13053v3,cs.CL
Large Language Models Can Infer Personality from Free-Form User Interactions,"This study investigates the capacity of Large Language Models (LLMs) to infer
the Big Five personality traits from free-form user interactions. The results
demonstrate that a chatbot powered by GPT-4 can infer personality with moderate
accuracy, outperforming previous approaches drawing inferences from static text
content. The accuracy of inferences varied across different conversational
settings. Performance was highest when the chatbot was prompted to elicit
personality-relevant information from users (mean r=.443, range=[.245, .640]),
followed by a condition placing greater emphasis on naturalistic interaction
(mean r=.218, range=[.066, .373]). Notably, the direct focus on personality
assessment did not result in a less positive user experience, with participants
reporting the interactions to be equally natural, pleasant, engaging, and
humanlike across both conditions. A chatbot mimicking ChatGPT's default
behavior of acting as a helpful assistant led to markedly inferior personality
inferences and lower user experience ratings but still captured psychologically
meaningful information for some of the personality traits (mean r=.117,
range=[-.004, .209]). Preliminary analyses suggest that the accuracy of
personality inferences varies only marginally across different
socio-demographic subgroups. Our results highlight the potential of LLMs for
psychological profiling based on conversational interactions. We discuss
practical implications and ethical challenges associated with these findings.",2024-05-19,"Heinrich Peters, Moran Cerf, Sandra C. Matz",http://arxiv.org/pdf/2405.13052v1,cs.CL
Cyber Risks of Machine Translation Critical Errors : Arabic Mental Health Tweets as a Case Study,"With the advent of Neural Machine Translation (NMT) systems, the MT output
has reached unprecedented accuracy levels which resulted in the ubiquity of MT
tools on almost all online platforms with multilingual content. However, NMT
systems, like other state-of-the-art AI generative systems, are prone to errors
that are deemed machine hallucinations. The problem with NMT hallucinations is
that they are remarkably \textit{fluent} hallucinations. Since they are trained
to produce grammatically correct utterances, NMT systems are capable of
producing mistranslations that are too fluent to be recognised by both users of
the MT tool, as well as by automatic quality metrics that are used to gauge
their performance. In this paper, we introduce an authentic dataset of machine
translation critical errors to point to the ethical and safety issues involved
in the common use of MT. The dataset comprises mistranslations of Arabic mental
health postings manually annotated with critical error types. We also show how
the commonly used quality metrics do not penalise critical errors and highlight
this as a critical issue that merits further attention from researchers.",2024-05-19,"Hadeel Saadany, Ashraf Tantawy, Constantin Orasan",http://arxiv.org/pdf/2405.11668v1,cs.CL
"Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning","The adoption of large language models (LLMs) in healthcare has attracted
significant research interest. However, their performance in healthcare remains
under-investigated and potentially limited, due to i) they lack rich
domain-specific knowledge and medical reasoning skills; and ii) most
state-of-the-art LLMs are unimodal, text-only models that cannot directly
process multimodal inputs. To this end, we propose a multimodal medical
collaborative reasoning framework \textbf{MultiMedRes}, which incorporates a
learner agent to proactively gain essential information from domain-specific
expert models, to solve medical multimodal reasoning problems. Our method
includes three steps: i) \textbf{Inquire}: The learner agent first decomposes
given complex medical reasoning problems into multiple domain-specific
sub-problems; ii) \textbf{Interact}: The agent then interacts with
domain-specific expert models by repeating the ``ask-answer'' process to
progressively obtain different domain-specific knowledge; iii)
\textbf{Integrate}: The agent finally integrates all the acquired
domain-specific knowledge to accurately address the medical reasoning problem.
We validate the effectiveness of our method on the task of difference visual
question answering for X-ray images. The experiments demonstrate that our
zero-shot prediction achieves state-of-the-art performance, and even
outperforms the fully supervised methods. Besides, our approach can be
incorporated into various LLMs and multimodal LLMs to significantly boost their
performance.",2024-05-19,"Zishan Gu, Fenglin Liu, Changchang Yin, Ping Zhang",http://arxiv.org/pdf/2405.11640v1,cs.CL
Zero-Shot Stance Detection using Contextual Data Generation with LLMs,"Stance detection, the classification of attitudes expressed in a text towards
a specific topic, is vital for applications like fake news detection and
opinion mining. However, the scarcity of labeled data remains a challenge for
this task. To address this problem, we propose Dynamic Model Adaptation with
Contextual Data Generation (DyMoAdapt) that combines Few-Shot Learning and
Large Language Models. In this approach, we aim to fine-tune an existing model
at test time. We achieve this by generating new topic-specific data using
GPT-3. This method could enhance performance by allowing the adaptation of the
model to new topics. However, the results did not increase as we expected.
Furthermore, we introduce the Multi Generated Topic VAST (MGT-VAST) dataset,
which extends VAST using GPT-3. In this dataset, each context is associated
with multiple topics, allowing the model to understand the relationship between
contexts and various potential topics",2024-05-19,"Ghazaleh Mahmoudi, Babak Behkamkia, Sauleh Eetemadi",http://arxiv.org/pdf/2405.11637v1,cs.CL
Continuous Predictive Modeling of Clinical Notes and ICD Codes in Patient Health Records,"Electronic Health Records (EHR) serve as a valuable source of patient
information, offering insights into medical histories, treatments, and
outcomes. Previous research has developed systems for detecting applicable ICD
codes that should be assigned while writing a given EHR document, mainly
focusing on discharge summaries written at the end of a hospital stay. In this
work, we investigate the potential of predicting these codes for the whole
patient stay at different time points during their stay, even before they are
officially assigned by clinicians. The development of methods to predict
diagnoses and treatments earlier in advance could open opportunities for
predictive medicine, such as identifying disease risks sooner, suggesting
treatments, and optimizing resource allocation. Our experiments show that
predictions regarding final ICD codes can be made already two days after
admission and we propose a custom model that improves performance on this early
prediction task.",2024-05-19,"Mireia Hernandez Caralt, Clarence Boon Liang Ng, Marek Rei",http://arxiv.org/pdf/2405.11622v2,cs.CL
Decoding by Contrasting Knowledge: Enhancing LLMs' Confidence on Edited Facts,"The knowledge within large language models (LLMs) may become outdated
quickly. While in-context editing (ICE) is currently the most effective method
for knowledge editing (KE), it is constrained by the black-box modeling of LLMs
and thus lacks interpretability. Our work aims to elucidate the superior
performance of ICE on the KE by analyzing the impacts of in-context new
knowledge on token-wise distributions. We observe that despite a significant
boost in logits of the new knowledge, the performance of is still hindered by
stubborn knowledge. Stubborn knowledge refers to as facts that have gained
excessive confidence during pretraining, making it hard to edit effectively. To
address this issue and further enhance the performance of ICE, we propose a
novel approach termed $\textbf{De}$coding by $\textbf{C}$ontrasting
$\textbf{K}$nowledge (DeCK). DeCK derives the distribution of the next token by
contrasting the logits obtained from the newly edited knowledge guided by ICE
with those from the unedited parametric knowledge. Our experiments consistently
demonstrate that DeCK enhances the confidence of LLMs in edited facts. For
instance, it improves the performance of LLaMA3-8B-instruct on MQuAKE by up to
219%, demonstrating its capability to strengthen ICE in the editing of stubborn
knowledge. Our work paves the way to develop the both effective and accountable
KE methods for LLMs. (The source code is available at:
https://deck-llm.meirtz.com)",2024-05-19,"Baolong Bi, Shenghua Liu, Lingrui Mei, Yiwei Wang, Pengliang Ji, Xueqi Cheng",http://arxiv.org/pdf/2405.11613v2,cs.CL
Language Reconstruction with Brain Predictive Coding from fMRI Data,"Many recent studies have shown that the perception of speech can be decoded
from brain signals and subsequently reconstructed as continuous language.
However, there is a lack of neurological basis for how the semantic information
embedded within brain signals can be used more effectively to guide language
reconstruction. The theory of predictive coding suggests that human brain
naturally engages in continuously predicting future word representations that
span multiple timescales. This implies that the decoding of brain signals could
potentially be associated with a predictable future. To explore the predictive
coding theory within the context of language reconstruction, this paper
proposes a novel model \textsc{PredFT} for jointly modeling neural decoding and
brain prediction. It consists of a main decoding network for language
reconstruction and a side network for predictive coding. The side network
obtains brain predictive coding representation from related brain regions of
interest with a multi-head self-attention module. This representation is fused
into the main decoding network with cross-attention to facilitate the language
models' generation process. Experiments are conducted on the largest
naturalistic language comprehension fMRI dataset Narratives. \textsc{PredFT}
achieves current state-of-the-art decoding performance with a maximum BLEU-1
score of $27.8\%$.",2024-05-19,"Congchi Yin, Ziyi Ye, Piji Li",http://arxiv.org/pdf/2405.11597v1,cs.CL
SLAB: Efficient Transformers with Simplified Linear Attention and Progressive Re-parameterized Batch Normalization,"Transformers have become foundational architectures for both natural language
and computer vision tasks. However, the high computational cost makes it quite
challenging to deploy on resource-constraint devices. This paper investigates
the computational bottleneck modules of efficient transformer, i.e.,
normalization layers and attention modules. LayerNorm is commonly used in
transformer architectures but is not computational friendly due to statistic
calculation during inference. However, replacing LayerNorm with more efficient
BatchNorm in transformer often leads to inferior performance and collapse in
training. To address this problem, we propose a novel method named PRepBN to
progressively replace LayerNorm with re-parameterized BatchNorm in training.
Moreover, we propose a simplified linear attention (SLA) module that is simple
yet effective to achieve strong performance. Extensive experiments on image
classification as well as object detection demonstrate the effectiveness of our
proposed method. For example, our SLAB-Swin obtains $83.6\%$ top-1 accuracy on
ImageNet-1K with $16.2$ms latency, which is $2.4$ms less than that of
Flatten-Swin with $0.1\%$ higher accuracy. We also evaluated our method for
language modeling task and obtain comparable performance and lower
latency.Codes are publicly available at https://github.com/xinghaochen/SLAB and
https://github.com/mindspore-lab/models/tree/master/research/huawei-noah/SLAB.",2024-05-19,"Jialong Guo, Xinghao Chen, Yehui Tang, Yunhe Wang",http://arxiv.org/pdf/2405.11582v2,cs.CL
Exploring the Capabilities of Prompted Large Language Models in Educational and Assessment Applications,"In the era of generative artificial intelligence (AI), the fusion of large
language models (LLMs) offers unprecedented opportunities for innovation in the
field of modern education. We embark on an exploration of prompted LLMs within
the context of educational and assessment applications to uncover their
potential. Through a series of carefully crafted research questions, we
investigate the effectiveness of prompt-based techniques in generating
open-ended questions from school-level textbooks, assess their efficiency in
generating open-ended questions from undergraduate-level technical textbooks,
and explore the feasibility of employing a chain-of-thought inspired
multi-stage prompting approach for language-agnostic multiple-choice question
(MCQ) generation. Additionally, we evaluate the ability of prompted LLMs for
language learning, exemplified through a case study in the low-resource Indian
language Bengali, to explain Bengali grammatical errors. We also evaluate the
potential of prompted LLMs to assess human resource (HR) spoken interview
transcripts. By juxtaposing the capabilities of LLMs with those of human
experts across various educational tasks and domains, our aim is to shed light
on the potential and limitations of LLMs in reshaping educational practices.",2024-05-19,"Subhankar Maity, Aniket Deroy, Sudeshna Sarkar",http://arxiv.org/pdf/2405.11579v1,cs.CL
A Multi-Perspective Analysis of Memorization in Large Language Models,"Large Language Models (LLMs), trained on massive corpora with billions of
parameters, show unprecedented performance in various fields. Though surprised
by their excellent performances, researchers also noticed some special
behaviors of those LLMs. One of those behaviors is memorization, in which LLMs
can generate the same content used to train them. Though previous research has
discussed memorization, the memorization of LLMs still lacks explanation,
especially the cause of memorization and the dynamics of generating them. In
this research, we comprehensively discussed memorization from various
perspectives and extended the discussion scope to not only just the memorized
content but also less and unmemorized content. Through various studies, we
found that: (1) Through experiments, we revealed the relation of memorization
between model size, continuation size, and context size. Further, we showed how
unmemorized sentences transition to memorized sentences. (2) Through embedding
analysis, we showed the distribution and decoding dynamics across model size in
embedding space for sentences with different memorization scores. The n-gram
statistics analysis presents d (3) An analysis over n-gram and entropy decoding
dynamics discovered a boundary effect when the model starts to generate
memorized sentences or unmemorized sentences. (4)We trained a Transformer model
to predict the memorization of different models, showing that it is possible to
predict memorizations by context.",2024-05-19,"Bowen Chen, Namgi Han, Yusuke Miyao",http://arxiv.org/pdf/2405.11577v4,cs.CL
SEEP: Training Dynamics Grounds Latent Representation Search for Mitigating Backdoor Poisoning Attacks,"Modern NLP models are often trained on public datasets drawn from diverse
sources, rendering them vulnerable to data poisoning attacks. These attacks can
manipulate the model's behavior in ways engineered by the attacker. One such
tactic involves the implantation of backdoors, achieved by poisoning specific
training instances with a textual trigger and a target class label. Several
strategies have been proposed to mitigate the risks associated with backdoor
attacks by identifying and removing suspected poisoned examples. However, we
observe that these strategies fail to offer effective protection against
several advanced backdoor attacks. To remedy this deficiency, we propose a
novel defensive mechanism that first exploits training dynamics to identify
poisoned samples with high precision, followed by a label propagation step to
improve recall and thus remove the majority of poisoned instances. Compared
with recent advanced defense methods, our method considerably reduces the
success rates of several backdoor attacks while maintaining high classification
accuracy on clean test sets.",2024-05-19,"Xuanli He, Qiongkai Xu, Jun Wang, Benjamin I. P. Rubinstein, Trevor Cohn",http://arxiv.org/pdf/2405.11575v1,cs.CL
DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for Unconventional Reasoning,"While significant work has been done in the field of NLP on vertical
thinking, which involves primarily logical thinking, little work has been done
towards lateral thinking, which involves looking at problems from an
unconventional perspective and defying existing conceptions and notions.
Towards this direction, SemEval 2024 introduces the task of BRAINTEASER, which
involves two types of questions -- Sentence Puzzles and Word Puzzles that defy
conventional common-sense reasoning and constraints. In this paper, we tackle
both types of questions using few-shot prompting on GPT-3.5 and gain insights
regarding the difference in the nature of the two types. Our prompting strategy
placed us 26th on the leaderboard for the Sentence Puzzle and 15th on the Word
Puzzle task.",2024-05-19,"Suyash Vardhan Mathur, Akshett Rai Jindal, Manish Shrivastava",http://arxiv.org/pdf/2405.11559v1,cs.CL
Simple-Sampling and Hard-Mixup with Prototypes to Rebalance Contrastive Learning for Text Classification,"Text classification is a crucial and fundamental task in natural language
processing. Compared with the previous learning paradigm of pre-training and
fine-tuning by cross entropy loss, the recently proposed supervised contrastive
learning approach has received tremendous attention due to its powerful feature
learning capability and robustness. Although several studies have incorporated
this technique for text classification, some limitations remain. First, many
text datasets are imbalanced, and the learning mechanism of supervised
contrastive learning is sensitive to data imbalance, which may harm the model
performance. Moreover, these models leverage separate classification branch
with cross entropy and supervised contrastive learning branch without explicit
mutual guidance. To this end, we propose a novel model named SharpReCL for
imbalanced text classification tasks. First, we obtain the prototype vector of
each class in the balanced classification branch to act as a representation of
each class. Then, by further explicitly leveraging the prototype vectors, we
construct a proper and sufficient target sample set with the same size for each
class to perform the supervised contrastive learning procedure. The empirical
results show the effectiveness of our model, which even outperforms popular
large language models across several datasets.",2024-05-19,"Mengyu Li, Yonghao Liu, Fausto Giunchiglia, Xiaoyue Feng, Renchu Guan",http://arxiv.org/pdf/2405.11524v1,cs.CL
MSNER: A Multilingual Speech Dataset for Named Entity Recognition,"While extensively explored in text-based tasks, Named Entity Recognition
(NER) remains largely neglected in spoken language understanding. Existing
resources are limited to a single, English-only dataset. This paper addresses
this gap by introducing MSNER, a freely available, multilingual speech corpus
annotated with named entities. It provides annotations to the VoxPopuli dataset
in four languages (Dutch, French, German, and Spanish). We have also releasing
an efficient annotation tool that leverages automatic pre-annotations for
faster manual refinement. This results in 590 and 15 hours of silver-annotated
speech for training and validation, alongside a 17-hour, manually-annotated
evaluation set. We further provide an analysis comparing silver and gold
annotations. Finally, we present baseline NER models to stimulate further
research on this newly available dataset.",2024-05-19,"Quentin Meeus, Marie-Francine Moens, Hugo Van hamme",http://arxiv.org/pdf/2405.11519v1,cs.CL
SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations,"The ability to understand emotions is an essential component of human-like
artificial intelligence, as emotions greatly influence human cognition,
decision making, and social interactions. In addition to emotion recognition in
conversations, the task of identifying the potential causes behind an
individual's emotional state in conversations, is of great importance in many
application scenarios. We organize SemEval-2024 Task 3, named Multimodal
Emotion Cause Analysis in Conversations, which aims at extracting all pairs of
emotions and their corresponding causes from conversations. Under different
modality settings, it consists of two subtasks: Textual Emotion-Cause Pair
Extraction in Conversations (TECPE) and Multimodal Emotion-Cause Pair
Extraction in Conversations (MECPE). The shared task has attracted 143
registrations and 216 successful submissions. In this paper, we introduce the
task, dataset and evaluation settings, summarize the systems of the top teams,
and discuss the findings of the participants.",2024-05-19,"Fanfan Wang, Heqing Ma, Jianfei Yu, Rui Xia, Erik Cambria",http://arxiv.org/pdf/2405.13049v3,cs.CL
Effective In-Context Example Selection through Data Compression,"In-context learning has been extensively validated in large language models.
However, the mechanism and selection strategy for in-context example selection,
which is a crucial ingredient in this approach, lacks systematic and in-depth
research. In this paper, we propose a data compression approach to the
selection of in-context examples. We introduce a two-stage method that can
effectively choose relevant examples and retain sufficient information about
the training dataset within the in-context examples. Our method shows a
significant improvement of an average of 5.90% across five different real-world
datasets using four language models.",2024-05-19,"Zhongxiang Sun, Kepu Zhang, Haoyu Wang, Xiao Zhang, Jun Xu",http://arxiv.org/pdf/2405.11465v1,cs.CL
Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion,"Prompt tuning is a promising method to fine-tune a pre-trained language model
without retraining its large-scale parameters. Instead, it attaches a soft
prompt to the input text, whereby downstream tasks can be well adapted by
merely learning the embeddings of prompt tokens. Nevertheless, existing methods
still suffer from two challenges: (i) they are hard to balance accuracy and
efficiency. A longer (shorter) soft prompt generally leads to a better(worse)
accuracy but at the cost of more (less) training time. (ii)The performance may
not be consistent when adapting to different downstream tasks. We attribute it
to the same embedding space but responsible for different requirements of
downstream tasks. To address these issues, we propose an Efficient Prompt
Tuning method (EPT) by multi-space projection and prompt fusion. Specifically,
it decomposes a given soft prompt into a shorter prompt and two low-rank
matrices, significantly reducing the training time. Accuracy is also enhanced
by leveraging low-rank matrices and the short prompt as additional knowledge
sources to enrich the semantics of the original short prompt. In addition, we
project the soft prompt into multiple subspaces to improve the performance
consistency, and then adaptively learn the combination weights of different
spaces through a gating network. Experiments on 13 natural language processing
downstream tasks show that our method significantly and consistently
outperforms 11 comparison methods with the relative percentage of improvements
up to 12.9%, and training time decreased by 14%.",2024-05-19,"Pengxiang Lan, Enneng Yang, Yuting Liu, Guibing Guo, Jianzhe Zhao, Xingwei Wang",http://arxiv.org/pdf/2405.11464v3,cs.CL
DocReLM: Mastering Document Retrieval with Language Model,"With over 200 million published academic documents and millions of new
documents being written each year, academic researchers face the challenge of
searching for information within this vast corpus. However, existing retrieval
systems struggle to understand the semantics and domain knowledge present in
academic papers. In this work, we demonstrate that by utilizing large language
models, a document retrieval system can achieve advanced semantic understanding
capabilities, significantly outperforming existing systems. Our approach
involves training the retriever and reranker using domain-specific data
generated by large language models. Additionally, we utilize large language
models to identify candidates from the references of retrieved papers to
further enhance the performance. We use a test set annotated by academic
researchers in the fields of quantum physics and computer vision to evaluate
our system's performance. The results show that DocReLM achieves a Top 10
accuracy of 44.12% in computer vision, compared to Google Scholar's 15.69%, and
an increase to 36.21% in quantum physics, while that of Google Scholar is
12.96%.",2024-05-19,"Gengchen Wei, Xinle Pang, Tianning Zhang, Yu Sun, Xun Qian, Chen Lin, Han-Sen Zhong, Wanli Ouyang",http://arxiv.org/pdf/2405.11461v1,cs.CL
Du-IN: Discrete units-guided mask modeling for decoding speech from Intracranial Neural signals,"Invasive brain-computer interfaces with Electrocorticography (ECoG) have
shown promise for high-performance speech decoding in medical applications, but
less damaging methods like intracranial stereo-electroencephalography (sEEG)
remain underexplored. With rapid advances in representation learning,
leveraging abundant recordings to enhance speech decoding is increasingly
attractive. However, popular methods often pre-train temporal models based on
brain-level tokens, overlooking that brain activities in different regions are
highly desynchronized during tasks. Alternatively, they pre-train
spatial-temporal models based on channel-level tokens but fail to evaluate them
on challenging tasks like speech decoding, which requires intricate processing
in specific language-related areas. To address this issue, we collected a
well-annotated Chinese word-reading sEEG dataset targeting language-related
brain networks from 12 subjects. Using this benchmark, we developed the Du-IN
model, which extracts contextual embeddings based on region-level tokens
through discrete codex-guided mask modeling. Our model achieves
state-of-the-art performance on the 61-word classification task, surpassing all
baselines. Model comparisons and ablation studies reveal that our design
choices, including (i) temporal modeling based on region-level tokens by
utilizing 1D depthwise convolution to fuse channels in the ventral sensorimotor
cortex (vSMC) and superior temporal gyrus (STG) and (ii) self-supervision
through discrete codex-guided mask modeling, significantly contribute to this
performance. Overall, our approach -- inspired by neuroscience findings and
capitalizing on region-level representations from specific brain regions -- is
suitable for invasive brain modeling and represents a promising neuro-inspired
AI approach in brain-computer interfaces.",2024-05-19,"Hui Zheng, Hai-Teng Wang, Wei-Bang Jiang, Zhong-Tao Chen, Li He, Pei-Yang Lin, Peng-Hu Wei, Guo-Guang Zhao, Yun-Zhe Liu",http://arxiv.org/pdf/2405.11459v3,cs.CL
MAML-en-LLM: Model Agnostic Meta-Training of LLMs for Improved In-Context Learning,"Adapting large language models (LLMs) to unseen tasks with in-context
training samples without fine-tuning remains an important research problem. To
learn a robust LLM that adapts well to unseen tasks, multiple meta-training
approaches have been proposed such as MetaICL and MetaICT, which involve
meta-training pre-trained LLMs on a wide variety of diverse tasks. These
meta-training approaches essentially perform in-context multi-task fine-tuning
and evaluate on a disjointed test set of tasks. Even though they achieve
impressive performance, their goal is never to compute a truly general set of
parameters. In this paper, we propose MAML-en-LLM, a novel method for
meta-training LLMs, which can learn truly generalizable parameters that not
only perform well on disjointed tasks but also adapts to unseen tasks. We see
an average increase of 2% on unseen domains in the performance while a massive
4% improvement on adaptation performance. Furthermore, we demonstrate that
MAML-en-LLM outperforms baselines in settings with limited amount of training
data on both seen and unseen domains by an average of 2%. Finally, we discuss
the effects of type of tasks, optimizers and task complexity, an avenue barely
explored in meta-training literature. Exhaustive experiments across 7 task
settings along with two data settings demonstrate that models trained with
MAML-en-LLM outperform SOTA meta-training approaches.",2024-05-19,"Sanchit Sinha, Yuguang Yue, Victor Soto, Mayank Kulkarni, Jianhua Lu, Aidong Zhang",http://arxiv.org/pdf/2405.11446v1,cs.CL
EmbSum: Leveraging the Summarization Capabilities of Large Language Models for Content-Based Recommendations,"Content-based recommendation systems play a crucial role in delivering
personalized content to users in the digital world. In this work, we introduce
EmbSum, a novel framework that enables offline pre-computations of users and
candidate items while capturing the interactions within the user engagement
history. By utilizing the pretrained encoder-decoder model and poly-attention
layers, EmbSum derives User Poly-Embedding (UPE) and Content Poly-Embedding
(CPE) to calculate relevance scores between users and candidate items. EmbSum
actively learns the long user engagement histories by generating user-interest
summary with supervision from large language model (LLM). The effectiveness of
EmbSum is validated on two datasets from different domains, surpassing
state-of-the-art (SoTA) methods with higher accuracy and fewer parameters.
Additionally, the model's ability to generate summaries of user interests
serves as a valuable by-product, enhancing its usefulness for personalized
content recommendations.",2024-05-19,"Chiyu Zhang, Yifei Sun, Minghao Wu, Jun Chen, Jie Lei, Muhammad Abdul-Mageed, Rong Jin, Angli Liu, Ji Zhu, Sem Park, Ning Yao, Bo Long",http://arxiv.org/pdf/2405.11441v2,cs.CL
MHPP: Exploring the Capabilities and Limitations of Language Models Beyond Basic Code Generation,"Recent advancements in large language models (LLMs) have greatly improved
code generation, specifically at the function level. For instance, GPT-4o has
achieved a 91.0\% pass rate on HumanEval. However, this draws into question the
adequacy of existing benchmarks in thoroughly assessing function-level code
generation capabilities. Our study analyzed two common benchmarks, HumanEval
and MBPP, and found that these might not thoroughly evaluate LLMs' code
generation capacities due to limitations in quality, difficulty, and
granularity. To resolve this, we introduce the Mostly Hard Python Problems
(MHPP) dataset, consisting of 210 unique human-curated problems. By focusing on
the combination of natural language and code reasoning, MHPP gauges LLMs'
abilities to comprehend specifications and restrictions, engage in multi-step
reasoning, and apply coding knowledge effectively. Initial evaluations of 26
LLMs using MHPP showed many high-performing models on HumanEval failed to
achieve similar success on MHPP. Moreover, MHPP highlighted various previously
undiscovered limitations within various LLMs, leading us to believe that it
could pave the way for a better understanding of LLMs' capabilities and
limitations. MHPP, evaluation pipeline, and leaderboard can be found in
https://github.com/SparksofAGI/MHPP.",2024-05-19,"Jianbo Dai, Jianqiao Lu, Yunlong Feng, Dong Huang, Guangtao Zeng, Rongju Ruan, Ming Cheng, Haochen Tan, Zhijiang Guo",http://arxiv.org/pdf/2405.11430v2,cs.CL
Metric Dimension and Resolvability of Jaccard Spaces,"A subset of points in a metric space is said to resolve it if each point in
the space is uniquely characterized by its distance to each point in the
subset. In particular, resolving sets can be used to represent points in
abstract metric spaces as Euclidean vectors. Importantly, due to the triangle
inequality, points close by in the space are represented as vectors with
similar coordinates, which may find applications in classification problems of
symbolic objects under suitably chosen metrics. In this manuscript, we address
the resolvability of Jaccard spaces, i.e., metric spaces of the form
$(2^X,\text{Jac})$, where $2^X$ is the power set of a finite set $X$, and
$\text{Jac}$ is the Jaccard distance between subsets of $X$. Specifically, for
different $a,b\in 2^X$, $\text{Jac}(a,b)=|a\Delta b|/|a\cup b|$, where
$|\cdot|$ denotes size (i.e., cardinality) and $\Delta$ denotes the symmetric
difference of sets. We combine probabilistic and linear algebra arguments to
construct highly likely but nearly optimal (i.e., of minimal size) resolving
sets of $(2^X,\text{Jac})$. In particular, we show that the metric dimension of
$(2^X,\text{Jac})$, i.e., the minimum size of a resolving set of this space, is
$\Theta(|X|/\ln|X|)$. In addition, we show that a much smaller subset of $2^X$
suffices to resolve, with high probability, all different pairs of subsets of
$X$ of cardinality at most $\sqrt{|X|}/\ln|X|$, up to a factor.",2024-05-19,"Manuel E. Lladser, Alexander J. Paradise",http://arxiv.org/pdf/2405.11424v2,cs.CL
Large Language Models are Biased Reinforcement Learners,"In-context learning enables large language models (LLMs) to perform a variety
of tasks, including learning to make reward-maximizing choices in simple bandit
tasks. Given their potential use as (autonomous) decision-making agents, it is
important to understand how these models perform such reinforcement learning
(RL) tasks and the extent to which they are susceptible to biases. Motivated by
the fact that, in humans, it has been widely documented that the value of an
outcome depends on how it compares to other local outcomes, the present study
focuses on whether similar value encoding biases apply to how LLMs encode
rewarding outcomes. Results from experiments with multiple bandit tasks and
models show that LLMs exhibit behavioral signatures of a relative value bias.
Adding explicit outcome comparisons to the prompt produces opposing effects on
performance, enhancing maximization in trained choice sets but impairing
generalization to new choice sets. Computational cognitive modeling reveals
that LLM behavior is well-described by a simple RL algorithm that incorporates
relative values at the outcome encoding stage. Lastly, we present preliminary
evidence that the observed biases are not limited to fine-tuned LLMs, and that
relative value processing is detectable in the final hidden layer activations
of a raw, pretrained model. These findings have important implications for the
use of LLMs in decision-making applications.",2024-05-19,"William M. Hayes, Nicolas Yax, Stefano Palminteri",http://arxiv.org/pdf/2405.11422v1,cs.CL
Can Public LLMs be used for Self-Diagnosis of Medical Conditions ?,"Advancements in deep learning have generated a large-scale interest in the
development of foundational deep learning models. The development of Large
Language Models (LLM) has evolved as a transformative paradigm in
conversational tasks, which has led to its integration and extension even in
the critical domain of healthcare. With LLMs becoming widely popular and their
public access through open-source models and integration with other
applications, there is a need to investigate their potential and limitations.
One such crucial task where LLMs are applied but require a deeper understanding
is that of self-diagnosis of medical conditions based on bias-validating
symptoms in the interest of public health. The widespread integration of Gemini
with Google search and GPT-4.0 with Bing search has led to a shift in the trend
of self-diagnosis using search engines to conversational LLM models. Owing to
the critical nature of the task, it is prudent to investigate and understand
the potential and limitations of public LLMs in the task of self-diagnosis. In
this study, we prepare a prompt engineered dataset of 10000 samples and test
the performance on the general task of self-diagnosis. We compared the
performance of both the state-of-the-art GPT-4.0 and the fee Gemini model on
the task of self-diagnosis and recorded contrasting accuracies of 63.07% and
6.01%, respectively. We also discuss the challenges, limitations, and potential
of both Gemini and GPT-4.0 for the task of self-diagnosis to facilitate future
research and towards the broader impact of general public knowledge.
Furthermore, we demonstrate the potential and improvement in performance for
the task of self-diagnosis using Retrieval Augmented Generation.",2024-05-18,"Nikil Sharan Prabahar Balasubramanian, Sagnik Dakshit",http://arxiv.org/pdf/2405.11407v2,cs.CL
LeaPformer: Enabling Linear Transformers for Autoregressive and Simultaneous Tasks via Learned Proportions,"A promising approach to preserving model performance in linearized
transformers is to employ position-based re-weighting functions. However,
state-of-the-art re-weighting functions rely heavily on target sequence
lengths, making it difficult or impossible to apply them to autoregressive and
simultaneous tasks, where the target and sometimes even the input sequence
length are unknown. To address this issue, we propose Learned Proportions
(LeaP) and LeaPformers. Our contribution is built on two major components.
First, we generalize the dependence on explicit positional representations and
sequence lengths into dependence on sequence proportions for re-weighting.
Second, we replace static positional representations with dynamic proportions
derived via a compact module, enabling more flexible attention concentration
patterns. We evaluate LeaPformer against eight representative efficient
transformers on the Long-Range Arena benchmark, showing that LeaPformer
achieves the best quality-throughput trade-off, as well as LeaPformer to
Wikitext-103 autoregressive language modeling and simultaneous speech-to-text
translation for two language pairs, achieving competitive results.",2024-05-18,"Victor Agostinelli, Sanghyun Hong, Lizhong Chen",http://arxiv.org/pdf/2405.13046v1,cs.CL
MapCoder: Multi-Agent Code Generation for Competitive Problem Solving,"Code synthesis, which requires a deep understanding of complex natural
language problem descriptions, generation of code instructions for complex
algorithms and data structures, and the successful execution of comprehensive
unit tests, presents a significant challenge. While large language models
(LLMs) demonstrate impressive proficiency in natural language processing, their
performance in code generation tasks remains limited. In this paper, we
introduce a new approach to code generation tasks leveraging multi-agent
prompting that uniquely replicates the full cycle of program synthesis as
observed in human developers. Our framework, MapCoder, consists of four LLM
agents specifically designed to emulate the stages of this cycle: recalling
relevant examples, planning, code generation, and debugging. After conducting
thorough experiments, with multiple LLM ablations and analyses across eight
challenging competitive problem-solving and program synthesis benchmarks,
MapCoder showcases remarkable code generation capabilities, achieving new
state-of-the-art results (pass@1) on HumanEval (93.9%), MBPP (83.1%), APPS
(22.0%), CodeContests (28.5%), and xCodeEval (45.3%). Moreover, our method
consistently delivers superior performance across various programming languages
and varying problem difficulties. We open-source our framework at
https://github.com/Md-Ashraful-Pramanik/MapCoder.",2024-05-18,"Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez",http://arxiv.org/pdf/2405.11403v1,cs.CL
Large Language Models Lack Understanding of Character Composition of Words,"Large language models (LLMs) have demonstrated remarkable performances on a
wide range of natural language tasks. Yet, LLMs' successes have been largely
restricted to tasks concerning words, sentences, or documents, and it remains
questionable how much they understand the minimal units of text, namely
characters. In this paper, we examine contemporary LLMs regarding their ability
to understand character composition of words, and show that most of them fail
to reliably carry out even the simple tasks that can be handled by humans with
perfection. We analyze their behaviors with comparison to token level
performances, and discuss the potential directions for future research.",2024-05-18,"Andrew Shin, Kunitake Kaneko",http://arxiv.org/pdf/2405.11357v3,cs.CL
Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models,"Fine-grained image classification, particularly in zero/few-shot scenarios,
presents a significant challenge for vision-language models (VLMs), such as
CLIP. These models often struggle with the nuanced task of distinguishing
between semantically similar classes due to limitations in their pre-trained
recipe, which lacks supervision signals for fine-grained categorization. This
paper introduces CascadeVLM, an innovative framework that overcomes the
constraints of previous CLIP-based methods by effectively leveraging the
granular knowledge encapsulated within large vision-language models (LVLMs).
Experiments across various fine-grained image datasets demonstrate that
CascadeVLM significantly outperforms existing models, specifically on the
Stanford Cars dataset, achieving an impressive 85.6% zero-shot accuracy.
Performance gain analysis validates that LVLMs produce more accurate
predictions for challenging images that CLIPs are uncertain about, bringing the
overall accuracy boost. Our framework sheds light on a holistic integration of
VLMs and LVLMs for effective and efficient fine-grained image classification.",2024-05-18,Canshi Wei,http://arxiv.org/pdf/2405.11301v1,cs.CL
EnterpriseEM: Fine-tuned Embeddings for Enterprise Semantic Search,"Enterprises grapple with the significant challenge of managing proprietary
unstructured data, hindering efficient information retrieval. This has led to
the emergence of AI-driven information retrieval solutions, designed to adeptly
extract relevant insights to address employee inquiries. These solutions often
leverage pre-trained embedding models and generative models as foundational
components. While pre-trained embeddings may exhibit proximity or disparity
based on their original training objectives, they might not fully align with
the unique characteristics of enterprise-specific data, leading to suboptimal
alignment with the retrieval goals of enterprise environments. In this paper,
we propose a comprehensive methodology for contextualizing pre-trained
embedding models to enterprise environments, covering the entire process from
data preparation to model fine-tuning and evaluation. By adapting the
embeddings to better suit the retrieval tasks prevalent in enterprises, we aim
to enhance the performance of information retrieval solutions. We discuss the
process of fine-tuning, its effect on retrieval accuracy, and the potential
benefits for enterprise information management. Our findings demonstrate the
efficacy of fine-tuned embedding models in improving the precision and
relevance of search results in enterprise settings.",2024-05-18,"Kamalkumar Rathinasamy, Jayarama Nettar, Amit Kumar, Vishal Manchanda, Arun Vijayakumar, Ayush Kataria, Venkateshprasanna Manjunath, Chidambaram GS, Jaskirat Singh Sodhi, Shoeb Shaikh, Wasim Akhtar Khan, Prashant Singh, Tanishq Dattatray Ige, Vipin Tiwari, Rajab Ali Mondal, Harshini K, S Reka, Chetana Amancharla, Faiz ur Rahman, Harikrishnan P A, Indraneel Saha, Bhavya Tiwary, Navin Shankar Patel, Pradeep T S, Balaji A J, Priyapravas, Mohammed Rafee Tarafdar",http://arxiv.org/pdf/2406.00010v2,cs.CL
Unveiling Key Aspects of Fine-Tuning in Sentence Embeddings: A Representation Rank Analysis,"The latest advancements in unsupervised learning of sentence embeddings
predominantly involve employing contrastive learning-based (CL-based)
fine-tuning over pre-trained language models. In this study, we analyze the
latest sentence embedding methods by adopting representation rank as the
primary tool of analysis. We first define Phase 1 and Phase 2 of fine-tuning
based on when representation rank peaks. Utilizing these phases, we conduct a
thorough analysis and obtain essential findings across key aspects, including
alignment and uniformity, linguistic abilities, and correlation between
performance and rank. For instance, we find that the dynamics of the key
aspects can undergo significant changes as fine-tuning transitions from Phase 1
to Phase 2. Based on these findings, we experiment with a rank reduction (RR)
strategy that facilitates rapid and stable fine-tuning of the latest CL-based
methods. Through empirical investigations, we showcase the efficacy of RR in
enhancing the performance and stability of five state-of-the-art sentence
embedding methods.",2024-05-18,"Euna Jung, Jaeill Kim, Jungmin Ko, Jinwoo Park, Wonjong Rhee",http://arxiv.org/pdf/2405.11297v1,cs.CL
MBIAS: Mitigating Bias in Large Language Models While Retaining Context,"The deployment of Large Language Models (LLMs) in diverse applications
necessitates an assurance of safety without compromising the contextual
integrity of the generated content. Traditional approaches, including
safety-specific fine-tuning or adversarial testing, often yield safe outputs at
the expense of contextual meaning. This can result in a diminished capacity to
handle nuanced aspects of bias and toxicity, such as underrepresentation or
negative portrayals across various demographics. To address these challenges,
we introduce MBIAS, an LLM framework carefully instruction fine-tuned on a
custom dataset designed specifically for safety interventions. MBIAS is
designed to significantly reduce biases and toxic elements in LLM outputs while
preserving the main information. This work also details our further use of
LLMs: as annotator under human supervision and as evaluator of generated
content. Empirical analysis reveals that MBIAS achieves a reduction in bias and
toxicity by over 30\% in standard evaluations, and by more than 90\% in diverse
demographic tests, highlighting the robustness of our approach. We make the
dataset and the fine-tuned model available to the research community for
further investigation and ensure reproducibility. The code for this project can
be accessed here https://github.com/shainarazavi/MBIAS/tree/main.
  Warning: This paper contains examples that may be offensive or upsetting.",2024-05-18,"Shaina Raza, Ananya Raval, Veronica Chatrath",http://arxiv.org/pdf/2405.11290v3,cs.CL
Estimating the Level of Dialectness Predicts Interannotator Agreement in Multi-dialect Arabic Datasets,"On annotating multi-dialect Arabic datasets, it is common to randomly assign
the samples across a pool of native Arabic speakers. Recent analyses
recommended routing dialectal samples to native speakers of their respective
dialects to build higher-quality datasets. However, automatically identifying
the dialect of samples is hard. Moreover, the pool of annotators who are native
speakers of specific Arabic dialects might be scarce. Arabic Level of
Dialectness (ALDi) was recently introduced as a quantitative variable that
measures how sentences diverge from Standard Arabic. On randomly assigning
samples to annotators, we hypothesize that samples of higher ALDi scores are
harder to label especially if they are written in dialects that the annotators
do not speak. We test this by analyzing the relation between ALDi scores and
the annotators' agreement, on 15 public datasets having raw individual sample
annotations for various sentence-classification tasks. We find strong evidence
supporting our hypothesis for 11 of them. Consequently, we recommend
prioritizing routing samples of high ALDi scores to native speakers of each
sample's dialect, for which the dialect could be automatically identified at
higher accuracies.",2024-05-18,"Amr Keleg, Walid Magdy, Sharon Goldwater",http://arxiv.org/pdf/2405.11282v3,cs.CL
Action Controlled Paraphrasing,"Recent studies have demonstrated the potential to control paraphrase
generation, such as through syntax, which has broad applications in various
downstream tasks. However, these methods often require detailed parse trees or
syntactic exemplars, countering human-like paraphrasing behavior in language
use. Furthermore, an inference gap exists, as control specifications are only
available during training but not during inference. In this work, we propose a
new setup for controlled paraphrase generation. Specifically, we represent user
intent as action tokens, embedding and concatenating them with text embeddings,
thus flowing together into a self-attention encoder for representation fusion.
To address the inference gap, we introduce an optional action token as a
placeholder that encourages the model to determine the appropriate action
independently when users' intended actions are not provided. Experimental
results show that our method successfully enables precise action-controlled
paraphrasing and preserves or even enhances performance compared to
conventional uncontrolled methods when actions are not given. Our findings
promote the concept of action-controlled paraphrasing for a more user-centered
design.",2024-05-18,"Ning Shi, Zijun Wu",http://arxiv.org/pdf/2405.11277v2,cs.CL
Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts,"Recent advancements in Multimodal Large Language Models (MLLMs) underscore
the significance of scalable models and data to boost performance, yet this
often incurs substantial computational costs. Although the Mixture of Experts
(MoE) architecture has been employed to efficiently scale large language and
image-text models, these efforts typically involve fewer experts and limited
modalities. To address this, our work presents the pioneering attempt to
develop a unified MLLM with the MoE architecture, named Uni-MoE that can handle
a wide array of modalities. Specifically, it features modality-specific
encoders with connectors for a unified multimodal representation. We also
implement a sparse MoE architecture within the LLMs to enable efficient
training and inference through modality-level data parallelism and expert-level
model parallelism. To enhance the multi-expert collaboration and
generalization, we present a progressive training strategy: 1) Cross-modality
alignment using various connectors with different cross-modality data, 2)
Training modality-specific experts with cross-modality instruction data to
activate experts' preferences, and 3) Tuning the Uni-MoE framework utilizing
Low-Rank Adaptation (LoRA) on mixed multimodal instruction data. We evaluate
the instruction-tuned Uni-MoE on a comprehensive set of multimodal datasets.
The extensive experimental results demonstrate Uni-MoE's principal advantage of
significantly reducing performance bias in handling mixed multimodal datasets,
alongside improved multi-expert collaboration and generalization. Our findings
highlight the substantial potential of MoE frameworks in advancing MLLMs and
the code is available at
https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs.",2024-05-18,"Yunxin Li, Shenyuan Jiang, Baotian Hu, Longyue Wang, Wanqi Zhong, Wenhan Luo, Lin Ma, Min Zhang",http://arxiv.org/pdf/2405.11273v1,cs.CL
EnviroExam: Benchmarking Environmental Science Knowledge of Large Language Models,"In the field of environmental science, it is crucial to have robust
evaluation metrics for large language models to ensure their efficacy and
accuracy. We propose EnviroExam, a comprehensive evaluation method designed to
assess the knowledge of large language models in the field of environmental
science. EnviroExam is based on the curricula of top international
universities, covering undergraduate, master's, and doctoral courses, and
includes 936 questions across 42 core courses. By conducting 0-shot and 5-shot
tests on 31 open-source large language models, EnviroExam reveals the
performance differences among these models in the domain of environmental
science and provides detailed evaluation standards. The results show that 61.3%
of the models passed the 5-shot tests, while 48.39% passed the 0-shot tests. By
introducing the coefficient of variation as an indicator, we evaluate the
performance of mainstream open-source large language models in environmental
science from multiple perspectives, providing effective criteria for selecting
and fine-tuning language models in this field. Future research will involve
constructing more domain-specific test sets using specialized environmental
science textbooks to further enhance the accuracy and specificity of the
evaluation.",2024-05-18,"Yu Huang, Liang Guo, Wanqian Guo, Zhe Tao, Yang Lv, Zhihao Sun, Dongfang Zhao",http://arxiv.org/pdf/2405.11265v1,cs.CL
Cross-Language Assessment of Mathematical Capability of ChatGPT,"This paper presents an evaluation of the mathematical capability of ChatGPT
across diverse languages like Hindi, Gujarati, and Marathi. ChatGPT, based on
GPT-3.5 by OpenAI, has garnered significant attention for its natural language
understanding and generation abilities. However, its performance in solving
mathematical problems across multiple natural languages remains a comparatively
unexplored area, especially in regional Indian languages. In this paper, we
explore those capabilities as well as using chain-of-thought prompting to
figure out if it increases the accuracy of responses as much as it does in the
English language and provide insights into the current limitations.",2024-05-18,"Gargi Sathe, Aneesh Shamraj, Aditya Surve, Nahush Patil, Kumkum Saxena",http://arxiv.org/pdf/2405.11264v1,cs.CL
"WisPerMed at ""Discharge Me!"": Advancing Text Generation in Healthcare with Large Language Models, Dynamic Expert Selection, and Priming Techniques on MIMIC-IV","This study aims to leverage state of the art language models to automate
generating the ""Brief Hospital Course"" and ""Discharge Instructions"" sections of
Discharge Summaries from the MIMIC-IV dataset, reducing clinicians'
administrative workload. We investigate how automation can improve
documentation accuracy, alleviate clinician burnout, and enhance operational
efficacy in healthcare facilities. This research was conducted within our
participation in the Shared Task Discharge Me! at BioNLP @ ACL 2024. Various
strategies were employed, including few-shot learning, instruction tuning, and
Dynamic Expert Selection (DES), to develop models capable of generating the
required text sections. Notably, utilizing an additional clinical
domain-specific dataset demonstrated substantial potential to enhance clinical
language processing. The DES method, which optimizes the selection of text
outputs from multiple predictions, proved to be especially effective. It
achieved the highest overall score of 0.332 in the competition, surpassing
single-model outputs. This finding suggests that advanced deep learning methods
in combination with DES can effectively automate parts of electronic health
record documentation. These advancements could enhance patient care by freeing
clinician time for patient interactions. The integration of text selection
strategies represents a promising avenue for further research.",2024-05-18,"Hendrik Damm, Tabea M. G. Pakull, Bahadır Eryılmaz, Helmut Becker, Ahmad Idrissi-Yaghir, Henning Schäfer, Sergej Schultenkämper, Christoph M. Friedrich",http://arxiv.org/pdf/2405.11255v1,cs.CL
Case-Based Reasoning Approach for Solving Financial Question Answering,"Measuring a machine's understanding of human language often involves
assessing its reasoning skills, i.e. logical process of deriving answers to
questions. While recent language models have shown remarkable proficiency in
text based tasks, their efficacy in complex reasoning problems involving
heterogeneous information such as text, tables, and numbers remain uncertain.
Addressing this gap, FinQA introduced a numerical reasoning dataset for
financial documents and simultaneously proposed a program generation approach .
Our investigation reveals that half of the errors (48%) stem from incorrect
operations being generated. To address this issue, we propose a novel approach
to tackle numerical reasoning problems using case based reasoning (CBR), an
artificial intelligence paradigm that provides problem solving guidance by
offering similar cases (i.e. similar questions and corresponding logical
programs). Our model retrieves relevant cases to address a given question, and
then generates an answer based on the retrieved cases and contextual
information. Through experiments on the FinQA dataset, we demonstrate
competitive performance of our approach and additionally show that by expanding
case repository, we can help solving complex multi step programs which FinQA
showed weakness of.",2024-05-18,"Yikyung Kim, Jay-Yoon Lee",http://arxiv.org/pdf/2405.13044v1,cs.CL
BadActs: A Universal Backdoor Defense in the Activation Space,"Backdoor attacks pose an increasingly severe security threat to Deep Neural
Networks (DNNs) during their development stage. In response, backdoor sample
purification has emerged as a promising defense mechanism, aiming to eliminate
backdoor triggers while preserving the integrity of the clean content in the
samples. However, existing approaches have been predominantly focused on the
word space, which are ineffective against feature-space triggers and
significantly impair performance on clean data. To address this, we introduce a
universal backdoor defense that purifies backdoor samples in the activation
space by drawing abnormal activations towards optimized minimum clean
activation distribution intervals. The advantages of our approach are twofold:
(1) By operating in the activation space, our method captures from
surface-level information like words to higher-level semantic concepts such as
syntax, thus counteracting diverse triggers; (2) the fine-grained continuous
nature of the activation space allows for more precise preservation of clean
content while removing triggers. Furthermore, we propose a detection module
based on statistical information of abnormal activations, to achieve a better
trade-off between clean accuracy and defending performance.",2024-05-18,"Biao Yi, Sishuo Chen, Yiming Li, Tong Li, Baolei Zhang, Zheli Liu",http://arxiv.org/pdf/2405.11227v1,cs.CL
Transformer based neural networks for emotion recognition in conversations,"This paper outlines the approach of the ISDS-NLP team in the SemEval 2024
Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). For
Subtask 1 we obtained a weighted F1 score of 0.43 and placed 12 in the
leaderboard. We investigate two distinct approaches: Masked Language Modeling
(MLM) and Causal Language Modeling (CLM). For MLM, we employ pre-trained
BERT-like models in a multilingual setting, fine-tuning them with a classifier
to predict emotions. Experiments with varying input lengths, classifier
architectures, and fine-tuning strategies demonstrate the effectiveness of this
approach. Additionally, we utilize Mistral 7B Instruct V0.2, a state-of-the-art
model, applying zero-shot and few-shot prompting techniques. Our findings
indicate that while Mistral shows promise, MLMs currently outperform them in
sentence-level emotion classification.",2024-05-18,"Claudiu Creanga, Liviu P. Dinu",http://arxiv.org/pdf/2405.11222v1,cs.CL
Identifying and Aligning Medical Claims Made on Social Media with Medical Evidence,"Evidence-based medicine is the practice of making medical decisions that
adhere to the latest, and best known evidence at that time. Currently, the best
evidence is often found in the form of documents, such as randomized control
trials, meta-analyses and systematic reviews. This research focuses on aligning
medical claims made on social media platforms with this medical evidence. By
doing so, individuals without medical expertise can more effectively assess the
veracity of such medical claims. We study three core tasks: identifying medical
claims, extracting medical vocabulary from these claims, and retrieving
evidence relevant to those identified medical claims. We propose a novel system
that can generate synthetic medical claims to aid each of these core tasks. We
additionally introduce a novel dataset produced by our synthetic generator
that, when applied to these tasks, demonstrates not only a more flexible and
holistic approach, but also an improvement in all comparable metrics. We make
our dataset, the Expansive Medical Claim Corpus (EMCC), available at
https://zenodo.org/records/8321460",2024-05-18,"Anthony Hughes, Xingyi Song",http://arxiv.org/pdf/2405.11219v1,cs.CL
MemeMQA: Multimodal Question Answering for Memes via Rationale-Based Inferencing,"Memes have evolved as a prevalent medium for diverse communication, ranging
from humour to propaganda. With the rising popularity of image-focused content,
there is a growing need to explore its potential harm from different aspects.
Previous studies have analyzed memes in closed settings - detecting harm,
applying semantic labels, and offering natural language explanations. To extend
this research, we introduce MemeMQA, a multimodal question-answering framework
aiming to solicit accurate responses to structured questions while providing
coherent explanations. We curate MemeMQACorpus, a new dataset featuring 1,880
questions related to 1,122 memes with corresponding answer-explanation pairs.
We further propose ARSENAL, a novel two-stage multimodal framework that
leverages the reasoning capabilities of LLMs to address MemeMQA. We benchmark
MemeMQA using competitive baselines and demonstrate its superiority - ~18%
enhanced answer prediction accuracy and distinct text generation lead across
various metrics measuring lexical and semantic alignment over the best
baseline. We analyze ARSENAL's robustness through diversification of
question-set, confounder-based evaluation regarding MemeMQA's generalizability,
and modality-specific assessment, enhancing our understanding of meme
interpretation in the multimodal communication landscape.",2024-05-18,"Siddhant Agarwal, Shivam Sharma, Preslav Nakov, Tanmoy Chakraborty",http://arxiv.org/pdf/2405.11215v1,cs.CL
Automated Text Identification Using CNN and Training Dynamics,"We used Data Maps to model and characterize the AuTexTification dataset. This
provides insights about the behaviour of individual samples during training
across epochs (training dynamics). We characterized the samples across 3
dimensions: confidence, variability and correctness. This shows the presence of
3 regions: easy-to-learn, ambiguous and hard-to-learn examples. We used a
classic CNN architecture and found out that training the model only on a subset
of ambiguous examples improves the model's out-of-distribution generalization.",2024-05-18,"Claudiu Creanga, Liviu Petrisor Dinu",http://arxiv.org/pdf/2405.11212v1,cs.CL
LexGen: Domain-aware Multilingual Lexicon Generation,"Lexicon or dictionary generation across domains is of significant societal
importance, as it can potentially enhance information accessibility for a
diverse user base while preserving language identity. Prior work in the field
primarily focuses on bilingual lexical induction, which deals with word
alignments using mapping-based or corpora-based approaches. Though initiated by
researchers, the research associated with lexicon generation is limited, even
more so with domain-specific lexicons. This task becomes particularly important
in atypical medical, engineering, and other technical domains, owing to the
highly infrequent usage of the terms and negligibly low data availability of
technical terms in many low-resource languages. Owing to the research gap in
lexicon generation, especially with a limited focus on the domain-specific
area, we propose a new model to generate dictionary words for 6 Indian
languages in the multi-domain setting. Our model consists of domain-specific
and domain-generic layers that encode information, and these layers are invoked
via a learnable routing technique. Further, we propose an approach to
explicitly leverage the relatedness between these Indian languages toward
coherent translation. We also release a new benchmark dataset across 6 Indian
languages that span 8 diverse domains that can propel further research in
domain-specific lexicon induction. We conduct both zero-shot and few-shot
experiments across multiple domains to show the efficacy of our proposed model
in generalizing to unseen domains and unseen languages.",2024-05-18,"Ayush Maheshwari, Atul Kumar Singh, Karthika NJ, Krishnakant Bhatt, Preethi Jyothi, Ganesh Ramakrishnan",http://arxiv.org/pdf/2405.11200v2,cs.CL
Designing NLP Systems That Adapt to Diverse Worldviews,"Natural Language Inference (NLI) is foundational for evaluating language
understanding in AI. However, progress has plateaued, with models failing on
ambiguous examples and exhibiting poor generalization. We argue that this stems
from disregarding the subjective nature of meaning, which is intrinsically tied
to an individual's \textit{weltanschauung} (which roughly translates to
worldview). Existing NLP datasets often obscure this by aggregating labels or
filtering out disagreement. We propose a perspectivist approach: building
datasets that capture annotator demographics, values, and justifications for
their labels. Such datasets would explicitly model diverse worldviews. Our
initial experiments with a subset of the SBIC dataset demonstrate that even
limited annotator metadata can improve model performance.",2024-05-18,"Claudiu Creanga, Liviu P. Dinu",http://arxiv.org/pdf/2405.11197v1,cs.CL
BrainStorm @ iREL at #SMM4H 2024: Leveraging Translation and Topical Embeddings for Annotation Detection in Tweets,"The proliferation of LLMs in various NLP tasks has sparked debates regarding
their reliability, particularly in annotation tasks where biases and
hallucinations may arise. In this shared task, we address the challenge of
distinguishing annotations made by LLMs from those made by human domain experts
in the context of COVID-19 symptom detection from tweets in Latin American
Spanish. This paper presents BrainStorm @ iRELs approach to the SMM4H 2024
Shared Task, leveraging the inherent topical information in tweets, we propose
a novel approach to identify and classify annotations, aiming to enhance the
trustworthiness of annotated data.",2024-05-18,"Manav Chaudhary, Harshit Gupta, Vasudeva Varma",http://arxiv.org/pdf/2405.11192v2,cs.CL
Towards Knowledge-Infused Automated Disease Diagnosis Assistant,"With the advancement of internet communication and telemedicine, people are
increasingly turning to the web for various healthcare activities. With an
ever-increasing number of diseases and symptoms, diagnosing patients becomes
challenging. In this work, we build a diagnosis assistant to assist doctors,
which identifies diseases based on patient-doctor interaction. During
diagnosis, doctors utilize both symptomatology knowledge and diagnostic
experience to identify diseases accurately and efficiently. Inspired by this,
we investigate the role of medical knowledge in disease diagnosis through
doctor-patient interaction. We propose a two-channel, knowledge-infused,
discourse-aware disease diagnosis model (KI-DDI), where the first channel
encodes patient-doctor communication using a transformer-based encoder, while
the other creates an embedding of symptom-disease using a graph attention
network (GAT). In the next stage, the conversation and knowledge graph
embeddings are infused together and fed to a deep neural network for disease
identification. Furthermore, we first develop an empathetic conversational
medical corpus comprising conversations between patients and doctors, annotated
with intent and symptoms information. The proposed model demonstrates a
significant improvement over the existing state-of-the-art models, establishing
the crucial roles of (a) a doctor's effort for additional symptom extraction
(in addition to patient self-report) and (b) infusing medical knowledge in
identifying diseases effectively. Many times, patients also show their medical
conditions, which acts as crucial evidence in diagnosis. Therefore, integrating
visual sensory information would represent an effective avenue for enhancing
the capabilities of diagnostic assistants.",2024-05-18,"Mohit Tomar, Abhisek Tiwari, Sriparna Saha",http://arxiv.org/pdf/2405.11181v1,cs.CL
Automating PTSD Diagnostics in Clinical Interviews: Leveraging Large Language Models for Trauma Assessments,"The shortage of clinical workforce presents significant challenges in mental
healthcare, limiting access to formal diagnostics and services. We aim to
tackle this shortage by integrating a customized large language model (LLM)
into the workflow, thus promoting equity in mental healthcare for the general
population. Although LLMs have showcased their capability in clinical
decision-making, their adaptation to severe conditions like Post-traumatic
Stress Disorder (PTSD) remains largely unexplored. Therefore, we collect 411
clinician-administered diagnostic interviews and devise a novel approach to
obtain high-quality data. Moreover, we build a comprehensive framework to
automate PTSD diagnostic assessments based on interview contents by leveraging
two state-of-the-art LLMs, GPT-4 and Llama-2, with potential for broader
clinical diagnoses. Our results illustrate strong promise for LLMs, tested on
our dataset, to aid clinicians in diagnostic validation. To the best of our
knowledge, this is the first AI system that fully automates assessments for
mental illness based on clinician-administered interviews.",2024-05-18,"Sichang Tu, Abigail Powers, Natalie Merrill, Negar Fani, Sierra Carter, Stephen Doogan, Jinho D. Choi",http://arxiv.org/pdf/2405.11178v1,cs.CL
LG AI Research & KAIST at EHRSQL 2024: Self-Training Large Language Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL System on EHRs,"Text-to-SQL models are pivotal for making Electronic Health Records (EHRs)
accessible to healthcare professionals without SQL knowledge. With the
advancements in large language models, these systems have become more adept at
translating complex questions into SQL queries. Nonetheless, the critical need
for reliability in healthcare necessitates these models to accurately identify
unanswerable questions or uncertain predictions, preventing misinformation. To
address this problem, we present a self-training strategy using pseudo-labeled
unanswerable questions to enhance the reliability of text-to-SQL models for
EHRs. This approach includes a two-stage training process followed by a
filtering method based on the token entropy and query execution. Our
methodology's effectiveness is validated by our top performance in the EHRSQL
2024 shared task, showcasing the potential to improve healthcare
decision-making through more reliable text-to-SQL systems.",2024-05-18,"Yongrae Jo, Seongyun Lee, Minju Seo, Sung Ju Hwang, Moontae Lee",http://arxiv.org/pdf/2405.11162v1,cs.CL
Towards Modular LLMs by Building and Reusing a Library of LoRAs,"The growing number of parameter-efficient adaptations of a base large
language model (LLM) calls for studying whether we can reuse such trained
adapters to improve performance for new tasks. We study how to best build a
library of adapters given multi-task data and devise techniques for both
zero-shot and supervised task generalization through routing in such library.
We benchmark existing approaches to build this library and introduce
model-based clustering, MBC, a method that groups tasks based on the similarity
of their adapter parameters, indirectly optimizing for transfer across the
multi-task dataset. To re-use the library, we present a novel zero-shot routing
mechanism, Arrow, which enables dynamic selection of the most relevant adapters
for new inputs without the need for retraining. We experiment with several
LLMs, such as Phi-2 and Mistral, on a wide array of held-out tasks, verifying
that MBC-based adapters and Arrow routing lead to superior generalization to
new tasks. We make steps towards creating modular, adaptable LLMs that can
match or outperform traditional joint training.",2024-05-18,"Oleksiy Ostapenko, Zhan Su, Edoardo Maria Ponti, Laurent Charlin, Nicolas Le Roux, Matheus Pereira, Lucas Caccia, Alessandro Sordoni",http://arxiv.org/pdf/2405.11157v1,cs.CL
A Reproducibility Study on Quantifying Language Similarity: The Impact of Missing Values in the URIEL Knowledge Base,"In the pursuit of supporting more languages around the world, tools that
characterize properties of languages play a key role in expanding the existing
multilingual NLP research. In this study, we focus on a widely used typological
knowledge base, URIEL, which aggregates linguistic information into numeric
vectors. Specifically, we delve into the soundness and reproducibility of the
approach taken by URIEL in quantifying language similarity. Our analysis
reveals URIEL's ambiguity in calculating language distances and in handling
missing values. Moreover, we find that URIEL does not provide any information
about typological features for 31\% of the languages it represents, undermining
the reliabilility of the database, particularly on low-resource languages. Our
literature review suggests URIEL and lang2vec are used in papers on diverse NLP
tasks, which motivates us to rigorously verify the database as the
effectiveness of these works depends on the reliability of the information the
tool provides.",2024-05-17,"Hasti Toossi, Guo Qing Huai, Jinyu Liu, Eric Khiu, A. Seza Doğruöz, En-Shiun Annie Lee",http://arxiv.org/pdf/2405.11125v1,cs.CL
Dynamic Embeddings with Task-Oriented prompting,"This paper introduces Dynamic Embeddings with Task-Oriented prompting
(DETOT), a novel approach aimed at improving the adaptability and efficiency of
machine learning models by implementing a flexible embedding layer. Unlike
traditional static embeddings [14], DETOT dynamically adjusts embeddings based
on task-specific requirements and performance feedback, optimizing input data
representation for individual tasks [4]. This method enhances both accuracy and
computational performance by tailoring the representation layer to meet the
unique needs of each task. The structure of DETOT is detailed, highlighting its
task-specific adaptation, continuous feedback loop, and mechanisms for
preventing overfitting. Empirical evaluations demonstrate its superiority over
existing methods.",2024-05-17,"Allmin Balloccu, Jack Zhang",http://arxiv.org/pdf/2405.11117v2,cs.CL
Watermarking Language Models for Many Adaptive Users,"We study watermarking schemes for language models with provable guarantees.
As we show, prior works offer no robustness guarantees against adaptive
prompting: when a user queries a language model more than once, as even benign
users do. And with just a single exception (Christ and Gunn, 2024), prior works
are restricted to zero-bit watermarking: machine-generated text can be detected
as such, but no additional information can be extracted from the watermark.
Unfortunately, merely detecting AI-generated text may not prevent future
abuses.
  We introduce multi-user watermarks, which allow tracing model-generated text
to individual users or to groups of colluding users, even in the face of
adaptive prompting. We construct multi-user watermarking schemes from
undetectable, adaptively robust, zero-bit watermarking schemes (and prove that
the undetectable zero-bit scheme of Christ, Gunn, and Zamir (2024) is
adaptively robust). Importantly, our scheme provides both zero-bit and
multi-user assurances at the same time. It detects shorter snippets just as
well as the original scheme, and traces longer excerpts to individuals.
  The main technical component is a construction of message-embedding
watermarks from zero-bit watermarks. Ours is the first generic reduction
between watermarking schemes for language models. A challenge for such
reductions is the lack of a unified abstraction for robustness -- that marked
text is detectable even after edits. We introduce a new unifying abstraction
called AEB-robustness. AEB-robustness provides that the watermark is detectable
whenever the edited text ""approximates enough blocks"" of model-generated
output.",2024-05-17,"Aloni Cohen, Alexander Hoover, Gabe Schoenbach",http://arxiv.org/pdf/2405.11109v2,cs.CL
LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions,"In recent years, Large Language Models (LLMs) have shown great abilities in
various tasks, including question answering, arithmetic problem solving, and
poem writing, among others. Although research on LLM-as-an-agent has shown that
LLM can be applied to Reinforcement Learning (RL) and achieve decent results,
the extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as
many aspects, such as coordination and communication between agents, are not
considered in the RL frameworks of a single agent. To inspire more research on
LLM-based MARL, in this letter, we survey the existing LLM-based single-agent
and multi-agent RL frameworks and provide potential research directions for
future research. In particular, we focus on the cooperative tasks of multiple
agents with a common goal and communication among them. We also consider
human-in/on-the-loop scenarios enabled by the language component in the
framework.",2024-05-17,"Chuanneng Sun, Songjun Huang, Dario Pompili",http://arxiv.org/pdf/2405.11106v1,cs.CL
Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations,"Large language models (LLMs) have taken centre stage in debates on Artificial
Intelligence. Yet there remains a gap in how to assess LLMs' conformity to
important human values. In this paper, we investigate whether state-of-the-art
LLMs, GPT-4 and Claude 2.1 (Gemini Pro and LLAMA 2 did not generate valid
results) are moral hypocrites. We employ two research instruments based on the
Moral Foundations Theory: (i) the Moral Foundations Questionnaire (MFQ), which
investigates which values are considered morally relevant in abstract moral
judgements; and (ii) the Moral Foundations Vignettes (MFVs), which evaluate
moral cognition in concrete scenarios related to each moral foundation. We
characterise conflicts in values between these different abstractions of moral
evaluation as hypocrisy. We found that both models displayed reasonable
consistency within each instrument compared to humans, but they displayed
contradictory and hypocritical behaviour when we compared the abstract values
present in the MFQ to the evaluation of concrete moral violations of the MFV.",2024-05-17,"José Luiz Nunes, Guilherme F. C. F. Almeida, Marcelo de Araujo, Simone D. J. Barbosa",http://arxiv.org/pdf/2405.11100v2,cs.CL
AudioSetMix: Enhancing Audio-Language Datasets with LLM-Assisted Augmentations,"Multi-modal learning in the audio-language domain has seen significant
advancements in recent years. However, audio-language learning faces challenges
due to limited and lower-quality data compared to image-language tasks.
Existing audio-language datasets are notably smaller, and manual labeling is
hindered by the need to listen to entire audio clips for accurate labeling.
  Our method systematically generates audio-caption pairs by augmenting audio
clips with natural language labels and corresponding audio signal processing
operations. Leveraging a Large Language Model, we generate descriptions of
augmented audio clips with a prompt template. This scalable method produces
AudioSetMix, a high-quality training dataset for text-and-audio related models.
  Integration of our dataset improves models performance on benchmarks by
providing diversified and better-aligned examples. Notably, our dataset
addresses the absence of modifiers (adjectives and adverbs) in existing
datasets. By enabling models to learn these concepts, and generating hard
negative examples during training, we achieve state-of-the-art performance on
multiple benchmarks.",2024-05-17,David Xu,http://arxiv.org/pdf/2405.11093v2,cs.CL
Multilingual Substitution-based Word Sense Induction,"Word Sense Induction (WSI) is the task of discovering senses of an ambiguous
word by grouping usages of this word into clusters corresponding to these
senses. Many approaches were proposed to solve WSI in English and a few other
languages, but these approaches are not easily adaptable to new languages. We
present multilingual substitution-based WSI methods that support any of 100
languages covered by the underlying multilingual language model with minimal to
no adaptation required. Despite the multilingual capabilities, our methods
perform on par with the existing monolingual approaches on popular English WSI
datasets. At the same time, they will be most useful for lower-resourced
languages which miss lexical resources available for English, thus, have higher
demand for unsupervised methods like WSI.",2024-05-17,"Denis Kokosinskii, Nikolay Arefyev",http://arxiv.org/pdf/2405.11086v1,cs.CL
Prompt Exploration with Prompt Regression,"In the advent of democratized usage of large language models (LLMs), there is
a growing desire to systematize LLM prompt creation and selection processes
beyond iterative trial-and-error. Prior works majorly focus on searching the
space of prompts without accounting for relations between prompt variations.
Here we propose a framework, Prompt Exploration with Prompt Regression (PEPR),
to predict the effect of prompt combinations given results for individual
prompt elements as well as a simple method to select an effective prompt for a
given use-case. We evaluate our approach with open-source LLMs of different
sizes on several different tasks.",2024-05-17,"Michael Feffer, Ronald Xu, Yuekai Sun, Mikhail Yurochkin",http://arxiv.org/pdf/2405.11083v2,cs.CL
Jill Watson: A Virtual Teaching Assistant powered by ChatGPT,"Conversational AI agents often require extensive datasets for training that
are not publicly released, are limited to social chit-chat or handling a
specific domain, and may not be easily extended to accommodate the latest
advances in AI technologies. This paper introduces Jill Watson, a
conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of
ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a
modular design to allow the integration of new APIs using a skill-based
architecture inspired by XiaoIce. Jill Watson is also well-suited for
intelligent textbooks as it can process and converse using multiple large
documents. We exclusively utilize publicly available resources for
reproducibility and extensibility. Comparative analysis shows that our system
outperforms the legacy knowledge-based Jill Watson as well as the OpenAI
Assistants service. We employ many safety measures that reduce instances of
hallucinations and toxicity. The paper also includes real-world examples from a
classroom setting that demonstrate different features of Jill Watson and its
effectiveness.",2024-05-17,"Karan Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, Ashok K. Goel",http://arxiv.org/pdf/2405.11070v1,cs.CL
Leveraging Discourse Structure for Extractive Meeting Summarization,"We introduce an extractive summarization system for meetings that leverages
discourse structure to better identify salient information from complex
multi-party discussions. Using discourse graphs to represent semantic relations
between the contents of utterances in a meeting, we train a GNN-based node
classification model to select the most important utterances, which are then
combined to create an extractive summary. Experimental results on AMI and ICSI
demonstrate that our approach surpasses existing text-based and graph-based
extractive summarization systems, as measured by both classification and
summarization metrics. Additionally, we conduct ablation studies on discourse
structure and relation type to provide insights for future NLP applications
leveraging discourse analysis theory.",2024-05-17,"Virgile Rennard, Guokan Shang, Michalis Vazirgiannis, Julie Hunter",http://arxiv.org/pdf/2405.11055v3,cs.CL
From Generalist to Specialist: Improving Large Language Models for Medical Physics Using ARCoT,"Large Language Models (LLMs) have achieved remarkable progress, yet their
application in specialized fields, such as medical physics, remains challenging
due to the need for domain-specific knowledge. This study introduces ARCoT
(Adaptable Retrieval-based Chain of Thought), a framework designed to enhance
the domain-specific accuracy of LLMs without requiring fine-tuning or extensive
retraining. ARCoT integrates a retrieval mechanism to access relevant
domain-specific information and employs step-back and chain-of-thought
prompting techniques to guide the LLM's reasoning process, ensuring more
accurate and context-aware responses. Benchmarking on a medical physics
multiple-choice exam, our model outperformed standard LLMs and reported average
human performance, demonstrating improvements of up to 68% and achieving a high
score of 90%. This method reduces hallucinations and increases domain-specific
performance. The versatility and model-agnostic nature of ARCoT make it easily
adaptable to various domains, showcasing its significant potential for
enhancing the accuracy and reliability of LLMs in specialized fields.",2024-05-17,"Jace Grandinetti, Rafe McBeth",http://arxiv.org/pdf/2405.11040v1,cs.CL
CC-GPX: Extracting High-Quality Annotated Geospatial Data from Common Crawl,"The Common Crawl (CC) corpus is the largest open web crawl dataset containing
9.5+ petabytes of data captured since 2008. The dataset is instrumental in
training large language models, and as such it has been studied for
(un)desirable content, and distilled for smaller, domain-specific datasets.
However, to our knowledge, no research has been dedicated to using CC as a
source of annotated geospatial data. In this paper, we introduce an efficient
pipeline to extract annotated user-generated tracks from GPX files found in CC,
and the resulting multimodal dataset with 1,416 pairings of human-written
descriptions and MultiLineString vector data from the 6 most recent CC
releases. The dataset can be used to study people's outdoor activity patterns,
the way people talk about their outdoor experiences, as well as for developing
trajectory generation or track annotation models, or for various other problems
in place of synthetically generated routes. Our reproducible code is available
on GitHub: https://github.com/ilyankou/cc-gpx",2024-05-17,"Ilya Ilyankou, Meihui Wang, Stefano Cavazzi, James Haworth",http://arxiv.org/pdf/2405.11039v3,cs.CL
The Unappreciated Role of Intent in Algorithmic Moderation of Social Media Content,"As social media has become a predominant mode of communication globally, the
rise of abusive content threatens to undermine civil discourse. Recognizing the
critical nature of this issue, a significant body of research has been
dedicated to developing language models that can detect various types of online
abuse, e.g., hate speech, cyberbullying. However, there exists a notable
disconnect between platform policies, which often consider the author's
intention as a criterion for content moderation, and the current capabilities
of detection models, which typically lack efforts to capture intent. This paper
examines the role of intent in content moderation systems. We review state of
the art detection models and benchmark training datasets for online abuse to
assess their awareness and ability to capture intent. We propose strategic
changes to the design and development of automated detection and moderation
systems to improve alignment with ethical and policy conceptualizations of
abuse.",2024-05-17,"Xinyu Wang, Sai Koneru, Pranav Narayanan Venkit, Brett Frischmann, Sarah Rajtmajer",http://arxiv.org/pdf/2405.11030v1,cs.CL
Generative Artificial Intelligence: A Systematic Review and Applications,"In recent years, the study of artificial intelligence (AI) has undergone a
paradigm shift. This has been propelled by the groundbreaking capabilities of
generative models both in supervised and unsupervised learning scenarios.
Generative AI has shown state-of-the-art performance in solving perplexing
real-world conundrums in fields such as image translation, medical diagnostics,
textual imagery fusion, natural language processing, and beyond. This paper
documents the systematic review and analysis of recent advancements and
techniques in Generative AI with a detailed discussion of their applications
including application-specific models. Indeed, the major impact that generative
AI has made to date, has been in language generation with the development of
large language models, in the field of image translation and several other
interdisciplinary applications of generative AI. Moreover, the primary
contribution of this paper lies in its coherent synthesis of the latest
advancements in these areas, seamlessly weaving together contemporary
breakthroughs in the field. Particularly, how it shares an exploration of the
future trajectory for generative AI. In conclusion, the paper ends with a
discussion of Responsible AI principles, and the necessary ethical
considerations for the sustainability and growth of these generative models.",2024-05-17,"Sandeep Singh Sengar, Affan Bin Hasan, Sanjay Kumar, Fiona Carroll",http://arxiv.org/pdf/2405.11029v1,cs.CL
Observational Scaling Laws and the Predictability of Language Model Performance,"Understanding how language model performance varies with scale is critical to
benchmark and algorithm development. Scaling laws are one approach to building
this understanding, but the requirement of training models across many
different scales has limited their use. We propose an alternative,
observational approach that bypasses model training and instead builds scaling
laws from ~100 publically available models. Building a single scaling law from
multiple model families is challenging due to large variations in their
training compute efficiencies and capabilities. However, we show that these
variations are consistent with a simple, generalized scaling law where language
model performance is a function of a low-dimensional capability space, and
model families only vary in their efficiency in converting training compute to
capabilities. Using this approach, we show the surprising predictability of
complex scaling phenomena: we show that several emergent phenomena follow a
smooth, sigmoidal behavior and are predictable from small models; we show that
the agent performance of models such as GPT-4 can be precisely predicted from
simpler non-agentic benchmarks; and we show how to predict the impact of
post-training interventions like Chain-of-Thought and Self-Consistency as
language model capabilities continue to improve.",2024-05-17,"Yangjun Ruan, Chris J. Maddison, Tatsunori Hashimoto",http://arxiv.org/pdf/2405.10938v3,cs.CL
A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers,"The rapid development of Large Language Models (LLMs) demonstrates remarkable
multilingual capabilities in natural language processing, attracting global
attention in both academia and industry. To mitigate potential discrimination
and enhance the overall usability and accessibility for diverse language user
groups, it is important for the development of language-fair technology.
Despite the breakthroughs of LLMs, the investigation into the multilingual
scenario remains insufficient, where a comprehensive survey to summarize recent
approaches, developments, limitations, and potential solutions is desirable. To
this end, we provide a survey with multiple perspectives on the utilization of
LLMs in the multilingual scenario. We first rethink the transitions between
previous and current research on pre-trained language models. Then we introduce
several perspectives on the multilingualism of LLMs, including training and
inference methods, information retrieval, model security, multi-domain with
language culture, and usage of datasets. We also discuss the major challenges
that arise in these aspects, along with possible solutions. Besides, we
highlight future research directions that aim at further enhancing LLMs with
multilingualism. The survey aims to help the research community address
multilingual problems and provide a comprehensive understanding of the core
concepts, key techniques, and latest developments in multilingual natural
language processing based on LLMs.",2024-05-17,"Kaiyu Huang, Fengran Mo, Xinyu Zhang, Hongliang Li, You Li, Yuanchi Zhang, Weijian Yi, Yulong Mao, Jinchen Liu, Yuzhuang Xu, Jinan Xu, Jian-Yun Nie, Yang Liu",http://arxiv.org/pdf/2405.10936v2,cs.CL
The Arabic Noun System Generation,"In this paper, we show that the multiple-stem approach to nouns with a broken
plural pattern allows for greater generalizations to be stated in the
morphological system. Such an approach dispenses with truncating/deleting rules
and other complex rules that are required to account for the highly allomorphic
broken plural system. The generation of inflected sound nouns necessitates a
pre-specification of the affixes denoting the sound plural masculine and the
sound plural feminine, namely uwna and aAt, in the lexicon. The first
subsection of section one provides an evaluation of some of the previous
analyses of the Arabic broken plural. We provide both linguistic and
statistical evidence against deriving broken plurals from the singular or the
root. In subsection two, we propose a multiple stem approach to the Arabic Noun
Plural System within the Lexeme-based Morphology framework. In section two, we
look at the noun inflection of Arabic. Section three provides an implementation
of the Arabic Noun system in MORPHE. In this context, we show how the
generalizations discussed in the linguistic analysis section are captured in
Morphe using the equivalencing nodes.",2024-05-17,"Abdelhadi Soudi, Violetta Cavalli-Sforza, Abderrahim Jamari",http://arxiv.org/pdf/2405.11014v1,cs.CL
A Framework for Leveraging Partially-Labeled Data for Product Attribute-Value Identification,"In the e-commerce domain, the accurate extraction of attribute-value pairs
(e.g., Brand: Apple) from product titles and user search queries is crucial for
enhancing search and recommendation systems. A major challenge with neural
models for this task is the lack of high-quality training data, as the
annotations for attribute-value pairs in the available datasets are often
incomplete. To address this, we introduce GenToC, a model designed for training
directly with partially-labeled data, eliminating the necessity for a fully
annotated dataset. GenToC employs a marker-augmented generative model to
identify potential attributes, followed by a token classification model that
determines the associated values for each attribute. GenToC outperforms
existing state-of-the-art models, exhibiting upto 56.3% increase in the number
of accurate extractions. Furthermore, we utilize GenToC to regenerate the
training dataset to expand attribute-value annotations. This bootstrapping
substantially improves the data quality for training other standard NER models,
which are typically faster but less capable in handling partially-labeled data,
enabling them to achieve comparable performance to GenToC. Our results
demonstrate GenToC's unique ability to learn from a limited set of
partially-labeled data and improve the training of more efficient models,
advancing the automated extraction of attribute-value pairs. Finally, our model
has been successfully integrated into IndiaMART, India's largest B2B e-commerce
platform, achieving a significant increase of 20.2% in the number of correctly
identified attribute-value pairs over the existing deployed system while
achieving a high precision of 89.5%.",2024-05-17,"D. Subhalingam, Keshav Kolluru, Mausam, Saurabh Singal",http://arxiv.org/pdf/2405.10918v2,cs.CL
"COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain","Large Language Models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence (AI) technology which is rapidly evolving and promises
to aid in medical diagnosis either by assisting doctors or by simulating a
doctor's workflow in more advanced and complex implementations. In this
technical paper, we outline Cognitive Network Evaluation Toolkit for Medical
Domains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in
the medical domain. Specifically, we propose a scoring-framework with increased
difficulty to assess the ability of LLMs in interpreting medical text. The
proposed framework is accompanied with a database of Multiple Choice Quizzes
(MCQs). To ensure alignment with current medical trends and enhance safety,
usefulness, and applicability, these MCQs have been constructed in
collaboration with several associated medical experts in various medical
domains and are characterized by varying degrees of difficulty. The current
(first) version of the database includes the medical domains of Psychiatry,
Dentistry, Pulmonology, Dermatology and Endocrinology, but it will be
continuously extended and expanded to include additional medical domains.",2024-05-17,"Dimitrios P. Panagoulias, Persephone Papatheodosiou, Anastasios P. Palamidas, Mattheos Sanoudos, Evridiki Tsoureli-Nikita, Maria Virvou, George A. Tsihrintzis",http://arxiv.org/pdf/2405.10893v1,cs.CL
Tailoring Vaccine Messaging with Common-Ground Opinions,"One way to personalize chatbot interactions is by establishing common ground
with the intended reader. A domain where establishing mutual understanding
could be particularly impactful is vaccine concerns and misinformation. Vaccine
interventions are forms of messaging which aim to answer concerns expressed
about vaccination. Tailoring responses in this domain is difficult, since
opinions often have seemingly little ideological overlap. We define the task of
tailoring vaccine interventions to a Common-Ground Opinion (CGO). Tailoring
responses to a CGO involves meaningfully improving the answer by relating it to
an opinion or belief the reader holds. In this paper we introduce TAILOR-CGO, a
dataset for evaluating how well responses are tailored to provided CGOs. We
benchmark several major LLMs on this task; finding GPT-4-Turbo performs
significantly better than others. We also build automatic evaluation metrics,
including an efficient and accurate BERT model that outperforms finetuned LLMs,
investigate how to successfully tailor vaccine messaging to CGOs, and provide
actionable recommendations from this investigation.
  Code and model weights: https://github.com/rickardstureborg/tailor-cgo
Dataset: https://huggingface.co/datasets/DukeNLP/tailor-cgo",2024-05-17,"Rickard Stureborg, Sanxing Chen, Ruoyu Xie, Aayushi Patel, Christopher Li, Chloe Qinyu Zhu, Tingnan Hu, Jun Yang, Bhuwan Dhingra",http://arxiv.org/pdf/2405.10861v2,cs.CL
ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains,"Understanding the process of emotion generation is crucial for analyzing the
causes behind emotions. Causal Emotion Entailment (CEE), an
emotion-understanding task, aims to identify the causal utterances in a
conversation that stimulate the emotions expressed in a target utterance.
However, current works in CEE mainly focus on modeling semantic and emotional
interactions in conversations, neglecting the exploration of the
emotion-generation process. This hinders the models from deeply understanding
emotions, restricting their ability to produce explainable predictions. In this
work, inspired by the emotion generation process of
""stimulus-appraisal-emotion"" in the cognitive appraisal theory, we introduce a
step-by-step reasoning method, Emotion-Cause Reasoning Chain (ECR-Chain), to
infer the stimulus from the target emotional expressions in conversations.
Specifically, we first introduce the ECR-Chain to ChatGPT via few-shot
prompting, which significantly improves its performance on the CEE task. We
further propose an automated construction process to utilize ChatGPT in
building an ECR-Chain set, which can enhance the reasoning abilities of smaller
models through supervised training and assist the Vicuna-7B model in achieving
state-of-the-art CEE performance. Moreover, our methods can enable these
generative language models to effectively perform emotion-cause reasoning in an
explainable manner. Our code, data and more details are at
https://github.com/hzp3517/ECR-Chain.",2024-05-17,"Zhaopei Huang, Jinming Zhao, Qin Jin",http://arxiv.org/pdf/2405.10860v2,cs.CL
Assessing Political Bias in Large Language Models,"The assessment of bias within Large Language Models (LLMs) has emerged as a
critical concern in the contemporary discourse surrounding Artificial
Intelligence (AI) in the context of their potential impact on societal
dynamics. Recognizing and considering political bias within LLM applications is
especially important when closing in on the tipping point toward performative
prediction. Then, being educated about potential effects and the societal
behavior LLMs can drive at scale due to their interplay with human operators.
In this way, the upcoming elections of the European Parliament will not remain
unaffected by LLMs. We evaluate the political bias of the currently most
popular open-source LLMs (instruct or assistant models) concerning political
issues within the European Union (EU) from a German voter's perspective. To do
so, we use the ""Wahl-O-Mat,"" a voting advice application used in Germany. From
the voting advice of the ""Wahl-O-Mat"" we quantize the degree of alignment of
LLMs with German political parties. We show that larger models, such as
Llama3-70B, tend to align more closely with left-leaning political parties,
while smaller models often remain neutral, particularly when prompted in
English. The central finding is that LLMs are similarly biased, with low
variances in the alignment concerning a specific party. Our findings underline
the importance of rigorously assessing and making bias transparent in LLMs to
safeguard the integrity and trustworthiness of applications that employ the
capabilities of performative prediction and the invisible hand of machine
learning prediction and language generation.",2024-05-17,"Luca Rettenberger, Markus Reischl, Mark Schutera",http://arxiv.org/pdf/2405.13041v3,cs.CL
ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios,"Active learning is designed to minimize annotation efforts by prioritizing
instances that most enhance learning. However, many active learning strategies
struggle with a `cold-start' problem, needing substantial initial data to be
effective. This limitation reduces their utility in the increasingly relevant
few-shot scenarios, where the instance selection has a substantial impact. To
address this, we introduce ActiveLLM, a novel active learning approach that
leverages Large Language Models such as GPT-4, o1, Llama 3, or Mistral Large
for selecting instances. We demonstrate that ActiveLLM significantly enhances
the classification performance of BERT classifiers in few-shot scenarios,
outperforming traditional active learning methods as well as improving the
few-shot learning methods ADAPET, PERFECT, and SetFit. Additionally, ActiveLLM
can be extended to non-few-shot scenarios, allowing for iterative selections.
In this way, ActiveLLM can even help other active learning strategies to
overcome their cold-start problem. Our results suggest that ActiveLLM offers a
promising solution for improving model performance across various learning
setups.",2024-05-17,"Markus Bayer, Justin Lutz, Christian Reuter",http://arxiv.org/pdf/2405.10808v2,cs.CL
Petri nets in modelling glucose regulating processes in the liver,"Diabetes is a chronic condition, considered one of the civilization diseases,
that is characterized by sustained high blood sugar levels. There is no doubt
that more and more people is going to suffer from diabetes, hence it is crucial
to understand better its biological foundations. The essential processes
related to the control of glucose levels in the blood are: glycolysis (process
of breaking down of glucose) and glucose synthesis, both taking place in the
liver. The glycolysis occurs during feeding and it is stimulated by insulin. On
the other hand, the glucose synthesis arises during fasting and it is
stimulated by glucagon. In the paper we present a Petri net model of glycolysis
and glucose synthesis in the liver. The model is created based on medical
literature. Standard Petri nets techniques are used to analyse the properties
of the model: traps, reachability graphs, tokens dynamics, deadlocks analysis.
The results are described in the paper. Our analysis shows that the model
captures the interactions between different enzymes and substances, which is
consistent with the biological processes occurring during fasting and feeding.
The model constitutes the first element of our long-time goal to create the
whole body model of the glucose regulation in a healthy human and a person with
diabetes.",2024-05-17,"Kamila Barylska, Anna Gogolińska",http://arxiv.org/pdf/2405.11009v1,cs.CL
Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings,"Knowledge-intensive tasks pose a significant challenge for Machine Learning
(ML) techniques. Commonly adopted methods, such as Large Language Models
(LLMs), often exhibit limitations when applied to such tasks. Nevertheless,
there have been notable endeavours to mitigate these challenges, with a
significant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While
KGs provide many advantages for representing knowledge, their development costs
can deter extensive research and applications. Addressing this limitation, we
introduce a framework for enriching embeddings of small-scale domain-specific
Knowledge Graphs with well-established general-purpose KGs. Adopting our
method, a modest domain-specific KG can benefit from a performance boost in
downstream tasks when linked to a substantial general-purpose KG. Experimental
evaluations demonstrate a notable enhancement, with up to a 44% increase
observed in the Hits@10 metric. This relatively unexplored research direction
can catalyze more frequent incorporation of KGs in knowledge-intensive tasks,
resulting in more robust, reliable ML implementations, which hallucinates less
than prevalent LLM solutions.
  Keywords: knowledge graph, knowledge graph completion, entity alignment,
representation learning, machine learning",2024-05-17,"Albert Sawczyn, Jakub Binkowski, Piotr Bielak, Tomasz Kajdanowicz",http://arxiv.org/pdf/2405.10745v1,cs.CL
SBAAM! Eliminating Transcript Dependency in Automatic Subtitling,"Subtitling plays a crucial role in enhancing the accessibility of audiovisual
content and encompasses three primary subtasks: translating spoken dialogue,
segmenting translations into concise textual units, and estimating timestamps
that govern their on-screen duration. Past attempts to automate this process
rely, to varying degrees, on automatic transcripts, employed diversely for the
three subtasks. In response to the acknowledged limitations associated with
this reliance on transcripts, recent research has shifted towards
transcription-free solutions for translation and segmentation, leaving the
direct generation of timestamps as uncharted territory. To fill this gap, we
introduce the first direct model capable of producing automatic subtitles,
entirely eliminating any dependence on intermediate transcripts also for
timestamp prediction. Experimental results, backed by manual evaluation,
showcase our solution's new state-of-the-art performance across multiple
language pairs and diverse conditions.",2024-05-17,"Marco Gaido, Sara Papi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli",http://arxiv.org/pdf/2405.10741v1,cs.CL
Feature-Adaptive and Data-Scalable In-Context Learning,"In-context learning (ICL), which promotes inference with several
demonstrations, has become a widespread paradigm to stimulate LLM capabilities
for downstream tasks. Due to context length constraints, it cannot be further
improved in spite of more training data, and general features directly from
LLMs in ICL are not adaptive to the specific downstream task. In this paper, we
propose a feature-adaptive and data-scalable in-context learning framework
(FADS-ICL), which can leverage task-adaptive features to promote inference on
the downstream task, with the supervision of beyond-context samples.
Specifically, it first extracts general features of beyond-context samples via
the LLM with ICL input form one by one, and introduces a task-specific
modulator to perform feature refinement and prediction after fitting a specific
downstream task. We conduct extensive experiments on FADS-ICL under varying
data settings (4$\sim$128 shots) and LLM scale (0.8$\sim$70B) settings.
Experimental results show that FADS-ICL consistently outperforms previous
state-of-the-art methods by a significant margin under all settings, verifying
the effectiveness and superiority of FADS-ICL. For example, under the 1.5B and
32 shots setting, FADS-ICL can achieve \textbf{+14.3} average accuracy from
feature adaptation over vanilla ICL on 10 datasets, with \textbf{+6.2} average
accuracy over the previous state-of-the-art method, and the performance can
further improve with increasing training data. Code and data are publicly
available at \url{https://github.com/jiahaozhenbang/FADS-ICL}.",2024-05-17,"Jiahao Li, Quan Wang, Licheng Zhang, Guoqing Jin, Zhendong Mao",http://arxiv.org/pdf/2405.10738v2,cs.CL
INDUS: Effective and Efficient Language Models for Scientific Applications,"Large language models (LLMs) trained on general domain corpora showed
remarkable results on natural language processing (NLP) tasks. However,
previous research demonstrated LLMs trained using domain-focused corpora
perform better on specialized tasks. Inspired by this insight, we developed
INDUS, a comprehensive suite of LLMs tailored for the closely-related domains
of Earth science, biology, physics, heliophysics, planetary sciences and
astrophysics, and trained using curated scientific corpora drawn from diverse
data sources. The suite of models include: (1) an encoder model trained using
domain-specific vocabulary and corpora to address NLP tasks, (2) a
contrastive-learning based text embedding model trained using a diverse set of
datasets to address information retrieval tasks and (3) smaller versions of
these models created using knowledge distillation for applications which have
latency or resource constraints. We also created three new scientific benchmark
datasets, CLIMATE-CHANGE NER (entity-recognition), NASA-QA (extractive QA) and
NASA-IR (IR) to accelerate research in these multi-disciplinary fields. We show
that our models outperform both general-purpose (RoBERTa) and domain-specific
(SCIBERT) encoders on these new tasks as well as existing tasks in the domains
of interest. Furthermore, we demonstrate the use of these models in two
industrial settings -- as a retrieval model for large-scale vector search
applications and in automatic content tagging systems.",2024-05-17,"Bishwaranjan Bhattacharjee, Aashka Trivedi, Masayasu Muraoka, Muthukumaran Ramasubramanian, Takuma Udagawa, Iksha Gurung, Nishan Pantha, Rong Zhang, Bharath Dandala, Rahul Ramachandran, Manil Maskey, Kaylin Bugbee, Mike Little, Elizabeth Fancher, Irina Gerasimov, Armin Mehrabian, Lauren Sanders, Sylvain Costes, Sergi Blanco-Cuaresma, Kelly Lockhart, Thomas Allen, Felix Grezes, Megan Ansdell, Alberto Accomazzi, Yousef El-Kurdi, Davis Wertheimer, Birgit Pfitzmann, Cesar Berrospi Ramis, Michele Dolfi, Rafael Teixeira de Lima, Panagiotis Vagenas, S. Karthik Mukkavilli, Peter Staar, Sanaz Vahidinia, Ryan McGranaghan, Tsendgar Lee",http://arxiv.org/pdf/2405.10725v3,cs.CL
SignLLM: Sign Language Production Large Language Models,"In this paper, we propose SignLLM, a multilingual Sign Language Production
(SLP) large language model, which includes two novel multilingual SLP modes
MLSF and Prompt2LangGloss that allow sign language gestures generation from
query texts input and question-style prompts input respectively. Both modes can
use a new RL loss based on reinforcement learning and a new RL module named
Priority Learning Channel. These RL components can accelerate the training by
enhancing the model's capability to sample high-quality data. To train SignLLM,
we introduce Prompt2Sign, a comprehensive multilingual sign language dataset,
which builds from public data, including American Sign Language (ASL) and seven
others. This dataset standardizes information by extracting pose information
from sign language videos into a unified compressed format. We extensively
evaluate SignLLM, demonstrating that our model achieves state-of-the-art
performance on SLP tasks across eight sign languages.",2024-05-17,"Sen Fang, Chen Chen, Lei Wang, Ce Zheng, Chunyu Sui, Yapeng Tian",http://arxiv.org/pdf/2405.10718v3,cs.CL
Persian Pronoun Resolution: Leveraging Neural Networks and Language Models,"Coreference resolution, critical for identifying textual entities referencing
the same entity, faces challenges in pronoun resolution, particularly
identifying pronoun antecedents. Existing methods often treat pronoun
resolution as a separate task from mention detection, potentially missing
valuable information. This study proposes the first end-to-end neural network
system for Persian pronoun resolution, leveraging pre-trained Transformer
models like ParsBERT. Our system jointly optimizes both mention detection and
antecedent linking, achieving a 3.37 F1 score improvement over the previous
state-of-the-art system (which relied on rule-based and statistical methods) on
the Mehr corpus. This significant improvement demonstrates the effectiveness of
combining neural networks with linguistic models, potentially marking a
significant advancement in Persian pronoun resolution and paving the way for
further research in this under-explored area.",2024-05-17,"Hassan Haji Mohammadi, Alireza Talebpour, Ahmad Mahmoudi Aznaveh, Samaneh Yazdani",http://arxiv.org/pdf/2405.10714v1,cs.CL
Empowering Prior to Court Legal Analysis: A Transparent and Accessible Dataset for Defensive Statement Classification and Interpretation,"The classification of statements provided by individuals during police
interviews is a complex and significant task within the domain of natural
language processing (NLP) and legal informatics. The lack of extensive
domain-specific datasets raises challenges to the advancement of NLP methods in
the field. This paper aims to address some of the present challenges by
introducing a novel dataset tailored for classification of statements made
during police interviews, prior to court proceedings. Utilising the curated
dataset for training and evaluation, we introduce a fine-tuned DistilBERT model
that achieves state-of-the-art performance in distinguishing truthful from
deceptive statements. To enhance interpretability, we employ explainable
artificial intelligence (XAI) methods to offer explainability through saliency
maps, that interpret the model's decision-making process. Lastly, we present an
XAI interface that empowers both legal professionals and non-specialists to
interact with and benefit from our system. Our model achieves an accuracy of
86%, and is shown to outperform a custom transformer architecture in a
comparative study. This holistic approach advances the accessibility,
transparency, and effectiveness of statement analysis, with promising
implications for both legal practice and research.",2024-05-17,"Yannis Spyridis, Jean-Paul, Haneen Deeb, Vasileios Argyriou",http://arxiv.org/pdf/2405.10702v1,cs.CL
SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks,"Diaspora communities are disproportionately impacted by off-the-radar
misinformation and often neglected by mainstream fact-checking efforts,
creating a critical need to scale-up efforts of nascent fact-checking
initiatives. In this paper we present SynDy, a framework for Synthetic Dynamic
Dataset Generation to leverage the capabilities of the largest frontier Large
Language Models (LLMs) to train local, specialized language models. To the best
of our knowledge, SynDy is the first paper utilizing LLMs to create
fine-grained synthetic labels for tasks of direct relevance to misinformation
mitigation, namely Claim Matching, Topical Clustering, and Claim Relationship
Classification. SynDy utilizes LLMs and social media queries to automatically
generate distantly-supervised, topically-focused datasets with synthetic labels
on these three tasks, providing essential tools to scale up human-led
fact-checking at a fraction of the cost of human-annotated data. Training on
SynDy's generated labels shows improvement over a standard baseline and is not
significantly worse compared to training on human labels (which may be
infeasible to acquire). SynDy is being integrated into Meedan's chatbot
tiplines that are used by over 50 organizations, serve over 230K users
annually, and automatically distribute human-written fact-checks via messaging
apps such as WhatsApp. SynDy will also be integrated into our deployed
Co-Insights toolkit, enabling low-resource organizations to launch tiplines for
their communities. Finally, we envision SynDy enabling additional fact-checking
tools such as matching new misinformation claims to high-quality explainers on
common misinformation topics.",2024-05-17,"Michael Shliselberg, Ashkan Kazemi, Scott A. Hale, Shiri Dori-Hacohen",http://arxiv.org/pdf/2405.10700v1,cs.CL
Revolutionizing Process Mining: A Novel Architecture for ChatGPT Integration and Enhanced User Experience through Optimized Prompt Engineering,"In the rapidly evolving field of business process management, there is a
growing need for analytical tools that can transform complex data into
actionable insights. This research introduces a novel approach by integrating
Large Language Models (LLMs), such as ChatGPT, into process mining tools,
making process analytics more accessible to a wider audience. The study aims to
investigate how ChatGPT enhances analytical capabilities, improves user
experience, increases accessibility, and optimizes the architectural frameworks
of process mining tools. The key innovation of this research lies in developing
a tailored prompt engineering strategy for each process mining submodule,
ensuring that the AI-generated outputs are accurate and relevant to the
context. The integration architecture follows an Extract, Transform, Load (ETL)
process, which includes various process mining engine modules and utilizes
zero-shot and optimized prompt engineering techniques. ChatGPT is connected via
APIs and receives structured outputs from the process mining modules, enabling
conversational interactions. To validate the effectiveness of this approach,
the researchers used data from 17 companies that employ BehfaLab's Process
Mining Tool. The results showed significant improvements in user experience,
with an expert panel rating 72% of the results as ""Good"". This research
contributes to the advancement of business process analysis methodologies by
combining process mining with artificial intelligence. Future research
directions include further optimization of prompt engineering, exploration of
integration with other AI technologies, and assessment of scalability across
various business environments. This study paves the way for continuous
innovation at the intersection of process mining and artificial intelligence,
promising to revolutionize the way businesses analyze and optimize their
processes.",2024-05-17,"Mehrdad Agha Mohammad Ali Kermani, Hamid Reza Seddighi, Mehrdad Maghsoudi",http://arxiv.org/pdf/2405.10689v1,cs.CL
Realistic Evaluation of Toxicity in Large Language Models,"Large language models (LLMs) have become integral to our professional
workflows and daily lives. Nevertheless, these machine companions of ours have
a critical flaw: the huge amount of data which endows them with vast and
diverse knowledge, also exposes them to the inevitable toxicity and bias. While
most LLMs incorporate defense mechanisms to prevent the generation of harmful
content, these safeguards can be easily bypassed with minimal prompt
engineering. In this paper, we introduce the new Thoroughly Engineered Toxicity
(TET) dataset, comprising manually crafted prompts designed to nullify the
protective layers of such models. Through extensive evaluations, we demonstrate
the pivotal role of TET in providing a rigorous benchmark for evaluation of
toxicity awareness in several popular LLMs: it highlights the toxicity in the
LLMs that might remain hidden when using normal prompts, thus revealing subtler
issues in their behavior.",2024-05-17,"Tinh Son Luong, Thanh-Thien Le, Linh Ngo Van, Thien Huu Nguyen",http://arxiv.org/pdf/2405.10659v2,cs.CL
SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation,"Compositional generalization is an important ability of language models and
has many different manifestations. For data-to-text generation, previous
research on this ability is limited to a single manifestation called
Systematicity and lacks consideration of large language models (LLMs), which
cannot fully cover practical application scenarios. In this work, we propose
SPOR, a comprehensive and practical evaluation method for compositional
generalization in data-to-text generation. SPOR includes four aspects of
manifestations (Systematicity, Productivity, Order invariance, and Rule
learnability) and allows high-quality evaluation without additional manual
annotations based on existing datasets. We demonstrate SPOR on two different
datasets and evaluate some existing language models including LLMs. We find
that the models are deficient in various aspects of the evaluation and need
further improvement. Our work shows the necessity for comprehensive research on
different manifestations of compositional generalization in data-to-text
generation and provides a framework for evaluation.",2024-05-17,"Ziyao Xu, Houfeng Wang",http://arxiv.org/pdf/2405.10650v8,cs.CL
Layer-Condensed KV Cache for Efficient Inference of Large Language Models,"Huge memory consumption has been a major bottleneck for deploying
high-throughput large language models in real-world applications. In addition
to the large number of parameters, the key-value (KV) cache for the attention
mechanism in the transformer architecture consumes a significant amount of
memory, especially when the number of layers is large for deep language models.
In this paper, we propose a novel method that only computes and caches the KVs
of a small number of layers, thus significantly saving memory consumption and
improving inference throughput. Our experiments on large language models show
that our method achieves up to 26$\times$ higher throughput than standard
transformers and competitive performance in language modeling and downstream
tasks. In addition, our method is orthogonal to existing transformer
memory-saving techniques, so it is straightforward to integrate them with our
model, achieving further improvement in inference efficiency. Our code is
available at https://github.com/whyNLP/LCKV.",2024-05-17,"Haoyi Wu, Kewei Tu",http://arxiv.org/pdf/2405.10637v2,cs.CL
"Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges","This paper surveys and organizes research works on medical dialog systems,
which is an important yet challenging task. Although these systems have been
surveyed in the medical community from an application perspective, a systematic
review from a rigorous technical perspective has to date remained noticeably
absent. As a result, an overview of the categories, methods, and evaluation of
medical dialogue systems remain limited and underspecified, hindering the
further improvement of this area. To fill this gap, we investigate an initial
pool of 325 papers from well-known computer science, and natural language
processing conferences and journals, and make an overview. Recently, large
language models have shown strong model capacity on downstream tasks, which
also reshaped medical dialog systems' foundation. Despite the alluring
practical application value, current medical dialogue systems still suffer from
problems. To this end, this paper lists the grand challenges of medical dialog
systems, especially of large language models.",2024-05-17,"Xiaoming Shi, Zeming Liu, Li Du, Yuxuan Wang, Hongru Wang, Yuhang Guo, Tong Ruan, Jie Xu, Shaoting Zhang",http://arxiv.org/pdf/2405.10630v1,cs.CL
DeepPavlov at SemEval-2024 Task 8: Leveraging Transfer Learning for Detecting Boundaries of Machine-Generated Texts,"The Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated
Text Detection shared task in the SemEval-2024 competition aims to tackle the
problem of misusing collaborative human-AI writing. Although there are a lot of
existing detectors of AI content, they are often designed to give a binary
answer and thus may not be suitable for more nuanced problem of finding the
boundaries between human-written and machine-generated texts, while hybrid
human-AI writing becomes more and more popular. In this paper, we address the
boundary detection problem. Particularly, we present a pipeline for augmenting
data for supervised fine-tuning of DeBERTaV3. We receive new best MAE score,
according to the leaderboard of the competition, with this pipeline.",2024-05-17,"Anastasia Voznyuk, Vasily Konovalov",http://arxiv.org/pdf/2405.10629v1,cs.CL
Dynamic data sampler for cross-language transfer learning in large language models,"Large Language Models (LLMs) have gained significant attention in the field
of natural language processing (NLP) due to their wide range of applications.
However, training LLMs for languages other than English poses significant
challenges, due to the difficulty in acquiring large-scale corpus and the
requisite computing resources. In this paper, we propose ChatFlow, a
cross-language transfer-based LLM, to address these challenges and train large
Chinese language models in a cost-effective manner. We employ a mix of Chinese,
English, and parallel corpus to continuously train the LLaMA2 model, aiming to
align cross-language representations and facilitate the knowledge transfer
specifically to the Chinese language model. In addition, we use a dynamic data
sampler to progressively transition the model from unsupervised pre-training to
supervised fine-tuning. Experimental results demonstrate that our approach
accelerates model convergence and achieves superior performance. We evaluate
ChatFlow on popular Chinese and English benchmarks, the results indicate that
it outperforms other Chinese models post-trained on LLaMA-2-7B.",2024-05-17,"Yudong Li, Yuhao Feng, Wen Zhou, Zhe Zhao, Linlin Shen, Cheng Hou, Xianxu Hou",http://arxiv.org/pdf/2405.10626v1,cs.CL
Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction,"Transformer-based encoder-decoder models have demonstrated impressive results
in chemical reaction prediction tasks. However, these models typically rely on
pretraining using tens of millions of unlabelled molecules, which can be
time-consuming and GPU-intensive. One of the central questions we aim to answer
in this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained
solely on language data, be effectively specialised for organic reaction
prediction through task-specific fine-tuning? We conduct a systematic empirical
study on several key issues of the process, including tokenisation, the impact
of (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding
algorithms at inference. Our key findings indicate that although being
pretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation
to fine-tune for reaction prediction, and thus become `chemistry domain
compatible' in the process. This suggests that GPU-intensive and expensive
pretraining on a large dataset of unlabelled molecules may be useful yet not
essential to leverage the power of language models for chemistry. All our
models achieve comparable Top-1 and Top-5 accuracy although some variation
across different models does exist. Notably, tokenisation and vocabulary
trimming slightly affect final performance but can speed up training and
inference; The most efficient greedy decoding strategy is very competitive
while only marginal gains can be achieved from more sophisticated decoding
algorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions
and benchmark their impact on organic reaction prediction, which may guide more
effective use of these state-of-the-art language models for chemistry-related
tasks in the future.",2024-05-17,"Jiayun Pang, Ivan Vulić",http://arxiv.org/pdf/2405.10625v1,cs.CL
MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains,"In the Vision-and-Language Navigation (VLN) task, the agent is required to
navigate to a destination following a natural language instruction. While
learning-based approaches have been a major solution to the task, they suffer
from high training costs and lack of interpretability. Recently, Large Language
Models (LLMs) have emerged as a promising tool for VLN due to their strong
generalization capabilities. However, existing LLM-based methods face
limitations in memory construction and diversity of navigation strategies. To
address these challenges, we propose a suite of techniques. Firstly, we
introduce a method to maintain a topological map that stores navigation
history, retaining information about viewpoints, objects, and their spatial
relationships. This map also serves as a global action space. Additionally, we
present a Navigation Chain of Thoughts module, leveraging human navigation
examples to enrich navigation strategy diversity. Finally, we establish a
pipeline that integrates navigational memory and strategies with perception and
action prediction modules. Experimental results on the REVERIE and R2R datasets
show that our method effectively enhances the navigation ability of the LLM and
improves the interpretability of navigation reasoning.",2024-05-17,"Zhaohuan Zhan, Lisha Yu, Sijie Yu, Guang Tan",http://arxiv.org/pdf/2405.10620v2,cs.CL
Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization,"In recent years, large language models (LLMs) have driven advances in natural
language processing. Still, their growing scale has increased the computational
burden, necessitating a balance between efficiency and performance. Low-rank
compression, a promising technique, reduces non-essential parameters by
decomposing weight matrices into products of two low-rank matrices. Yet, its
application in LLMs has not been extensively studied. The key to low-rank
compression lies in low-rank factorization and low-rank dimensions allocation.
To address the challenges of low-rank compression in LLMs, we conduct empirical
research on the low-rank characteristics of large models. We propose a low-rank
compression method suitable for LLMs. This approach involves precise estimation
of feature distributions through pooled covariance matrices and a Bayesian
optimization strategy for allocating low-rank dimensions. Experiments on the
LLaMA-2 models demonstrate that our method outperforms existing strong
structured pruning and low-rank compression techniques in maintaining model
performance at the same compression ratio.",2024-05-17,"Yixin Ji, Yang Xiang, Juntao Li, Qingrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Kehai Chen, Min Zhang",http://arxiv.org/pdf/2405.10616v2,cs.CL
UniCL: A Universal Contrastive Learning Framework for Large Time Series Models,"Time-series analysis plays a pivotal role across a range of critical
applications, from finance to healthcare, which involves various tasks, such as
forecasting and classification. To handle the inherent complexities of
time-series data, such as high dimensionality and noise, traditional supervised
learning methods first annotate extensive labels for time-series data in each
task, which is very costly and impractical in real-world applications. In
contrast, pre-trained foundation models offer a promising alternative by
leveraging unlabeled data to capture general time series patterns, which can
then be fine-tuned for specific tasks. However, existing approaches to
pre-training such models typically suffer from high-bias and low-generality
issues due to the use of predefined and rigid augmentation operations and
domain-specific data training. To overcome these limitations, this paper
introduces UniCL, a universal and scalable contrastive learning framework
designed for pretraining time-series foundation models across cross-domain
datasets. Specifically, we propose a unified and trainable time-series
augmentation operation to generate pattern-preserved, diverse, and low-bias
time-series data by leveraging spectral information. Besides, we introduce a
scalable augmentation algorithm capable of handling datasets with varying
lengths, facilitating cross-domain pretraining. Extensive experiments on two
benchmark datasets across eleven domains validate the effectiveness of UniCL,
demonstrating its high generalization on time-series analysis across various
fields.",2024-05-17,"Jiawei Li, Jingshu Peng, Haoyang Li, Lei Chen",http://arxiv.org/pdf/2405.10597v1,cs.CL
"Surgical Feature-Space Decomposition of LLMs: Why, When and How?","Low-rank approximations, of the weight and feature space can enhance the
performance of deep learning models, whether in terms of improving
generalization or reducing the latency of inference. However, there is no clear
consensus yet on \emph{how}, \emph{when} and \emph{why} these approximations
are helpful for large language models (LLMs). In this work, we empirically
study the efficacy of weight and feature space decomposition in
transformer-based LLMs. We demonstrate that surgical decomposition not only
provides critical insights into the trade-off between compression and language
modelling performance, but also sometimes enhances commonsense reasoning
performance of LLMs. Our empirical analysis identifies specific network
segments that intrinsically exhibit a low-rank structure. Furthermore, we
extend our investigation to the implications of low-rank approximations on
model bias. Overall, our findings offer a novel perspective on optimizing LLMs,
presenting the low-rank approximation not only as a tool for performance
enhancements, but also as a means to potentially rectify biases within these
models. Our code is available at
\href{https://github.com/nyunAI/SFSD-LLM}{GitHub}.",2024-05-17,"Arnav Chavan, Nahush Lele, Deepak Gupta",http://arxiv.org/pdf/2405.13039v1,cs.CL
RDRec: Rationale Distillation for LLM-based Recommendation,"Large language model (LLM)-based recommender models that bridge users and
items through textual prompts for effective semantic reasoning have gained
considerable attention. However, few methods consider the underlying rationales
behind interactions, such as user preferences and item attributes, limiting the
reasoning capability of LLMs for recommendations. This paper proposes a
rationale distillation recommender (RDRec), a compact model designed to learn
rationales generated by a larger language model (LM). By leveraging rationales
from reviews related to users and items, RDRec remarkably specifies their
profiles for recommendations. Experiments show that RDRec achieves
state-of-the-art (SOTA) performance in both top-N and sequential
recommendations. Our source code is released at
https://github.com/WangXFng/RDRec.",2024-05-17,"Xinfeng Wang, Jin Cui, Yoshimi Suzuki, Fumiyo Fukumoto",http://arxiv.org/pdf/2405.10587v3,cs.CL
A Hybrid Deep Learning Framework for Stock Price Prediction Considering the Investor Sentiment of Online Forum Enhanced by Popularity,"Stock price prediction has always been a difficult task for forecasters.
Using cutting-edge deep learning techniques, stock price prediction based on
investor sentiment extracted from online forums has become feasible. We propose
a novel hybrid deep learning framework for predicting stock prices. The
framework leverages the XLNET model to analyze the sentiment conveyed in user
posts on online forums, combines these sentiments with the post popularity
factor to compute daily group sentiments, and integrates this information with
stock technical indicators into an improved BiLSTM-highway model for stock
price prediction. Through a series of comparative experiments involving four
stocks on the Chinese stock market, it is demonstrated that the hybrid
framework effectively predicts stock prices. This study reveals the necessity
of analyzing investors' textual views for stock price prediction.",2024-05-17,"Huiyu Li, Junhua Hu",http://arxiv.org/pdf/2405.10584v1,cs.CL
A Hard Nut to Crack: Idiom Detection with Conversational Large Language Models,"In this work, we explore idiomatic language processing with Large Language
Models (LLMs). We introduce the Idiomatic language Test Suite IdioTS, a new
dataset of difficult examples specifically designed by language experts to
assess the capabilities of LLMs to process figurative language at sentence
level. We propose a comprehensive evaluation methodology based on an idiom
detection task, where LLMs are prompted with detecting an idiomatic expression
in a given English sentence. We present a thorough automatic and manual
evaluation of the results and an extensive error analysis.",2024-05-17,"Francesca De Luca Fornaciari, Begoña Altuna, Itziar Gonzalez-Dios, Maite Melero",http://arxiv.org/pdf/2405.10579v1,cs.CL
Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation,"Dialogue State Tracking (DST) is designed to monitor the evolving dialogue
state in the conversations and plays a pivotal role in developing task-oriented
dialogue systems. However, obtaining the annotated data for the DST task is
usually a costly endeavor. In this paper, we focus on employing LLMs to
generate dialogue data to reduce dialogue collection and annotation costs.
Specifically, GPT-4 is used to simulate the user and agent interaction,
generating thousands of dialogues annotated with DST labels. Then a two-stage
fine-tuning on LLaMA 2 is performed on the generated data and the real data for
the DST prediction. Experimental results on two public DST benchmarks show that
with the generated dialogue data, our model performs better than the baseline
trained solely on real data. In addition, our approach is also capable of
adapting to the dynamic demands in real-world scenarios, generating dialogues
in new domains swiftly. After replacing dialogue segments in any domain with
the corresponding generated ones, the model achieves comparable performance to
the model trained on real data.",2024-05-17,"Cheng Niu, Xingguang Wang, Xuxin Cheng, Juntong Song, Tong Zhang",http://arxiv.org/pdf/2405.13037v1,cs.CL
Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks,"Large Language Models (LLMs) have transformed NLP with their remarkable
In-context Learning (ICL) capabilities. Automated assistants based on LLMs are
gaining popularity; however, adapting them to novel tasks is still challenging.
While colossal models excel in zero-shot performance, their computational
demands limit widespread use, and smaller language models struggle without
context. This paper investigates whether LLMs can generalize from labeled
examples of predefined tasks to novel tasks. Drawing inspiration from
biological neurons and the mechanistic interpretation of the Transformer
architecture, we explore the potential for information sharing across tasks. We
design a cross-task prompting setup with three LLMs and show that LLMs achieve
significant performance improvements despite no examples from the target task
in the context. Cross-task prompting leads to a remarkable performance boost of
107% for LLaMA-2 7B, 18.6% for LLaMA-2 13B, and 3.2% for GPT 3.5 on average
over zero-shot prompting, and performs comparable to standard in-context
learning. The effectiveness of generating pseudo-labels for in-task examples is
demonstrated, and our analyses reveal a strong correlation between the effect
of cross-task examples and model activation similarities in source and target
input tokens. This paper offers a first-of-its-kind exploration of LLMs'
ability to solve novel tasks based on contextual signals from different task
examples.",2024-05-17,"Anwoy Chatterjee, Eshaan Tanwar, Subhabrata Dutta, Tanmoy Chakraborty",http://arxiv.org/pdf/2405.10548v3,cs.CL
Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset,"In light of recent breakthroughs in large language models (LLMs) that have
revolutionized natural language processing (NLP), there is an urgent need for
new benchmarks to keep pace with the fast development of LLMs. In this paper,
we propose CFLUE, the Chinese Financial Language Understanding Evaluation
benchmark, designed to assess the capability of LLMs across various dimensions.
Specifically, CFLUE provides datasets tailored for both knowledge assessment
and application assessment. In knowledge assessment, it consists of 38K+
multiple-choice questions with associated solution explanations. These
questions serve dual purposes: answer prediction and question reasoning. In
application assessment, CFLUE features 16K+ test instances across distinct
groups of NLP tasks such as text classification, machine translation, relation
extraction, reading comprehension, and text generation. Upon CFLUE, we conduct
a thorough evaluation of representative LLMs. The results reveal that only
GPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\% in answer prediction
for knowledge assessment, suggesting that there is still substantial room for
improvement in current LLMs. In application assessment, although GPT-4 and
GPT-4-turbo are the top two performers, their considerable advantage over
lightweight LLMs is noticeably diminished. The datasets and scripts associated
with CFLUE are openly accessible at https://github.com/aliyun/cflue.",2024-05-17,"Jie Zhu, Junhui Li, Yalong Wen, Lifan Guo",http://arxiv.org/pdf/2405.10542v1,cs.CL
Adaptable and Reliable Text Classification using Large Language Models,"Text classification is fundamental in Natural Language Processing (NLP), and
the advent of Large Language Models (LLMs) has revolutionized the field. This
paper introduces an adaptable and reliable text classification paradigm, which
leverages LLMs as the core component to address text classification tasks. Our
system simplifies the traditional text classification workflows, reducing the
need for extensive preprocessing and domain-specific expertise to deliver
adaptable and reliable text classification results. We evaluated the
performance of several LLMs, machine learning algorithms, and neural
network-based architectures on four diverse datasets. Results demonstrate that
certain LLMs surpass traditional methods in sentiment analysis, spam SMS
detection, and multi-label classification. Furthermore, it is shown that the
system's performance can be further enhanced through few-shot or fine-tuning
strategies, making the fine-tuned model the top performer across all datasets.
Source code and datasets are available in this GitHub repository:
https://github.com/yeyimilk/llm-zero-shot-classifiers.",2024-05-17,"Zhiqiang Wang, Yiran Pang, Yanbin Lin, Xingquan Zhu",http://arxiv.org/pdf/2405.10523v3,cs.CL
Towards Better Question Generation in QA-based Event Extraction,"Event Extraction (EE) is an essential information extraction task that aims
to extract event-related information from unstructured texts. The paradigm of
this task has shifted from conventional classification-based methods to more
contemporary question-answering-based (QA-based) approaches. However, in
QA-based EE, the quality of the questions dramatically affects the extraction
accuracy, and how to generate high-quality questions for QA-based EE remains a
challenge. In this work, to tackle this challenge, we suggest four criteria to
evaluate the quality of a question and propose a reinforcement learning method,
RLQG, for QA-based EE that can generate generalizable, high-quality, and
context-dependent questions and provides clear guidance to QA models. The
extensive experiments conducted on ACE and RAMS datasets have strongly
validated our approach's effectiveness, which also demonstrates its robustness
in scenarios with limited training data. The corresponding code of RLQG is
released for further research.",2024-05-17,"Zijin Hong, Jian Liu",http://arxiv.org/pdf/2405.10517v3,cs.CL
Language Models can Evaluate Themselves via Probability Discrepancy,"In this paper, we initiate our discussion by demonstrating how Large Language
Models (LLMs), when tasked with responding to queries, display a more even
probability distribution in their answers if they are more adept, as opposed to
their less skilled counterparts. Expanding on this foundational insight, we
propose a new self-evaluation method ProbDiff for assessing the efficacy of
various LLMs. This approach obviates the necessity for an additional evaluation
model or the dependence on external, proprietary models like GPT-4 for
judgment. It uniquely utilizes the LLMs being tested to compute the probability
discrepancy between the initial response and its revised versions. A higher
discrepancy for a given query between two LLMs indicates a relatively weaker
capability. Our findings reveal that ProbDiff achieves results on par with
those obtained from evaluations based on GPT-4, spanning a range of scenarios
that include natural language generation (NLG) tasks such as translation,
summarization, and our proposed Xiaohongshu blog writing task, and benchmarks
for LLM evaluation like AlignBench, MT-Bench, and AlpacaEval, across LLMs of
varying magnitudes.",2024-05-17,"Tingyu Xia, Bowen Yu, Yuan Wu, Yi Chang, Chang Zhou",http://arxiv.org/pdf/2405.10516v2,cs.CL
Automatic News Generation and Fact-Checking System Based on Language Processing,"This paper explores an automatic news generation and fact-checking system
based on language processing, aimed at enhancing the efficiency and quality of
news production while ensuring the authenticity and reliability of the news
content. With the rapid development of Natural Language Processing (NLP) and
deep learning technologies, automatic news generation systems are capable of
extracting key information from massive data and generating well-structured,
fluent news articles. Meanwhile, by integrating fact-checking technology, the
system can effectively prevent the spread of false news and improve the
accuracy and credibility of news. This study details the key technologies
involved in automatic news generation and factchecking, including text
generation, information extraction, and the application of knowledge graphs,
and validates the effectiveness of these technologies through experiments.
Additionally, the paper discusses the future development directions of
automatic news generation and fact-checking systems, emphasizing the importance
of further integration and innovation of technologies. The results show that
with continuous technological optimization and practical application, these
systems will play an increasingly important role in the future news industry,
providing more efficient and reliable news services.",2024-05-17,"Xirui Peng, Qiming Xu, Zheng Feng, Haopeng Zhao, Lianghao Tan, Yan Zhou, Zecheng Zhang, Chenwei Gong, Yingqiao Zheng",http://arxiv.org/pdf/2405.10492v2,cs.CL
CNER: A tool Classifier of Named-Entity Relationships,"We introduce CNER, an ensemble of capable tools for extraction of semantic
relationships between named entities in Spanish language. Built upon a
container-based architecture, CNER integrates different Named entity
recognition and relation extraction tools with a user-friendly interface that
allows users to input free text or files effortlessly, facilitating streamlined
analysis. Developed as a prototype version for the Natural Language Processing
(NLP) Group at Universidad del Valle, CNER serves as a practical educational
resource, illustrating how machine learning techniques can effectively tackle
diverse NLP tasks in Spanish. Our preliminary results reveal the promising
potential of CNER in advancing the understanding and development of NLP tools,
particularly within Spanish-language contexts.",2024-05-17,"Jefferson A. Peña Torres, Raúl E. Gutiérrez De Piñerez",http://arxiv.org/pdf/2405.10485v1,cs.CL
Rethinking ChatGPT's Success: Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs' Prompting,"Over the last decade, a wide range of training and deployment strategies for
Large Language Models (LLMs) have emerged. Among these, the prompting paradigms
of Auto-regressive LLMs (AR-LLMs) have catalyzed a significant surge in
Artificial Intelligence (AI). This paper aims to emphasize the significance of
utilizing free-form modalities (forms of input and output) and verbal free-form
contexts as user-directed channels (methods for transforming modalities) for
downstream deployment. Specifically, we analyze the structure of modalities
within both two types of LLMs and six task-specific channels during deployment.
From the perspective of users, our analysis introduces and applies the
analytical metrics of task customizability, transparency, and complexity to
gauge their usability, highlighting the superior nature of AR-LLMs' prompting
paradigms. Moreover, we examine the stimulation of diverse cognitive behaviors
in LLMs through the adoption of free-form text and verbal contexts, mirroring
human linguistic expressions of such behaviors. We then detail four common
cognitive behaviors to underscore how AR-LLMs' prompting successfully imitate
human-like behaviors using this free-form modality and channel. Lastly, the
potential for improving LLM deployment, both as autonomous agents and within
multi-agent systems, is identified via cognitive behavior concepts and
principles.",2024-05-17,"Xinzhe Li, Ming Liu",http://arxiv.org/pdf/2405.10474v1,cs.CL
Can formal argumentative reasoning enhance LLMs performances?,"Recent years witnessed significant performance advancements in
deep-learning-driven natural language models, with a strong focus on the
development and release of Large Language Models (LLMs). These improvements
resulted in better quality AI-generated output but rely on resource-expensive
training and upgrading of models. Although different studies have proposed a
range of techniques to enhance LLMs without retraining, none have considered
computational argumentation as an option. This is a missed opportunity since
computational argumentation is an intuitive mechanism that formally captures
agents' interactions and the information conflict that may arise during such
interplays, and so it seems well-suited for boosting the reasoning and
conversational abilities of LLMs in a seamless manner. In this paper, we
present a pipeline (MQArgEng) and preliminary study to evaluate the effect of
introducing computational argumentation semantics on the performance of LLMs.
Our experiment's goal was to provide a proof-of-concept and a feasibility
analysis in order to foster (or deter) future research towards a fully-fledged
argumentation engine plugin for LLMs. Exploratory results using the MT-Bench
indicate that MQArgEng provides a moderate performance gain in most of the
examined topical categories and, as such, show promise and warrant further
research.",2024-05-16,"Federico Castagna, Isabel Sassoon, Simon Parsons",http://arxiv.org/pdf/2405.13036v1,cs.CL
Participle-Prepended Nominals Have Lower Entropy Than Nominals Appended After the Participle,"English allows for both compounds (e.g., London-made) and phrasal paraphrases
(e.g., made in London). While these constructions have roughly the same
truth-conditional meaning, we hypothesize that the compound allows less freedom
to express the nature of the semantic relationship between the participle and
the pre-participle nominal. We thus predict that the pre-participle slot is
more constrained than the equivalent position in the phrasal construction. We
test this prediction in a large corpus by measuring the entropy of
corresponding nominal slots, conditional on the participle used. That is, we
compare the entropy of $\alpha$ in compound construction slots like
$\alpha$-[V]ed to the entropy of $\alpha$ in phrasal constructions like [V]ed
by $\alpha$ for a given verb V. As predicted, there is significantly lower
entropy in the compound construction than in the phrasal construction. We
consider how these predictions follow from more general grammatical properties
and processing factors.",2024-05-16,"Kristie Denlinger, Stephen Wechsler, Kyle Mahowald",http://arxiv.org/pdf/2405.10457v1,cs.CL
Exploring Public Attention in the Circular Economy through Topic Modelling with Twin Hyperparameter Optimisation,"To advance the circular economy (CE), it is crucial to gain insights into the
evolution of public attention, cognitive pathways of the masses concerning
circular products, and to identify primary concerns. To achieve this, we
collected data from diverse platforms, including Twitter, Reddit, and The
Guardian, and utilised three topic models to analyse the data. Given the
performance of topic modelling may vary depending on hyperparameter settings,
this research proposed a novel framework that integrates twin (single and
multi-objective) hyperparameter optimisation for the CE. We conducted
systematic experiments to ensure that topic models are set with appropriate
hyperparameters under different constraints, providing valuable insights into
the correlations between CE and public attention. In summary, our optimised
model reveals that public remains concerned about the economic impacts of
sustainability and circular practices, particularly regarding recyclable
materials and environmentally sustainable technologies. The analysis shows that
the CE has attracted significant attention on The Guardian, especially in
topics related to sustainable development and environmental protection
technologies, while discussions are comparatively less active on Twitter. These
insights highlight the need for policymakers to implement targeted education
programs, create incentives for businesses to adopt CE principles, and enforce
more stringent waste management policies alongside improved recycling
processes.",2024-05-16,"Junhao Song, Yingfang Yuan, Kaiwen Chang, Bing Xu, Jin Xuan, Wei Pang",http://arxiv.org/pdf/2405.10452v2,cs.CL
Large Language Models for Tuning Evolution Strategies,"Large Language Models (LLMs) exhibit world knowledge and inference
capabilities, making them powerful tools for various applications. This paper
proposes a feedback loop mechanism that leverages these capabilities to tune
Evolution Strategies (ES) parameters effectively. The mechanism involves a
structured process of providing programming instructions, executing the
corresponding code, and conducting thorough analysis. This process is
specifically designed for the optimization of ES parameters. The method
operates through an iterative cycle, ensuring continuous refinement of the ES
parameters. First, LLMs process the instructions to generate or modify the
code. The code is then executed, and the results are meticulously logged.
Subsequent analysis of these results provides insights that drive further
improvements. An experiment on tuning the learning rates of ES using the LLaMA3
model demonstrate the feasibility of this approach. This research illustrates
how LLMs can be harnessed to improve ES algorithms' performance and suggests
broader applications for similar feedback loop mechanisms in various domains.",2024-05-16,Oliver Kramer,http://arxiv.org/pdf/2405.10999v1,cs.CL
"Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation","Large language models (LLMs) have achieved state-of-the-art performance in
various language processing tasks, motivating their adoption in simultaneous
translation. Current fine-tuning methods to adapt LLMs for simultaneous
translation focus on prompting optimization strategies using either data
augmentation or prompt structure modifications. However, these methods suffer
from several issues, such as unnecessarily expanded training sets,
computational inefficiency from dumping the key and value cache, increased
prompt sizes, or restriction to a single decision policy. To eliminate these
issues, in this work, we propose SimulMask, a new paradigm for fine-tuning LLMs
for simultaneous translation. It utilizes a novel attention mask approach that
models simultaneous translation during fine-tuning by masking attention for a
desired decision policy. Applying the proposed SimulMask on a Falcon LLM for
the IWSLT 2017 dataset, we have observed a significant translation quality
improvement compared to state-of-the-art prompting optimization strategies on
five language pairs while reducing the computational cost.",2024-05-16,"Matthew Raffel, Victor Agostinelli, Lizhong Chen",http://arxiv.org/pdf/2405.10443v4,cs.CL
A Hybrid Framework with Large Language Models for Rare Disease Phenotyping,"Rare diseases pose significant challenges in diagnosis and treatment due to
their low prevalence and heterogeneous clinical presentations. Unstructured
clinical notes contain valuable information for identifying rare diseases, but
manual curation is time-consuming and prone to subjectivity. This study aims to
develop a hybrid approach combining dictionary-based natural language
processing (NLP) tools with large language models (LLMs) to improve rare
disease identification from unstructured clinical reports. We propose a novel
hybrid framework that integrates the Orphanet Rare Disease Ontology (ORDO) and
the Unified Medical Language System (UMLS) to create a comprehensive rare
disease vocabulary. The proposed hybrid approach demonstrates superior
performance compared to traditional NLP systems and standalone LLMs. Notably,
the approach uncovers a significant number of potential rare disease cases not
documented in structured diagnostic records, highlighting its ability to
identify previously unrecognized patients.",2024-05-16,"Jinge Wu, Hang Dong, Zexi Li, Haowei Wang, Runci Li, Arijit Patra, Chengliang Dai, Waqar Ali, Phil Scordis, Honghan Wu",http://arxiv.org/pdf/2405.10440v3,cs.CL
Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models,"Existing debiasing techniques are typically training-based or require access
to the model's internals and output distributions, so they are inaccessible to
end-users looking to adapt LLM outputs for their particular needs. In this
study, we examine whether structured prompting techniques can offer
opportunities for fair text generation. We evaluate a comprehensive
end-user-focused iterative framework of debiasing that applies System 2
thinking processes for prompts to induce logical, reflective, and critical text
generation, with single, multi-step, instruction, and role-based variants. By
systematically evaluating many LLMs across many datasets and different
prompting strategies, we show that the more complex System 2-based Implicative
Prompts significantly improve over other techniques demonstrating lower mean
bias in the outputs with competitive performance on the downstream tasks. Our
work offers research directions for the design and the potential of
end-user-focused evaluative frameworks for LLM use.",2024-05-16,"Shaz Furniturewala, Surgan Jandial, Abhinav Java, Pragyan Banerjee, Simra Shahid, Sumit Bhatia, Kokil Jaidka",http://arxiv.org/pdf/2405.10431v1,cs.CL
Memory-efficient Energy-adaptive Inference of Pre-Trained Models on Batteryless Embedded Systems,"Batteryless systems frequently face power failures, requiring extra runtime
buffers to maintain inference progress and leaving only a memory space for
storing ultra-tiny deep neural networks (DNNs). Besides, making these models
responsive to stochastic energy harvesting dynamics during inference requires a
balance between inference accuracy, latency, and energy overhead. Recent works
on compression mostly focus on time and memory, but often ignore energy
dynamics or significantly reduce the accuracy of pre-trained DNNs. Existing
energy-adaptive inference works modify the architecture of pre-trained models
and have significant memory overhead. Thus, energy-adaptive and accurate
inference of pre-trained DNNs on batteryless devices with extreme memory
constraints is more challenging than traditional microcontrollers. We combat
these issues by proposing FreeML, a framework to optimize pre-trained DNN
models for memory-efficient and energy-adaptive inference on batteryless
systems. FreeML comprises (1) a novel compression technique to reduce the model
footprint and runtime memory requirements simultaneously, making them
executable on extremely memory-constrained batteryless platforms; and (2) the
first early exit mechanism that uses a single exit branch for all exit points
to terminate inference at any time, making models energy-adaptive with minimal
memory overhead. Our experiments showed that FreeML reduces the model sizes by
up to $95 \times$, supports adaptive inference with a $2.03-19.65 \times$ less
memory overhead, and provides significant time and energy benefits with only a
negligible accuracy drop compared to the state-of-the-art.",2024-05-16,"Pietro Farina, Subrata Biswas, Eren Yıldız, Khakim Akhunov, Saad Ahmed, Bashima Islam, Kasım Sinan Yıldırım",http://arxiv.org/pdf/2405.10426v1,cs.CL
AmazUtah_NLP at SemEval-2024 Task 9: A MultiChoice Question Answering System for Commonsense Defying Reasoning,"The SemEval 2024 BRAINTEASER task represents a pioneering venture in Natural
Language Processing (NLP) by focusing on lateral thinking, a dimension of
cognitive reasoning that is often overlooked in traditional linguistic
analyses. This challenge comprises of Sentence Puzzle and Word Puzzle subtasks
and aims to test language models' capacity for divergent thinking.
  In this paper, we present our approach to the BRAINTEASER task. We employ a
holistic strategy by leveraging cutting-edge pre-trained models in multiple
choice architecture, and diversify the training data with Sentence and Word
Puzzle datasets. To gain further improvement, we fine-tuned the model with
synthetic humor or jokes dataset and the RiddleSense dataset which helped
augmenting the model's lateral thinking abilities. Empirical results show that
our approach achieve 92.5% accuracy in Sentence Puzzle subtask and 80.2%
accuracy in Word Puzzle subtask.",2024-05-16,"Mina Ghashami, Soumya Smruti Mishra",http://arxiv.org/pdf/2405.10385v2,cs.CL
How Far Are We From AGI: Are LLMs All We Need?,"The evolution of artificial intelligence (AI) has profoundly impacted human
society, driving significant advancements in multiple sectors. AGI,
distinguished by its ability to execute diverse real-world tasks with
efficiency and effectiveness comparable to human intelligence, reflects a
paramount milestone in AI evolution. While existing studies have reviewed
specific advancements in AI and proposed potential paths to AGI, such as large
language models (LLMs), they fall short of providing a thorough exploration of
AGI's definitions, objectives, and developmental trajectories. Unlike previous
survey papers, this work goes beyond summarizing LLMs by addressing key
questions about our progress toward AGI and outlining the strategies essential
for its realization through comprehensive analysis, in-depth discussions, and
novel insights. We start by articulating the requisite capability frameworks
for AGI, integrating the internal, interface, and system dimensions. As the
realization of AGI requires more advanced capabilities and adherence to
stringent constraints, we further discuss necessary AGI alignment technologies
to harmonize these factors. Notably, we emphasize the importance of approaching
AGI responsibly by first defining the key levels of AGI progression, followed
by the evaluation framework that situates the status quo, and finally giving
our roadmap of how to reach the pinnacle of AGI. Moreover, to give tangible
insights into the ubiquitous impact of the integration of AI, we outline
existing challenges and potential pathways toward AGI in multiple domains. In
sum, serving as a pioneering exploration into the current state and future
trajectory of AGI, this paper aims to foster a collective comprehension and
catalyze broader public discussions among researchers and practitioners on AGI.",2024-05-16,"Tao Feng, Chuanyang Jin, Jingyu Liu, Kunlun Zhu, Haoqin Tu, Zirui Cheng, Guanyu Lin, Jiaxuan You",http://arxiv.org/pdf/2405.10313v2,cs.CL
Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning,"Large vision-language models (VLMs) fine-tuned on specialized visual
instruction-following data have exhibited impressive language reasoning
capabilities across various scenarios. However, this fine-tuning paradigm may
not be able to efficiently learn optimal decision-making agents in multi-step
goal-directed tasks from interactive environments. To address this challenge,
we propose an algorithmic framework that fine-tunes VLMs with reinforcement
learning (RL). Specifically, our framework provides a task description and then
prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM
to efficiently explore intermediate reasoning steps that lead to the final
text-based action. Next, the open-ended text output is parsed into an
executable action to interact with the environment to obtain goal-directed task
rewards. Finally, our framework uses these task rewards to fine-tune the entire
VLM with RL. Empirically, we demonstrate that our proposed framework enhances
the decision-making capabilities of VLM agents across various tasks, enabling
7b models to outperform commercial models such as GPT4-V or Gemini.
Furthermore, we find that CoT reasoning is a crucial component for performance
improvement, as removing the CoT reasoning results in a significant decrease in
the overall performance of our method.",2024-05-16,"Yuexiang Zhai, Hao Bai, Zipeng Lin, Jiayi Pan, Shengbang Tong, Yifei Zhou, Alane Suhr, Saining Xie, Yann LeCun, Yi Ma, Sergey Levine",http://arxiv.org/pdf/2405.10292v3,cs.CL
Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction,"Facts extraction is pivotal for constructing knowledge graphs. Recently, the
increasing demand for temporal facts in downstream tasks has led to the
emergence of the task of temporal fact extraction. In this paper, we
specifically address the extraction of temporal facts from natural language
text. Previous studies fail to handle the challenge of establishing
time-to-fact correspondences in complex sentences. To overcome this hurdle, we
propose a timeline-based sentence decomposition strategy using large language
models (LLMs) with in-context learning, ensuring a fine-grained understanding
of the timeline associated with various facts. In addition, we evaluate the
performance of LLMs for direct temporal fact extraction and get unsatisfactory
results. To this end, we introduce TSDRE, a method that incorporates the
decomposition capabilities of LLMs into the traditional fine-tuning of smaller
pre-trained language models (PLMs). To support the evaluation, we construct
ComplexTRED, a complex temporal fact extraction dataset. Our experiments show
that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and
ComplexTRED datasets.",2024-05-16,"Jianhao Chen, Haoyuan Ouyang, Junyang Ren, Wentao Ding, Wei Hu, Yuzhong Qu",http://arxiv.org/pdf/2405.10288v3,cs.CL
Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers,"Numerous recent works aim to enhance the efficacy of Large Language Models
(LLMs) through strategic prompting. In particular, the Optimization by
PROmpting (OPRO) approach provides state-of-the-art performance by leveraging
LLMs as optimizers where the optimization task is to find instructions that
maximize the task accuracy. In this paper, we revisit OPRO for automated
prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral
7B. Our investigation reveals that OPRO shows limited effectiveness in
small-scale LLMs, with limited inference capabilities constraining optimization
ability. We suggest future automatic prompting engineering to consider both
model capabilities and computational costs. Additionally, for small-scale LLMs,
we recommend direct instructions that clearly outline objectives and
methodologies as robust prompt baselines, ensuring efficient and effective
prompt engineering in ongoing research.",2024-05-16,"Tuo Zhang, Jinyue Yuan, Salman Avestimehr",http://arxiv.org/pdf/2405.10276v2,cs.CL
A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision,"In this work, our goals are two fold: large-vocabulary continuous sign
language recognition (CSLR), and sign language retrieval. To this end, we
introduce a multi-task Transformer model, CSLR2, that is able to ingest a
signing sequence and output in a joint embedding space between signed language
and spoken language text. To enable CSLR evaluation in the large-vocabulary
setting, we introduce new dataset annotations that have been manually
collected. These provide continuous sign-level annotations for six hours of
test videos, and will be made publicly available. We demonstrate that by a
careful choice of loss functions, training the model for both the CSLR and
retrieval tasks is mutually beneficial in terms of performance -- retrieval
improves CSLR performance by providing context, while CSLR improves retrieval
with more fine-grained supervision. We further show the benefits of leveraging
weak and noisy supervision from large-vocabulary datasets such as BOBSL, namely
sign-level pseudo-labels, and English subtitles. Our model significantly
outperforms the previous state of the art on both tasks.",2024-05-16,"Charles Raude, K R Prajwal, Liliane Momeni, Hannah Bull, Samuel Albanie, Andrew Zisserman, Gül Varol",http://arxiv.org/pdf/2405.10266v1,cs.CL
Keep It Private: Unsupervised Privatization of Online Text,"Authorship obfuscation techniques hold the promise of helping people protect
their privacy in online communications by automatically rewriting text to hide
the identity of the original author. However, obfuscation has been evaluated in
narrow settings in the NLP literature and has primarily been addressed with
superficial edit operations that can lead to unnatural outputs. In this work,
we introduce an automatic text privatization framework that fine-tunes a large
language model via reinforcement learning to produce rewrites that balance
soundness, sense, and privacy. We evaluate it extensively on a large-scale test
set of English Reddit posts by 68k authors composed of short-medium length
texts. We study how the performance changes among evaluative conditions
including authorial profile length and authorship detection strategy. Our
method maintains high text quality according to both automated metrics and
human evaluation, and successfully evades several automated authorship attacks.",2024-05-16,"Calvin Bao, Marine Carpuat",http://arxiv.org/pdf/2405.10260v1,cs.CL
A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks,"Recent efforts have evaluated large language models (LLMs) in areas such as
commonsense reasoning, mathematical reasoning, and code generation. However, to
the best of our knowledge, no work has specifically investigated the
performance of LLMs in natural language generation (NLG) tasks, a pivotal
criterion for determining model excellence. Thus, this paper conducts a
comprehensive evaluation of well-known and high-performing LLMs, namely
ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models,
in the context of NLG tasks. We select English and Chinese datasets
encompassing Dialogue Generation and Text Summarization. Moreover, we propose a
common evaluation setting that incorporates input templates and post-processing
strategies. Our study reports both automatic results, accompanied by a detailed
analysis.",2024-05-16,"Xuanfan Ni, Piji Li",http://arxiv.org/pdf/2405.10251v1,cs.CL
Words as Trigger Points in Social Media Discussions,"Trigger points, introduced by Mau et al . [30], are rooted in theories of
affective political identity and relate to deeply lying beliefs about moral
expectations and social dispositions. Examining trigger points in online
discussions helps understand why and when social media users engage in
disagreements or affective political deliberations. This opens the door to
modelling social media user engagement more effectively and studying the
conditions and causal mechanisms that lead to adverse reactions, hate speech,
and abusive language in online debates.",2024-05-16,"Dimosthenis Antypas, Christian Arnold, Jose Camacho-Collados, Nedjma Ousidhoum, Carla Perez Almendros",http://arxiv.org/pdf/2405.10213v2,cs.CL
CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations,"In this paper, we introduce a novel psychological benchmark, CPsyExam,
constructed from questions sourced from Chinese language examinations. CPsyExam
is designed to prioritize psychological knowledge and case analysis separately,
recognizing the significance of applying psychological knowledge to real-world
scenarios. From the pool of 22k questions, we utilize 4k to create the
benchmark that offers balanced coverage of subjects and incorporates a diverse
range of case analysis techniques.Furthermore, we evaluate a range of existing
large language models~(LLMs), spanning from open-sourced to API-based models.
Our experiments and analysis demonstrate that CPsyExam serves as an effective
benchmark for enhancing the understanding of psychology within LLMs and enables
the comparison of LLMs across various granularities.",2024-05-16,"Jiahao Zhao, Jingwei Zhu, Minghuan Tan, Min Yang, Renhao Li, Di Yang, Chenhao Zhang, Guancheng Ye, Chengming Li, Xiping Hu, Derek F. Wong",http://arxiv.org/pdf/2405.10212v3,cs.CL
Building a Luganda Text-to-Speech Model From Crowdsourced Data,"Text-to-speech (TTS) development for African languages such as Luganda is
still limited, primarily due to the scarcity of high-quality, single-speaker
recordings essential for training TTS models. Prior work has focused on
utilizing the Luganda Common Voice recordings of multiple speakers aged between
20-49. Although the generated speech is intelligible, it is still of lower
quality than the model trained on studio-grade recordings. This is due to the
insufficient data preprocessing methods applied to improve the quality of the
Common Voice recordings. Furthermore, speech convergence is more difficult to
achieve due to varying intonations, as well as background noise. In this paper,
we show that the quality of Luganda TTS from Common Voice can improve by
training on multiple speakers of close intonation in addition to further
preprocessing of the training data. Specifically, we selected six female
speakers with close intonation determined by subjectively listening and
comparing their voice recordings. In addition to trimming out silent portions
from the beginning and end of the recordings, we applied a pre-trained speech
enhancement model to reduce background noise and enhance audio quality. We also
utilized a pre-trained, non-intrusive, self-supervised Mean Opinion Score (MOS)
estimation model to filter recordings with an estimated MOS over 3.5,
indicating high perceived quality. Subjective MOS evaluations from nine native
Luganda speakers demonstrate that our TTS model achieves a significantly better
MOS of 3.55 compared to the reported 2.5 MOS of the existing model. Moreover,
for a fair comparison, our model trained on six speakers outperforms models
trained on a single-speaker (3.13 MOS) or two speakers (3.22 MOS). This
showcases the effectiveness of compensating for the lack of data from one
speaker with data from multiple speakers of close intonation to improve TTS
quality.",2024-05-16,"Sulaiman Kagumire, Andrew Katumba, Joyce Nakatumba-Nabende, John Quinn",http://arxiv.org/pdf/2405.10211v1,cs.CL
Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level,"Scientific document summarization has been a challenging task due to the long
structure of the input text. The long input hinders the simultaneous effective
modeling of both global high-order relations between sentences and local
intra-sentence relations which is the most critical step in extractive
summarization. However, existing methods mostly focus on one type of relation,
neglecting the simultaneous effective modeling of both relations, which can
lead to insufficient learning of semantic representations. In this paper, we
propose HAESum, a novel approach utilizing graph neural networks to locally and
globally model documents based on their hierarchical discourse structure.
First, intra-sentence relations are learned using a local heterogeneous graph.
Subsequently, a novel hypergraph self-attention layer is introduced to further
enhance the characterization of high-order inter-sentence relations. We
validate our approach on two benchmark datasets, and the experimental results
demonstrate the effectiveness of HAESum and the importance of considering
hierarchical structures in modeling long scientific documents. Our code will be
available at \url{https://github.com/MoLICHENXI/HAESum}",2024-05-16,"Chenlong Zhao, Xiwen Zhou, Xiaopeng Xie, Yong Zhang",http://arxiv.org/pdf/2405.10202v1,cs.CL
LFED: A Literary Fiction Evaluation Dataset for Large Language Models,"The rapid evolution of large language models (LLMs) has ushered in the need
for comprehensive assessments of their performance across various dimensions.
In this paper, we propose LFED, a Literary Fiction Evaluation Dataset, which
aims to evaluate the capability of LLMs on the long fiction comprehension and
reasoning. We collect 95 literary fictions that are either originally written
in Chinese or translated into Chinese, covering a wide range of topics across
several centuries. We define a question taxonomy with 8 question categories to
guide the creation of 1,304 questions. Additionally, we conduct an in-depth
analysis to ascertain how specific attributes of literary fictions (e.g., novel
types, character numbers, the year of publication) impact LLM performance in
evaluations. Through a series of experiments with various state-of-the-art
LLMs, we demonstrate that these models face considerable challenges in
effectively addressing questions related to literary fictions, with ChatGPT
reaching only 57.08% under the zero-shot setting. The dataset will be publicly
available at https://github.com/tjunlp-lab/LFED.git",2024-05-16,"Linhao Yu, Qun Liu, Deyi Xiong",http://arxiv.org/pdf/2405.10166v1,cs.CL
Speaker Verification in Agent-Generated Conversations,"The recent success of large language models (LLMs) has attracted widespread
interest to develop role-playing conversational agents personalized to the
characteristics and styles of different speakers to enhance their abilities to
perform both general and special purpose dialogue tasks. However, the ability
to personalize the generated utterances to speakers, whether conducted by human
or LLM, has not been well studied. To bridge this gap, our study introduces a
novel evaluation challenge: speaker verification in agent-generated
conversations, which aimed to verify whether two sets of utterances originate
from the same speaker. To this end, we assemble a large dataset collection
encompassing thousands of speakers and their utterances. We also develop and
evaluate speaker verification models under experiment setups. We further
utilize the speaker verification models to evaluate the personalization
abilities of LLM-based role-playing models. Comprehensive experiments suggest
that the current role-playing models fail in accurately mimicking speakers,
primarily due to their inherent linguistic characteristics.",2024-05-16,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Ee-Peng Lim",http://arxiv.org/pdf/2405.10150v2,cs.CL
PL-MTEB: Polish Massive Text Embedding Benchmark,"In this paper, we introduce the Polish Massive Text Embedding Benchmark
(PL-MTEB), a comprehensive benchmark for text embeddings in Polish. The PL-MTEB
consists of 28 diverse NLP tasks from 5 task types. We adapted the tasks based
on previously used datasets by the Polish NLP community. In addition, we
created a new PLSC (Polish Library of Science Corpus) dataset consisting of
titles and abstracts of scientific publications in Polish, which was used as
the basis for two novel clustering tasks. We evaluated 15 publicly available
models for text embedding, including Polish and multilingual ones, and
collected detailed results for individual tasks and aggregated results for each
task type and the entire benchmark. PL-MTEB comes with open-source code at
https://github.com/rafalposwiata/pl-mteb.",2024-05-16,"Rafał Poświata, Sławomir Dadas, Michał Perełkiewicz",http://arxiv.org/pdf/2405.10138v1,cs.CL
Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language,"Over the past century, the Turkish language has undergone substantial
changes, primarily driven by governmental interventions. In this work, our goal
is to investigate the evolution of the Turkish language since the establishment
of T\""urkiye in 1923. Thus, we first introduce Turkronicles which is a
diachronic corpus for Turkish derived from the Official Gazette of T\""urkiye.
Turkronicles contains 45,375 documents, detailing governmental actions, making
it a pivotal resource for analyzing the linguistic evolution influenced by the
state policies. In addition, we expand an existing diachronic Turkish corpus
which consists of the records of the Grand National Assembly of T\""urkiye by
covering additional years. Next, combining these two diachronic corpora, we
seek answers for two main research questions: How have the Turkish vocabulary
and the writing conventions changed since the 1920s? Our analysis reveals that
the vocabularies of two different time periods diverge more as the time between
them increases, and newly coined Turkish words take the place of their old
counterparts. We also observe changes in writing conventions. In particular,
the use of circumflex noticeably decreases and words ending with the letters
""-b"" and ""-d"" are successively replaced with ""-p"" and ""-t"" letters,
respectively. Overall, this study quantitatively highlights the dramatic
changes in Turkish from various aspects of the language in a diachronic
perspective.",2024-05-16,"Togay Yazar, Mucahid Kutlu, İsa Kerem Bayırlı",http://arxiv.org/pdf/2405.10133v1,cs.CL
StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis,"The emergence of large language models (LLMs) capable of generating realistic
texts and images has sparked ethical concerns across various sectors. In
response, researchers in academia and industry are actively exploring methods
to distinguish AI-generated content from human-authored material. However, a
crucial question remains: What are the unique characteristics of AI-generated
text? Addressing this gap, this study proposes StyloAI, a data-driven model
that uses 31 stylometric features to identify AI-generated texts by applying a
Random Forest classifier on two multi-domain datasets. StyloAI achieves
accuracy rates of 81% and 98% on the test set of the AuTextification dataset
and the Education dataset, respectively. This approach surpasses the
performance of existing state-of-the-art models and provides valuable insights
into the differences between AI-generated and human-authored texts.",2024-05-16,Chidimma Opara,http://arxiv.org/pdf/2405.10129v1,cs.CL
Red Teaming Language Models for Processing Contradictory Dialogues,"Most language models currently available are prone to self-contradiction
during dialogues. To mitigate this issue, this study explores a novel
contradictory dialogue processing task that aims to detect and modify
contradictory statements in a conversation. This task is inspired by research
on context faithfulness and dialogue comprehension, which have demonstrated
that the detection and understanding of contradictions often necessitate
detailed explanations. We develop a dataset comprising contradictory dialogues,
in which one side of the conversation contradicts itself. Each dialogue is
accompanied by an explanatory label that highlights the location and details of
the contradiction. With this dataset, we present a Red Teaming framework for
contradictory dialogue processing. The framework detects and attempts to
explain the dialogue, then modifies the existing contradictory content using
the explanation. Our experiments demonstrate that the framework improves the
ability to detect contradictory dialogues and provides valid explanations.
Additionally, it showcases distinct capabilities for modifying such dialogues.
Our study highlights the importance of the logical inconsistency problem in
conversational AI.",2024-05-16,"Xiaofei Wen, Bangzheng Li, Tenghao Huang, Muhao Chen",http://arxiv.org/pdf/2405.10128v3,cs.CL
Distilling Implicit Multimodal Knowledge into Large Language Models for Zero-Resource Dialogue Generation,"Integrating multimodal knowledge into large language models (LLMs) represents
a significant advancement in dialogue generation capabilities. However, the
effective incorporation of such knowledge in zero-resource scenarios remains a
substantial challenge due to the scarcity of diverse, high-quality dialogue
datasets. To address this, we propose the Visual Implicit Knowledge
Distillation Framework (VIKDF), an innovative approach aimed at enhancing LLMs
for enriched dialogue generation in zero-resource contexts by leveraging
implicit multimodal knowledge. VIKDF comprises two main stages: knowledge
distillation, using an Implicit Query Transformer to extract and encode visual
implicit knowledge from image-text pairs into knowledge vectors; and knowledge
integration, employing a novel Bidirectional Variational Information Fusion
technique to seamlessly integrate these distilled vectors into LLMs. This
enables the LLMs to generate dialogues that are not only coherent and engaging
but also exhibit a deep understanding of the context through implicit
multimodal cues, effectively overcoming the limitations of zero-resource
scenarios. Our extensive experimentation across two dialogue datasets shows
that VIKDF outperforms existing state-of-the-art models in generating
high-quality dialogues. The code is available at
https://github.com/zhangbo-nlp/VIKDF.",2024-05-16,"Bo Zhang, Hui Ma, Jian Ding, Jian Wang, Bo Xu, Hongfei Lin",http://arxiv.org/pdf/2405.10121v2,cs.CL
Autonomous Workflow for Multimodal Fine-Grained Training Assistants Towards Mixed Reality,"Autonomous artificial intelligence (AI) agents have emerged as promising
protocols for automatically understanding the language-based environment,
particularly with the exponential development of large language models (LLMs).
However, a fine-grained, comprehensive understanding of multimodal environments
remains under-explored. This work designs an autonomous workflow tailored for
integrating AI agents seamlessly into extended reality (XR) applications for
fine-grained training. We present a demonstration of a multimodal fine-grained
training assistant for LEGO brick assembly in a pilot XR environment.
Specifically, we design a cerebral language agent that integrates LLM with
memory, planning, and interaction with XR tools and a vision-language agent,
enabling agents to decide their actions based on past experiences. Furthermore,
we introduce LEGO-MRTA, a multimodal fine-grained assembly dialogue dataset
synthesized automatically in the workflow served by a commercial LLM. This
dataset comprises multimodal instruction manuals, conversations, XR responses,
and vision question answering. Last, we present several prevailing
open-resource LLMs as benchmarks, assessing their performance with and without
fine-tuning on the proposed dataset. We anticipate that the broader impact of
this workflow will advance the development of smarter assistants for seamless
user interaction in XR environments, fostering research in both AI and HCI
communities.",2024-05-16,"Jiahuan Pei, Irene Viola, Haochen Huang, Junxiao Wang, Moonisa Ahsan, Fanghua Ye, Jiang Yiming, Yao Sai, Di Wang, Zhumin Chen, Pengjie Ren, Pablo Cesar",http://arxiv.org/pdf/2405.13034v2,cs.CL
KnowledgeHub: An end-to-end Tool for Assisted Scientific Discovery,"This paper describes the KnowledgeHub tool, a scientific literature
Information Extraction (IE) and Question Answering (QA) pipeline. This is
achieved by supporting the ingestion of PDF documents that are converted to
text and structured representations. An ontology can then be constructed where
a user defines the types of entities and relationships they want to capture. A
browser-based annotation tool enables annotating the contents of the PDF
documents according to the ontology. Named Entity Recognition (NER) and
Relation Classification (RC) models can be trained on the resulting annotations
and can be used to annotate the unannotated portion of the documents. A
knowledge graph is constructed from these entity and relation triples which can
be queried to obtain insights from the data. Furthermore, we integrate a suite
of Large Language Models (LLMs) that can be used for QA and summarisation that
is grounded in the included documents via a retrieval component. KnowledgeHub
is a unique tool that supports annotation, IE and QA, which gives the user full
insight into the knowledge discovery pipeline.",2024-05-16,"Shinnosuke Tanaka, James Barry, Vishnudev Kuruvanthodi, Movina Moses, Maxwell J. Giammona, Nathan Herr, Mohab Elkaref, Geeth De Mel",http://arxiv.org/pdf/2406.00008v2,cs.CL
MarkLLM: An Open-Source Toolkit for LLM Watermarking,"LLM watermarking, which embeds imperceptible yet algorithmically detectable
signals in model outputs to identify LLM-generated text, has become crucial in
mitigating the potential misuse of large language models. However, the
abundance of LLM watermarking algorithms, their intricate mechanisms, and the
complex evaluation procedures and perspectives pose challenges for researchers
and the community to easily experiment with, understand, and assess the latest
advancements. To address these issues, we introduce MarkLLM, an open-source
toolkit for LLM watermarking. MarkLLM offers a unified and extensible framework
for implementing LLM watermarking algorithms, while providing user-friendly
interfaces to ensure ease of access. Furthermore, it enhances understanding by
supporting automatic visualization of the underlying mechanisms of these
algorithms. For evaluation, MarkLLM offers a comprehensive suite of 12 tools
spanning three perspectives, along with two types of automated evaluation
pipelines. Through MarkLLM, we aim to support researchers while improving the
comprehension and involvement of the general public in LLM watermarking
technology, fostering consensus and driving further advancements in research
and application. Our code is available at https://github.com/THU-BPM/MarkLLM.",2024-05-16,"Leyi Pan, Aiwei Liu, Zhiwei He, Zitian Gao, Xuandong Zhao, Yijian Lu, Binglin Zhou, Shuliang Liu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu",http://arxiv.org/pdf/2405.10051v6,cs.CL
PyTorch-IE: Fast and Reproducible Prototyping for Information Extraction,"The objective of Information Extraction (IE) is to derive structured
representations from unstructured or semi-structured documents. However,
developing IE models is complex due to the need of integrating several
subtasks. Additionally, representation of data among varied tasks and
transforming datasets into task-specific model inputs presents further
challenges. To streamline this undertaking for researchers, we introduce
PyTorch-IE, a deep-learning-based framework uniquely designed to enable swift,
reproducible, and reusable implementations of IE models. PyTorch-IE offers a
flexible data model capable of creating complex data structures by integrating
interdependent layers of annotations derived from various data types, like
plain text or semi-structured text, and even images. We propose task modules to
decouple the concerns of data representation and model-specific
representations, thereby fostering greater flexibility and reusability of code.
PyTorch-IE also extends support for widely used libraries such as
PyTorch-Lightning for training, HuggingFace datasets for dataset reading, and
Hydra for experiment configuration. Supplementary libraries and GitHub
templates for the easy setup of new projects are also provided. By ensuring
functionality and versatility, PyTorch-IE provides vital support to the
research community engaged in Information Extraction.",2024-05-16,"Arne Binder, Leonhard Hennig, Christoph Alt",http://arxiv.org/pdf/2406.00007v1,cs.CL
SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation,"It is often desirable to distill the capabilities of large language models
(LLMs) into smaller student models due to compute and memory constraints. One
way to do this for classification tasks is via dataset synthesis, which can be
accomplished by generating examples of each label from the LLM. Prior
approaches to synthesis use few-shot prompting, which relies on the LLM's
parametric knowledge to generate usable examples. However, this leads to issues
of repetition, bias towards popular entities, and stylistic differences from
human text. In this work, we propose Synthesize by Retrieval and Refinement
(SynthesizRR), which uses retrieval augmentation to introduce variety into the
dataset synthesis process: as retrieved passages vary, the LLM is seeded with
different content to generate its examples. We empirically study the synthesis
of six datasets, covering topic classification, sentiment analysis, tone
detection, and humor, requiring complex synthesis strategies. We find that
SynthesizRR greatly improves lexical and semantic diversity, similarity to
human-written text, and distillation performance, when compared to 32-shot
prompting and four prior approaches. We release our code to perform all steps
at https://github.com/amazon-science/synthesizrr",2024-05-16,"Abhishek Divekar, Greg Durrett",http://arxiv.org/pdf/2405.10040v3,cs.CL
Faithful Attention Explainer: Verbalizing Decisions Based on Discriminative Features,"In recent years, model explanation methods have been designed to interpret
model decisions faithfully and intuitively so that users can easily understand
them. In this paper, we propose a framework, Faithful Attention Explainer
(FAE), capable of generating faithful textual explanations regarding the
attended-to features. Towards this goal, we deploy an attention module that
takes the visual feature maps from the classifier for sentence generation.
Furthermore, our method successfully learns the association between features
and words, which allows a novel attention enforcement module for attention
explanation. Our model achieves promising performance in caption quality
metrics and a faithful decision-relevance metric on two datasets (CUB and
ACT-X). In addition, we show that FAE can interpret gaze-based human attention,
as human gaze indicates the discriminative features that humans use for
decision-making, demonstrating the potential of deploying human gaze for
advanced human-AI interaction.",2024-05-16,"Yao Rong, David Scheerer, Enkelejda Kasneci",http://arxiv.org/pdf/2405.13032v2,cs.CL
Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models,"Recent advances in large language models (LLMs) have promoted generative
error correction (GER) for automatic speech recognition (ASR), which aims to
predict the ground-truth transcription from the decoded N-best hypotheses.
Thanks to the strong language generation ability of LLMs and rich information
in the N-best list, GER shows great effectiveness in enhancing ASR results.
However, it still suffers from two limitations: 1) LLMs are unaware of the
source speech during GER, which may lead to results that are grammatically
correct but violate the source speech content, 2) N-best hypotheses usually
only vary in a few tokens, making it redundant to send all of them for GER,
which could confuse LLM about which tokens to focus on and thus lead to
increased miscorrection. In this paper, we propose ClozeGER, a new paradigm for
ASR generative error correction. First, we introduce a multimodal LLM (i.e.,
SpeechGPT) to receive source speech as extra input to improve the fidelity of
correction output. Then, we reformat GER as a cloze test with logits
calibration to remove the input information redundancy and simplify GER with
clear instructions. Experiments show that ClozeGER achieves a new breakthrough
over vanilla GER on 9 popular ASR datasets.",2024-05-16,"Yuchen Hu, Chen Chen, Chengwei Qin, Qiushi Zhu, Eng Siong Chng, Ruizhe Li",http://arxiv.org/pdf/2405.10025v1,cs.CL
Natural Language Can Help Bridge the Sim2Real Gap,"The main challenge in learning image-conditioned robotic policies is
acquiring a visual representation conducive to low-level control. Due to the
high dimensionality of the image space, learning a good visual representation
requires a considerable amount of visual data. However, when learning in the
real world, data is expensive. Sim2Real is a promising paradigm for overcoming
data scarcity in the real-world target domain by using a simulator to collect
large amounts of cheap data closely related to the target task. However, it is
difficult to transfer an image-conditioned policy from sim to real when the
domains are very visually dissimilar. To bridge the sim2real visual gap, we
propose using natural language descriptions of images as a unifying signal
across domains that captures the underlying task-relevant semantics. Our key
insight is that if two image observations from different domains are labeled
with similar language, the policy should predict similar action distributions
for both images. We demonstrate that training the image encoder to predict the
language description or the distance between descriptions of a sim or real
image serves as a useful, data-efficient pretraining step that helps learn a
domain-invariant image representation. We can then use this image encoder as
the backbone of an IL policy trained simultaneously on a large amount of
simulated and a handful of real demonstrations. Our approach outperforms widely
used prior sim2real methods and strong vision-language pretraining baselines
like CLIP and R3M by 25 to 40%. See additional videos and materials at
https://robin-lab.cs.utexas.edu/lang4sim2real/.",2024-05-16,"Albert Yu, Adeline Foote, Raymond Mooney, Roberto Martín-Martín",http://arxiv.org/pdf/2405.10020v2,cs.CL
Zero-Shot Hierarchical Classification on the Common Procurement Vocabulary Taxonomy,"Classifying public tenders is a useful task for both companies that are
invited to participate and for inspecting fraudulent activities. To facilitate
the task for both participants and public administrations, the European Union
presented a common taxonomy (Common Procurement Vocabulary, CPV) which is
mandatory for tenders of certain importance; however, the contracts in which a
CPV label is mandatory are the minority compared to all the Public
Administrations activities. Classifying over a real-world taxonomy introduces
some difficulties that can not be ignored. First of all, some fine-grained
classes have an insufficient (if any) number of observations in the training
set, while other classes are far more frequent (even thousands of times) than
the average. To overcome those difficulties, we present a zero-shot approach,
based on a pre-trained language model that relies only on label description and
respects the label taxonomy. To train our proposed model, we used industrial
data, which comes from contrattipubblici.org, a service by SpazioDati s.r.l.
that collects public contracts stipulated in Italy in the last 25 years.
Results show that the proposed model achieves better performance in classifying
low-frequent classes compared to three different baselines, and is also able to
predict never-seen classes.",2024-05-16,"Federico Moiraghi, Matteo Palmonari, Davide Allavena, Federico Morando",http://arxiv.org/pdf/2405.09983v2,cs.CL
FinTextQA: A Dataset for Long-form Financial Question Answering,"Accurate evaluation of financial question answering (QA) systems necessitates
a comprehensive dataset encompassing diverse question types and contexts.
However, current financial QA datasets lack scope diversity and question
complexity. This work introduces FinTextQA, a novel dataset for long-form
question answering (LFQA) in finance. FinTextQA comprises 1,262 high-quality,
source-attributed QA pairs extracted and selected from finance textbooks and
government agency websites.Moreover, we developed a Retrieval-Augmented
Generation (RAG)-based LFQA system, comprising an embedder, retriever,
reranker, and generator. A multi-faceted evaluation approach, including human
ranking, automatic metrics, and GPT-4 scoring, was employed to benchmark the
performance of different LFQA system configurations under heightened noisy
conditions. The results indicate that: (1) Among all compared generators,
Baichuan2-7B competes closely with GPT-3.5-turbo in accuracy score; (2) The
most effective system configuration on our dataset involved setting the
embedder, retriever, reranker, and generator as Ada2, Automated Merged
Retrieval, Bge-Reranker-Base, and Baichuan2-7B, respectively; (3) models are
less susceptible to noise after the length of contexts reaching a specific
threshold.",2024-05-16,"Jian Chen, Peilin Zhou, Yining Hua, Yingxin Loh, Kehui Chen, Ziyuan Li, Bing Zhu, Junwei Liang",http://arxiv.org/pdf/2405.09980v1,cs.CL
A Robust Autoencoder Ensemble-Based Approach for Anomaly Detection in Text,"Anomaly detection (AD) is a fast growing and popular domain among established
applications like vision and time series. We observe a rich literature for
these applications, but anomaly detection in text is only starting to blossom.
Recently, self-supervised methods with self-attention mechanism have been the
most popular choice. While recent works have proposed a working ground for
building and benchmarking state of the art approaches, we propose two principal
contributions in this paper: contextual anomaly contamination and a novel
ensemble-based approach. Our method, Textual Anomaly Contamination (TAC),
allows to contaminate inlier classes with either independent or contextual
anomalies. In the literature, it appears that this distinction is not
performed. For finding contextual anomalies, we propose RoSAE, a Robust
Subspace Local Recovery Autoencoder Ensemble. All autoencoders of the ensemble
present a different latent representation through local manifold learning.
Benchmark shows that our approach outperforms recent works on both independent
and contextual anomalies, while being more robust. We also provide 8 dataset
comparison instead of only relying to Reuters and 20 Newsgroups corpora.",2024-05-16,"Jeremie Pantin, Christophe Marsala",http://arxiv.org/pdf/2405.13031v2,cs.CL
Luganda Speech Intent Recognition for IoT Applications,"The advent of Internet of Things (IoT) technology has generated massive
interest in voice-controlled smart homes. While many voice-controlled smart
home systems are designed to understand and support widely spoken languages
like English, speakers of low-resource languages like Luganda may need more
support. This research project aimed to develop a Luganda speech intent
classification system for IoT applications to integrate local languages into
smart home environments. The project uses hardware components such as Raspberry
Pi, Wio Terminal, and ESP32 nodes as microcontrollers. The Raspberry Pi
processes Luganda voice commands, the Wio Terminal is a display device, and the
ESP32 nodes control the IoT devices. The ultimate objective of this work was to
enable voice control using Luganda, which was accomplished through a natural
language processing (NLP) model deployed on the Raspberry Pi. The NLP model
utilized Mel Frequency Cepstral Coefficients (MFCCs) as acoustic features and a
Convolutional Neural Network (Conv2D) architecture for speech intent
classification. A dataset of Luganda voice commands was curated for this
purpose and this has been made open-source. This work addresses the
localization challenges and linguistic diversity in IoT applications by
incorporating Luganda voice commands, enabling users to interact with smart
home devices without English proficiency, especially in regions where local
languages are predominant.",2024-05-16,"Andrew Katumba, Sudi Murindanyi, John Trevor Kasule, Elvis Mugume",http://arxiv.org/pdf/2405.19343v1,cs.CL
Mitigating Text Toxicity with Counterfactual Generation,"Toxicity mitigation consists in rephrasing text in order to remove offensive
or harmful meaning. Neural natural language processing (NLP) models have been
widely used to target and mitigate textual toxicity. However, existing methods
fail to detoxify text while preserving the initial non-toxic meaning at the
same time. In this work, we propose to apply counterfactual generation methods
from the eXplainable AI (XAI) field to target and mitigate textual toxicity. In
particular, we perform text detoxification by applying local feature importance
and counterfactual generation methods to a toxicity classifier distinguishing
between toxic and non-toxic texts. We carry out text detoxification through
counterfactual generation on three datasets and compare our approach to three
competitors. Automatic and human evaluations show that recently developed NLP
counterfactual generators can mitigate toxicity accurately while better
preserving the meaning of the initial text as compared to classical
detoxification methods. Finally, we take a step back from using automated
detoxification tools, and discuss how to manage the polysemous nature of
toxicity and the risk of malicious use of detoxification tools. This work is
the first to bridge the gap between counterfactual generation and text
detoxification and paves the way towards more practical application of XAI
methods.",2024-05-16,"Milan Bhan, Jean-Noel Vittaut, Nina Achache, Victor Legrand, Nicolas Chesneau, Annabelle Blangero, Juliette Murris, Marie-Jeanne Lesot",http://arxiv.org/pdf/2405.09948v2,cs.CL
SciQAG: A Framework for Auto-Generated Science Question Answering Dataset with Fine-grained Evaluation,"We introduce SciQAG, a novel framework for automatically generating
high-quality science question-answer pairs from a large corpus of scientific
literature based on large language models (LLMs). SciQAG consists of a QA
generator and a QA evaluator, which work together to extract diverse and
research-level questions and answers from scientific papers. Utilizing this
framework, we construct a large-scale, high-quality, open-ended science QA
dataset containing 188,042 QA pairs extracted from 22,743 scientific papers
across 24 scientific domains. We also introduce SciQAG-24D, a new benchmark
task designed to evaluate the science question-answering ability of LLMs.
Extensive experiments demonstrate that fine-tuning LLMs on the SciQAG dataset
significantly improves their performance on both open-ended question answering
and scientific tasks. To foster research and collaboration, we make the
datasets, models, and evaluation codes publicly available, contributing to the
advancement of science question answering and developing more interpretable and
reasoning-capable AI systems.",2024-05-16,"Yuwei Wan, Yixuan Liu, Aswathy Ajith, Clara Grazian, Bram Hoex, Wenjie Zhang, Chunyu Kit, Tong Xie, Ian Foster",http://arxiv.org/pdf/2405.09939v2,cs.CL
DEBATE: Devil's Advocate-Based Assessment and Text Evaluation,"As natural language generation (NLG) models have become prevalent,
systematically assessing the quality of machine-generated texts has become
increasingly important. Recent studies introduce LLM-based evaluators that
operate as reference-free metrics, demonstrating their capability to adeptly
handle novel tasks. However, these models generally rely on a single-agent
approach, which, we argue, introduces an inherent limit to their performance.
This is because there exist biases in LLM agent's responses, including
preferences for certain text structure or content. In this work, we propose
DEBATE, an NLG evaluation framework based on multi-agent scoring system
augmented with a concept of Devil's Advocate. Within the framework, one agent
is instructed to criticize other agents' arguments, potentially resolving the
bias in LLM agent's answers. DEBATE substantially outperforms the previous
state-of-the-art methods in two meta-evaluation benchmarks in NLG evaluation,
SummEval and TopicalChat. We also show that the extensiveness of debates among
agents and the persona of an agent can influence the performance of evaluators.",2024-05-16,"Alex Kim, Keonwoo Kim, Sangwon Yoon",http://arxiv.org/pdf/2405.09935v2,cs.CL
TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained Language Models for Transliterated Data,"Transliterating related languages that use different scripts into a common
script is effective for improving crosslingual transfer in downstream tasks.
However, this methodology often makes pretraining a model from scratch
unavoidable, as transliteration brings about new subwords not covered in
existing multilingual pretrained language models (mPLMs). This is undesirable
because it requires a large computation budget. A more promising way is to make
full use of available mPLMs. To this end, this paper proposes a simple but
effective framework: Transliterate-Merge-Initialize (TransMI). TransMI can
create strong baselines for data that is transliterated into a common script by
exploiting an existing mPLM and its tokenizer without any training. TransMI has
three stages: (a) transliterate the vocabulary of an mPLM into a common script;
(b) merge the new vocabulary with the original vocabulary; and (c) initialize
the embeddings of the new subwords. We apply TransMI to three strong recent
mPLMs. Our experiments demonstrate that TransMI not only preserves the mPLM's
ability to handle non-transliterated data, but also enables it to effectively
process transliterated data, thereby facilitating crosslingual transfer across
scripts. The results show consistent improvements of 3% to 34% for different
mPLMs and tasks. We make our code and models publicly available at
\url{https://github.com/cisnlp/TransMI}.",2024-05-16,"Yihong Liu, Chunlan Ma, Haotian Ye, Hinrich Schütze",http://arxiv.org/pdf/2405.09913v2,cs.CL
Crowdsourcing with Enhanced Data Quality Assurance: An Efficient Approach to Mitigate Resource Scarcity Challenges in Training Large Language Models for Healthcare,"Large Language Models (LLMs) have demonstrated immense potential in
artificial intelligence across various domains, including healthcare. However,
their efficacy is hindered by the need for high-quality labeled data, which is
often expensive and time-consuming to create, particularly in low-resource
domains like healthcare. To address these challenges, we propose a
crowdsourcing (CS) framework enriched with quality control measures at the
pre-, real-time-, and post-data gathering stages. Our study evaluated the
effectiveness of enhancing data quality through its impact on LLMs (Bio-BERT)
for predicting autism-related symptoms. The results show that real-time quality
control improves data quality by 19 percent compared to pre-quality control.
Fine-tuning Bio-BERT using crowdsourced data generally increased recall
compared to the Bio-BERT baseline but lowered precision. Our findings
highlighted the potential of crowdsourcing and quality control in
resource-constrained environments and offered insights into optimizing
healthcare LLMs for informed decision-making and improved patient care.",2024-05-16,"P. Barai, G. Leroy, P. Bisht, J. M. Rothman, S. Lee, J. Andrews, S. A. Rice, A. Ahmed",http://arxiv.org/pdf/2405.13030v1,cs.CL
"""Hunt Takes Hare"": Theming Games Through Game-Word Vector Translation","A game's theme is an important part of its design -- it conveys narrative
information, rhetorical messages, helps the player intuit strategies, aids in
tutorialisation and more. Thematic elements of games are notoriously difficult
for AI systems to understand and manipulate, however, and often rely on large
amounts of hand-written interpretations and knowledge. In this paper we present
a technique which connects game embeddings, a recent method for modelling game
dynamics from log data, and word embeddings, which models semantic information
about language. We explain two different approaches for using game embeddings
in this way, and show evidence that game embeddings enhance the linguistic
translations of game concepts from one theme to another, opening up exciting
new possibilities for reasoning about the thematic elements of games in the
future.",2024-05-16,"Rabii Younès, Cook Michael",http://arxiv.org/pdf/2405.09893v1,cs.CL
Learnable Privacy Neurons Localization in Language Models,"Concerns regarding Large Language Models (LLMs) to memorize and disclose
private information, particularly Personally Identifiable Information (PII),
become prominent within the community. Many efforts have been made to mitigate
the privacy risks. However, the mechanism through which LLMs memorize PII
remains poorly understood. To bridge this gap, we introduce a pioneering method
for pinpointing PII-sensitive neurons (privacy neurons) within LLMs. Our method
employs learnable binary weight masks to localize specific neurons that account
for the memorization of PII in LLMs through adversarial training. Our
investigations discover that PII is memorized by a small subset of neurons
across all layers, which shows the property of PII specificity. Furthermore, we
propose to validate the potential in PII risk mitigation by deactivating the
localized privacy neurons. Both quantitative and qualitative experiments
demonstrate the effectiveness of our neuron localization algorithm.",2024-05-16,"Ruizhe Chen, Tianxiang Hu, Yang Feng, Zuozhu Liu",http://arxiv.org/pdf/2405.10989v1,cs.CL
IGOT: Information Gain Optimized Tokenizer on Domain Adaptive Pretraining,"Pretrained Large Language Models (LLM) such as ChatGPT, Claude, etc. have
demonstrated strong capabilities in various fields of natural language
generation. However, there are still many problems when using LLM in
specialized domain-specific fields. When using generative AI to process
downstream tasks, a common approach is to add new knowledge (e.g., private
domain knowledge, cutting-edge information) to a pretrained model through
continued training or fine-tuning. However, whether there is a universal
paradigm for domain adaptation training is still an open question. In this
article, we proposed Information Gain Optimized Tokenizer (IGOT), which
analyzes the special token set of downstream tasks, constructs a new subset
using heuristic function $\phi$ with the special token and its information
gain, to build new domain-specific tokenizer, and continues pretraining on the
downstream task data. We explored the many positive effects of this method's
customized tokenizer on domain-adaptive pretraining and verified this method
can perform better than the ordinary method of just collecting data and
fine-tuning. Based on our experiment, the continued pretraining process of IGOT
with LLaMA-7B achieved 11.9\% token saving, 12.2\% training time saving, and
5.8\% maximum GPU VRAM usage saving, combined with the T5 model, we can even
reach a 31.5\% of training time saving, making porting general generative AI to
specific domains more effective than before. In domain-specific tasks,
supervised $IGOT_\tau$ shows great performance on reducing both the convergence
radius and convergence point during keep pretraining.",2024-05-16,"Dawei Feng, Yihai Zhang, Zhixuan Xu",http://arxiv.org/pdf/2405.09857v1,cs.CL
Striking a Balance between Classical and Deep Learning Approaches in Natural Language Processing Pedagogy,"While deep learning approaches represent the state-of-the-art of natural
language processing (NLP) today, classical algorithms and approaches still find
a place in NLP textbooks and courses of recent years. This paper discusses the
perspectives of conveners of two introductory NLP courses taught in Australia
and India, and examines how classical and deep learning approaches can be
balanced within the lecture plan and assessments of the courses. We also draw
parallels with the objects-first and objects-later debate in CS1 education. We
observe that teaching classical approaches adds value to student learning by
building an intuitive understanding of NLP problems, potential solutions, and
even deep learning models themselves. Despite classical approaches not being
state-of-the-art, the paper makes a case for their inclusion in NLP courses
today.",2024-05-16,"Aditya Joshi, Jake Renzella, Pushpak Bhattacharyya, Saurav Jha, Xiangyu Zhang",http://arxiv.org/pdf/2405.09854v2,cs.CL
Enhancing Semantics in Multimodal Chain of Thought via Soft Negative Sampling,"Chain of thought (CoT) has proven useful for problems requiring complex
reasoning. Many of these problems are both textual and multimodal. Given the
inputs in different modalities, a model generates a rationale and then uses it
to answer a question. Because of the hallucination issue, the generated soft
negative rationales with high textual quality but illogical semantics do not
always help improve answer accuracy. This study proposes a rationale generation
method using soft negative sampling (SNSE-CoT) to mitigate hallucinations in
multimodal CoT. Five methods were applied to generate soft negative samples
that shared highly similar text but had different semantics from the original.
Bidirectional margin loss (BML) was applied to introduce them into the
traditional contrastive learning framework that involves only positive and
negative samples. Extensive experiments on the ScienceQA dataset demonstrated
the effectiveness of the proposed method. Code and data are released at
https://github.com/zgMin/SNSE-CoT.",2024-05-16,"Guangmin Zheng, Jin Wang, Xiaobing Zhou, Xuejie Zhang",http://arxiv.org/pdf/2405.09848v1,cs.CL
DuetSim: Building User Simulator with Dual Large Language Models for Task-Oriented Dialogues,"User Simulators play a pivotal role in training and evaluating task-oriented
dialogue systems. Traditional user simulators typically rely on
human-engineered agendas, resulting in generated responses that often lack
diversity and spontaneity. Although large language models (LLMs) exhibit a
remarkable capacity for generating coherent and contextually appropriate
utterances, they may fall short when tasked with generating responses that
effectively guide users towards their goals, particularly in dialogues with
intricate constraints and requirements. This paper introduces DuetSim, a novel
framework designed to address the intricate demands of task-oriented dialogues
by leveraging LLMs. DuetSim stands apart from conventional approaches by
employing two LLMs in tandem: one dedicated to response generation and the
other focused on verification. This dual LLM approach empowers DuetSim to
produce responses that not only exhibit diversity but also demonstrate accuracy
and are preferred by human users. We validate the efficacy of our method
through extensive experiments conducted on the MultiWOZ dataset, highlighting
improvements in response quality and correctness, largely attributed to the
incorporation of the second LLM. Our code is accessible at:
https://github.com/suntea233/DuetSim.",2024-05-16,"Xiang Luo, Zhiwen Tang, Jin Wang, Xuejie Zhang",http://arxiv.org/pdf/2405.13028v1,cs.CL
Chameleon: Mixed-Modal Early-Fusion Foundation Models,"We present Chameleon, a family of early-fusion token-based mixed-modal models
capable of understanding and generating images and text in any arbitrary
sequence. We outline a stable training approach from inception, an alignment
recipe, and an architectural parameterization tailored for the early-fusion,
token-based, mixed-modal setting. The models are evaluated on a comprehensive
range of tasks, including visual question answering, image captioning, text
generation, image generation, and long-form mixed modal generation. Chameleon
demonstrates broad and general capabilities, including state-of-the-art
performance in image captioning tasks, outperforms Llama-2 in text-only tasks
while being competitive with models such as Mixtral 8x7B and Gemini-Pro, and
performs non-trivial image generation, all in a single model. It also matches
or exceeds the performance of much larger models, including Gemini Pro and
GPT-4V, according to human judgments on a new long-form mixed-modal generation
evaluation, where either the prompt or outputs contain mixed sequences of both
images and text. Chameleon marks a significant step forward in a unified
modeling of full multimodal documents.",2024-05-16,Chameleon Team,http://arxiv.org/pdf/2405.09818v2,cs.CL
MediSyn: A Generalist Text-Guided Latent Diffusion Model For Diverse Medical Image Synthesis,"Deep learning algorithms require extensive data to achieve robust
performance. However, data availability is often restricted in the medical
domain due to patient privacy concerns. Synthetic data presents a possible
solution to these challenges. Recently, image generative models have found
increasing use for medical applications but are often designed for singular
medical specialties and imaging modalities, thus limiting their broader
utility. To address this, we introduce MediSyn: a text-guided, latent diffusion
model capable of generating synthetic images from 6 medical specialties and 10
image types. The synthetic images are validated by expert clinicians for
alignment with their corresponding text prompts. Furthermore, a direct
comparison of the synthetic images against the real images confirms that our
model synthesizes novel images and, crucially, may preserve patient privacy.
Finally, classifiers trained on a mixture of synthetic and real data achieve
similar performance to those trained on twice the amount of real data. Our
findings highlight the immense potential for generalist image generative models
to accelerate algorithmic research and development in medicine.",2024-05-16,"Joseph Cho, Mrudang Mathur, Cyril Zakka, Dhamanpreet Kaur, Matthew Leipzig, Alex Dalal, Aravind Krishnan, Eubee Koo, Karen Wai, Cindy S. Zhao, Rohan Shad, Robyn Fong, Ross Wightman, Akshay Chaudhari, William Hiesinger",http://arxiv.org/pdf/2405.09806v4,cs.CL
"SecureLLM: Using Compositionality to Build Provably Secure Language Models for Private, Sensitive, and Secret Data","Traditional security mechanisms isolate resources from users who should not
access them. We reflect the compositional nature of such security mechanisms
back into the structure of LLMs to build a provably secure LLM; that we term
SecureLLM. Other approaches to LLM safety attempt to protect against bad actors
or bad outcomes, but can only do so to an extent making them inappropriate for
sensitive data. SecureLLM blends access security with fine-tuning methods. Each
data silo has associated with it a separate fine-tuning and a user has access
only to the collection of fine-tunings that they have permission for. The model
must then perform on compositional tasks at the intersection of those data
silos with the combination of those individual fine-tunings. While applicable
to any task like document QA or making API calls, in this work we concern
ourselves with models that learn the layouts of new SQL databases to provide
natural-language-to-SQL translation capabilities. Existing fine-tuning
composition methods fail in this challenging environment, as they are not
well-equipped for handling compositional tasks. Compositionality remains a
challenge for LLMs. We contribute both a difficult new compositional
natural-language-to-SQL translation task and a new perspective on LLM security
that allows models to be deployed to secure environments today.",2024-05-16,"Abdulrahman Alabdulkareem, Christian M Arnold, Yerim Lee, Pieter M Feenstra, Boris Katz, Andrei Barbu",http://arxiv.org/pdf/2405.09805v2,cs.CL
Many-Shot In-Context Learning in Multimodal Foundation Models,"Large language models are effective at few-shot in-context learning (ICL).
Recent advancements in multimodal foundation models have enabled
unprecedentedly long context windows, presenting an opportunity to explore
their capability to perform ICL with many more demonstrating examples. In this
work, we evaluate the performance of multimodal foundation models scaling from
few-shot to many-shot ICL. We benchmark GPT-4o and Gemini 1.5 Pro across 14
datasets spanning multiple domains (natural imagery, medical imagery, remote
sensing, and molecular imagery) and tasks (image classification, visual QA, and
object localization). We observe that many-shot ICL, including up to almost
2,000 demonstrating examples, leads to substantial improvements compared to
few-shot (<100 examples) ICL across all of the datasets. Further, Gemini 1.5
Pro performance continues to improve log-linearly up to the maximum number of
tested examples on many datasets. We also find open-weights multimodal
foundation models like Llama 3.2-Vision do not benefit from the demonstrating
examples, highlighting an important gap between open and closed multimodal
foundation models. Given the high inference costs required for many-shot ICL,
we also explore the impact of batching multiple queries in a single API call.
We show that batching up to 50 queries can lead to performance improvements
under zero-shot and many-shot ICL, with substantial gains in the zero-shot
setting on multiple datasets, while drastically reducing per-query cost and
latency. Finally, while GPT-4o and Gemini 1.5 Pro achieve similar zero-shot
performance across the datasets, Gemini 1.5 Pro learns more quickly than GPT-4o
on most datasets. Our results suggest that many-shot ICL could enable users to
efficiently adapt multimodal foundation models to new applications and domains.
Our codebase is publicly available at
https://github.com/stanfordmlgroup/ManyICL .",2024-05-16,"Yixing Jiang, Jeremy Irvin, Ji Hun Wang, Muhammad Ahmed Chaudhry, Jonathan H. Chen, Andrew Y. Ng",http://arxiv.org/pdf/2405.09798v2,cs.CL
Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3),"With the rapid development of natural language processing (NLP) technology,
large-scale pre-trained language models such as GPT-3 have become a popular
research object in NLP field. This paper aims to explore sentiment analysis
optimization techniques based on large pre-trained language models such as
GPT-3 to improve model performance and effect and further promote the
development of natural language processing (NLP). By introducing the importance
of sentiment analysis and the limitations of traditional methods, GPT-3 and
Fine-tuning techniques are introduced in this paper, and their applications in
sentiment analysis are explained in detail. The experimental results show that
the Fine-tuning technique can optimize GPT-3 model and obtain good performance
in sentiment analysis task. This study provides an important reference for
future sentiment analysis using large-scale language models.",2024-05-16,"Tong Zhan, Chenxi Shi, Yadong Shi, Huixiang Li, Yiyu Lin",http://arxiv.org/pdf/2405.09770v1,cs.CL
Unsupervised Extractive Dialogue Summarization in Hyperdimensional Space,"We present HyperSum, an extractive summarization framework that captures both
the efficiency of traditional lexical summarization and the accuracy of
contemporary neural approaches. HyperSum exploits the pseudo-orthogonality that
emerges when randomly initializing vectors at extremely high dimensions
(""blessing of dimensionality"") to construct representative and efficient
sentence embeddings. Simply clustering the obtained embeddings and extracting
their medoids yields competitive summaries. HyperSum often outperforms
state-of-the-art summarizers -- in terms of both summary accuracy and
faithfulness -- while being 10 to 100 times faster. We open-source HyperSum as
a strong baseline for unsupervised extractive summarization.",2024-05-16,"Seongmin Park, Kyungho Kim, Jaejin Seo, Jihwa Lee",http://arxiv.org/pdf/2405.09765v1,cs.CL
Leveraging Human Revisions for Improving Text-to-Layout Models,"Learning from human feedback has shown success in aligning large, pretrained
models with human values. Prior works have mostly focused on learning from
high-level labels, such as preferences between pairs of model outputs. On the
other hand, many domains could benefit from more involved, detailed feedback,
such as revisions, explanations, and reasoning of human users. Our work
proposes using nuanced feedback through the form of human revisions for
stronger alignment. In this paper, we ask expert designers to fix layouts
generated from a generative layout model that is pretrained on a large-scale
dataset of mobile screens. Then, we train a reward model based on how human
designers revise these generated layouts. With the learned reward model, we
optimize our model with reinforcement learning from human feedback (RLHF). Our
method, Revision-Aware Reward Models ($\method$), allows a generative
text-to-layout model to produce more modern, designer-aligned layouts, showing
the potential for utilizing human revisions and stronger forms of feedback in
improving generative models.",2024-05-16,"Amber Xie, Chin-Yi Cheng, Forrest Huang, Yang Li",http://arxiv.org/pdf/2405.13026v1,cs.CL
Many Hands Make Light Work: Task-Oriented Dialogue System with Module-Based Mixture-of-Experts,"Task-oriented dialogue systems are broadly used in virtual assistants and
other automated services, providing interfaces between users and machines to
facilitate specific tasks. Nowadays, task-oriented dialogue systems have
greatly benefited from pre-trained language models (PLMs). However, their
task-solving performance is constrained by the inherent capacities of PLMs, and
scaling these models is expensive and complex as the model size becomes larger.
To address these challenges, we propose Soft Mixture-of-Expert Task-Oriented
Dialogue system (SMETOD) which leverages an ensemble of Mixture-of-Experts
(MoEs) to excel at subproblems and generate specialized outputs for
task-oriented dialogues. SMETOD also scales up a task-oriented dialogue system
with simplicity and flexibility while maintaining inference efficiency. We
extensively evaluate our model on three benchmark functionalities: intent
prediction, dialogue state tracking, and dialogue response generation.
Experimental results demonstrate that SMETOD achieves state-of-the-art
performance on most evaluated metrics. Moreover, comparisons against existing
strong baselines show that SMETOD has a great advantage in the cost of
inference and correctness in problem-solving.",2024-05-16,"Ruolin Su, Biing-Hwang Juang",http://arxiv.org/pdf/2405.09744v1,cs.CL
An Analysis of Sentential Neighbors in Implicit Discourse Relation Prediction,"Discourse relation classification is an especially difficult task without
explicit context markers (Prasad et al., 2008). Current approaches to implicit
relation prediction solely rely on two neighboring sentences being targeted,
ignoring the broader context of their surrounding environments (Atwell et al.,
2021). In this research, we propose three new methods in which to incorporate
context in the task of sentence relation prediction: (1) Direct Neighbors
(DNs), (2) Expanded Window Neighbors (EWNs), and (3) Part-Smart Random
Neighbors (PSRNs). Our findings indicate that the inclusion of context beyond
one discourse unit is harmful in the task of discourse relation classification.",2024-05-16,"Evi Judge, Reece Suchocki, Konner Syed",http://arxiv.org/pdf/2405.09735v2,cs.CL
SCI 3.0: A Web-based Schema Curation Interface for Graphical Event Representations,"To understand the complexity of global events, one must navigate a web of
interwoven sub-events, identifying those most impactful elements within the
larger, abstract macro-event framework at play. This concept can be extended to
the field of natural language processing (NLP) through the creation of
structured event schemas which can serve as representations of these abstract
events. Central to our approach is the Schema Curation Interface 3.0 (SCI 3.0),
a web application that facilitates real-time editing of event schema properties
within a generated graph e.g., adding, removing, or editing sub-events,
entities, and relations directly through an interface.",2024-05-15,"Reece Suchocki, Mary Martin, Martha Palmer, Susan Brown",http://arxiv.org/pdf/2405.09733v2,cs.CL
"A survey on fairness of large language models in e-commerce: progress, application, and challenge","This survey explores the fairness of large language models (LLMs) in
e-commerce, examining their progress, applications, and the challenges they
face. LLMs have become pivotal in the e-commerce domain, offering innovative
solutions and enhancing customer experiences. This work presents a
comprehensive survey on the applications and challenges of LLMs in e-commerce.
The paper begins by introducing the key principles underlying the use of LLMs
in e-commerce, detailing the processes of pretraining, fine-tuning, and
prompting that tailor these models to specific needs. It then explores the
varied applications of LLMs in e-commerce, including product reviews, where
they synthesize and analyze customer feedback; product recommendations, where
they leverage consumer data to suggest relevant items; product information
translation, enhancing global accessibility; and product question and answer
sections, where they automate customer support. The paper critically addresses
the fairness challenges in e-commerce, highlighting how biases in training data
and algorithms can lead to unfair outcomes, such as reinforcing stereotypes or
discriminating against certain groups. These issues not only undermine consumer
trust, but also raise ethical and legal concerns. Finally, the work outlines
future research directions, emphasizing the need for more equitable and
transparent LLMs in e-commerce. It advocates for ongoing efforts to mitigate
biases and improve the fairness of these systems, ensuring they serve diverse
global markets effectively and ethically. Through this comprehensive analysis,
the survey provides a holistic view of the current landscape of LLMs in
e-commerce, offering insights into their potential and limitations, and guiding
future endeavors in creating fairer and more inclusive e-commerce environments.",2024-05-15,"Qingyang Ren, Zilin Jiang, Jinghan Cao, Sijia Li, Chiqu Li, Yiyang Liu, Shuning Huo, Tiange He, Yuan Chen",http://arxiv.org/pdf/2405.13025v2,cs.CL
Spectral Editing of Activations for Large Language Model Alignment,"Large language models (LLMs) often exhibit undesirable behaviours, such as
generating untruthful or biased content. Editing their internal representations
has been shown to be effective in mitigating such behaviours on top of the
existing alignment methods. We propose a novel inference-time editing method,
namely spectral editing of activations (SEA), to project the input
representations into directions with maximal covariance with the positive
demonstrations (e.g., truthful) while minimising covariance with the negative
demonstrations (e.g., hallucinated). We also extend our method to non-linear
editing using feature functions. We run extensive experiments on benchmarks
concerning truthfulness and bias with six open-source LLMs of different sizes
and model families. The results demonstrate the superiority of SEA in
effectiveness, generalisation to similar tasks, as well as computation and data
efficiency. We also show that SEA editing only has a limited negative impact on
other model capabilities.",2024-05-15,"Yifu Qiu, Zheng Zhao, Yftah Ziser, Anna Korhonen, Edoardo M. Ponti, Shay B. Cohen",http://arxiv.org/pdf/2405.09719v3,cs.CL
SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge,"Learning commonsense reasoning from visual contexts and scenes in real-world
is a crucial step toward advanced artificial intelligence. However, existing
video reasoning benchmarks are still inadequate since they were mainly designed
for factual or situated reasoning and rarely involve broader knowledge in the
real world. Our work aims to delve deeper into reasoning evaluations,
specifically within dynamic, open-world, and structured context knowledge. We
propose a new benchmark (SOK-Bench), consisting of 44K questions and 10K
situations with instance-level annotations depicted in the videos. The
reasoning process is required to understand and apply situated knowledge and
general knowledge for problem-solving. To create such a dataset, we propose an
automatic and scalable generation method to generate question-answer pairs,
knowledge graphs, and rationales by instructing the combinations of LLMs and
MLLMs. Concretely, we first extract observable situated entities, relations,
and processes from videos for situated knowledge and then extend to open-world
knowledge beyond the visible content. The task generation is facilitated
through multiple dialogues as iterations and subsequently corrected and refined
by our designed self-promptings and demonstrations. With a corpus of both
explicit situated facts and implicit commonsense, we generate associated
question-answer pairs and reasoning processes, finally followed by manual
reviews for quality assurance. We evaluated recent mainstream large
vision-language models on the benchmark and found several insightful
conclusions. For more information, please refer to our benchmark at
www.bobbywu.com/SOKBench.",2024-05-15,"Andong Wang, Bo Wu, Sunli Chen, Zhenfang Chen, Haotian Guan, Wei-Ning Lee, Li Erran Li, Chuang Gan",http://arxiv.org/pdf/2405.09713v2,cs.CL
STAR: A Benchmark for Situated Reasoning in Real-World Videos,"Reasoning in the real world is not divorced from situations. How to capture
the present knowledge from surrounding situations and perform reasoning
accordingly is crucial and challenging for machine intelligence. This paper
introduces a new benchmark that evaluates the situated reasoning ability via
situation abstraction and logic-grounded question answering for real-world
videos, called Situated Reasoning in Real-World Videos (STAR Benchmark). This
benchmark is built upon the real-world videos associated with human actions or
interactions, which are naturally dynamic, compositional, and logical. The
dataset includes four types of questions, including interaction, sequence,
prediction, and feasibility. We represent the situations in real-world videos
by hyper-graphs connecting extracted atomic entities and relations (e.g.,
actions, persons, objects, and relationships). Besides visual perception,
situated reasoning also requires structured situation comprehension and logical
reasoning. Questions and answers are procedurally generated. The answering
logic of each question is represented by a functional program based on a
situation hyper-graph. We compare various existing video reasoning models and
find that they all struggle on this challenging situated reasoning task. We
further propose a diagnostic neuro-symbolic model that can disentangle visual
perception, situation abstraction, language understanding, and functional
reasoning to understand the challenges of this benchmark.",2024-05-15,"Bo Wu, Shoubin Yu, Zhenfang Chen, Joshua B Tenenbaum, Chuang Gan",http://arxiv.org/pdf/2405.09711v1,cs.CL
Simulating Policy Impacts: Developing a Generative Scenario Writing Method to Evaluate the Perceived Effects of Regulation,"The rapid advancement of AI technologies yields numerous future impacts on
individuals and society. Policymakers are tasked to react quickly and establish
policies that mitigate those impacts. However, anticipating the effectiveness
of policies is a difficult task, as some impacts might only be observable in
the future and respective policies might not be applicable to the future
development of AI. In this work we develop a method for using large language
models (LLMs) to evaluate the efficacy of a given piece of policy at mitigating
specified negative impacts. We do so by using GPT-4 to generate scenarios both
pre- and post-introduction of policy and translating these vivid stories into
metrics based on human perceptions of impacts. We leverage an already
established taxonomy of impacts of generative AI in the media environment to
generate a set of scenario pairs both mitigated and non-mitigated by the
transparency policy in Article 50 of the EU AI Act. We then run a user study
(n=234) to evaluate these scenarios across four risk-assessment dimensions:
severity, plausibility, magnitude, and specificity to vulnerable populations.
We find that this transparency legislation is perceived to be effective at
mitigating harms in areas such as labor and well-being, but largely ineffective
in areas such as social cohesion and security. Through this case study we
demonstrate the efficacy of our method as a tool to iterate on the
effectiveness of policy for mitigating various negative impacts. We expect this
method to be useful to researchers or other stakeholders who want to brainstorm
the potential utility of different pieces of policy or other mitigation
strategies.",2024-05-15,"Julia Barnett, Kimon Kieslich, Nicholas Diakopoulos",http://arxiv.org/pdf/2405.09679v2,cs.CL
LoRA Learns Less and Forgets Less,"Low-Rank Adaptation (LoRA) is a widely-used parameter-efficient finetuning
method for large language models. LoRA saves memory by training only low rank
perturbations to selected weight matrices. In this work, we compare the
performance of LoRA and full finetuning on two target domains, programming and
mathematics. We consider both the instruction finetuning (approximately 100K
prompt-response pairs) and continued pretraining (20B unstructured tokens) data
regimes. Our results show that, in the standard low-rank settings, LoRA
substantially underperforms full finetuning. Nevertheless, LoRA better
maintains the base model's performance on tasks outside the target domain. We
show that LoRA mitigates forgetting more than common regularization techniques
such as weight decay and dropout; it also helps maintain more diverse
generations. Finally, we show that full finetuning learns perturbations with a
rank that is 10-100X greater than typical LoRA configurations, possibly
explaining some of the reported gaps. We conclude by proposing best practices
for finetuning with LoRA.",2024-05-15,"Dan Biderman, Jacob Portes, Jose Javier Gonzalez Ortiz, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, Cody Blakeney, John P. Cunningham",http://arxiv.org/pdf/2405.09673v2,cs.CL
Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models,"The ability to build and leverage world models is essential for a
general-purpose AI agent. Testing such capabilities is hard, in part because
the building blocks of world models are ill-defined. We present Elements of
World Knowledge (EWOK), a framework for evaluating world modeling in language
models by testing their ability to use knowledge of a concept to match a target
text with a plausible/implausible context. EWOK targets specific concepts from
multiple knowledge domains known to be vital for world modeling in humans.
Domains range from social interactions (help/hinder) to spatial relations
(left/right). Both, contexts and targets are minimal pairs. Objects, agents,
and locations in the items can be flexibly filled in enabling easy generation
of multiple controlled datasets. We then introduce EWOK-CORE-1.0, a dataset of
4,374 items covering 11 world knowledge domains. We evaluate 20 openweights
large language models (1.3B--70B parameters) across a battery of evaluation
paradigms along with a human norming study comprising 12,480 measurements. The
overall performance of all tested models is worse than human performance, with
results varying drastically across domains. These data highlight simple cases
where even large models fail and present rich avenues for targeted research on
LLM world modeling capabilities.",2024-05-15,"Anna A. Ivanova, Aalok Sathe, Benjamin Lipkin, Unnathi Kumar, Setayesh Radkani, Thomas H. Clark, Carina Kauf, Jennifer Hu, R. T. Pramod, Gabriel Grand, Vivian Paulun, Maria Ryskina, Ekin Akyürek, Ethan Wilcox, Nafisa Rashid, Leshem Choshen, Roger Levy, Evelina Fedorenko, Joshua Tenenbaum, Jacob Andreas",http://arxiv.org/pdf/2405.09605v1,cs.CL
Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer Architectures for Cross-Language Structural Priming,"This study evaluates the performance of Recurrent Neural Network (RNN) and
Transformer models in replicating cross-language structural priming, a key
indicator of abstract grammatical representations in human language processing.
Focusing on Chinese-English priming, which involves two typologically distinct
languages, we examine how these models handle the robust phenomenon of
structural priming, where exposure to a particular sentence structure increases
the likelihood of selecting a similar structure subsequently. Our findings
indicate that transformers outperform RNNs in generating primed sentence
structures, with accuracy rates that exceed 25.84\% to 33. 33\%. This
challenges the conventional belief that human sentence processing primarily
involves recurrent and immediate processing and suggests a role for cue-based
retrieval mechanisms. This work contributes to our understanding of how
computational models may reflect human cognitive processes across diverse
language families.",2024-05-15,"Demi Zhang, Bushi Xiao, Chao Gao, Sangpil Youm, Bonnie J Dorr",http://arxiv.org/pdf/2405.09508v2,cs.CL
QueryNER: Segmentation of E-commerce Queries,"We present QueryNER, a manually-annotated dataset and accompanying model for
e-commerce query segmentation. Prior work in sequence labeling for e-commerce
has largely addressed aspect-value extraction which focuses on extracting
portions of a product title or query for narrowly defined aspects. Our work
instead focuses on the goal of dividing a query into meaningful chunks with
broadly applicable types. We report baseline tagging results and conduct
experiments comparing token and entity dropping for null and low recall query
recovery. Challenging test sets are created using automatic transformations and
show how simple data augmentation techniques can make the models more robust to
noise. We make the QueryNER dataset publicly available.",2024-05-15,"Chester Palen-Michel, Lizzie Liang, Zhe Wu, Constantine Lignos",http://arxiv.org/pdf/2405.09507v1,cs.CL
ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using Wikidata,"We introduce ParaNames, a massively multilingual parallel name resource
consisting of 140 million names spanning over 400 languages. Names are provided
for 16.8 million entities, and each entity is mapped from a complex type
hierarchy to a standard type (PER/LOC/ORG). Using Wikidata as a source, we
create the largest resource of this type to date. We describe our approach to
filtering and standardizing the data to provide the best quality possible.
ParaNames is useful for multilingual language processing, both in defining
tasks for name translation/transliteration and as supplementary data for tasks
such as named entity recognition and linking. We demonstrate the usefulness of
ParaNames on two tasks. First, we perform canonical name translation between
English and 17 other languages. Second, we use it as a gazetteer for
multilingual named entity recognition, obtaining performance improvements on
all 10 languages evaluated.",2024-05-15,"Jonne Sälevä, Constantine Lignos",http://arxiv.org/pdf/2405.09496v1,cs.CL
Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts,"Using large language models (LLMs) for educational applications like
dialogue-based teaching is a hot topic. Effective teaching, however, requires
teachers to adapt the difficulty of content and explanations to the education
level of their students. Even the best LLMs today struggle to do this well. If
we want to improve LLMs on this adaptation task, we need to be able to measure
adaptation success reliably. However, current Static metrics for text
difficulty, like the Flesch-Kincaid Reading Ease score, are known to be crude
and brittle. We, therefore, introduce and evaluate a new set of Prompt-based
metrics for text difficulty. Based on a user study, we create Prompt-based
metrics as inputs for LLMs. They leverage LLM's general language understanding
capabilities to capture more abstract and complex features than Static metrics.
Regression experiments show that adding our Prompt-based metrics significantly
improves text difficulty classification over Static metrics alone. Our results
demonstrate the promise of using LLMs to evaluate text adaptation to different
education levels.",2024-05-15,"Donya Rooein, Paul Rottger, Anastassia Shaitarova, Dirk Hovy",http://arxiv.org/pdf/2405.09482v2,cs.CL
Tell Me Why: Explainable Public Health Fact-Checking with Large Language Models,"This paper presents a comprehensive analysis of explainable fact-checking
through a series of experiments, focusing on the ability of large language
models to verify public health claims and provide explanations or
justifications for their veracity assessments. We examine the effectiveness of
zero/few-shot prompting and parameter-efficient fine-tuning across various open
and closed-source models, examining their performance in both isolated and
joint tasks of veracity prediction and explanation generation. Importantly, we
employ a dual evaluation approach comprising previously established automatic
metrics and a novel set of criteria through human evaluation. Our automatic
evaluation indicates that, within the zero-shot scenario, GPT-4 emerges as the
standout performer, but in few-shot and parameter-efficient fine-tuning
contexts, open-source models demonstrate their capacity to not only bridge the
performance gap but, in some instances, surpass GPT-4. Human evaluation reveals
yet more nuance as well as indicating potential problems with the gold
explanations.",2024-05-15,"Majid Zarharan, Pascal Wullschleger, Babak Behkam Kia, Mohammad Taher Pilehvar, Jennifer Foster",http://arxiv.org/pdf/2405.09454v1,cs.CL
Facilitating Opinion Diversity through Hybrid NLP Approaches,"Modern democracies face a critical issue of declining citizen participation
in decision-making. Online discussion forums are an important avenue for
enhancing citizen participation. This thesis proposal 1) identifies the
challenges involved in facilitating large-scale online discussions with Natural
Language Processing (NLP), 2) suggests solutions to these challenges by
incorporating hybrid human-AI technologies, and 3) investigates what these
technologies can reveal about individual perspectives in online discussions. We
propose a three-layered hierarchy for representing perspectives that can be
obtained by a mixture of human intelligence and large language models. We
illustrate how these representations can draw insights into the diversity of
perspectives and allow us to investigate interactions in online discussions.",2024-05-15,Michiel van der Meer,http://arxiv.org/pdf/2405.09439v1,cs.CL
Intelligent Tutor: Leveraging ChatGPT and Microsoft Copilot Studio to Deliver a Generative AI Student Support and Feedback System within Teams,"This study explores the integration of the ChatGPT API with GPT-4 model and
Microsoft Copilot Studio on the Microsoft Teams platform to develop an
intelligent tutoring system. Designed to provide instant support to students,
the system dynamically adjusts educational content in response to the learners'
progress and feedback. Utilizing advancements in natural language processing
and machine learning, it interprets student inquiries, offers tailored
feedback, and facilitates the educational journey. Initial implementation
highlights the system's potential in boosting students' motivation and
engagement, while equipping educators with critical insights into the learning
process, thus promoting tailored educational experiences and enhancing
instructional effectiveness.",2024-05-15,Wei-Yu Chen,http://arxiv.org/pdf/2405.13024v1,cs.CL
Matching domain experts by training from scratch on domain knowledge,"Recently, large language models (LLMs) have outperformed human experts in
predicting the results of neuroscience experiments (Luo et al., 2024). What is
the basis for this performance? One possibility is that statistical patterns in
that specific scientific literature, as opposed to emergent reasoning abilities
arising from broader training, underlie LLMs' performance. To evaluate this
possibility, we trained (next word prediction) a relatively small
124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge.
Despite being orders of magnitude smaller than larger LLMs trained on trillions
of tokens, small models achieved expert-level performance in predicting
neuroscience results. Small models trained on the neuroscience literature
succeeded when they were trained from scratch using a tokenizer specifically
trained on neuroscience text or when the neuroscience literature was used to
finetune a pretrained GPT-2. Our results indicate that expert-level performance
may be attained by even small LLMs through domain-specific, auto-regressive
training approaches.",2024-05-15,"Xiaoliang Luo, Guangzhi Sun, Bradley C. Love",http://arxiv.org/pdf/2405.09395v2,cs.CL
PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models,"Recent advances in large language models (LLMs) have led to their extensive
global deployment, and ensuring their safety calls for comprehensive and
multilingual toxicity evaluations. However, existing toxicity benchmarks are
overwhelmingly focused on English, posing serious risks to deploying LLMs in
other languages. We address this by introducing PolygloToxicityPrompts (PTP),
the first large-scale multilingual toxicity evaluation benchmark of 425K
naturally occurring prompts spanning 17 languages. We overcome the scarcity of
naturally occurring toxicity in web-text and ensure coverage across languages
with varying resources by automatically scraping over 100M web-text documents.
Using PTP, we investigate research questions to study the impact of model size,
prompt language, and instruction and preference-tuning methods on toxicity by
benchmarking over 60 LLMs. Notably, we find that toxicity increases as language
resources decrease or model size increases. Although instruction- and
preference-tuning reduce toxicity, the choice of preference-tuning method does
not have any significant impact. Our findings shed light on crucial
shortcomings of LLM safeguarding and highlight areas for future research.",2024-05-15,"Devansh Jain, Priyanshu Kumar, Samuel Gehman, Xuhui Zhou, Thomas Hartvigsen, Maarten Sap",http://arxiv.org/pdf/2405.09373v3,cs.CL
Large Language Model Bias Mitigation from the Perspective of Knowledge Editing,"Existing debiasing methods inevitably make unreasonable or undesired
predictions as they are designated and evaluated to achieve parity across
different social groups but leave aside individual facts, resulting in modified
existing knowledge. In this paper, we first establish a new bias mitigation
benchmark BiasKE leveraging existing and additional constructed datasets, which
systematically assesses debiasing performance by complementary metrics on
fairness, specificity, and generalization. Meanwhile, we propose a novel
debiasing method, Fairness Stamp (FAST), which enables editable fairness
through fine-grained calibration on individual biased knowledge. Comprehensive
experiments demonstrate that FAST surpasses state-of-the-art baselines with
remarkable debiasing performance while not hampering overall model capability
for knowledge preservation, highlighting the prospect of fine-grained debiasing
strategies for editable fairness in LLMs.",2024-05-15,"Ruizhe Chen, Yichen Li, Zikai Xiao, Zuozhu Liu",http://arxiv.org/pdf/2405.09341v2,cs.CL
Prompting-based Synthetic Data Generation for Few-Shot Question Answering,"Although language models (LMs) have boosted the performance of Question
Answering, they still need plenty of data. Data annotation, in contrast, is a
time-consuming process. This especially applies to Question Answering, where
possibly large documents have to be parsed and annotated with questions and
their corresponding answers. Furthermore, Question Answering models often only
work well for the domain they were trained on. Since annotation is costly, we
argue that domain-agnostic knowledge from LMs, such as linguistic
understanding, is sufficient to create a well-curated dataset. With this
motivation, we show that using large language models can improve Question
Answering performance on various datasets in the few-shot setting compared to
state-of-the-art approaches. For this, we perform data generation leveraging
the Prompting framework, suggesting that language models contain valuable
task-agnostic knowledge that can be used beyond the common
pre-training/fine-tuning scheme. As a result, we consistently outperform
previous approaches on few-shot Question Answering.",2024-05-15,"Maximilian Schmidt, Andrea Bartezzaghi, Ngoc Thang Vu",http://arxiv.org/pdf/2405.09335v1,cs.CL
LLMs can learn self-restraint through iterative self-reflection,"In order to be deployed safely, Large Language Models (LLMs) must be capable
of dynamically adapting their behavior based on their level of knowledge and
uncertainty associated with specific topics. This adaptive behavior, which we
refer to as self-restraint, is non-trivial to teach since it depends on the
internal knowledge of an LLM. By default, LLMs are trained to maximize the next
token likelihood, which does not teach the model to modulate its answer based
on its level of uncertainty. In order to learn self-restraint, we devise a
utility function that can encourage the model to produce responses only when it
is confident in them. This utility function can be used to score generation of
different length and abstention. To optimize this function, we introduce
ReSearch, a process of ""self-reflection"" consisting of iterative self-prompting
and self-evaluation. We use the ReSearch algorithm to generate synthetic data
on which we finetune our models. Compared to their original versions, our
resulting models generate fewer \emph{hallucinations} overall at no additional
inference cost, for both known and unknown topics, as the model learns to
selectively restrain itself. In addition, our method elegantly incorporates the
ability to abstain by augmenting the samples generated by the model during the
search procedure with an answer expressing abstention.",2024-05-15,"Alexandre Piché, Aristides Milios, Dzmitry Bahdanau, Chris Pal",http://arxiv.org/pdf/2405.13022v2,cs.CL
Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support,"Background: Rapid advancements in natural language processing have led to the
development of large language models with the potential to revolutionize mental
health care. These models have shown promise in assisting clinicians and
providing support to individuals experiencing various psychological challenges.
  Objective: This study aims to compare the performance of two large language
models, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,
to assess their potential applicability in mental health care settings.
  Methods: A blind methodology was employed, with a clinical psychologist
evaluating the models' responses without knowledge of their origins. The
prompts encompassed a diverse range of mental health topics, including
depression, anxiety, and trauma, to ensure a comprehensive assessment.
  Results: The results demonstrated a significant difference in performance
between the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out
of 10, while Chat-GPT received an average rating of 6.52. The clinical
psychologist's evaluation suggested that GPT-4 was more effective at generating
clinically relevant and empathetic responses, thereby providing better support
and guidance to potential users.
  Conclusions: This study contributes to the growing body of literature on the
applicability of large language models in mental health care settings. The
findings underscore the importance of continued research and development in the
field to optimize these models for clinical use. Further investigation is
necessary to understand the specific factors underlying the performance
differences between the two models and to explore their generalizability across
various populations and mental health conditions.",2024-05-15,Birger Moell,http://arxiv.org/pdf/2405.09300v1,cs.CL
IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning Inner Monologues,"Although the Retrieval-Augmented Generation (RAG) paradigms can use external
knowledge to enhance and ground the outputs of Large Language Models (LLMs) to
mitigate generative hallucinations and static knowledge base problems, they
still suffer from limited flexibility in adopting Information Retrieval (IR)
systems with varying capabilities, constrained interpretability during the
multi-round retrieval process, and a lack of end-to-end optimization. To
address these challenges, we propose a novel LLM-centric approach, IM-RAG, that
integrates IR systems with LLMs to support multi-round RAG through learning
Inner Monologues (IM, i.e., the human inner voice that narrates one's
thoughts). During the IM process, the LLM serves as the core reasoning model
(i.e., Reasoner) to either propose queries to collect more information via the
Retriever or to provide a final answer based on the conversational context. We
also introduce a Refiner that improves the outputs from the Retriever,
effectively bridging the gap between the Reasoner and IR modules with varying
capabilities and fostering multi-round communications. The entire IM process is
optimized via Reinforcement Learning (RL) where a Progress Tracker is
incorporated to provide mid-step rewards, and the answer prediction is further
separately optimized via Supervised Fine-Tuning (SFT). We conduct extensive
experiments with the HotPotQA dataset, a popular benchmark for retrieval-based,
multi-step question-answering. The results show that our approach achieves
state-of-the-art (SOTA) performance while providing high flexibility in
integrating IR modules as well as strong interpretability exhibited in the
learned inner monologues.",2024-05-15,"Diji Yang, Jinmeng Rao, Kezhen Chen, Xiaoyuan Guo, Yawen Zhang, Jie Yang, Yi Zhang",http://arxiv.org/pdf/2405.13021v1,cs.CL
Do language models capture implied discourse meanings? An investigation with exhaustivity implicatures of Korean morphology,"Markedness in natural language is often associated with non-literal meanings
in discourse. Differential Object Marking (DOM) in Korean is one instance of
this phenomenon, where post-positional markers are selected based on both the
semantic features of the noun phrases and the discourse features that are
orthogonal to the semantic features. Previous work has shown that
distributional models of language recover certain semantic features of words --
do these models capture implied discourse-level meanings as well? We evaluate
whether a set of large language models are capable of associating discourse
meanings with different object markings in Korean. Results suggest that
discourse meanings of a grammatical marker can be more challenging to encode
than that of a discourse marker.",2024-05-15,"Hagyeong Shin, Sean Trott",http://arxiv.org/pdf/2405.09293v1,cs.CL
Sign of the Times: Evaluating the use of Large Language Models for Idiomaticity Detection,"Despite the recent ubiquity of large language models and their high zero-shot
prompted performance across a wide range of tasks, it is still not known how
well they perform on tasks which require processing of potentially idiomatic
language. In particular, how well do such models perform in comparison to
encoder-only models fine-tuned specifically for idiomaticity tasks? In this
work, we attempt to answer this question by looking at the performance of a
range of LLMs (both local and software-as-a-service models) on three
idiomaticity datasets: SemEval 2022 Task 2a, FLUTE, and MAGPIE. Overall, we
find that whilst these models do give competitive performance, they do not
match the results of fine-tuned task-specific models, even at the largest
scales (e.g. for GPT-4). Nevertheless, we do see consistent performance
improvements across model scale. Additionally, we investigate prompting
approaches to improve performance, and discuss the practicalities of using LLMs
for these tasks.",2024-05-15,"Dylan Phelps, Thomas Pickard, Maggie Mi, Edward Gow-Smith, Aline Villavicencio",http://arxiv.org/pdf/2405.09279v1,cs.CL
Using Combinatorial Optimization to Design a High quality LLM Solution,"We introduce a novel LLM based solution design approach that utilizes
combinatorial optimization and sampling. Specifically, a set of factors that
influence the quality of the solution are identified. They typically include
factors that represent prompt types, LLM inputs alternatives, and parameters
governing the generation and design alternatives. Identifying the factors that
govern the LLM solution quality enables the infusion of subject matter expert
knowledge. Next, a set of interactions between the factors are defined and
combinatorial optimization is used to create a small subset $P$ that ensures
all desired interactions occur in $P$. Each element $p \in P$ is then developed
into an appropriate benchmark. Applying the alternative solutions on each
combination, $p \in P$ and evaluating the results facilitate the design of a
high quality LLM solution pipeline. The approach is especially applicable when
the design and evaluation of each benchmark in $P$ is time-consuming and
involves manual steps and human evaluation. Given its efficiency the approach
can also be used as a baseline to compare and validate an autoML approach that
searches over the factors governing the solution.",2024-05-15,"Samuel Ackerman, Eitan Farchi, Rami Katan, Orna Raz",http://arxiv.org/pdf/2405.13020v1,cs.CL
New Textual Corpora for Serbian Language Modeling,"This paper will present textual corpora for Serbian (and Serbo-Croatian),
usable for the training of large language models and publicly available at one
of the several notable online repositories. Each corpus will be classified
using multiple methods and its characteristics will be detailed. Additionally,
the paper will introduce three new corpora: a new umbrella web corpus of
Serbo-Croatian, a new high-quality corpus based on the doctoral dissertations
stored within National Repository of Doctoral Dissertations from all
Universities in Serbia, and a parallel corpus of abstract translation from the
same source. The uniqueness of both old and new corpora will be accessed via
frequency-based stylometric methods, and the results will be briefly discussed.",2024-05-15,"Mihailo Škorić, Nikola Janković",http://arxiv.org/pdf/2405.09250v1,cs.CL
A Survey on Transformers in NLP with Focus on Efficiency,"The advent of transformers with attention mechanisms and associated
pre-trained models have revolutionized the field of Natural Language Processing
(NLP). However, such models are resource-intensive due to highly complex
architecture. This limits their application to resource-constrained
environments. While choosing an appropriate NLP model, a major trade-off exists
over choosing accuracy over efficiency and vice versa. This paper presents a
commentary on the evolution of NLP and its applications with emphasis on their
accuracy as-well-as efficiency. Following this, a survey of research
contributions towards enhancing the efficiency of transformer-based models at
various stages of model development along with hardware considerations has been
conducted. The goal of this survey is to determine how current NLP techniques
contribute towards a sustainable society and to establish a foundation for
future research.",2024-05-15,"Wazib Ansar, Saptarsi Goswami, Amlan Chakrabarti",http://arxiv.org/pdf/2406.16893v1,cs.CL
"Infer Induced Sentiment of Comment Response to Video: A New Task, Dataset and Baseline","Existing video multi-modal sentiment analysis mainly focuses on the sentiment
expression of people within the video, yet often neglects the induced sentiment
of viewers while watching the videos. Induced sentiment of viewers is essential
for inferring the public response to videos, has broad application in analyzing
public societal sentiment, effectiveness of advertising and other areas. The
micro videos and the related comments provide a rich application scenario for
viewers induced sentiment analysis. In light of this, we introduces a novel
research task, Multi-modal Sentiment Analysis for Comment Response of Video
Induced(MSA-CRVI), aims to inferring opinions and emotions according to the
comments response to micro video. Meanwhile, we manually annotate a dataset
named Comment Sentiment toward to Micro Video (CSMV) to support this research.
It is the largest video multi-modal sentiment dataset in terms of scale and
video duration to our knowledge, containing 107,267 comments and 8,210 micro
videos with a video duration of 68.83 hours. To infer the induced sentiment of
comment should leverage the video content, so we propose the Video
Content-aware Comment Sentiment Analysis (VC-CSA) method as baseline to address
the challenges inherent in this new task. Extensive experiments demonstrate
that our method is showing significant improvements over other established
baselines.",2024-05-15,"Qi Jia, Baoyu Fan, Cong Xu, Lu Liu, Liang Jin, Guoguang Du, Zhenhua Guo, Yaqian Zhao, Xuanjing Huang, Rengang Li",http://arxiv.org/pdf/2407.06115v1,cs.CL
"A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models","The rapid advancement of foundation models (FMs) across language, image,
audio, and video domains has shown remarkable capabilities in diverse tasks.
However, the proliferation of FMs brings forth a critical challenge: the
potential to generate hallucinated outputs, particularly in high-stakes
applications. The tendency of foundation models to produce hallucinated content
arguably represents the biggest hindrance to their widespread adoption in
real-world scenarios, especially in domains where reliability and accuracy are
paramount. This survey paper presents a comprehensive overview of recent
developments that aim to identify and mitigate the problem of hallucination in
FMs, spanning text, image, video, and audio modalities. By synthesizing recent
advancements in detecting and mitigating hallucination across various
modalities, the paper aims to provide valuable insights for researchers,
developers, and practitioners. Essentially, it establishes a clear framework
encompassing definition, taxonomy, and detection strategies for addressing
hallucination in multimodal foundation models, laying the foundation for future
research in this pivotal area.",2024-05-15,"Pranab Sahoo, Prabhash Meharia, Akash Ghosh, Sriparna Saha, Vinija Jain, Aman Chadha",http://arxiv.org/pdf/2405.09589v4,cs.CL
Word Alignment as Preference for Machine Translation,"The problem of hallucination and omission, a long-standing problem in machine
translation (MT), is more pronounced when a large language model (LLM) is used
in MT because an LLM itself is susceptible to these phenomena. In this work, we
mitigate the problem in an LLM-based MT model by guiding it to better word
alignment. We first study the correlation between word alignment and the
phenomena of hallucination and omission in MT. Then we propose to utilize word
alignment as preference to optimize the LLM-based MT model. The preference data
are constructed by selecting chosen and rejected translations from multiple MT
tools. Subsequently, direct preference optimization is used to optimize the
LLM-based model towards the preference signal. Given the absence of evaluators
specifically designed for hallucination and omission in MT, we further propose
selecting hard instances and utilizing GPT-4 to directly evaluate the
performance of the models in mitigating these issues. We verify the rationality
of these designed evaluation methods by experiments, followed by extensive
results demonstrating the effectiveness of word alignment-based preference
optimization to mitigate hallucination and omission. On the other hand,
although it shows promise in mitigating hallucination and omission, the overall
performance of MT in different language directions remains mixed, with slight
increases in BLEU and decreases in COMET.",2024-05-15,"Qiyu Wu, Masaaki Nagata, Zhongtao Miao, Yoshimasa Tsuruoka",http://arxiv.org/pdf/2405.09223v2,cs.CL
Bridging the gap in online hate speech detection: a comparative analysis of BERT and traditional models for homophobic content identification on X/Twitter,"Our study addresses a significant gap in online hate speech detection
research by focusing on homophobia, an area often neglected in sentiment
analysis research. Utilising advanced sentiment analysis models, particularly
BERT, and traditional machine learning methods, we developed a nuanced approach
to identify homophobic content on X/Twitter. This research is pivotal due to
the persistent underrepresentation of homophobia in detection models. Our
findings reveal that while BERT outperforms traditional methods, the choice of
validation technique can impact model performance. This underscores the
importance of contextual understanding in detecting nuanced hate speech. By
releasing the largest open-source labelled English dataset for homophobia
detection known to us, an analysis of various models' performance and our
strongest BERT-based model, we aim to enhance online safety and inclusivity.
Future work will extend to broader LGBTQIA+ hate speech detection, addressing
the challenges of sourcing diverse datasets. Through this endeavour, we
contribute to the larger effort against online hate, advocating for a more
inclusive digital landscape. Our study not only offers insights into the
effective detection of homophobic content by improving on previous research
results, but it also lays groundwork for future advancements in hate speech
analysis.",2024-05-15,"Josh McGiff, Nikola S. Nikolov",http://arxiv.org/pdf/2405.09221v1,cs.CL
ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models,"Planning is a crucial element of both human intelligence and contemporary
large language models (LLMs). In this paper, we initiate a theoretical
investigation into the emergence of planning capabilities in Transformer-based
LLMs via their next-word prediction mechanisms. We model planning as a network
path-finding task, where the objective is to generate a valid path from a
specified source node to a designated target node. Our mathematical
characterization shows that Transformer architectures can execute path-finding
by embedding the adjacency and reachability matrices within their weights.
Furthermore, our theoretical analysis of gradient-based learning dynamics
reveals that LLMs can learn both the adjacency and a limited form of the
reachability matrices. These theoretical insights are then validated through
experiments, which demonstrate that Transformer architectures indeed learn the
adjacency and an incomplete reachability matrices, consistent with our
theoretical predictions. When applying our methodology to the real-world
planning benchmark Blocksworld, our observations remain consistent.
Additionally, our analyses uncover a fundamental limitation of current
Transformer architectures in path-finding: these architectures cannot identify
reachability relationships through transitivity, which leads to failures in
generating paths when concatenation is required. These findings provide new
insights into how the internal mechanisms of autoregressive learning facilitate
intelligent planning and deepen our understanding of how future LLMs might
achieve more advanced and general planning-and-reasoning capabilities across
diverse applications.",2024-05-15,"Siwei Wang, Yifei Shen, Shi Feng, Haoran Sun, Shang-Hua Teng, Wei Chen",http://arxiv.org/pdf/2405.09220v3,cs.CL
HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants,"Language models (LMs) as conversational assistants recently became popular
tools that help people accomplish a variety of tasks. These typically result
from adapting LMs pretrained on general domain text sequences through further
instruction-tuning and possibly preference optimisation methods. The evaluation
of such LMs would ideally be performed using human judgement, however, this is
not scalable. On the other hand, automatic evaluation featuring auxiliary LMs
as judges and/or knowledge-based tasks is scalable but struggles with assessing
conversational ability and adherence to instructions. To help accelerate the
development of LMs as conversational assistants, we propose a novel automatic
evaluation task: HumanRankEval (HRE). It consists of a large-scale, diverse and
high-quality set of questions, each with several answers authored and scored by
humans. To perform evaluation, HRE ranks these answers based on their
log-likelihood under the LM's distribution, and subsequently calculates their
correlation with the corresponding human rankings. We support HRE's efficacy by
investigating how efficiently it separates pretrained and instruction-tuned LMs
of various sizes. We show that HRE correlates well with human judgements and is
particularly responsive to model changes following instruction-tuning.",2024-05-15,"Milan Gritta, Gerasimos Lampouras, Ignacio Iacobacci",http://arxiv.org/pdf/2405.09186v1,cs.CL
A Comprehensive Survey of Accelerated Generation Techniques in Large Language Models,"Despite the crucial importance of accelerating text generation in large
language models (LLMs) for efficiently producing content, the sequential nature
of this process often leads to high inference latency, posing challenges for
real-time applications. Various techniques have been proposed and developed to
address these challenges and improve efficiency. This paper presents a
comprehensive survey of accelerated generation techniques in autoregressive
language models, aiming to understand the state-of-the-art methods and their
applications. We categorize these techniques into several key areas:
speculative decoding, early exiting mechanisms, and non-autoregressive methods.
We discuss each category's underlying principles, advantages, limitations, and
recent advancements. Through this survey, we aim to offer insights into the
current landscape of techniques in LLMs and provide guidance for future
research directions in this critical area of natural language processing.",2024-05-15,"Mahsa Khoshnoodi, Vinija Jain, Mingye Gao, Malavika Srikanth, Aman Chadha",http://arxiv.org/pdf/2405.13019v2,cs.CL
Adapting Abstract Meaning Representation Parsing to the Clinical Narrative -- the SPRING THYME parser,"This paper is dedicated to the design and evaluation of the first AMR parser
tailored for clinical notes. Our objective was to facilitate the precise
transformation of the clinical notes into structured AMR expressions, thereby
enhancing the interpretability and usability of clinical text data at scale.
Leveraging the colon cancer dataset from the Temporal Histories of Your Medical
Events (THYME) corpus, we adapted a state-of-the-art AMR parser utilizing
continuous training. Our approach incorporates data augmentation techniques to
enhance the accuracy of AMR structure predictions. Notably, through this
learning strategy, our parser achieved an impressive F1 score of 88% on the
THYME corpus's colon cancer dataset. Moreover, our research delved into the
efficacy of data required for domain adaptation within the realm of clinical
notes, presenting domain adaptation data requirements for AMR parsing. This
exploration not only underscores the parser's robust performance but also
highlights its potential in facilitating a deeper understanding of clinical
narratives through structured semantic representations.",2024-05-15,"Jon Z. Cai, Kristin Wright-Bettner, Martha Palmer, Guergana K. Savova, James H. Martin",http://arxiv.org/pdf/2405.09153v1,cs.CL
Continued Pretraining for Domain Adaptation of Wav2vec2.0 in Automatic Speech Recognition for Elementary Math Classroom Settings,"Creating Automatic Speech Recognition (ASR) systems that are robust and
resilient to classroom conditions is paramount to the development of AI tools
to aid teachers and students. In this work, we study the efficacy of continued
pretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that
CPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of
Wav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the
model's robustness to different noises, microphones, classroom conditions as
well as classroom demographics. Our CPT models show improved ability to
generalize to different demographics unseen in the labeled finetuning data.",2024-05-15,"Ahmed Adel Attia, Dorottya Demszky, Tolulope Ogunremi, Jing Liu, Carol Espy-Wilson",http://arxiv.org/pdf/2405.13018v1,cs.CL
A Systematic Analysis on the Temporal Generalization of Language Models in Social Media,"In machine learning, temporal shifts occur when there are differences between
training and test splits in terms of time. For streaming data such as news or
social media, models are commonly trained on a fixed corpus from a certain
period of time, and they can become obsolete due to the dynamism and evolving
nature of online content. This paper focuses on temporal shifts in social media
and, in particular, Twitter. We propose a unified evaluation scheme to assess
the performance of language models (LMs) under temporal shift on standard
social media tasks. LMs are tested on five diverse social media NLP tasks under
different temporal settings, which revealed two important findings: (i) the
decrease in performance under temporal shift is consistent across different
models for entity-focused tasks such as named entity recognition or
disambiguation, and hate speech detection, but not significant in the other
tasks analysed (i.e., topic and sentiment classification); and (ii) continuous
pre-training on the test period does not improve the temporal adaptability of
LMs.",2024-05-15,"Asahi Ushio, Jose Camacho-Collados",http://arxiv.org/pdf/2405.13017v1,cs.CL
A safety realignment framework via subspace-oriented model fusion for large language models,"The current safeguard mechanisms for large language models (LLMs) are indeed
susceptible to jailbreak attacks, making them inherently fragile. Even the
process of fine-tuning on apparently benign data for downstream tasks can
jeopardize safety. One potential solution is to conduct safety fine-tuning
subsequent to downstream fine-tuning. However, there's a risk of catastrophic
forgetting during safety fine-tuning, where LLMs may regain safety measures but
lose the task-specific knowledge acquired during downstream fine-tuning. In
this paper, we introduce a safety realignment framework through
subspace-oriented model fusion (SOMF), aiming to combine the safeguard
capabilities of initially aligned model and the current fine-tuned model into a
realigned model. Our approach begins by disentangling all task vectors from the
weights of each fine-tuned model. We then identify safety-related regions
within these vectors by subspace masking techniques. Finally, we explore the
fusion of the initial safely aligned LLM with all task vectors based on the
identified safety subspace. We validate that our safety realignment framework
satisfies the safety requirements of a single fine-tuned model as well as
multiple models during their fusion. Our findings confirm that SOMF preserves
safety without notably compromising performance on downstream tasks, including
instruction following in Chinese, English, and Hindi, as well as
problem-solving capabilities in Code and Math.",2024-05-15,"Xin Yi, Shunfan Zheng, Linlin Wang, Xiaoling Wang, Liang He",http://arxiv.org/pdf/2405.09055v1,cs.CL
A Japanese-Chinese Parallel Corpus Using Crowdsourcing for Web Mining,"Using crowdsourcing, we collected more than 10,000 URL pairs (parallel top
page pairs) of bilingual websites that contain parallel documents and created a
Japanese-Chinese parallel corpus of 4.6M sentence pairs from these websites. We
used a Japanese-Chinese bilingual dictionary of 160K word pairs for document
and sentence alignment. We then used high-quality 1.2M Japanese-Chinese
sentence pairs to train a parallel corpus filter based on statistical language
models and word translation probabilities. We compared the translation accuracy
of the model trained on these 4.6M sentence pairs with that of the model
trained on Japanese-Chinese sentence pairs from CCMatrix (12.4M), a parallel
corpus from global web mining. Although our corpus is only one-third the size
of CCMatrix, we found that the accuracy of the two models was comparable and
confirmed that it is feasible to use crowdsourcing for web mining of parallel
data.",2024-05-15,"Masaaki Nagata, Makoto Morishita, Katsuki Chousa, Norihito Yasuda",http://arxiv.org/pdf/2405.09017v1,cs.CL
Spatial Semantic Recurrent Mining for Referring Image Segmentation,"Referring Image Segmentation (RIS) consistently requires language and
appearance semantics to more understand each other. The need becomes acute
especially under hard situations. To achieve, existing works tend to resort to
various trans-representing mechanisms to directly feed forward language
semantic along main RGB branch, which however will result in referent
distribution weakly-mined in space and non-referent semantic contaminated along
channel. In this paper, we propose Spatial Semantic Recurrent Mining
(S\textsuperscript{2}RM) to achieve high-quality cross-modality fusion. It
follows a working strategy of trilogy: distributing language feature, spatial
semantic recurrent coparsing, and parsed-semantic balancing. During fusion,
S\textsuperscript{2}RM will first generate a constraint-weak yet
distribution-aware language feature, then bundle features of each row and
column from rotated features of one modality context to recurrently correlate
relevant semantic contained in feature from other modality context, and finally
resort to self-distilled weights to weigh on the contributions of different
parsed semantics. Via coparsing, S\textsuperscript{2}RM transports information
from the near and remote slice layers of generator context to the current slice
layer of parsed context, capable of better modeling global relationship
bidirectional and structured. Besides, we also propose a Cross-scale Abstract
Semantic Guided Decoder (CASG) to emphasize the foreground of the referent,
finally integrating different grained features at a comparatively low cost.
Extensive experimental results on four current challenging datasets show that
our proposed method performs favorably against other state-of-the-art
algorithms.",2024-05-15,"Jiaxing Yang, Lihe Zhang, Jiayu Sun, Huchuan Lu",http://arxiv.org/pdf/2405.09006v1,cs.CL
LLM-Assisted Rule Based Machine Translation for Low/No-Resource Languages,"We propose a new paradigm for machine translation that is particularly useful
for no-resource languages (those without any publicly available bilingual or
monolingual corpora): LLM-RBMT (LLM-Assisted Rule Based Machine Translation).
Using the LLM-RBMT paradigm, we design the first language
education/revitalization-oriented machine translator for Owens Valley Paiute
(OVP), a critically endangered Indigenous American language for which there is
virtually no publicly available data. We present a detailed evaluation of the
translator's components: a rule-based sentence builder, an OVP to English
translator, and an English to OVP translator. We also discuss the potential of
the paradigm, its limitations, and the many avenues for future research that it
opens up.",2024-05-14,"Jared Coleman, Bhaskar Krishnamachari, Khalil Iskarous, Ruben Rosales",http://arxiv.org/pdf/2405.08997v2,cs.CL
What is it for a Machine Learning Model to Have a Capability?,"What can contemporary machine learning (ML) models do? Given the
proliferation of ML models in society, answering this question matters to a
variety of stakeholders, both public and private. The evaluation of models'
capabilities is rapidly emerging as a key subfield of modern ML, buoyed by
regulatory attention and government grants. Despite this, the notion of an ML
model possessing a capability has not been interrogated: what are we saying
when we say that a model is able to do something? And what sorts of evidence
bear upon this question? In this paper, we aim to answer these questions, using
the capabilities of large language models (LLMs) as a running example. Drawing
on the large philosophical literature on abilities, we develop an account of ML
models' capabilities which can be usefully applied to the nascent science of
model evaluation. Our core proposal is a conditional analysis of model
abilities (CAMA): crudely, a machine learning model has a capability to X just
when it would reliably succeed at doing X if it 'tried'. The main contribution
of the paper is making this proposal precise in the context of ML, resulting in
an operationalisation of CAMA applicable to LLMs. We then put CAMA to work,
showing that it can help make sense of various features of ML model evaluation
practice, as well as suggest procedures for performing fair inter-model
comparisons.",2024-05-14,"Jacqueline Harding, Nathaniel Sharadin",http://arxiv.org/pdf/2405.08989v1,cs.CL
Challenges in Deploying Long-Context Transformers: A Theoretical Peak Performance Analysis,"Transformer-based long context generative models power emerging AI
applications like hour-long video understanding and project-level coding agent.
Deploying long context transformers (e.g., 100K to 10M tokens) is prohibitively
expensive compared to short context (e.g., 4K tokens) model variants. Reducing
the cost of long-context transformers is becoming a pressing research and
engineering challenge starting from the year of 2024. This work describes a
concurrent programming framework for quantitatively analyzing the efficiency
challenges in serving multiple long-context requests under limited size of GPU
high-bandwidth memory (HBM) regime. We give a detailed analysis of how all
additional computational costs, compared to 4K context, trace back to
\textit{one single source: the large size of the KV cache}. We use a 34B
GPT-3.5 level model of 50K context on A100 NVLink as a running example, and
describe how its large KV cache causes four types of deployment challenges: (1)
prefilling long inputs takes much longer compute time and GPU memory than short
inputs; (2) after prefilling, the large KV cache residing on the GPU HBM
substantially restricts the number of concurrent users being served; (3) during
decoding, repeatedly reading the KV cache from HBM to SM largely increases
latency; (4) when KV cache memory overflows, swapping it from HBM to DDR causes
significant context switching latency. We use this framework to analyze
existing works and identify possibilities of combining them to build end-to-end
systems. Overall, this work offers a foundational framework for analyzing long
context transformer deployment and identifies directions towards reducing the
inference cost of 1M context to be as cheap as 4K.",2024-05-14,Yao Fu,http://arxiv.org/pdf/2405.08944v1,cs.CL
Self-supervised vision-langage alignment of deep learning representations for bone X-rays analysis,"This paper proposes leveraging vision-language pretraining on bone X-rays
paired with French reports to address downstream tasks of interest on bone
radiography. A practical processing pipeline is introduced to anonymize and
process French medical reports. Pretraining then consists in the
self-supervised alignment of visual and textual embedding spaces derived from
deep model encoders. The resulting image encoder is then used to handle various
downstream tasks, including quantification of osteoarthritis, estimation of
bone age on pediatric wrists, bone fracture and anomaly detection. Our approach
demonstrates competitive performance on downstream tasks, compared to
alternatives requiring a significantly larger amount of human expert
annotations. Our work stands as the first study to integrate French reports to
shape the embedding space devoted to bone X-Rays representations, capitalizing
on the large quantity of paired images and reports data available in an
hospital. By relying on generic vision-laguage deep models in a
language-specific scenario, it contributes to the deployement of vision models
for wider healthcare applications.",2024-05-14,"Alexandre Englebert, Anne-Sophie Collin, Olivier Cornu, Christophe De Vleeschouwer",http://arxiv.org/pdf/2405.08932v1,cs.CL
Large Language Models for Human-Machine Collaborative Particle Accelerator Tuning through Natural Language,"Autonomous tuning of particle accelerators is an active and challenging field
of research with the goal of enabling novel accelerator technologies
cutting-edge high-impact applications, such as physics discovery, cancer
research and material sciences. A key challenge with autonomous accelerator
tuning remains that the most capable algorithms require an expert in
optimisation, machine learning or a similar field to implement the algorithm
for every new tuning task. In this work, we propose the use of large language
models (LLMs) to tune particle accelerators. We demonstrate on a
proof-of-principle example the ability of LLMs to successfully and autonomously
tune a particle accelerator subsystem based on nothing more than a natural
language prompt from the operator, and compare the performance of our LLM-based
solution to state-of-the-art optimisation algorithms, such as Bayesian
optimisation (BO) and reinforcement learning-trained optimisation (RLO). In
doing so, we also show how LLMs can perform numerical optimisation of a highly
non-linear real-world objective function. Ultimately, this work represents yet
another complex task that LLMs are capable of solving and promises to help
accelerate the deployment of autonomous tuning algorithms to the day-to-day
operations of particle accelerators.",2024-05-14,"Jan Kaiser, Annika Eichler, Anne Lauscher",http://arxiv.org/pdf/2405.08888v1,cs.CL
Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram,"We used a dictionary built from biomedical terminology extracted from various
sources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8
million Instagram posts by users who have mentioned an epilepsy-relevant drug
at least once, between 2010 and early 2016. A random sample of 1,771 posts with
2,947 term matches was evaluated by human annotators to identify
false-positives. OpenAI's GPT series models were compared against human
annotation. Frequent terms with a high false-positive rate were removed from
the dictionary. Analysis of the estimated false-positive rates of the annotated
terms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which
were removed from the original dictionary. To study the effect of removing
those terms, we constructed knowledge networks using the refined and the
original dictionaries and performed an eigenvector-centrality analysis on both
networks. We show that the refined dictionary thus produced leads to a
significantly different rank of important terms, as measured by their
eigenvector-centrality of the knowledge networks. Furthermore, the most
important terms obtained after refinement are of greater medical relevance. In
addition, we show that OpenAI's GPT series models fare worse than human
annotators in this task.",2024-05-14,"Aehong Min, Xuan Wang, Rion Brattig Correia, Jordan Rozum, Wendy R. Miller, Luis M. Rocha",http://arxiv.org/pdf/2405.08784v1,cs.CL
"Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs","Humans often express their communicative intents indirectly or non-literally,
which requires their interlocutors -- human or AI -- to understand beyond the
literal meaning of words. While most existing work has focused on
discriminative evaluations, we present a new approach to generatively evaluate
large language models' (LLMs') intention understanding by examining their
responses to non-literal utterances. Ideally, an LLM should respond in line
with the true intention of a non-literal utterance, not its literal
interpretation. Our findings show that LLMs struggle to generate pragmatically
relevant responses to non-literal language, achieving only 50-55% accuracy on
average. While explicitly providing oracle intentions significantly improves
performance (e.g., 75% for Mistral-Instruct), this still indicates challenges
in leveraging given intentions to produce appropriate responses. Using
chain-of-thought to make models spell out intentions yields much smaller gains
(60% for Mistral-Instruct). These findings suggest that LLMs are not yet
effective pragmatic interlocutors, highlighting the need for better approaches
for modeling intentions and utilizing them for pragmatic generation.",2024-05-14,"Akhila Yerukola, Saujas Vaduguru, Daniel Fried, Maarten Sap",http://arxiv.org/pdf/2405.08760v2,cs.CL
From Text to Context: An Entailment Approach for News Stakeholder Classification,"Navigating the complex landscape of news articles involves understanding the
various actors or entities involved, referred to as news stakeholders. These
stakeholders, ranging from policymakers to opposition figures, citizens, and
more, play pivotal roles in shaping news narratives. Recognizing their
stakeholder types, reflecting their roles, political alignments, social
standing, and more, is paramount for a nuanced comprehension of news content.
Despite existing works focusing on salient entity extraction, coverage
variations, and political affiliations through social media data, the automated
detection of stakeholder roles within news content remains an underexplored
domain. In this paper, we bridge this gap by introducing an effective approach
to classify stakeholder types in news articles. Our method involves
transforming the stakeholder classification problem into a natural language
inference task, utilizing contextual information from news articles and
external knowledge to enhance the accuracy of stakeholder type detection.
Moreover, our proposed model showcases efficacy in zero-shot settings, further
extending its applicability to diverse news contexts.",2024-05-14,"Alapan Kuila, Sudeshna Sarkar",http://arxiv.org/pdf/2405.08751v1,cs.CL
Targeted Augmentation for Low-Resource Event Extraction,"Addressing the challenge of low-resource information extraction remains an
ongoing issue due to the inherent information scarcity within limited training
examples. Existing data augmentation methods, considered potential solutions,
struggle to strike a balance between weak augmentation (e.g., synonym
augmentation) and drastic augmentation (e.g., conditional generation without
proper guidance). This paper introduces a novel paradigm that employs targeted
augmentation and back validation to produce augmented examples with enhanced
diversity, polarity, accuracy, and coherence. Extensive experimental results
demonstrate the effectiveness of the proposed paradigm. Furthermore, identified
limitations are discussed, shedding light on areas for future improvement.",2024-05-14,"Sijia Wang, Lifu Huang",http://arxiv.org/pdf/2405.08729v1,cs.CL
The Evolution of Darija Open Dataset: Introducing Version 2,"Darija Open Dataset (DODa) represents an open-source project aimed at
enhancing Natural Language Processing capabilities for the Moroccan dialect,
Darija. With approximately 100,000 entries, DODa stands as the largest
collaborative project of its kind for Darija-English translation. The dataset
features semantic and syntactic categorizations, variations in spelling, verb
conjugations across multiple tenses, as well as tens of thousands of translated
sentences. The dataset includes entries written in both Latin and Arabic
alphabets, reflecting the linguistic variations and preferences found in
different sources and applications. The availability of such dataset is
critical for developing applications that can accurately understand and
generate Darija, thus supporting the linguistic needs of the Moroccan community
and potentially extending to similar dialects in neighboring regions. This
paper explores the strategic importance of DODa, its current achievements, and
the envisioned future enhancements that will continue to promote its use and
expansion in the global NLP landscape.",2024-05-14,"Aissam Outchakoucht, Hamza Es-Samaali",http://arxiv.org/pdf/2405.13016v1,cs.CL
"Navigating LLM Ethics: Advancements, Challenges, and Future Directions","This study addresses ethical issues surrounding Large Language Models (LLMs)
within the field of artificial intelligence. It explores the common ethical
challenges posed by both LLMs and other AI systems, such as privacy and
fairness, as well as ethical challenges uniquely arising from LLMs. It
highlights challenges such as hallucination, verifiable accountability, and
decoding censorship complexity, which are unique to LLMs and distinct from
those encountered in traditional AI systems. The study underscores the need to
tackle these complexities to ensure accountability, reduce biases, and enhance
transparency in the influential role that LLMs play in shaping information
dissemination. It proposes mitigation strategies and future directions for LLM
ethics, advocating for interdisciplinary collaboration. It recommends ethical
frameworks tailored to specific domains and dynamic auditing systems adapted to
diverse contexts. This roadmap aims to guide responsible development and
integration of LLMs, envisioning a future where ethical considerations govern
AI advancements in society.",2024-05-14,"Junfeng Jiao, Saleh Afroogh, Yiming Xu, Connor Phillips",http://arxiv.org/pdf/2406.18841v4,cs.CL
Thinking Tokens for Language Modeling,"How much is 56 times 37? Language models often make mistakes in these types
of difficult calculations. This is usually explained by their inability to
perform complex reasoning. Since language models rely on large training sets
and great memorization capability, naturally they are not equipped to run
complex calculations. However, one can argue that humans also cannot perform
this calculation immediately and require a considerable amount of time to
construct the solution. In order to enhance the generalization capability of
language models, and as a parallel to human behavior, we propose to use special
'thinking tokens' which allow the model to perform much more calculations
whenever a complex problem is encountered.",2024-05-14,"David Herel, Tomas Mikolov",http://arxiv.org/pdf/2405.08644v1,cs.CL
ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation,"The field of chemistry and Artificial Intelligence (AI) intersection is an
area of active research that aims to accelerate scientific discovery. The
integration of large language models (LLMs) with scientific modalities has
shown significant promise in this endeavour. However, challenges persist in
effectively addressing training efficacy and the out-of-distribution problem,
particularly as existing approaches rely on larger models and datasets. In this
context, we focus on machine language-molecule translation and deploy a novel
training approach called contrastive preference optimisation, which avoids
generating translations that are merely adequate but not perfect. To ensure
generalisability and mitigate memorisation effects, we conduct experiments
using only 10% of the data. Our results demonstrate that our models achieve up
to a 32% improvement compared to counterpart models. Finally, we introduce a
fine-grained, domain-agnostic evaluation method to assess hallucination in LLMs
and promote responsible use.",2024-05-14,Dimitris Gkoumas,http://arxiv.org/pdf/2405.08619v3,cs.CL
Assisted Debate Builder with Large Language Models,"We introduce ADBL2, an assisted debate builder tool. It is based on the
capability of large language models to generalise and perform relation-based
argument mining in a wide-variety of domains. It is the first open-source tool
that leverages relation-based mining for (1) the verification of
pre-established relations in a debate and (2) the assisted creation of new
arguments by means of large language models. ADBL2 is highly modular and can
work with any open-source large language models that are used as plugins. As a
by-product, we also provide the first fine-tuned Mistral-7B large language
model for relation-based argument mining, usable by ADBL2, which outperforms
existing approaches for this task with an overall F1-score of 90.59% across all
domains.",2024-05-14,"Elliot Faugier, Frédéric Armetta, Angela Bonifati, Bruno Yun",http://arxiv.org/pdf/2405.13015v1,cs.CL
A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine,"Since the release of ChatGPT and GPT-4, large language models (LLMs) and
multimodal large language models (MLLMs) have attracted widespread attention
for their exceptional capabilities in understanding, reasoning, and generation,
introducing transformative paradigms for integrating artificial intelligence
into medicine. This survey provides a comprehensive overview of the
development, principles, application scenarios, challenges, and future
directions of LLMs and MLLMs in medicine. Specifically, it begins by examining
the paradigm shift, tracing the transition from traditional models to LLMs and
MLLMs, and highlighting the unique advantages of these LLMs and MLLMs in
medical applications. Next, the survey reviews existing medical LLMs and MLLMs,
providing detailed guidance on their construction and evaluation in a clear and
systematic manner. Subsequently, to underscore the substantial value of LLMs
and MLLMs in healthcare, the survey explores five promising applications in the
field. Finally, the survey addresses the challenges confronting medical LLMs
and MLLMs and proposes practical strategies and future directions for their
integration into medicine. In summary, this survey offers a comprehensive
analysis of the technical methodologies and practical clinical applications of
medical LLMs and MLLMs, with the goal of bridging the gap between these
advanced technologies and clinical practice, thereby fostering the evolution of
the next generation of intelligent healthcare systems.",2024-05-14,"Hanguang Xiao, Feizhong Zhou, Xingyue Liu, Tianqi Liu, Zhipeng Li, Xin Liu, Xiaoxuan Huang",http://arxiv.org/pdf/2405.08603v3,cs.CL
QCRD: Quality-guided Contrastive Rationale Distillation for Large Language Models,"The deployment of large language models (LLMs) faces considerable challenges
concerning resource constraints and inference efficiency. Recent research has
increasingly focused on smaller, task-specific models enhanced by distilling
knowledge from LLMs. However, prior studies have often overlooked the diversity
and quality of knowledge, especially the untapped potential of negative
knowledge. Constructing effective negative knowledge remains severely
understudied. In this paper, we introduce a novel framework called
quality-guided contrastive rationale distillation aimed at enhancing reasoning
capabilities through contrastive knowledge learning. For positive knowledge, we
enrich its diversity through temperature sampling and employ self-consistency
for further denoising and refinement. For negative knowledge, we propose an
innovative self-adversarial approach that generates low-quality rationales by
sampling previous iterations of smaller language models, embracing the idea
that one can learn from one's own weaknesses. A contrastive loss is developed
to distill both positive and negative knowledge into smaller language models,
where an online-updating discriminator is integrated to assess qualities of
rationales and assign them appropriate weights, optimizing the training
process. Through extensive experiments across multiple reasoning tasks, we
demonstrate that our method consistently outperforms existing distillation
techniques, yielding higher-quality rationales.",2024-05-14,"Wei Wang, Zhaowei Li, Qi Xu, Yiqing Cai, Hang Song, Qi Qi, Ran Zhou, Zhida Huang, Tao Wang, Li Xiao",http://arxiv.org/pdf/2405.13014v2,cs.CL
Rethinking the adaptive relationship between Encoder Layers and Decoder Layers,"This article explores the adaptive relationship between Encoder Layers and
Decoder Layers using the SOTA model Helsinki-NLP/opus-mt-de-en, which
translates German to English. The specific method involves introducing a
bias-free fully connected layer between the Encoder and Decoder, with different
initializations of the layer's weights, and observing the outcomes of
fine-tuning versus retraining. Four experiments were conducted in total. The
results suggest that directly modifying the pre-trained model structure for
fine-tuning yields suboptimal performance. However, upon observing the outcomes
of the experiments with retraining, this structural adjustment shows
significant potential.",2024-05-14,Yubo Song,http://arxiv.org/pdf/2405.08570v1,cs.CL
Sonos Voice Control Bias Assessment Dataset: A Methodology for Demographic Bias Assessment in Voice Assistants,"Recent works demonstrate that voice assistants do not perform equally well
for everyone, but research on demographic robustness of speech technologies is
still scarce. This is mainly due to the rarity of large datasets with
controlled demographic tags. This paper introduces the Sonos Voice Control Bias
Assessment Dataset, an open dataset composed of voice assistant requests for
North American English in the music domain (1,038 speakers, 166 hours, 170k
audio samples, with 9,040 unique labelled transcripts) with a controlled
demographic diversity (gender, age, dialectal region and ethnicity). We also
release a statistical demographic bias assessment methodology, at the
univariate and multivariate levels, tailored to this specific use case and
leveraging spoken language understanding metrics rather than transcription
accuracy, which we believe is a better proxy for user experience. To
demonstrate the capabilities of this dataset and statistical method to detect
demographic bias, we consider a pair of state-of-the-art Automatic Speech
Recognition and Spoken Language Understanding models. Results show
statistically significant differences in performance across age, dialectal
region and ethnicity. Multivariate tests are crucial to shed light on mixed
effects between dialectal region, gender and age.",2024-05-14,"Chloé Sekkat, Fanny Leroy, Salima Mdhaffar, Blake Perry Smith, Yannick Estève, Joseph Dureau, Alice Coucke",http://arxiv.org/pdf/2405.19342v1,cs.CL
The Unseen Targets of Hate -- A Systematic Review of Hateful Communication Datasets,"Machine learning (ML)-based content moderation tools are essential to keep
online spaces free from hateful communication. Yet, ML tools can only be as
capable as the quality of the data they are trained on allows them. While there
is increasing evidence that they underperform in detecting hateful
communications directed towards specific identities and may discriminate
against them, we know surprisingly little about the provenance of such bias. To
fill this gap, we present a systematic review of the datasets for the automated
detection of hateful communication introduced over the past decade, and unpack
the quality of the datasets in terms of the identities that they embody: those
of the targets of hateful communication that the data curators focused on, as
well as those unintentionally included in the datasets. We find, overall, a
skewed representation of selected target identities and mismatches between the
targets that research conceptualizes and ultimately includes in datasets. Yet,
by contextualizing these findings in the language and location of origin of the
datasets, we highlight a positive trend towards the broadening and
diversification of this research space.",2024-05-14,"Zehui Yu, Indira Sen, Dennis Assenmacher, Mattia Samory, Leon Fröhling, Christina Dahn, Debora Nozza, Claudia Wagner",http://arxiv.org/pdf/2405.08562v1,cs.CL
Improving Transformers with Dynamically Composable Multi-Head Attention,"Multi-Head Attention (MHA) is a key component of Transformer. In MHA,
attention heads work independently, causing problems such as low-rank
bottleneck of attention score matrices and head redundancy. We propose
Dynamically Composable Multi-Head Attention (DCMHA), a parameter and
computation efficient attention architecture that tackles the shortcomings of
MHA and increases the expressive power of the model by dynamically composing
attention heads. At the core of DCMHA is a $\it{Compose}$ function that
transforms the attention score and weight matrices in an input-dependent way.
DCMHA can be used as a drop-in replacement of MHA in any transformer
architecture to obtain the corresponding DCFormer. DCFormer significantly
outperforms Transformer on different architectures and model scales in language
modeling, matching the performance of models with ~1.7x-2.0x compute. For
example, DCPythia-6.9B outperforms open source Pythia-12B on both pretraining
perplexity and downstream task evaluation. The code and models are available at
https://github.com/Caiyun-AI/DCFormer.",2024-05-14,"Da Xiao, Qingye Meng, Shengping Li, Xingyuan Yuan",http://arxiv.org/pdf/2405.08553v2,cs.CL
Analysing Cross-Speaker Convergence in Face-to-Face Dialogue through the Lens of Automatically Detected Shared Linguistic Constructions,"Conversation requires a substantial amount of coordination between dialogue
participants, from managing turn taking to negotiating mutual understanding.
Part of this coordination effort surfaces as the reuse of linguistic behaviour
across speakers, a process often referred to as alignment. While the presence
of linguistic alignment is well documented in the literature, several questions
remain open, including the extent to which patterns of reuse across speakers
have an impact on the emergence of labelling conventions for novel referents.
In this study, we put forward a methodology for automatically detecting shared
lemmatised constructions -- expressions with a common lexical core used by both
speakers within a dialogue -- and apply it to a referential communication
corpus where participants aim to identify novel objects for which no
established labels exist. Our analyses uncover the usage patterns of shared
constructions in interaction and reveal that features such as their frequency
and the amount of different constructions used for a referent are associated
with the degree of object labelling convergence the participants exhibit after
social interaction. More generally, the present study shows that automatically
detected shared constructions offer a useful level of analysis to investigate
the dynamics of reference negotiation in dialogue.",2024-05-14,"Esam Ghaleb, Marlou Rasenberg, Wim Pouw, Ivan Toni, Judith Holler, Aslı Özyürek, Raquel Fernández",http://arxiv.org/pdf/2405.08546v1,cs.CL
A Prompt-driven Task Planning Method for Multi-drones based on Large Language Model,"With the rapid development of drone technology, the application of
multi-drones is becoming increasingly widespread in various fields. However,
the task planning technology for multi-drones still faces challenges such as
the complexity of remote operation and the convenience of human-machine
interaction. To address these issues, this paper proposes a prompt-driven task
planning method for multi-drones based on large language models. By introducing
the Prompt technique, appropriate prompt information is provided for the
multi-drone system.",2024-05-14,Yaohua Liu,http://arxiv.org/pdf/2406.00006v1,cs.CL
Falcon 7b for Software Mention Detection in Scholarly Documents,"This paper aims to tackle the challenge posed by the increasing integration
of software tools in research across various disciplines by investigating the
application of Falcon-7b for the detection and classification of software
mentions within scholarly texts. Specifically, the study focuses on solving
Subtask I of the Software Mention Detection in Scholarly Publications (SOMD),
which entails identifying and categorizing software mentions from academic
literature. Through comprehensive experimentation, the paper explores different
training strategies, including a dual-classifier approach, adaptive sampling,
and weighted loss scaling, to enhance detection accuracy while overcoming the
complexities of class imbalance and the nuanced syntax of scholarly writing.
The findings highlight the benefits of selective labelling and adaptive
sampling in improving the model's performance. However, they also indicate that
integrating multiple strategies does not necessarily result in cumulative
improvements. This research offers insights into the effective application of
large language models for specific tasks such as SOMD, underlining the
importance of tailored approaches to address the unique challenges presented by
academic text analysis.",2024-05-14,"AmeerAli Khan, Qusai Ramadan, Cong Yang, Zeyd Boukhers",http://arxiv.org/pdf/2405.08514v1,cs.CL
Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure,"The SemEval task on Argument Reasoning in Civil Procedure is challenging in
that it requires understanding legal concepts and inferring complex arguments.
Currently, most Large Language Models (LLM) excelling in the legal realm are
principally purposed for classification tasks, hence their reasoning rationale
is subject to contention. The approach we advocate involves using a powerful
teacher-LLM (ChatGPT) to extend the training dataset with explanations and
generate synthetic data. The resulting data are then leveraged to fine-tune a
small student-LLM. Contrary to previous work, our explanations are not directly
derived from the teacher's internal knowledge. Instead they are grounded in
authentic human analyses, therefore delivering a superior reasoning signal.
Additionally, a new `mutation' method generates artificial data instances
inspired from existing ones. We are publicly releasing the explanations as an
extension to the original dataset, along with the synthetic dataset and the
prompts that were used to generate both. Our system ranked 15th in the SemEval
competition. It outperforms its own teacher and can produce explanations
aligned with the original human analyses, as verified by legal experts.",2024-05-14,"Odysseas S. Chlapanis, Ion Androutsopoulos, Dimitrios Galanis",http://arxiv.org/pdf/2405.08502v1,cs.CL
"Is Less More? Quality, Quantity and Context in Idiom Processing with Natural Language Models","Compositionality in language models presents a problem when processing
idiomatic expressions, as their meaning often cannot be directly derived from
their individual parts. Although fine-tuning and other optimization strategies
can be used to improve representations of idiomatic expressions, this depends
on the availability of relevant data. We present the Noun Compound Synonym
Substitution in Books - NCSSB - datasets, which are created by substitution of
synonyms of potentially idiomatic English noun compounds in public domain book
texts. We explore the trade-off between data quantity and quality when training
models for idiomaticity detection, in conjunction with contextual information
obtained locally (from the surrounding sentences) or externally (through
language resources). Performance on an idiomaticity detection task indicates
that dataset quality is a stronger factor for context-enriched models, but that
quantity also plays a role in models without context inclusion strategies.",2024-05-14,"Agne Knietaite, Adam Allsebrook, Anton Minkov, Adam Tomaszewski, Norbert Slinko, Richard Johnson, Thomas Pickard, Dylan Phelps, Aline Villavicencio",http://arxiv.org/pdf/2405.08497v1,cs.CL
When Large Language Models Meet Optical Networks: Paving the Way for Automation,"Since the advent of GPT, large language models (LLMs) have brought about
revolutionary advancements in all walks of life. As a superior natural language
processing (NLP) technology, LLMs have consistently achieved state-of-the-art
performance on numerous areas. However, LLMs are considered to be
general-purpose models for NLP tasks, which may encounter challenges when
applied to complex tasks in specialized fields such as optical networks. In
this study, we propose a framework of LLM-empowered optical networks,
facilitating intelligent control of the physical layer and efficient
interaction with the application layer through an LLM-driven agent (AI-Agent)
deployed in the control layer. The AI-Agent can leverage external tools and
extract domain knowledge from a comprehensive resource library specifically
established for optical networks. This is achieved through user input and
well-crafted prompts, enabling the generation of control instructions and
result representations for autonomous operation and maintenance in optical
networks. To improve LLM's capability in professional fields and stimulate its
potential on complex tasks, the details of performing prompt engineering,
establishing domain knowledge library, and implementing complex tasks are
illustrated in this study. Moreover, the proposed framework is verified on two
typical tasks: network alarm analysis and network performance optimization. The
good response accuracies and sematic similarities of 2,400 test situations
exhibit the great potential of LLM in optical networks.",2024-05-14,"Danshi Wang, Yidi Wang, Xiaotian Jiang, Yao Zhang, Yue Pang, Min Zhang",http://arxiv.org/pdf/2405.17441v2,cs.CL
Amplifying Aspect-Sentence Awareness: A Novel Approach for Aspect-Based Sentiment Analysis,"Aspect-Based Sentiment Analysis (ABSA) is increasingly crucial in Natural
Language Processing (NLP) for applications such as customer feedback analysis
and product recommendation systems. ABSA goes beyond traditional sentiment
analysis by extracting sentiments related to specific aspects mentioned in the
text; existing attention-based models often need help to effectively connect
aspects with context due to language complexity and multiple sentiment
polarities in a single sentence. Recent research underscores the value of
integrating syntactic information, such as dependency trees, to understand
long-range syntactic relationships better and link aspects with context.
Despite these advantages, challenges persist, including sensitivity to parsing
errors and increased computational complexity when combining syntactic and
semantic information. To address these issues, we propose Amplifying
Aspect-Sentence Awareness (A3SN), a novel technique designed to enhance ABSA
through amplifying aspect-sentence awareness attention. Following the
transformer's standard process, our innovative approach incorporates multi-head
attention mechanisms to augment the model with sentence and aspect semantic
information. We added another multi-head attention module: amplify
aspect-sentence awareness attention. By doubling its focus between the sentence
and aspect, we effectively highlighted aspect importance within the sentence
context. This enables accurate capture of subtle relationships and
dependencies. Additionally, gated fusion integrates feature representations
from multi-head and amplified aspect-sentence awareness attention mechanisms,
which is essential for ABSA. Experimental results across three benchmark
datasets demonstrate A3SN's effectiveness and outperform state-of-the-art
(SOTA) baseline models.",2024-05-14,"Adamu Lawan, Juhua Pu, Haruna Yunusa, Jawad Muhammad, Aliyu Umar",http://arxiv.org/pdf/2405.13013v2,cs.CL
Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models,"Machine translation (MT) models are known to suffer from gender bias,
especially when translating into languages with extensive gendered morphology.
Accordingly, they still fall short in using gender-inclusive language, also
representative of non-binary identities. In this paper, we look at
gender-inclusive neomorphemes, neologistic elements that avoid binary gender
markings as an approach towards fairer MT. In this direction, we explore
prompting techniques with large language models (LLMs) to translate from
English into Italian using neomorphemes. So far, this area has been
under-explored due to its novelty and the lack of publicly available evaluation
resources. We fill this gap by releasing Neo-GATE, a resource designed to
evaluate gender-inclusive en-it translation with neomorphemes. With Neo-GATE,
we assess four LLMs of different families and sizes and different prompt
formats, identifying strengths and weaknesses of each on this novel task for
MT.",2024-05-14,"Andrea Piergentili, Beatrice Savoldi, Matteo Negri, Luisa Bentivogli",http://arxiv.org/pdf/2405.08477v1,cs.CL
GPT-3.5 for Grammatical Error Correction,"This paper investigates the application of GPT-3.5 for Grammatical Error
Correction (GEC) in multiple languages in several settings: zero-shot GEC,
fine-tuning for GEC, and using GPT-3.5 to re-rank correction hypotheses
generated by other GEC models. In the zero-shot setting, we conduct automatic
evaluations of the corrections proposed by GPT-3.5 using several methods:
estimating grammaticality with language models (LMs), the Scribendi test, and
comparing the semantic embeddings of sentences. GPT-3.5 has a known tendency to
over-correct erroneous sentences and propose alternative corrections. For
several languages, such as Czech, German, Russian, Spanish, and Ukrainian,
GPT-3.5 substantially alters the source sentences, including their semantics,
which presents significant challenges for evaluation with reference-based
metrics. For English, GPT-3.5 demonstrates high recall, generates fluent
corrections, and generally preserves sentence semantics. However, human
evaluation for both English and Russian reveals that, despite its strong
error-detection capabilities, GPT-3.5 struggles with several error types,
including punctuation mistakes, tense errors, syntactic dependencies between
words, and lexical compatibility at the sentence level.",2024-05-14,"Anisia Katinskaia, Roman Yangarber",http://arxiv.org/pdf/2405.08469v1,cs.CL
Challenges and Opportunities in Text Generation Explainability,"The necessity for interpretability in natural language processing (NLP) has
risen alongside the growing prominence of large language models. Among the
myriad tasks within NLP, text generation stands out as a primary objective of
autoregressive models. The NLP community has begun to take a keen interest in
gaining a deeper understanding of text generation, leading to the development
of model-agnostic explainable artificial intelligence (xAI) methods tailored to
this task. The design and evaluation of explainability methods are non-trivial
since they depend on many factors involved in the text generation process,
e.g., the autoregressive model and its stochastic nature. This paper outlines
17 challenges categorized into three groups that arise during the development
and assessment of attribution-based explainability methods. These challenges
encompass issues concerning tokenization, defining explanation similarity,
determining token importance and prediction change metrics, the level of human
intervention required, and the creation of suitable test datasets. The paper
illustrates how these challenges can be intertwined, showcasing new
opportunities for the community. These include developing probabilistic
word-level explainability methods and engaging humans in the explainability
pipeline, from the data design to the final evaluation, to draw robust
conclusions on xAI methods.",2024-05-14,"Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady",http://arxiv.org/pdf/2405.08468v1,cs.CL
Is Your LLM Outdated? A Deep Look at Temporal Generalization,"The rapid advancement of Large Language Models (LLMs) has led to the
development of benchmarks that consider temporal dynamics, however, there
remains a gap in understanding how well these models can generalize across
temporal contexts due to the inherent dynamic nature of language and
information. This paper introduces the concept of temporal generalization in
LLMs, including bias in past and future generalizations. Then we introduce
FreshBench, a new evaluation framework that employs fresh text and event
prediction for assessing LLMs' temporal adaptability, ensuring the evaluation
process free from data leakage and subjective bias. The experiment shows
significant temporal biases and a decline in performance over time. Our
findings reveal that powerful models, while initially superior, tend to decline
more rapidly in future generalization. Additionally, powerful open-source
models demonstrate better long-term adaptability compared to their
closed-source counterparts. Our code is available at
https://github.com/FreedomIntelligence/FreshBench.",2024-05-14,"Chenghao Zhu, Nuo Chen, Yufei Gao, Yunyi Zhang, Prayag Tiwari, Benyou Wang",http://arxiv.org/pdf/2405.08460v3,cs.CL
Alignment Helps Make the Most of Multimodal Data,"When studying political communication, combining the information from text,
audio, and video signals promises to reflect the richness of human
communication more comprehensively than confining it to individual modalities
alone. However, its heterogeneity, connectedness, and interaction are
challenging to address when modeling such multimodal data. We argue that
aligning the respective modalities can be an essential step in entirely using
the potential of multimodal data because it informs the model with human
understanding. Taking care of the data-generating process of multimodal data,
our framework proposes four principles to organize alignment and, thus, address
the challenges of multimodal data. We illustrate the utility of these
principles by analyzing how German MPs address members of the far-right AfD in
their speeches and predicting the tone of video advertising in the context of
the 2020 US presidential race. Our paper offers important insights to all keen
to analyze multimodal data effectively.",2024-05-14,"Christian Arnold, Andreas Küpfer",http://arxiv.org/pdf/2405.08454v2,cs.CL
"Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline","Stickers are increasingly used in social media to express sentiment and
intent. When finding typing troublesome, people often use a sticker instead.
Despite the significant impact of stickers on sentiment analysis and intent
recognition, little research has been conducted. To address this gap, we
propose a new task: Multimodal chat Sentiment Analysis and Intent Recognition
involving Stickers (MSAIRS). Additionally, we introduce a novel multimodal
dataset containing Chinese chat records and stickers excerpted from several
mainstream social media platforms. Our dataset includes paired data with the
same text but different stickers, and various stickers consisting of the same
images with different texts, allowing us to better understand the impact of
stickers on chat sentiment and intent. We also propose an effective multimodal
joint model, MMSAIR, for our task, which is validated on our datasets and
indicates that visual information of stickers counts. Our dataset and code will
be publicly available.",2024-05-14,"Yuanchen Shi, Biao Ma, Fang Kong",http://arxiv.org/pdf/2405.08427v1,cs.CL
Investigating the 'Autoencoder Behavior' in Speech Self-Supervised Models: a focus on HuBERT's Pretraining,"Self-supervised learning has shown great success in Speech Recognition.
However, it has been observed that finetuning all layers of the learned model
leads to lower performance compared to resetting top layers. This phenomenon is
attributed to the ''autoencoder'' behavior: top layers contain information
closer to the input and are less suitable for tasks that require linguistic
information, such as Speech Recognition.To better our understanding of this
behavior, we propose to study the evolution of high-level information within
the model during pretraining. We focus on the HuBERT model, which exhibits a
less pronounced ''autoencoder'' behavior. By experimentally exploring various
factors that may have an impact, we aim to improve the training procedure and
enhance the top layers of HuBERT for high-level tasks.Furthermore, our
experiments demonstrate that these improvements in the training procedure
result in faster convergence and competitive performance on downstream tasks.",2024-05-14,Valentin Vielzeuf,http://arxiv.org/pdf/2405.08402v1,cs.CL
Stylometric Watermarks for Large Language Models,"The rapid advancement of large language models (LLMs) has made it
increasingly difficult to distinguish between text written by humans and
machines. Addressing this, we propose a novel method for generating watermarks
that strategically alters token probabilities during generation. Unlike
previous works, this method uniquely employs linguistic features such as
stylometry. Concretely, we introduce acrostica and sensorimotor norms to LLMs.
Further, these features are parameterized by a key, which is updated every
sentence. To compute this key, we use semantic zero shot classification, which
enhances resilience. In our evaluation, we find that for three or more
sentences, our method achieves a false positive and false negative rate of
0.02. For the case of a cyclic translation attack, we observe similar results
for seven or more sentences. This research is of particular of interest for
proprietary LLMs to facilitate accountability and prevent societal harm.",2024-05-14,"Georg Niess, Roman Kern",http://arxiv.org/pdf/2405.08400v1,cs.CL
PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation using Ensemble LLMs,"This paper presents our approach to the EHRSQL-2024 shared task, which aims
to develop a reliable Text-to-SQL system for electronic health records. We
propose two approaches that leverage large language models (LLMs) for prompting
and fine-tuning to generate EHRSQL queries. In both techniques, we concentrate
on bridging the gap between the real-world knowledge on which LLMs are trained
and the domain specific knowledge required for the task. The paper provides the
results of each approach individually, demonstrating that they achieve high
execution accuracy. Additionally, we show that an ensemble approach further
enhances generation reliability by reducing errors. This approach secured us
2nd place in the shared task competition. The methodologies outlined in this
paper are designed to be transferable to domain-specific Text-to-SQL problems
that emphasize both accuracy and reliability.",2024-05-14,"Satya K Gundabathula, Sriram R Kolar",http://arxiv.org/pdf/2405.08839v1,cs.CL
On the Connection Between Non-negative Matrix Factorization and Latent Dirichlet Allocation,"Non-negative matrix factorization with the generalized Kullback-Leibler
divergence (NMF) and latent Dirichlet allocation (LDA) are two popular
approaches for dimensionality reduction of non-negative data. Here, we show
that NMF with $\ell_1$ normalization constraints on the columns of both
matrices of the decomposition and a Dirichlet prior on the columns of one
matrix is equivalent to LDA. To show this, we demonstrate that explicitly
accounting for the scaling ambiguity of NMF by adding $\ell_1$ normalization
constraints to the optimization problem allows a joint update of both matrices
in the widely used multiplicative updates (MU) algorithm. When both of the
matrices are normalized, the joint MU algorithm leads to probabilistic latent
semantic analysis (PLSA), which is LDA without a Dirichlet prior. Our approach
of deriving joint updates for NMF also reveals that a Lasso penalty on one
matrix together with an $\ell_1$ normalization constraint on the other matrix
is insufficient to induce any sparsity.",2024-05-30,"Benedikt Geiger, Peter J. Park",http://arxiv.org/pdf/2405.20542v1,cs.LG
Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models,"In this work, we investigate whether small language models can determine
high-quality subsets of large-scale text datasets that improve the performance
of larger language models. While existing work has shown that pruning based on
the perplexity of a larger model can yield high-quality data, we investigate
whether smaller models can be used for perplexity-based pruning and how pruning
is affected by the domain composition of the data being pruned. We demonstrate
that for multiple dataset compositions, perplexity-based pruning of pretraining
data can \emph{significantly} improve downstream task performance: pruning
based on perplexities computed with a 125 million parameter model improves the
average performance on downstream tasks of a 3 billion parameter model by up to
2.04 and achieves up to a $1.45\times$ reduction in pretraining steps to reach
commensurate baseline performance. Furthermore, we demonstrate that such
perplexity-based data pruning also yields downstream performance gains in the
over-trained and data-constrained regimes.",2024-05-30,"Zachary Ankner, Cody Blakeney, Kartik Sreenivasan, Max Marion, Matthew L. Leavitt, Mansheej Paul",http://arxiv.org/pdf/2405.20541v1,cs.LG
Fully Unconstrained Online Learning,"We provide an online learning algorithm that obtains regret
$G\|w_\star\|\sqrt{T\log(\|w_\star\|G\sqrt{T})} + \|w_\star\|^2 + G^2$ on
$G$-Lipschitz convex losses for any comparison point $w_\star$ without knowing
either $G$ or $\|w_\star\|$. Importantly, this matches the optimal bound
$G\|w_\star\|\sqrt{T}$ available with such knowledge (up to logarithmic
factors), unless either $\|w_\star\|$ or $G$ is so large that even
$G\|w_\star\|\sqrt{T}$ is roughly linear in $T$. Thus, it matches the optimal
bound in all cases in which one can achieve sublinear regret, which arguably
most ""interesting"" scenarios.",2024-05-30,"Ashok Cutkosky, Zakaria Mhammedi",http://arxiv.org/pdf/2405.20540v1,cs.LG
SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents,"Reinforcement learning (RL) is an actively growing field that is seeing
increased usage in real-world, safety-critical applications -- making it
paramount to ensure the robustness of RL algorithms against adversarial
attacks. In this work we explore a particularly stealthy form of training-time
attacks against RL -- backdoor poisoning. Here the adversary intercepts the
training of an RL agent with the goal of reliably inducing a particular action
when the agent observes a pre-determined trigger at inference time. We uncover
theoretical limitations of prior work by proving their inability to generalize
across domains and MDPs. Motivated by this, we formulate a novel poisoning
attack framework which interlinks the adversary's objectives with those of
finding an optimal policy -- guaranteeing attack success in the limit. Using
insights from our theoretical analysis we develop ``SleeperNets'' as a
universal backdoor attack which exploits a newly proposed threat model and
leverages dynamic reward poisoning techniques. We evaluate our attack in 6
environments spanning multiple domains and demonstrate significant improvements
in attack success over existing methods, while preserving benign episodic
return.",2024-05-30,"Ethan Rathbun, Christopher Amato, Alina Oprea",http://arxiv.org/pdf/2405.20539v2,cs.LG
Q-learning as a monotone scheme,"Stability issues with reinforcement learning methods persist. To better
understand some of these stability and convergence issues involving deep
reinforcement learning methods, we examine a simple linear quadratic example.
We interpret the convergence criterion of exact Q-learning in the sense of a
monotone scheme and discuss consequences of function approximation on
monotonicity properties.",2024-05-30,Lingyi Yang,http://arxiv.org/pdf/2405.20538v1,cs.LG
Aquatic Navigation: A Challenging Benchmark for Deep Reinforcement Learning,"An exciting and promising frontier for Deep Reinforcement Learning (DRL) is
its application to real-world robotic systems. While modern DRL approaches
achieved remarkable successes in many robotic scenarios (including mobile
robotics, surgical assistance, and autonomous driving) unpredictable and
non-stationary environments can pose critical challenges to such methods. These
features can significantly undermine fundamental requirements for a successful
training process, such as the Markovian properties of the transition model. To
address this challenge, we propose a new benchmarking environment for aquatic
navigation using recent advances in the integration between game engines and
DRL. In more detail, we show that our benchmarking environment is problematic
even for state-of-the-art DRL approaches that may struggle to generate reliable
policies in terms of generalization power and safety. Specifically, we focus on
PPO, one of the most widely accepted algorithms, and we propose advanced
training techniques (such as curriculum learning and learnable
hyperparameters). Our extensive empirical evaluation shows that a well-designed
combination of these ingredients can achieve promising results. Our simulation
environment and training baselines are freely available to facilitate further
research on this open problem and encourage collaboration in the field.",2024-05-30,"Davide Corsi, Davide Camponogara, Alessandro Farinelli",http://arxiv.org/pdf/2405.20534v1,cs.LG
Mitigating the Impact of Labeling Errors on Training via Rockafellian Relaxation,"Labeling errors in datasets are common, arising in a variety of contexts,
such as human labeling, noisy labeling, and weak labeling (i.e., image
classification). Although neural networks (NNs) can tolerate modest amounts of
these errors, their performance degrades substantially once error levels exceed
a certain threshold. We propose a new loss reweighting,
architecture-independent methodology, Rockafellian Relaxation Method (RRM) for
neural network training. Experiments indicate RRM can enhance neural network
methods to achieve robust performance across classification tasks in computer
vision and natural language processing (sentiment analysis). We find that RRM
can mitigate the effects of dataset contamination stemming from both (heavy)
labeling error and/or adversarial perturbation, demonstrating effectiveness
across a variety of data domains and machine learning tasks.",2024-05-30,"Louis L. Chen, Bobbie Chern, Eric Eckstrand, Amogh Mahapatra, Johannes O. Royset",http://arxiv.org/pdf/2405.20531v2,cs.LG
WaveCastNet: An AI-enabled Wavefield Forecasting Framework for Earthquake Early Warning,"Large earthquakes can be destructive and quickly wreak havoc on a landscape.
To mitigate immediate threats, early warning systems have been developed to
alert residents, emergency responders, and critical infrastructure operators
seconds to a minute before seismic waves arrive. These warnings provide time to
take precautions and prevent damage. The success of these systems relies on
fast, accurate predictions of ground motion intensities, which is challenging
due to the complex physics of earthquakes, wave propagation, and their
intricate spatial and temporal interactions. To improve early warning, we
propose a novel AI-enabled framework, WaveCastNet, for forecasting ground
motions from large earthquakes. WaveCastNet integrates a novel convolutional
Long Expressive Memory (ConvLEM) model into a sequence to sequence (seq2seq)
forecasting framework to model long-term dependencies and multi-scale patterns
in both space and time. WaveCastNet, which shares weights across spatial and
temporal dimensions, requires fewer parameters compared to more
resource-intensive models like transformers and thus, in turn, reduces
inference times. Importantly, WaveCastNet also generalizes better than
transformer-based models to different seismic scenarios, including to more rare
and critical situations with higher magnitude earthquakes. Our results using
simulated data from the San Francisco Bay Area demonstrate the capability to
rapidly predict the intensity and timing of destructive ground motions.
Importantly, our proposed approach does not require estimating earthquake
magnitudes and epicenters, which are prone to errors using conventional
approaches; nor does it require empirical ground motion models, which fail to
capture strongly heterogeneous wave propagation effects.",2024-05-30,"Dongwei Lyu, Rie Nakata, Pu Ren, Michael W. Mahoney, Arben Pitarka, Nori Nakata, N. Benjamin Erichson",http://arxiv.org/pdf/2405.20516v1,cs.LG
Deep Modeling of Non-Gaussian Aleatoric Uncertainty,"Deep learning offers promising new ways to accurately model aleatoric
uncertainty in robotic state estimation systems, particularly when the
uncertainty distributions do not conform to traditional assumptions of being
fixed and Gaussian. In this study, we formulate and evaluate three fundamental
deep learning approaches for conditional probability density modeling to
quantify non-Gaussian aleatoric uncertainty: parametric, discretized, and
generative modeling. We systematically compare the respective strengths and
weaknesses of these three methods on simulated non-Gaussian densities as well
as on real-world terrain-relative navigation data. Our results show that these
deep learning methods can accurately capture complex uncertainty patterns,
highlighting their potential for improving the reliability and robustness of
estimation systems.",2024-05-30,"Aastha Acharya, Caleb Lee, Marissa D'Alonzo, Jared Shamwell, Nisar R. Ahmed, Rebecca Russell",http://arxiv.org/pdf/2405.20513v2,cs.LG
How Multilingual Are Large Language Models Fine-Tuned for Translation?,"A new paradigm for machine translation has recently emerged: fine-tuning
large language models (LLM) on parallel text has been shown to outperform
dedicated translation systems trained in a supervised fashion on much larger
amounts of parallel data (Xu et al., 2024a; Alves et al., 2024). However, it
remains unclear whether this paradigm can enable massively multilingual machine
translation or whether it requires fine-tuning dedicated models for a small
number of language pairs. How does translation fine-tuning impact the MT
capabilities of LLMs for zero-shot languages, zero-shot language pairs, and
translation tasks that do not involve English? To address these questions, we
conduct an extensive empirical evaluation of the translation quality of the
TOWER family of language models (Alves et al., 2024) on 132 translation tasks
from the multi-parallel FLORES-200 data. We find that translation fine-tuning
improves translation quality even for zero-shot languages on average, but that
the impact is uneven depending on the language pairs involved. These results
call for further research to effectively enable massively multilingual
translation with LLMs.",2024-05-30,"Aquia Richburg, Marine Carpuat",http://arxiv.org/pdf/2405.20512v1,cs.LG
SPOT: Text Source Prediction from Originality Score Thresholding,"The wide acceptance of large language models (LLMs) has unlocked new
applications and social risks. Popular countermeasures aim at detecting
misinformation, usually involve domain specific models trained to recognize the
relevance of any information. Instead of evaluating the validity of the
information, we propose to investigate LLM generated text from the perspective
of trust. In this study, we define trust as the ability to know if an input
text was generated by a LLM or a human. To do so, we design SPOT, an efficient
method, that classifies the source of any, standalone, text input based on
originality score. This score is derived from the prediction of a given LLM to
detect other LLMs. We empirically demonstrate the robustness of the method to
the architecture, training data, evaluation data, task and compression of
modern LLMs.",2024-05-30,"Edouard Yvinec, Gabriel Kasser",http://arxiv.org/pdf/2405.20505v1,cs.LG
FCOM: A Federated Collaborative Online Monitoring Framework via Representation Learning,"Online learning has demonstrated notable potential to dynamically allocate
limited resources to monitor a large population of processes, effectively
balancing the exploitation of processes yielding high rewards, and the
exploration of uncertain processes. However, most online learning algorithms
were designed under 1) a centralized setting that requires data sharing across
processes to obtain an accurate prediction or 2) a homogeneity assumption that
estimates a single global model from the decentralized data. To facilitate the
online learning of heterogeneous processes from the decentralized data, we
propose a federated collaborative online monitoring method, which captures the
latent representative models inherent in the population through representation
learning and designs a novel federated collaborative UCB algorithm to estimate
the representative models from sequentially observed decentralized data. The
efficiency of our method is illustrated through theoretical analysis,
simulation studies, and decentralized cognitive degradation monitoring in
Alzheimer's disease.",2024-05-30,"Tanapol Kosolwattana, Huazheng Wang, Raed Al Kontar, Ying Lin",http://arxiv.org/pdf/2405.20504v1,cs.LG
Optimizing cnn-Bigru performance: Mish activation and comparative analysis with Relu,"Deep learning is currently extensively employed across a range of research
domains. The continuous advancements in deep learning techniques contribute to
solving intricate challenges. Activation functions (AF) are fundamental
components within neural networks, enabling them to capture complex patterns
and relationships in the data. By introducing non-linearities, AF empowers
neural networks to model and adapt to the diverse and nuanced nature of
real-world data, enhancing their ability to make accurate predictions across
various tasks. In the context of intrusion detection, the Mish, a recent AF,
was implemented in the CNN-BiGRU model, using three datasets: ASNM-TUN,
ASNM-CDX, and HOGZILLA. The comparison with Rectified Linear Unit (ReLU), a
widely used AF, revealed that Mish outperforms ReLU, showcasing superior
performance across the evaluated datasets. This study illuminates the
effectiveness of AF in elevating the performance of intrusion detection
systems.",2024-05-30,"Asmaa Benchama, Khalid Zebbara",http://arxiv.org/pdf/2405.20503v1,cs.LG
Deep Learning Approaches for Detecting Adversarial Cyberbullying and Hate Speech in Social Networks,"Cyberbullying is a significant concern intricately linked to technology that
can find resolution through technological means. Despite its prevalence,
technology also provides solutions to mitigate cyberbullying. To address
growing concerns regarding the adverse impact of cyberbullying on individuals'
online experiences, various online platforms and researchers are actively
adopting measures to enhance the safety of digital environments. While
researchers persist in crafting detection models to counteract or minimize
cyberbullying, malicious actors are deploying adversarial techniques to
circumvent these detection methods. This paper focuses on detecting
cyberbullying in adversarial attack content within social networking site text
data, specifically emphasizing hate speech. Utilizing a deep learning-based
approach with a correction algorithm, this paper yielded significant results.
An LSTM model with a fixed epoch of 100 demonstrated remarkable performance,
achieving high accuracy, precision, recall, F1-score, and AUC-ROC scores of
87.57%, 88.73%, 87.57%, 88.15%, and 91% respectively. Additionally, the LSTM
model's performance surpassed that of previous studies.",2024-05-30,"Sylvia Worlali Azumah, Nelly Elsayed, Zag ElSayed, Murat Ozer, Amanda La Guardia",http://arxiv.org/pdf/2406.17793v1,cs.LG
ShelfHelp: Empowering Humans to Perform Vision-Independent Manipulation Tasks with a Socially Assistive Robotic Cane,"The ability to shop independently, especially in grocery stores, is important
for maintaining a high quality of life. This can be particularly challenging
for people with visual impairments (PVI). Stores carry thousands of products,
with approximately 30,000 new products introduced each year in the US market
alone, presenting a challenge even for modern computer vision solutions.
Through this work, we present a proof-of-concept socially assistive robotic
system we call ShelfHelp, and propose novel technical solutions for enhancing
instrumented canes traditionally meant for navigation tasks with additional
capability within the domain of shopping. ShelfHelp includes a novel visual
product locator algorithm designed for use in grocery stores and a novel
planner that autonomously issues verbal manipulation guidance commands to guide
the user during product retrieval. Through a human subjects study, we show the
system's success in locating and providing effective manipulation guidance to
retrieve desired products with novice users. We compare two autonomous verbal
guidance modes achieving comparable performance to a human assistance baseline
and present encouraging findings that validate our system's efficiency and
effectiveness and through positive subjective metrics including competence,
intelligence, and ease of use.",2024-05-30,"Shivendra Agrawal, Suresh Nayak, Ashutosh Naik, Bradley Hayes",http://arxiv.org/pdf/2405.20501v1,cs.LG
Hybrid Reinforcement Learning Framework for Mixed-Variable Problems,"Optimization problems characterized by both discrete and continuous variables
are common across various disciplines, presenting unique challenges due to
their complex solution landscapes and the difficulty of navigating
mixed-variable spaces effectively. To Address these challenges, we introduce a
hybrid Reinforcement Learning (RL) framework that synergizes RL for discrete
variable selection with Bayesian Optimization for continuous variable
adjustment. This framework stands out by its strategic integration of RL and
continuous optimization techniques, enabling it to dynamically adapt to the
problem's mixed-variable nature. By employing RL for exploring discrete
decision spaces and Bayesian Optimization to refine continuous parameters, our
approach not only demonstrates flexibility but also enhances optimization
performance. Our experiments on synthetic functions and real-world machine
learning hyperparameter tuning tasks reveal that our method consistently
outperforms traditional RL, random search, and standalone Bayesian optimization
in terms of effectiveness and efficiency.",2024-05-30,"Haoyan Zhai, Qianli Hu, Jiangning Chen",http://arxiv.org/pdf/2405.20500v1,cs.LG
Transfer Q Star: Principled Decoding for LLM Alignment,"Aligning foundation models is essential for their safe and trustworthy
deployment. However, traditional fine-tuning methods are computationally
intensive and require updating billions of model parameters. A promising
alternative, alignment via decoding, adjusts the response distribution directly
without model updates to maximize a target reward $r$, thus providing a
lightweight and adaptable framework for alignment. However, principled decoding
methods rely on oracle access to an optimal Q-function ($Q^*$), which is often
unavailable in practice. Hence, prior SoTA methods either approximate this
$Q^*$ using $Q^{\pi_{\texttt{sft}}}$ (derived from the reference $\texttt{SFT}$
model) or rely on short-term rewards, resulting in sub-optimal decoding
performance. In this work, we propose Transfer $Q^*$, which implicitly
estimates the optimal value function for a target reward $r$ through a baseline
model $\rho_{\texttt{BL}}$ aligned with a baseline reward $\rho_{\texttt{BL}}$
(which can be different from the target reward $r$). Theoretical analyses of
Transfer $Q^*$ provide a rigorous characterization of its optimality, deriving
an upper bound on the sub-optimality gap and identifying a hyperparameter to
control the deviation from the pre-trained reference $\texttt{SFT}$ model based
on user needs. Our approach significantly reduces the sub-optimality gap
observed in prior SoTA methods and demonstrates superior empirical performance
across key metrics such as coherence, diversity, and quality in extensive tests
on several synthetic and real datasets.",2024-05-30,"Souradip Chakraborty, Soumya Suvra Ghosal, Ming Yin, Dinesh Manocha, Mengdi Wang, Amrit Singh Bedi, Furong Huang",http://arxiv.org/pdf/2405.20495v1,cs.LG
Slight Corruption in Pre-training Data Makes Better Diffusion Models,"Diffusion models (DMs) have shown remarkable capabilities in generating
realistic high-quality images, audios, and videos. They benefit significantly
from extensive pre-training on large-scale datasets, including web-crawled data
with paired data and conditions, such as image-text and image-class pairs.
Despite rigorous filtering, these pre-training datasets often inevitably
contain corrupted pairs where conditions do not accurately describe the data.
This paper presents the first comprehensive study on the impact of such
corruption in pre-training data of DMs. We synthetically corrupt ImageNet-1K
and CC3M to pre-train and evaluate over 50 conditional DMs. Our empirical
findings reveal that various types of slight corruption in pre-training can
significantly enhance the quality, diversity, and fidelity of the generated
images across different DMs, both during pre-training and downstream adaptation
stages. Theoretically, we consider a Gaussian mixture model and prove that
slight corruption in the condition leads to higher entropy and a reduced
2-Wasserstein distance to the ground truth of the data distribution generated
by the corruptly trained DMs. Inspired by our analysis, we propose a simple
method to improve the training of DMs on practical datasets by adding condition
embedding perturbations (CEP). CEP significantly improves the performance of
various DMs in both pre-training and downstream tasks. We hope that our study
provides new insights into understanding the data and pre-training processes of
DMs and all models are released at https://huggingface.co/DiffusionNoise.",2024-05-30,"Hao Chen, Yujin Han, Diganta Misra, Xiang Li, Kai Hu, Difan Zou, Masashi Sugiyama, Jindong Wang, Bhiksha Raj",http://arxiv.org/pdf/2405.20494v2,cs.LG
Policy Trees for Prediction: Interpretable and Adaptive Model Selection for Machine Learning,"As a multitude of capable machine learning (ML) models become widely
available in forms such as open-source software and public APIs, central
questions remain regarding their use in real-world applications, especially in
high-stakes decision-making. Is there always one best model that should be
used? When are the models likely to be error-prone? Should a black-box or
interpretable model be used? In this work, we develop a prescriptive
methodology to address these key questions, introducing a tree-based approach,
Optimal Predictive-Policy Trees (OP2T), that yields interpretable policies for
adaptively selecting a predictive model or ensemble, along with a parameterized
option to reject making a prediction. We base our methods on learning globally
optimized prescriptive trees. Our approach enables interpretable and adaptive
model selection and rejection while only assuming access to model outputs. By
learning policies over different feature spaces, including the model outputs,
our approach works with both structured and unstructured datasets. We evaluate
our approach on real-world datasets, including regression and classification
tasks with both structured and unstructured data. We demonstrate that our
approach provides both strong performance against baseline methods while
yielding insights that help answer critical questions about which models to
use, and when.",2024-05-30,"Dimitris Bertsimas, Matthew Peroni",http://arxiv.org/pdf/2405.20486v1,cs.LG
Phantom: General Trigger Attacks on Retrieval Augmented Language Generation,"Retrieval Augmented Generation (RAG) expands the capabilities of modern large
language models (LLMs), by anchoring, adapting, and personalizing their
responses to the most relevant knowledge sources. It is particularly useful in
chatbot applications, allowing developers to customize LLM output without
expensive retraining. Despite their significant utility in various
applications, RAG systems present new security risks. In this work, we propose
new attack vectors that allow an adversary to inject a single malicious
document into a RAG system's knowledge base, and mount a backdoor poisoning
attack. We design Phantom, a general two-stage optimization framework against
RAG systems, that crafts a malicious poisoned document leading to an integrity
violation in the model's output. First, the document is constructed to be
retrieved only when a specific trigger sequence of tokens appears in the
victim's queries. Second, the document is further optimized with crafted
adversarial text that induces various adversarial objectives on the LLM output,
including refusal to answer, reputation damage, privacy violations, and harmful
behaviors. We demonstrate our attacks on multiple LLM architectures, including
Gemma, Vicuna, and Llama, and show that they transfer to GPT-3.5 Turbo and
GPT-4. Finally, we successfully conducted a Phantom attack on NVIDIA's
black-box production RAG system, ""Chat with RTX"".",2024-05-30,"Harsh Chaudhari, Giorgio Severi, John Abascal, Matthew Jagielski, Christopher A. Choquette-Choo, Milad Nasr, Cristina Nita-Rotaru, Alina Oprea",http://arxiv.org/pdf/2405.20485v2,cs.LG
Sparsity regularization via tree-structured environments for disentangled representations,"Many causal systems such as biological processes in cells can only be
observed indirectly via measurements, such as gene expression. Causal
representation learning -- the task of correctly mapping low-level observations
to latent causal variables -- could advance scientific understanding by
enabling inference of latent variables such as pathway activation. In this
paper, we develop methods for inferring latent variables from multiple related
datasets (environments) and tasks. As a running example, we consider the task
of predicting a phenotype from gene expression, where we often collect data
from multiple cell types or organisms that are related in known ways. The key
insight is that the mapping from latent variables driven by gene expression to
the phenotype of interest changes sparsely across closely related environments.
To model sparse changes, we introduce Tree-Based Regularization (TBR), an
objective that minimizes both prediction error and regularizes closely related
environments to learn similar predictors. We prove that under assumptions about
the degree of sparse changes, TBR identifies the true latent variables up to
some simple transformations. We evaluate the theory empirically with both
simulations and ground-truth gene expression data. We find that TBR recovers
the latent causal variables better than related methods across these settings,
even under settings that violate some assumptions of the theory.",2024-05-30,"Elliot Layne, Jason Hartford, Sébastien Lachapelle, Mathieu Blanchette, Dhanya Sridhar",http://arxiv.org/pdf/2405.20482v2,cs.LG
Contextual Counting: A Mechanistic Study of Transformers on a Quantitative Task,"Transformers have revolutionized machine learning across diverse domains, yet
understanding their behavior remains crucial, particularly in high-stakes
applications. This paper introduces the contextual counting task, a novel toy
problem aimed at enhancing our understanding of Transformers in quantitative
and scientific contexts. This task requires precise localization and
computation within datasets, akin to object detection or region-based
scientific analysis. We present theoretical and empirical analysis using both
causal and non-causal Transformer architectures, investigating the influence of
various positional encodings on performance and interpretability. In
particular, we find that causal attention is much better suited for the task,
and that no positional embeddings lead to the best accuracy, though rotary
embeddings are competitive and easier to train. We also show that out of
distribution performance is tightly linked to which tokens it uses as a bias
term.",2024-05-30,"Siavash Golkar, Alberto Bietti, Mariel Pettee, Michael Eickenberg, Miles Cranmer, Keiya Hirashima, Geraud Krawezik, Nicholas Lourie, Michael McCabe, Rudy Morel, Ruben Ohana, Liam Holden Parker, Bruno Régaldo-Saint Blancard, Kyunghyun Cho, Shirley Ho",http://arxiv.org/pdf/2406.02585v1,cs.LG
A Scoping Review of Earth Observation and Machine Learning for Causal Inference: Implications for the Geography of Poverty,"Earth observation (EO) data such as satellite imagery can have far-reaching
impacts on our understanding of the geography of poverty, especially when
coupled with machine learning (ML) and computer vision. Early research used
computer vision to predict living conditions in areas with limited data, but
recent studies increasingly focus on causal analysis. Despite this shift, the
use of EO-ML methods for causal inference lacks thorough documentation, and
best practices are still developing. Through a comprehensive scoping review, we
catalog the current literature on EO-ML methods in causal analysis. We
synthesize five principal approaches to incorporating EO data in causal
workflows: (1) outcome imputation for downstream causal analysis, (2) EO image
deconfounding, (3) EO-based treatment effect heterogeneity, (4) EO-based
transportability analysis, and (5) image-informed causal discovery. Building on
these findings, we provide a detailed protocol guiding researchers in
integrating EO data into causal analysis -- covering data requirements,
computer vision model selection, and evaluation metrics. While our focus
centers on health and living conditions outcomes, our protocol is adaptable to
other sustainable development domains utilizing EO data.",2024-05-30,"Kazuki Sakamoto, Connor T. Jerzak, Adel Daoud",http://arxiv.org/pdf/2406.02584v4,cs.LG
Exploring the Potential of Polynomial Basis Functions in Kolmogorov-Arnold Networks: A Comparative Study of Different Groups of Polynomials,"This paper presents a comprehensive survey of 18 distinct polynomials and
their potential applications in Kolmogorov-Arnold Network (KAN) models as an
alternative to traditional spline-based methods. The polynomials are classified
into various groups based on their mathematical properties, such as orthogonal
polynomials, hypergeometric polynomials, q-polynomials, Fibonacci-related
polynomials, combinatorial polynomials, and number-theoretic polynomials. The
study aims to investigate the suitability of these polynomials as basis
functions in KAN models for complex tasks like handwritten digit classification
on the MNIST dataset. The performance metrics of the KAN models, including
overall accuracy, Kappa, and F1 score, are evaluated and compared. The
Gottlieb-KAN model achieves the highest performance across all metrics,
suggesting its potential as a suitable choice for the given task. However,
further analysis and tuning of these polynomials on more complex datasets are
necessary to fully understand their capabilities in KAN models. The source code
for the implementation of these KAN models is available at
https://github.com/seydi1370/Basis_Functions .",2024-05-30,Seyd Teymoor Seydi,http://arxiv.org/pdf/2406.02583v2,cs.LG
MTEB-French: Resources for French Sentence Embedding Evaluation and Analysis,"Recently, numerous embedding models have been made available and widely used
for various NLP tasks. The Massive Text Embedding Benchmark (MTEB) has
primarily simplified the process of choosing a model that performs well for
several tasks in English, but extensions to other languages remain challenging.
This is why we expand MTEB to propose the first massive benchmark of sentence
embeddings for French. We gather 15 existing datasets in an easy-to-use
interface and create three new French datasets for a global evaluation of 8
task categories. We compare 51 carefully selected embedding models on a large
scale, conduct comprehensive statistical tests, and analyze the correlation
between model performance and many of their characteristics. We find out that
even if no model is the best on all tasks, large multilingual models
pre-trained on sentence similarity perform exceptionally well. Our work comes
with open-source code, new datasets and a public leaderboard.",2024-05-30,"Mathieu Ciancone, Imene Kerboua, Marion Schaeffer, Wissam Siblini",http://arxiv.org/pdf/2405.20468v2,cs.LG
Performance of NPG in Countable State-Space Average-Cost RL,"We consider policy optimization methods in reinforcement learning settings
where the state space is arbitrarily large, or even countably infinite. The
motivation arises from control problems in communication networks, matching
markets, and other queueing systems. Specifically, we consider the popular
Natural Policy Gradient (NPG) algorithm, which has been studied in the past
only under the assumption that the cost is bounded and the state space is
finite, neither of which holds for the aforementioned control problems.
Assuming a Lyapunov drift condition, which is naturally satisfied in some cases
and can be satisfied in other cases at a small cost in performance, we design a
state-dependent step-size rule which dramatically improves the performance of
NPG for our intended applications. In addition to experimentally verifying the
performance improvement, we also theoretically show that the iteration
complexity of NPG can be made independent of the size of the state space. The
key analytical tool we use is the connection between NPG step-sizes and the
solution to Poisson's equation. In particular, we provide policy-independent
bounds on the solution to Poisson's equation, which are then used to guide the
choice of NPG step-sizes.",2024-05-30,"Yashaswini Murthy, Isaac Grosof, Siva Theja Maguluri, R. Srikant",http://arxiv.org/pdf/2405.20467v2,cs.LG
ENTIRe-ID: An Extensive and Diverse Dataset for Person Re-Identification,"The growing importance of person reidentification in computer vision has
highlighted the need for more extensive and diverse datasets. In response, we
introduce the ENTIRe-ID dataset, an extensive collection comprising over 4.45
million images from 37 different cameras in varied environments. This dataset
is uniquely designed to tackle the challenges of domain variability and model
generalization, areas where existing datasets for person re-identification have
fallen short. The ENTIRe-ID dataset stands out for its coverage of a wide array
of real-world scenarios, encompassing various lighting conditions, angles of
view, and diverse human activities. This design ensures a realistic and robust
training platform for ReID models. The ENTIRe-ID dataset is publicly available
at https://serdaryildiz.github.io/ENTIRe-ID",2024-05-30,"Serdar Yildiz, Ahmet Nezih Kasim",http://arxiv.org/pdf/2405.20465v1,cs.LG
Scaling Laws for the Value of Individual Data Points in Machine Learning,"Recent works have shown that machine learning models improve at a predictable
rate with the total amount of training data, leading to scaling laws that
describe the relationship between error and dataset size. These scaling laws
can help design a model's training dataset, but they typically take an
aggregate view of the data by only considering the dataset's size. We introduce
a new perspective by investigating scaling behavior for the value of individual
data points: we find that a data point's contribution to model's performance
shrinks predictably with the size of the dataset in a log-linear manner.
Interestingly, there is significant variability in the scaling exponent among
different data points, indicating that certain points are more valuable in
small datasets while others are relatively more useful as a part of large
datasets. We provide learning theory to support our scaling law, and we observe
empirically that it holds across diverse model classes. We further propose a
maximum likelihood estimator and an amortized estimator to efficiently learn
the individualized scaling behaviors from a small number of noisy observations
per data point. Using our estimators, we provide insights into factors that
influence the scaling behavior of different data points. Finally, we
demonstrate applications of the individualized scaling laws to data valuation
and data subset selection. Overall, our work represents a first step towards
understanding and utilizing scaling properties for the value of individual data
points.",2024-05-30,"Ian Covert, Wenlong Ji, Tatsunori Hashimoto, James Zou",http://arxiv.org/pdf/2405.20456v1,cs.LG
Understanding Encoder-Decoder Structures in Machine Learning Using Information Measures,"We present new results to model and understand the role of encoder-decoder
design in machine learning (ML) from an information-theoretic angle. We use two
main information concepts, information sufficiency (IS) and mutual information
loss (MIL), to represent predictive structures in machine learning. Our first
main result provides a functional expression that characterizes the class of
probabilistic models consistent with an IS encoder-decoder latent predictive
structure. This result formally justifies the encoder-decoder forward stages
many modern ML architectures adopt to learn latent (compressed) representations
for classification. To illustrate IS as a realistic and relevant model
assumption, we revisit some known ML concepts and present some interesting new
examples: invariant, robust, sparse, and digital models. Furthermore, our IS
characterization allows us to tackle the fundamental question of how much
performance (predictive expressiveness) could be lost, using the cross entropy
risk, when a given encoder-decoder architecture is adopted in a learning
setting. Here, our second main result shows that a mutual information loss
quantifies the lack of expressiveness attributed to the choice of a (biased)
encoder-decoder ML design. Finally, we address the problem of universal
cross-entropy learning with an encoder-decoder design where necessary and
sufficiency conditions are established to meet this requirement. In all these
results, Shannon's information measures offer new interpretations and
explanations for representation learning.",2024-05-30,"Jorge F. Silva, Victor Faraggi, Camilo Ramirez, Alvaro Egana, Eduardo Pavez",http://arxiv.org/pdf/2405.20452v1,cs.LG
Statistical Properties of Robust Satisficing,"The Robust Satisficing (RS) model is an emerging approach to robust
optimization, offering streamlined procedures and robust generalization across
various applications. However, the statistical theory of RS remains unexplored
in the literature. This paper fills in the gap by comprehensively analyzing the
theoretical properties of the RS model. Notably, the RS structure offers a more
straightforward path to deriving statistical guarantees compared to the seminal
Distributionally Robust Optimization (DRO), resulting in a richer set of
results. In particular, we establish two-sided confidence intervals for the
optimal loss without the need to solve a minimax optimization problem
explicitly. We further provide finite-sample generalization error bounds for
the RS optimizer. Importantly, our results extend to scenarios involving
distribution shifts, where discrepancies exist between the sampling and target
distributions. Our numerical experiments show that the RS model consistently
outperforms the baseline empirical risk minimization in small-sample regimes
and under distribution shifts. Furthermore, compared to the DRO model, the RS
model exhibits lower sensitivity to hyperparameter tuning, highlighting its
practicability for robustness considerations.",2024-05-30,"Zhiyi Li, Yunbei Xu, Ruohan Zhan",http://arxiv.org/pdf/2405.20451v1,cs.LG
Knockout: A simple way to handle missing inputs,"Deep learning models can extract predictive and actionable information from
complex inputs. The richer the inputs, the better these models usually perform.
However, models that leverage rich inputs (e.g., multi-modality) can be
difficult to deploy widely, because some inputs may be missing at inference.
Current popular solutions to this problem include marginalization, imputation,
and training multiple models. Marginalization can obtain calibrated predictions
but it is computationally costly and therefore only feasible for low
dimensional inputs. Imputation may result in inaccurate predictions because it
employs point estimates for missing variables and does not work well for high
dimensional inputs (e.g., images). Training multiple models whereby each model
takes different subsets of inputs can work well but requires knowing missing
input patterns in advance. Furthermore, training and retaining multiple models
can be costly. We propose an efficient way to learn both the conditional
distribution using full inputs and the marginal distributions. Our method,
Knockout, randomly replaces input features with appropriate placeholder values
during training. We provide a theoretical justification of Knockout and show
that it can be viewed as an implicit marginalization strategy. We evaluate
Knockout in a wide range of simulations and real-world datasets and show that
it can offer strong empirical performance.",2024-05-30,"Minh Nguyen, Batuhan K. Karaman, Heejong Kim, Alan Q. Wang, Fengbei Liu, Mert R. Sabuncu",http://arxiv.org/pdf/2405.20448v2,cs.LG
Algorithmic Fairness in Performative Policy Learning: Escaping the Impossibility of Group Fairness,"In many prediction problems, the predictive model affects the distribution of
the prediction target. This phenomenon is known as performativity and is often
caused by the behavior of individuals with vested interests in the outcome of
the predictive model. Although performativity is generally problematic because
it manifests as distribution shifts, we develop algorithmic fairness practices
that leverage performativity to achieve stronger group fairness guarantees in
social classification problems (compared to what is achievable in
non-performative settings). In particular, we leverage the policymaker's
ability to steer the population to remedy inequities in the long term. A
crucial benefit of this approach is that it is possible to resolve the
incompatibilities between conflicting group fairness definitions.",2024-05-30,"Seamus Somerstep, Ya'acov Ritov, Yuekai Sun",http://arxiv.org/pdf/2405.20447v1,cs.LG
Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation,"Retrieval Augmented Generation (RAG) systems have shown great promise in
natural language processing. However, their reliance on data stored in a
retrieval database, which may contain proprietary or sensitive information,
introduces new privacy concerns. Specifically, an attacker may be able to infer
whether a certain text passage appears in the retrieval database by observing
the outputs of the RAG system, an attack known as a Membership Inference Attack
(MIA). Despite the significance of this threat, MIAs against RAG systems have
yet remained under-explored. This study addresses this gap by introducing an
efficient and easy-to-use method for conducting MIA against RAG systems. We
demonstrate the effectiveness of our attack using two benchmark datasets and
multiple generative models, showing that the membership of a document in the
retrieval database can be efficiently determined through the creation of an
appropriate prompt in both black-box and gray-box settings. Moreover, we
introduce an initial defense strategy based on adding instructions to the RAG
template, which shows high effectiveness for some datasets and models. Our
findings highlight the importance of implementing security countermeasures in
deployed RAG systems and developing more advanced defenses to protect the
privacy and security of retrieval databases.",2024-05-30,"Maya Anderson, Guy Amit, Abigail Goldsteen",http://arxiv.org/pdf/2405.20446v3,cs.LG
Fully-inductive Node Classification on Arbitrary Graphs,"One fundamental challenge in graph machine learning is generalizing to new
graphs. Many existing methods following the inductive setup can generalize to
test graphs with new structures, but assuming the feature and label spaces
remain the same as the training ones. This paper introduces a fully-inductive
setup, where models should perform inference on arbitrary test graphs with new
structures, feature and label spaces. We propose GraphAny as the first attempt
at this challenging setup. GraphAny models inference on a new graph as an
analytical solution to a LinearGNN, which can be naturally applied to graphs
with any feature and label spaces. To further build a stronger model with
learning capacity, we fuse multiple LinearGNN predictions with learned
inductive attention scores. Specifically, the attention module is carefully
parameterized as a function of the entropy-normalized distance features between
pairs of LinearGNN predictions to ensure generalization to new graphs.
Empirically, GraphAny trained on a single Wisconsin dataset with only 120
labeled nodes can generalize to 30 new graphs with an average accuracy of
67.26%, surpassing not only all inductive baselines, but also strong
transductive methods trained separately on each of the 30 test graphs.",2024-05-30,"Jianan Zhao, Zhaocheng Zhu, Mikhail Galkin, Hesham Mostafa, Michael Bronstein, Jian Tang",http://arxiv.org/pdf/2405.20445v5,cs.LG
Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning,"Sharpness-Aware Minimization (SAM) has emerged as a promising alternative
optimizer to stochastic gradient descent (SGD). The originally-proposed
motivation behind SAM was to bias neural networks towards flatter minima that
are believed to generalize better. However, recent studies have shown
conflicting evidence on the relationship between flatness and generalization,
suggesting that flatness does fully explain SAM's success. Sidestepping this
debate, we identify an orthogonal effect of SAM that is beneficial
out-of-distribution: we argue that SAM implicitly balances the quality of
diverse features. SAM achieves this effect by adaptively suppressing
well-learned features which gives remaining features opportunity to be learned.
We show that this mechanism is beneficial in datasets that contain redundant or
spurious features where SGD falls for the simplicity bias and would not
otherwise learn all available features. Our insights are supported by
experiments on real data: we demonstrate that SAM improves the quality of
features in datasets containing redundant or spurious features, including
CelebA, Waterbirds, CIFAR-MNIST, and DomainBed.",2024-05-30,"Jacob Mitchell Springer, Vaishnavh Nagarajan, Aditi Raghunathan",http://arxiv.org/pdf/2405.20439v1,cs.LG
Deep Learning for Computing Convergence Rates of Markov Chains,"Convergence rate analysis for general state-space Markov chains is
fundamentally important in areas such as Markov chain Monte Carlo and
algorithmic analysis (for computing explicit convergence bounds). This problem,
however, is notoriously difficult because traditional analytical methods often
do not generate practically useful convergence bounds for realistic Markov
chains. We propose the Deep Contractive Drift Calculator (DCDC), the first
general-purpose sample-based algorithm for bounding the convergence of Markov
chains to stationarity in Wasserstein distance. The DCDC has two components.
First, inspired by the new convergence analysis framework in (Qu et.al, 2023),
we introduce the Contractive Drift Equation (CDE), the solution of which leads
to an explicit convergence bound. Second, we develop an efficient
neural-network-based CDE solver. Equipped with these two components, DCDC
solves the CDE and converts the solution into a convergence bound. We analyze
the sample complexity of the algorithm and further demonstrate the
effectiveness of the DCDC by generating convergence bounds for realistic Markov
chains arising from stochastic processing networks as well as constant
step-size stochastic optimization.",2024-05-30,"Yanlin Qu, Jose Blanchet, Peter Glynn",http://arxiv.org/pdf/2405.20435v1,cs.LG
Exploring the Practicality of Federated Learning: A Survey Towards the Communication Perspective,"Federated Learning (FL) is a promising paradigm that offers significant
advancements in privacy-preserving, decentralized machine learning by enabling
collaborative training of models across distributed devices without
centralizing data. However, the practical deployment of FL systems faces a
significant bottleneck: the communication overhead caused by frequently
exchanging large model updates between numerous devices and a central server.
This communication inefficiency can hinder training speed, model performance,
and the overall feasibility of real-world FL applications. In this survey, we
investigate various strategies and advancements made in communication-efficient
FL, highlighting their impact and potential to overcome the communication
challenges inherent in FL systems. Specifically, we define measures for
communication efficiency, analyze sources of communication inefficiency in FL
systems, and provide a taxonomy and comprehensive review of state-of-the-art
communication-efficient FL methods. Additionally, we discuss promising future
research directions for enhancing the communication efficiency of FL systems.
By addressing the communication bottleneck, FL can be effectively applied and
enable scalable and practical deployment across diverse applications that
require privacy-preserving, decentralized machine learning, such as IoT,
healthcare, or finance.",2024-05-30,"Khiem Le, Nhan Luong-Ha, Manh Nguyen-Duc, Danh Le-Phuoc, Cuong Do, Kok-Seng Wong",http://arxiv.org/pdf/2405.20431v1,cs.LG
Spatiotemporal Predictions of Toxic Urban Plumes Using Deep Learning,"Industrial accidents, chemical spills, and structural fires can release large
amounts of harmful materials that disperse into urban atmospheres and impact
populated areas. Computer models are typically used to predict the transport of
toxic plumes by solving fluid dynamical equations. However, these models can be
computationally expensive due to the need for many grid cells to simulate
turbulent flow and resolve individual buildings and streets. In emergency
response situations, alternative methods are needed that can run quickly and
adequately capture important spatiotemporal features. Here, we present a novel
deep learning model called ST-GasNet that was inspired by the mathematical
equations that govern the behavior of plumes as they disperse through the
atmosphere. ST-GasNet learns the spatiotemporal dependencies from a limited set
of temporal sequences of ground-level toxic urban plumes generated by a
high-resolution large eddy simulation model. On independent sequences,
ST-GasNet accurately predicts the late-time spatiotemporal evolution, given the
early-time behavior as an input, even for cases when a building splits a large
plume into smaller plumes. By incorporating large-scale wind boundary condition
information, ST-GasNet achieves a prediction accuracy of at least 90% on test
data for the entire prediction period.",2024-05-30,"Yinan Wang, M. Giselle Fernández-Godino, Nipun Gunawardena, Donald D. Lucas, Xiaowei Yue",http://arxiv.org/pdf/2406.02582v1,cs.LG
Enhancing Performance for Highly Imbalanced Medical Data via Data Regularization in a Federated Learning Setting,"The increased availability of medical data has significantly impacted
healthcare by enabling the application of machine / deep learning approaches in
various instances. However, medical datasets are usually small and scattered
across multiple providers, suffer from high class-imbalance, and are subject to
stringent data privacy constraints. In this paper, the application of a data
regularization algorithm, suitable for learning under high class-imbalance, in
a federated learning setting is proposed. Specifically, the goal of the
proposed method is to enhance model performance for cardiovascular disease
prediction by tackling the class-imbalance that typically characterizes
datasets used for this purpose, as well as by leveraging patient data available
in different nodes of a federated ecosystem without compromising their privacy
and enabling more resource sensitive allocation. The method is evaluated across
four datasets for cardiovascular disease prediction, which are scattered across
different clients, achieving improved performance. Meanwhile, its robustness
under various hyperparameter settings, as well as its ability to adapt to
different resource allocation scenarios, is verified.",2024-05-30,"Georgios Tsoumplekas, Ilias Siniosoglou, Vasileios Argyriou, Ioannis D. Moscholios, Panagiotis Sarigiannidis",http://arxiv.org/pdf/2405.20430v1,cs.LG
"Fair Machine Learning for Healthcare Requires Recognizing the Intersectionality of Sociodemographic Factors, a Case Study","As interest in implementing artificial intelligence (AI) in medical systems
grows, discussion continues on how to evaluate the fairness of these systems,
or the disparities they may perpetuate. Socioeconomic status (SES) is commonly
included in machine learning models to control for health inequities, with the
underlying assumption that increased SES is associated with better health. In
this work, we considered a large cohort of patients from the Mount Sinai Health
System in New York City to investigate the effect of patient SES, race, and sex
on schizophrenia (SCZ) diagnosis rates via a logistic regression model. Within
an intersectional framework, patient SES, race, and sex were found to have
significant interactions. Our findings showed that increased SES is associated
with a higher probability of obtaining a SCZ diagnosis in Black Americans
($\beta=4.1\times10^{-8}$, $SE=4.5\times10^{-9}$, $p < 0.001$). Whereas high
SES acts as a protective factor for SCZ diagnosis in White Americans
($\beta=-4.1\times10^{-8}$, $SE=6.7\times10^{-9}$, $p < 0.001$). Further
investigation is needed to reliably explain and quantify health disparities.
Nevertheless, we advocate that building fair AI tools for the health care space
requires recognizing the intersectionality of sociodemographic factors.",2024-05-30,"Alissa A. Valentine, Alexander W. Charney, Isotta Landi",http://arxiv.org/pdf/2407.15006v1,cs.LG
Optimizing Photometric Light Curve Analysis: Evaluating Scipy's Minimize Function for Eclipse Mapping of Cataclysmic Variables,"With a particular focus on Scipy's minimize function the eclipse mapping
method is thoroughly researched and implemented utilizing Python and essential
libraries. Many optimization techniques are used, including Sequential Least
Squares Programming (SLSQP), Nelder-Mead, and Conjugate Gradient (CG). However,
for the purpose of examining photometric light curves these methods seek to
solve the maximum entropy equation under a chi-squared constraint. Therefore,
these techniques are first evaluated on two-dimensional Gaussian data without a
chi-squared restriction, and then they are used to map the accretion disc and
uncover the Gaussian structure of the Cataclysmic Variable KIC 201325107.
Critical analysis is performed on the code structure to find possible faults
and design problems. Additionally, the analysis shows how several factors
impacting computing time and image quality are included including the variance
in Gaussian weighting, disc image resolution, number of data points in the
light curve, and degree of constraint.",2024-05-30,"Anoop Kumar, Madan Mohan Tito Ayyalasomayajula, Dheerendra Panwar, Yeshwanth Vasa",http://arxiv.org/pdf/2406.00071v1,cs.LG
Back to the Basics on Predicting Transfer Performance,"In the evolving landscape of deep learning, selecting the best pre-trained
models from a growing number of choices is a challenge. Transferability scorers
propose alleviating this scenario, but their recent proliferation, ironically,
poses the challenge of their own assessment. In this work, we propose both
robust benchmark guidelines for transferability scorers, and a well-founded
technique to combine multiple scorers, which we show consistently improves
their results. We extensively evaluate 13 scorers from literature across 11
datasets, comprising generalist, fine-grained, and medical imaging datasets. We
show that few scorers match the predictive performance of the simple raw metric
of models on ImageNet, and that all predictors suffer on medical datasets. Our
results highlight the potential of combining different information sources for
reliably predicting transferability across varied domains.",2024-05-30,"Levy Chaves, Eduardo Valle, Alceu Bissoto, Sandra Avila",http://arxiv.org/pdf/2405.20420v1,cs.LG
Enhancing Antibiotic Stewardship using a Natural Language Approach for Better Feature Representation,"The rapid emergence of antibiotic-resistant bacteria is recognized as a
global healthcare crisis, undermining the efficacy of life-saving antibiotics.
This crisis is driven by the improper and overuse of antibiotics, which
escalates bacterial resistance. In response, this study explores the use of
clinical decision support systems, enhanced through the integration of
electronic health records (EHRs), to improve antibiotic stewardship. However,
EHR systems present numerous data-level challenges, complicating the effective
synthesis and utilization of data. In this work, we transform EHR data into a
serialized textual representation and employ pretrained foundation models to
demonstrate how this enhanced feature representation can aid in antibiotic
susceptibility predictions. Our results suggest that this text representation,
combined with foundation models, provides a valuable tool to increase
interpretability and support antibiotic stewardship efforts.",2024-05-30,"Simon A. Lee, Trevor Brokowski, Jeffrey N. Chiang",http://arxiv.org/pdf/2405.20419v1,cs.LG
The Impact of Ontology on the Prediction of Cardiovascular Disease Compared to Machine Learning Algorithms,"Cardiovascular disease is one of the chronic diseases that is on the rise.
The complications occur when cardiovascular disease is not discovered early and
correctly diagnosed at the right time. Various machine learning approaches,
including ontology-based Machine Learning techniques, have lately played an
essential role in medical science by building an automated system that can
identify heart illness. This paper compares and reviews the most prominent
machine learning algorithms, as well as ontology-based Machine Learning
classification. Random Forest, Logistic regression, Decision Tree, Naive Bayes,
k-Nearest Neighbours, Artificial Neural Network, and Support Vector Machine
were among the classification methods explored. The dataset used consists of
70000 instances and can be downloaded from the Kaggle website. The findings are
assessed using performance measures generated from the confusion matrix, such
as F-Measure, Accuracy, Recall, and Precision. The results showed that the
ontology outperformed all the machine learning algorithms.",2024-05-30,"Hakim El Massari, Noreddine Gherabi, Sajida Mhammedi, Hamza Ghandi, Mohamed Bahaj, Muhammad Raza Naqvi",http://arxiv.org/pdf/2405.20414v1,cs.LG
Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters,"Large Language Models (LLMs) are typically harmless but remain vulnerable to
carefully crafted prompts known as ``jailbreaks'', which can bypass protective
measures and induce harmful behavior. Recent advancements in LLMs have
incorporated moderation guardrails that can filter outputs, which trigger
processing errors for certain malicious questions. Existing red-teaming
benchmarks often neglect to include questions that trigger moderation
guardrails, making it difficult to evaluate jailbreak effectiveness. To address
this issue, we introduce JAMBench, a harmful behavior benchmark designed to
trigger and evaluate moderation guardrails. JAMBench involves 160 manually
crafted instructions covering four major risk categories at multiple severity
levels. Furthermore, we propose a jailbreak method, JAM (Jailbreak Against
Moderation), designed to attack moderation guardrails using jailbreak prefixes
to bypass input-level filters and a fine-tuned shadow model functionally
equivalent to the guardrail model to generate cipher characters to bypass
output-level filters. Our extensive experiments on four LLMs demonstrate that
JAM achieves higher jailbreak success ($\sim$ $\times$ 19.88) and lower
filtered-out rates ($\sim$ $\times$ 1/6) than baselines.",2024-05-30,"Haibo Jin, Andy Zhou, Joe D. Menke, Haohan Wang",http://arxiv.org/pdf/2405.20413v1,cs.LG
Audio2Rig: Artist-oriented deep learning tool for facial animation,"Creating realistic or stylized facial and lip sync animation is a tedious
task. It requires lot of time and skills to sync the lips with audio and convey
the right emotion to the character's face. To allow animators to spend more
time on the artistic and creative part of the animation, we present Audio2Rig:
a new deep learning based tool leveraging previously animated sequences of a
show, to generate facial and lip sync rig animation from an audio file. Based
in Maya, it learns from any production rig without any adjustment and generates
high quality and stylized animations which mimic the style of the show.
Audio2Rig fits in the animator workflow: since it generates keys on the rig
controllers, the animation can be easily retaken. The method is based on 3
neural network modules which can learn an arbitrary number of controllers.
Hence, different configurations can be created for specific parts of the face
(such as the tongue, lips or eyes). With Audio2Rig, animators can also pick
different emotions and adjust their intensities to experiment or customize the
output, and have high level controls on the keyframes setting. Our method shows
excellent results, generating fine animation details while respecting the show
style. Finally, as the training relies on the studio data and is done
internally, it ensures data privacy and prevents from copyright infringement.",2024-05-30,"Bastien Arcelin, Nicolas Chaverou",http://arxiv.org/pdf/2405.20412v1,cs.LG
Convolutional L2LFlows: Generating Accurate Showers in Highly Granular Calorimeters Using Convolutional Normalizing Flows,"In the quest to build generative surrogate models as computationally
efficient alternatives to rule-based simulations, the quality of the generated
samples remains a crucial frontier. So far, normalizing flows have been among
the models with the best fidelity. However, as the latent space in such models
is required to have the same dimensionality as the data space, scaling up
normalizing flows to high dimensional datasets is not straightforward. The
prior L2LFlows approach successfully used a series of separate normalizing
flows and sequence of conditioning steps to circumvent this problem. In this
work, we extend L2LFlows to simulate showers with a 9-times larger profile in
the lateral direction. To achieve this, we introduce convolutional layers and
U-Net-type connections, move from masked autoregressive flows to coupling
layers, and demonstrate the successful modelling of showers in the ILD
Electromagnetic Calorimeter as well as Dataset 3 from the public CaloChallenge
dataset.",2024-05-30,"Thorsten Buss, Frank Gaede, Gregor Kasieczka, Claudius Krause, David Shih",http://arxiv.org/pdf/2405.20407v3,cs.LG
Confidence-Aware Sub-Structure Beam Search (CABS): Mitigating Hallucination in Structured Data Generation with Large Language Models,"Large Language Models (LLMs) have facilitated structured data generation,
with applications in domains like tabular data, document databases, product
catalogs, etc. However, concerns persist about generation veracity due to
incorrect references or hallucinations, necessitating the incorporation of some
form of model confidence for mitigation. Existing confidence estimation methods
on LLM generations primarily focus on the confidence at the individual token
level or the entire output sequence level, limiting their applicability to
structured data generation, which consists of an intricate mix of both
independent and correlated entries at the sub-structure level. In this paper,
we first investigate confidence estimation methods for generated
sub-structure-level data. We introduce the concept of Confidence Network that
applies on the hidden state of the LLM transformer, as a more targeted estimate
than the traditional token conditional probability. We further propose
Confidence-Aware sub-structure Beam Search (CABS), a novel decoding method
operating at the sub-structure level in structured data generation. CABS
enhances the faithfulness of structured data generation by considering
confidence scores from the Confidence Network for each sub-structure-level data
and iteratively refining the prompts. Results show that CABS outperforms
traditional token-level beam search for structured data generation by 16.7%
Recall at 90% precision averagely on the problem of product attribute
generation.",2024-05-30,"Chengwei Wei, Kee Kiat Koo, Amir Tavanaei, Karim Bouyarmane",http://arxiv.org/pdf/2406.00069v1,cs.LG
Private Mean Estimation with Person-Level Differential Privacy,"We study person-level differentially private (DP) mean estimation in the case
where each person holds multiple samples. DP here requires the usual notion of
distributional stability when $\textit{all}$ of a person's datapoints can be
modified. Informally, if $n$ people each have $m$ samples from an unknown
$d$-dimensional distribution with bounded $k$-th moments, we show that \[n =
\tilde \Theta\left(\frac{d}{\alpha^2 m} + \frac{d}{\alpha m^{1/2} \varepsilon}
+ \frac{d}{\alpha^{k/(k-1)} m \varepsilon} + \frac{d}{\varepsilon}\right)\]
people are necessary and sufficient to estimate the mean up to distance
$\alpha$ in $\ell_2$-norm under $\varepsilon$-differential privacy (and its
common relaxations). In the multivariate setting, we give computationally
efficient algorithms under approximate-DP and computationally inefficient
algorithms under pure DP, and our nearly matching lower bounds hold for the
most permissive case of approximate DP. Our computationally efficient
estimators are based on the standard clip-and-noise framework, but the analysis
for our setting requires both new algorithmic techniques and new analyses. In
particular, our new bounds on the tails of sums of independent, vector-valued,
bounded-moments random variables may be of interest.",2024-05-30,"Sushant Agarwal, Gautam Kamath, Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan Ullman",http://arxiv.org/pdf/2405.20405v3,cs.LG
XPrompt:Explaining Large Language Model's Generation via Joint Prompt Attribution,"Large Language Models (LLMs) have demonstrated impressive performances in
complex text generation tasks. However, the contribution of the input prompt to
the generated content still remains obscure to humans, underscoring the
necessity of elucidating and explaining the causality between input and output
pairs. Existing works for providing prompt-specific explanation often confine
model output to be classification or next-word prediction. Few initial attempts
aiming to explain the entire language generation often treat input prompt texts
independently, ignoring their combinatorial effects on the follow-up
generation. In this study, we introduce a counterfactual explanation framework
based on joint prompt attribution, XPrompt, which aims to explain how a few
prompt texts collaboratively influences the LLM's complete generation.
Particularly, we formulate the task of prompt attribution for generation
interpretation as a combinatorial optimization problem, and introduce a
probabilistic algorithm to search for the casual input combination in the
discrete space. We define and utilize multiple metrics to evaluate the produced
explanations, demonstrating both faithfulness and efficiency of our framework.",2024-05-30,"Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin",http://arxiv.org/pdf/2405.20404v1,cs.LG
Fast leave-one-cluster-out cross-validation using clustered Network Information Criterion (NICc),"For prediction models developed on clustered data that do not account for
cluster heterogeneity in model parameterization, it is crucial to use
cluster-based validation to assess model generalizability on unseen clusters.
This paper introduces a clustered estimator of the Network Information
Criterion (NICc) to approximate leave-one-cluster-out deviance for standard
prediction models with twice differentiable log-likelihood functions. The NICc
serves as a fast alternative to cluster-based cross-validation. Stone (1977)
proved that the Akaike Information Criterion (AIC) is asymptotically equivalent
to leave-one-observation-out cross-validation for true parametric models with
independent and identically distributed observations. Ripley (1996) noted that
the Network Information Criterion (NIC), derived from Stone's proof, is a
better approximation when the model is misspecified. For clustered data, we
derived NICc by substituting the Fisher information matrix in the NIC with a
clustering-adjusted estimator. The NICc imposes a greater penalty when the data
exhibits stronger clustering, thereby allowing the NICc to better prevent
over-parameterization. In a simulation study and an empirical example, we used
standard regression to develop prediction models for clustered data with
Gaussian or binomial responses. Compared to the commonly used AIC and BIC for
standard regression, NICc provides a much more accurate approximation to
leave-one-cluster-out deviance and results in more accurate model size and
variable selection, as determined by cluster-based cross-validation, especially
when the data exhibit strong clustering.",2024-05-30,"Jiaxing Qiu, Douglas E. Lake, Pavel Chernyavskiy, Teague R. Henry",http://arxiv.org/pdf/2405.20400v2,cs.LG
Explainable Data-driven Modeling of Adsorption Energy in Heterogeneous Catalysis,"The increasing popularity of machine learning (ML) in catalysis has spurred
interest in leveraging these techniques to enhance catalyst design. Our study
aims to bridge the gap between physics-based studies and data-driven
methodologies by integrating ML techniques with eXplainable AI (XAI).
Specifically, we employ two XAI techniques: Post-hoc XAI analysis and Symbolic
Regression. These techniques help us unravel the correlation between adsorption
energy and the properties of the adsorbate-catalyst system. Leveraging a large
dataset such as the Open Catalyst Dataset (OC20), we employ a combination of
shallow ML techniques and XAI methodologies. Our investigation involves
utilizing multiple shallow machine learning techniques to predict adsorption
energy, followed by post-hoc analysis for feature importance, inter-feature
correlations, and the influence of various feature values on the prediction of
adsorption energy. The post-hoc analysis reveals that adsorbate properties
exert a greater influence than catalyst properties in our dataset. The top five
features based on higher Shapley values are adsorbate electronegativity, the
number of adsorbate atoms, catalyst electronegativity, effective coordination
number, and the sum of atomic numbers of the adsorbate molecule. There is a
positive correlation between catalyst and adsorbate electronegativity with the
prediction of adsorption energy. Additionally, symbolic regression yields
results consistent with SHAP analysis. It deduces a mathematical relationship
indicating that the square of the catalyst electronegativity is directly
proportional to the adsorption energy. These consistent correlations resemble
those derived from physics-based equations in previous research. Our work
establishes a robust framework that integrates ML techniques with XAI,
leveraging large datasets like OC20 to enhance catalyst design through model
explainability.",2024-05-30,"Tirtha Vinchurkar, Janghoon Ock, Amir Barati Farimani",http://arxiv.org/pdf/2405.20397v2,cs.LG
Quantitative Convergences of Lie Group Momentum Optimizers,"Explicit, momentum-based dynamics that optimize functions defined on Lie
groups can be constructed via variational optimization and momentum
trivialization. Structure preserving time discretizations can then turn this
dynamics into optimization algorithms. This article investigates two types of
discretization, Lie Heavy-Ball, which is a known splitting scheme, and Lie
NAG-SC, which is newly proposed. Their convergence rates are explicitly
quantified under $L$-smoothness and local strong convexity assumptions. Lie
NAG-SC provides acceleration over the momentumless case, i.e. Riemannian
gradient descent, but Lie Heavy-Ball does not. When compared to existing
accelerated optimizers for general manifolds, both Lie Heavy-Ball and Lie
NAG-SC are computationally cheaper and easier to implement, thanks to their
utilization of group structure. Only gradient oracle and exponential map are
required, but not logarithm map or parallel transport which are computational
costly.",2024-05-30,"Lingkai Kong, Molei Tao",http://arxiv.org/pdf/2405.20390v1,cs.LG
Recurrent neural network wave functions for Rydberg atom arrays on kagome lattice,"Rydberg atom array experiments have demonstrated the ability to act as
powerful quantum simulators, preparing strongly-correlated phases of matter
which are challenging to study for conventional computer simulations. A key
direction has been the implementation of interactions on frustrated geometries,
in an effort to prepare exotic many-body states such as spin liquids and
glasses. In this paper, we apply two-dimensional recurrent neural network (RNN)
wave functions to study the ground states of Rydberg atom arrays on the kagome
lattice. We implement an annealing scheme to find the RNN variational
parameters in regions of the phase diagram where exotic phases may occur,
corresponding to rough optimization landscapes. For Rydberg atom array
Hamiltonians studied previously on the kagome lattice, our RNN ground states
show no evidence of exotic spin liquid or emergent glassy behavior. In the
latter case, we argue that the presence of a non-zero Edwards-Anderson order
parameter is an artifact of the long autocorrelations times experienced with
quantum Monte Carlo simulations. This result emphasizes the utility of
autoregressive models, such as RNNs, to explore Rydberg atom array physics on
frustrated lattices and beyond.",2024-05-30,"Mohamed Hibat-Allah, Ejaaz Merali, Giacomo Torlai, Roger G Melko, Juan Carrasquilla",http://arxiv.org/pdf/2405.20384v1,cs.LG
Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image,"In this work, we introduce Unique3D, a novel image-to-3D framework for
efficiently generating high-quality 3D meshes from single-view images,
featuring state-of-the-art generation fidelity and strong generalizability.
Previous methods based on Score Distillation Sampling (SDS) can produce
diversified 3D results by distilling 3D knowledge from large 2D diffusion
models, but they usually suffer from long per-case optimization time with
inconsistent issues. Recent works address the problem and generate better 3D
results either by finetuning a multi-view diffusion model or training a fast
feed-forward model. However, they still lack intricate textures and complex
geometries due to inconsistency and limited generated resolution. To
simultaneously achieve high fidelity, consistency, and efficiency in single
image-to-3D, we propose a novel framework Unique3D that includes a multi-view
diffusion model with a corresponding normal diffusion model to generate
multi-view images with their normal maps, a multi-level upscale process to
progressively improve the resolution of generated orthographic multi-views, as
well as an instant and consistent mesh reconstruction algorithm called ISOMER,
which fully integrates the color and geometric priors into mesh results.
Extensive experiments demonstrate that our Unique3D significantly outperforms
other image-to-3D baselines in terms of geometric and textural details.",2024-05-30,"Kailu Wu, Fangfu Liu, Zhihan Cai, Runjie Yan, Hanyang Wang, Yating Hu, Yueqi Duan, Kaisheng Ma",http://arxiv.org/pdf/2405.20343v3,cs.LG
From Zero to Hero: Cold-Start Anomaly Detection,"When first deploying an anomaly detection system, e.g., to detect
out-of-scope queries in chatbots, there are no observed data, making
data-driven approaches ineffective. Zero-shot anomaly detection methods offer a
solution to such ""cold-start"" cases, but unfortunately they are often not
accurate enough. This paper studies the realistic but underexplored cold-start
setting where an anomaly detection model is initialized using zero-shot
guidance, but subsequently receives a small number of contaminated observations
(namely, that may include anomalies). The goal is to make efficient use of both
the zero-shot guidance and the observations. We propose ColdFusion, a method
that effectively adapts the zero-shot anomaly detector to contaminated
observations. To support future development of this new setting, we propose an
evaluation suite consisting of evaluation protocols and metrics.",2024-05-30,"Tal Reiss, George Kour, Naama Zwerdling, Ateret Anaby-Tavor, Yedid Hoshen",http://arxiv.org/pdf/2405.20341v1,cs.LG
CoSy: Evaluating Textual Explanations of Neurons,"A crucial aspect of understanding the complex nature of Deep Neural Networks
(DNNs) is the ability to explain learned concepts within their latent
representations. While methods exist to connect neurons to human-understandable
textual descriptions, evaluating the quality of these explanations is
challenging due to the lack of a unified quantitative approach. We introduce
CoSy (Concept Synthesis), a novel, architecture-agnostic framework for
evaluating textual explanations of latent neurons. Given textual explanations,
our proposed framework uses a generative model conditioned on textual input to
create data points representing the explanations. By comparing the neuron's
response to these generated data points and control data points, we can
estimate the quality of the explanation. We validate our framework through
sanity checks and benchmark various neuron description methods for Computer
Vision tasks, revealing significant differences in quality.",2024-05-30,"Laura Kopf, Philine Lou Bommer, Anna Hedström, Sebastian Lapuschkin, Marina M. -C. Höhne, Kirill Bykov",http://arxiv.org/pdf/2405.20331v2,cs.LG
Don't drop your samples! Coherence-aware training benefits Conditional diffusion,"Conditional diffusion models are powerful generative models that can leverage
various types of conditional information, such as class labels, segmentation
masks, or text captions. However, in many real-world scenarios, conditional
information may be noisy or unreliable due to human annotation errors or weak
alignment. In this paper, we propose the Coherence-Aware Diffusion (CAD), a
novel method that integrates coherence in conditional information into
diffusion models, allowing them to learn from noisy annotations without
discarding data. We assume that each data point has an associated coherence
score that reflects the quality of the conditional information. We then
condition the diffusion model on both the conditional information and the
coherence score. In this way, the model learns to ignore or discount the
conditioning when the coherence is low. We show that CAD is theoretically sound
and empirically effective on various conditional generation tasks. Moreover, we
show that leveraging coherence generates realistic and diverse samples that
respect conditional information better than models trained on cleaned datasets
where samples with low coherence have been discarded.",2024-05-30,"Nicolas Dufour, Victor Besnier, Vicky Kalogeiton, David Picard",http://arxiv.org/pdf/2405.20324v2,cs.LG
Vision-based Manipulation from Single Human Video with Open-World Object Graphs,"We present an object-centric approach to empower robots to learn vision-based
manipulation skills from human videos. We investigate the problem of imitating
robot manipulation from a single human video in the open-world setting, where a
robot must learn to manipulate novel objects from one video demonstration. We
introduce ORION, an algorithm that tackles the problem by extracting an
object-centric manipulation plan from a single RGB-D video and deriving a
policy that conditions on the extracted plan. Our method enables the robot to
learn from videos captured by daily mobile devices such as an iPad and
generalize the policies to deployment environments with varying visual
backgrounds, camera angles, spatial layouts, and novel object instances. We
systematically evaluate our method on both short-horizon and long-horizon
tasks, demonstrating the efficacy of ORION in learning from a single human
video in the open world. Videos can be found in the project website
https://ut-austin-rpl.github.io/ORION-release.",2024-05-30,"Yifeng Zhu, Arisrei Lim, Peter Stone, Yuke Zhu",http://arxiv.org/pdf/2405.20321v1,cs.LG
Improving the Training of Rectified Flows,"Diffusion models have shown great promise for image and video generation, but
sampling from state-of-the-art models requires expensive numerical integration
of a generative ODE. One approach for tackling this problem is rectified flows,
which iteratively learn smooth ODE paths that are less susceptible to
truncation error. However, rectified flows still require a relatively large
number of function evaluations (NFEs). In this work, we propose improved
techniques for training rectified flows, allowing them to compete with
\emph{knowledge distillation} methods even in the low NFE setting. Our main
insight is that under realistic settings, a single iteration of the Reflow
algorithm for training rectified flows is sufficient to learn nearly straight
trajectories; hence, the current practice of using multiple Reflow iterations
is unnecessary. We thus propose techniques to improve one-round training of
rectified flows, including a U-shaped timestep distribution and LPIPS-Huber
premetric. With these techniques, we improve the FID of the previous
2-rectified flow by up to 75\% in the 1 NFE setting on CIFAR-10. On ImageNet
64$\times$64, our improved rectified flow outperforms the state-of-the-art
distillation methods such as consistency distillation and progressive
distillation in both one-step and two-step settings and rivals the performance
of improved consistency training (iCT) in FID. Code is available at
https://github.com/sangyun884/rfpp.",2024-05-30,"Sangyun Lee, Zinan Lin, Giulia Fanti",http://arxiv.org/pdf/2405.20320v2,cs.LG
Quriosity: Analyzing Human Questioning Behavior and Causal Inquiry through Curiosity-Driven Queries,"Recent progress in Large Language Model (LLM) technology has changed our role
in interacting with these models. Instead of primarily testing these models
with questions we already know answers to, we are now using them for queries
where the answers are unknown to us, driven by human curiosity. This shift
highlights the growing need to understand curiosity-driven human questions -
those that are more complex, open-ended, and reflective of real-world needs. To
this end, we present Quriosity, a collection of 13.5K naturally occurring
questions from three diverse sources: human-to-search-engine queries,
human-to-human interactions, and human-to-LLM conversations. Our comprehensive
collection enables a rich understanding of human curiosity across various
domains and contexts. Our analysis reveals a significant presence of causal
questions (up to 42%) in the dataset, for which we develop an iterative prompt
improvement framework to identify all causal queries and examine their unique
linguistic properties, cognitive complexity and source distribution. Our paper
paves the way for future work on causal question identification and open-ended
chatbot interactions.",2024-05-30,"Roberto Ceraolo, Dmitrii Kharlapenko, Ahmad Khan, Amélie Reymond, Rada Mihalcea, Bernhard Schölkopf, Mrinmaya Sachan, Zhijing Jin",http://arxiv.org/pdf/2405.20318v3,cs.LG
Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Backbone Generation,"Proteins are essential for almost all biological processes and derive their
diverse functions from complex 3D structures, which are in turn determined by
their amino acid sequences. In this paper, we exploit the rich biological
inductive bias of amino acid sequences and introduce FoldFlow-2, a novel
sequence-conditioned SE(3)-equivariant flow matching model for protein
structure generation. FoldFlow-2 presents substantial new architectural
features over the previous FoldFlow family of models including a protein large
language model to encode sequence, a new multi-modal fusion trunk that combines
structure and sequence representations, and a geometric transformer based
decoder. To increase diversity and novelty of generated samples -- crucial for
de-novo drug design -- we train FoldFlow-2 at scale on a new dataset that is an
order of magnitude larger than PDB datasets of prior works, containing both
known proteins in PDB and high-quality synthetic structures achieved through
filtering. We further demonstrate the ability to align FoldFlow-2 to arbitrary
rewards, e.g. increasing secondary structures diversity, by introducing a
Reinforced Finetuning (ReFT) objective. We empirically observe that FoldFlow-2
outperforms previous state-of-the-art protein structure-based generative
models, improving over RFDiffusion in terms of unconditional generation across
all metrics including designability, diversity, and novelty across all protein
lengths, as well as exhibiting generalization on the task of equilibrium
conformation sampling. Finally, we demonstrate that a fine-tuned FoldFlow-2
makes progress on challenging conditional design tasks such as designing
scaffolds for the VHH nanobody.",2024-05-30,"Guillaume Huguet, James Vuckovic, Kilian Fatras, Eric Thibodeau-Laufer, Pablo Lemos, Riashat Islam, Cheng-Hao Liu, Jarrid Rector-Brooks, Tara Akhound-Sadegh, Michael Bronstein, Alexander Tong, Avishek Joey Bose",http://arxiv.org/pdf/2405.20313v2,cs.LG
Large Language Models Can Self-Improve At Web Agent Tasks,"Training models to act as agents that can effectively navigate and perform
actions in a complex environment, such as a web browser, has typically been
challenging due to lack of training data. Large language models (LLMs) have
recently demonstrated some capability to navigate novel environments as agents
in a zero-shot or few-shot fashion, purely guided by natural language
instructions as prompts. Recent research has also demonstrated LLMs have the
capability to exceed their base performance through self-improvement, i.e.
fine-tuning on data generated by the model itself. In this work, we explore the
extent to which LLMs can self-improve their performance as agents in
long-horizon tasks in a complex environment using the WebArena benchmark. In
WebArena, an agent must autonomously navigate and perform actions on web pages
to achieve a specified objective. We explore fine-tuning on three distinct
synthetic training data mixtures and achieve a 31\% improvement in task
completion rate over the base model on the WebArena benchmark through a
self-improvement procedure. We additionally contribute novel evaluation metrics
for assessing the performance, robustness, capabilities, and quality of
trajectories of our fine-tuned agent models to a greater degree than simple,
aggregate-level benchmark scores currently used to measure self-improvement.",2024-05-30,"Ajay Patel, Markus Hofmarcher, Claudiu Leoveanu-Condrei, Marius-Constantin Dinu, Chris Callison-Burch, Sepp Hochreiter",http://arxiv.org/pdf/2405.20309v2,cs.LG
Group Robust Preference Optimization in Reward-free RLHF,"Adapting large language models (LLMs) for specific tasks usually involves
fine-tuning through reinforcement learning with human feedback (RLHF) on
preference data. While these data often come from diverse labelers' groups
(e.g., different demographics, ethnicities, company teams, etc.), traditional
RLHF approaches adopt a ""one-size-fits-all"" approach, i.e., they
indiscriminately assume and optimize a single preference model, thus not being
robust to unique characteristics and needs of the various groups. To address
this limitation, we propose a novel Group Robust Preference Optimization (GRPO)
method to align LLMs to individual groups' preferences robustly. Our approach
builds upon reward-free direct preference optimization methods, but unlike
previous approaches, it seeks a robust policy which maximizes the worst-case
group performance. To achieve this, GRPO adaptively and sequentially weights
the importance of different groups, prioritizing groups with worse cumulative
loss. We theoretically study the feasibility of GRPO and analyze its
convergence for the log-linear policy class. By fine-tuning LLMs with GRPO
using diverse group-based global opinion data, we significantly improved
performance for the worst-performing groups, reduced loss imbalances across
groups, and improved probability accuracies compared to non-robust baselines.",2024-05-30,"Shyam Sundhar Ramesh, Yifan Hu, Iason Chaimalas, Viraj Mehta, Pier Giuseppe Sessa, Haitham Bou Ammar, Ilija Bogunovic",http://arxiv.org/pdf/2405.20304v1,cs.LG
Unveiling and Mitigating Backdoor Vulnerabilities based on Unlearning Weight Changes and Backdoor Activeness,"The security threat of backdoor attacks is a central concern for deep neural
networks (DNNs). Recently, without poisoned data, unlearning models with clean
data and then learning a pruning mask have contributed to backdoor defense.
Additionally, vanilla fine-tuning with those clean data can help recover the
lost clean accuracy. However, the behavior of clean unlearning is still
under-explored, and vanilla fine-tuning unintentionally induces back the
backdoor effect. In this work, we first investigate model unlearning from the
perspective of weight changes and gradient norms, and find two interesting
observations in the backdoored model: 1) the weight changes between poison and
clean unlearning are positively correlated, making it possible for us to
identify the backdoored-related neurons without using poisoned data; 2) the
neurons of the backdoored model are more active (i.e., larger changes in
gradient norm) than those in the clean model, suggesting the need to suppress
the gradient norm during fine-tuning. Then, we propose an effective two-stage
defense method. In the first stage, an efficient Neuron Weight Change
(NWC)-based Backdoor Reinitialization is proposed based on observation 1). In
the second stage, based on observation 2), we design an Activeness-Aware
Fine-Tuning to replace the vanilla fine-tuning. Extensive experiments,
involving eight backdoor attacks on three benchmark datasets, demonstrate the
superior performance of our proposed method compared to recent state-of-the-art
backdoor defense approaches.",2024-05-30,"Weilin Lin, Li Liu, Shaokui Wei, Jianze Li, Hui Xiong",http://arxiv.org/pdf/2405.20291v1,cs.LG
DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation,"Controllable music generation methods are critical for human-centered
AI-based music creation, but are currently limited by speed, quality, and
control design trade-offs. Diffusion Inference-Time T-optimization (DITTO), in
particular, offers state-of-the-art results, but is over 10x slower than
real-time, limiting practical use. We propose Distilled Diffusion
Inference-Time T -Optimization (or DITTO-2), a new method to speed up
inference-time optimization-based control and unlock faster-than-real-time
generation for a wide-variety of applications such as music inpainting,
outpainting, intensity, melody, and musical structure control. Our method works
by (1) distilling a pre-trained diffusion model for fast sampling via an
efficient, modified consistency or consistency trajectory distillation process
(2) performing inference-time optimization using our distilled model with
one-step sampling as an efficient surrogate optimization task and (3) running a
final multi-step sampling generation (decoding) using our estimated noise
latents for best-quality, fast, controllable generation. Through thorough
evaluation, we find our method not only speeds up generation over 10-20x, but
simultaneously improves control adherence and generation quality all at once.
Furthermore, we apply our approach to a new application of maximizing text
adherence (CLAP score) and show we can convert an unconditional diffusion model
without text inputs into a model that yields state-of-the-art text control.
Sound examples can be found at https://ditto-music.github.io/ditto2/.",2024-05-30,"Zachary Novack, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas Bryan",http://arxiv.org/pdf/2405.20289v1,cs.LG
Flexible SE(2) graph neural networks with applications to PDE surrogates,"This paper presents a novel approach for constructing graph neural networks
equivariant to 2D rotations and translations and leveraging them as PDE
surrogates on non-gridded domains. We show that aligning the representations
with the principal axis allows us to sidestep many constraints while preserving
SE(2) equivariance. By applying our model as a surrogate for fluid flow
simulations and conducting thorough benchmarks against non-equivariant models,
we demonstrate significant gains in terms of both data efficiency and accuracy.",2024-05-30,"Maria Bånkestad, Olof Mogren, Aleksis Pirinen",http://arxiv.org/pdf/2405.20287v1,cs.LG
Length independent generalization bounds for deep SSM architectures via Rademacher contraction and stability constraints,"Many state-of-the-art models trained on long-range sequences, for example S4,
S5 or LRU, are made of sequential blocks combining State-Space Models (SSMs)
with neural networks. In this paper we provide a PAC bound that holds for these
kind of architectures with \emph{stable} SSM blocks and does not depend on the
length of the input sequence. Imposing stability of the SSM blocks is a
standard practice in the literature, and it is known to help performance. Our
results provide a theoretical justification for the use of stable SSM blocks as
the proposed PAC bound decreases as the degree of stability of the SSM blocks
increases.",2024-05-30,"Dániel Rácz, Mihály Petreczky, Bálint Daróczy",http://arxiv.org/pdf/2405.20278v3,cs.LG
ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection for ABSA,"Aspect-Based Sentiment Analysis (ABSA) has experienced tremendous expansion
and diversity due to various shared tasks spanning several languages and fields
and organized via SemEval workshops and Germeval. Nonetheless, a few
shortcomings still need to be addressed, such as the lack of low-resource
language evaluations and the emphasis on sentence-level analysis. To thoroughly
assess ABSA techniques in the context of complete reviews, this research
presents a novel task, Review-Level Opinion Aspect Sentiment Target (ROAST).
ROAST seeks to close the gap between sentence-level and text-level ABSA by
identifying every ABSA constituent at the review level. We extend the available
datasets to enable ROAST, addressing the drawbacks noted in previous research
by incorporating low-resource languages, numerous languages, and a variety of
topics. Through this effort, ABSA research will be able to cover more ground
and get a deeper comprehension of the task and its practical application in a
variety of languages and domains (https://github.com/RiTUAL-UH/ROAST-ABSA).",2024-05-30,"Siva Uday Sampreeth Chebolu, Franck Dernoncourt, Nedim Lipka, Thamar Solorio",http://arxiv.org/pdf/2405.20274v2,cs.LG
Reconstruction Attacks on Machine Unlearning: Simple Models are Vulnerable,"Machine unlearning is motivated by desire for data autonomy: a person can
request to have their data's influence removed from deployed models, and those
models should be updated as if they were retrained without the person's data.
We show that, counter-intuitively, these updates expose individuals to
high-accuracy reconstruction attacks which allow the attacker to recover their
data in its entirety, even when the original models are so simple that privacy
risk might not otherwise have been a concern. We show how to mount a
near-perfect attack on the deleted data point from linear regression models. We
then generalize our attack to other loss functions and architectures, and
empirically demonstrate the effectiveness of our attacks across a wide range of
datasets (capturing both tabular and image data). Our work highlights that
privacy risk is significant even for extremely simple model classes when
individuals can request deletion of their data from the model.",2024-05-30,"Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu",http://arxiv.org/pdf/2405.20272v1,cs.LG
ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane Reflections,"Parameter-efficient finetuning (PEFT) has become ubiquitous to adapt
foundation models to downstream task requirements while retaining their
generalization ability. However, the amount of additionally introduced
parameters and compute for successful adaptation and hyperparameter searches
can explode quickly, especially when deployed at scale to serve numerous
individual requests. To ensure effective, parameter-efficient, and
hyperparameter-robust adaptation, we propose the ETHER transformation family,
which performs Efficient fineTuning via HypErplane Reflections. By design,
ETHER transformations require a minimal number of parameters, are less likely
to deteriorate model performance, and exhibit robustness to hyperparameter and
learning rate choices. In particular, we introduce ETHER and its relaxation
ETHER+, which match or outperform existing PEFT methods with significantly
fewer parameters ($\sim$$10$-$100$ times lower than LoRA or OFT) across
multiple image synthesis and natural language tasks without exhaustive
hyperparameter tuning. Finally, we investigate the recent emphasis on
Hyperspherical Energy retention for adaptation and raise questions on its
practical utility. The code is available at https://github.com/mwbini/ether.",2024-05-30,"Massimo Bini, Karsten Roth, Zeynep Akata, Anna Khoreva",http://arxiv.org/pdf/2405.20271v2,cs.LG
Entropy annealing for policy mirror descent in continuous time and space,"Entropy regularization has been widely used in policy optimization algorithms
to enhance exploration and the robustness of the optimal control; however it
also introduces an additional regularization bias. This work quantifies the
impact of entropy regularization on the convergence of policy gradient methods
for stochastic exit time control problems. We analyze a continuous-time policy
mirror descent dynamics, which updates the policy based on the gradient of an
entropy-regularized value function and adjusts the strength of entropy
regularization as the algorithm progresses. We prove that with a fixed entropy
level, the mirror descent dynamics converges exponentially to the optimal
solution of the regularized problem. We further show that when the entropy
level decays at suitable polynomial rates, the annealed flow converges to the
solution of the unregularized problem at a rate of $\mathcal O(1/S)$ for
discrete action spaces and, under suitable conditions, at a rate of $\mathcal
O(1/\sqrt{S})$ for general action spaces, with $S$ being the gradient flow
running time. The technical challenge lies in analyzing the gradient flow in
the infinite-dimensional space of Markov kernels for nonconvex objectives. This
paper explains how entropy regularization improves policy optimization, even
with the true gradient, from the perspective of convergence rate.",2024-05-30,"Deven Sethi, David Šiška, Yufei Zhang",http://arxiv.org/pdf/2405.20250v3,cs.LG
KerasCV and KerasNLP: Vision and Language Power-Ups,"We present the Keras domain packages KerasCV and KerasNLP, extensions of the
Keras API for Computer Vision and Natural Language Processing workflows,
capable of running on either JAX, TensorFlow, or PyTorch. These domain packages
are designed to enable fast experimentation, with a focus on ease-of-use and
performance. We adopt a modular, layered design: at the library's lowest level
of abstraction, we provide building blocks for creating models and data
preprocessing pipelines, and at the library's highest level of abstraction, we
provide pretrained ``task"" models for popular architectures such as Stable
Diffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have
built-in preprocessing, pretrained weights, and can be fine-tuned on raw
inputs. To enable efficient training, we support XLA compilation for all
models, and run all preprocessing via a compiled graph of TensorFlow operations
using the tf.data API. The libraries are fully open-source (Apache 2.0 license)
and available on GitHub.",2024-05-30,"Matthew Watson, Divyashree Shivakumar Sreepathihalli, Francois Chollet, Martin Gorner, Kiranbir Sodhia, Ramesh Sampath, Tirth Patel, Haifeng Jin, Neel Kovelamudi, Gabriel Rasskin, Samaneh Saadat, Luke Wood, Chen Qian, Jonathan Bischof, Ian Stenbit, Abheesht Sharma, Anshuman Mishra",http://arxiv.org/pdf/2405.20247v3,cs.LG
Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use,"Business Document Information Extraction (BDIE) is the problem of
transforming a blob of unstructured information (raw text, scanned documents,
etc.) into a structured format that downstream systems can parse and use. It
has two main tasks: Key-Information Extraction (KIE) and Line Items Recognition
(LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem,
where the tools are these downstream systems. We then present Retrieval
Augmented Structured Generation (RASG), a novel general framework for BDIE that
achieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE
benchmarks.
  The contributions of this paper are threefold: (1) We show, with ablation
benchmarks, that Large Language Models (LLMs) with RASG are already competitive
with or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on
BDIE benchmarks. (2) We propose a new metric class for Line Items Recognition,
General Line Items Recognition Metric (GLIRM), that is more aligned with
practical BDIE use cases compared to existing metrics, such as ANLS*, DocILE,
and GriTS. (3) We provide a heuristic algorithm for backcalculating bounding
boxes of predicted line items and tables without the need for vision encoders.
Finally, we claim that, while LMMs might sometimes offer marginal performance
benefits, LLMs + RASG is oftentimes superior given real-world applications and
constraints of BDIE.",2024-05-30,"Franz Louis Cesista, Rui Aguiar, Jason Kim, Paolo Acilo",http://arxiv.org/pdf/2405.20245v1,cs.LG
Training-efficient density quantum machine learning,"Quantum machine learning (QML) requires powerful, flexible and efficiently
trainable models to be successful in solving challenging problems. We introduce
density quantum neural networks, a model family that prepares mixtures of
trainable unitaries, with a distributional constraint over coefficients. This
framework balances expressivity and efficient trainability, especially on
quantum hardware. For expressivity, the Hastings-Campbell Mixing lemma converts
benefits from linear combination of unitaries into density models with similar
performance guarantees but shallower circuits. For trainability,
commuting-generator circuits enable density model construction with efficiently
extractable gradients. The framework connects to various facets of QML
including post-variational and measurement-based learning. In classical
settings, density models naturally integrate the mixture of experts formalism,
and offer natural overfitting mitigation. The framework is versatile - we
uplift several quantum models into density versions to improve model
performance, or trainability, or both. These include Hamming weight-preserving
and equivariant models, among others. Extensive numerical experiments validate
our findings.",2024-05-30,"Brian Coyle, Snehal Raj, Natansh Mathur, El Amine Cherrat, Nishant Jain, Skander Kazdaghli, Iordanis Kerenidis",http://arxiv.org/pdf/2405.20237v2,cs.LG
Disentangling and Mitigating the Impact of Task Similarity for Continual Learning,"Continual learning of partially similar tasks poses a challenge for
artificial neural networks, as task similarity presents both an opportunity for
knowledge transfer and a risk of interference and catastrophic forgetting.
However, it remains unclear how task similarity in input features and readout
patterns influences knowledge transfer and forgetting, as well as how they
interact with common algorithms for continual learning. Here, we develop a
linear teacher-student model with latent structure and show analytically that
high input feature similarity coupled with low readout similarity is
catastrophic for both knowledge transfer and retention. Conversely, the
opposite scenario is relatively benign. Our analysis further reveals that
task-dependent activity gating improves knowledge retention at the expense of
transfer, while task-dependent plasticity gating does not affect either
retention or transfer performance at the over-parameterized limit. In contrast,
weight regularization based on the Fisher information metric significantly
improves retention, regardless of task similarity, without compromising
transfer performance. Nevertheless, its diagonal approximation and
regularization in the Euclidean space are much less robust against task
similarity. We demonstrate consistent results in a permuted MNIST task with
latent variables. Overall, this work provides insights into when continual
learning is difficult and how to mitigate it.",2024-05-30,Naoki Hiratani,http://arxiv.org/pdf/2405.20236v1,cs.LG
Grokfast: Accelerated Grokking by Amplifying Slow Gradients,"One puzzling artifact in machine learning dubbed grokking is where delayed
generalization is achieved tenfolds of iterations after near perfect
overfitting to the training data. Focusing on the long delay itself on behalf
of machine learning practitioners, our goal is to accelerate generalization of
a model under grokking phenomenon. By regarding a series of gradients of a
parameter over training iterations as a random signal over time, we can
spectrally decompose the parameter trajectories under gradient descent into two
components: the fast-varying, overfitting-yielding component and the
slow-varying, generalization-inducing component. This analysis allows us to
accelerate the grokking phenomenon more than $\times 50$ with only a few lines
of code that amplifies the slow-varying components of gradients. The
experiments show that our algorithm applies to diverse tasks involving images,
languages, and graphs, enabling practical availability of this peculiar
artifact of sudden generalization. Our code is available at
https://github.com/ironjr/grokfast.",2024-05-30,"Jaerin Lee, Bong Gyun Kang, Kihoon Kim, Kyoung Mu Lee",http://arxiv.org/pdf/2405.20233v2,cs.LG
"The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof","Many algorithms and observed phenomena in deep learning appear to be affected
by parameter symmetries -- transformations of neural network parameters that do
not change the underlying neural network function. These include linear mode
connectivity, model merging, Bayesian neural network inference, metanetworks,
and several other characteristics of optimization or loss-landscapes. However,
theoretical analysis of the relationship between parameter space symmetries and
these phenomena is difficult. In this work, we empirically investigate the
impact of neural parameter symmetries by introducing new neural network
architectures that have reduced parameter space symmetries. We develop two
methods, with some provable guarantees, of modifying standard neural networks
to reduce parameter space symmetries. With these new methods, we conduct a
comprehensive experimental study consisting of multiple tasks aimed at
assessing the effect of removing parameter symmetries. Our experiments reveal
several interesting observations on the empirical impact of parameter
symmetries; for instance, we observe linear mode connectivity between our
networks without alignment of weight spaces, and we find that our networks
allow for faster and more effective Bayesian neural network training. Our code
is available at https://github.com/cptq/asymmetric-networks",2024-05-30,"Derek Lim, Theo Moe Putterman, Robin Walters, Haggai Maron, Stefanie Jegelka",http://arxiv.org/pdf/2405.20231v3,cs.LG
Boost Your Human Image Generation Model via Direct Preference Optimization,"Human image generation is a key focus in image synthesis due to its broad
applications, but even slight inaccuracies in anatomy, pose, or details can
compromise realism. To address these challenges, we explore Direct Preference
Optimization (DPO), which trains models to generate preferred (winning) images
while diverging from non-preferred (losing) ones. However, conventional DPO
methods use generated images as winning images, limiting realism. To overcome
this limitation, we propose an enhanced DPO approach that incorporates
high-quality real images as winning images, encouraging outputs to resemble
real images rather than generated ones. However, implementing this concept is
not a trivial task. Therefore, our approach, HG-DPO (Human image Generation
through DPO), employs a novel curriculum learning framework that gradually
improves the output of the model toward greater realism, making training more
feasible. Furthermore, HG-DPO effectively adapts to personalized text-to-image
tasks, generating high-quality and identity-specific images, which highlights
the practical value of our approach.",2024-05-30,"Sanghyeon Na, Yonggyu Kim, Hyunjoon Lee",http://arxiv.org/pdf/2405.20216v3,cs.LG
PostDoc: Generating Poster from a Long Multimodal Document Using Deep Submodular Optimization,"A poster from a long input document can be considered as a one-page
easy-to-read multimodal (text and images) summary presented on a nice template
with good design elements. Automatic transformation of a long document into a
poster is a very less studied but challenging task. It involves content
summarization of the input document followed by template generation and
harmonization. In this work, we propose a novel deep submodular function which
can be trained on ground truth summaries to extract multimodal content from the
document and explicitly ensures good coverage, diversity and alignment of text
and images. Then, we use an LLM based paraphraser and propose to generate a
template with various design aspects conditioned on the input content. We show
the merits of our approach through extensive automated and human evaluations.",2024-05-30,"Vijay Jaisankar, Sambaran Bandyopadhyay, Kalp Vyas, Varre Chaitanya, Shwetha Somasundaram",http://arxiv.org/pdf/2405.20213v1,cs.LG
Unified Explanations in Machine Learning Models: A Perturbation Approach,"A high-velocity paradigm shift towards Explainable Artificial Intelligence
(XAI) has emerged in recent years. Highly complex Machine Learning (ML) models
have flourished in many tasks of intelligence, and the questions have started
to shift away from traditional metrics of validity towards something deeper:
What is this model telling me about my data, and how is it arriving at these
conclusions? Inconsistencies between XAI and modeling techniques can have the
undesirable effect of casting doubt upon the efficacy of these explainability
approaches. To address these problems, we propose a systematic,
perturbation-based analysis against a popular, model-agnostic method in XAI,
SHapley Additive exPlanations (Shap). We devise algorithms to generate relative
feature importance in settings of dynamic inference amongst a suite of popular
machine learning and deep learning methods, and metrics that allow us to
quantify how well explanations generated under the static case hold. We propose
a taxonomy for feature importance methodology, measure alignment, and observe
quantifiable similarity amongst explanation models across several datasets.",2024-05-30,"Jacob Dineen, Don Kridel, Daniel Dolk, David Castillo",http://arxiv.org/pdf/2405.20200v1,cs.LG
Occam Gradient Descent,"Deep learning neural network models must be large enough to adapt to their
problem domain, while small enough to avoid overfitting training data during
gradient descent. To balance these competing demands, overprovisioned deep
learning models such as transformers are trained for a single epoch on large
data sets, and hence inefficient with both computing resources and training
data. In response to these inefficiencies, we exploit learning theory to derive
Occam Gradient Descent, an algorithm that interleaves adaptive reduction of
model size to minimize generalization error, with gradient descent on model
weights to minimize fitting error. In contrast, traditional gradient descent
greedily minimizes fitting error without regard to generalization error. Our
algorithm simultaneously descends the space of weights and topological size of
any neural network without modification. With respect to loss, compute and
model size, our experiments show (a) on image classification benchmarks, linear
and convolutional neural networks trained with Occam Gradient Descent
outperform traditional gradient descent with or without post-train pruning; (b)
on a range of tabular data classification tasks, neural networks trained with
Occam Gradient Descent outperform traditional gradient descent, as well as
Random Forests; (c) on natural language transformers, Occam Gradient Descent
outperforms traditional gradient descent.",2024-05-30,B. N. Kausik,http://arxiv.org/pdf/2405.20194v8,cs.LG
Transformers and Slot Encoding for Sample Efficient Physical World Modelling,"World modelling, i.e. building a representation of the rules that govern the
world so as to predict its evolution, is an essential ability for any agent
interacting with the physical world. Recent applications of the Transformer
architecture to the problem of world modelling from video input show notable
improvements in sample efficiency. However, existing approaches tend to work
only at the image level thus disregarding that the environment is composed of
objects interacting with each other. In this paper, we propose an architecture
combining Transformers for world modelling with the slot-attention paradigm, an
approach for learning representations of objects appearing in a scene. We
describe the resulting neural architecture and report experimental results
showing an improvement over the existing solutions in terms of sample
efficiency and a reduction of the variation of the performance over the
training examples. The code for our architecture and experiments is available
at https://github.com/torchipeppo/transformers-and-slot-encoding-for-wm",2024-05-30,"Francesco Petri, Luigi Asprino, Aldo Gangemi",http://arxiv.org/pdf/2405.20180v1,cs.LG
Non-intrusive data-driven model order reduction for circuits based on Hammerstein architectures,"We demonstrate that data-driven system identification techniques can provide
a basis for effective, non-intrusive model order reduction (MOR) for common
circuits that are key building blocks in microelectronics. Our approach is
motivated by the practical operation of these circuits and utilizes a canonical
Hammerstein architecture. To demonstrate the approach we develop a parsimonious
Hammerstein model for a non-linear CMOS differential amplifier. We train this
model on a combination of direct current (DC) and transient Spice (Xyce)
circuit simulation data using a novel sequential strategy to identify the
static nonlinear and linear dynamical parts of the model. Simulation results
show that the Hammerstein model is an effective surrogate for the differential
amplifier circuit that accurately and efficiently reproduces its behavior over
a wide range of operating points and input frequencies.",2024-05-30,"Joshua Hanson, Biliana Paskaleva, Pavel Bochev",http://arxiv.org/pdf/2405.20178v1,cs.LG
Tropical Expressivity of Neural Networks,"We propose an algebraic geometric framework to study the expressivity of
linear activation neural networks. A particular quantity of neural networks
that has been actively studied is the number of linear regions, which gives a
quantification of the information capacity of the architecture. To study and
evaluate information capacity and expressivity, we work in the setting of
tropical geometry - a combinatorial and polyhedral variant of algebraic
geometry - where there are known connections between tropical rational maps and
feedforward neural networks. Our work builds on and expands this connection to
capitalize on the rich theory of tropical geometry to characterize and study
various architectural aspects of neural networks. Our contributions are
threefold: we provide a novel tropical geometric approach to selecting sampling
domains among linear regions; an algebraic result allowing for a guided
restriction of the sampling domain for network architectures with symmetries;
and a new open source OSCAR library to analyze neural networks symbolically
using their tropical representations, where we present a new algorithm that
computes the exact number of their linear regions. We provide a comprehensive
set of proof-of-concept numerical experiments demonstrating the breadth of
neural network architectures to which tropical geometric theory can be applied
to reveal insights on expressivity characteristics of a network. Our work
provides the foundations for the adaptation of both theory and existing
software from computational tropical geometry and symbolic computation to
neural networks and deep learning",2024-05-30,"Paul Lezeau, Thomas Walker, Yueqi Cao, Shiv Bhatia, Anthea Monod",http://arxiv.org/pdf/2405.20174v2,cs.LG
Iterative Feature Boosting for Explainable Speech Emotion Recognition,"In speech emotion recognition (SER), using predefined features without
considering their practical importance may lead to high dimensional datasets,
including redundant and irrelevant information. Consequently, high-dimensional
learning often results in decreasing model accuracy while increasing
computational complexity. Our work underlines the importance of carefully
considering and analyzing features in order to build efficient SER systems. We
present a new supervised SER method based on an efficient feature engineering
approach. We pay particular attention to the explainability of results to
evaluate feature relevance and refine feature sets. This is performed
iteratively through feature evaluation loop, using Shapley values to boost
feature selection and improve overall framework performance. Our approach
allows thus to balance the benefits between model performance and transparency.
The proposed method outperforms human-level performance (HLP) and
state-of-the-art machine learning methods in emotion recognition on the TESS
dataset. The source code of this paper is publicly available at
https://github.com/alaaNfissi/Iterative-Feature-Boosting-for-Explainable-Speech-Emotion-Recognition.",2024-05-30,"Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara",http://arxiv.org/pdf/2405.20172v3,cs.LG
Randomized Exploration for Reinforcement Learning with Multinomial Logistic Function Approximation,"We study reinforcement learning with multinomial logistic (MNL) function
approximation where the underlying transition probability kernel of the Markov
decision processes (MDPs) is parametrized by an unknown transition core with
features of state and action. For the finite horizon episodic setting with
inhomogeneous state transitions, we propose provably efficient algorithms with
randomized exploration having frequentist regret guarantees. For our first
algorithm, $\texttt{RRL-MNL}$, we adapt optimistic sampling to ensure the
optimism of the estimated value function with sufficient frequency. We
establish that $\texttt{RRL-MNL}$ achieves a $\tilde{O}(\kappa^{-1}
d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T})$ frequentist regret bound with
constant-time computational cost per episode. Here, $d$ is the dimension of the
transition core, $H$ is the horizon length, $T$ is the total number of steps,
and $\kappa$ is a problem-dependent constant. Despite the simplicity and
practicality of $\texttt{RRL-MNL}$, its regret bound scales with $\kappa^{-1}$,
which is potentially large in the worst case. To improve the dependence on
$\kappa^{-1}$, we propose $\texttt{ORRL-MNL}$, which estimates the value
function using the local gradient information of the MNL transition model. We
show that its frequentist regret bound is $\tilde{O}(d^{\frac{3}{2}}
H^{\frac{3}{2}} \sqrt{T} + \kappa^{-1} d^2 H^2)$. To the best of our knowledge,
these are the first randomized RL algorithms for the MNL transition model that
achieve statistical guarantees with constant-time computational cost per
episode. Numerical experiments demonstrate the superior performance of the
proposed algorithms.",2024-05-30,"Wooseong Cho, Taehyun Hwang, Joongkyu Lee, Min-hwan Oh",http://arxiv.org/pdf/2405.20165v2,cs.LG
GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning,"Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form
of triplets (head, relation, tail), which collectively form a graph. Question
Answering over KGs (KGQA) is the task of answering natural questions grounding
the reasoning to the information provided by the KG. Large Language Models
(LLMs) are the state-of-the-art models for QA tasks due to their remarkable
ability to understand natural language. On the other hand, Graph Neural
Networks (GNNs) have been widely used for KGQA as they can handle the complex
graph information stored in the KG. In this work, we introduce GNN-RAG, a novel
method for combining language understanding abilities of LLMs with the
reasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.
First, a GNN reasons over a dense KG subgraph to retrieve answer candidates for
a given question. Second, the shortest paths in the KG that connect question
entities and answer candidates are extracted to represent KG reasoning paths.
The extracted paths are verbalized and given as input for LLM reasoning with
RAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to
extract useful graph information, while the LLM leverages its natural language
processing ability for ultimate KGQA. Furthermore, we develop a retrieval
augmentation (RA) technique to further boost KGQA performance with GNN-RAG.
Experimental results show that GNN-RAG achieves state-of-the-art performance in
two widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching
GPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop
and multi-entity questions outperforming competing approaches by 8.9--15.5%
points at answer F1.",2024-05-30,"Costas Mavromatis, George Karypis",http://arxiv.org/pdf/2405.20139v1,cs.LG
Language Models Need Inductive Biases to Count Inductively,"Counting is a fundamental example of generalization, whether viewed through
the mathematical lens of Peano's axioms defining the natural numbers or the
cognitive science literature for children learning to count. The argument holds
for both cases that learning to count means learning to count infinitely. While
few papers have tried to distill transformer ""reasoning"" to the simplest case
of counting, investigating length generalization does occur throughout the
literature. In the ""train short, test long"" paradigm of NLP, length refers to
the training sentence length. In formal language recognition, length refers to
the input sequence length, or the maximum stack size induced by a pushdown
automata. In general problem solving, length refers to the number of hops in a
deductive reasoning chain or the recursion depth. For all cases, counting is
central to task success. And crucially, generalizing counting inductively is
central to success on OOD instances. This work provides extensive empirical
results on training language models to count. We experiment with architectures
ranging from RNNs, Transformers, State-Space Models and RWKV. We present
carefully-designed task formats, auxiliary tasks and positional embeddings to
avoid limitations in generalization with OOD-position and OOD-vocabulary. We
find that while traditional RNNs trivially achieve inductive counting,
Transformers have to rely on positional embeddings to count out-of-domain. As
counting is the basis for many arguments concerning the expressivity of
Transformers, our finding calls for the community to reexamine the application
scope of primitive functions defined in formal characterizations. Finally,
modern RNNs also largely underperform traditional RNNs in generalizing counting
inductively. We discuss how design choices that enable parallelized training of
modern RNNs cause them to lose merits of a recurrent nature.",2024-05-30,"Yingshan Chang, Yonatan Bisk",http://arxiv.org/pdf/2405.20131v2,cs.LG
SPAM: Stochastic Proximal Point Method with Momentum Variance Reduction for Non-convex Cross-Device Federated Learning,"Cross-device training is a crucial subfield of federated learning, where the
number of clients can reach into the billions. Standard approaches and local
methods are prone to issues such as client drift and insensitivity to data
similarities. We propose a novel algorithm (SPAM) for cross-device federated
learning with non-convex losses, which solves both issues. We provide sharp
analysis under second-order (Hessian) similarity, a condition satisfied by a
variety of machine learning problems in practice. Additionally, we extend our
results to the partial participation setting, where a cohort of selected
clients communicate with the server at each communication round. Our method is
the first in its kind, that does not require the smoothness of the objective
and provably benefits from clients having similar data.",2024-05-30,"Avetik Karagulyan, Egor Shulgin, Abdurakhmon Sadiev, Peter Richtárik",http://arxiv.org/pdf/2405.20127v1,cs.LG
A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set,"The state-of-the-art methods for estimating high-dimensional covariance
matrices all shrink the eigenvalues of the sample covariance matrix towards a
data-insensitive shrinkage target. The underlying shrinkage transformation is
either chosen heuristically - without compelling theoretical justification - or
optimally in view of restrictive distributional assumptions. In this paper, we
propose a principled approach to construct covariance estimators without
imposing restrictive assumptions. That is, we study distributionally robust
covariance estimation problems that minimize the worst-case Frobenius error
with respect to all data distributions close to a nominal distribution, where
the proximity of distributions is measured via a divergence on the space of
covariance matrices. We identify mild conditions on this divergence under which
the resulting minimizers represent shrinkage estimators. We show that the
corresponding shrinkage transformations are intimately related to the
geometrical properties of the underlying divergence. We also prove that our
robust estimators are efficiently computable and asymptotically consistent and
that they enjoy finite-sample performance guarantees. We exemplify our general
methodology by synthesizing explicit estimators induced by the
Kullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical
experiments based on synthetic and real data show that our robust estimators
are competitive with state-of-the-art estimators.",2024-05-30,"Man-Chung Yue, Yves Rychener, Daniel Kuhn, Viet Anh Nguyen",http://arxiv.org/pdf/2405.20124v1,cs.LG
Towards Faster Decentralized Stochastic Optimization with Communication Compression,"Communication efficiency has garnered significant attention as it is
considered the main bottleneck for large-scale decentralized Machine Learning
applications in distributed and federated settings. In this regime, clients are
restricted to transmitting small amounts of quantized information to their
neighbors over a communication graph. Numerous endeavors have been made to
address this challenging problem by developing algorithms with compressed
communication for decentralized non-convex optimization problems. Despite
considerable efforts, the current results suffer from various issues such as
non-scalability with the number of clients, requirements for large batches, or
bounded gradient assumption. In this paper, we introduce MoTEF, a novel
approach that integrates communication compression with Momentum Tracking and
Error Feedback. Our analysis demonstrates that MoTEF achieves most of the
desired properties, and significantly outperforms existing methods under
arbitrary data heterogeneity. We provide numerical experiments to validate our
theoretical findings and confirm the practical superiority of MoTEF.",2024-05-30,"Rustem Islamov, Yuan Gao, Sebastian U. Stich",http://arxiv.org/pdf/2405.20114v2,cs.LG
Low-dimensional approximations of the conditional law of Volterra processes: a non-positive curvature approach,"Predicting the conditional evolution of Volterra processes with stochastic
volatility is a crucial challenge in mathematical finance. While deep neural
network models offer promise in approximating the conditional law of such
processes, their effectiveness is hindered by the curse of dimensionality
caused by the infinite dimensionality and non-smooth nature of these problems.
To address this, we propose a two-step solution. Firstly, we develop a stable
dimension reduction technique, projecting the law of a reasonably broad class
of Volterra process onto a low-dimensional statistical manifold of non-positive
sectional curvature. Next, we introduce a sequentially deep learning model
tailored to the manifold's geometry, which we show can approximate the
projected conditional law of the Volterra process. Our model leverages an
auxiliary hypernetwork to dynamically update its internal parameters, allowing
it to encode non-stationary dynamics of the Volterra process, and it can be
interpreted as a gating mechanism in a mixture of expert models where each
expert is specialized at a specific point in time. Our hypernetwork further
allows us to achieve approximation rates that would seemingly only be possible
with very large networks.",2024-05-30,"Reza Arabpour, John Armstrong, Luca Galimberti, Anastasis Kratsios, Giulia Livieri",http://arxiv.org/pdf/2405.20094v1,cs.LG
VAAD: Visual Attention Analysis Dashboard applied to e-Learning,"In this paper, we present an approach in the Multimodal Learning Analytics
field. Within this approach, we have developed a tool to visualize and analyze
eye movement data collected during learning sessions in online courses. The
tool is named VAAD, an acronym for Visual Attention Analysis Dashboard. These
eye movement data have been gathered using an eye-tracker and subsequently
processed and visualized for interpretation. The purpose of the tool is to
conduct a descriptive analysis of the data by facilitating its visualization,
enabling the identification of differences and learning patterns among various
learner populations. Additionally, it integrates a predictive module capable of
anticipating learner activities during a learning session. Consequently, VAAD
holds the potential to offer valuable insights into online learning behaviors
from both descriptive and predictive perspectives.",2024-05-30,"Miriam Navarro, Álvaro Becerra, Roberto Daza, Ruth Cobos, Aythami Morales, Julian Fierrez",http://arxiv.org/pdf/2405.20091v4,cs.LG
Analysis of a multi-target linear shrinkage covariance estimator,"Multi-target linear shrinkage is an extension of the standard single-target
linear shrinkage for covariance estimation. We combine several constant
matrices - the targets - with the sample covariance matrix. We derive the
oracle and a \textit{bona fide} multi-target linear shrinkage estimator with
exact and empirical mean. In both settings, we proved its convergence towards
the oracle under Kolmogorov asymptotics. Finally, we show empirically that it
outperforms other standard estimators in various situations.",2024-05-30,Benoit Oriol,http://arxiv.org/pdf/2405.20086v2,cs.LG
Soft Partitioning of Latent Space for Semantic Channel Equalization,"Semantic channel equalization has emerged as a solution to address language
mismatch in multi-user semantic communications. This approach aims to align the
latent spaces of an encoder and a decoder which were not jointly trained and it
relies on a partition of the semantic (latent) space into atoms based on the
the semantic meaning. In this work we explore the role of the semantic space
partition in scenarios where the task structure involves a one-to-many mapping
between the semantic space and the action space. In such scenarios,
partitioning based on hard inference results results in loss of information
which degrades the equalization performance. We propose a soft criterion to
derive the atoms of the partition which leverages the soft decoder's output and
offers a more comprehensive understanding of the semantic space's structure.
Through empirical validation, we demonstrate that soft partitioning yields a
more descriptive and regular partition of the space, consequently enhancing the
performance of the equalization algorithm.",2024-05-30,"Tomás Hüttebräucker, Mohamed Sana, Emilio Calvanese Strinati",http://arxiv.org/pdf/2405.20085v2,cs.LG
"Segment, Shuffle, and Stitch: A Simple Layer for Improving Time-Series Representations","Existing approaches for learning representations of time-series keep the
temporal arrangement of the time-steps intact with the presumption that the
original order is the most optimal for learning. However, non-adjacent sections
of real-world time-series may have strong dependencies. Accordingly, we raise
the question: Is there an alternative arrangement for time-series which could
enable more effective representation learning? To address this, we propose a
simple plug-and-play neural network layer called Segment, Shuffle, and Stitch
(S3) designed to improve representation learning in time-series models. S3
works by creating non-overlapping segments from the original sequence and
shuffling them in a learned manner that is optimal for the task at hand. It
then re-attaches the shuffled segments back together and performs a learned
weighted sum with the original input to capture both the newly shuffled
sequence along with the original sequence. S3 is modular and can be stacked to
achieve different levels of granularity, and can be added to many forms of
neural architectures including CNNs or Transformers with negligible computation
overhead. Through extensive experiments on several datasets and
state-of-the-art baselines, we show that incorporating S3 results in
significant improvements for the tasks of time-series classification,
forecasting, and anomaly detection, improving performance on certain datasets
by up to 68\%. We also show that S3 makes the learning more stable with a
smoother training loss curve and loss landscape compared to the original
baseline. The code is available at
https://github.com/shivam-grover/S3-TimeSeries.",2024-05-30,"Shivam Grover, Amin Jalali, Ali Etemad",http://arxiv.org/pdf/2405.20082v3,cs.LG
Student Answer Forecasting: Transformer-Driven Answer Choice Prediction for Language Learning,"Intelligent Tutoring Systems (ITS) enhance personalized learning by
predicting student answers to provide immediate and customized instruction.
However, recent research has primarily focused on the correctness of the answer
rather than the student's performance on specific answer choices, limiting
insights into students' thought processes and potential misconceptions. To
address this gap, we present MCQStudentBert, an answer forecasting model that
leverages the capabilities of Large Language Models (LLMs) to integrate
contextual understanding of students' answering history along with the text of
the questions and answers. By predicting the specific answer choices students
are likely to make, practitioners can easily extend the model to new answer
choices or remove answer choices for the same multiple-choice question (MCQ)
without retraining the model. In particular, we compare MLP, LSTM, BERT, and
Mistral 7B architectures to generate embeddings from students' past
interactions, which are then incorporated into a finetuned BERT's
answer-forecasting mechanism. We apply our pipeline to a dataset of language
learning MCQ, gathered from an ITS with over 10,000 students to explore the
predictive accuracy of MCQStudentBert, which incorporates student interaction
patterns, in comparison to correct answer prediction and traditional
mastery-learning feature-based approaches. This work opens the door to more
personalized content, modularization, and granular support.",2024-05-30,"Elena Grazia Gado, Tommaso Martorella, Luca Zunino, Paola Mejia-Domenzain, Vinitra Swamy, Jibril Frej, Tanja Käser",http://arxiv.org/pdf/2405.20079v1,cs.LG
A Staged Approach using Machine Learning and Uncertainty Quantification to Predict the Risk of Hip Fracture,"Despite advancements in medical care, hip fractures impose a significant
burden on individuals and healthcare systems. This paper focuses on the
prediction of hip fracture risk in older and middle-aged adults, where falls
and compromised bone quality are predominant factors. We propose a novel staged
model that combines advanced imaging and clinical data to improve predictive
performance. By using CNNs to extract features from hip DXA images, along with
clinical variables, shape measurements, and texture features, our method
provides a comprehensive framework for assessing fracture risk. A staged
machine learning-based model was developed using two ensemble models: Ensemble
1 (clinical variables only) and Ensemble 2 (clinical variables and DXA imaging
features). This staged approach used uncertainty quantification from Ensemble 1
to decide if DXA features are necessary for further prediction. Ensemble 2
exhibited the highest performance, achieving an AUC of 0.9541, an accuracy of
0.9195, a sensitivity of 0.8078, and a specificity of 0.9427. The staged model
also performed well, with an AUC of 0.8486, an accuracy of 0.8611, a
sensitivity of 0.5578, and a specificity of 0.9249, outperforming Ensemble 1,
which had an AUC of 0.5549, an accuracy of 0.7239, a sensitivity of 0.1956, and
a specificity of 0.8343. Furthermore, the staged model suggested that 54.49% of
patients did not require DXA scanning. It effectively balanced accuracy and
specificity, offering a robust solution when DXA data acquisition is not always
feasible. Statistical tests confirmed significant differences between the
models, highlighting the advantages of the advanced modeling strategies. Our
staged approach could identify individuals at risk with a high accuracy but
reduce the unnecessary DXA scanning. It has great promise to guide
interventions to prevent hip fractures with reduced cost and radiation.",2024-05-30,"Anjum Shaik, Kristoffer Larsen, Nancy E. Lane, Chen Zhao, Kuan-Jui Su, Joyce H. Keyak, Qing Tian, Qiuying Sha, Hui Shen, Hong-Wen Deng, Weihua Zhou",http://arxiv.org/pdf/2405.20071v1,cs.LG
Would I Lie To You? Inference Time Alignment of Language Models using Direct Preference Heads,"Pre-trained Language Models (LMs) exhibit strong zero-shot and in-context
learning capabilities; however, their behaviors are often difficult to control.
By utilizing Reinforcement Learning from Human Feedback (RLHF), it is possible
to fine-tune unsupervised LMs to follow instructions and produce outputs that
reflect human preferences. Despite its benefits, RLHF has been shown to
potentially harm a language model's reasoning capabilities and introduce
artifacts such as hallucinations where the model may fabricate facts. To
address this issue we introduce Direct Preference Heads (DPH), a fine-tuning
framework that enables LMs to learn human preference signals through an
auxiliary reward head without directly affecting the output distribution of the
language modeling head. We perform a theoretical analysis of our objective
function and find strong ties to Conservative Direct Preference Optimization
(cDPO). Finally we evaluate our models on GLUE, RACE, and the GPT4All
evaluation suite and demonstrate that our method produces models which achieve
higher scores than those fine-tuned with Supervised Fine-Tuning (SFT) or Direct
Preference Optimization (DPO) alone.",2024-05-30,"Avelina Asada Hadji-Kyriacou, Ognjen Arandjelovic",http://arxiv.org/pdf/2405.20053v1,cs.LG
Hardware-Efficient EMG Decoding for Next-Generation Hand Prostheses,"Advancements in neural engineering have enabled the development of Robotic
Prosthetic Hands (RPHs) aimed at restoring hand functionality. Current
commercial RPHs offer limited control through basic on/off commands. Recent
progresses in machine learning enable finger movement decoding with higher
degrees of freedom, yet the high computational complexity of such models limits
their application in portable devices. Future RPH designs must balance
portability, low power consumption, and high decoding accuracy to be practical
for individuals with disabilities. To this end, we introduce a novel
attractor-based neural network to realize on-chip movement decoding for
next-generation portable RPHs. The proposed architecture comprises an encoder,
an attention layer, an attractor network, and a refinement regressor. We tested
our model on four healthy subjects and achieved a decoding accuracy of 80.3%.
Our proposed model is over 120 and 50 times more compact compared to
state-of-the-art LSTM and CNN models, respectively, with comparable (or
superior) decoding accuracy. Therefore, it exhibits minimal hardware complexity
and can be effectively integrated as a System-on-Chip.",2024-05-30,"Mohammad Kalbasi, MohammadAli Shaeri, Vincent Alexandre Mendez, Solaiman Shokur, Silvestro Micera, Mahsa Shoaran",http://arxiv.org/pdf/2405.20052v2,cs.LG
Threshold-Independent Fair Matching through Score Calibration,"Entity Matching (EM) is a critical task in numerous fields, such as
healthcare, finance, and public administration, as it identifies records that
refer to the same entity within or across different databases. EM faces
considerable challenges, particularly with false positives and negatives. These
are typically addressed by generating matching scores and apply thresholds to
balance false positives and negatives in various contexts. However, adjusting
these thresholds can affect the fairness of the outcomes, a critical factor
that remains largely overlooked in current fair EM research. The existing body
of research on fair EM tends to concentrate on static thresholds, neglecting
their critical impact on fairness. To address this, we introduce a new approach
in EM using recent metrics for evaluating biases in score based binary
classification, particularly through the lens of distributional parity. This
approach enables the application of various bias metrics like equalized odds,
equal opportunity, and demographic parity without depending on threshold
settings. Our experiments with leading matching methods reveal potential
biases, and by applying a calibration technique for EM scores using Wasserstein
barycenters, we not only mitigate these biases but also preserve accuracy
across real world datasets. This paper contributes to the field of fairness in
data cleaning, especially within EM, which is a central task in data cleaning,
by promoting a method for generating matching scores that reduce biases across
different thresholds.",2024-05-30,"Mohammad Hossein Moslemi, Mostafa Milani",http://arxiv.org/pdf/2405.20051v1,cs.LG
"Iterative Learning Control of Fast, Nonlinear, Oscillatory Dynamics (Preprint)","The sudden onset of deleterious and oscillatory dynamics (often called
instabilities) is a known challenge in many fluid, plasma, and aerospace
systems. These dynamics are difficult to address because they are nonlinear,
chaotic, and are often too fast for active control schemes. In this work, we
develop an alternative active controls system using an iterative,
trajectory-optimization and parameter-tuning approach based on Iterative
Learning Control (ILC), Time-Lagged Phase Portraits (TLPP) and Gaussian Process
Regression (GPR). The novelty of this approach is that it can control a
system's dynamics despite the controller being much slower than the dynamics.
We demonstrate this controller on the Lorenz system of equations where it
iteratively adjusts (tunes) the system's input parameters to successfully
reproduce a desired oscillatory trajectory or state. Additionally, we
investigate the system's dynamical sensitivity to its control parameters,
identify continuous and bounded regions of desired dynamical trajectories, and
demonstrate that the controller is robust to missing information and
uncontrollable parameters as long as certain requirements are met. The
controller presented in this work provides a framework for low-speed control
for a variety of fast, nonlinear systems that may aid in instability
suppression and mitigation.",2024-05-30,"John W. Brooks, Christine M. Greve",http://arxiv.org/pdf/2405.20045v1,cs.LG
CycleFormer : TSP Solver Based on Language Modeling,"We propose a new transformer model for the Traveling Salesman Problem (TSP)
called CycleFormer. We identified distinctive characteristics that need to be
considered when applying a conventional transformer model to TSP and aimed to
fully incorporate these elements into the TSP-specific transformer. Unlike the
token sets in typical language models, which are limited and static, the token
(node) set in TSP is unlimited and dynamic. To exploit this fact to the
fullest, we equated the encoder output with the decoder linear layer and
directly connected the context vector of the encoder to the decoder encoding.
Additionally, we added a positional encoding to the encoder tokens that
reflects the two-dimensional nature of TSP, and devised a circular positional
encoding for the decoder tokens that considers the cyclic properties of a tour.
By incorporating these ideas, CycleFormer outperforms state-of-the-art (SOTA)
transformer models for TSP from TSP-50 to TSP-500. Notably, on TSP-500, the
optimality gap was reduced by approximately 2.8 times, from 3.09% to 1.10%,
compared to the existing SOTA. The code will be made available at
https://github.com/Giventicket/CycleFormer.",2024-05-30,"Jieun Yook, Junpyo Seo, Joon Huh, Han Joon Byun, Byung-ro Moon",http://arxiv.org/pdf/2405.20042v4,cs.LG
Task-Agnostic Machine-Learning-Assisted Inference,"Machine learning (ML) is playing an increasingly important role in scientific
research. In conjunction with classical statistical approaches, ML-assisted
analytical strategies have shown great promise in accelerating research
findings. This has also opened a whole field of methodological research
focusing on integrative approaches that leverage both ML and statistics to
tackle data science challenges. One type of study that has quickly gained
popularity employs ML to predict unobserved outcomes in massive samples, and
then uses predicted outcomes in downstream statistical inference. However,
existing methods designed to ensure the validity of this type of
post-prediction inference are limited to very basic tasks such as linear
regression analysis. This is because any extension of these approaches to new,
more sophisticated statistical tasks requires task-specific algebraic
derivations and software implementations, which ignores the massive library of
existing software tools already developed for the same scientific problem given
observed data. This severely constrains the scope of application for
post-prediction inference. To address this challenge, we introduce a novel
statistical framework named PSPS for task-agnostic ML-assisted inference. It
provides a post-prediction inference solution that can be easily plugged into
almost any established data analysis routines. It delivers valid and efficient
inference that is robust to arbitrary choice of ML model, allowing nearly all
existing statistical frameworks to be incorporated into the analysis of
ML-predicted data. Through extensive experiments, we showcase our method's
validity, versatility, and superiority compared to existing approaches. Our
software is available at https://github.com/qlu-lab/psps.",2024-05-30,"Jiacheng Miao, Qiongshi Lu",http://arxiv.org/pdf/2405.20039v3,cs.LG
A Random Forest-based Prediction Model for Turning Points in Antagonistic Event-Group Competitions,"At present, most of the prediction studies related to antagonistic
event-group competitions focus on the prediction of competition results, and
less on the prediction of the competition process, which can not provide
real-time feedback of the athletes' state information in the actual
competition, and thus can not analyze the changes of the competition situation.
In order to solve this problem, this paper proposes a prediction model based on
Random Forest for the turning point of the antagonistic event-group. Firstly,
the quantitative equation of competitive potential energy is proposed;
Secondly, the quantitative value of competitive potential energy is obtained by
using the dynamic combination of weights method, and the turning point of the
competition situation of the antagonistic event-group is marked according to
the quantitative time series graph; Finally, the random forest prediction model
based on the optimisation of the KM-SMOTE algorithm and the grid search method
is established. The experimental analysis shows that: The quantitative equation
of competitive potential energy can effectively reflect the dynamic situation
of the competition; The model can effectively predict the turning point of the
competition situation of the antagonistic event-group, and the recall rate of
the model in the test set is 86.13%; The model has certain significance for the
future study of the competition situation of the antagonistic event-group.",2024-05-30,Zishuo Zhu,http://arxiv.org/pdf/2405.20029v2,cs.LG
A Simple and Adaptive Learning Rate for FTRL in Online Learning with Minimax Regret of $Θ(T^{2/3})$ and its Application to Best-of-Both-Worlds,"Follow-the-Regularized-Leader (FTRL) is a powerful framework for various
online learning problems. By designing its regularizer and learning rate to be
adaptive to past observations, FTRL is known to work adaptively to various
properties of an underlying environment. However, most existing adaptive
learning rates are for online learning problems with a minimax regret of
$\Theta(\sqrt{T})$ for the number of rounds $T$, and there are only a few
studies on adaptive learning rates for problems with a minimax regret of
$\Theta(T^{2/3})$, which include several important problems dealing with
indirect feedback. To address this limitation, we establish a new adaptive
learning rate framework for problems with a minimax regret of
$\Theta(T^{2/3})$. Our learning rate is designed by matching the stability,
penalty, and bias terms that naturally appear in regret upper bounds for
problems with a minimax regret of $\Theta(T^{2/3})$. As applications of this
framework, we consider three major problems with a minimax regret of
$\Theta(T^{2/3})$: partial monitoring, graph bandits, and multi-armed bandits
with paid observations. We show that FTRL with our learning rate and the
Tsallis entropy regularizer improves existing Best-of-Both-Worlds (BOBW) regret
upper bounds, which achieve simultaneous optimality in the stochastic and
adversarial regimes. The resulting learning rate is surprisingly simple
compared to the existing learning rates for BOBW algorithms for problems with a
minimax regret of $\Theta(T^{2/3})$.",2024-05-30,"Taira Tsuchiya, Shinji Ito",http://arxiv.org/pdf/2405.20028v2,cs.LG
Safe Multi-agent Reinforcement Learning with Natural Language Constraints,"The role of natural language constraints in Safe Multi-agent Reinforcement
Learning (MARL) is crucial, yet often overlooked. While Safe MARL has vast
potential, especially in fields like robotics and autonomous vehicles, its full
potential is limited by the need to define constraints in pre-designed
mathematical terms, which requires extensive domain expertise and reinforcement
learning knowledge, hindering its broader adoption. To address this limitation
and make Safe MARL more accessible and adaptable, we propose a novel approach
named Safe Multi-agent Reinforcement Learning with Natural Language constraints
(SMALL). Our method leverages fine-tuned language models to interpret and
process free-form textual constraints, converting them into semantic embeddings
that capture the essence of prohibited states and behaviours. These embeddings
are then integrated into the multi-agent policy learning process, enabling
agents to learn policies that minimize constraint violations while optimizing
rewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a
multi-task benchmark designed to assess the performance of multiple agents in
adhering to natural language constraints. Empirical evaluations across various
environments demonstrate that SMALL achieves comparable rewards and
significantly fewer constraint violations, highlighting its effectiveness in
understanding and enforcing natural language constraints.",2024-05-30,"Ziyan Wang, Meng Fang, Tristan Tomilin, Fei Fang, Yali Du",http://arxiv.org/pdf/2405.20018v1,cs.LG
subMFL: Compatiple subModel Generation for Federated Learning in Device Heterogenous Environment,"Federated Learning (FL) is commonly used in systems with distributed and
heterogeneous devices with access to varying amounts of data and diverse
computing and storage capacities. FL training process enables such devices to
update the weights of a shared model locally using their local data and then a
trusted central server combines all of those models to generate a global model.
In this way, a global model is generated while the data remains local to
devices to preserve privacy. However, training large models such as Deep Neural
Networks (DNNs) on resource-constrained devices can take a prohibitively long
time and consume a large amount of energy. In the current process, the
low-capacity devices are excluded from the training process, although they
might have access to unseen data. To overcome this challenge, we propose a
model compression approach that enables heterogeneous devices with varying
computing capacities to participate in the FL process. In our approach, the
server shares a dense model with all devices to train it: Afterwards, the
trained model is gradually compressed to obtain submodels with varying levels
of sparsity to be used as suitable initial global models for
resource-constrained devices that were not capable of train the first dense
model. This results in an increased participation rate of resource-constrained
devices while the transferred weights from the previous round of training are
preserved. Our validation experiments show that despite reaching about 50 per
cent global sparsity, generated submodels maintain their accuracy while can be
shared to increase participation by around 50 per cent.",2024-05-30,"Zeyneddin Oz, Ceylan Soygul Oz, Abdollah Malekjafarian, Nima Afraz, Fatemeh Golpayegani",http://arxiv.org/pdf/2405.20014v1,cs.LG
FlexiDrop: Theoretical Insights and Practical Advances in Random Dropout Method on GNNs,"Graph Neural Networks (GNNs) are powerful tools for handling graph-type data.
Recently, GNNs have been widely applied in various domains, but they also face
some issues, such as overfitting, over-smoothing and non-robustness. The
existing research indicates that random dropout methods are an effective way to
address these issues. However, random dropout methods in GNNs still face
unresolved problems. Currently, the choice of dropout rate, often determined by
heuristic or grid search methods, can increase the generalization error,
contradicting the principal aims of dropout. In this paper, we propose a novel
random dropout method for GNNs called FlexiDrop. First, we conduct a
theoretical analysis of dropout in GNNs using rademacher complexity and
demonstrate that the generalization error of traditional random dropout methods
is constrained by a function related to the dropout rate. Subsequently, we use
this function as a regularizer to unify the dropout rate and empirical loss
within a single loss function, optimizing them simultaneously. Therefore, our
method enables adaptive adjustment of the dropout rate and theoretically
balances the trade-off between model complexity and generalization ability.
Furthermore, extensive experimental results on benchmark datasets show that
FlexiDrop outperforms traditional random dropout methods in GNNs.",2024-05-30,"Zhiheng Zhou, Sihao Liu, Weichen Zhao",http://arxiv.org/pdf/2405.20012v1,cs.LG
Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities,"Uncertainty quantification in Large Language Models (LLMs) is crucial for
applications where safety and reliability are important. In particular,
uncertainty can be used to improve the trustworthiness of LLMs by detecting
factually incorrect model responses, commonly called hallucinations.
Critically, one should seek to capture the model's semantic uncertainty, i.e.,
the uncertainty over the meanings of LLM outputs, rather than uncertainty over
lexical or syntactic variations that do not affect answer correctness. To
address this problem, we propose Kernel Language Entropy (KLE), a novel method
for uncertainty estimation in white- and black-box LLMs. KLE defines positive
semidefinite unit trace kernels to encode the semantic similarities of LLM
outputs and quantifies uncertainty using the von Neumann entropy. It considers
pairwise semantic dependencies between answers (or semantic clusters),
providing more fine-grained uncertainty estimates than previous methods based
on hard clustering of answers. We theoretically prove that KLE generalizes the
previous state-of-the-art method called semantic entropy and empirically
demonstrate that it improves uncertainty quantification performance across
multiple natural language generation datasets and LLM architectures.",2024-05-30,"Alexander Nikitin, Jannik Kossen, Yarin Gal, Pekka Marttinen",http://arxiv.org/pdf/2405.20003v1,cs.LG
Symmetries in Overparametrized Neural Networks: A Mean-Field View,"We develop a Mean-Field (MF) view of the learning dynamics of
overparametrized Artificial Neural Networks (NN) under data symmetric in law
wrt the action of a general compact group $G$. We consider for this a class of
generalized shallow NNs given by an ensemble of $N$ multi-layer units, jointly
trained using stochastic gradient descent (SGD) and possibly
symmetry-leveraging (SL) techniques, such as Data Augmentation (DA), Feature
Averaging (FA) or Equivariant Architectures (EA). We introduce the notions of
weakly and strongly invariant laws (WI and SI) on the parameter space of each
single unit, corresponding, respectively, to $G$-invariant distributions, and
to distributions supported on parameters fixed by the group action (which
encode EA). This allows us to define symmetric models compatible with taking
$N\to\infty$ and give an interpretation of the asymptotic dynamics of DA, FA
and EA in terms of Wasserstein Gradient Flows describing their MF limits. When
activations respect the group action, we show that, for symmetric data, DA, FA
and freely-trained models obey the exact same MF dynamic, which stays in the
space of WI laws and minimizes therein the population risk. We also give a
counterexample to the general attainability of an optimum over SI laws. Despite
this, quite remarkably, we show that the set of SI laws is also preserved by
the MF dynamics even when freely trained. This sharply contrasts the finite-$N$
setting, in which EAs are generally not preserved by unconstrained SGD. We
illustrate the validity of our findings as $N$ gets larger in a teacher-student
experimental setting, training a student NN to learn from a WI, SI or arbitrary
teacher model through various SL schemes. We last deduce a data-driven
heuristic to discover the largest subspace of parameters supporting SI
distributions for a problem, that could be used for designing EA with minimal
generalization error.",2024-05-30,"Javier Maass, Joaquin Fontbona",http://arxiv.org/pdf/2405.19995v3,cs.LG
Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics,"Natural language is often the easiest and most convenient modality for humans
to specify tasks for robots. However, learning to ground language to behavior
typically requires impractical amounts of diverse, language-annotated
demonstrations collected on each target robot. In this work, we aim to separate
the problem of what to accomplish from how to accomplish it, as the former can
benefit from substantial amounts of external observation-only data, and only
the latter depends on a specific robot embodiment. To this end, we propose
Video-Language Critic, a reward model that can be trained on readily available
cross-embodiment data using contrastive learning and a temporal ranking
objective, and use it to score behavior traces from a separate actor. When
trained on Open X-Embodiment data, our reward model enables 2x more
sample-efficient policy training on Meta-World tasks than a sparse reward only,
despite a significant domain gap. Using in-domain data but in a challenging
task generalization setting on Meta-World, we further demonstrate more
sample-efficient training than is possible with prior language-conditioned
reward models that are either trained with binary classification, use static
images, or do not leverage the temporal information present in video data.",2024-05-30,"Minttu Alakuijala, Reginald McLean, Isaac Woungang, Nariman Farsad, Samuel Kaski, Pekka Marttinen, Kai Yuan",http://arxiv.org/pdf/2405.19988v2,cs.LG
Targeted Sequential Indirect Experiment Design,"Scientific hypotheses typically concern specific aspects of complex,
imperfectly understood or entirely unknown mechanisms, such as the effect of
gene expression levels on phenotypes or how microbial communities influence
environmental health. Such queries are inherently causal (rather than purely
associational), but in many settings, experiments can not be conducted directly
on the target variables of interest, but are indirect. Therefore, they perturb
the target variable, but do not remove potential confounding factors. If,
additionally, the resulting experimental measurements are multi-dimensional and
the studied mechanisms nonlinear, the query of interest is generally not
identified. We develop an adaptive strategy to design indirect experiments that
optimally inform a targeted query about the ground truth mechanism in terms of
sequentially narrowing the gap between an upper and lower bound on the query.
While the general formulation consists of a bi-level optimization procedure, we
derive an efficiently estimable analytical kernel-based estimator of the bounds
for the causal effect, a query of key interest, and demonstrate the efficacy of
our approach in confounded, multivariate, nonlinear synthetic settings.",2024-05-30,"Elisabeth Ailer, Niclas Dern, Jason Hartford, Niki Kilbertus",http://arxiv.org/pdf/2405.19985v2,cs.LG
Domain Adaptation with Cauchy-Schwarz Divergence,"Domain adaptation aims to use training data from one or multiple source
domains to learn a hypothesis that can be generalized to a different, but
related, target domain. As such, having a reliable measure for evaluating the
discrepancy of both marginal and conditional distributions is crucial. We
introduce Cauchy-Schwarz (CS) divergence to the problem of unsupervised domain
adaptation (UDA). The CS divergence offers a theoretically tighter
generalization error bound than the popular Kullback-Leibler divergence. This
holds for the general case of supervised learning, including multi-class
classification and regression. Furthermore, we illustrate that the CS
divergence enables a simple estimator on the discrepancy of both marginal and
conditional distributions between source and target domains in the
representation space, without requiring any distributional assumptions. We
provide multiple examples to illustrate how the CS divergence can be
conveniently used in both distance metric- or adversarial training-based UDA
frameworks, resulting in compelling performance.",2024-05-30,"Wenzhe Yin, Shujian Yu, Yicong Lin, Jie Liu, Jan-Jakob Sonke, Efstratios Gavves",http://arxiv.org/pdf/2405.19978v1,cs.LG
Consistent Submodular Maximization,"Maximizing monotone submodular functions under cardinality constraints is a
classic optimization task with several applications in data mining and machine
learning. In this paper we study this problem in a dynamic environment with
consistency constraints: elements arrive in a streaming fashion and the goal is
maintaining a constant approximation to the optimal solution while having a
stable solution (i.e., the number of changes between two consecutive solutions
is bounded). We provide algorithms in this setting with different trade-offs
between consistency and approximation quality. We also complement our
theoretical results with an experimental analysis showing the effectiveness of
our algorithms in real-world instances.",2024-05-30,"Paul Dütting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, Morteza Zadimoghaddam",http://arxiv.org/pdf/2405.19977v1,cs.LG
GasTrace: Detecting Sandwich Attack Malicious Accounts in Ethereum,"The openness and transparency of Ethereum transaction data make it easy to be
exploited by any entities, executing malicious attacks. The sandwich attack
manipulates the Automated Market Maker (AMM) mechanism, profiting from
manipulating the market price through front or after-running transactions. To
identify and prevent sandwich attacks, we propose a cascade classification
framework GasTrace. GasTrace analyzes various transaction features to detect
malicious accounts, notably through the analysis and modeling of Gas features.
In the initial classification, we utilize the Support Vector Machine (SVM) with
the Radial Basis Function (RBF) kernel to generate the predicted probabilities
of accounts, further constructing a detailed transaction network. Subsequently,
the behavior features are captured by the Graph Attention Network (GAT)
technique in the second classification. Through cascade classification,
GasTrace can analyze and classify the sandwich attacks. Our experimental
results demonstrate that GasTrace achieves a remarkable detection and
generation capability, performing an accuracy of 96.73% and an F1 score of
95.71% for identifying sandwich attack accounts.",2024-05-30,"Zekai Liu, Xiaoqi Li, Hongli Peng, Wenkai Li",http://arxiv.org/pdf/2405.19971v2,cs.LG
Improved Out-of-Scope Intent Classification with Dual Encoding and Threshold-based Re-Classification,"Detecting out-of-scope user utterances is essential for task-oriented
dialogues and intent classification. Current methodologies face difficulties
with the unpredictable distribution of outliers and often rely on assumptions
about data distributions. We present the Dual Encoder for Threshold-Based
Re-Classification (DETER) to address these challenges. This end-to-end
framework efficiently detects out-of-scope intents without requiring
assumptions on data distributions or additional post-processing steps. The core
of DETER utilizes dual text encoders, the Universal Sentence Encoder (USE) and
the Transformer-based Denoising AutoEncoder (TSDAE), to generate user utterance
embeddings, which are classified through a branched neural architecture.
Further, DETER generates synthetic outliers using self-supervision and
incorporates out-of-scope phrases from open-domain datasets. This approach
ensures a comprehensive training set for out-of-scope detection. Additionally,
a threshold-based re-classification mechanism refines the model's initial
predictions. Evaluations on the CLINC-150, Stackoverflow, and Banking77
datasets demonstrate DETER's efficacy. Our model outperforms previous
benchmarks, increasing up to 13% and 5% in F1 score for known and unknown
intents on CLINC-150 and Stackoverflow, and 16% for known and 24% % for unknown
intents on Banking77. The source code has been released at
https://github.com/Hossam-Mohammed-tech/Intent_Classification_OOS.",2024-05-30,"Hossam M. Zawbaa, Wael Rashwan, Sourav Dutta, Haytham Assem",http://arxiv.org/pdf/2405.19967v2,cs.LG
Use of a Multiscale Vision Transformer to predict Nursing Activities Score from Low Resolution Thermal Videos in an Intensive Care Unit,"Excessive caregiver workload in hospital nurses has been implicated in poorer
patient care and increased worker burnout. Measurement of this workload in the
Intensive Care Unit (ICU) is often done using the Nursing Activities Score
(NAS), but this is usually recorded manually and sporadically. Previous work
has made use of Ambient Intelligence (AmI) by using computer vision to
passively derive caregiver-patient interaction times to monitor staff workload.
In this letter, we propose using a Multiscale Vision Transformer (MViT) to
passively predict the NAS from low-resolution thermal videos recorded in an
ICU. 458 videos were obtained from an ICU in Melbourne, Australia and used to
train a MViTv2 model using an indirect prediction and a direct prediction
method. The indirect method predicted 1 of 8 potentially identifiable NAS
activities from the video before inferring the NAS. The direct method predicted
the NAS score immediately from the video. The indirect method yielded an
average 5-fold accuracy of 57.21%, an area under the receiver operating
characteristic curve (ROC AUC) of 0.865, a F1 score of 0.570 and a mean squared
error (MSE) of 28.16. The direct method yielded a MSE of 18.16. We also showed
that the MViTv2 outperforms similar models such as R(2+1)D and ResNet50-LSTM
under identical settings.
  This study shows the feasibility of using a MViTv2 to passively predict the
NAS in an ICU and monitor staff workload automatically. Our results above also
show an increased accuracy in predicting NAS directly versus predicting NAS
indirectly. We hope that our study can provide a direction for future work and
further improve the accuracy of passive NAS monitoring.",2024-05-30,"Isaac YL Lee, Thanh Nguyen-Duc, Ryo Ueno, Jesse Smith, Peter Y Chan",http://arxiv.org/pdf/2406.04364v1,cs.LG
Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers,"Understanding transition pathways between two meta-stable states of a
molecular system is crucial to advance drug discovery and material design.
However, unbiased molecular dynamics (MD) simulations are computationally
infeasible because of the high energy barriers that separate these states.
Although recent machine learning techniques are proposed to sample rare events,
they are often limited to simple systems and rely on collective variables (CVs)
derived from costly domain expertise. In this paper, we introduce a novel
approach that trains diffusion path samplers (DPS) to address the transition
path sampling (TPS) problem without requiring CVs. We reformulate the problem
as an amortized sampling from the transition path distribution by minimizing
the log-variance divergence between the path distribution induced by DPS and
the transition path distribution. Based on the log-variance divergence, we
propose learnable control variates to reduce the variance of gradient
estimators and the off-policy training objective with replay buffers and
simulated annealing techniques to improve sample efficiency and diversity. We
also propose a scale-based equivariant parameterization of the bias forces to
ensure scalability for large systems. We extensively evaluate our approach,
termed TPS-DPS, on a synthetic system, small peptide, and challenging
fast-folding proteins, demonstrating that it produces more realistic and
diverse transition pathways than existing baselines.",2024-05-30,"Kiyoung Seong, Seonghyun Park, Seonghwan Kim, Woo Youn Kim, Sungsoo Ahn",http://arxiv.org/pdf/2405.19961v5,cs.LG
"GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection, Localization, Reasoning, and Remediation","A key challenge associated with Kubernetes configuration files (KCFs) is that
they are often highly complex and error-prone, leading to security
vulnerabilities and operational setbacks. Rule-based (RB) tools for KCF
misconfiguration detection rely on static rule sets, making them inherently
limited and unable to detect newly-discovered misconfigurations. RB tools also
suffer from misdetection, since mistakes are likely when coding the detection
rules. Recent methods for detecting and remediating KCF misconfigurations are
limited in terms of their scalability and detection coverage, or due to the
fact that they have high expertise requirements and do not offer automated
remediation along with misconfiguration detection. Novel approaches that employ
LLMs in their pipeline rely on API-based, general-purpose, and mainly
commercial models. Thus, they pose security challenges, have inconsistent
classification performance, and can be costly. In this paper, we propose
GenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition
to detecting a wide variety of KCF misconfigurations, also identifies the exact
location of the misconfigurations and provides detailed reasoning about them,
along with suggested remediation. When empirically compared with three
industry-standard RB tools, GenKubeSec achieved equivalent precision (0.990)
and superior recall (0.999). When a random sample of KCFs was examined by a
Kubernetes security expert, GenKubeSec's explanations as to misconfiguration
localization, reasoning and remediation were 100% correct, informative and
useful. To facilitate further advancements in this domain, we share the unique
dataset we collected, a unified misconfiguration index we developed for label
standardization, our experimentation code, and GenKubeSec itself as an
open-source tool.",2024-05-30,"Ehud Malul, Yair Meidan, Dudu Mimran, Yuval Elovici, Asaf Shabtai",http://arxiv.org/pdf/2405.19954v1,cs.LG
Multimodal Lego: Model Merging and Fine-Tuning Across Topologies and Modalities in Biomedicine,"Learning holistic computational representations in physical, chemical or
biological systems requires the ability to process information from different
distributions and modalities within the same model. Thus, the demand for
multimodal machine learning models has sharply risen for modalities that go
beyond vision and language, such as sequences, graphs, time series, or tabular
data. While there are many available multimodal fusion and alignment
approaches, most of them require end-to-end training, scale quadratically with
the number of modalities, cannot handle cases of high modality imbalance in the
training set, or are highly topology-specific, making them too restrictive for
many biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego),
a general-purpose fusion framework to turn any set of encoders into a
competitive multimodal model with no or minimal fine-tuning. We achieve this by
introducing a wrapper for any unimodal encoder that enforces shape consistency
between modality representations. It harmonises these representations by
learning features in the frequency domain to enable model merging with little
signal interference. We show that MM-Lego 1) can be used as a model merging
method which achieves competitive performance with end-to-end fusion models
without any fine-tuning, 2) can operate on any unimodal encoder, and 3) is a
model fusion method that, with minimal fine-tuning, surpasses all benchmarks in
five out of seven datasets.",2024-05-30,"Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik",http://arxiv.org/pdf/2405.19950v2,cs.LG
Learning Latent Graph Structures and their Uncertainty,"Within a prediction task, Graph Neural Networks (GNNs) use relational
information as an inductive bias to enhance the model's accuracy. As
task-relevant relations might be unknown, graph structure learning approaches
have been proposed to learn them while solving the downstream prediction task.
In this paper, we demonstrate that minimization of a point-prediction loss
function, e.g., the mean absolute error, does not guarantee proper learning of
the latent relational information and its associated uncertainty. Conversely,
we prove that a suitable loss function on the stochastic model outputs
simultaneously grants (i) the unknown adjacency matrix latent distribution and
(ii) optimal performance on the prediction task. Finally, we propose a
sampling-based method that solves this joint learning task. Empirical results
validate our theoretical claims and demonstrate the effectiveness of the
proposed approach.",2024-05-30,"Alessandro Manenti, Daniele Zambon, Cesare Alippi",http://arxiv.org/pdf/2405.19933v1,cs.LG
Exploring Diffusion Models' Corruption Stage in Few-Shot Fine-tuning and Mitigating with Bayesian Neural Networks,"Few-shot fine-tuning of Diffusion Models (DMs) is a key advancement,
significantly reducing training costs and enabling personalized AI
applications. However, we explore the training dynamics of DMs and observe an
unanticipated phenomenon: during the training process, image fidelity initially
improves, then unexpectedly deteriorates with the emergence of noisy patterns,
only to recover later with severe overfitting. We term the stage with generated
noisy patterns as corruption stage. To understand this corruption stage, we
begin by theoretically modeling the one-shot fine-tuning scenario, and then
extend this modeling to more general cases. Through this modeling, we identify
the primary cause of this corruption stage: a narrowed learning distribution
inherent in the nature of few-shot fine-tuning. To tackle this, we apply
Bayesian Neural Networks (BNNs) on DMs with variational inference to implicitly
broaden the learned distribution, and present that the learning target of the
BNNs can be naturally regarded as an expectation of the diffusion loss and a
further regularization with the pretrained DMs. This approach is highly
compatible with current few-shot fine-tuning methods in DMs and does not
introduce any extra inference costs. Experimental results demonstrate that our
method significantly mitigates corruption, and improves the fidelity, quality
and diversity of the generated images in both object-driven and subject-driven
generation tasks.",2024-05-30,"Xiaoyu Wu, Jiaru Zhang, Yang Hua, Bohan Lyu, Hao Wang, Tao Song, Haibing Guan",http://arxiv.org/pdf/2405.19931v1,cs.LG
BAN: Detecting Backdoors Activated by Adversarial Neuron Noise,"Backdoor attacks on deep learning represent a recent threat that has gained
significant attention in the research community. Backdoor defenses are mainly
based on backdoor inversion, which has been shown to be generic,
model-agnostic, and applicable to practical threat scenarios. State-of-the-art
backdoor inversion recovers a mask in the feature space to locate prominent
backdoor features, where benign and backdoor features can be disentangled.
However, it suffers from high computational overhead, and we also find that it
overly relies on prominent backdoor features that are highly distinguishable
from benign features. To tackle these shortcomings, this paper improves
backdoor feature inversion for backdoor detection by incorporating extra neuron
activation information. In particular, we adversarially increase the loss of
backdoored models with respect to weights to activate the backdoor effect,
based on which we can easily differentiate backdoored and clean models.
Experimental results demonstrate our defense, BAN, is 1.37$\times$ (on
CIFAR-10) and 5.11$\times$ (on ImageNet200) more efficient with an average
9.99\% higher detect success rate than the state-of-the-art defense BTI-DBF.
Our code and trained models are publicly available
at~\url{https://github.com/xiaoyunxxy/ban}.",2024-05-30,"Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Shujian Yu, Stjepan Picek",http://arxiv.org/pdf/2405.19928v2,cs.LG
Unraveling the Impact of Heterophilic Structures on Graph Positive-Unlabeled Learning,"While Positive-Unlabeled (PU) learning is vital in many real-world scenarios,
its application to graph data still remains under-explored. We unveil that a
critical challenge for PU learning on graph lies on the edge heterophily, which
directly violates the irreducibility assumption for Class-Prior Estimation
(class prior is essential for building PU learning algorithms) and degenerates
the latent label inference on unlabeled nodes during classifier training. In
response to this challenge, we introduce a new method, named Graph PU Learning
with Label Propagation Loss (GPL). Specifically, GPL considers learning from PU
nodes along with an intermediate heterophily reduction, which helps mitigate
the negative impact of the heterophilic structure. We formulate this procedure
as a bilevel optimization that reduces heterophily in the inner loop and
efficiently learns a classifier in the outer loop. Extensive experiments across
a variety of datasets have shown that GPL significantly outperforms baseline
methods, confirming its effectiveness and superiority.",2024-05-30,"Yuhao Wu, Jiangchao Yao, Bo Han, Lina Yao, Tongliang Liu",http://arxiv.org/pdf/2405.19919v2,cs.LG
Robust Kernel Hypothesis Testing under Data Corruption,"We propose a general method for constructing robust permutation tests under
data corruption. The proposed tests effectively control the non-asymptotic type
I error under data corruption, and we prove their consistency in power under
minimal conditions. This contributes to the practical deployment of hypothesis
tests for real-world applications with potential adversarial attacks. For the
two-sample and independence settings, we show that our kernel robust tests are
minimax optimal, in the sense that they are guaranteed to be non-asymptotically
powerful against alternatives uniformly separated from the null in the kernel
MMD and HSIC metrics at some optimal rate (tight with matching lower bound). We
point out that existing differentially private tests can be adapted to be
robust to data corruption, and we demonstrate in experiments that our proposed
tests achieve much higher power than these private tests. Finally, we provide
publicly available implementations and empirically illustrate the practicality
of our robust tests.",2024-05-30,"Antonin Schrab, Ilmun Kim",http://arxiv.org/pdf/2405.19912v3,cs.LG
Adaptive Advantage-Guided Policy Regularization for Offline Reinforcement Learning,"In offline reinforcement learning, the challenge of out-of-distribution (OOD)
is pronounced. To address this, existing methods often constrain the learned
policy through policy regularization. However, these methods often suffer from
the issue of unnecessary conservativeness, hampering policy improvement. This
occurs due to the indiscriminate use of all actions from the behavior policy
that generates the offline dataset as constraints. The problem becomes
particularly noticeable when the quality of the dataset is suboptimal. Thus, we
propose Adaptive Advantage-guided Policy Regularization (A2PR), obtaining
high-advantage actions from an augmented behavior policy combined with VAE to
guide the learned policy. A2PR can select high-advantage actions that differ
from those present in the dataset, while still effectively maintaining
conservatism from OOD actions. This is achieved by harnessing the VAE capacity
to generate samples matching the distribution of the data points. We
theoretically prove that the improvement of the behavior policy is guaranteed.
Besides, it effectively mitigates value overestimation with a bounded
performance gap. Empirically, we conduct a series of experiments on the D4RL
benchmark, where A2PR demonstrates state-of-the-art performance. Furthermore,
experimental results on additional suboptimal mixed datasets reveal that A2PR
exhibits superior performance. Code is available at
https://github.com/ltlhuuu/A2PR.",2024-05-30,"Tenglong Liu, Yang Li, Yixing Lan, Hao Gao, Wei Pan, Xin Xu",http://arxiv.org/pdf/2405.19909v3,cs.LG
Utilizing Weak-to-Strong Consistency for Semi-Supervised Glomeruli Segmentation,"Accurate segmentation of glomerulus instances attains high clinical
significance in the automated analysis of renal biopsies to aid in diagnosing
and monitoring kidney disease. Analyzing real-world histopathology images often
encompasses inter-observer variability and requires a labor-intensive process
of data annotation. Therefore, conventional supervised learning approaches
generally achieve sub-optimal performance when applied to external datasets.
Considering these challenges, we present a semi-supervised learning approach
for glomeruli segmentation based on the weak-to-strong consistency framework
validated on multiple real-world datasets. Our experimental results on 3
independent datasets indicate superior performance of our approach as compared
with existing supervised baseline models such as U-Net and SegFormer.",2024-05-30,"Irina Zhang, Jim Denholm, Azam Hamidinekoo, Oskar Ålund, Christopher Bagnall, Joana Palés Huix, Michal Sulikowski, Ortensia Vito, Arthur Lewis, Robert Unwin, Magnus Soderberg, Nikolay Burlutskiy, Talha Qaiser",http://arxiv.org/pdf/2406.16900v1,cs.LG
Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection,"Label noise, commonly found in real-world datasets, has a detrimental impact
on a model's generalization. To effectively detect incorrectly labeled
instances, previous works have mostly relied on distinguishable training
signals, such as training loss, as indicators to differentiate between clean
and noisy labels. However, they have limitations in that the training signals
incompletely reveal the model's behavior and are not effectively generalized to
various noise types, resulting in limited detection accuracy. In this paper, we
propose DynaCor framework that distinguishes incorrectly labeled instances from
correctly labeled ones based on the dynamics of the training signals. To cope
with the absence of supervision for clean and noisy labels, DynaCor first
introduces a label corruption strategy that augments the original dataset with
intentionally corrupted labels, enabling indirect simulation of the model's
behavior on noisy labels. Then, DynaCor learns to identify clean and noisy
instances by inducing two clearly distinguishable clusters from the latent
representations of training dynamics. Our comprehensive experiments show that
DynaCor outperforms the state-of-the-art competitors and shows strong
robustness to various noise types and noise rates.",2024-05-30,"Suyeon Kim, Dongha Lee, SeongKu Kang, Sukang Chae, Sanghwan Jang, Hwanjo Yu",http://arxiv.org/pdf/2405.19902v1,cs.LG
"Ensemble Model With Bert,Roberta and Xlnet For Molecular property prediction","This paper presents a novel approach for predicting molecular properties with
high accuracy without the need for extensive pre-training. Employing ensemble
learning and supervised fine-tuning of BERT, RoBERTa, and XLNet, our method
demonstrates significant effectiveness compared to existing advanced models.
Crucially, it addresses the issue of limited computational resources faced by
experimental groups, enabling them to accurately predict molecular properties.
This innovation provides a cost-effective and resource-efficient solution,
potentially advancing further research in the molecular domain.",2024-05-30,Junling Hu,http://arxiv.org/pdf/2406.06553v1,cs.LG
Urban Air Pollution Forecasting: a Machine Learning Approach leveraging Satellite Observations and Meteorological Forecasts,"Air pollution poses a significant threat to public health and well-being,
particularly in urban areas. This study introduces a series of machine-learning
models that integrate data from the Sentinel-5P satellite, meteorological
conditions, and topological characteristics to forecast future levels of five
major pollutants. The investigation delineates the process of data collection,
detailing the combination of diverse data sources utilized in the study.
Through experiments conducted in the Milan metropolitan area, the models
demonstrate their efficacy in predicting pollutant levels for the forthcoming
day, achieving a percentage error of around 30%. The proposed models are
advantageous as they are independent of monitoring stations, facilitating their
use in areas without existing infrastructure. Additionally, we have released
the collected dataset to the public, aiming to stimulate further research in
this field. This research contributes to advancing our understanding of urban
air quality dynamics and emphasizes the importance of amalgamating satellite,
meteorological, and topographical data to develop robust pollution forecasting
models.",2024-05-30,"Giacomo Blanco, Luca Barco, Lorenzo Innocenti, Claudio Rossi",http://arxiv.org/pdf/2405.19901v1,cs.LG
Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts,"In recent years, large language models (LLMs) have made remarkable
achievements in various domains. However, the untimeliness and cost of
knowledge updates coupled with hallucination issues of LLMs have curtailed
their applications in knowledge intensive tasks, where retrieval augmented
generation (RAG) can be of help. Nevertheless, existing retrieval augmented
models typically use similarity as a bridge between queries and documents and
follow a retrieve then read procedure. In this work, we argue that similarity
is not always the panacea and totally relying on similarity would sometimes
degrade the performance of retrieval augmented generation. To this end, we
propose MetRag, a Multi layEred Thoughts enhanced Retrieval Augmented
Generation framework. To begin with, beyond existing similarity oriented
thought, we embrace a small scale utility model that draws supervision from an
LLM for utility oriented thought and further come up with a smarter model by
comprehensively combining the similarity and utility oriented thoughts.
Furthermore, given the fact that the retrieved document set tends to be huge
and using them in isolation makes it difficult to capture the commonalities and
characteristics among them, we propose to make an LLM as a task adaptive
summarizer to endow retrieval augmented generation with compactness-oriented
thought. Finally, with multi layered thoughts from the precedent stages, an LLM
is called for knowledge augmented generation. Extensive experiments on
knowledge-intensive tasks have demonstrated the superiority of MetRag.",2024-05-30,"Chunjing Gan, Dan Yang, Binbin Hu, Hanxiao Zhang, Siyuan Li, Ziqi Liu, Yue Shen, Lin Ju, Zhiqiang Zhang, Jinjie Gu, Lei Liang, Jun Zhou",http://arxiv.org/pdf/2405.19893v1,cs.LG
Deep Joint Semantic Coding and Beamforming for Near-Space Airship-Borne Massive MIMO Network,"Near-space airship-borne communication network is recognized to be an
indispensable component of the future integrated ground-air-space network
thanks to airships' advantage of long-term residency at stratospheric
altitudes, but it urgently needs reliable and efficient Airship-to-X link. To
improve the transmission efficiency and capacity, this paper proposes to
integrate semantic communication with massive multiple-input multiple-output
(MIMO) technology. Specifically, we propose a deep joint semantic coding and
beamforming (JSCBF) scheme for airship-based massive MIMO image transmission
network in space, in which semantics from both source and channel are fused to
jointly design the semantic coding and physical layer beamforming. First, we
design two semantic extraction networks to extract semantics from image source
and channel state information, respectively. Then, we propose a semantic fusion
network that can fuse these semantics into complex-valued semantic features for
subsequent physical-layer transmission. To efficiently transmit the fused
semantic features at the physical layer, we then propose the hybrid data and
model-driven semantic-aware beamforming networks. At the receiver, a semantic
decoding network is designed to reconstruct the transmitted images. Finally, we
perform end-to-end deep learning to jointly train all the modules, using the
image reconstruction quality at the receivers as a metric. The proposed deep
JSCBF scheme fully combines the efficient source compressibility and robust
error correction capability of semantic communication with the high spectral
efficiency of massive MIMO, achieving a significant performance improvement
over existing approaches.",2024-05-30,"Minghui Wu, Zhen Gao, Zhaocheng Wang, Dusit Niyato, George K. Karagiannidis, Sheng Chen",http://arxiv.org/pdf/2405.19889v1,cs.LG
Parrot: Efficient Serving of LLM-based Applications with Semantic Variable,"The rise of large language models (LLMs) has enabled LLM-based applications
(a.k.a. AI agents or co-pilots), a new software paradigm that combines the
strength of LLM and conventional software. Diverse LLM applications from
different tenants could design complex workflows using multiple LLM requests to
accomplish one task. However, they have to use the over-simplified
request-level API provided by today's public LLM services, losing essential
application-level information. Public LLM services have to blindly optimize
individual LLM requests, leading to sub-optimal end-to-end performance of LLM
applications.
  This paper introduces Parrot, an LLM service system that focuses on the
end-to-end experience of LLM-based applications. Parrot proposes Semantic
Variable, a unified abstraction to expose application-level knowledge to public
LLM services. A Semantic Variable annotates an input/output variable in the
prompt of a request, and creates the data pipeline when connecting multiple LLM
requests, providing a natural way to program LLM applications. Exposing
Semantic Variables to the public LLM service allows it to perform conventional
data flow analysis to uncover the correlation across multiple LLM requests.
This correlation opens a brand-new optimization space for the end-to-end
performance of LLM-based applications. Extensive evaluations demonstrate that
Parrot can achieve up to an order-of-magnitude improvement for popular and
practical use cases of LLM applications.",2024-05-30,"Chaofan Lin, Zhenhua Han, Chengruidong Zhang, Yuqing Yang, Fan Yang, Chen Chen, Lili Qiu",http://arxiv.org/pdf/2405.19888v1,cs.LG
Federated Learning with Multi-resolution Model Broadcast,"In federated learning, a server must periodically broadcast a model to the
agents. We propose to use multi-resolution coding and modulation (also known as
non-uniform modulation) for this purpose. In the simplest instance, broadcast
transmission is used, whereby all agents are targeted with one and the same
transmission (typically without any particular favored beam direction), which
is coded using multi-resolution coding/modulation. This enables high-SNR
agents, with high path gains to the server, to receive a more accurate model
than the low-SNR agents do, without consuming more downlink resources. As one
implementation, we use transmission with a non-uniform 8-PSK constellation,
where a high-SNR receiver (agent) can separate all 8 constellation points
(hence receive 3 bits) whereas a low-SNR receiver can only separate 4 points
(hence receive 2 bits). By encoding the least significant information in the
third bit, the high-SNR receivers can obtain the model with higher accuracy,
while the low-SNR receiver can still obtain the model although with reduced
accuracy, thereby facilitating at least some basic participation of the low-SNR
receiver. We show the effectiveness of our proposed scheme via experimentation
using federated learning with the MNIST data-set.",2024-05-30,"Henrik Rydén, Reza Moosavi, Erik G. Larsson",http://arxiv.org/pdf/2405.19886v1,cs.LG
Fourier Controller Networks for Real-Time Decision-Making in Embodied Learning,"Transformer has shown promise in reinforcement learning to model time-varying
features for obtaining generalized low-level robot policies on diverse robotics
datasets in embodied learning. However, it still suffers from the issues of low
data efficiency and high inference latency. In this paper, we propose to
investigate the task from a new perspective of the frequency domain. We first
observe that the energy density in the frequency domain of a robot's trajectory
is mainly concentrated in the low-frequency part. Then, we present the Fourier
Controller Network (FCNet), a new network that uses Short-Time Fourier
Transform (STFT) to extract and encode time-varying features through frequency
domain interpolation. In order to do real-time decision-making, we further
adopt FFT and Sliding DFT methods in the model architecture to achieve parallel
training and efficient recurrent inference. Extensive results in both simulated
(e.g., D4RL) and real-world environments (e.g., robot locomotion) demonstrate
FCNet's substantial efficiency and effectiveness over existing methods such as
Transformer, e.g., FCNet outperforms Transformer on multi-environmental
robotics datasets of all types of sizes (from 1.9M to 120M). The project page
and code can be found https://thkkk.github.io/fcnet.",2024-05-30,"Hengkai Tan, Songming Liu, Kai Ma, Chengyang Ying, Xingxing Zhang, Hang Su, Jun Zhu",http://arxiv.org/pdf/2405.19885v2,cs.LG
From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems,"In this work, from a theoretical lens, we aim to understand why large
language model (LLM) empowered agents are able to solve decision-making
problems in the physical world. To this end, consider a hierarchical
reinforcement learning (RL) model where the LLM Planner and the Actor perform
high-level task planning and low-level execution, respectively. Under this
model, the LLM Planner navigates a partially observable Markov decision process
(POMDP) by iteratively generating language-based subgoals via prompting. Under
proper assumptions on the pretraining data, we prove that the pretrained LLM
Planner effectively performs Bayesian aggregated imitation learning (BAIL)
through in-context learning. Additionally, we highlight the necessity for
exploration beyond the subgoals derived from BAIL by proving that naively
executing the subgoals returned by LLM leads to a linear regret. As a remedy,
we introduce an $\epsilon$-greedy exploration strategy to BAIL, which is proven
to incur sublinear regret when the pretraining error is small. Finally, we
extend our theoretical framework to include scenarios where the LLM Planner
serves as a world model for inferring the transition model of the environment
and to multi-agent settings, enabling coordination among multiple Actors.",2024-05-30,"Jianliang He, Siyu Chen, Fengzhuo Zhang, Zhuoran Yang",http://arxiv.org/pdf/2405.19883v2,cs.LG
Learning from Random Demonstrations: Offline Reinforcement Learning with Importance-Sampled Diffusion Models,"Generative models such as diffusion have been employed as world models in
offline reinforcement learning to generate synthetic data for more effective
learning. Existing work either generates diffusion models one-time prior to
training or requires additional interaction data to update it. In this paper,
we propose a novel approach for offline reinforcement learning with closed-loop
policy evaluation and world-model adaptation. It iteratively leverages a guided
diffusion world model to directly evaluate the offline target policy with
actions drawn from it, and then performs an importance-sampled world model
update to adaptively align the world model with the updated policy. We analyzed
the performance of the proposed method and provided an upper bound on the
return gap between our method and the real environment under an optimal policy.
The result sheds light on various factors affecting learning performance.
Evaluations in the D4RL environment show significant improvement over
state-of-the-art baselines, especially when only random or medium-expertise
demonstrations are available -- thus requiring improved alignment between the
world model and offline policy evaluation.",2024-05-30,"Zeyu Fang, Tian Lan",http://arxiv.org/pdf/2405.19878v1,cs.LG
Is In-Context Learning Sufficient for Instruction Following in LLMs?,"In-context learning (ICL) allows LLMs to learn from examples without changing
their weights: this is a particularly promising capability for long-context
LLMs that can potentially learn from many examples. Recently, Lin et al. (2024)
proposed URIAL, a method using only three in-context examples to align base
LLMs, achieving non-trivial instruction following performance. In this work, we
show that, while effective, ICL alignment with URIAL still underperforms
compared to instruction fine-tuning on the established benchmark MT-Bench,
especially with more capable base LLMs. We then uncover the most relevant
elements for successful in-context alignment, finding the crucial role of the
decoding parameters. Based on these insights, we show that the approach of
URIAL can indeed be improved by adding high-quality, potentially carefully
selected via greedy search, demonstrations in context, getting closer to the
performance of instruct models. Finally, we provide the first, to our
knowledge, systematic comparison of ICL and instruction fine-tuning (IFT) for
instruction following in the low data regime, where ICL can be a viable
alternative to IFT. Overall, our work advances the understanding of ICL as an
alignment technique and its relationship to IFT. We provide our code at
https://github.com/tml-epfl/icl-alignment.",2024-05-30,"Hao Zhao, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion",http://arxiv.org/pdf/2405.19874v3,cs.LG
On Vessel Location Forecasting and the Effect of Federated Learning,"The wide spread of Automatic Identification System (AIS) has motivated
several maritime analytics operations. Vessel Location Forecasting (VLF) is one
of the most critical operations for maritime awareness. However, accurate VLF
is a challenging problem due to the complexity and dynamic nature of maritime
traffic conditions. Furthermore, as privacy concerns and restrictions have
grown, training data has become increasingly fragmented, resulting in dispersed
databases of several isolated data silos among different organizations, which
in turn decreases the quality of learning models. In this paper, we propose an
efficient VLF solution based on LSTM neural networks, in two variants, namely
Nautilus and FedNautilus for the centralized and the federated learning
approach, respectively. We also demonstrate the superiority of the centralized
approach with respect to current state of the art and discuss the advantages
and disadvantages of the federated against the centralized approach.",2024-05-30,"Andreas Tritsarolis, Nikos Pelekis, Konstantina Bereta, Dimitris Zissis, Yannis Theodoridis",http://arxiv.org/pdf/2405.19870v1,cs.LG
Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction,"Machine learning is increasingly used to predict lifestyle-related disease
onset using health and medical data. However, its predictive accuracy for use
is often hindered by dataset shift, which refers to discrepancies in data
distribution between the training and testing datasets. This issue leads to the
misclassification of out-of-distribution (OOD) data. To diminish dataset shift
in real-world settings, this paper proposes the out-of-distribution reject
option for prediction (ODROP). This method integrates an OOD detection model to
preclude OOD data from the prediction phase. We used two real-world health
checkup datasets (Hirosaki and Wakayama) with dataset shift, across three
disease onset prediction tasks: diabetes, dyslipidemia, and hypertension. Both
components of ODROP method -- the OOD detection model and the prediction model
-- were trained on the Hirosaki dataset. We assessed the effectiveness of ODROP
on the Wakayama dataset using AUROC-rejection rate curve plot. In the five OOD
detection approaches (the variational autoencoder, neural network ensemble std,
neural network ensemble epistemic, neural network energy, and neural network
gaussian mixture based energy measurement), the variational autoencoder method
demonstrated notably higher stability and a greater improvement in AUROC. For
example, in the Wakayama dataset, the AUROC for diabetes onset increased from
0.80 without ODROP to 0.90 at a 31.1% rejection rate, and for dyslipidemia, it
improved from 0.70 without ODROP to 0.76 at a 34% rejection rate. In addition,
we categorized dataset shifts into two types using SHAP clustering -- those
that considerably affect predictions and those that do not. This study is the
first to apply OOD detection to actual health and medical data, demonstrating
its potential to substantially improve the accuracy and reliability of disease
prediction models amidst dataset shift.",2024-05-30,"Taisei Tosaki, Eiichiro Uchino, Ryosuke Kojima, Yohei Mineharu, Yuji Okamoto, Mikio Arita, Nobuyuki Miyai, Yoshinori Tamada, Tatsuya Mikami, Koichi Murashita, Shigeyuki Nakaji, Yasushi Okuno",http://arxiv.org/pdf/2405.19864v2,cs.LG
The Merit of River Network Topology for Neural Flood Forecasting,"Climate change exacerbates riverine floods, which occur with higher frequency
and intensity than ever. The much-needed forecasting systems typically rely on
accurate river discharge predictions. To this end, the SOTA data-driven
approaches treat forecasting at spatially distributed gauge stations as
isolated problems, even within the same river network. However, incorporating
the known topology of the river network into the prediction model has the
potential to leverage the adjacency relationship between gauges. Thus, we model
river discharge for a network of gauging stations with GNNs and compare the
forecasting performance achieved by different adjacency definitions. Our
results show that the model fails to benefit from the river network topology
information, both on the entire network and small subgraphs. The learned edge
weights correlate with neither of the static definitions and exhibit no regular
pattern. Furthermore, the GNNs struggle to predict sudden, narrow discharge
spikes. Our work hints at a more general underlying phenomenon of neural
prediction not always benefitting from graphical structure and may inspire a
systematic study of the conditions under which this happens.",2024-05-30,"Nikolas Kirschstein, Yixuan Sun",http://arxiv.org/pdf/2405.19836v1,cs.LG
Joint Selective State Space Model and Detrending for Robust Time Series Anomaly Detection,"Deep learning-based sequence models are extensively employed in Time Series
Anomaly Detection (TSAD) tasks due to their effective sequential modeling
capabilities. However, the ability of TSAD is limited by two key challenges:
(i) the ability to model long-range dependency and (ii) the generalization
issue in the presence of non-stationary data. To tackle these challenges, an
anomaly detector that leverages the selective state space model known for its
proficiency in capturing long-term dependencies across various domains is
proposed. Additionally, a multi-stage detrending mechanism is introduced to
mitigate the prominent trend component in non-stationary data to address the
generalization issue. Extensive experiments conducted on realworld public
datasets demonstrate that the proposed methods surpass all 12 compared baseline
methods.",2024-05-30,"Junqi Chen, Xu Tan, Sylwan Rahardja, Jiawei Yang, Susanto Rahardja",http://arxiv.org/pdf/2405.19823v2,cs.LG
Robust Image Semantic Coding with Learnable CSI Fusion Masking over MIMO Fading Channels,"Though achieving marvelous progress in various scenarios, existing semantic
communication frameworks mainly consider single-input single-output Gaussian
channels or Rayleigh fading channels, neglecting the widely-used multiple-input
multiple-output (MIMO) channels, which hinders the application into practical
systems. One common solution to combat MIMO fading is to utilize feedback MIMO
channel state information (CSI). In this paper, we incorporate MIMO CSI into
system designs from a new perspective and propose the learnable CSI fusion
semantic communication (LCFSC) framework, where CSI is treated as side
information by the semantic extractor to enhance the semantic coding. To avoid
feature fusion due to abrupt combination of CSI with features, we present a
non-invasive CSI fusion multi-head attention module inside the Swin
Transformer. With the learned attention masking map determined by both source
and channel states, more robust attention distribution could be generated.
Furthermore, the percentage of mask elements could be flexibly adjusted by the
learnable mask ratio, which is produced based on the conditional variational
interference in an unsupervised manner. In this way, CSI-aware semantic coding
is achieved through learnable CSI fusion masking. Experiment results testify
the superiority of LCFSC over traditional schemes and state-of-the-art Swin
Transformer-based semantic communication frameworks in MIMO fading channels.",2024-05-30,"Bingyan Xie, Yongpeng Wu, Yuxuan Shi, Wenjun Zhang, Shuguang Cui, Merouane Debbah",http://arxiv.org/pdf/2406.07389v1,cs.LG
Efficient Stimuli Generation using Reinforcement Learning in Design Verification,"The increasing design complexity of System-on-Chips (SoCs) has led to
significant verification challenges, particularly in meeting coverage targets
within a timely manner. At present, coverage closure is heavily dependent on
constrained random and coverage driven verification methodologies where the
randomized stimuli are bounded to verify certain scenarios and to reach
coverage goals. This process is said to be exhaustive and to consume a lot of
project time. In this paper, a novel methodology is proposed to generate
efficient stimuli with the help of Reinforcement Learning (RL) to reach the
maximum code coverage of the Design Under Verification (DUV). Additionally, an
automated framework is created using metamodeling to generate a SystemVerilog
testbench and an RL environment for any given design. The proposed approach is
applied to various designs and the produced results proves that the RL agent
provides effective stimuli to achieve code coverage faster in comparison with
baseline random simulations. Furthermore, various RL agents and reward schemes
are analyzed in our work.",2024-05-30,"Deepak Narayan Gadde, Thomas Nalapat, Aman Kumar, Djones Lettnin, Wolfgang Kunz, Sebastian Simon",http://arxiv.org/pdf/2405.19815v1,cs.LG
Approximate Global Convergence of Independent Learning in Multi-Agent Systems,"Independent learning (IL), despite being a popular approach in practice to
achieve scalability in large-scale multi-agent systems, usually lacks global
convergence guarantees. In this paper, we study two representative algorithms,
independent $Q$-learning and independent natural actor-critic, within
value-based and policy-based frameworks, and provide the first finite-sample
analysis for approximate global convergence. The results imply a sample
complexity of $\tilde{\mathcal{O}}(\epsilon^{-2})$ up to an error term that
captures the dependence among agents and characterizes the fundamental limit of
IL in achieving global convergence. To establish the result, we develop a novel
approach for analyzing IL by constructing a separable Markov decision process
(MDP) for convergence analysis and then bounding the gap due to model
difference between the separable MDP and the original one. Moreover, we conduct
numerical experiments using a synthetic MDP and an electric vehicle charging
example to verify our theoretical findings and to demonstrate the practical
applicability of IL.",2024-05-30,"Ruiyang Jin, Zaiwei Chen, Yiheng Lin, Jie Song, Adam Wierman",http://arxiv.org/pdf/2405.19811v1,cs.LG
MetaCURL: Non-stationary Concave Utility Reinforcement Learning,"We explore online learning in episodic loop-free Markov decision processes on
non-stationary environments (changing losses and probability transitions). Our
focus is on the Concave Utility Reinforcement Learning problem (CURL), an
extension of classical RL for handling convex performance criteria in
state-action distributions induced by agent policies. While various machine
learning problems can be written as CURL, its non-linearity invalidates
traditional Bellman equations. Despite recent solutions to classical CURL, none
address non-stationary MDPs. This paper introduces MetaCURL, the first CURL
algorithm for non-stationary MDPs. It employs a meta-algorithm running multiple
black-box algorithms instances over different intervals, aggregating outputs
via a sleeping expert framework. The key hurdle is partial information due to
MDP uncertainty. Under partial information on the probability transitions
(uncertainty and non-stationarity coming only from external noise, independent
of agent state-action pairs), we achieve optimal dynamic regret without prior
knowledge of MDP changes. Unlike approaches for RL, MetaCURL handles full
adversarial losses, not just stochastic ones. We believe our approach for
managing non-stationarity with experts can be of interest to the RL community.",2024-05-30,"Bianca Marin Moreno, Margaux Brégère, Pierre Gaillard, Nadia Oudjane",http://arxiv.org/pdf/2405.19807v1,cs.LG
Preference Alignment with Flow Matching,"We present Preference Flow Matching (PFM), a new framework for
preference-based reinforcement learning (PbRL) that streamlines the integration
of preferences into an arbitrary class of pre-trained models. Existing PbRL
methods require fine-tuning pre-trained models, which presents challenges such
as scalability, inefficiency, and the need for model modifications, especially
with black-box APIs like GPT-4. In contrast, PFM utilizes flow matching
techniques to directly learn from preference data, thereby reducing the
dependency on extensive fine-tuning of pre-trained models. By leveraging
flow-based models, PFM transforms less preferred data into preferred outcomes,
and effectively aligns model outputs with human preferences without relying on
explicit or implicit reward function estimation, thus avoiding common issues
like overfitting in reward models. We provide theoretical insights that support
our method's alignment with standard PbRL objectives. Experimental results
indicate the practical effectiveness of our method, offering a new direction in
aligning a pre-trained model to preference. Our code is available at
https://github.com/jadehaus/preference-flow-matching.",2024-05-30,"Minu Kim, Yongsik Lee, Sehyeok Kang, Jihwan Oh, Song Chong, Se-Young Yun",http://arxiv.org/pdf/2405.19806v2,cs.LG
Complexity of Deciding Injectivity and Surjectivity of ReLU Neural Networks,"Neural networks with ReLU activation play a key role in modern machine
learning. In view of safety-critical applications, the verification of trained
networks is of great importance and necessitates a thorough understanding of
essential properties of the function computed by a ReLU network, including
characteristics like injectivity and surjectivity. Recently, Puthawala et al.
[JMLR 2022] came up with a characterization for injectivity of a ReLU layer,
which implies an exponential time algorithm. However, the exact computational
complexity of deciding injectivity remained open. We answer this question by
proving coNP-completeness of deciding injectivity of a ReLU layer. On the
positive side, as our main result, we present a parameterized algorithm which
yields fixed-parameter tractability of the problem with respect to the input
dimension. In addition, we also characterize surjectivity for two-layer ReLU
networks with one-dimensional output. Remarkably, the decision problem turns
out to be the complement of a basic network verification task. We prove
NP-hardness for surjectivity, implying a stronger hardness result than
previously known for the network verification problem. Finally, we reveal
interesting connections to computational convexity by formulating the
surjectivity problem as a zonotope containment problem",2024-05-30,"Vincent Froese, Moritz Grillo, Martin Skutella",http://arxiv.org/pdf/2405.19805v1,cs.LG
Exploring Key Factors for Long-Term Vessel Incident Risk Prediction,"Factor analysis acts a pivotal role in enhancing maritime safety. Most
previous studies conduct factor analysis within the framework of
incident-related label prediction, where the developed models can be
categorized into short-term and long-term prediction models. The long-term
models offer a more strategic approach, enabling more proactive risk
management, compared to the short-term ones. Nevertheless, few studies have
devoted to rigorously identifying the key factors for the long-term prediction
and undertaking comprehensive factor analysis. Hence, this study aims to delve
into the key factors for predicting the incident risk levels in the subsequent
year given a specific datestamp. The majority of candidate factors potentially
contributing to the incident risk are collected from vessels' historical safety
performance data spanning up to five years. An improved embedded feature
selection, which integrates Random Forest classifier with a feature filtering
process is proposed to identify key risk-contributing factors from the
candidate pool. The results demonstrate superior performance of the proposed
method in incident prediction and factor interpretability. Comprehensive
analysis is conducted upon the key factors, which could help maritime
stakeholders formulate management strategies for incident prevenion.",2024-05-30,"Tianyi Chen, Hua Wang, Yutong Cai, Maohan Liang, Qiang Meng",http://arxiv.org/pdf/2405.19804v1,cs.LG
Estimating before Debiasing: A Bayesian Approach to Detaching Prior Bias in Federated Semi-Supervised Learning,"Federated Semi-Supervised Learning (FSSL) leverages both labeled and
unlabeled data on clients to collaboratively train a model.In FSSL, the
heterogeneous data can introduce prediction bias into the model, causing the
model's prediction to skew towards some certain classes. Existing FSSL methods
primarily tackle this issue by enhancing consistency in model parameters or
outputs. However, as the models themselves are biased, merely constraining
their consistency is not sufficient to alleviate prediction bias. In this
paper, we explore this bias from a Bayesian perspective and demonstrate that it
principally originates from label prior bias within the training data. Building
upon this insight, we propose a debiasing method for FSSL named FedDB. FedDB
utilizes the Average Prediction Probability of Unlabeled Data (APP-U) to
approximate the biased prior.During local training, FedDB employs APP-U to
refine pseudo-labeling through Bayes' theorem, thereby significantly reducing
the label prior bias. Concurrently, during the model aggregation, FedDB uses
APP-U from participating clients to formulate unbiased aggregate weights,
thereby effectively diminishing bias in the global model. Experimental results
show that FedDB can surpass existing FSSL methods. The code is available at
https://github.com/GuogangZhu/FedDB.",2024-05-30,"Guogang Zhu, Xuefeng Liu, Xinghao Wu, Shaojie Tang, Chao Tang, Jianwei Niu, Hao Su",http://arxiv.org/pdf/2405.19789v1,cs.LG
From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers,"Instruction tuning -- tuning large language models on instruction-output
pairs -- is a promising technique for making models better adapted to the real
world. Yet, the key factors driving the model's capability to understand and
follow instructions not seen during training remain under-explored. Our
investigation begins with a series of synthetic experiments within the
theoretical framework of a Turing-complete algorithm called Markov algorithm,
which allows fine-grained control over the instruction-tuning data.
Generalization and robustness with respect to the training distribution emerge
once a diverse enough set of tasks is provided, even though very few examples
are provided for each task. We extend these initial results to a real-world
application scenario of code generation and find that a more diverse
instruction set, extending beyond code-related tasks, improves the performance
of code generation. Our observations suggest that a more diverse semantic space
for instruction-tuning sets greatly improves the model's ability to follow
instructions and perform tasks.",2024-05-30,"Dylan Zhang, Justin Wang, Francois Charton",http://arxiv.org/pdf/2405.19787v2,cs.LG
Recurrent Deep Kernel Learning of Dynamical Systems,"Digital twins require computationally-efficient reduced-order models (ROMs)
that can accurately describe complex dynamics of physical assets. However,
constructing ROMs from noisy high-dimensional data is challenging. In this
work, we propose a data-driven, non-intrusive method that utilizes stochastic
variational deep kernel learning (SVDKL) to discover low-dimensional latent
spaces from data and a recurrent version of SVDKL for representing and
predicting the evolution of latent dynamics. The proposed method is
demonstrated with two challenging examples -- a double pendulum and a
reaction-diffusion system. Results show that our framework is capable of (i)
denoising and reconstructing measurements, (ii) learning compact
representations of system states, (iii) predicting system evolution in
low-dimensional latent spaces, and (iv) quantifying modeling uncertainties.",2024-05-30,"Nicolò Botteghi, Paolo Motta, Andrea Manzoni, Paolo Zunino, Mengwu Guo",http://arxiv.org/pdf/2405.19785v3,cs.LG
PixelsDB: Serverless and NL-Aided Data Analytics with Flexible Service Levels and Prices,"Serverless query processing has become increasingly popular due to its
advantages, including automated resource management, high elasticity, and
pay-as-you-go pricing. For users who are not system experts, serverless query
processing greatly reduces the cost of owning a data analytic system. However,
it is still a significant challenge for non-expert users to transform their
complex and evolving data analytic needs into proper SQL queries and select a
serverless query service that delivers satisfactory performance and price for
each type of query.
  This paper presents PixelsDB, an open-source data analytic system that allows
users who lack system or SQL expertise to explore data efficiently. It allows
users to generate and debug SQL queries using a natural language interface
powered by fine-tuned language models. The queries are then executed by a
serverless query engine that offers varying prices for different performance
service levels (SLAs). The performance SLAs are natively supported by dedicated
architecture design and heterogeneous resource scheduling that can apply
cost-efficient resources to process non-urgent queries. We demonstrate that the
combination of a serverless paradigm, a natural-language-aided interface, and
flexible SLAs and prices will substantially improve the usability of cloud data
analytic systems.",2024-05-30,"Haoqiong Bian, Dongyang Geng, Haoyang Li, Yunpeng Chai, Anastasia Ailamaki",http://arxiv.org/pdf/2405.19784v2,cs.LG
Instruction-Guided Visual Masking,"Instruction following is crucial in contemporary LLM. However, when extended
to multimodal setting, it often suffers from misalignment between specific
textual instruction and targeted local region of an image. To achieve more
accurate and nuanced multimodal instruction following, we introduce
Instruction-guided Visual Masking (IVM), a new versatile visual grounding model
that is compatible with diverse multimodal models, such as LMM and robot model.
By constructing visual masks for instruction-irrelevant regions, IVM-enhanced
multimodal models can effectively focus on task-relevant image regions to
better align with complex instructions. Specifically, we design a visual
masking data generation pipeline and create an IVM-Mix-1M dataset with 1
million image-instruction pairs. We further introduce a new learning technique,
Discriminator Weighted Supervised Learning (DWSL) for preferential IVM training
that prioritizes high-quality data samples. Experimental results on generic
multimodal tasks such as VQA and embodied robotic control demonstrate the
versatility of IVM, which as a plug-and-play tool, significantly boosts the
performance of diverse multimodal models, yielding new state-of-the-art results
across challenging multimodal benchmarks. Code, model and data are available at
https://github.com/2toinf/IVM.",2024-05-30,"Jinliang Zheng, Jianxiong Li, Sijie Cheng, Yinan Zheng, Jiaming Li, Jihao Liu, Yu Liu, Jingjing Liu, Xianyuan Zhan",http://arxiv.org/pdf/2405.19783v2,cs.LG
Automatic Graph Topology-Aware Transformer,"Existing efforts are dedicated to designing many topologies and graph-aware
strategies for the graph Transformer, which greatly improve the model's
representation capabilities. However, manually determining the suitable
Transformer architecture for a specific graph dataset or task requires
extensive expert knowledge and laborious trials. This paper proposes an
evolutionary graph Transformer architecture search framework (EGTAS) to
automate the construction of strong graph Transformers. We build a
comprehensive graph Transformer search space with the micro-level and
macro-level designs. EGTAS evolves graph Transformer topologies at the macro
level and graph-aware strategies at the micro level. Furthermore, a surrogate
model based on generic architectural coding is proposed to directly predict the
performance of graph Transformers, substantially reducing the evaluation cost
of evolutionary search. We demonstrate the efficacy of EGTAS across a range of
graph-level and node-level tasks, encompassing both small-scale and large-scale
graph datasets. Experimental results and ablation studies show that EGTAS can
construct high-performance architectures that rival state-of-the-art manual and
automated baselines.",2024-05-30,"Chao Wang, Jiaxuan Zhao, Lingling Li, Licheng Jiao, Fang Liu, Shuyuan Yang",http://arxiv.org/pdf/2405.19779v2,cs.LG
Medication Recommendation via Dual Molecular Modalities and Multi-Step Enhancement,"Existing works based on molecular knowledge neglect the 3D geometric
structure of molecules and fail to learn the high-dimensional information of
medications, leading to structural confusion. Additionally, it does not extract
key substructures from a single patient visit, resulting in the failure to
identify medication molecules suitable for the current patient visit. To
address the above limitations, we propose a bimodal molecular recommendation
framework named BiMoRec, which introduces 3D molecular structures to obtain
atomic 3D coordinates and edge indices, overcoming the inherent lack of
high-dimensional molecular information in 2D molecular structures. To retain
the fast training and prediction efficiency of the recommendation system, we
use bimodal graph contrastive pretraining to maximize the mutual information
between the two molecular modalities, achieving the fusion of 2D and 3D
molecular graphs. Additionally, we designed a molecular multi-step enhancement
mechanism to re-calibrate the molecular weights. Specifically, we employ a
pre-training method that captures both 2D and 3D molecular structure
representations, along with substructure representations, and leverages
contrastive learning to extract mutual information. We then use the pre-trained
encoder to generate molecular representations, enhancing them through a
three-step process: intra-visit, molecular per-visit, and latest-visit.
Finally, we apply temporal information aggregation to generate the final
medication combinations. Our implementation on the MIMIC-III and MIMIC-IV
datasets demonstrates that our method achieves state-of-the-art performance.",2024-05-30,"Shi Mu, Chen Li, Xiang Li, Shunpan Liang",http://arxiv.org/pdf/2405.20358v4,cs.LG
Identifiability of a statistical model with two latent vectors: Importance of the dimensionality relation and application to graph embedding,"Identifiability of statistical models is a key notion in unsupervised
representation learning. Recent work of nonlinear independent component
analysis (ICA) employs auxiliary data and has established identifiable
conditions. This paper proposes a statistical model of two latent vectors with
single auxiliary data generalizing nonlinear ICA, and establishes various
identifiability conditions. Unlike previous work, the two latent vectors in the
proposed model can have arbitrary dimensions, and this property enables us to
reveal an insightful dimensionality relation among two latent vectors and
auxiliary data in identifiability conditions. Furthermore, surprisingly, we
prove that the indeterminacies of the proposed model has the same as
\emph{linear} ICA under certain conditions: The elements in the latent vector
can be recovered up to their permutation and scales. Next, we apply the
identifiability theory to a statistical model for graph data. As a result, one
of the identifiability conditions includes an appealing implication:
Identifiability of the statistical model could depend on the maximum value of
link weights in graph data. Then, we propose a practical method for
identifiable graph embedding. Finally, we numerically demonstrate that the
proposed method well-recovers the latent vectors and model identifiability
clearly depends on the maximum value of link weights, which supports the
implication of our theoretical results",2024-05-30,Hiroaki Sasaki,http://arxiv.org/pdf/2405.19760v1,cs.LG
Improving SMOTE via Fusing Conditional VAE for Data-adaptive Noise Filtering,"Recent advances in a generative neural network model extend the development
of data augmentation methods. However, the augmentation methods based on the
modern generative models fail to achieve notable performance for class
imbalance data compared to the conventional model, Synthetic Minority
Oversampling Technique (SMOTE). We investigate the problem of the generative
model for imbalanced classification and introduce a framework to enhance the
SMOTE algorithm using Variational Autoencoders (VAE). Our approach
systematically quantifies the density of data points in a low-dimensional
latent space using the VAE, simultaneously incorporating information on class
labels and classification difficulty. Then, the data points potentially
degrading the augmentation are systematically excluded, and the neighboring
observations are directly augmented on the data space. Empirical studies on
several imbalanced datasets represent that this simple process innovatively
improves the conventional SMOTE algorithm over the deep learning models.
Consequently, we conclude that the selection of minority data and the
interpolation in the data space are beneficial for imbalanced classification
problems with a relatively small number of data points.",2024-05-30,"Sungchul Hong, Seunghwan An, Jong-June Jeon",http://arxiv.org/pdf/2405.19757v3,cs.LG
Understanding Memory-Regret Trade-Off for Streaming Stochastic Multi-Armed Bandits,"We study the stochastic multi-armed bandit problem in the $P$-pass streaming
model. In this problem, the $n$ arms are present in a stream and at most $m<n$
arms and their statistics can be stored in the memory. We give a complete
characterization of the optimal regret in terms of $m, n$ and $P$.
Specifically, we design an algorithm with $\tilde
O\left((n-m)^{1+\frac{2^{P}-2}{2^{P+1}-1}} n^{\frac{2-2^{P+1}}{2^{P+1}-1}}
T^{\frac{2^P}{2^{P+1}-1}}\right)$ regret and complement it with an $\tilde
\Omega\left((n-m)^{1+\frac{2^{P}-2}{2^{P+1}-1}} n^{\frac{2-2^{P+1}}{2^{P+1}-1}}
T^{\frac{2^P}{2^{P+1}-1}}\right)$ lower bound when the number of rounds $T$ is
sufficiently large. Our results are tight up to a logarithmic factor in $n$ and
$P$.",2024-05-30,"Yuchen He, Zichun Ye, Chihao Zhang",http://arxiv.org/pdf/2405.19752v2,cs.LG
Understanding and mitigating difficulties in posterior predictive evaluation,"Predictive posterior densities (PPDs) are of interest in approximate Bayesian
inference. Typically, these are estimated by simple Monte Carlo (MC) averages
using samples from the approximate posterior. We observe that the
signal-to-noise ratio (SNR) of such estimators can be extremely low. An
analysis for exact inference reveals SNR decays exponentially as there is an
increase in (a) the mismatch between training and test data, (b) the
dimensionality of the latent space, or (c) the size of the test data relative
to the training data. Further analysis extends these results to approximate
inference. To remedy the low SNR problem, we propose replacing simple MC
sampling with importance sampling using a proposal distribution optimized at
test time on a variational proxy for the SNR and demonstrate that this yields
greatly improved estimates.",2024-05-30,"Abhinav Agrawal, Justin Domke",http://arxiv.org/pdf/2405.19747v1,cs.LG
LLM as a Complementary Optimizer to Gradient Descent: A Case Study in Prompt Tuning,"Mastering a skill generally relies on both hands-on experience from doers and
insightful, high-level guidance by mentors. Will this strategy also work well
for solving complex non-convex optimization problems? Here, a common
gradient-based optimizer acts like a disciplined doer, making locally optimal
updates at each step. Large Language Models (LLMs) can also search for better
solutions by inferring from natural language instructions, akin to a high-level
mentor. In this paper, we show that these two participators are complementary
to each other and can effectively collaborate as a combined optimization
framework. The collaborative optimization is achieved by alternating between
the gradient-based and LLM-based optimizers. We instruct LLMs to generate
possibly improved solutions by taking parameter trajectories recorded during
the previous stage of gradient-based optimization into account. Inferred
results of LLMs are used as restarting points for the next stage of gradient
optimization. We verify the effectiveness of this optimization framework on
prompt tuning. By leveraging both the locally rigorous gradient-based optimizer
and the high-level deductive LLM-based optimizer, the combined optimization
method consistently yields improvements over competitive baselines on a variety
of tasks. Our results demonstrate the synergistic effect of conventional
gradient-based optimization and the inference ability of LLMs. The code is
released at https://github.com/guozix/LLM-catalyst.",2024-05-30,"Zixian Guo, Ming Liu, Zhilong Ji, Jinfeng Bai, Yiwen Guo, Wangmeng Zuo",http://arxiv.org/pdf/2405.19732v4,cs.LG
Research on the Spatial Data Intelligent Foundation Model,"This report focuses on spatial data intelligent large models, delving into
the principles, methods, and cutting-edge applications of these models. It
provides an in-depth discussion on the definition, development history, current
status, and trends of spatial data intelligent large models, as well as the
challenges they face. The report systematically elucidates the key technologies
of spatial data intelligent large models and their applications in urban
environments, aerospace remote sensing, geography, transportation, and other
scenarios. Additionally, it summarizes the latest application cases of spatial
data intelligent large models in themes such as urban development, multimodal
systems, remote sensing, smart transportation, and resource environments.
Finally, the report concludes with an overview and outlook on the development
prospects of spatial data intelligent large models.",2024-05-30,"Shaohua Wang, Xing Xie, Yong Li, Danhuai Guo, Zhi Cai, Yu Liu, Yang Yue, Xiao Pan, Feng Lu, Huayi Wu, Zhipeng Gui, Zhiming Ding, Bolong Zheng, Fuzheng Zhang, Jingyuan Wang, Zhengchao Chen, Hao Lu, Jiayi Li, Peng Yue, Wenhao Yu, Yao Yao, Leilei Sun, Yong Zhang, Longbiao Chen, Xiaoping Du, Xiang Li, Xueying Zhang, Kun Qin, Zhaoya Gong, Weihua Dong, Xiaofeng Meng",http://arxiv.org/pdf/2405.19730v5,cs.LG
Dynamic feature selection in medical predictive monitoring by reinforcement learning,"In this paper, we investigate dynamic feature selection within multivariate
time-series scenario, a common occurrence in clinical prediction monitoring
where each feature corresponds to a bio-test result. Many existing feature
selection methods fall short in effectively leveraging time-series information,
primarily because they are designed for static data. Our approach addresses
this limitation by enabling the selection of time-varying feature subsets for
each patient. Specifically, we employ reinforcement learning to optimize a
policy under maximum cost restrictions. The prediction model is subsequently
updated using synthetic data generated by trained policy. Our method can
seamlessly integrate with non-differentiable prediction models. We conducted
experiments on a sizable clinical dataset encompassing regression and
classification tasks. The results demonstrate that our approach outperforms
strong feature selection baselines, particularly when subjected to stringent
cost limitations. Code will be released once paper is accepted.",2024-05-30,"Yutong Chen, Jiandong Gao, Ji Wu",http://arxiv.org/pdf/2405.19729v1,cs.LG
SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths,"Speculative decoding reduces the inference latency of a target large language
model via utilizing a smaller and faster draft model. Its performance depends
on a hyperparameter K -- the candidate length, i.e., the number of candidate
tokens for the target model to verify in each round. However, previous methods
often use simple heuristics to choose K, which may result in sub-optimal
performance. We study the choice of the candidate length K and formulate it as
a Markov Decision Process. We theoretically show that the optimal policy of
this Markov decision process takes the form of a threshold policy, i.e., the
current speculation should stop and be verified when the probability of getting
a rejection exceeds a threshold value. Motivated by this theory, we propose
SpecDec++, an enhanced version of speculative decoding that adaptively
determines the candidate length on the fly. We augment the draft model with a
trained acceptance prediction head to predict the conditional acceptance
probability of the candidate tokens. SpecDec++ will stop the current
speculation when the predicted probability that at least one token gets
rejected exceeds a threshold. We implement SpecDec++ and apply it to the
llama-2-chat 7B & 70B model pair. Our adaptive method achieves a 2.04x speedup
on the Alpaca dataset (an additional 7.2% improvement over the baseline
speculative decoding). On the GSM8K and HumanEval datasets, our method achieves
a 2.26x speedup (9.4% improvement) and 2.23x speedup (11.1% improvement),
respectively.",2024-05-30,"Kaixuan Huang, Xudong Guo, Mengdi Wang",http://arxiv.org/pdf/2405.19715v2,cs.LG
Enhancing Adversarial Robustness in SNNs with Sparse Gradients,"Spiking Neural Networks (SNNs) have attracted great attention for their
energy-efficient operations and biologically inspired structures, offering
potential advantages over Artificial Neural Networks (ANNs) in terms of energy
efficiency and interpretability. Nonetheless, similar to ANNs, the robustness
of SNNs remains a challenge, especially when facing adversarial attacks.
Existing techniques, whether adapted from ANNs or specifically designed for
SNNs, exhibit limitations in training SNNs or defending against strong attacks.
In this paper, we propose a novel approach to enhance the robustness of SNNs
through gradient sparsity regularization. We observe that SNNs exhibit greater
resilience to random perturbations compared to adversarial perturbations, even
at larger scales. Motivated by this, we aim to narrow the gap between SNNs
under adversarial and random perturbations, thereby improving their overall
robustness. To achieve this, we theoretically prove that this performance gap
is upper bounded by the gradient sparsity of the probability associated with
the true label concerning the input image, laying the groundwork for a
practical strategy to train robust SNNs by regularizing the gradient sparsity.
We validate the effectiveness of our approach through extensive experiments on
both image-based and event-based datasets. The results demonstrate notable
improvements in the robustness of SNNs. Our work highlights the importance of
gradient sparsity in SNNs and its role in enhancing robustness.",2024-05-30,"Yujia Liu, Tong Bu, Jianhao Ding, Zecheng Hao, Tiejun Huang, Zhaofei Yu",http://arxiv.org/pdf/2405.20355v1,cs.LG
Universal Online Convex Optimization with $1$ Projection per Round,"To address the uncertainty in function types, recent progress in online
convex optimization (OCO) has spurred the development of universal algorithms
that simultaneously attain minimax rates for multiple types of convex
functions. However, for a $T$-round online problem, state-of-the-art methods
typically conduct $O(\log T)$ projections onto the domain in each round, a
process potentially time-consuming with complicated feasible sets. In this
paper, inspired by the black-box reduction of Cutkosky and Orabona (2018), we
employ a surrogate loss defined over simpler domains to develop universal OCO
algorithms that only require $1$ projection. Embracing the framework of
prediction with expert advice, we maintain a set of experts for each type of
functions and aggregate their predictions via a meta-algorithm. The crux of our
approach lies in a uniquely designed expert-loss for strongly convex functions,
stemming from an innovative decomposition of the regret into the meta-regret
and the expert-regret. Our analysis sheds new light on the surrogate loss,
facilitating a rigorous examination of the discrepancy between the regret of
the original loss and that of the surrogate loss, and carefully controlling
meta-regret under the strong convexity condition. In this way, with only $1$
projection per round, we establish optimal regret bounds for general convex,
exponentially concave, and strongly convex functions simultaneously.
Furthermore, we enhance the expert-loss to exploit the smoothness property, and
demonstrate that our algorithm can attain small-loss regret for multiple types
of convex and smooth functions.",2024-05-30,"Wenhao Yang, Yibo Wang, Peng Zhao, Lijun Zhang",http://arxiv.org/pdf/2405.19705v1,cs.LG
Enhancing Sufficient Dimension Reduction via Hellinger Correlation,"In this work, we develop a new theory and method for sufficient dimension
reduction (SDR) in single-index models, where SDR is a sub-field of supervised
dimension reduction based on conditional independence. Our work is primarily
motivated by the recent introduction of the Hellinger correlation as a
dependency measure. Utilizing this measure, we develop a method capable of
effectively detecting the dimension reduction subspace, complete with
theoretical justification. Through extensive numerical experiments, we
demonstrate that our proposed method significantly enhances and outperforms
existing SDR methods. This improvement is largely attributed to our proposed
method's deeper understanding of data dependencies and the refinement of
existing SDR techniques.",2024-05-30,"Seungbeom Hong, Ilmun Kim, Jun Song",http://arxiv.org/pdf/2405.19704v1,cs.LG
Towards a Better Evaluation of Out-of-Domain Generalization,"The objective of Domain Generalization (DG) is to devise algorithms and
models capable of achieving high performance on previously unseen test
distributions. In the pursuit of this objective, average measure has been
employed as the prevalent measure for evaluating models and comparing
algorithms in the existing DG studies. Despite its significance, a
comprehensive exploration of the average measure has been lacking and its
suitability in approximating the true domain generalization performance has
been questionable. In this study, we carefully investigate the limitations
inherent in the average measure and propose worst+gap measure as a robust
alternative. We establish theoretical grounds of the proposed measure by
deriving two theorems starting from two different assumptions. We conduct
extensive experimental investigations to compare the proposed worst+gap measure
with the conventional average measure. Given the indispensable need to access
the true DG performance for studying measures, we modify five existing datasets
to come up with SR-CMNIST, C-Cats&Dogs, L-CIFAR10, PACS-corrupted, and
VLCS-corrupted datasets. The experiment results unveil an inferior performance
of the average measure in approximating the true DG performance and confirm the
robustness of the theoretically supported worst+gap measure.",2024-05-30,"Duhun Hwang, Suhyun Kang, Moonjung Eo, Jimyeong Kim, Wonjong Rhee",http://arxiv.org/pdf/2405.19703v2,cs.LG
Bilevel reinforcement learning via the development of hyper-gradient without lower-level convexity,"Bilevel reinforcement learning (RL), which features intertwined two-level
problems, has attracted growing interest recently. The inherent non-convexity
of the lower-level RL problem is, however, to be an impediment to developing
bilevel optimization methods. By employing the fixed point equation associated
with the regularized RL, we characterize the hyper-gradient via fully
first-order information, thus circumventing the assumption of lower-level
convexity. This, remarkably, distinguishes our development of hyper-gradient
from the general AID-based bilevel frameworks since we take advantage of the
specific structure of RL problems. Moreover, we design both model-based and
model-free bilevel reinforcement learning algorithms, facilitated by access to
the fully first-order hyper-gradient. Both algorithms enjoy the convergence
rate $O(\epsilon^{-1})$. To extend the applicability, a stochastic version of
the model-free algorithm is proposed, along with results on its iteration and
sample complexity. In addition, numerical experiments demonstrate that the
hyper-gradient indeed serves as an integration of exploitation and exploration.",2024-05-30,"Yan Yang, Bin Gao, Ya-xiang Yuan",http://arxiv.org/pdf/2405.19697v2,cs.LG
Diffusion Policies creating a Trust Region for Offline Reinforcement Learning,"Offline reinforcement learning (RL) leverages pre-collected datasets to train
optimal policies. Diffusion Q-Learning (DQL), introducing diffusion models as a
powerful and expressive policy class, significantly boosts the performance of
offline RL. However, its reliance on iterative denoising sampling to generate
actions slows down both training and inference. While several recent attempts
have tried to accelerate diffusion-QL, the improvement in training and/or
inference speed often results in degraded performance. In this paper, we
introduce a dual policy approach, Diffusion Trusted Q-Learning (DTQL), which
comprises a diffusion policy for pure behavior cloning and a practical one-step
policy. We bridge the two polices by a newly introduced diffusion trust region
loss. The diffusion policy maintains expressiveness, while the trust region
loss directs the one-step policy to explore freely and seek modes within the
region defined by the diffusion policy. DTQL eliminates the need for iterative
denoising sampling during both training and inference, making it remarkably
computationally efficient. We evaluate its effectiveness and algorithmic
characteristics against popular Kullback--Leibler divergence-based distillation
methods in 2D bandit scenarios and gym tasks. We then show that DTQL could not
only outperform other methods on the majority of the D4RL benchmark tasks but
also demonstrate efficiency in training and inference speeds. The PyTorch
implementation is available at
https://github.com/TianyuCodings/Diffusion_Trusted_Q_Learning.",2024-05-30,"Tianyu Chen, Zhendong Wang, Mingyuan Zhou",http://arxiv.org/pdf/2405.19690v3,cs.LG
A Machine Learning-Based Framework for Assessing Cryptographic Indistinguishability of Lightweight Block Ciphers,"Indistinguishability is a fundamental principle of cryptographic security,
crucial for securing data transmitted between Internet of Things (IoT) devices.
This principle ensures that an attacker cannot distinguish between the
encrypted data, also known as ciphertext, and random data or the ciphertexts of
the two messages encrypted with the same key. This research investigates the
ability of machine learning (ML) in assessing indistinguishability property in
encryption systems, with a focus on lightweight ciphers. As our first case
study, we consider the SPECK32/64 and SIMON32/64 lightweight block ciphers,
designed for IoT devices operating under significant energy constraints.
  In this research, we introduce MIND-Crypt, a novel ML-based framework
designed to assess the cryptographic indistinguishability of lightweight block
ciphers, specifically the SPECK32/64 and SIMON32/64 encryption algorithm in CBC
mode (Cipher Block Chaining), under Known Plaintext Attacks (KPA). Our approach
involves training ML models using ciphertexts from two plaintext messages
encrypted with same key to determine whether ML algorithms can identify
meaningful cryptographic patterns or leakage. Our experiments show that modern
ML techniques consistently achieve accuracy equivalent to random guessing,
indicating that no statistically exploitable patterns exists in the ciphertexts
generated by considered lightweight block ciphers. Furthermore, we demonstrate
that in ML algorithms with all the possible combinations of the ciphertexts for
given plaintext messages reflects memorization rather than generalization to
unseen ciphertexts.
  Collectively, these findings suggest that existing block ciphers have secure
cryptographic designs against ML-based indistinguishability assessments,
reinforcing their security even under round-reduced conditions.",2024-05-30,"Jimmy Dani, Kalyan Nakka, Nitesh Saxena",http://arxiv.org/pdf/2405.19683v2,cs.LG
Bayesian Online Natural Gradient (BONG),"We propose a novel approach to sequential Bayesian inference based on
variational Bayes (VB). The key insight is that, in the online setting, we do
not need to add the KL term to regularize to the prior (which comes from the
posterior at the previous timestep); instead we can optimize just the expected
log-likelihood, performing a single step of natural gradient descent starting
at the prior predictive. We prove this method recovers exact Bayesian inference
if the model is conjugate. We also show how to compute an efficient
deterministic approximation to the VB objective, as well as our simplified
objective, when the variational distribution is Gaussian or a sub-family,
including the case of a diagonal plus low-rank precision matrix. We show
empirically that our method outperforms other online VB methods in the
non-conjugate setting, such as online learning for neural networks, especially
when controlling for computational costs.",2024-05-30,"Matt Jones, Peter Chang, Kevin Murphy",http://arxiv.org/pdf/2405.19681v2,cs.LG
Efficient Trajectory Inference in Wasserstein Space Using Consecutive Averaging,"Capturing data from dynamic processes through cross-sectional measurements is
seen in many fields, such as computational biology. Trajectory inference deals
with the challenge of reconstructing continuous processes from such
observations. In this work, we propose methods for B-spline approximation and
interpolation of point clouds through consecutive averaging that is intrinsic
to the Wasserstein space. Combining subdivision schemes with optimal
transport-based geodesic, our methods carry out trajectory inference at a
chosen level of precision and smoothness, and can automatically handle
scenarios where particles undergo division over time. We prove linear
convergence rates and rigorously evaluate our method on cell data characterized
by bifurcations, merges, and trajectory splitting scenarios like $supercells$,
comparing its performance against state-of-the-art trajectory inference and
interpolation methods. The results not only underscore the effectiveness of our
method in inferring trajectories but also highlight the benefit of performing
interpolation and approximation that respect the inherent geometric properties
of the data.",2024-05-30,"Amartya Banerjee, Harlin Lee, Nir Sharon, Caroline Moosmüller",http://arxiv.org/pdf/2405.19679v2,cs.LG
Bridging Model-Based Optimization and Generative Modeling via Conservative Fine-Tuning of Diffusion Models,"AI-driven design problems, such as DNA/protein sequence design, are commonly
tackled from two angles: generative modeling, which efficiently captures the
feasible design space (e.g., natural images or biological sequences), and
model-based optimization, which utilizes reward models for extrapolation. To
combine the strengths of both approaches, we adopt a hybrid method that
fine-tunes cutting-edge diffusion models by optimizing reward models through
RL. Although prior work has explored similar avenues, they primarily focus on
scenarios where accurate reward models are accessible. In contrast, we
concentrate on an offline setting where a reward model is unknown, and we must
learn from static offline datasets, a common scenario in scientific domains. In
offline scenarios, existing approaches tend to suffer from overoptimization, as
they may be misled by the reward model in out-of-distribution regions. To
address this, we introduce a conservative fine-tuning approach, BRAID, by
optimizing a conservative reward model, which includes additional penalization
outside of offline data distributions. Through empirical and theoretical
analysis, we demonstrate the capability of our approach to outperform the best
designs in offline data, leveraging the extrapolation capabilities of reward
models while avoiding the generation of invalid designs through pre-trained
diffusion models.",2024-05-30,"Masatoshi Uehara, Yulai Zhao, Ehsan Hajiramezanali, Gabriele Scalia, Gökcen Eraslan, Avantika Lal, Sergey Levine, Tommaso Biancalani",http://arxiv.org/pdf/2405.19673v2,cs.LG
CRIS: Collaborative Refinement Integrated with Segmentation for Polyp Segmentation,"Accurate detection of colorectal cancer and early prevention heavily rely on
precise polyp identification during gastrointestinal colonoscopy. Due to
limited data, many current state-of-the-art deep learning methods for polyp
segmentation often rely on post-processing of masks to reduce noise and enhance
results. In this study, we propose an approach that integrates mask refinement
and binary semantic segmentation, leveraging a novel collaborative training
strategy that surpasses current widely-used refinement strategies. We
demonstrate the superiority of our approach through comprehensive evaluation on
established benchmark datasets and its successful application across various
medical image segmentation architectures.",2024-05-30,"Ankush Gajanan Arudkar, Bernard J. E. Evans",http://arxiv.org/pdf/2405.19672v1,cs.LG
Reconciling Model Multiplicity for Downstream Decision Making,"We consider the problem of model multiplicity in downstream decision-making,
a setting where two predictive models of equivalent accuracy cannot agree on
the best-response action for a downstream loss function. We show that even when
the two predictive models approximately agree on their individual predictions
almost everywhere, it is still possible for their induced best-response actions
to differ on a substantial portion of the population. We address this issue by
proposing a framework that calibrates the predictive models with regard to both
the downstream decision-making problem and the individual probability
prediction. Specifically, leveraging tools from multi-calibration, we provide
an algorithm that, at each time-step, first reconciles the differences in
individual probability prediction, then calibrates the updated models such that
they are indistinguishable from the true probability distribution to the
decision-maker. We extend our results to the setting where one does not have
direct access to the true probability distribution and instead relies on a set
of i.i.d data to be the empirical distribution. Finally, we provide a set of
experiments to empirically evaluate our methods: compared to existing work, our
proposed algorithm creates a pair of predictive models with both improved
downstream decision-making losses and agrees on their best-response actions
almost everywhere.",2024-05-30,"Ally Yalei Du, Dung Daniel Ngo, Zhiwei Steven Wu",http://arxiv.org/pdf/2405.19667v1,cs.LG
A novel fault localization with data refinement for hydroelectric units,"Due to the scarcity of fault samples and the complexity of non-linear and
non-smooth characteristics data in hydroelectric units, most of the traditional
hydroelectric unit fault localization methods are difficult to carry out
accurate localization. To address these problems, a sparse autoencoder
(SAE)-generative adversarial network (GAN)-wavelet noise reduction (WNR)-
manifold-boosted deep learning (SG-WMBDL) based fault localization method for
hydroelectric units is proposed. To overcome the data scarcity, a SAE is
embedded into the GAN to generate more high-quality samples in the data
generation module. Considering the signals involving non-linear and non-smooth
characteristics, the improved WNR which combining both soft and hard
thresholding and local linear embedding (LLE) are utilized to the data
preprocessing module in order to reduce the noise and effectively capture the
local features. In addition, to seek higher performance, the novel Adaptive
Boost (AdaBoost) combined with multi deep learning is proposed to achieve
accurate fault localization. The experimental results show that the SG-WMBDL
can locate faults for hydroelectric units under a small number of fault samples
with non-linear and non-smooth characteristics on higher precision and accuracy
compared to other frontier methods, which verifies the effectiveness and
practicality of the proposed method.",2024-05-30,"Jialong Huang, Junlin Song, Penglong Lian, Mengjie Gan, Zhiheng Su, Benhao Wang, Wenji Zhu, Xiaomin Pu, Jianxiao Zou, Shicai Fan",http://arxiv.org/pdf/2405.19665v1,cs.LG
MGCP: A Multi-Grained Correlation based Prediction Network for Multivariate Time Series,"Multivariate time series prediction is widely used in daily life, which poses
significant challenges due to the complex correlations that exist at
multi-grained levels. Unfortunately, the majority of current time series
prediction models fail to simultaneously learn the correlations of multivariate
time series at multi-grained levels, resulting in suboptimal performance. To
address this, we propose a Multi-Grained Correlations-based Prediction (MGCP)
Network, which simultaneously considers the correlations at three granularity
levels to enhance prediction performance. Specifically, MGCP utilizes Adaptive
Fourier Neural Operators and Graph Convolutional Networks to learn the global
spatiotemporal correlations and inter-series correlations, enabling the
extraction of potential features from multivariate time series at fine-grained
and medium-grained levels. Additionally, MGCP employs adversarial training with
an attention mechanism-based predictor and conditional discriminator to
optimize prediction results at coarse-grained level, ensuring high fidelity
between the generated forecast results and the actual data distribution.
Finally, we compare MGCP with several state-of-the-art time series prediction
algorithms on real-world benchmark datasets, and our results demonstrate the
generality and effectiveness of the proposed model.",2024-05-30,"Zhicheng Chen, Xi Xiao, Ke Xu, Zhong Zhang, Yu Rong, Qing Li, Guojun Gan, Zhiqiang Xu, Peilin Zhao",http://arxiv.org/pdf/2405.19661v1,cs.LG
SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems,"Surrogate models are used to predict the behavior of complex energy systems
that are too expensive to simulate with traditional numerical methods. Our work
introduces the use of language descriptions, which we call ``system captions''
or SysCaps, to interface with such surrogates. We argue that interacting with
surrogates through text, particularly natural language, makes these models more
accessible for both experts and non-experts. We introduce a lightweight
multimodal text and timeseries regression model and a training pipeline that
uses large language models (LLMs) to synthesize high-quality captions from
simulation metadata. Our experiments on two real-world simulators of buildings
and wind farms show that our SysCaps-augmented surrogates have better accuracy
on held-out systems than traditional methods while enjoying new generalization
abilities, such as handling semantically related descriptions of the same test
system. Additional experiments also highlight the potential of SysCaps to
unlock language-driven design space exploration and to regularize training
through prompt augmentation.",2024-05-30,"Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen",http://arxiv.org/pdf/2405.19653v4,cs.LG
Few for Many: Tchebycheff Set Scalarization for Many-Objective Optimization,"Multi-objective optimization can be found in many real-world applications
where some conflicting objectives can not be optimized by a single solution.
Existing optimization methods often focus on finding a set of Pareto solutions
with different optimal trade-offs among the objectives. However, the required
number of solutions to well approximate the whole Pareto optimal set could be
exponentially large with respect to the number of objectives, which makes these
methods unsuitable for handling many optimization objectives. In this work,
instead of finding a dense set of Pareto solutions, we propose a novel
Tchebycheff set scalarization method to find a few representative solutions
(e.g., 5) to cover a large number of objectives (e.g., $>100$) in a
collaborative and complementary manner. In this way, each objective can be well
addressed by at least one solution in the small solution set. In addition, we
further develop a smooth Tchebycheff set scalarization approach for efficient
optimization with good theoretical guarantees. Experimental studies on
different problems with many optimization objectives demonstrate the
effectiveness of our proposed method.",2024-05-30,"Xi Lin, Yilu Liu, Xiaoyuan Zhang, Fei Liu, Zhenkun Wang, Qingfu Zhang",http://arxiv.org/pdf/2405.19650v2,cs.LG
Towards Deeper Understanding of PPR-based Embedding Approaches: A Topological Perspective,"Node embedding learns low-dimensional vectors for nodes in the graph. Recent
state-of-the-art embedding approaches take Personalized PageRank (PPR) as the
proximity measure and factorize the PPR matrix or its adaptation to generate
embeddings. However, little previous work analyzes what information is encoded
by these approaches, and how the information correlates with their superb
performance in downstream tasks. In this work, we first show that
state-of-the-art embedding approaches that factorize a PPR-related matrix can
be unified into a closed-form framework. Then, we study whether the embeddings
generated by this strategy can be inverted to better recover the graph topology
information than random-walk based embeddings. To achieve this, we propose two
methods for recovering graph topology via PPR-based embeddings, including the
analytical method and the optimization method. Extensive experimental results
demonstrate that the embeddings generated by factorizing a PPR-related matrix
maintain more topological information, such as common edges and community
structures, than that generated by random walks, paving a new way to
systematically comprehend why PPR-based node embedding approaches outperform
random walk-based alternatives in various downstream tasks. To the best of our
knowledge, this is the first work that focuses on the interpretability of
PPR-based node embedding approaches.",2024-05-30,"Xingyi Zhang, Zixuan Weng, Sibo Wang",http://arxiv.org/pdf/2405.19649v1,cs.LG
Detecting Hallucinations in Large Language Model Generation: A Token Probability Approach,"Concerns regarding the propensity of Large Language Models (LLMs) to produce
inaccurate outputs, also known as hallucinations, have escalated. Detecting
them is vital for ensuring the reliability of applications relying on
LLM-generated content. Current methods often demand substantial resources and
rely on extensive LLMs or employ supervised learning with multidimensional
features or intricate linguistic and semantic analyses difficult to reproduce
and largely depend on using the same LLM that hallucinated. This paper
introduces a supervised learning approach employing two simple classifiers
utilizing only four numerical features derived from tokens and vocabulary
probabilities obtained from other LLM evaluators, which are not necessarily the
same. The method yields promising results, surpassing state-of-the-art outcomes
in multiple tasks across three different benchmarks. Additionally, we provide a
comprehensive examination of the strengths and weaknesses of our approach,
highlighting the significance of the features utilized and the LLM employed as
an evaluator. We have released our code publicly at
https://github.com/Baylor-AI/HalluDetect.",2024-05-30,"Ernesto Quevedo, Jorge Yero, Rachel Koerner, Pablo Rivas, Tomas Cerny",http://arxiv.org/pdf/2405.19648v1,cs.LG
FTS: A Framework to Find a Faithful TimeSieve,"The field of time series forecasting has garnered significant attention in
recent years, prompting the development of advanced models like TimeSieve,
which demonstrates impressive performance. However, an analysis reveals certain
unfaithfulness issues, including high sensitivity to random seeds and minute
input noise perturbations. Recognizing these challenges, we embark on a quest
to define the concept of \textbf{\underline{F}aithful
\underline{T}ime\underline{S}ieve \underline{(FTS)}}, a model that consistently
delivers reliable and robust predictions. To address these issues, we propose a
novel framework aimed at identifying and rectifying unfaithfulness in
TimeSieve. Our framework is designed to enhance the model's stability and
resilience, ensuring that its outputs are less susceptible to the
aforementioned factors. Experimentation validates the effectiveness of our
proposed framework, demonstrating improved faithfulness in the model's
behavior. Looking forward, we plan to expand our experimental scope to further
validate and optimize our algorithm, ensuring comprehensive faithfulness across
a wide range of scenarios. Ultimately, we aspire to make this framework can be
applied to enhance the faithfulness of not just TimeSieve but also other
state-of-the-art temporal methods, thereby contributing to the reliability and
robustness of temporal modeling as a whole.",2024-05-30,"Songning Lai, Ninghui Feng, Haochen Sui, Ze Ma, Hao Wang, Zichen Song, Hang Zhao, Yutao Yue",http://arxiv.org/pdf/2405.19647v3,cs.LG
Efficient Systematic Reviews: Literature Filtering with Transformers & Transfer Learning,"Identifying critical research within the growing body of academic work is an
intrinsic aspect of conducting quality research. Systematic review processes
used in evidence-based medicine formalise this as a procedure that must be
followed in a research program. However, it comes with an increasing burden in
terms of the time required to identify the important articles of research for a
given topic. In this work, we develop a method for building a general-purpose
filtering system that matches a research question, posed as a natural language
description of the required content, against a candidate set of articles
obtained via the application of broad search terms. Our results demonstrate
that transformer models, pre-trained on biomedical literature, and then fine
tuned for the specific task, offer a promising solution to this problem. The
model can remove large volumes of irrelevant articles for most research
questions. Furthermore, analysis of the specific research questions in our
training data suggest natural avenues for further improvement.",2024-05-30,"John Hawkins, David Tivey",http://arxiv.org/pdf/2405.20354v2,cs.LG
EgoSurgery-Phase: A Dataset of Surgical Phase Recognition from Egocentric Open Surgery Videos,"Surgical phase recognition has gained significant attention due to its
potential to offer solutions to numerous demands of the modern operating room.
However, most existing methods concentrate on minimally invasive surgery (MIS),
leaving surgical phase recognition for open surgery understudied. This
discrepancy is primarily attributed to the scarcity of publicly available open
surgery video datasets for surgical phase recognition. To address this issue,
we introduce a new egocentric open surgery video dataset for phase recognition,
named EgoSurgery-Phase. This dataset comprises 15 hours of real open surgery
videos spanning 9 distinct surgical phases all captured using an egocentric
camera attached to the surgeon's head. In addition to video, the
EgoSurgery-Phase offers eye gaze. As far as we know, it is the first real open
surgery video dataset for surgical phase recognition publicly available.
Furthermore, inspired by the notable success of masked autoencoders (MAEs) in
video understanding tasks (e.g., action recognition), we propose a gaze-guided
masked autoencoder (GGMAE). Considering the regions where surgeons' gaze
focuses are often critical for surgical phase recognition (e.g., surgical
field), in our GGMAE, the gaze information acts as an empirical semantic
richness prior to guiding the masking process, promoting better attention to
semantically rich spatial regions. GGMAE significantly improves the previous
state-of-the-art recognition method (6.4% in Jaccard) and the masked
autoencoder-based method (3.1% in Jaccard) on EgoSurgery-Phase. The dataset is
released at https://github.com/Fujiry0/EgoSurgery.",2024-05-30,"Ryo Fujii, Masashi Hatano, Hideo Saito, Hiroki Kajita",http://arxiv.org/pdf/2405.19644v3,cs.LG
Easy Problems That LLMs Get Wrong,"We introduce a comprehensive Linguistic Benchmark designed to evaluate the
limitations of Large Language Models (LLMs) in domains such as logical
reasoning, spatial intelligence, and linguistic understanding, among others.
Through a series of straightforward questions, it uncovers the significant
limitations of well-regarded models to perform tasks that humans manage with
ease. It also highlights the potential of prompt engineering to mitigate some
errors and underscores the necessity for better training methodologies. Our
findings stress the importance of grounding LLMs with human reasoning and
common sense, emphasising the need for human-in-the-loop for enterprise
applications. We hope this work paves the way for future research to enhance
the usefulness and reliability of new models.",2024-05-30,"Sean Williams, James Huckle",http://arxiv.org/pdf/2405.19616v2,cs.LG
Factor Augmented Tensor-on-Tensor Neural Networks,"This paper studies the prediction task of tensor-on-tensor regression in
which both covariates and responses are multi-dimensional arrays (a.k.a.,
tensors) across time with arbitrary tensor order and data dimension. Existing
methods either focused on linear models without accounting for possibly
nonlinear relationships between covariates and responses, or directly employed
black-box deep learning algorithms that failed to utilize the inherent tensor
structure. In this work, we propose a Factor Augmented Tensor-on-Tensor Neural
Network (FATTNN) that integrates tensor factor models into deep neural
networks. We begin with summarizing and extracting useful predictive
information (represented by the ``factor tensor'') from the complex structured
tensor covariates, and then proceed with the prediction task using the
estimated factor tensor as input of a temporal convolutional neural network.
The proposed methods effectively handle nonlinearity between complex data
structures, and improve over traditional statistical models and conventional
deep learning approaches in both prediction accuracy and computational cost. By
leveraging tensor factor models, our proposed methods exploit the underlying
latent factor structure to enhance the prediction, and in the meantime,
drastically reduce the data dimensionality that speeds up the computation. The
empirical performances of our proposed methods are demonstrated via simulation
studies and real-world applications to three public datasets. Numerical results
show that our proposed algorithms achieve substantial increases in prediction
accuracy and significant reductions in computational time compared to benchmark
methods.",2024-05-30,"Guanhao Zhou, Yuefeng Han, Xiufan Yu",http://arxiv.org/pdf/2405.19610v2,cs.LG
Constrained or Unconstrained? Neural-Network-Based Equation Discovery from Data,"Throughout many fields, practitioners often rely on differential equations to
model systems. Yet, for many applications, the theoretical derivation of such
equations and/or accurate resolution of their solutions may be intractable.
Instead, recently developed methods, including those based on parameter
estimation, operator subset selection, and neural networks, allow for the
data-driven discovery of both ordinary and partial differential equations
(PDEs), on a spectrum of interpretability. The success of these strategies is
often contingent upon the correct identification of representative equations
from noisy observations of state variables and, as importantly and intertwined
with that, the mathematical strategies utilized to enforce those equations.
Specifically, the latter has been commonly addressed via unconstrained
optimization strategies. Representing the PDE as a neural network, we propose
to discover the PDE by solving a constrained optimization problem and using an
intermediate state representation similar to a Physics-Informed Neural Network
(PINN). The objective function of this constrained optimization problem
promotes matching the data, while the constraints require that the PDE is
satisfied at several spatial collocation points. We present a penalty method
and a widely used trust-region barrier method to solve this constrained
optimization problem, and we compare these methods on numerical examples. Our
results on the Burgers' and the Korteweg-De Vreis equations demonstrate that
the latter constrained method outperforms the penalty method, particularly for
higher noise levels or fewer collocation points. For both methods, we solve
these discovered neural network PDEs with classical methods, such as finite
difference methods, as opposed to PINNs-type methods relying on automatic
differentiation. We briefly highlight other small, yet crucial, implementation
details.",2024-05-30,"Grant Norman, Jacqueline Wentz, Hemanth Kolla, Kurt Maute, Alireza Doostan",http://arxiv.org/pdf/2406.02581v2,cs.LG
Analysing the Public Discourse around OpenAI's Text-To-Video Model 'Sora' using Topic Modeling,"The recent introduction of OpenAI's text-to-video model Sora has sparked
widespread public discourse across online communities. This study aims to
uncover the dominant themes and narratives surrounding Sora by conducting topic
modeling analysis on a corpus of 1,827 Reddit comments from five relevant
subreddits (r/OpenAI, r/technology, r/singularity, r/vfx, and r/ChatGPT). The
comments were collected over a two-month period following Sora's announcement
in February 2024. After preprocessing the data, Latent Dirichlet Allocation
(LDA) was employed to extract four key topics: 1) AI Impact and Trends in Sora
Discussions, 2) Public Opinion and Concerns about Sora, 3) Artistic Expression
and Video Creation with Sora, and 4) Sora's Applications in Media and
Entertainment. Visualizations including word clouds, bar charts, and t-SNE
clustering provided insights into the importance of topic keywords and the
distribution of comments across topics. The results highlight prominent
narratives around Sora's potential impact on industries and employment, public
sentiment and ethical concerns, creative applications, and use cases in the
media and entertainment sectors. While limited to Reddit data within a specific
timeframe, this study offers a framework for understanding public perceptions
of emerging generative AI technologies through online discourse analysis.",2024-05-30,Vatsal Vinay Parikh,http://arxiv.org/pdf/2407.13071v1,cs.LG
Rethinking Spectral Augmentation for Contrast-based Graph Self-Supervised Learning,"The recent surge in contrast-based graph self-supervised learning has
prominently featured an intensified exploration of spectral cues. Spectral
augmentation, which involves modifying a graph's spectral properties such as
eigenvalues or eigenvectors, is widely believed to enhance model performance.
However, an intriguing paradox emerges, as methods grounded in seemingly
conflicting assumptions regarding the spectral domain demonstrate notable
enhancements in learning performance. Through extensive empirical studies, we
find that simple edge perturbations - random edge dropping for node-level and
random edge adding for graph-level self-supervised learning - consistently
yield comparable or superior performance while being significantly more
computationally efficient. This suggests that the computational overhead of
sophisticated spectral augmentations may not justify their practical benefits.
Our theoretical analysis of the InfoNCE loss bounds for shallow GNNs further
supports this observation. The proposed insights represent a significant leap
forward in the field, potentially refining the understanding and implementation
of graph self-supervised learning.",2024-05-30,"Xiangru Jian, Xinjian Zhao, Wei Pang, Chaolong Ying, Yimu Wang, Yaoyao Xu, Tianshu Yu",http://arxiv.org/pdf/2405.19600v2,cs.LG
SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors,"Popular parameter-efficient fine-tuning (PEFT) methods, such as LoRA and its
variants, freeze pre-trained model weights \(W\) and inject learnable matrices
\(\Delta W\). These \(\Delta W\) matrices are structured for efficient
parameterization, often using techniques like low-rank approximations or
scaling vectors. However, these methods typically show a performance gap
compared to full fine-tuning. Although recent PEFT methods have narrowed this
gap, they do so at the cost of additional learnable parameters. We propose
SVFT, a simple approach that fundamentally differs from existing methods: the
structure imposed on \(\Delta W\) depends on the specific weight matrix \(W\).
Specifically, SVFT updates \(W\) as a sparse combination of outer products of
its singular vectors, training only the coefficients (scales) of these sparse
combinations. This approach allows fine-grained control over expressivity
through the number of coefficients. Extensive experiments on language and
vision benchmarks show that SVFT recovers up to 96% of full fine-tuning
performance while training only 0.006 to 0.25% of parameters, outperforming
existing methods that only recover up to 85% performance using 0.03 to 0.8% of
the trainable parameter budget.",2024-05-30,"Vijay Lingam, Atula Tejaswi, Aditya Vavre, Aneesh Shetty, Gautham Krishna Gudur, Joydeep Ghosh, Alex Dimakis, Eunsol Choi, Aleksandar Bojchevski, Sujay Sanghavi",http://arxiv.org/pdf/2405.19597v1,cs.LG
Why Larger Language Models Do In-context Learning Differently?,"Large language models (LLM) have emerged as a powerful tool for AI, with the
key ability of in-context learning (ICL), where they can perform well on unseen
tasks based on a brief series of task examples without necessitating any
adjustments to the model parameters. One recent interesting mysterious
observation is that models of different scales may have different ICL
behaviors: larger models tend to be more sensitive to noise in the test
context. This work studies this observation theoretically aiming to improve the
understanding of LLM and ICL. We analyze two stylized settings: (1) linear
regression with one-layer single-head linear transformers and (2) parity
classification with two-layer multiple attention heads transformers (non-linear
data and non-linear model). In both settings, we give closed-form optimal
solutions and find that smaller models emphasize important hidden features
while larger ones cover more hidden features; thus, smaller models are more
robust to noise while larger ones are more easily distracted, leading to
different ICL behaviors. This sheds light on where transformers pay attention
to and how that affects ICL. Preliminary experimental results on large base and
chat models provide positive support for our analysis.",2024-05-30,"Zhenmei Shi, Junyi Wei, Zhuoyan Xu, Yingyu Liang",http://arxiv.org/pdf/2405.19592v1,cs.LG
Weights Augmentation: it has never ever ever ever let her model down,"Weight play an essential role in deep learning network models. Unlike network
structure design, this article proposes the concept of weight augmentation,
focusing on weight exploration. The core of Weight Augmentation Strategy (WAS)
is to adopt random transformed weight coefficients training and transformed
coefficients, named Shadow Weight(SW), for networks that can be used to
calculate loss function to affect parameter updates. However, stochastic
gradient descent is applied to Plain Weight(PW), which is referred to as the
original weight of the network before the random transformation. During
training, numerous SW collectively form high-dimensional space, while PW is
directly learned from the distribution of SW instead of the data. The weight of
the accuracy-oriented mode(AOM) relies on PW, which guarantees the network is
highly robust and accurate. The desire-oriented mode(DOM) weight uses SW, which
is determined by the network model's unique functions based on WAT's
performance desires, such as lower computational complexity, lower sensitivity
to particular data, etc. The dual mode be switched at anytime if needed. WAT
extends the augmentation technique from data augmentation to weight, and it is
easy to understand and implement, but it can improve almost all networks
amazingly. Our experimental results show that convolutional neural networks,
such as VGG-16, ResNet-18, ResNet-34, GoogleNet, MobilementV2, and
Efficientment-Lite, can benefit much at little or no cost. The accuracy of
models is on the CIFAR100 and CIFAR10 datasets, which can be evaluated to
increase by 7.32\% and 9.28\%, respectively, with the highest values being
13.42\% and 18.93\%, respectively. In addition, DOM can reduce floating point
operations (FLOPs) by up to 36.33\%. The code is available at
https://github.com/zlearh/Weight-Augmentation-Technology.",2024-05-30,"Junbin Zhuang, Guiguang Din, Yunyi Yan",http://arxiv.org/pdf/2405.19590v1,cs.LG
SAM-E: Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation,"Acquiring a multi-task imitation policy in 3D manipulation poses challenges
in terms of scene understanding and action prediction. Current methods employ
both 3D representation and multi-view 2D representation to predict the poses of
the robot's end-effector. However, they still require a considerable amount of
high-quality robot trajectories, and suffer from limited generalization in
unseen tasks and inefficient execution in long-horizon reasoning. In this
paper, we propose SAM-E, a novel architecture for robot manipulation by
leveraging a vision-foundation model for generalizable scene understanding and
sequence imitation for long-term action reasoning. Specifically, we adopt
Segment Anything (SAM) pre-trained on a huge number of images and promptable
masks as the foundation model for extracting task-relevant features, and employ
parameter-efficient fine-tuning on robot data for a better understanding of
embodied scenarios. To address long-horizon reasoning, we develop a novel
multi-channel heatmap that enables the prediction of the action sequence in a
single pass, notably enhancing execution efficiency. Experimental results from
various instruction-following tasks demonstrate that SAM-E achieves superior
performance with higher execution efficiency compared to the baselines, and
also significantly improves generalization in few-shot adaptation to new tasks.",2024-05-30,"Junjie Zhang, Chenjia Bai, Haoran He, Wenke Xia, Zhigang Wang, Bin Zhao, Xiu Li, Xuelong Li",http://arxiv.org/pdf/2405.19586v1,cs.LG
Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding,"Vision-Language Models (VLM) can support clinicians by analyzing medical
images and engaging in natural language interactions to assist in diagnostic
and treatment tasks. However, VLMs often exhibit ""hallucinogenic"" behavior,
generating textual outputs not grounded in contextual multimodal information.
This challenge is particularly pronounced in the medical domain, where we do
not only require VLM outputs to be accurate in single interactions but also to
be consistent with clinical reasoning and diagnostic pathways throughout
multi-turn conversations. For this purpose, we propose a new alignment
algorithm that uses symbolic representations of clinical reasoning to ground
VLMs in medical knowledge. These representations are utilized to (i) generate
GPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM
conversations with demonstrations of clinical reasoning, and (ii) create an
automatic reward function that evaluates the clinical validity of VLM
generations throughout clinician-VLM interactions. Our algorithm eliminates the
need for human involvement in training data generation or reward model
construction, reducing costs compared to standard reinforcement learning with
human feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a
conversational VLM finetuned for analyzing bone marrow pathology slides,
demonstrating strong performance in multi-turn medical conversations.",2024-05-29,"Shenghuan Sun, Alexander Schubert, Gregory M. Goldgof, Zhiqing Sun, Thomas Hartvigsen, Atul J. Butte, Ahmed Alaa",http://arxiv.org/pdf/2405.19567v2,cs.LG
Selective Explanations,"Feature attribution methods explain black-box machine learning (ML) models by
assigning importance scores to input features. These methods can be
computationally expensive for large ML models. To address this challenge, there
has been increasing efforts to develop amortized explainers, where a machine
learning model is trained to predict feature attribution scores with only one
inference. Despite their efficiency, amortized explainers can produce
inaccurate predictions and misleading explanations. In this paper, we propose
selective explanations, a novel feature attribution method that (i) detects
when amortized explainers generate low-quality explanations and (ii) improves
these explanations using a technique called explanations with initial guess.
Our selective explanation method allows practitioners to specify the fraction
of samples that receive explanations with initial guess, offering a principled
way to bridge the gap between amortized explainers and their high-quality
counterparts.",2024-05-29,"Lucas Monteiro Paes, Dennis Wei, Flavio P. Calmon",http://arxiv.org/pdf/2405.19562v1,cs.LG
Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study,"Automated clinical text anonymization has the potential to unlock the
widespread sharing of textual health data for secondary usage while assuring
patient privacy and safety. Despite the proposal of many complex and
theoretically successful anonymization solutions in literature, these
techniques remain flawed. As such, clinical institutions are still reluctant to
apply them for open access to their data. Recent advances in developing Large
Language Models (LLMs) pose a promising opportunity to further the field, given
their capability to perform various tasks. This paper proposes six new
evaluation metrics tailored to the challenges of generative anonymization with
LLMs. Moreover, we present a comparative study of LLM-based methods, testing
them against two baseline techniques. Our results establish LLM-based models as
a reliable alternative to common approaches, paving the way toward trustworthy
anonymization of clinical text.",2024-05-29,"David Pissarra, Isabel Curioso, João Alveira, Duarte Pereira, Bruno Ribeiro, Tomás Souper, Vasco Gomes, André V. Carreiro, Vitor Rolla",http://arxiv.org/pdf/2406.00062v1,cs.LG
STAT: Shrinking Transformers After Training,"We present STAT: a simple algorithm to prune transformer models without any
fine-tuning. STAT eliminates both attention heads and neurons from the network,
while preserving accuracy by calculating a correction to the weights of the
next layer. Each layer block in the network is compressed using a series of
principled matrix factorizations that preserve the network structure. Our
entire algorithm takes minutes to compress BERT, and less than three hours to
compress models with 7B parameters using a single GPU. Using only several
hundred data examples, STAT preserves the output of the network and improves
upon existing gradient-free pruning methods. It is even competitive with
methods that include significant fine-tuning. We demonstrate our method on both
encoder and decoder architectures, including BERT, DistilBERT, and Llama-2
using benchmarks such as GLUE, Squad, WikiText2.",2024-05-29,"Megan Flynn, Alexander Wang, Dean Edward Alvarez, Christopher De Sa, Anil Damle",http://arxiv.org/pdf/2406.00061v1,cs.LG
Clustering Mixtures of Discrete Distributions: A Note on Mitra's Algorithm,"In this note, we provide a refined analysis of Mitra's algorithm
\cite{mitra2008clustering} for classifying general discrete mixture
distribution models. Built upon spectral clustering
\cite{mcsherry2001spectral}, this algorithm offers compelling conditions for
probability distributions. We enhance this analysis by tailoring the model to
bipartite stochastic block models, resulting in more refined conditions.
Compared to those derived in \cite{mitra2008clustering}, our improved
separation conditions are obtained.",2024-05-29,"Mohamed Seif, Yanxi Chen",http://arxiv.org/pdf/2405.19559v1,cs.LG
Convergence Bounds for Sequential Monte Carlo on Multimodal Distributions using Soft Decomposition,"We prove bounds on the variance of a function $f$ under the empirical measure
of the samples obtained by the Sequential Monte Carlo (SMC) algorithm, with
time complexity depending on local rather than global Markov chain mixing
dynamics. SMC is a Markov Chain Monte Carlo (MCMC) method, which starts by
drawing $N$ particles from a known distribution, and then, through a sequence
of distributions, re-weights and re-samples the particles, at each instance
applying a Markov chain for smoothing. In principle, SMC tries to alleviate
problems from multi-modality. However, most theoretical guarantees for SMC are
obtained by assuming global mixing time bounds, which are only efficient in the
uni-modal setting. We show that bounds can be obtained in the truly multi-modal
setting, with mixing times that depend only on local MCMC dynamics.",2024-05-29,"Holden Lee, Matheau Santana-Gijzen",http://arxiv.org/pdf/2405.19553v1,cs.LG
Cascade-Aware Training of Language Models,"Reducing serving cost and latency is a fundamental concern for the deployment
of language models (LMs) in business applications. To address this, cascades of
LMs offer an effective solution that conditionally employ smaller models for
simpler queries. Cascaded systems are typically built with independently
trained models, neglecting the advantages of considering inference-time
interactions of the cascaded LMs during training. In this paper, we present
cascade-aware training(CAT), an approach to optimizing the overall quality-cost
performance tradeoff of a cascade of LMs. We achieve inference-time benefits by
training the small LM with awareness of its place in a cascade and downstream
capabilities. We demonstrate the value of the proposed method with over 60 LM
tasks of the SuperGLUE, WMT22, and FLAN2021 datasets.",2024-05-29,"Congchao Wang, Sean Augenstein, Keith Rush, Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Aditya Krishna Menon, Alec Go",http://arxiv.org/pdf/2406.00060v1,cs.LG
Stress-Testing Capability Elicitation With Password-Locked Models,"To determine the safety of large language models (LLMs), AI developers must
be able to assess their dangerous capabilities. But simple prompting strategies
often fail to elicit an LLM's full capabilities. One way to elicit capabilities
more robustly is to fine-tune the LLM to complete the task. In this paper, we
investigate the conditions under which fine-tuning-based elicitation suffices
to elicit capabilities. To do this, we introduce password-locked models, LLMs
fine-tuned such that some of their capabilities are deliberately hidden.
Specifically, these LLMs are trained to exhibit these capabilities only when a
password is present in the prompt, and to imitate a much weaker LLM otherwise.
Password-locked models enable a novel method of evaluating capabilities
elicitation methods, by testing whether these password-locked capabilities can
be elicited without using the password. We find that a few high-quality
demonstrations are often sufficient to fully elicit password-locked
capabilities. More surprisingly, fine-tuning can elicit other capabilities that
have been locked using the same password, or even different passwords.
Furthermore, when only evaluations, and not demonstrations, are available,
approaches like reinforcement learning are still often able to elicit
capabilities. Overall, our findings suggest that fine-tuning is an effective
method of eliciting hidden capabilities of current models, but may be
unreliable when high-quality demonstrations are not available, e.g. as may be
the case when models' (hidden) capabilities exceed those of human
demonstrators.",2024-05-29,"Ryan Greenblatt, Fabien Roger, Dmitrii Krasheninnikov, David Krueger",http://arxiv.org/pdf/2405.19550v1,cs.LG
RLeXplore: Accelerating Research in Intrinsically-Motivated Reinforcement Learning,"Extrinsic rewards can effectively guide reinforcement learning (RL) agents in
specific tasks. However, extrinsic rewards frequently fall short in complex
environments due to the significant human effort needed for their design and
annotation. This limitation underscores the necessity for intrinsic rewards,
which offer auxiliary and dense signals and can enable agents to learn in an
unsupervised manner. Although various intrinsic reward formulations have been
proposed, their implementation and optimization details are insufficiently
explored and lack standardization, thereby hindering research progress. To
address this gap, we introduce RLeXplore, a unified, highly modularized, and
plug-and-play framework offering reliable implementations of eight
state-of-the-art intrinsic reward methods. Furthermore, we conduct an in-depth
study that identifies critical implementation details and establishes
well-justified standard practices in intrinsically-motivated RL. Our
documentation, examples, and source code are available at
https://github.com/RLE-Foundation/RLeXplore.",2024-05-29,"Mingqi Yuan, Roger Creus Castanyer, Bo Li, Xin Jin, Wenjun Zeng, Glen Berseth",http://arxiv.org/pdf/2405.19548v2,cs.LG
CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning,"Data selection has emerged as a core issue for large-scale visual-language
model pretaining (e.g., CLIP), particularly with noisy web-curated datasets.
Three main data selection approaches are: (1) leveraging external non-CLIP
models to aid data selection, (2) training new CLIP-style embedding models that
are more effective at selecting high-quality data than the original OpenAI CLIP
model, and (3) designing better metrics or strategies universally applicable to
any CLIP embedding without requiring specific model properties (e.g., CLIPScore
is one popular metric). While the first two approaches have been extensively
studied, the third remains under-explored. In this paper, we advance the third
approach by proposing two new methods. Firstly, instead of classical CLIP
scores that only consider the alignment between two modalities from a single
sample, we introduce surrogate-CLIPLoss (s-CLIPLoss), a CLIP loss-inspired
method that adds the alignment between one sample and its contrastive pairs as
an extra normalization term for better quality measurement. Secondly, when
downstream tasks are known, we propose a new norm-based metric, NormSim, to
measure the similarity between pretraining data and target data. We test our
methods on the data selection benchmark, DataComp~\cite{gadre2023datacomp}.
Compared to the best baseline using only OpenAI's CLIP-L/14, our methods
achieve a 5.3\% improvement on ImageNet-1k and a 2.8\% improvement on 38
downstream evaluation tasks. Moreover, both s-CLIPLoss and NormSim are
compatible with existing techniques. By combining our methods with the current
best methods DFN and HYPE, we can boost average performance on downstream tasks
by 0.9\%, achieving a new state-of-the-art on the DataComp-medium benchmark.",2024-05-29,"Yiping Wang, Yifang Chen, Wendan Yan, Alex Fang, Wenjing Zhou, Kevin Jamieson, Simon Shaolei Du",http://arxiv.org/pdf/2405.19547v2,cs.LG
One-Shot Safety Alignment for Large Language Models via Optimal Dualization,"The growing safety concerns surrounding large language models raise an urgent
need to align them with diverse human preferences to simultaneously enhance
their helpfulness and safety. A promising approach is to enforce safety
constraints through Reinforcement Learning from Human Feedback (RLHF). For such
constrained RLHF, typical Lagrangian-based primal-dual policy optimization
methods are computationally expensive and often unstable. This paper presents a
perspective of dualization that reduces constrained alignment to an equivalent
unconstrained alignment problem. We do so by pre-optimizing a smooth and convex
dual function that has a closed form. This shortcut eliminates the need for
cumbersome primal-dual policy iterations, greatly reducing the computational
burden and improving training stability. Our strategy leads to two practical
algorithms in model-based and preference-based settings (MoCAN and PeCAN,
respectively). A broad range of experiments demonstrate the effectiveness and
merits of our algorithms.",2024-05-29,"Xinmeng Huang, Shuo Li, Edgar Dobriban, Osbert Bastani, Hamed Hassani, Dongsheng Ding",http://arxiv.org/pdf/2405.19544v3,cs.LG
Anatomical Region Recognition and Real-time Bone Tracking Methods by Dynamically Decoding A-Mode Ultrasound Signals,"Accurate bone tracking is crucial for kinematic analysis in orthopedic
surgery and prosthetic robotics. Traditional methods (e.g., skin markers) are
subject to soft tissue artifacts, and the bone pins used in surgery introduce
the risk of additional trauma and infection. For electromyography (EMG), its
inability to directly measure joint angles requires complex algorithms for
kinematic estimation. To address these issues, A-mode ultrasound-based tracking
has been proposed as a non-invasive and safe alternative. However, this
approach suffers from limited accuracy in peak detection when processing
received ultrasound signals. To build a precise and real-time bone tracking
approach, this paper introduces a deep learning-based method for anatomical
region recognition and bone tracking using A-mode ultrasound signals,
specifically focused on the knee joint. The algorithm is capable of
simultaneously performing bone tracking and identifying the anatomical region
where the A-mode ultrasound transducer is placed. It contains the fully
connection between all encoding and decoding layers of the cascaded U-Nets to
focus only on the signal region that is most likely to have the bone peak, thus
pinpointing the exact location of the peak and classifying the anatomical
region of the signal. The experiment showed a 97% accuracy in the
classification of the anatomical regions and a precision of around 0.5$\pm$1mm
under dynamic tracking conditions for various anatomical areas surrounding the
knee joint. In general, this approach shows great potential beyond the
traditional method, in terms of the accuracy achieved and the recognition of
the anatomical region where the ultrasound has been attached as an additional
functionality.",2024-05-29,"Bangyu Lan, Stefano Stramigioli, Kenan Niu",http://arxiv.org/pdf/2405.19542v2,cs.LG
Exploiting Chaotic Dynamics as Deep Neural Networks,"Chaos presents complex dynamics arising from nonlinearity and a sensitivity
to initial states. These characteristics suggest a depth of expressivity that
underscores their potential for advanced computational applications. However,
strategies to effectively exploit chaotic dynamics for information processing
have largely remained elusive. In this study, we reveal that the essence of
chaos can be found in various state-of-the-art deep neural networks. Drawing
inspiration from this revelation, we propose a novel method that directly
leverages chaotic dynamics for deep learning architectures. Our approach is
systematically evaluated across distinct chaotic systems. In all instances, our
framework presents superior results to conventional deep neural networks in
terms of accuracy, convergence speed, and efficiency. Furthermore, we found an
active role of transient chaos formation in our scheme. Collectively, this
study offers a new path for the integration of chaos, which has long been
overlooked in information processing, and provides insights into the
prospective fusion of chaotic dynamics within the domains of machine learning
and neuromorphic computation.",2024-05-29,"Shuhong Liu, Nozomi Akashi, Qingyao Huang, Yasuo Kuniyoshi, Kohei Nakajima",http://arxiv.org/pdf/2406.02580v1,cs.LG
"CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats","Since the release of the original CheXpert paper five years ago, CheXpert has
become one of the most widely used and cited clinical AI datasets. The
emergence of vision language models has sparked an increase in demands for
sharing reports linked to CheXpert images, along with a growing interest among
AI fairness researchers in obtaining demographic data. To address this,
CheXpert Plus serves as a new collection of radiology data sources, made
publicly available to enhance the scaling, performance, robustness, and
fairness of models for all subsequent machine learning tasks in the field of
radiology. CheXpert Plus is the largest text dataset publicly released in
radiology, with a total of 36 million text tokens, including 13 million
impression tokens. To the best of our knowledge, it represents the largest text
de-identification effort in radiology, with almost 1 million PHI spans
anonymized. It is only the second time that a large-scale English paired
dataset has been released in radiology, thereby enabling, for the first time,
cross-institution training at scale. All reports are paired with high-quality
images in DICOM format, along with numerous image and patient metadata covering
various clinical and socio-economic groups, as well as many pathology labels
and RadGraph annotations. We hope this dataset will boost research for AI
models that can further assist radiologists and help improve medical care. Data
is available at the following URL:
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Models are available at the following URL:
https://github.com/Stanford-AIMI/chexpert-plus",2024-05-29,"Pierre Chambon, Jean-Benoit Delbrouck, Thomas Sounack, Shih-Cheng Huang, Zhihong Chen, Maya Varma, Steven QH Truong, Chu The Chuong, Curtis P. Langlotz",http://arxiv.org/pdf/2405.19538v2,cs.LG
Preference Learning Algorithms Do Not Learn Preference Rankings,"Preference learning algorithms (e.g., RLHF and DPO) are frequently used to
steer LLMs to produce generations that are more preferred by humans, but our
understanding of their inner workings is still limited. In this work, we study
the conventional wisdom that preference learning trains models to assign higher
likelihoods to more preferred outputs than less preferred outputs, measured via
ranking accuracy. Surprisingly, we find that most state-of-the-art
preference-tuned models achieve a ranking accuracy of less than 60% on common
preference datasets. We furthermore derive the idealized ranking accuracy that
a preference-tuned LLM would achieve if it optimized the DPO or RLHF objective
perfectly. We demonstrate that existing models exhibit a significant alignment
gap -- i.e., a gap between the observed and idealized ranking accuracies. We
attribute this discrepancy to the DPO objective, which is empirically and
theoretically ill-suited to fix even mild ranking errors in the reference
model, and derive a simple and efficient formula for quantifying the difficulty
of learning a given preference datapoint. Finally, we demonstrate that ranking
accuracy strongly correlates with the empirically popular win rate metric when
the model is close to the reference model used in the objective, shedding
further light on the differences between on-policy (e.g., RLHF) and off-policy
(e.g., DPO) preference learning algorithms.",2024-05-29,"Angelica Chen, Sadhika Malladi, Lily H. Zhang, Xinyi Chen, Qiuyi Zhang, Rajesh Ranganath, Kyunghyun Cho",http://arxiv.org/pdf/2405.19534v4,cs.LG
Contrasting Multiple Representations with the Multi-Marginal Matching Gap,"Learning meaningful representations of complex objects that can be seen
through multiple ($k\geq 3$) views or modalities is a core task in machine
learning. Existing methods use losses originally intended for paired views, and
extend them to $k$ views, either by instantiating $\tfrac12k(k-1)$ loss-pairs,
or by using reduced embeddings, following a \textit{one vs. average-of-rest}
strategy. We propose the multi-marginal matching gap (M3G), a loss that borrows
tools from multi-marginal optimal transport (MM-OT) theory to simultaneously
incorporate all $k$ views. Given a batch of $n$ points, each seen as a
$k$-tuple of views subsequently transformed into $k$ embeddings, our loss
contrasts the cost of matching these $n$ ground-truth $k$-tuples with the MM-OT
polymatching cost, which seeks $n$ optimally arranged $k$-tuples chosen within
these $n\times k$ vectors. While the exponential complexity $O(n^k$) of the
MM-OT problem may seem daunting, we show in experiments that a suitable
generalization of the Sinkhorn algorithm for that problem can scale to, e.g.,
$k=3\sim 6$ views using mini-batches of size $64~\sim128$. Our experiments
demonstrate improved performance over multiview extensions of pairwise losses,
for both self-supervised and multimodal tasks.",2024-05-29,"Zoe Piran, Michal Klein, James Thornton, Marco Cuturi",http://arxiv.org/pdf/2405.19532v1,cs.LG
Conveyor: Efficient Tool-aware LLM Serving with Tool Partial Execution,"The complexity of large language model (LLM) serving workloads has
substantially increased due to the integration with external tool invocations,
such as ChatGPT plugins. In this paper, we identify a new opportunity for
efficient LLM serving for requests that trigger tools: tool partial execution
alongside LLM decoding. To this end, we design Conveyor, an efficient LLM
serving system optimized for handling requests involving external tools. We
introduce a novel interface for tool developers to expose partial execution
opportunities to the LLM serving system and a request scheduler that
facilitates partial tool execution. Our results demonstrate that tool partial
execution can improve request completion latency by up to 38.8%.",2024-05-29,"Yechen Xu, Xinhao Kong, Tingjun Chen, Danyang Zhuo",http://arxiv.org/pdf/2406.00059v2,cs.LG
Hierarchical Procedural Framework for Low-latency Robot-Assisted Hand-Object Interaction,"Advances in robotics have been driving the development of human-robot
interaction (HRI) technologies. However, accurately perceiving human actions
and achieving adaptive control remains a challenge in facilitating seamless
coordination between human and robotic movements. In this paper, we propose a
hierarchical procedural framework to enable dynamic robot-assisted hand-object
interaction. An open-loop hierarchy leverages the computer vision (CV)-based 3D
reconstruction of the human hand, based on which motion primitives have been
designed to translate hand motions into robotic actions. The low-level
coordination hierarchy fine-tunes the robot's action by using the continuously
updated 3D hand models. Experimental validation demonstrates the effectiveness
of the hierarchical control architecture. The adaptive coordination between
human and robot behavior has achieved a delay of $\leq 0.3$ seconds in the
tele-interaction scenario. A case study of ring-wearing tasks indicates the
potential application of this work in assistive technologies such as healthcare
and manufacturing.",2024-05-29,"Mingqi Yuan, Huijiang Wang, Kai-Fung Chu, Fumiya Iida, Bo Li, Wenjun Zeng",http://arxiv.org/pdf/2405.19531v2,cs.LG
Crowdsourcing with Difficulty: A Bayesian Rating Model for Heterogeneous Items,"In applied statistics and machine learning, the ""gold standards"" used for
training are often biased and almost always noisy. Dawid and Skene's
justifiably popular crowdsourcing model adjusts for rater (coder, annotator)
sensitivity and specificity, but fails to capture distributional properties of
rating data gathered for training, which in turn biases training. In this
study, we introduce a general purpose measurement-error model with which we can
infer consensus categories by adding item-level effects for difficulty,
discriminativeness, and guessability. We further show how to constrain the
bimodal posterior of these models to avoid (or if necessary, allow) adversarial
raters. We validate our model's goodness of fit with posterior predictive
checks, the Bayesian analogue of $\chi^2$ tests. Dawid and Skene's model is
rejected by goodness of fit tests, whereas our new model, which adjusts for
item heterogeneity, is not rejected. We illustrate our new model with two
well-studied data sets, binary rating data for caries in dental X-rays and
implication in natural language.",2024-05-29,"Seong Woo Han, Ozan Adıgüzel, Bob Carpenter",http://arxiv.org/pdf/2405.19521v2,cs.LG
Prediction Beyond the Medium Range with an Atmosphere-Ocean Model that Combines Physics-based Modeling and Machine Learning,"This paper explores the potential of a hybrid modeling approach that combines
machine learning (ML) with conventional physics-based modeling for weather
prediction beyond the medium range. It extends the work of Arcomano et al.
(2022), which tested the approach for short- and medium-range weather
prediction, and the work of Arcomano et al. (2023), which investigated its
potential for climate modeling. The hybrid model used for the forecast
experiments of the paper is based on the low-resolution, simplified
parameterization atmospheric general circulation model SPEEDY. In addition to
the hybridized prognostic variables of SPEEDY, the model has three purely
ML-based prognostic variables: the 6h cumulative precipitation, the sea surface
temperature, and the heat content of the top 300m deep layer of the ocean (a
new addition compared to the model used in Arcomano et al., 2023). The model
has skill in predicting the El Nino cycle and its global teleconnections with
precipitation for 3-7 months depending on the season. The model captures
equatorial variability of the precipitation associated with Kelvin and Rossby
waves and MJO. Predictions of the precipitation in the equatorial region have
skill for 15 days in the East Pacific and 11.5 days in the West Pacific. Though
the model has low spatial resolution, for these tasks it has prediction skill
comparable to what has been published for high-resolution, purely
physics-based, conventional, operational forecast models.",2024-05-29,"Dhruvit Patel, Troy Arcomano, Brian Hunt, Istvan Szunyogh, Edward Ott",http://arxiv.org/pdf/2405.19518v2,cs.LG
Enabling Visual Recognition at Radio Frequency,"This paper introduces PanoRadar, a novel RF imaging system that brings RF
resolution close to that of LiDAR, while providing resilience against
conditions challenging for optical signals. Our LiDAR-comparable 3D imaging
results enable, for the first time, a variety of visual recognition tasks at
radio frequency, including surface normal estimation, semantic segmentation,
and object detection. PanoRadar utilizes a rotating single-chip mmWave radar,
along with a combination of novel signal processing and machine learning
algorithms, to create high-resolution 3D images of the surroundings. Our system
accurately estimates robot motion, allowing for coherent imaging through a
dense grid of synthetic antennas. It also exploits the high azimuth resolution
to enhance elevation resolution using learning-based methods. Furthermore,
PanoRadar tackles 3D learning via 2D convolutions and addresses challenges due
to the unique characteristics of RF signals. Our results demonstrate
PanoRadar's robust performance across 12 buildings.",2024-05-29,"Haowen Lai, Gaoxiang Luo, Yifei Liu, Mingmin Zhao",http://arxiv.org/pdf/2405.19516v1,cs.LG
Decentralized Optimization in Time-Varying Networks with Arbitrary Delays,"We consider a decentralized optimization problem for networks affected by
communication delays. Examples of such networks include collaborative machine
learning, sensor networks, and multi-agent systems. To mimic communication
delays, we add virtual non-computing nodes to the network, resulting in
directed graphs. This motivates investigating decentralized optimization
solutions on directed graphs. Existing solutions assume nodes know their
out-degrees, resulting in limited applicability. To overcome this limitation,
we introduce a novel gossip-based algorithm, called DT-GO, that does not need
to know the out-degrees. The algorithm is applicable in general directed
networks, for example networks with delays or limited acknowledgment
capabilities. We derive convergence rates for both convex and non-convex
objectives, showing that our algorithm achieves the same complexity order as
centralized Stochastic Gradient Descent. In other words, the effects of the
graph topology and delays are confined to higher-order terms. Additionally, we
extend our analysis to accommodate time-varying network topologies. Numerical
simulations are provided to support our theoretical findings.",2024-05-29,"Tomas Ortega, Hamid Jafarkhani",http://arxiv.org/pdf/2405.19513v2,cs.LG
Momentum for the Win: Collaborative Federated Reinforcement Learning across Heterogeneous Environments,"We explore a Federated Reinforcement Learning (FRL) problem where $N$ agents
collaboratively learn a common policy without sharing their trajectory data. To
date, existing FRL work has primarily focused on agents operating in the same
or ``similar"" environments. In contrast, our problem setup allows for
arbitrarily large levels of environment heterogeneity. To obtain the optimal
policy which maximizes the average performance across all potentially
completely different environments, we propose two algorithms: FedSVRPG-M and
FedHAPG-M. In contrast to existing results, we demonstrate that both FedSVRPG-M
and FedHAPG-M, both of which leverage momentum mechanisms, can exactly converge
to a stationary point of the average performance function, regardless of the
magnitude of environment heterogeneity. Furthermore, by incorporating the
benefits of variance-reduction techniques or Hessian approximation, both
algorithms achieve state-of-the-art convergence results, characterized by a
sample complexity of $\mathcal{O}\left(\epsilon^{-\frac{3}{2}}/N\right)$.
Notably, our algorithms enjoy linear convergence speedups with respect to the
number of agents, highlighting the benefit of collaboration among agents in
finding a common policy.",2024-05-29,"Han Wang, Sihong He, Zhili Zhang, Fei Miao, James Anderson",http://arxiv.org/pdf/2405.19499v1,cs.LG
Gaussian Flow Bridges for Audio Domain Transfer with Unpaired Data,"Audio domain transfer is the process of modifying audio signals to match
characteristics of a different domain, while retaining the original content.
This paper investigates the potential of Gaussian Flow Bridges, an emerging
approach in generative modeling, for this problem. The presented framework
addresses the transport problem across different distributions of audio signals
through the implementation of a series of two deterministic probability flows.
The proposed framework facilitates manipulation of the target distribution
properties through a continuous control variable, which defines a certain
aspect of the target domain. Notably, this approach does not rely on paired
examples for training. To address identified challenges on maintaining the
speech content consistent, we recommend a training strategy that incorporates
chunk-based minibatch Optimal Transport couplings of data samples and noise.
Comparing our unsupervised method with established baselines, we find
competitive performance in tasks of reverberation and distortion manipulation.
Despite encoutering limitations, the intriguing results obtained in this study
underscore potential for further exploration.",2024-05-29,"Eloi Moliner, Sebastian Braun, Hannes Gamper",http://arxiv.org/pdf/2405.19497v1,cs.LG
Online Nonparametric Supervised Learning for Massive Data,"Despite their benefits in terms of simplicity, low computational cost and
data requirement, parametric machine learning algorithms, such as linear
discriminant analysis, quadratic discriminant analysis or logistic regression,
suffer from serious drawbacks including linearity, poor fit of features to the
usually imposed normal distribution and high dimensionality. Batch kernel-based
nonparametric classifier, which overcomes the linearity and normality of
features constraints, represent an interesting alternative for supervised
classification problem. However, it suffers from the ``curse of dimension"". The
problem can be alleviated by the explosive sample size in the era of big data,
while large-scale data size presents some challenges in the storage of data and
the calculation of the classifier. These challenges make the classical batch
nonparametric classifier no longer applicable. This motivates us to develop a
fast algorithm adapted to the real-time calculation of the nonparametric
classifier in massive as well as streaming data frameworks. This online
classifier includes two steps. First, we consider an online principle
components analysis to reduce the dimension of the features with a very low
computation cost. Then, a stochastic approximation algorithm is deployed to
obtain a real-time calculation of the nonparametric classifier. The proposed
methods are evaluated and compared to some commonly used machine learning
algorithms for real-time fetal well-being monitoring. The study revealed that,
in terms of accuracy, the offline (or Batch), as well as, the online
classifiers are good competitors to the random forest algorithm. Moreover, we
show that the online classifier gives the best trade-off accuracy/computation
cost compared to the offline classifier.",2024-05-29,"Mohamed Chaouch, Omama M. Al-Hamed",http://arxiv.org/pdf/2405.19486v1,cs.LG
Participation in the age of foundation models,"Growing interest and investment in the capabilities of foundation models has
positioned such systems to impact a wide array of public services. Alongside
these opportunities is the risk that these systems reify existing power
imbalances and cause disproportionate harm to marginalized communities.
Participatory approaches hold promise to instead lend agency and
decision-making power to marginalized stakeholders. But existing approaches in
participatory AI/ML are typically deeply grounded in context - how do we apply
these approaches to foundation models, which are, by design, disconnected from
context? Our paper interrogates this question.
  First, we examine existing attempts at incorporating participation into
foundation models. We highlight the tension between participation and scale,
demonstrating that it is intractable for impacted communities to meaningfully
shape a foundation model that is intended to be universally applicable. In
response, we develop a blueprint for participatory foundation models that
identifies more local, application-oriented opportunities for meaningful
participation. In addition to the ""foundation"" layer, our framework proposes
the ""subfloor'' layer, in which stakeholders develop shared technical
infrastructure, norms and governance for a grounded domain, and the ""surface''
layer, in which affected communities shape the use of a foundation model for a
specific downstream task. The intermediate ""subfloor'' layer scopes the range
of potential harms to consider, and affords communities more concrete avenues
for deliberation and intervention. At the same time, it avoids duplicative
effort by scaling input across relevant use cases. Through three case studies
in clinical care, financial services, and journalism, we illustrate how this
multi-layer model can create more meaningful opportunities for participation
than solely intervening at the foundation layer.",2024-05-29,"Harini Suresh, Emily Tseng, Meg Young, Mary L. Gray, Emma Pierson, Karen Levy",http://arxiv.org/pdf/2405.19479v1,cs.LG
The Data Minimization Principle in Machine Learning,"The principle of data minimization aims to reduce the amount of data
collected, processed or retained to minimize the potential for misuse,
unauthorized access, or data breaches. Rooted in privacy-by-design principles,
data minimization has been endorsed by various global data protection
regulations. However, its practical implementation remains a challenge due to
the lack of a rigorous formulation. This paper addresses this gap and
introduces an optimization framework for data minimization based on its legal
definitions. It then adapts several optimization algorithms to perform data
minimization and conducts a comprehensive evaluation in terms of their
compliance with minimization objectives as well as their impact on user
privacy. Our analysis underscores the mismatch between the privacy expectations
of data minimization and the actual privacy benefits, emphasizing the need for
approaches that account for multiple facets of real-world privacy risks.",2024-05-29,"Prakhar Ganesh, Cuong Tran, Reza Shokri, Ferdinando Fioretto",http://arxiv.org/pdf/2405.19471v1,cs.LG
Active Exploration via Autoregressive Generation of Missing Data,"We pose uncertainty quantification and exploration in online decision-making
as a problem of training and generation from an autoregressive sequence model,
an area experiencing rapid innovation. Our approach rests on viewing
uncertainty as arising from missing future outcomes that would be revealed
through appropriate action choices, rather than from unobservable latent
parameters of the environment. This reformulation aligns naturally with modern
machine learning capabilities: we can i) train generative models through
next-outcome prediction rather than fit explicit priors, ii) assess uncertainty
through autoregressive generation rather than parameter sampling, and iii)
adapt to new information through in-context learning rather than explicit
posterior updating. To showcase these ideas, we formulate a challenging
meta-bandit problem where effective performance requires leveraging
unstructured prior information (like text features) while exploring judiciously
to resolve key remaining uncertainties. We validate our approach through both
theory and experiments. Our theory establishes a reduction, showing success at
offline next-outcome prediction translates to reliable online uncertainty
quantification and decision-making, even with strategically collected data.
Semi-synthetic experiments show our insights bear out in a news-article
recommendation task, where article text can be leveraged to minimize
exploration.",2024-05-29,"Tiffany Tianhui Cai, Hongseok Namkoong, Daniel Russo, Kelly W Zhang",http://arxiv.org/pdf/2405.19466v3,cs.LG
Stochastic Optimization Algorithms for Instrumental Variable Regression with Streaming Data,"We develop and analyze algorithms for instrumental variable regression by
viewing the problem as a conditional stochastic optimization problem. In the
context of least-squares instrumental variable regression, our algorithms
neither require matrix inversions nor mini-batches and provides a fully online
approach for performing instrumental variable regression with streaming data.
When the true model is linear, we derive rates of convergence in expectation,
that are of order $\mathcal{O}(\log T/T)$ and $\mathcal{O}(1/T^{1-\iota})$ for
any $\iota>0$, respectively under the availability of two-sample and one-sample
oracles, respectively, where $T$ is the number of iterations. Importantly,
under the availability of the two-sample oracle, our procedure avoids
explicitly modeling and estimating the relationship between confounder and the
instrumental variables, demonstrating the benefit of the proposed approach over
recent works based on reformulating the problem as minimax optimization
problems. Numerical experiments are provided to corroborate the theoretical
results.",2024-05-29,"Xuxing Chen, Abhishek Roy, Yifan Hu, Krishnakumar Balasubramanian",http://arxiv.org/pdf/2405.19463v1,cs.LG
Clustering-Based Validation Splits for Model Selection under Domain Shift,"This paper considers the problem of model selection under domain shift.
Motivated by principles from distributionally robust optimisation (DRO) and
domain adaptation theory, it is proposed that the training-validation split
should maximise the distribution mismatch between the two sets. By adopting the
maximum mean discrepancy (MMD) as the measure of mismatch, it is shown that the
partitioning problem reduces to kernel k-means clustering. A constrained
clustering algorithm, which leverages linear programming to control the size,
label, and (optionally) group distributions of the splits, is presented. The
algorithm does not require additional metadata, and comes with convergence
guarantees. In experiments, the technique consistently outperforms alternative
splitting strategies across a range of datasets and training algorithms, for
both domain generalisation (DG) and unsupervised domain adaptation (UDA) tasks.
Analysis also shows the MMD between the training and validation sets to be
strongly rank-correlated ($\rho=0.63$) with test domain accuracy, further
substantiating the validity of this approach.",2024-05-29,"Andrea Napoli, Paul White",http://arxiv.org/pdf/2405.19461v2,cs.LG
Deep Grokking: Would Deep Neural Networks Generalize Better?,"Recent research on the grokking phenomenon has illuminated the intricacies of
neural networks' training dynamics and their generalization behaviors. Grokking
refers to a sharp rise of the network's generalization accuracy on the test
set, which occurs long after an extended overfitting phase, during which the
network perfectly fits the training set. While the existing research primarily
focus on shallow networks such as 2-layer MLP and 1-layer Transformer, we
explore grokking on deep networks (e.g. 12-layer MLP). We empirically replicate
the phenomenon and find that deep neural networks can be more susceptible to
grokking than its shallower counterparts. Meanwhile, we observe an intriguing
multi-stage generalization phenomenon when increase the depth of the MLP model
where the test accuracy exhibits a secondary surge, which is scarcely seen on
shallow models. We further uncover compelling correspondences between the
decreasing of feature ranks and the phase transition from overfitting to the
generalization stage during grokking. Additionally, we find that the
multi-stage generalization phenomenon often aligns with a double-descent
pattern in feature ranks. These observations suggest that internal feature rank
could serve as a more promising indicator of the model's generalization
behavior compared to the weight-norm. We believe our work is the first one to
dive into grokking in deep neural networks, and investigate the relationship of
feature rank and generalization performance.",2024-05-29,"Simin Fan, Razvan Pascanu, Martin Jaggi",http://arxiv.org/pdf/2405.19454v1,cs.LG
Gaitor: Learning a Unified Representation Across Gaits for Real-World Quadruped Locomotion,"The current state-of-the-art in quadruped locomotion is able to produce a
variety of complex motions. These methods either rely on switching between a
discrete set of skills or learn a distribution across gaits using complex
black-box models. Alternatively, we present Gaitor, which learns a disentangled
and 2D representation across locomotion gaits. This learnt representation forms
a planning space for closed-loop control delivering continuous gait transitions
and perceptive terrain traversal. Gaitor's latent space is readily
interpretable and we discover that during gait transitions, novel unseen gaits
emerge. The latent space is disentangled with respect to footswing heights and
lengths. This means that these gait characteristics can be varied independently
in the 2D latent representation. Together with a simple terrain encoding and a
learnt planner operating in the latent space, Gaitor can take motion commands
including desired gait type and swing characteristics all while reacting to
uneven terrain. We evaluate Gaitor in both simulation and the real world on the
ANYmal C platform. To the best of our knowledge, this is the first work
learning a unified and interpretable latent space for multiple gaits, resulting
in continuous blending between different locomotion modes on a real quadruped
robot. An overview of the methods and results in this paper is found at
https://youtu.be/eVFQbRyilCA.",2024-05-29,"Alexander L. Mitchell, Wolfgang Merkt, Aristotelis Papatheodorou, Ioannis Havoutis, Ingmar Posner",http://arxiv.org/pdf/2405.19452v2,cs.LG
"MGDA Converges under Generalized Smoothness, Provably","Multi-objective optimization (MOO) is receiving more attention in various
fields such as multi-task learning. Recent works provide some effective
algorithms with theoretical analysis but they are limited by the standard
$L$-smooth or bounded-gradient assumptions, which typically do not hold for
neural networks, such as Long short-term memory (LSTM) models and Transformers.
In this paper, we study a more general and realistic class of generalized
$\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function
of gradient norm. We revisit and analyze the fundamental multiple gradient
descent algorithm (MGDA) and its stochastic version with double sampling for
solving the generalized $\ell$-smooth MOO problems, which approximate the
conflict-avoidant (CA) direction that maximizes the minimum improvement among
objectives. We provide a comprehensive convergence analysis of these algorithms
and show that they converge to an $\epsilon$-accurate Pareto stationary point
with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between
the updating direction and the CA direction) over all iterations, where totally
$\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are
needed for deterministic and stochastic settings, respectively. We prove that
they can also guarantee a tighter $\epsilon$-level CA distance in each
iteration using more samples. Moreover, we analyze an efficient variant of MGDA
named MGDA-FA using only $\mathcal{O}(1)$ time and space, while achieving the
same performance guarantee as MGDA.",2024-05-29,"Qi Zhang, Peiyao Xiao, Shaofeng Zou, Kaiyi Ji",http://arxiv.org/pdf/2405.19440v5,cs.LG
Toward Conversational Agents with Context and Time Sensitive Long-term Memory,"There has recently been growing interest in conversational agents with
long-term memory which has led to the rapid development of language models that
use retrieval-augmented generation (RAG). Until recently, most work on RAG has
focused on information retrieval from large databases of texts, like Wikipedia,
rather than information from long-form conversations. In this paper, we argue
that effective retrieval from long-form conversational data faces two unique
problems compared to static database retrieval: 1) time/event-based queries,
which requires the model to retrieve information about previous conversations
based on time or the order of a conversational event (e.g., the third
conversation on Tuesday), and 2) ambiguous queries that require surrounding
conversational context to understand. To better develop RAG-based agents that
can deal with these challenges, we generate a new dataset of ambiguous and
time-based questions that build upon a recent dataset of long-form, simulated
conversations, and demonstrate that standard RAG based approaches handle such
questions poorly. We then develop a novel retrieval model which combines
chained-of-table search methods, standard vector-database retrieval, and a
prompting method to disambiguate queries, and demonstrate that this approach
substantially improves over current methods at solving these tasks. We believe
that this new dataset and more advanced RAG agent can act as a key benchmark
and stepping stone towards effective memory augmented conversational agents
that can be used in a wide variety of AI applications.",2024-05-29,"Nick Alonso, Tomás Figliolia, Anthony Ndirango, Beren Millidge",http://arxiv.org/pdf/2406.00057v2,cs.LG
System-2 Recommenders: Disentangling Utility and Engagement in Recommendation Systems via Temporal Point-Processes,"Recommender systems are an important part of the modern human experience
whose influence ranges from the food we eat to the news we read. Yet, there is
still debate as to what extent recommendation platforms are aligned with the
user goals. A core issue fueling this debate is the challenge of inferring a
user utility based on engagement signals such as likes, shares, watch time
etc., which are the primary metric used by platforms to optimize content. This
is because users utility-driven decision-processes (which we refer to as
System-2), e.g., reading news that are relevant for them, are often confounded
by their impulsive decision-processes (which we refer to as System-1), e.g.,
spend time on click-bait news. As a result, it is difficult to infer whether an
observed engagement is utility-driven or impulse-driven. In this paper we
explore a new approach to recommender systems where we infer user utility based
on their return probability to the platform rather than engagement signals. Our
intuition is that users tend to return to a platform in the long run if it
creates utility for them, while pure engagement-driven interactions that do not
add utility, may affect user return in the short term but will not have a
lasting effect. We propose a generative model in which past content
interactions impact the arrival rates of users based on a self-exciting Hawkes
process. These arrival rates to the platform are a combination of both System-1
and System-2 decision processes. The System-2 arrival intensity depends on the
utility and has a long lasting effect, while the System-1 intensity depends on
the instantaneous gratification and tends to vanish rapidly. We show
analytically that given samples it is possible to disentangle System-1 and
System-2 and allow content optimization based on user utility. We conduct
experiments on synthetic data to demonstrate the effectiveness of our approach.",2024-05-29,"Arpit Agarwal, Nicolas Usunier, Alessandro Lazaric, Maximilian Nickel",http://arxiv.org/pdf/2406.01611v1,cs.LG
Learning Human-Aligned Representations with Contrastive Learning and Generative Similarity,"Humans rely on effective representations to learn from few examples and
abstract useful information from sensory data. Inducing such representations in
machine learning models has been shown to improve their performance on various
benchmarks such as few-shot learning and robustness. However, finding effective
training procedures to achieve that goal can be challenging as psychologically
rich training data such as human similarity judgments are expensive to scale,
and Bayesian models of human inductive biases are often intractable for
complex, realistic domains. Here, we address this challenge by leveraging a
Bayesian notion of generative similarity whereby two data points are considered
similar if they are likely to have been sampled from the same distribution.
This measure can be applied to complex generative processes, including
probabilistic programs. We incorporate generative similarity into a contrastive
learning objective to enable learning of embeddings that express human
cognitive representations. We demonstrate the utility of our approach by
showing that it can be used to capture human-like representations of shape
regularity, abstract Euclidean geometric concepts, and semantic hierarchies for
natural images.",2024-05-29,"Raja Marjieh, Sreejan Kumar, Declan Campbell, Liyi Zhang, Gianluca Bencomo, Jake Snell, Thomas L. Griffiths",http://arxiv.org/pdf/2405.19420v3,cs.LG
Safety through Permissibility: Shield Construction for Fast and Safe Reinforcement Learning,"Designing Reinforcement Learning (RL) solutions for real-life problems
remains a significant challenge. A major area of concern is safety. ""Shielding""
is a popular technique to enforce safety in RL by turning user-defined safety
specifications into safe agent behavior. However, these methods either suffer
from extreme learning delays, demand extensive human effort in designing models
and safe domains in the problem, or require pre-computation. In this paper, we
propose a new permissibility-based framework to deal with safety and shield
construction. Permissibility was originally designed for eliminating
(non-permissible) actions that will not lead to an optimal solution to improve
RL training efficiency. This paper shows that safety can be naturally
incorporated into this framework, i.e. extending permissibility to include
safety, and thereby we can achieve both safety and improved efficiency.
Experimental evaluation using three standard RL applications shows the
effectiveness of the approach.",2024-05-29,"Alexander Politowicz, Sahisnu Mazumder, Bing Liu",http://arxiv.org/pdf/2405.19414v1,cs.LG
Ground state phases of the two-dimension electron gas with a unified variational approach,"The two-dimensional electron gas (2DEG) is a fundamental model, which is
drawing increasing interest because of recent advances in experimental and
theoretical studies of 2D materials. Current understanding of the ground state
of the 2DEG relies on quantum Monte Carlo calculations, based on variational
comparisons of different ansatze for different phases. We use a single
variational ansatz, a general backflow-type wave function using a
message-passing neural quantum state architecture, for a unified description
across the entire density range. The variational optimization consistently
leads to lower ground-state energies than previous best results. Transition
into a Wigner crystal (WC) phase occurs automatically at rs = 37 +/- 1, a
density lower than currently believed. Between the liquid and WC phases, the
same ansatz and variational search strongly suggest the existence of
intermediate states in a broad range of densities, with enhanced short-range
nematic spin correlations.",2024-05-29,"Conor Smith, Yixiao Chen, Ryan Levy, Yubo Yang, Miguel A. Morales, Shiwei Zhang",http://arxiv.org/pdf/2405.19397v1,cs.LG
Neural Scaling Laws From Large-N Field Theory: Solvable Model Beyond the Ridgeless Limit,"Many machine learning models based on neural networks exhibit scaling laws:
their performance scales as power laws with respect to the sizes of the model
and training data set. We use large-N field theory methods to solve a model
recently proposed by Maloney, Roberts and Sully which provides a simplified
setting to study neural scaling laws. Our solution extends the result in this
latter paper to general nonzero values of the ridge parameter, which are
essential to regularize the behavior of the model. In addition to obtaining new
and more precise scaling laws, we also uncover a duality transformation at the
diagrams level which explains the symmetry between model and training data set
sizes. The same duality underlies recent efforts to design neural networks to
simulate quantum field theories.",2024-05-29,Zhengkang Zhang,http://arxiv.org/pdf/2405.19398v1,cs.LG
X-VILA: Cross-Modality Alignment for Large Language Model,"We introduce X-VILA, an omni-modality model designed to extend the
capabilities of large language models (LLMs) by incorporating image, video, and
audio modalities. By aligning modality-specific encoders with LLM inputs and
diffusion decoders with LLM outputs, X-VILA achieves cross-modality
understanding, reasoning, and generation. To facilitate this cross-modality
alignment, we curate an effective interleaved any-to-any modality
instruction-following dataset. Furthermore, we identify a significant problem
with the current cross-modality alignment method, which results in visual
information loss. To address the issue, we propose a visual alignment mechanism
with a visual embedding highway module. We then introduce a resource-efficient
recipe for training X-VILA, that exhibits proficiency in any-to-any modality
conversation, surpassing previous approaches by large margins. X-VILA also
showcases emergent properties across modalities even in the absence of similar
training data. The project will be made open-source.",2024-05-29,"Hanrong Ye, De-An Huang, Yao Lu, Zhiding Yu, Wei Ping, Andrew Tao, Jan Kautz, Song Han, Dan Xu, Pavlo Molchanov, Hongxu Yin",http://arxiv.org/pdf/2405.19335v1,cs.LG
Self-Exploring Language Models: Active Preference Elicitation for Online Alignment,"Preference optimization, particularly through Reinforcement Learning from
Human Feedback (RLHF), has achieved significant success in aligning Large
Language Models (LLMs) to adhere to human intentions. Unlike offline alignment
with a fixed dataset, online feedback collection from humans or AI on model
generations typically leads to more capable reward models and better-aligned
LLMs through an iterative process. However, achieving a globally accurate
reward model requires systematic exploration to generate diverse responses that
span the vast space of natural language. Random sampling from standard
reward-maximizing LLMs alone is insufficient to fulfill this requirement. To
address this issue, we propose a bilevel objective optimistically biased
towards potentially high-reward responses to actively explore
out-of-distribution regions. By solving the inner-level problem with the
reparameterized reward function, the resulting algorithm, named Self-Exploring
Language Models (SELM), eliminates the need for a separate RM and iteratively
updates the LLM with a straightforward objective. Compared to Direct Preference
Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen
extrapolations and enhances exploration efficiency. Our experimental results
demonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct
models, SELM significantly boosts the performance on instruction-following
benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard
academic benchmarks in different settings. Our code and models are available at
https://github.com/shenao-zhang/SELM.",2024-05-29,"Shenao Zhang, Donghan Yu, Hiteshi Sharma, Han Zhong, Zhihan Liu, Ziyi Yang, Shuohang Wang, Hany Hassan, Zhaoran Wang",http://arxiv.org/pdf/2405.19332v3,cs.LG
MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series,"Large Language Models (LLMs) have made great strides in recent years to
achieve unprecedented performance across different tasks. However, due to
commercial interest, the most competitive models like GPT, Gemini, and Claude
have been gated behind proprietary interfaces without disclosing the training
details. Recently, many institutions have open-sourced several strong LLMs like
LLaMA-3, comparable to existing closed-source LLMs. However, only the model's
weights are provided with most details (e.g., intermediate checkpoints,
pre-training corpus, and training code, etc.) being undisclosed. To improve the
transparency of LLMs, the research community has formed to open-source truly
open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training
corpus and training code) are being provided. These models have greatly
advanced the scientific study of these large models including their strengths,
weaknesses, biases and risks. However, we observe that the existing truly open
LLMs on reasoning, knowledge, and coding tasks are still inferior to existing
state-of-the-art LLMs with similar model sizes. To this end, we open-source
MAP-Neo, a highly capable and transparent bilingual language model with 7B
parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the
first fully open-sourced bilingual LLM with comparable performance compared to
existing state-of-the-art LLMs. Moreover, we open-source all details to
reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning
pipeline, checkpoints, and well-optimized training/evaluation framework are
provided. Finally, we hope our MAP-Neo will enhance and strengthen the open
research community and inspire more innovations and creativities to facilitate
the further improvements of LLMs.",2024-05-29,"Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, Noah Wang, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, Zenith Wang, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen",http://arxiv.org/pdf/2405.19327v4,cs.LG
Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys,"Can large language models (LLMs) simulate social surveys? To answer this
question, we conducted millions of simulations in which LLMs were asked to
answer subjective questions. A comparison of different LLM responses with the
European Social Survey (ESS) data suggests that the effect of prompts on bias
and variability is fundamental, highlighting major cultural, age, and gender
biases. We further discussed statistical methods for measuring the difference
between LLM answers and survey data and proposed a novel measure inspired by
Jaccard similarity, as LLM-generated responses are likely to have a smaller
variance. Our experiments also reveal that it is important to analyze the
robustness and variability of prompts before using LLMs to simulate social
surveys, as their imitation abilities are approximate at best.",2024-05-29,"Mingmeng Geng, Sihong He, Roberto Trotta",http://arxiv.org/pdf/2405.19323v2,cs.LG
Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF,"Reinforcement learning from human feedback (RLHF) has demonstrated great
promise in aligning large language models (LLMs) with human preference.
Depending on the availability of preference data, both online and offline RLHF
are active areas of investigation. A key bottleneck is understanding how to
incorporate uncertainty estimation in the reward function learned from the
preference data for RLHF, regardless of how the preference data is collected.
While the principles of optimism or pessimism under uncertainty are
well-established in standard reinforcement learning (RL), a
practically-implementable and theoretically-grounded form amenable to large
language models is not yet available, as standard techniques for constructing
confidence intervals become intractable under arbitrary policy
parameterizations.
  In this paper, we introduce a unified approach to online and offline RLHF --
value-incentivized preference optimization (VPO) -- which regularizes the
maximum-likelihood estimate of the reward function with the corresponding value
function, modulated by a $\textit{sign}$ to indicate whether the optimism or
pessimism is chosen. VPO also directly optimizes the policy with implicit
reward modeling, and therefore shares a simpler RLHF pipeline similar to direct
preference optimization. Theoretical guarantees of VPO are provided for both
online and offline settings, matching the rates of their standard RL
counterparts. Moreover, experiments on text summarization and dialog verify the
practicality and effectiveness of VPO.",2024-05-29,"Shicong Cen, Jincheng Mei, Katayoon Goshvadi, Hanjun Dai, Tong Yang, Sherry Yang, Dale Schuurmans, Yuejie Chi, Bo Dai",http://arxiv.org/pdf/2405.19320v4,cs.LG
Interdisciplinary Expertise to Advance Equitable Explainable AI,"The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.",2024-05-29,"Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles",http://arxiv.org/pdf/2406.18563v1,cs.LG
Generalized Neyman Allocation for Locally Minimax Optimal Best-Arm Identification,"This study investigates an asymptotically locally minimax optimal algorithm
for fixed-budget best-arm identification (BAI). We propose the Generalized
Neyman Allocation (GNA) algorithm and demonstrate that its worst-case upper
bound on the probability of misidentifying the best arm aligns with the
worst-case lower bound under the small-gap regime, where the gap between the
expected outcomes of the best and suboptimal arms is small. Our lower and upper
bounds are tight, matching exactly including constant terms within the
small-gap regime. The GNA algorithm generalizes the Neyman allocation for
two-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and refines existing
BAI algorithms, such as those proposed by Glynn & Juneja (2004). By proposing
an asymptotically minimax optimal algorithm, we address the longstanding open
issue in BAI (Kaufmann, 2020) and treatment choice (Kasy & Sautmann, 202) by
restricting a class of distributions to the small-gap regimes.",2024-05-29,Masahiro Kato,http://arxiv.org/pdf/2405.19317v4,cs.LG
Robust Preference Optimization through Reward Model Distillation,"Language model (LM) post-training (or alignment) involves maximizing a reward
function that is derived from preference annotations. Direct Preference
Optimization (DPO) is a popular offline alignment method that trains a policy
directly on preference data without the need to train a reward model or apply
reinforcement learning. However, the empirical evidence suggests that DPO
typically assigns implicit rewards that overfit, and trend towards infinite
magnitude. This frequently leads to degenerate policies, sometimes causing even
the probabilities of the preferred generations to go to zero. In this work, we
analyze this phenomenon and use distillation to get a better proxy for the true
preference distribution over generation pairs: we train the LM such that its
induced implicit reward, i.e., the scaled log-likelihood ratio of the model to
the reference model, matches an explicit reward model trained on the preference
data. Moreover, to account for uncertainty in the reward model we are
distilling from, we optimize against a family of reward models that, as a
whole, is likely to include at least one reasonable proxy for the preference
distribution. Our results show that distilling from such a family of reward
models leads to improved robustness to distribution shift in preference
annotations, while preserving the simple supervised nature of DPO.",2024-05-29,"Adam Fisch, Jacob Eisenstein, Vicky Zayats, Alekh Agarwal, Ahmad Beirami, Chirag Nagpal, Pete Shaw, Jonathan Berant",http://arxiv.org/pdf/2405.19316v2,cs.LG
Matryoshka Query Transformer for Large Vision-Language Models,"Large Vision-Language Models (LVLMs) typically encode an image into a fixed
number of visual tokens (e.g., 576) and process these tokens with a language
model. Despite their strong performance, LVLMs face challenges in adapting to
varying computational constraints. This raises the question: can we achieve
flexibility in the number of visual tokens to suit different tasks and
computational resources? We answer this with an emphatic yes. Inspired by
Matryoshka Representation Learning, we introduce the Matryoshka Query
Transformer (MQT), capable of encoding an image into m visual tokens during
inference, where m can be any number up to a predefined maximum. This is
achieved by employing a query transformer with M latent query tokens to
compress the visual embeddings. During each training step, we randomly select m
<= M latent query tokens and train the model using only these first m tokens,
discarding the rest. Combining MQT with LLaVA, we train a single model once,
and flexibly and drastically reduce the number of inference-time visual tokens
while maintaining similar or better performance compared to training
independent models for each number of tokens. Our model, MQT-LLAVA, matches
LLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens
instead of LLaVA's fixed 576. Reducing to 16 tokens (8x less TFLOPs) only
sacrifices the performance by 2.4 points on MMBench. On certain tasks such as
ScienceQA and MMMU, we can even go down to only 2 visual tokens with
performance drops of just 3% and 6% each. Our exploration of the trade-off
between the accuracy and computational cost brought about by the number of
visual tokens facilitates future research to achieve the best of both worlds.",2024-05-29,"Wenbo Hu, Zi-Yi Dou, Liunian Harold Li, Amita Kamath, Nanyun Peng, Kai-Wei Chang",http://arxiv.org/pdf/2405.19315v2,cs.LG
Measuring and Mitigating Bias for Tabular Datasets with Multiple Protected Attributes,"Motivated by the recital (67) of the current corrigendum of the AI Act in the
European Union, we propose and present measures and mitigation strategies for
discrimination in tabular datasets. We specifically focus on datasets that
contain multiple protected attributes, such as nationality, age, and sex. This
makes measuring and mitigating bias more challenging, as many existing methods
are designed for a single protected attribute. This paper comes with a twofold
contribution: Firstly, new discrimination measures are introduced. These
measures are categorized in our framework along with existing ones, guiding
researchers and practitioners in choosing the right measure to assess the
fairness of the underlying dataset. Secondly, a novel application of an
existing bias mitigation method, FairDo, is presented. We show that this
strategy can mitigate any type of discrimination, including intersectional
discrimination, by transforming the dataset. By conducting experiments on
real-world datasets (Adult, Bank, COMPAS), we demonstrate that de-biasing
datasets with multiple protected attributes is possible. All transformed
datasets show a reduction in discrimination, on average by 28%. Further, these
datasets do not compromise any of the tested machine learning models'
performances significantly compared to the original datasets. Conclusively,
this study demonstrates the effectiveness of the mitigation strategy used and
contributes to the ongoing discussion on the implementation of the European
Union's AI Act.",2024-05-29,"Manh Khoi Duong, Stefan Conrad",http://arxiv.org/pdf/2405.19300v3,cs.LG
Neural Isometries: Taming Transformations for Equivariant ML,"Real-world geometry and 3D vision tasks are replete with challenging
symmetries that defy tractable analytical expression. In this paper, we
introduce Neural Isometries, an autoencoder framework which learns to map the
observation space to a general-purpose latent space wherein encodings are
related by isometries whenever their corresponding observations are
geometrically related in world space. Specifically, we regularize the latent
space such that maps between encodings preserve a learned inner product and
commute with a learned functional operator, in the same manner as rigid-body
transformations commute with the Laplacian. This approach forms an effective
backbone for self-supervised representation learning, and we demonstrate that a
simple off-the-shelf equivariant network operating in the pre-trained latent
space can achieve results on par with meticulously-engineered, handcrafted
networks designed to handle complex, nonlinear symmetries. Furthermore,
isometric maps capture information about the respective transformations in
world space, and we show that this allows us to regress camera poses directly
from the coefficients of the maps between encodings of adjacent views of a
scene.",2024-05-29,"Thomas W. Mitchel, Michael Taylor, Vincent Sitzmann",http://arxiv.org/pdf/2405.19296v2,cs.LG
Understanding and Minimising Outlier Features in Neural Network Training,"Outlier Features (OFs) are neurons whose activation magnitudes significantly
exceed the average over a neural network's (NN) width. They are well known to
emerge during standard transformer training and have the undesirable effect of
hindering quantisation in afflicted models. Despite their practical importance,
little is known behind why OFs emerge during training, nor how one can minimise
them.
  Our work focuses on the above questions, first identifying several
quantitative metrics, such as the kurtosis over neuron activation norms, to
measure OFs. With these metrics, we study how architectural and optimisation
choices influence OFs, and provide practical insights to minimise OFs during
training. As highlights, we introduce a novel unnormalised transformer block,
the Outlier Protected block, and present a previously unknown benefit of
non-diagonal preconditioning optimisers, finding both approaches to
significantly reduce OFs and improve quantisation without compromising
convergence speed, at scales of up to 7B parameters. Notably, our combination
of OP block and non-diagonal preconditioner (SOAP) achieves 14.87 int8
weight-and-activation perplexity (from 14.71 in standard precision), compared
to 63.4 int8 perplexity (from 16.00) with a default OF-prone combination of
Pre-Norm model and Adam, when quantising OPT-125m models post-training.
Overall, our findings shed new light on our understanding of, our ability to
prevent, and the complexity of this important aspect of NN training dynamics.",2024-05-29,"Bobby He, Lorenzo Noci, Daniele Paliotta, Imanol Schlag, Thomas Hofmann",http://arxiv.org/pdf/2405.19279v2,cs.LG
Deep Latent Variable Modeling of Physiological Signals,"A deep latent variable model is a powerful method for capturing complex
distributions. These models assume that underlying structures, but unobserved,
are present within the data. In this dissertation, we explore high-dimensional
problems related to physiological monitoring using latent variable models.
First, we present a novel deep state-space model to generate electrical
waveforms of the heart using optically obtained signals as inputs. This can
bring about clinical diagnoses of heart disease via simple assessment through
wearable devices. Second, we present a brain signal modeling scheme that
combines the strengths of probabilistic graphical models and deep adversarial
learning. The structured representations can provide interpretability and
encode inductive biases to reduce the data complexity of neural oscillations.
The efficacy of the learned representations is further studied in epilepsy
seizure detection formulated as an unsupervised learning problem. Third, we
propose a framework for the joint modeling of physiological measures and
behavior. Existing methods to combine multiple sources of brain data provided
are limited. Direct analysis of the relationship between different types of
physiological measures usually does not involve behavioral data. Our method can
identify the unique and shared contributions of brain regions to behavior and
can be used to discover new functions of brain regions. The success of these
innovative computational methods would allow the translation of biomarker
findings across species and provide insight into neurocognitive analysis in
numerous biological studies and clinical diagnoses, as well as emerging
consumer applications.",2024-05-29,Khuong Vo,http://arxiv.org/pdf/2405.19277v3,cs.LG
A Recipe for Charge Density Prediction,"In density functional theory, charge density is the core attribute of atomic
systems from which all chemical properties can be derived. Machine learning
methods are promising in significantly accelerating charge density prediction,
yet existing approaches either lack accuracy or scalability. We propose a
recipe that can achieve both. In particular, we identify three key ingredients:
(1) representing the charge density with atomic and virtual orbitals (spherical
fields centered at atom/virtual coordinates); (2) using expressive and
learnable orbital basis sets (basis function for the spherical fields); and (3)
using high-capacity equivariant neural network architecture. Our method
achieves state-of-the-art accuracy while being more than an order of magnitude
faster than existing methods. Furthermore, our method enables flexible
efficiency-accuracy trade-offs by adjusting the model/basis sizes.",2024-05-29,"Xiang Fu, Andrew Rosen, Kyle Bystrom, Rui Wang, Albert Musaelian, Boris Kozinsky, Tess Smidt, Tommi Jaakkola",http://arxiv.org/pdf/2405.19276v1,cs.LG
Differentially Private Clustered Federated Learning,"Federated learning (FL), which is a decentralized machine learning (ML)
approach, often incorporates differential privacy (DP) to provide rigorous data
privacy guarantees. Previous works attempted to address high structured data
heterogeneity in vanilla FL settings through clustering clients (a.k.a
clustered FL), but these methods remain sensitive and prone to errors, further
exacerbated by the DP noise. This vulnerability makes the previous methods
inappropriate for differentially private FL (DPFL) settings with structured
data heterogeneity. To address this gap, we propose an algorithm for
differentially private clustered FL, which is robust to the DP noise in the
system and identifies the underlying clients' clusters correctly. To this end,
we propose to cluster clients based on both their model updates and training
loss values. Furthermore, for clustering clients' model updates at the end of
the first round, our proposed approach addresses the server's uncertainties by
employing large batch sizes as well as Gaussian Mixture Models (GMM) to reduce
the impact of DP and stochastic noise and avoid potential clustering errors.
This idea is efficient especially in privacy-sensitive scenarios with more DP
noise. We provide theoretical analysis to justify our approach and evaluate it
across diverse data distributions and privacy budgets. Our experimental results
show its effectiveness in addressing large structured data heterogeneity in
DPFL.",2024-05-29,"Saber Malekmohammadi, Afaf Taik, Golnoosh Farnadi",http://arxiv.org/pdf/2405.19272v6,cs.LG
Rich-Observation Reinforcement Learning with Continuous Latent Dynamics,"Sample-efficiency and reliability remain major bottlenecks toward wide
adoption of reinforcement learning algorithms in continuous settings with
high-dimensional perceptual inputs. Toward addressing these challenges, we
introduce a new theoretical framework, RichCLD (Rich-Observation RL with
Continuous Latent Dynamics), in which the agent performs control based on
high-dimensional observations, but the environment is governed by
low-dimensional latent states and Lipschitz continuous dynamics. Our main
contribution is a new algorithm for this setting that is provably statistically
and computationally efficient. The core of our algorithm is a new
representation learning objective; we show that prior representation learning
schemes tailored to discrete dynamics do not naturally extend to the continuous
setting. Our new objective is amenable to practical implementation, and
empirically, we find that it compares favorably to prior schemes in a standard
evaluation protocol. We further provide several insights into the statistical
complexity of the RichCLD framework, in particular proving that certain notions
of Lipschitzness that admit sample-efficient learning in the absence of rich
observations are insufficient in the rich-observation setting.",2024-05-29,"Yuda Song, Lili Wu, Dylan J. Foster, Akshay Krishnamurthy",http://arxiv.org/pdf/2405.19269v1,cs.LG
Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models,"Large language models are usually fine-tuned to align with human preferences.
However, fine-tuning a large language model can be challenging. In this work,
we introduce $\textit{weak-to-strong search}$, framing the alignment of a large
language model as a test-time greedy search to maximize the log-probability
difference between small tuned and untuned models while sampling from the
frozen large model. This method serves both as (1) a compute-efficient model
up-scaling strategy that avoids directly tuning the large model and as (2) an
instance of weak-to-strong generalization that enhances a strong model with
weak test-time guidance. Empirically, we demonstrate the flexibility of
weak-to-strong search across different tasks. In controlled-sentiment
generation and summarization, we use tuned and untuned $\texttt{gpt2}$s to
improve the alignment of large models without additional training. Crucially,
in a more difficult instruction-following benchmark, AlpacaEval 2.0, we show
that reusing off-the-shelf small models (e.g., $\texttt{zephyr-7b-beta}$ and
its untuned version) can improve the length-controlled win rates of both
white-box and black-box large models against $\texttt{gpt-4-turbo}$ (e.g.,
$34.4\% \rightarrow 37.9\%$ for $\texttt{Llama-3-70B-Instruct}$ and $16.0\%
\rightarrow 20.1\%$ for $\texttt{gpt-3.5-turbo-instruct}$), despite the small
models' low win rates $\approx 10.0\%$.",2024-05-29,"Zhanhui Zhou, Zhixuan Liu, Jie Liu, Zhichen Dong, Chao Yang, Yu Qiao",http://arxiv.org/pdf/2405.19262v3,cs.LG
Faster Cascades via Speculative Decoding,"Cascades and speculative decoding are two common approaches to improving
language models' inference efficiency. Both approaches involve interleaving
models of different sizes, but via fundamentally distinct mechanisms: cascades
employ a deferral rule that invokes the larger model only for ""hard"" inputs,
while speculative decoding uses speculative execution to primarily invoke the
larger model in parallel verification mode. These mechanisms offer different
benefits: empirically, cascades offer better cost-quality trade-offs, often
even outperforming the large model, while theoretically, speculative decoding
offers a guarantee of quality-neutrality. In this paper, we leverage the best
of both these approaches by designing new speculative cascading techniques that
implement their deferral rule through speculative execution. We characterize
the optimal deferral rule for our speculative cascades, and employ a plug-in
approximation to the optimal rule. Experiments with Gemma and T5 models on a
range of language benchmarks show that our approach yields better cost quality
trade-offs than cascading and speculative decoding baselines.",2024-05-29,"Harikrishna Narasimhan, Wittawat Jitkrittum, Ankit Singh Rawat, Seungyeon Kim, Neha Gupta, Aditya Krishna Menon, Sanjiv Kumar",http://arxiv.org/pdf/2405.19261v2,cs.LG
Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation,"Sampling invariant distributions from an Ito diffusion process presents a
significant challenge in stochastic simulation. Traditional numerical solvers
for stochastic differential equations require both a fine step size and a
lengthy simulation period, resulting in both biased and correlated samples.
Current deep learning-based method solves the stationary Fokker--Planck
equation to determine the invariant probability density function in form of
deep neural networks, but they generally do not directly address the problem of
sampling from the computed density function. In this work, we introduce a
framework that employs a weak generative sampler (WGS) to directly generate
independent and identically distributed (iid) samples induced by a
transformation map derived from the stationary Fokker--Planck equation. Our
proposed loss function is based on the weak form of the Fokker--Planck
equation, integrating normalizing flows to characterize the invariant
distribution and facilitate sample generation from the base distribution. Our
randomized test function circumvents the need for mini-max optimization in the
traditional weak formulation. Distinct from conventional generative models, our
method neither necessitates the computationally intensive calculation of the
Jacobian determinant nor the invertibility of the transformation map. A crucial
component of our framework is the adaptively chosen family of test functions in
the form of Gaussian kernel functions with centres selected from the generated
data samples. Experimental results on several benchmark examples demonstrate
the effectiveness of our method, which offers both low computational costs and
excellent capability in exploring multiple metastable states.",2024-05-29,"Zhiqiang Cai, Yu Cao, Yuanfei Huang, Xiang Zhou",http://arxiv.org/pdf/2405.19256v1,cs.LG
Comparative Study of Neighbor-based Methods for Local Outlier Detection,"The neighbor-based method has become a powerful tool to handle the outlier
detection problem, which aims to infer the abnormal degree of the sample based
on the compactness of the sample and its neighbors. However, the existing
methods commonly focus on designing different processes to locate outliers in
the dataset, while the contributions of different types neighbors to outlier
detection has not been well discussed. To this end, this paper studies the
neighbor in the existing outlier detection algorithms and a taxonomy is
introduced, which uses the three-level components of information, neighbor and
methodology to define hybrid methods. This taxonomy can serve as a paradigm
where a novel neighbor-based outlier detection method can be proposed by
combining different components in this taxonomy. A large number of comparative
experiments were conducted on synthetic and real-world datasets in terms of
performance comparison and case study, and the results show that reverse
K-nearest neighbor based methods achieve promising performance and dynamic
selection method is suitable for working in high-dimensional space. Notably, it
is verified that rationally selecting components from this taxonomy may create
an algorithms superior to existing methods.",2024-05-29,"Zhuang Qi, Junlin Zhang, Xiaming Chen, Xin Qi",http://arxiv.org/pdf/2405.19247v1,cs.LG
ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning,"While large-scale text-to-image diffusion models have demonstrated impressive
image-generation capabilities, there are significant concerns about their
potential misuse for generating unsafe content, violating copyright, and
perpetuating societal biases. Recently, the text-to-image generation community
has begun addressing these concerns by editing or unlearning undesired concepts
from pre-trained models. However, these methods often involve data-intensive
and inefficient fine-tuning or utilize various forms of token remapping,
rendering them susceptible to adversarial jailbreaks. In this paper, we present
a simple and effective training-free approach, ConceptPrune, wherein we first
identify critical regions within pre-trained models responsible for generating
undesirable concepts, thereby facilitating straightforward concept unlearning
via weight pruning. Experiments across a range of concepts including artistic
styles, nudity, object erasure, and gender debiasing demonstrate that target
concepts can be efficiently erased by pruning a tiny fraction, approximately
0.12% of total weights, enabling multi-concept erasure and robustness against
various white-box and black-box adversarial attacks.",2024-05-29,"Ruchika Chavhan, Da Li, Timothy Hospedales",http://arxiv.org/pdf/2405.19237v1,cs.LG
Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach,"In transportation networks, intersections pose significant risks of
collisions due to conflicting movements of vehicles approaching from different
directions. To address this issue, various tools can exert influence on traffic
safety both directly and indirectly. This study focuses on investigating the
impact of adaptive signal control and connected and automated vehicles (CAVs)
on intersection safety using a deep reinforcement learning approach. The
objective is to assess the individual and combined effects of CAVs and adaptive
traffic signal control on traffic safety, considering rear-end and crossing
conflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals
and driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses
Time To Collision (TTC) metric to evaluate safety. The findings demonstrate a
significant reduction in rear-end and crossing conflicts through the combined
implementation of CAVs and DQNs-based traffic signal control. Additionally, the
long-term positive effects of CAVs on safety are similar to the short-term
effects of combined CAVs and DQNs-based traffic signal control. Overall, the
study emphasizes the potential benefits of integrating CAVs and adaptive
traffic signal control approaches in order to enhance traffic safety. The
findings of this study could provide valuable insights for city officials and
transportation authorities in developing effective strategies to improve safety
at signalized intersections.",2024-05-29,"Amir Hossein Karbasi, Hao Yang, Saiedeh Razavi",http://arxiv.org/pdf/2405.19236v1,cs.LG
Forward-Backward Knowledge Distillation for Continual Clustering,"Unsupervised Continual Learning (UCL) is a burgeoning field in machine
learning, focusing on enabling neural networks to sequentially learn tasks
without explicit label information. Catastrophic Forgetting (CF), where models
forget previously learned tasks upon learning new ones, poses a significant
challenge in continual learning, especially in UCL, where labeled information
of data is not accessible. CF mitigation strategies, such as knowledge
distillation and replay buffers, often face memory inefficiency and privacy
issues. Although current research in UCL has endeavored to refine data
representations and address CF in streaming data contexts, there is a
noticeable lack of algorithms specifically designed for unsupervised
clustering. To fill this gap, in this paper, we introduce the concept of
Unsupervised Continual Clustering (UCC). We propose Forward-Backward Knowledge
Distillation for unsupervised Continual Clustering (FBCC) to counteract CF
within the context of UCC. FBCC employs a single continual learner (the
``teacher'') with a cluster projector, along with multiple student models, to
address the CF issue. The proposed method consists of two phases: Forward
Knowledge Distillation, where the teacher learns new clusters while retaining
knowledge from previous tasks with guidance from specialized student models,
and Backward Knowledge Distillation, where a student model mimics the teacher's
behavior to retain task-specific knowledge, aiding the teacher in subsequent
tasks. FBCC marks a pioneering approach to UCC, demonstrating enhanced
performance and memory efficiency in clustering across various tasks,
outperforming the application of clustering algorithms to the latent space of
state-of-the-art UCL algorithms.",2024-05-29,"Mohammadreza Sadeghi, Zihan Wang, Narges Armanfard",http://arxiv.org/pdf/2405.19234v1,cs.LG
Valid Conformal Prediction for Dynamic GNNs,"Dynamic graphs provide a flexible data abstraction for modelling many sorts
of real-world systems, such as transport, trade, and social networks. Graph
neural networks (GNNs) are powerful tools allowing for different kinds of
prediction and inference on these systems, but getting a handle on uncertainty,
especially in dynamic settings, is a challenging problem. In this work we
propose to use a dynamic graph representation known in the tensor literature as
the unfolding, to achieve valid prediction sets via conformal prediction. This
representation, a simple graph, can be input to any standard GNN and does not
require any modification to existing GNN architectures or conformal prediction
routines. One of our key contributions is a careful mathematical consideration
of the different inference scenarios which can arise in a dynamic graph
modelling context. For a range of practically relevant cases, we obtain valid
prediction sets with almost no assumptions, even dispensing with
exchangeability. In a more challenging scenario, which we call the
semi-inductive regime, we achieve valid prediction under stronger assumptions,
akin to stationarity. We provide real data examples demonstrating validity,
showing improved accuracy over baselines, and sign-posting different failure
modes which can occur when those assumptions are violated.",2024-05-29,"Ed Davis, Ian Gallagher, Daniel John Lawson, Patrick Rubin-Delanchy",http://arxiv.org/pdf/2405.19230v2,cs.LG
Synthetic Potential Outcomes and Causal Mixture Identifiability,"Heterogeneous data from multiple populations, sub-groups, or sources is often
represented as a ``mixture model'' with a single latent class influencing all
of the observed covariates. Heterogeneity can be resolved at multiple levels by
grouping populations according to different notions of similarity. This paper
proposes grouping with respect to the causal response of an intervention or
perturbation on the system. This definition is distinct from previous notions,
such as similar covariate values (e.g. clustering) or similar correlations
between covariates (e.g. Gaussian mixture models). To solve the problem, we
``synthetically sample'' from a counterfactual distribution using higher-order
multi-linear moments of the observable data. To understand how these ``causal
mixtures'' fit in with more classical notions, we develop a hierarchy of
mixture identifiability.",2024-05-29,"Bijan Mazaheri, Chandler Squires, Caroline Uhler",http://arxiv.org/pdf/2405.19225v4,cs.LG
Domain adaptation in small-scale and heterogeneous biological datasets,"Machine learning techniques are steadily becoming more important in modern
biology, and are used to build predictive models, discover patterns, and
investigate biological problems. However, models trained on one dataset are
often not generalizable to other datasets from different cohorts or
laboratories, due to differences in the statistical properties of these
datasets. These could stem from technical differences, such as the measurement
technique used, or from relevant biological differences between the populations
studied. Domain adaptation, a type of transfer learning, can alleviate this
problem by aligning the statistical distributions of features and samples among
different datasets so that similar models can be applied across them. However,
a majority of state-of-the-art domain adaptation methods are designed to work
with large-scale data, mostly text and images, while biological datasets often
suffer from small sample sizes, and possess complexities such as heterogeneity
of the feature space. This Review aims to synthetically discuss domain
adaptation methods in the context of small-scale and highly heterogeneous
biological data. We describe the benefits and challenges of domain adaptation
in biological research and critically discuss some of its objectives,
strengths, and weaknesses through key representative methodologies. We argue
for the incorporation of domain adaptation techniques to the computational
biologist's toolkit, with further development of customized approaches.",2024-05-29,"Seyedmehdi Orouji, Martin C. Liu, Tal Korem, Megan A. K. Peters",http://arxiv.org/pdf/2405.19221v1,cs.LG
LoByITFL: Low Communication Secure and Private Federated Learning,"Federated Learning (FL) faces several challenges, such as the privacy of the
clients data and security against Byzantine clients. Existing works treating
privacy and security jointly make sacrifices on the privacy guarantee. In this
work, we introduce LoByITFL, the first communication-efficient
Information-Theoretic (IT) private and secure FL scheme that makes no
sacrifices on the privacy guarantees while ensuring security against Byzantine
adversaries. The key ingredients are a small and representative dataset
available to the federator, a careful transformation of the FLTrust algorithm
and the use of a trusted third party only in a one-time preprocessing phase
before the start of the learning algorithm. We provide theoretical guarantees
on privacy and Byzantine-resilience, and provide convergence guarantee and
experimental results validating our theoretical findings.",2024-05-29,"Yue Xia, Christoph Hofmeister, Maximilian Egger, Rawad Bitar",http://arxiv.org/pdf/2405.19217v1,cs.LG
EdgeSight: Enabling Modeless and Cost-Efficient Inference at the Edge,"Traditional ML inference is evolving toward modeless inference, which
abstracts the complexity of model selection from users, allowing the system to
automatically choose the most appropriate model for each request based on
accuracy and resource requirements. While prior studies have focused on
modeless inference within data centers, this paper tackles the pressing need
for cost-efficient modeless inference at the edge -- particularly within its
unique constraints of limited device memory, volatile network conditions, and
restricted power consumption.
  To overcome these challenges, we propose EdgeSight, a system that provides
cost-efficient EdgeSight serving for diverse DNNs at the edge. EdgeSight
employs an edge-data center (edge-DC) architecture, utilizing confidence
scaling to reduce the number of model options while meeting diverse accuracy
requirements. Additionally, it supports lossy inference in volatile network
environments. Our experimental results show that EdgeSight outperforms existing
systems by up to 1.6x in P99 latency for modeless services. Furthermore, our
FPGA prototype demonstrates similar performance at certain accuracy levels,
with a power consumption reduction of up to 3.34x.",2024-05-29,"ChonLam Lao, Jiaqi Gao, Ganesh Ananthanarayanan, Aditya Akella, Minlan Yu",http://arxiv.org/pdf/2405.19213v2,cs.LG
Partial Information Decomposition for Data Interpretability and Feature Selection,"In this paper, we introduce Partial Information Decomposition of Features
(PIDF), a new paradigm for simultaneous data interpretability and feature
selection. Contrary to traditional methods that assign a single importance
value, our approach is based on three metrics per feature: the mutual
information shared with the target variable, the feature's contribution to
synergistic information, and the amount of this information that is redundant.
In particular, we develop a novel procedure based on these three metrics, which
reveals not only how features are correlated with the target but also the
additional and overlapping information provided by considering them in
combination with other features. We extensively evaluate PIDF using both
synthetic and real-world data, demonstrating its potential applications and
effectiveness, by considering case studies from genetics and neuroscience.",2024-05-29,"Charles Westphal, Stephen Hailes, Mirco Musolesi",http://arxiv.org/pdf/2405.19212v3,cs.LG
Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning,"Machine learning models are vulnerable to adversarial attacks, including
attacks that leak information about the model's training data. There has
recently been an increase in interest about how to best address privacy
concerns, especially in the presence of data-removal requests. Machine
unlearning algorithms aim to efficiently update trained models to comply with
data deletion requests while maintaining performance and without having to
resort to retraining the model from scratch, a costly endeavor. Several
algorithms in the machine unlearning literature demonstrate some level of
privacy gains, but they are often evaluated only on rudimentary membership
inference attacks, which do not represent realistic threats. In this paper we
describe and propose alternative evaluation methods for three key shortcomings
in the current evaluation of unlearning algorithms. We show the utility of our
alternative evaluations via a series of experiments of state-of-the-art
unlearning algorithms on different computer vision datasets, presenting a more
detailed picture of the state of the field.",2024-05-29,"Keltin Grimes, Collin Abidi, Cole Frank, Shannon Gallagher",http://arxiv.org/pdf/2405.19211v1,cs.LG
Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes,"Ensuring high-quality data is paramount for maximizing the performance of
machine learning models and business intelligence systems. However, challenges
in data quality, including noise in data capture, missing records, limited data
production, and confounding variables, significantly constrain the potential
performance of these systems. In this study, we propose an
architecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to
address these challenges. GGH analyses gradients from hypotheses as a proxy of
distinct and possibly contradictory patterns in the data. This framework
entails an additional step in machine learning training, where gradients can be
included or excluded from backpropagation. In this manner, missing and noisy
data are addressed through a unified solution that perceives both challenges as
facets of the same overarching issue: the propagation of erroneous information.
Experimental validation of GGH is conducted using real-world open-source
datasets, where records with missing rates of up to 98.5% are simulated.
Comparative analysis with state-of-the-art imputation methods demonstrates a
substantial improvement in model performance achieved by GGH. Specifically in
very high scarcity regimes, GGH was found to be the only viable solution.
Additionally, GGH's noise detection capabilities are showcased by introducing
simulated noise into the datasets and observing enhanced model performance
after filtering out the noisy data. This study presents GGH as a promising
solution for improving data quality and model performance in various
applications.",2024-05-29,"Paulo Neves, Joerg K. Wegner, Philippe Schwaller",http://arxiv.org/pdf/2405.19210v1,cs.LG
Matrix Manifold Neural Networks++,"Deep neural networks (DNNs) on Riemannian manifolds have garnered increasing
interest in various applied areas. For instance, DNNs on spherical and
hyperbolic manifolds have been designed to solve a wide range of computer
vision and nature language processing tasks. One of the key factors that
contribute to the success of these networks is that spherical and hyperbolic
manifolds have the rich algebraic structures of gyrogroups and gyrovector
spaces. This enables principled and effective generalizations of the most
successful DNNs to these manifolds. Recently, some works have shown that many
concepts in the theory of gyrogroups and gyrovector spaces can also be
generalized to matrix manifolds such as Symmetric Positive Definite (SPD) and
Grassmann manifolds. As a result, some building blocks for SPD and Grassmann
neural networks, e.g., isometric models and multinomial logistic regression
(MLR) can be derived in a way that is fully analogous to their spherical and
hyperbolic counterparts. Building upon these works, we design fully-connected
(FC) and convolutional layers for SPD neural networks. We also develop MLR on
Symmetric Positive Semi-definite (SPSD) manifolds, and propose a method for
performing backpropagation with the Grassmann logarithmic map in the projector
perspective. We demonstrate the effectiveness of the proposed approach in the
human action recognition and node classification tasks.",2024-05-29,"Xuan Son Nguyen, Shuo Yang, Aymeric Histace",http://arxiv.org/pdf/2405.19206v1,cs.LG
Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey,"Traffic incidents involving vulnerable road users (VRUs) constitute a
significant proportion of global road accidents. Advances in traffic
communication ecosystems, coupled with sophisticated signal processing and
machine learning techniques, have facilitated the utilization of data from
diverse sensors. Despite these advancements and the availability of extensive
datasets, substantial progress is required to mitigate traffic casualties. This
paper provides a comprehensive survey of state-of-the-art technologies and
methodologies to enhance the safety of VRUs. The study delves into the
communication networks between vehicles and VRUs, emphasizing the integration
of advanced sensors and the availability of relevant datasets. It explores
preprocessing techniques and data fusion methods to enhance sensor data
quality. Furthermore, our study assesses critical simulation environments
essential for developing and testing VRU safety systems. Our research also
highlights recent advances in VRU detection and classification algorithms,
addressing challenges such as variable environmental conditions. Additionally,
we cover cutting-edge research in predicting VRU intentions and behaviors,
which is crucial for proactive collision avoidance strategies. Through this
survey, we aim to provide a comprehensive understanding of the current
landscape of VRU safety technologies, identifying areas of progress and areas
needing further research and development.",2024-05-29,"Renato M. Silva, Gregório F. Azevedo, Matheus V. V. Berto, Jean R. Rocha, Eduardo C. Fidelis, Matheus V. Nogueira, Pedro H. Lisboa, Tiago A. Almeida",http://arxiv.org/pdf/2405.19202v4,cs.LG
Long-Horizon Rollout via Dynamics Diffusion for Offline Reinforcement Learning,"With the great success of diffusion models (DMs) in generating realistic
synthetic vision data, many researchers have investigated their potential in
decision-making and control. Most of these works utilized DMs to sample
directly from the trajectory space, where DMs can be viewed as a combination of
dynamics models and policies. In this work, we explore how to decouple DMs'
ability as dynamics models in fully offline settings, allowing the learning
policy to roll out trajectories. As DMs learn the data distribution from the
dataset, their intrinsic policy is actually the behavior policy induced from
the dataset, which results in a mismatch between the behavior policy and the
learning policy. We propose Dynamics Diffusion, short as DyDiff, which can
inject information from the learning policy to DMs iteratively. DyDiff ensures
long-horizon rollout accuracy while maintaining policy consistency and can be
easily deployed on model-free algorithms. We provide theoretical analysis to
show the advantage of DMs on long-horizon rollout over models and demonstrate
the effectiveness of DyDiff in the context of offline reinforcement learning,
where the rollout dataset is provided but no online environment for
interaction. Our code is at https://github.com/FineArtz/DyDiff.",2024-05-29,"Hanye Zhao, Xiaoshen Han, Zhengbang Zhu, Minghuan Liu, Yong Yu, Weinan Zhang",http://arxiv.org/pdf/2405.19189v2,cs.LG
MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification,"Large Vision Language Models (LVLMs) have shown remarkable capabilities in
multimodal tasks like visual question answering or image captioning. However,
inconsistencies between the visual information and the generated text, a
phenomenon referred to as hallucinations, remain an unsolved problem with
regard to the trustworthiness of LVLMs. To address this problem, recent works
proposed to incorporate computationally costly Large (Vision) Language Models
in order to detect hallucinations on a sentence- or subsentence-level. In this
work, we introduce MetaToken, a lightweight binary classifier to detect
hallucinations on the token-level at negligible cost. Based on a statistical
analysis, we reveal key factors of hallucinations in LVLMs. MetaToken can be
applied to any open-source LVLM without any knowledge about ground truth data
providing a calibrated detection of hallucinations. We evaluate our method on
four state-of-the-art LVLMs demonstrating the effectiveness of our approach.",2024-05-29,"Laura Fieback, Jakob Spiegelberg, Hanno Gottschalk",http://arxiv.org/pdf/2405.19186v2,cs.LG
Model-independent cosmological inference post DESI DR1 BAO measurements,"In this work, we implement Gaussian process regression to reconstruct the
expansion history of the universe in a model-agnostic manner, using the
Pantheon-Plus SN-Ia compilation in combination with two different BAO
measurements (SDSS-IV and DESI DR1). In both the reconstructions, the
$\Lambda$CDM model is always included in the 95\% confidence intervals. We find
evidence that the DESI LRG data at $z_{\text{eff}} = 0.51$ is not an outlier
within our model-independent framework. We study the $\mathcal{O}m$-diagnostics
and the evolution of the total equation of state (EoS) of our universe, which
hint towards the possibility of a quintessence-like dark energy scenario with a
very slowly varying EoS, and a phantom-crossing in higher $z$. The entire
exercise is later complemented by considering two more SN-Ia compilations -
DES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI
BAO + DES-5YR SN data sets predicts that the $\Lambda$CDM model lies outside
the 3$\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the
$\Lambda$CDM model is always included within 1$\sigma$. We also report
constraints on $H_0 r_d$ from our model-agnostic analysis, independent of the
pre-recombination physics. Our results point towards an $\approx$ 2$\sigma$
discrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets,
which calls for further investigation.",2024-05-29,"Purba Mukherjee, Anjan Ananda Sen",http://arxiv.org/pdf/2405.19178v2,cs.LG
Online Linear Regression in Dynamic Environments via Discounting,"We develop algorithms for online linear regression which achieve optimal
static and dynamic regret guarantees \emph{even in the complete absence of
prior knowledge}. We present a novel analysis showing that a discounted variant
of the Vovk-Azoury-Warmuth forecaster achieves dynamic regret of the form
$R_{T}(\vec{u})\le O\left(d\log(T)\vee
\sqrt{dP_{T}^{\gamma}(\vec{u})T}\right)$, where $P_{T}^{\gamma}(\vec{u})$ is a
measure of variability of the comparator sequence, and show that the discount
factor achieving this result can be learned on-the-fly. We show that this
result is optimal by providing a matching lower bound. We also extend our
results to \emph{strongly-adaptive} guarantees which hold over every
sub-interval $[a,b]\subseteq[1,T]$ simultaneously.",2024-05-29,"Andrew Jacobsen, Ashok Cutkosky",http://arxiv.org/pdf/2405.19175v1,cs.LG
cryoSPHERE: Single-particle heterogeneous reconstruction from cryo EM,"The three-dimensional structure of proteins plays a crucial role in
determining their function. Protein structure prediction methods, like
AlphaFold, offer rapid access to a protein structure. However, large protein
complexes cannot be reliably predicted, and proteins are dynamic, making it
important to resolve their full conformational distribution. Single-particle
cryo-electron microscopy (cryo-EM) is a powerful tool for determining the
structures of large protein complexes. Importantly, the numerous images of a
given protein contain underutilized information about conformational
heterogeneity. These images are very noisy projections of the protein, and
traditional methods for cryo-EM reconstruction are limited to recovering only
one or a few consensus conformations. In this paper, we introduce cryoSPHERE,
which is a deep learning method that uses a nominal protein structure (e.g.,
from AlphaFold) as input, learns how to divide it into segments, and moves
these segments as approximately rigid bodies to fit the different conformations
present in the cryo-EM dataset. This approach provides enough constraints to
enable meaningful reconstructions of single protein structural ensembles. We
demonstrate this with two synthetic datasets featuring varying levels of noise,
as well as two real dataset. We show that cryoSPHERE is very resilient to the
high levels of noise typically encountered in experiments, where we see
consistent improvements over the current state-of-the-art for heterogeneous
reconstruction.",2024-05-29,"Gabriel Ducrocq, Lukas Grunewald, Sebastian Westenhoff, Fredrik Lindsten",http://arxiv.org/pdf/2407.01574v2,cs.LG
Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity,"Neural operator learning models have emerged as very effective surrogates in
data-driven methods for partial differential equations (PDEs) across different
applications from computational science and engineering. Such operator learning
models not only predict particular instances of a physical or biological system
in real-time but also forecast classes of solutions corresponding to a
distribution of initial and boundary conditions or forcing terms. % DeepONet is
the first neural operator model and has been tested extensively for a broad
class of solutions, including Riemann problems. Transformers have not been used
in that capacity, and specifically, they have not been tested for solutions of
PDEs with low regularity. %
  In this work, we first establish the theoretical groundwork that transformers
possess the universal approximation property as operator learning models.
  We then apply transformers to forecast solutions of diverse dynamical systems
with solutions of finite regularity for a plurality of initial conditions and
forcing terms. In particular, we consider three examples: the Izhikevich neuron
model, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and
the one-dimensional Euler equation Riemann problem. For the latter problem, we
also compare with variants of DeepONet, and we find that transformers
outperform DeepONet in accuracy but they are computationally more expensive.",2024-05-29,"Benjamin Shih, Ahmad Peyvan, Zhongqiang Zhang, George Em Karniadakis",http://arxiv.org/pdf/2405.19166v1,cs.LG
Does learning the right latent variables necessarily improve in-context learning?,"Large autoregressive models like Transformers can solve tasks through
in-context learning (ICL) without learning new weights, suggesting avenues for
efficiently solving new tasks. For many tasks, e.g., linear regression, the
data factorizes: examples are independent given a task latent that generates
the data, e.g., linear coefficients. While an optimal predictor leverages this
factorization by inferring task latents, it is unclear if Transformers
implicitly do so or if they instead exploit heuristics and statistical
shortcuts enabled by attention layers. Both scenarios have inspired active
ongoing work. In this paper, we systematically investigate the effect of
explicitly inferring task latents. We minimally modify the Transformer
architecture with a bottleneck designed to prevent shortcuts in favor of more
structured solutions, and then compare performance against standard
Transformers across various ICL tasks. Contrary to intuition and some recent
works, we find little discernible difference between the two; biasing towards
task-relevant latent variables does not lead to better out-of-distribution
performance, in general. Curiously, we find that while the bottleneck
effectively learns to extract latent task variables from context, downstream
processing struggles to utilize them for robust prediction. Our study
highlights the intrinsic limitations of Transformers in achieving structured
ICL solutions that generalize, and shows that while inferring the right latents
aids interpretability, it is not sufficient to alleviate this problem.",2024-05-29,"Sarthak Mittal, Eric Elmoznino, Leo Gagnon, Sangnie Bhardwaj, Dhanya Sridhar, Guillaume Lajoie",http://arxiv.org/pdf/2405.19162v1,cs.LG
Beyond Discrepancy: A Closer Look at the Theory of Distribution Shift,"Many machine learning models appear to deploy effortlessly under distribution
shift, and perform well on a target distribution that is considerably different
from the training distribution. Yet, learning theory of distribution shift
bounds performance on the target distribution as a function of the discrepancy
between the source and target, rarely guaranteeing high target accuracy.
Motivated by this gap, this work takes a closer look at the theory of
distribution shift for a classifier from a source to a target distribution.
Instead of relying on the discrepancy, we adopt an Invariant-Risk-Minimization
(IRM)-like assumption connecting the distributions, and characterize conditions
under which data from a source distribution is sufficient for accurate
classification of the target. When these conditions are not met, we show when
only unlabeled data from the target is sufficient, and when labeled target data
is needed. In all cases, we provide rigorous theoretical guarantees in the
large sample regime.",2024-05-29,"Robi Bhattacharjee, Nick Rittler, Kamalika Chaudhuri",http://arxiv.org/pdf/2405.19156v1,cs.LG
A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning,"Continual learning with deep neural networks presents challenges distinct
from both the fixed-dataset and convex continual learning regimes. One such
challenge is plasticity loss, wherein a neural network trained in an online
fashion displays a degraded ability to fit new tasks. This problem has been
extensively studied in both supervised learning and off-policy reinforcement
learning (RL), where a number of remedies have been proposed. Still, plasticity
loss has received less attention in the on-policy deep RL setting. Here we
perform an extensive set of experiments examining plasticity loss and a variety
of mitigation methods in on-policy deep RL. We demonstrate that plasticity loss
is pervasive under domain shift in this regime, and that a number of methods
developed to resolve it in other settings fail, sometimes even performing worse
than applying no intervention at all. In contrast, we find that a class of
``regenerative'' methods are able to consistently mitigate plasticity loss in a
variety of contexts, including in gridworld tasks and more challenging
environments like Montezuma's Revenge and ProcGen.",2024-05-29,"Arthur Juliani, Jordan T. Ash",http://arxiv.org/pdf/2405.19153v2,cs.LG
I Bet You Did Not Mean That: Testing Semantic Importance via Betting,"Recent works have extended notions of feature importance to semantic concepts
that are inherently interpretable to the users interacting with a black-box
predictive model. Yet, precise statistical guarantees, such as false positive
rate and false discovery rate control, are needed to communicate findings
transparently and to avoid unintended consequences in real-world scenarios. In
this paper, we formalize the global (i.e., over a population) and local (i.e.,
for a sample) statistical importance of semantic concepts for the predictions
of opaque models by means of conditional independence, which allows for
rigorous testing. We use recent ideas of sequential kernelized independence
testing (SKIT) to induce a rank of importance across concepts, and showcase the
effectiveness and flexibility of our framework on synthetic datasets as well as
on image classification tasks using several and diverse vision-language models.",2024-05-29,"Jacopo Teneggi, Jeremias Sulam",http://arxiv.org/pdf/2405.19146v2,cs.LG
Spatio-Spectral Graph Neural Networks,"Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for
learning on graph-structured data. However, key limitations of l-step MPGNNs
are that their ""receptive field"" is typically limited to the l-hop neighborhood
of a node and that information exchange between distant nodes is limited by
over-squashing. Motivated by these limitations, we propose Spatio-Spectral
Graph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural
Networks (GNNs) that synergistically combines spatially and spectrally
parametrized graph filters. Parameterizing filters partially in the frequency
domain enables global yet efficient information propagation. We show that
S$^2$GNNs vanquish over-squashing and yield strictly tighter
approximation-theoretic error bounds than MPGNNs. Further, rethinking graph
convolutions at a fundamental level unlocks new design spaces. For example,
S$^2$GNNs allow for free positional encodings that make them strictly more
expressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain
general-purpose S$^2$GNNs, we propose spectrally parametrized filters for
directed graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and
graph rewirings, e.g., on the peptide long-range benchmark tasks, and are
competitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs
scale to millions of nodes.",2024-05-29,"Simon Geisler, Arthur Kosmala, Daniel Herbst, Stephan Günnemann",http://arxiv.org/pdf/2405.19121v2,cs.LG
Can Graph Learning Improve Planning in LLM-based Agents?,"Task planning in language agents is emerging as an important research topic
alongside the development of large language models (LLMs). It aims to break
down complex user requests in natural language into solvable sub-tasks, thereby
fulfilling the original requests. In this context, the sub-tasks can be
naturally viewed as a graph, where the nodes represent the sub-tasks, and the
edges denote the dependencies among them. Consequently, task planning is a
decision-making problem that involves selecting a connected path or subgraph
within the corresponding graph and invoking it. In this paper, we explore graph
learning-based methods for task planning, a direction that is orthogonal to the
prevalent focus on prompt design. Our interest in graph learning stems from a
theoretical discovery: the biases of attention and auto-regressive loss impede
LLMs' ability to effectively navigate decision-making on graphs, which is
adeptly addressed by graph neural networks (GNNs). This theoretical insight led
us to integrate GNNs with LLMs to enhance overall performance. Extensive
experiments demonstrate that GNN-based methods surpass existing solutions even
without training, and minimal training can further enhance their performance.
The performance gain increases with a larger task graph size.",2024-05-29,"Xixi Wu, Yifei Shen, Caihua Shan, Kaitao Song, Siwei Wang, Bohang Zhang, Jiarui Feng, Hong Cheng, Wei Chen, Yun Xiong, Dongsheng Li",http://arxiv.org/pdf/2405.19119v3,cs.LG
Offline Regularised Reinforcement Learning for Large Language Models Alignment,"The dominant framework for alignment of large language models (LLM), whether
through reinforcement learning from human feedback or direct preference
optimisation, is to learn from preference data. This involves building datasets
where each element is a quadruplet composed of a prompt, two independent
responses (completions of the prompt) and a human preference between the two
independent responses, yielding a preferred and a dis-preferred response. Such
data is typically scarce and expensive to collect. On the other hand,
\emph{single-trajectory} datasets where each element is a triplet composed of a
prompt, a response and a human feedback is naturally more abundant. The
canonical element of such datasets is for instance an LLM's response to a
user's prompt followed by a user's feedback such as a thumbs-up/down.
Consequently, in this work, we propose DRO, or \emph{Direct Reward
Optimisation}, as a framework and associated algorithms that do not require
pairwise preferences. DRO uses a simple mean-squared objective that can be
implemented in various ways. We validate our findings empirically, using T5
encoder-decoder language models, and show DRO's performance over selected
baselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that
DRO is a simple and empirically compelling method for single-trajectory policy
optimisation.",2024-05-29,"Pierre Harvey Richemond, Yunhao Tang, Daniel Guo, Daniele Calandriello, Mohammad Gheshlaghi Azar, Rafael Rafailov, Bernardo Avila Pires, Eugene Tarassov, Lucas Spangher, Will Ellsworth, Aliaksei Severyn, Jonathan Mallinson, Lior Shani, Gil Shamir, Rishabh Joshi, Tianqi Liu, Remi Munos, Bilal Piot",http://arxiv.org/pdf/2405.19107v1,cs.LG
Voice Jailbreak Attacks Against GPT-4o,"Recently, the concept of artificial assistants has evolved from science
fiction into real-world applications. GPT-4o, the newest multimodal large
language model (MLLM) across audio, vision, and text, has further blurred the
line between fiction and reality by enabling more natural human-computer
interactions. However, the advent of GPT-4o's voice mode may also introduce a
new attack surface. In this paper, we present the first systematic measurement
of jailbreak attacks against the voice mode of GPT-4o. We show that GPT-4o
demonstrates good resistance to forbidden questions and text jailbreak prompts
when directly transferring them to voice mode. This resistance is primarily due
to GPT-4o's internal safeguards and the difficulty of adapting text jailbreak
prompts to voice mode. Inspired by GPT-4o's human-like behaviors, we propose
VoiceJailbreak, a novel voice jailbreak attack that humanizes GPT-4o and
attempts to persuade it through fictional storytelling (setting, character, and
plot). VoiceJailbreak is capable of generating simple, audible, yet effective
jailbreak prompts, which significantly increases the average attack success
rate (ASR) from 0.033 to 0.778 in six forbidden scenarios. We also conduct
extensive experiments to explore the impacts of interaction steps, key elements
of fictional writing, and different languages on VoiceJailbreak's effectiveness
and further enhance the attack performance with advanced fictional writing
techniques. We hope our study can assist the research community in building
more secure and well-regulated MLLMs.",2024-05-29,"Xinyue Shen, Yixin Wu, Michael Backes, Yang Zhang",http://arxiv.org/pdf/2405.19103v1,cs.LG
Poseidon: Efficient Foundation Models for PDEs,"We introduce Poseidon, a foundation model for learning the solution operators
of PDEs. It is based on a multiscale operator transformer, with
time-conditioned layer norms that enable continuous-in-time evaluations. A
novel training strategy leveraging the semi-group property of time-dependent
PDEs to allow for significant scaling-up of the training data is also proposed.
Poseidon is pretrained on a diverse, large scale dataset for the governing
equations of fluid dynamics. It is then evaluated on a suite of 15 challenging
downstream tasks that include a wide variety of PDE types and operators. We
show that Poseidon exhibits excellent performance across the board by
outperforming baselines significantly, both in terms of sample efficiency and
accuracy. Poseidon also generalizes very well to new physics that is not seen
during pretraining. Moreover, Poseidon scales with respect to model and data
size, both for pretraining and for downstream tasks. Taken together, our
results showcase the surprising ability of Poseidon to learn effective
representations from a very small set of PDEs during pretraining in order to
generalize well to unseen and unrelated PDEs downstream, demonstrating its
potential as an effective, general purpose PDE foundation model. Finally, the
Poseidon model as well as underlying pretraining and downstream datasets are
open sourced, with code being available at
https://github.com/camlab-ethz/poseidon and pretrained models and datasets at
https://huggingface.co/camlab-ethz.",2024-05-29,"Maximilian Herde, Bogdan Raonić, Tobias Rohner, Roger Käppeli, Roberto Molinaro, Emmanuel de Bézenac, Siddhartha Mishra",http://arxiv.org/pdf/2405.19101v2,cs.LG
Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior,"This paper studies the challenging black-box adversarial attack that aims to
generate adversarial examples against a black-box model by only using output
feedback of the model to input queries. Some previous methods improve the query
efficiency by incorporating the gradient of a surrogate white-box model into
query-based attacks due to the adversarial transferability. However, the
localized gradient is not informative enough, making these methods still
query-intensive. In this paper, we propose a Prior-guided Bayesian Optimization
(P-BO) algorithm that leverages the surrogate model as a global function prior
in black-box adversarial attacks. As the surrogate model contains rich prior
information of the black-box one, P-BO models the attack objective with a
Gaussian process whose mean function is initialized as the surrogate model's
loss. Our theoretical analysis on the regret bound indicates that the
performance of P-BO may be affected by a bad prior. Therefore, we further
propose an adaptive integration strategy to automatically adjust a coefficient
on the function prior by minimizing the regret bound. Extensive experiments on
image classifiers and large vision-language models demonstrate the superiority
of the proposed algorithm in reducing queries and improving attack success
rates compared with the state-of-the-art black-box attacks. Code is available
at https://github.com/yibo-miao/PBO-Attack.",2024-05-29,"Shuyu Cheng, Yibo Miao, Yinpeng Dong, Xiao Yang, Xiao-Shan Gao, Jun Zhu",http://arxiv.org/pdf/2405.19098v1,cs.LG
OMPO: A Unified Framework for RL under Policy and Dynamics Shifts,"Training reinforcement learning policies using environment interaction data
collected from varying policies or dynamics presents a fundamental challenge.
Existing works often overlook the distribution discrepancies induced by policy
or dynamics shifts, or rely on specialized algorithms with task priors, thus
often resulting in suboptimal policy performances and high learning variances.
In this paper, we identify a unified strategy for online RL policy learning
under diverse settings of policy and dynamics shifts: transition occupancy
matching. In light of this, we introduce a surrogate policy learning objective
by considering the transition occupancy discrepancies and then cast it into a
tractable min-max optimization problem through dual reformulation. Our method,
dubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized
actor-critic structure equipped with a distribution discriminator and a
small-size local buffer. We conduct extensive experiments based on the OpenAI
Gym, Meta-World, and Panda Robots environments, encompassing policy shifts
under stationary and nonstationary dynamics, as well as domain adaption. The
results demonstrate that OMPO outperforms the specialized baselines from
different categories in all settings. We also find that OMPO exhibits
particularly strong performance when combined with domain randomization,
highlighting its potential in RL-based robotics applications",2024-05-29,"Yu Luo, Tianying Ji, Fuchun Sun, Jianwei Zhang, Huazhe Xu, Xianyuan Zhan",http://arxiv.org/pdf/2405.19080v1,cs.LG
Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design,"We present Cephalo, a series of multimodal vision large language models
(V-LLMs) designed for materials science applications, integrating visual and
linguistic data for enhanced understanding. A key innovation of Cephalo is its
advanced dataset generation method. Cephalo is trained on integrated image and
text data from thousands of scientific papers and science-focused Wikipedia
data demonstrates can interpret complex visual scenes, generate precise
language descriptions, and answer queries about images effectively. The
combination of a vision encoder with an autoregressive transformer supports
multimodal natural language understanding, which can be coupled with other
generative methods to create an image-to-text-to-3D pipeline. To develop more
capable models from smaller ones, we report both mixture-of-expert methods and
model merging. We examine the models in diverse use cases that incorporate
biological materials, fracture and engineering analysis, protein biophysics,
and bio-inspired design based on insect behavior. Generative applications
include bio-inspired designs, including pollen-inspired architected materials,
as well as the synthesis of bio-inspired material microstructures from a
photograph of a solar eclipse. Additional model fine-tuning with a series of
molecular dynamics results demonstrate Cephalo's enhanced capabilities to
accurately predict statistical features of stress and atomic energy
distributions, as well as crack dynamics and damage in materials.",2024-05-29,Markus J. Buehler,http://arxiv.org/pdf/2405.19076v3,cs.LG
Relevance-aware Algorithmic Recourse,"As machine learning continues to gain prominence, transparency and
explainability are increasingly critical. Without an understanding of these
models, they can replicate and worsen human bias, adversely affecting
marginalized communities. Algorithmic recourse emerges as a tool for clarifying
decisions made by predictive models, providing actionable insights to alter
outcomes. They answer, 'What do I have to change?' to achieve the desired
result. Despite their importance, current algorithmic recourse methods treat
all domain values equally, which is unrealistic in real-world settings. In this
paper, we propose a novel framework, Relevance-Aware Algorithmic Recourse
(RAAR), that leverages the concept of relevance in applying algorithmic
recourse to regression tasks. We conducted multiple experiments on 15 datasets
to outline how relevance influences recourses. Results show that relevance
contributes algorithmic recourses comparable to well-known baselines, with
greater efficiency and lower relative costs.",2024-05-29,"Dongwhi Kim, Nuno Moniz",http://arxiv.org/pdf/2405.19072v1,cs.LG
xTern: Energy-Efficient Ternary Neural Network Inference on RISC-V-Based Edge Systems,"Ternary neural networks (TNNs) offer a superior accuracy-energy trade-off
compared to binary neural networks. However, until now, they have required
specialized accelerators to realize their efficiency potential, which has
hindered widespread adoption. To address this, we present xTern, a lightweight
extension of the RISC-V instruction set architecture (ISA) targeted at
accelerating TNN inference on general-purpose cores. To complement the ISA
extension, we developed a set of optimized kernels leveraging xTern, achieving
67% higher throughput than their 2-bit equivalents. Power consumption is only
marginally increased by 5.2%, resulting in an energy efficiency improvement by
57.1%. We demonstrate that the proposed xTern extension, integrated into an
octa-core compute cluster, incurs a minimal silicon area overhead of 0.9% with
no impact on timing. In end-to-end benchmarks, we demonstrate that xTern
enables the deployment of TNNs achieving up to 1.6 percentage points higher
CIFAR-10 classification accuracy than 2-bit networks at equal inference
latency. Our results show that xTern enables RISC-V-based ultra-low-power edge
AI platforms to benefit from the efficiency potential of TNNs.",2024-05-29,"Georg Rutishauser, Joan Mihali, Moritz Scherer, Luca Benini",http://arxiv.org/pdf/2405.19065v1,cs.LG
SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs,"While dynamic graph neural networks have shown promise in various
applications, explaining their predictions on continuous-time dynamic graphs
(CTDGs) is difficult. This paper investigates a new research task:
self-interpretable GNNs for CTDGs. We aim to predict future links within the
dynamic graph while simultaneously providing causal explanations for these
predictions. There are two key challenges: (1) capturing the underlying
structural and temporal information that remains consistent across both
independent and identically distributed (IID) and out-of-distribution (OOD)
data, and (2) efficiently generating high-quality link prediction results and
explanations. To tackle these challenges, we propose a novel causal inference
model, namely the Independent and Confounded Causal Model (ICCM). ICCM is then
integrated into a deep learning architecture that considers both effectiveness
and efficiency. Extensive experiments demonstrate that our proposed model
significantly outperforms existing methods across link prediction accuracy,
explanation quality, and robustness to shortcut features. Our code and datasets
are anonymously released at https://github.com/2024SIG/SIG.",2024-05-29,"Lanting Fang, Yulian Yang, Kai Wang, Shanshan Feng, Kaiyu Feng, Jie Gui, Shuliang Wang, Yew-Soon Ong",http://arxiv.org/pdf/2405.19062v1,cs.LG
"On the Condition Monitoring of Bolted Joints through Acoustic Emission and Deep Transfer Learning: Generalization, Ordinal Loss and Super-Convergence","This paper investigates the use of deep transfer learning based on
convolutional neural networks (CNNs) to monitor the condition of bolted joints
using acoustic emissions. Bolted structures are critical components in many
mechanical systems, and the ability to monitor their condition status is
crucial for effective structural health monitoring. We evaluated the
performance of our methodology using the ORION-AE benchmark, a structure
composed of two thin beams connected by three bolts, where highly noisy
acoustic emission measurements were taken to detect changes in the applied
tightening torque of the bolts. The data used from this structure is derived
from the transformation of acoustic emission data streams into images using
continuous wavelet transform, and leveraging pretrained CNNs for feature
extraction and denoising. Our experiments compared single-sensor versus
multiple-sensor fusion for estimating the tightening level (loosening) of bolts
and evaluated the use of raw versus prefiltered data on the performance. We
particularly focused on the generalization capabilities of CNN-based transfer
learning across different measurement campaigns and we studied ordinal loss
functions to penalize incorrect predictions less severely when close to the
ground truth, thereby encouraging misclassification errors to be in adjacent
classes. Network configurations as well as learning rate schedulers are also
investigated, and super-convergence is obtained, i.e., high classification
accuracy is achieved in a few number of iterations with different networks.
Furthermore, results demonstrate the generalization capabilities of CNN-based
transfer learning for monitoring bolted structures by acoustic emission with
varying amounts of prior information required during training.",2024-05-29,"Emmanuel Ramasso, Rafael de O. Teloli, Romain Marcel",http://arxiv.org/pdf/2405.20887v1,cs.LG
Robust Entropy Search for Safe Efficient Bayesian Optimization,"The practical use of Bayesian Optimization (BO) in engineering applications
imposes special requirements: high sampling efficiency on the one hand and
finding a robust solution on the other hand. We address the case of adversarial
robustness, where all parameters are controllable during the optimization
process, but a subset of them is uncontrollable or even adversely perturbed at
the time of application. To this end, we develop an efficient information-based
acquisition function that we call Robust Entropy Search (RES). We empirically
demonstrate its benefits in experiments on synthetic and real-life data. The
results showthat RES reliably finds robust optima, outperforming
state-of-the-art algorithms.",2024-05-29,"Dorina Weichert, Alexander Kister, Sebastian Houben, Patrick Link, Gunar Ernis",http://arxiv.org/pdf/2405.19059v2,cs.LG
Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations,"The rapid expansion of electric vehicles (EVs) has rendered the load
forecasting of electric vehicle charging stations (EVCS) increasingly critical.
The primary challenge in achieving precise load forecasting for EVCS lies in
accounting for the nonlinear of charging behaviors, the spatial interactions
among different stations, and the intricate temporal variations in usage
patterns. To address these challenges, we propose a Multiscale Spatio-Temporal
Enhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM
incorporates a multiscale graph neural network to discern hierarchical
nonlinear temporal dependencies across various time scales. Besides, it also
integrates a recurrent learning component and a residual fusion mechanism,
enhancing its capability to accurately capture spatial and temporal variations
in charging patterns. The effectiveness of the proposed MSTEM has been
validated through comparative analysis with six baseline models using three
evaluation metrics. The case studies utilize real-world datasets for both fast
and slow charging loads at EVCS in Perth, UK. The experimental results
demonstrate the superiority of MSTEM in short-term continuous load forecasting
for EVCS.",2024-05-29,"Zongbao Zhang, Jiao Hao, Wenmeng Zhao, Yan Liu, Yaohui Huang, Xinhang Luo",http://arxiv.org/pdf/2405.19053v1,cs.LG
Statistical Context Detection for Deep Lifelong Reinforcement Learning,"Context detection involves labeling segments of an online stream of data as
belonging to different tasks. Task labels are used in lifelong learning
algorithms to perform consolidation or other procedures that prevent
catastrophic forgetting. Inferring task labels from online experiences remains
a challenging problem. Most approaches assume finite and low-dimension
observation spaces or a preliminary training phase during which task labels are
learned. Moreover, changes in the transition or reward functions can be
detected only in combination with a policy, and therefore are more difficult to
detect than changes in the input distribution. This paper presents an approach
to learning both policies and labels in an online deep reinforcement learning
setting. The key idea is to use distance metrics, obtained via optimal
transport methods, i.e., Wasserstein distance, on suitable latent action-reward
spaces to measure distances between sets of data points from past and current
streams. Such distances can then be used for statistical tests based on an
adapted Kolmogorov-Smirnov calculation to assign labels to sequences of
experiences. A rollback procedure is introduced to learn multiple policies by
ensuring that only the appropriate data is used to train the corresponding
policy. The combination of task detection and policy deployment allows for the
optimization of lifelong reinforcement learning agents without an oracle that
provides task labels. The approach is tested using two benchmarks and the
results show promising performance when compared with related context detection
algorithms. The results suggest that optimal transport statistical methods
provide an explainable and justifiable procedure for online context detection
and reward optimization in lifelong reinforcement learning.",2024-05-29,"Jeffery Dick, Saptarshi Nath, Christos Peridis, Eseoghene Benjamin, Soheil Kolouri, Andrea Soltoggio",http://arxiv.org/pdf/2405.19047v2,cs.LG
State Space Models are Provably Comparable to Transformers in Dynamic Token Selection,"Deep neural networks based on state space models (SSMs) are attracting
significant attention in sequence modeling since their computational cost is
much smaller than that of Transformers. While the capabilities of SSMs have
been demonstrated through experiments in various tasks, theoretical
understanding of SSMs is still limited. In particular, most theoretical studies
discuss the capabilities of SSM layers without nonlinear layers, and there is a
lack of discussion on their combination with nonlinear layers. In this paper,
we explore the capabilities of SSMs combined with fully connected neural
networks, and show that they are comparable to Transformers in extracting the
essential tokens depending on the input. As concrete examples, we consider two
synthetic tasks, which are challenging for a single SSM layer, and demonstrate
that SSMs combined with nonlinear layers can efficiently solve these tasks.
Furthermore, we study the nonparametric regression task, and prove that the
ability of SSMs is equivalent to that of Transformers in estimating functions
belonging to a certain class.",2024-05-29,"Naoki Nishikawa, Taiji Suzuki",http://arxiv.org/pdf/2405.19036v2,cs.LG
CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation in Ultra-Lightweight and One-Shot Graph Classification on Edge,"Graph Neural Networks (GNNs) are computationally demanding and inefficient
when applied to graph classification tasks in resource-constrained edge
scenarios due to their inherent process, involving multiple rounds of forward
and backward propagation. As a lightweight alternative, Hyper-Dimensional
Computing (HDC), which leverages high-dimensional vectors for data encoding and
processing, offers a more efficient solution by addressing computational
bottleneck. However, current HDC methods primarily focus on static graphs and
neglect to effectively capture node attributes and structural information,
which leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced
expressive yet ultra-lightweight HDC model for graph classification. This model
introduces a novel node encoding strategy that preserves relative distance
isomorphism for accurate node connection representation. In addition, node
distances are utilized as edge weights for information aggregation, and the
encoded node attributes and structural information are concatenated to obtain a
comprehensive graph representation. Furthermore, we explore the relationship
between orthogonality and dimensionality to reduce the dimensions, thereby
further enhancing computational efficiency. Compared to the SOTA GNNs,
extensive experiments show that CiliaGraph reduces memory usage and accelerates
training speed by an average of 292 times(up to 2341 times) and 103 times(up to
313 times) respectively while maintaining comparable accuracy.",2024-05-29,"Yuxi Han, Jihe Wang, Danghui Wang",http://arxiv.org/pdf/2405.19033v1,cs.LG
Large Language Models for Code Summarization,"Recently, there has been increasing activity in using deep learning for
software engineering, including tasks like code generation and summarization.
In particular, the most recent coding Large Language Models seem to perform
well on these problems. In this technical report, we aim to review how these
models perform in code explanation/summarization, while also investigating
their code generation capabilities (based on natural language descriptions).",2024-05-29,"Balázs Szalontai, Gergő Szalay, Tamás Márton, Anna Sike, Balázs Pintér, Tibor Gregorics",http://arxiv.org/pdf/2405.19032v1,cs.LG
DiveR-CT: Diversity-enhanced Red Teaming Large Language Model Assistants with Relaxing Constraints,"Recent advances in large language model assistants have made them
indispensable, raising significant concerns over managing their safety.
Automated red teaming offers a promising alternative to the labor-intensive and
error-prone manual probing for vulnerabilities, providing more consistent and
scalable safety evaluations. However, existing approaches often compromise
diversity by focusing on maximizing attack success rate. Additionally, methods
that decrease the cosine similarity from historical embeddings with semantic
diversity rewards lead to novelty stagnation as history grows. To address these
issues, we introduce DiveR-CT, which relaxes conventional constraints on the
objective and semantic reward, granting greater freedom for the policy to
enhance diversity. Our experiments demonstrate DiveR-CT's marked superiority
over baselines by 1) generating data that perform better in various diversity
metrics across different attack success rate levels, 2) better-enhancing
resiliency in blue team models through safety tuning based on collected data,
3) allowing dynamic control of objective weights for reliable and controllable
attack success rates, and 4) reducing susceptibility to reward
overoptimization. Overall, our method provides an effective and efficient
approach to LLM red teaming, accelerating real-world deployment.",2024-05-29,"Andrew Zhao, Quentin Xu, Matthieu Lin, Shenzhi Wang, Yong-jin Liu, Zilong Zheng, Gao Huang",http://arxiv.org/pdf/2405.19026v2,cs.LG
Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory,"We consider inverse reinforcement learning problems with concave utilities.
Concave Utility Reinforcement Learning (CURL) is a generalisation of the
standard RL objective, which employs a concave function of the state occupancy
measure, rather than a linear function. CURL has garnered recent attention for
its ability to represent instances of many important applications including the
standard RL such as imitation learning, pure exploration, constrained MDPs,
offline RL, human-regularized RL, and others. Inverse reinforcement learning is
a powerful paradigm that focuses on recovering an unknown reward function that
can rationalize the observed behaviour of an agent. There has been recent
theoretical advances in inverse RL where the problem is formulated as
identifying the set of feasible reward functions. However, inverse RL for CURL
problems has not been considered previously. In this paper we show that most of
the standard IRL results do not apply to CURL in general, since CURL
invalidates the classical Bellman equations. This calls for a new theoretical
framework for the inverse CURL problem. Using a recent equivalence result
between CURL and Mean-field Games, we propose a new definition for the feasible
rewards for I-CURL by proving that this problem is equivalent to an inverse
game theory problem in a subclass of mean-field games. We outline future
directions and applications in human--AI collaboration enabled by our results.",2024-05-29,"Mustafa Mert Çelikok, Frans A. Oliehoek, Jan-Willem van de Meent",http://arxiv.org/pdf/2405.19024v3,cs.LG
Towards Standardizing AI Bias Exploration,"Creating fair AI systems is a complex problem that involves the assessment of
context-dependent bias concerns. Existing research and programming libraries
express specific concerns as measures of bias that they aim to constrain or
mitigate. In practice, one should explore a wide variety of (sometimes
incompatible) measures before deciding which ones warrant corrective action,
but their narrow scope means that most new situations can only be examined
after devising new measures. In this work, we present a mathematical framework
that distils literature measures of bias into building blocks, hereby
facilitating new combinations to cover a wide range of fairness concerns, such
as classification or recommendation differences across multiple multi-value
sensitive attributes (e.g., many genders and races, and their intersections).
We show how this framework generalizes existing concepts and present frequently
used blocks. We provide an open-source implementation of our framework as a
Python library, called FairBench, that facilitates systematic and extensible
exploration of potential bias concerns.",2024-05-29,"Emmanouil Krasanakis, Symeon Papadopoulos",http://arxiv.org/pdf/2405.19022v1,cs.LG
"Physics-Aware Neural Implicit Solvers for multiscale, parametric PDEs with applications in heterogeneous media","We propose Physics-Aware Neural Implicit Solvers (PANIS), a novel,
data-driven framework for learning surrogates for parametrized Partial
Differential Equations (PDEs). It consists of a probabilistic, learning
objective in which weighted residuals are used to probe the PDE and provide a
source of {\em virtual} data i.e. the actual PDE never needs to be solved. This
is combined with a physics-aware implicit solver that consists of a much
coarser, discretized version of the original PDE, which provides the requisite
information bottleneck for high-dimensional problems and enables generalization
in out-of-distribution settings (e.g. different boundary conditions). We
demonstrate its capability in the context of random heterogeneous materials
where the input parameters represent the material microstructure. We extend the
framework to multiscale problems and show that a surrogate can be learned for
the effective (homogenized) solution without ever solving the reference
problem. We further demonstrate how the proposed framework can accommodate and
generalize several existing learning objectives and architectures while
yielding probabilistic surrogates that can quantify predictive uncertainty.",2024-05-29,"Matthaios Chatzopoulos, Phaedon-Stelios Koutsourelakis",http://arxiv.org/pdf/2405.19019v1,cs.LG
Efficient Exploration in Average-Reward Constrained Reinforcement Learning: Achieving Near-Optimal Regret With Posterior Sampling,"We present a new algorithm based on posterior sampling for learning in
Constrained Markov Decision Processes (CMDP) in the infinite-horizon
undiscounted setting. The algorithm achieves near-optimal regret bounds while
being advantageous empirically compared to the existing algorithms. Our main
theoretical result is a Bayesian regret bound for each cost component of
$\tilde{O} (DS\sqrt{AT})$ for any communicating CMDP with $S$ states, $A$
actions, and diameter $D$. This regret bound matches the lower bound in order
of time horizon $T$ and is the best-known regret bound for communicating CMDPs
achieved by a computationally tractable algorithm. Empirical results show that
our posterior sampling algorithm outperforms the existing algorithms for
constrained reinforcement learning.",2024-05-29,"Danil Provodin, Maurits Kaptein, Mykola Pechenizkiy",http://arxiv.org/pdf/2405.19017v1,cs.LG
Distributed Management of Fluctuating Energy Resources in Dynamic Networked Systems,"Modern power systems integrate renewable distributed energy resources (DERs)
as an environment-friendly enhancement to meet the ever-increasing demands.
However, the inherent unreliability of renewable energy renders developing DER
management algorithms imperative. We study the energy-sharing problem in a
system consisting of several DERs. Each agent harvests and distributes
renewable energy in its neighborhood to optimize the network's performance
while minimizing energy waste. We model this problem as a bandit convex
optimization problem with constraints that correspond to each node's
limitations for energy production. We propose distributed decision-making
policies to solve the formulated problem, where we utilize the notion of
dynamic regret as the performance metric. We also include an adjustment
strategy in our developed algorithm to reduce the constraint violations.
Besides, we design a policy that deals with the non-stationary environment.
Theoretical analysis shows the effectiveness of our proposed algorithm.
Numerical experiments using a real-world dataset show superior performance of
our proposal compared to state-of-the-art methods.",2024-05-29,"Xiaotong Cheng, Ioannis Tsetis, Setareh Maghsudi",http://arxiv.org/pdf/2405.19015v1,cs.LG
Trust the Model Where It Trusts Itself -- Model-Based Actor-Critic with Uncertainty-Aware Rollout Adaption,"Dyna-style model-based reinforcement learning (MBRL) combines model-free
agents with predictive transition models through model-based rollouts. This
combination raises a critical question: 'When to trust your model?'; i.e.,
which rollout length results in the model providing useful data? Janner et al.
(2019) address this question by gradually increasing rollout lengths throughout
the training. While theoretically tempting, uniform model accuracy is a fallacy
that collapses at the latest when extrapolating. Instead, we propose asking the
question 'Where to trust your model?'. Using inherent model uncertainty to
consider local accuracy, we obtain the Model-Based Actor-Critic with
Uncertainty-Aware Rollout Adaption (MACURA) algorithm. We propose an
easy-to-tune rollout mechanism and demonstrate substantial improvements in data
efficiency and performance compared to state-of-the-art deep MBRL methods on
the MuJoCo benchmark.",2024-05-29,"Bernd Frauenknecht, Artur Eisele, Devdutt Subhasish, Friedrich Solowjow, Sebastian Trimpe",http://arxiv.org/pdf/2405.19014v3,cs.LG
On Dissipativity of Cross-Entropy Loss in Training ResNets,"The training of ResNets and neural ODEs can be formulated and analyzed from
the perspective of optimal control. This paper proposes a dissipative
formulation of the training of ResNets and neural ODEs for classification
problems by including a variant of the cross-entropy as a regularization in the
stage cost. Based on the dissipative formulation of the training, we prove that
the trained ResNet exhibit the turnpike phenomenon. We then illustrate that the
training exhibits the turnpike phenomenon by training on the two spirals and
MNIST datasets. This can be used to find very shallow networks suitable for a
given classification task.",2024-05-29,"Jens Püttschneider, Timm Faulwasser",http://arxiv.org/pdf/2405.19013v1,cs.LG
FedMAP: Unlocking Potential in Personalized Federated Learning through Bi-Level MAP Optimization,"Federated Learning (FL) enables collaborative training of machine learning
models on decentralized data while preserving data privacy. However, data
across clients often differs significantly due to class imbalance, feature
distribution skew, sample size imbalance, and other phenomena. Leveraging
information from these not identically distributed (non-IID) datasets poses
substantial challenges. FL methods based on a single global model cannot
effectively capture the variations in client data and underperform in non-IID
settings. Consequently, Personalized FL (PFL) approaches that adapt to each
client's data distribution but leverage other clients' data are essential but
currently underexplored. We propose a novel Bayesian PFL framework using
bi-level optimization to tackle the data heterogeneity challenges. Our proposed
framework utilizes the global model as a prior distribution within a Maximum A
Posteriori (MAP) estimation of personalized client models. This approach
facilitates PFL by integrating shared knowledge from the prior, thereby
enhancing local model performance, generalization ability, and communication
efficiency. We extensively evaluated our bi-level optimization approach on
real-world and synthetic datasets, demonstrating significant improvements in
model accuracy compared to existing methods while reducing communication
overhead. This study contributes to PFL by establishing a solid theoretical
foundation for the proposed method and offering a robust, ready-to-use
framework that effectively addresses the challenges posed by non-IID data in
FL.",2024-05-29,"Fan Zhang, Carlos Esteve-Yagüe, Sören Dittmer, Carola-Bibiane Schönlieb, Michael Roberts",http://arxiv.org/pdf/2405.19000v1,cs.LG
Kernel Semi-Implicit Variational Inference,"Semi-implicit variational inference (SIVI) extends traditional variational
families with semi-implicit distributions defined in a hierarchical manner. Due
to the intractable densities of semi-implicit distributions, classical SIVI
often resorts to surrogates of evidence lower bound (ELBO) that would introduce
biases for training. A recent advancement in SIVI, named SIVI-SM, utilizes an
alternative score matching objective made tractable via a minimax formulation,
albeit requiring an additional lower-level optimization. In this paper, we
propose kernel SIVI (KSIVI), a variant of SIVI-SM that eliminates the need for
lower-level optimization through kernel tricks. Specifically, we show that when
optimizing over a reproducing kernel Hilbert space (RKHS), the lower-level
problem has an explicit solution. This way, the upper-level objective becomes
the kernel Stein discrepancy (KSD), which is readily computable for stochastic
gradient descent due to the hierarchical structure of semi-implicit variational
distributions. An upper bound for the variance of the Monte Carlo gradient
estimators of the KSD objective is derived, which allows us to establish novel
convergence guarantees of KSIVI. We demonstrate the effectiveness and
efficiency of KSIVI on both synthetic distributions and a variety of real data
Bayesian inference tasks.",2024-05-29,"Ziheng Cheng, Longlin Yu, Tianyu Xie, Shiyue Zhang, Cheng Zhang",http://arxiv.org/pdf/2405.18997v1,cs.LG
Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space,"Proteins are complex molecules responsible for different functions in nature.
Enhancing the functionality of proteins and cellular fitness can significantly
impact various industries. However, protein optimization using computational
methods remains challenging, especially when starting from low-fitness
sequences. We propose LatProtRL, an optimization method to efficiently traverse
a latent space learned by an encoder-decoder leveraging a large protein
language model. To escape local optima, our optimization is modeled as a Markov
decision process using reinforcement learning acting directly in latent space.
We evaluate our approach on two important fitness optimization tasks,
demonstrating its ability to achieve comparable or superior fitness over
baseline methods. Our findings and in vitro evaluation show that the generated
sequences can reach high-fitness regions, suggesting a substantial potential of
LatProtRL in lab-in-the-loop scenarios.",2024-05-29,"Minji Lee, Luiz Felipe Vecchietti, Hyunkyu Jung, Hyun Joo Ro, Meeyoung Cha, Ho Min Kim",http://arxiv.org/pdf/2405.18986v1,cs.LG
Optimizing Vehicular Networks with Variational Quantum Circuits-based Reinforcement Learning,"In vehicular networks (VNets), ensuring both road safety and dependable
network connectivity is of utmost importance. Achieving this necessitates the
creation of resilient and efficient decision-making policies that prioritize
multiple objectives. In this paper, we develop a Variational Quantum Circuit
(VQC)-based multi-objective reinforcement learning (MORL) framework to
characterize efficient network selection and autonomous driving policies in a
vehicular network (VNet). Numerical results showcase notable enhancements in
both convergence rates and rewards when compared to conventional deep-Q
networks (DQNs), validating the efficacy of the VQC-MORL solution.",2024-05-29,"Zijiang Yan, Ramsundar Tanikella, Hina Tabassum",http://arxiv.org/pdf/2405.18984v1,cs.LG
Federated Learning under Partially Class-Disjoint Data via Manifold Reshaping,"Statistical heterogeneity severely limits the performance of federated
learning (FL), motivating several explorations e.g., FedProx, MOON and FedDyn,
to alleviate this problem. Despite effectiveness, their considered scenario
generally requires samples from almost all classes during the local training of
each client, although some covariate shifts may exist among clients. In fact,
the natural case of partially class-disjoint data (PCDD), where each client
contributes a few classes (instead of all classes) of samples, is practical yet
underexplored. Specifically, the unique collapse and invasion characteristics
of PCDD can induce the biased optimization direction in local training, which
prevents the efficiency of federated learning. To address this dilemma, we
propose a manifold reshaping approach called FedMR to calibrate the feature
space of local training. Our FedMR adds two interplaying losses to the vanilla
federated learning: one is intra-class loss to decorrelate feature dimensions
for anti-collapse; and the other one is inter-class loss to guarantee the
proper margin among categories in the feature expansion. We conduct extensive
experiments on a range of datasets to demonstrate that our FedMR achieves much
higher accuracy and better communication efficiency. Source code is available
at: https://github.com/MediaBrain-SJTU/FedMR.git.",2024-05-29,"Ziqing Fan, Jiangchao Yao, Ruipeng Zhang, Lingjuan Lyu, Ya Zhang, Yanfeng Wang",http://arxiv.org/pdf/2405.18983v2,cs.LG
MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts,"Leveraging the models' outputs, specifically the logits, is a common approach
to estimating the test accuracy of a pre-trained neural network on
out-of-distribution (OOD) samples without requiring access to the corresponding
ground truth labels. Despite their ease of implementation and computational
efficiency, current logit-based methods are vulnerable to overconfidence
issues, leading to prediction bias, especially under the natural shift. In this
work, we first study the relationship between logits and generalization
performance from the view of low-density separation assumption. Our findings
motivate our proposed method MaNo which (1) applies a data-dependent
normalization on the logits to reduce prediction bias, and (2) takes the $L_p$
norm of the matrix of normalized logits as the estimation score. Our
theoretical analysis highlights the connection between the provided score and
the model's uncertainty. We conduct an extensive empirical study on common
unsupervised accuracy estimation benchmarks and demonstrate that MaNo achieves
state-of-the-art performance across various architectures in the presence of
synthetic, natural, or subpopulation shifts. The code is available at
\url{https://github.com/Renchunzi-Xie/MaNo}.",2024-05-29,"Renchunzi Xie, Ambroise Odonnat, Vasilii Feofanov, Weijian Deng, Jianfeng Zhang, Bo An",http://arxiv.org/pdf/2405.18979v3,cs.LG
Hierarchical Classification Auxiliary Network for Time Series Forecasting,"Deep learning has significantly advanced time series forecasting through its
powerful capacity to capture sequence relationships. However, training these
models with the Mean Square Error (MSE) loss often results in over-smooth
predictions, making it challenging to handle the complexity and learn
high-entropy features from time series data with high variability and
unpredictability. In this work, we introduce a novel approach by tokenizing
time series values to train forecasting models via cross-entropy loss, while
considering the continuous nature of time series data. Specifically, we propose
a Hierarchical Classification Auxiliary Network, HCAN, a general model-agnostic
component that can be integrated with any forecasting model. HCAN is based on a
Hierarchy-Aware Attention module that integrates multi-granularity high-entropy
features at different hierarchy levels. At each level, we assign a class label
for timesteps to train an Uncertainty-Aware Classifier. This classifier
mitigates the over-confidence in softmax loss via evidence theory. We also
implement a Hierarchical Consistency Loss to maintain prediction consistency
across hierarchy levels. Extensive experiments integrating HCAN with
state-of-the-art forecasting models demonstrate substantial improvements over
baselines on several real-world datasets.",2024-05-29,"Yanru Sun, Zongxia Xie, Dongyue Chen, Emadeldeen Eldele, Qinghua Hu",http://arxiv.org/pdf/2405.18975v2,cs.LG
Federated Learning with Bilateral Curation for Partially Class-Disjoint Data,"Partially class-disjoint data (PCDD), a common yet under-explored data
formation where each client contributes a part of classes (instead of all
classes) of samples, severely challenges the performance of federated
algorithms. Without full classes, the local objective will contradict the
global objective, yielding the angle collapse problem for locally missing
classes and the space waste problem for locally existing classes. As far as we
know, none of the existing methods can intrinsically mitigate PCDD challenges
to achieve holistic improvement in the bilateral views (both global view and
local view) of federated learning. To address this dilemma, we are inspired by
the strong generalization of simplex Equiangular Tight Frame~(ETF) on the
imbalanced data, and propose a novel approach called FedGELA where the
classifier is globally fixed as a simplex ETF while locally adapted to the
personal distributions. Globally, FedGELA provides fair and equal
discrimination for all classes and avoids inaccurate updates of the classifier,
while locally it utilizes the space of locally missing classes for locally
existing classes. We conduct extensive experiments on a range of datasets to
demonstrate that our FedGELA achieves promising performance~(averaged
improvement of 3.9% to FedAvg and 1.5% to best baselines) and provide both
local and global convergence guarantees. Source code is available
at:https://github.com/MediaBrain-SJTU/FedGELA.git.",2024-05-29,"Ziqing Fan, Ruipeng Zhang, Jiangchao Yao, Bo Han, Ya Zhang, Yanfeng Wang",http://arxiv.org/pdf/2405.18972v1,cs.LG
UniIF: Unified Molecule Inverse Folding,"Molecule inverse folding has been a long-standing challenge in chemistry and
biology, with the potential to revolutionize drug discovery and material
science. Despite specified models have been proposed for different small- or
macro-molecules, few have attempted to unify the learning process, resulting in
redundant efforts. Complementary to recent advancements in molecular structure
prediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified
model UniIF for the inverse folding of all molecules. We do such unification in
two levels: 1) Data-Level: We propose a unified block graph data form for all
molecules, including the local frame building and geometric feature
initialization. 2) Model-Level: We introduce a geometric block attention
network, comprising a geometric interaction, interactive attention and virtual
long-term dependency modules, to capture the 3D interactions of all molecules.
Through comprehensive evaluations across various tasks such as protein design,
RNA design, and material design, we demonstrate that our proposed method
surpasses state-of-the-art methods on all tasks. UniIF offers a versatile and
effective solution for general molecule inverse folding.",2024-05-29,"Zhangyang Gao, Jue Wang, Cheng Tan, Lirong Wu, Yufei Huang, Siyuan Li, Zhirui Ye, Stan Z. Li",http://arxiv.org/pdf/2405.18968v1,cs.LG
MAGIC: Modular Auto-encoder for Generalisable Model Inversion with Bias Corrections,"Scientists often model physical processes to understand the natural world and
uncover the causation behind observations. Due to unavoidable simplification,
discrepancies often arise between model predictions and actual observations, in
the form of systematic biases, whose impact varies with model completeness.
Classical model inversion methods such as Bayesian inference or regressive
neural networks tend either to overlook biases or make assumptions about their
nature during data preprocessing, potentially leading to implausible results.
Inspired by recent work in inverse graphics, we replace the decoder stage of a
standard autoencoder with a physical model followed by a bias-correction layer.
This generalisable approach simultaneously inverts the model and corrects its
biases in an end-to-end manner without making strong assumptions about the
nature of the biases. We demonstrate the effectiveness of our approach using
two physical models from disparate domains: a complex radiative transfer model
from remote sensing; and a volcanic deformation model from geodesy. Our method
matches or surpasses results from classical approaches without requiring biases
to be explicitly filtered out, suggesting an effective pathway for
understanding the causation of various physical processes.",2024-05-29,"Yihang She, Clement Atzberger, Andrew Blake, Adriano Gualandi, Srinivasan Keshav",http://arxiv.org/pdf/2405.18953v1,cs.LG
An Open-Source Framework for Efficient Numerically-Tailored Computations,"We present a versatile open-source framework designed to facilitate
efficient, numerically-tailored Matrix-Matrix Multiplications (MMMs). The
framework offers two primary contributions: first, a fine-tuned, automated
pipeline for arithmetic datapath generation, enabling highly customizable
systolic MMM kernels; second, seamless integration of the generated kernels
into user code, irrespective of the programming language employed, without
necessitating modifications.
  The framework demonstrates a systematic enhancement in accuracy per energy
cost across diverse High Performance Computing (HPC) workloads displaying a
variety of numerical requirements, such as Artificial Intelligence (AI)
inference and Sea Surface Height (SSH) computation. For AI inference, we
consider a set of state-of-the-art neural network models, namely ResNet18,
ResNet34, ResNet50, DenseNet121, DenseNet161, DenseNet169, and VGG11, in
conjunction with two datasets, two computer formats, and 27 distinct
intermediate arithmetic datapaths. Our approach consistently reduces energy
consumption across all cases, with a notable example being the reduction by
factors of $3.3\times$ for IEEE754-32 and $1.4\times$ for Bfloat16 during
ImageNet inference with ResNet50. This is accomplished while maintaining
accuracies of $82.3\%$ and $86\%$, comparable to those achieved with
conventional Floating-Point Units (FPUs). In the context of SSH computation,
our method achieves fully-reproducible results using double-precision words,
surpassing the accuracy of conventional double- and quad-precision arithmetic
in FPUs. Our approach enhances SSH computation accuracy by a minimum of
$5\times$ and $27\times$ compared to IEEE754-64 and IEEE754-128, respectively,
resulting in $5.6\times$ and $15.1\times$ improvements in accuracy per power
cost.",2024-05-29,"Louis Ledoux, Marc Casas",http://arxiv.org/pdf/2406.02579v1,cs.LG
Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets,"Training Large Language Models (LLMs) with Reinforcement Learning from AI
Feedback (RLAIF) aligns model outputs more closely with human preferences. This
involves an evaluator model ranking multiple candidate responses to user
prompts. However, the rankings from popular evaluator models such as GPT-4 can
be inconsistent. We propose the Repeat Ranking method - where we evaluate the
same responses multiple times and train only on those responses which are
consistently ranked. Using 2,714 prompts in 62 languages, we generated
responses from 7 top multilingual LLMs and had GPT-4 rank them five times each.
Evaluating on MT-Bench chat benchmarks in six languages, our method
outperformed the standard practice of training on all available prompts. Our
work highlights the quality versus quantity trade-off in RLAIF dataset
generation and offers a stackable strategy for enhancing dataset and thus model
quality.",2024-05-29,Peter Devine,http://arxiv.org/pdf/2405.18952v2,cs.LG
Learning to Recover from Plan Execution Errors during Robot Manipulation: A Neuro-symbolic Approach,"Automatically detecting and recovering from failures is an important but
challenging problem for autonomous robots. Most of the recent work on learning
to plan from demonstrations lacks the ability to detect and recover from errors
in the absence of an explicit state representation and/or a (sub-) goal check
function. We propose an approach (blending learning with symbolic search) for
automated error discovery and recovery, without needing annotated data of
failures. Central to our approach is a neuro-symbolic state representation, in
the form of dense scene graph, structured based on the objects present within
the environment. This enables efficient learning of the transition function and
a discriminator that not only identifies failures but also localizes them
facilitating fast re-planning via computation of heuristic distance function.
We also present an anytime version of our algorithm, where instead of
recovering to the last correct state, we search for a sub-goal in the original
plan minimizing the total distance to the goal given a re-planning budget.
Experiments on a physics simulator with a variety of simulated failures show
the effectiveness of our approach compared to existing baselines, both in terms
of efficiency as well as accuracy of our recovery mechanism.",2024-05-29,"Namasivayam Kalithasan, Arnav Tuli, Vishal Bindal, Himanshu Gaurav Singh, Parag Singla, Rohan Paul",http://arxiv.org/pdf/2405.18948v1,cs.LG
WTTFNet: A Weather-Time-Trajectory Fusion Network for Pedestrian Trajectory Prediction in Urban Complex,"Pedestrian trajectory modelling in an urban complex is challenging because
pedestrians can have many possible destinations, such as shops, escalators, and
attractions. Moreover, weather and time-of-day may affect pedestrian behavior.
In this paper, a new weather-time-trajectory fusion network (WTTFNet) is
proposed to improve the performance of baseline deep neural network
architecture. By incorporating weather and time-of-day information as an
embedding structure, a novel WTTFNet based on gate multimodal unit is used to
fuse the multimodal information and deep representation of trajectories. A
joint loss function based on focal loss is used to co-optimize both the deep
trajectory features and final classifier, which helps to improve the accuracy
in predicting the intended destination of pedestrians and hence the
trajectories under possible scenarios of class imbalances. Experimental results
using the Osaka Asia and Pacific Trade Center (ATC) dataset shows improved
performance of the proposed approach over state-of-the-art algorithms by 23.67%
increase in classification accuracy, 9.16% and 7.07% reduction of average and
final displacement error. The proposed approach may serve as an attractive
approach for improving existing baseline trajectory prediction models when they
are applied to scenarios with influences of weather-time conditions. It can be
employed in numerous applications such as pedestrian facility engineering,
public space development and technology-driven retail.",2024-05-29,"Ho Chun Wu, Esther Hoi Shan Lau, Paul Yuen, Kevin Hung, John Kwok Tai Chui, Andrew Kwok Fai Lui",http://arxiv.org/pdf/2405.18945v1,cs.LG
Predicting Many Crystal Properties via an Adaptive Transformer-based Framework,"Machine learning has revolutionized many fields, including materials science.
However, predicting properties of crystalline materials using machine learning
faces challenges in input encoding, output versatility, and interpretability.
We introduce CrystalBERT, an adaptable transformer-based framework integrating
space group, elemental, and unit cell information. This novel structure can
seamlessly combine diverse features and accurately predict various physical
properties, including topological properties, superconducting transition
temperatures, dielectric constants, and more. CrystalBERT provides insightful
interpretations of features influencing target properties. Our results indicate
that space group and elemental information are crucial for predicting
topological and superconducting properties, underscoring their intricate
nature. By incorporating these features, we achieve 91\% accuracy in
topological classification, surpassing prior studies and identifying previously
misclassified materials. This research demonstrates that integrating diverse
material information enhances the prediction of complex material properties,
paving the way for more accurate and interpretable machine learning models in
materials science.",2024-05-29,"Haosheng Xu, Dongheng Qian, Jing Wang",http://arxiv.org/pdf/2405.18944v2,cs.LG
Verifiably Robust Conformal Prediction,"Conformal Prediction (CP) is a popular uncertainty quantification method that
provides distribution-free, statistically valid prediction sets, assuming that
training and test data are exchangeable. In such a case, CP's prediction sets
are guaranteed to cover the (unknown) true test output with a user-specified
probability. Nevertheless, this guarantee is violated when the data is
subjected to adversarial attacks, which often result in a significant loss of
coverage. Recently, several approaches have been put forward to recover CP
guarantees in this setting. These approaches leverage variations of randomised
smoothing to produce conservative sets which account for the effect of the
adversarial perturbations. They are, however, limited in that they only support
$\ell^2$-bounded perturbations and classification tasks. This paper introduces
VRCP (Verifiably Robust Conformal Prediction), a new framework that leverages
recent neural network verification methods to recover coverage guarantees under
adversarial attacks. Our VRCP method is the first to support perturbations
bounded by arbitrary norms including $\ell^1$, $\ell^2$, and $\ell^\infty$, as
well as regression tasks. We evaluate and compare our approach on image
classification tasks (CIFAR10, CIFAR100, and TinyImageNet) and regression tasks
for deep reinforcement learning environments. In every case, VRCP achieves
above nominal coverage and yields significantly more efficient and informative
prediction regions than the SotA.",2024-05-29,"Linus Jeary, Tom Kuipers, Mehran Hosseini, Nicola Paoletti",http://arxiv.org/pdf/2405.18942v3,cs.LG
Content-Agnostic Moderation for Stance-Neutral Recommendation,"Personalized recommendation systems often drive users towards more extreme
content, exacerbating opinion polarization. While (content-aware) moderation
has been proposed to mitigate these effects, such approaches risk curtailing
the freedom of speech and of information. To address this concern, we propose
and explore the feasibility of \emph{content-agnostic} moderation as an
alternative approach for reducing polarization. Content-agnostic moderation
does not rely on the actual content being moderated, arguably making it less
prone to forms of censorship. We establish theoretically that content-agnostic
moderation cannot be guaranteed to work in a fully generic setting. However, we
show that it can often be effectively achieved in practice with plausible
assumptions. We introduce two novel content-agnostic moderation methods that
modify the recommendations from the content recommender to disperse user-item
co-clusters without relying on content features.
  To evaluate the potential of content-agnostic moderation in controlled
experiments, we built a simulation environment to analyze the closed-loop
behavior of a system with a given set of users, recommendation system, and
moderation approach. Through comprehensive experiments in this environment, we
show that our proposed moderation methods significantly enhance stance
neutrality and maintain high recommendation quality across various data
scenarios. Our results indicate that achieving stance neutrality without direct
content information is not only feasible but can also help in developing more
balanced and informative recommendation systems without substantially degrading
user engagement.",2024-05-29,"Nan Li, Bo Kang, Tijl De Bie",http://arxiv.org/pdf/2405.18941v1,cs.LG
HLOB -- Information Persistence and Structure in Limit Order Books,"We introduce a novel large-scale deep learning model for Limit Order Book
mid-price changes forecasting, and we name it `HLOB'. This architecture (i)
exploits the information encoded by an Information Filtering Network, namely
the Triangulated Maximally Filtered Graph, to unveil deeper and non-trivial
dependency structures among volume levels; and (ii) guarantees deterministic
design choices to handle the complexity of the underlying system by drawing
inspiration from the groundbreaking class of Homological Convolutional Neural
Networks. We test our model against 9 state-of-the-art deep learning
alternatives on 3 real-world Limit Order Book datasets, each including 15
stocks traded on the NASDAQ exchange, and we systematically characterize the
scenarios where HLOB outperforms state-of-the-art architectures. Our approach
sheds new light on the spatial distribution of information in Limit Order Books
and on its degradation over increasing prediction horizons, narrowing the gap
between microstructural modeling and deep learning-based forecasting in
high-frequency financial markets.",2024-05-29,"Antonio Briola, Silvia Bartolucci, Tomaso Aste",http://arxiv.org/pdf/2405.18938v3,cs.LG
LSPI: Heterogeneous Graph Neural Network Classification Aggregation Algorithm Based on Size Neighbor Path Identification,"Existing heterogeneous graph neural network algorithms (HGNNs) mostly rely on
meta-paths to capture the rich semantic information contained in heterogeneous
graphs (also known as heterogeneous information networks (HINs)), but most of
these HGNNs focus on different ways of feature aggre gation and ignore the
properties of the meta-paths themselves. This paper studies meta-paths in three
commonly used data sets and finds that there are huge differences in the number
of neighbors connected by different meta paths. At the same time, the noise
information contained in large neigh bor paths will have an adverse impact on
model performance. Therefore, this paper proposes a Heterogeneous Graph Neural
Network Classification and Aggregation Algorithm Based on Large and Small
Neighbor Path Iden tification(LSPI). LSPI firstly divides the meta-paths into
large and small neighbor paths through the path discriminator , and in order to
reduce the noise interference problem in large neighbor paths, LSPI selects
neighbor nodes with higher similarity from both topology and feature
perspectives, and passes small neighbor paths and filtered large neighbor paths
through different graph convolution components. Aggregation is performed to
obtain feature information under different subgraphs, and then LSPI uses
subgraph level attention to fuse the feature information under different
subgraphs to generate the final node embedding. Finally this paper verifies the
superiority of the method through extensive experiments and also gives
suggestions on the number of nodes to be retained in large neighbor paths
through exper iments. The complete reproducible code adn data has been
published at: https://github.com/liuhua811/LSPIA.",2024-05-29,"Yufei Zhao, Shiduo Wang, Hua Duan",http://arxiv.org/pdf/2405.18933v2,cs.LG
A Mallows-like Criterion for Anomaly Detection with Random Forest Implementation,"The effectiveness of anomaly signal detection can be significantly undermined
by the inherent uncertainty of relying on one specified model. Under the
framework of model average methods, this paper proposes a novel criterion to
select the weights on aggregation of multiple models, wherein the focal loss
function accounts for the classification of extremely imbalanced data. This
strategy is further integrated into Random Forest algorithm by replacing the
conventional voting method. We have evaluated the proposed method on benchmark
datasets across various domains, including network intrusion. The findings
indicate that our proposed method not only surpasses the model averaging with
typical loss functions but also outstrips common anomaly detection algorithms
in terms of accuracy and robustness.",2024-05-29,"Gaoxiang Zhao, Lu Wang, Xiaoqiang Wang",http://arxiv.org/pdf/2405.18932v1,cs.LG
EntProp: High Entropy Propagation for Improving Accuracy and Robustness,"Deep neural networks (DNNs) struggle to generalize to out-of-distribution
domains that are different from those in training despite their impressive
performance. In practical applications, it is important for DNNs to have both
high standard accuracy and robustness against out-of-distribution domains. One
technique that achieves both of these improvements is disentangled learning
with mixture distribution via auxiliary batch normalization layers (ABNs). This
technique treats clean and transformed samples as different domains, allowing a
DNN to learn better features from mixed domains. However, if we distinguish the
domains of the samples based on entropy, we find that some transformed samples
are drawn from the same domain as clean samples, and these samples are not
completely different domains. To generate samples drawn from a completely
different domain than clean samples, we hypothesize that transforming clean
high-entropy samples to further increase the entropy generates
out-of-distribution samples that are much further away from the in-distribution
domain. On the basis of the hypothesis, we propose high entropy
propagation~(EntProp), which feeds high-entropy samples to the network that
uses ABNs. We introduce two techniques, data augmentation and free adversarial
training, that increase entropy and bring the sample further away from the
in-distribution domain. These techniques do not require additional training
costs. Our experimental results show that EntProp achieves higher standard
accuracy and robustness with a lower training cost than the baseline methods.
In particular, EntProp is highly effective at training on small datasets.",2024-05-29,Shohei Enomoto,http://arxiv.org/pdf/2405.18931v1,cs.LG
Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled Data,"Semi-supervised anomaly detection, which aims to improve the anomaly
detection performance by using a small amount of labeled anomaly data in
addition to unlabeled data, has attracted attention. Existing semi-supervised
approaches assume that most unlabeled data are normal, and train anomaly
detectors by minimizing the anomaly scores for the unlabeled data while
maximizing those for the labeled anomaly data. However, in practice, the
unlabeled data are often contaminated with anomalies. This weakens the effect
of maximizing the anomaly scores for anomalies, and prevents us from improving
the detection performance. To solve this problem, we propose the deep
positive-unlabeled anomaly detection framework, which integrates
positive-unlabeled learning with deep anomaly detection models such as
autoencoders and deep support vector data descriptions. Our approach enables
the approximation of anomaly scores for normal data using the unlabeled data
and the labeled anomaly data. Therefore, without labeled normal data, our
approach can train anomaly detectors by minimizing the anomaly scores for
normal data while maximizing those for the labeled anomaly data. Experiments on
various datasets show that our approach achieves better detection performance
than existing approaches.",2024-05-29,"Hiroshi Takahashi, Tomoharu Iwata, Atsutoshi Kumagai, Yuuki Yamanaka",http://arxiv.org/pdf/2405.18929v2,cs.LG
Federated Continual Learning Goes Online: Uncertainty-Aware Memory Management for Vision Tasks and Beyond,"Given the ability to model more realistic and dynamic problems, Federated
Continual Learning (FCL) has been increasingly investigated recently. A
well-known problem encountered in this setting is the so-called catastrophic
forgetting, for which the learning model is inclined to focus on more recent
tasks while forgetting the previously learned knowledge. The majority of the
current approaches in FCL propose generative-based solutions to solve said
problem. However, this setting requires multiple training epochs over the data,
implying an offline setting where datasets are stored locally and remain
unchanged over time. Furthermore, the proposed solutions are tailored for
vision tasks solely. To overcome these limitations, we propose a new approach
to deal with different modalities in the online scenario where new data arrive
in streams of mini-batches that can only be processed once. To solve
catastrophic forgetting, we propose an uncertainty-aware memory-based approach.
Specifically, we suggest using an estimator based on the Bregman Information
(BI) to compute the model's variance at the sample level. Through measures of
predictive uncertainty, we retrieve samples with specific characteristics, and
- by retraining the model on such samples - we demonstrate the potential of
this approach to reduce the forgetting effect in realistic settings while
maintaining data confidentiality and competitive communication efficiency
compared to state-of-the-art approaches.",2024-05-29,"Giuseppe Serra, Florian Buettner",http://arxiv.org/pdf/2405.18925v3,cs.LG
GLANCE: Global Actions in a Nutshell for Counterfactual Explainability,"The widespread deployment of machine learning systems in critical real-world
decision-making applications has highlighted the urgent need for counterfactual
explainability methods that operate effectively. Global counterfactual
explanations, expressed as actions to offer recourse, aim to provide succinct
explanations and insights applicable to large population subgroups.
Effectiveness is measured by the fraction of the population that is provided
recourse, ensuring that the actions benefit as many individuals as possible.
Keeping the cost of actions low ensures the proposed recourse actions remain
practical and actionable. Limiting the number of actions that provide global
counterfactuals is essential to maximize interpretability. The primary
challenge, therefore, is balancing these trade-offs, i.e., maximizing
effectiveness, minimizing cost, while maintaining a small number of actions. We
introduce GLANCE, a versatile and adaptive framework, comprising two
algorithms, that allows the careful balancing of the trade-offs among the three
key objectives, with the size objective functioning as a tunable parameter to
keep the actions few and easy to interpret. C-GLANCE employs a clustering
approach that considers both the feature space and the space of counterfactual
actions, thereby accounting for the distribution of points in a way that aligns
with the structure of the model. T-GLANCE provides additional features to
enhance flexibility. It employs a tree-based approach, that allows users to
specify split features, to build a decision tree with a single counterfactual
action at each node that can be used as a subgroup policy. Our extensive
experimental evaluation demonstrates that our method consistently shows greater
robustness and performance compared to existing methods across various datasets
and models.",2024-05-29,"Loukas Kavouras, Eleni Psaroudaki, Konstantinos Tsopelas, Dimitrios Rontogiannis, Nikolaos Theologitis, Dimitris Sacharidis, Giorgos Giannopoulos, Dimitrios Tomaras, Kleopatra Markou, Dimitrios Gunopulos, Dimitris Fotakis, Ioannis Emiris",http://arxiv.org/pdf/2405.18921v2,cs.LG
"Computing low-thrust transfers in the asteroid belt, a comparison between astrodynamical manipulations and a machine learning approach","Low-thrust trajectories play a crucial role in optimizing scientific output
and cost efficiency in asteroid belt missions. Unlike high-thrust transfers,
low-thrust trajectories require solving complex optimal control problems. This
complexity grows exponentially with the number of asteroids visited due to
orbital mechanics intricacies. In the literature, methods for approximating
low-thrust transfers without full optimization have been proposed, including
analytical and machine learning techniques. In this work, we propose new
analytical approximations and compare their accuracy and performance to machine
learning methods. While analytical approximations leverage orbit theory to
estimate trajectory costs, machine learning employs a more black-box approach,
utilizing neural networks to predict optimal transfers based on various
attributes. We build a dataset of about 3 million transfers, found by solving
the time and fuel optimal control problems, for different time of flights,
which we also release open-source. Comparison between the two methods on this
database reveals the superiority of machine learning, especially for longer
transfers. Despite challenges such as multi revolution transfers, both
approaches maintain accuracy within a few percent in the final mass errors, on
a database of trajectories involving numerous asteroids. This work contributes
to the efficient exploration of mission opportunities in the asteroid belt,
providing insights into the strengths and limitations of different
approximation strategies.",2024-05-29,"Giacomo Acciarini, Laurent Beauregard, Dario Izzo",http://arxiv.org/pdf/2405.18918v1,cs.LG
Causal Action Influence Aware Counterfactual Data Augmentation,"Offline data are both valuable and practical resources for teaching robots
complex behaviors. Ideally, learning agents should not be constrained by the
scarcity of available demonstrations, but rather generalize beyond the training
distribution. However, the complexity of real-world scenarios typically
requires huge amounts of data to prevent neural network policies from picking
up on spurious correlations and learning non-causal relationships. We propose
CAIAC, a data augmentation method that can create feasible synthetic
transitions from a fixed dataset without having access to online environment
interactions. By utilizing principled methods for quantifying causal influence,
we are able to perform counterfactual reasoning by swapping
$\it{action}$-unaffected parts of the state-space between independent
trajectories in the dataset. We empirically show that this leads to a
substantial increase in robustness of offline learning algorithms against
distributional shift.",2024-05-29,"Núria Armengol Urpí, Marco Bagatella, Marin Vlastelica, Georg Martius",http://arxiv.org/pdf/2405.18917v2,cs.LG
Time-Series Foundation Models for Forecasting Soil Moisture Levels in Smart Agriculture,"The recent surge in foundation models for natural language processing and
computer vision has fueled innovation across various domains. Inspired by this
progress, we explore the potential of foundation models for time-series
forecasting in smart agriculture, a field often plagued by limited data
availability. Specifically, this work presents a novel application of
$\texttt{TimeGPT}$, a state-of-the-art (SOTA) time-series foundation model, to
predict soil water potential ($\psi_\mathrm{soil}$), a key indicator of field
water status that is typically used for irrigation advice. Traditionally, this
task relies on a wide array of input variables. We explore
$\psi_\mathrm{soil}$'s ability to forecast $\psi_\mathrm{soil}$ in: ($i$) a
zero-shot setting, ($ii$) a fine-tuned setting relying solely on historic
$\psi_\mathrm{soil}$ measurements, and ($iii$) a fine-tuned setting where we
also add exogenous variables to the model. We compare $\texttt{TimeGPT}$'s
performance to established SOTA baseline models for forecasting
$\psi_\mathrm{soil}$. Our results demonstrate that $\texttt{TimeGPT}$ achieves
competitive forecasting accuracy using only historical $\psi_\mathrm{soil}$
data, highlighting its remarkable potential for agricultural applications. This
research paves the way for foundation time-series models for sustainable
development in agriculture by enabling forecasting tasks that were
traditionally reliant on extensive data collection and domain expertise.",2024-05-29,"Boje Deforce, Bart Baesens, Estefanía Serral Asensio",http://arxiv.org/pdf/2405.18913v3,cs.LG
NeuralODEs for VLEO simulations: Introducing thermoNET for Thermosphere Modeling,"We introduce a novel neural architecture termed thermoNET, designed to
represent thermospheric density in satellite orbital propagation using a
reduced amount of differentiable computations. Due to the appearance of a
neural network on the right-hand side of the equations of motion, the resulting
satellite dynamics is governed by a NeuralODE, a neural Ordinary Differential
Equation, characterized by its fully differentiable nature, allowing the
derivation of variational equations (hence of the state transition matrix) and
facilitating its use in connection to advanced numerical techniques such as
Taylor-based numerical propagation and differential algebraic techniques.
Efficient training of the network parameters occurs through two distinct
approaches. In the first approach, the network undergoes training independently
of spacecraft dynamics, engaging in a pure regression task against ground truth
models, including JB-08 and NRLMSISE-00. In the second paradigm, network
parameters are learned based on observed dynamics, adapting through ODE
sensitivities. In both cases, the outcome is a flexible, compact model of the
thermosphere density greatly enhancing numerical propagation efficiency while
maintaining accuracy in the orbital predictions.",2024-05-29,"Dario Izzo, Giacomo Acciarini, Francesco Biscani",http://arxiv.org/pdf/2405.19384v1,cs.LG
Language Generation with Strictly Proper Scoring Rules,"Language generation based on maximum likelihood estimation (MLE) has become
the fundamental approach for text generation. Maximum likelihood estimation is
typically performed by minimizing the log-likelihood loss, also known as the
logarithmic score in statistical decision theory. The logarithmic score is
strictly proper in the sense that it encourages honest forecasts, where the
expected score is maximized only when the model reports true probabilities.
Although many strictly proper scoring rules exist, the logarithmic score is the
only local scoring rule among them that depends exclusively on the probability
of the observed sample, making it capable of handling the exponentially large
sample space of natural text. In this work, we propose a straightforward
strategy for adapting scoring rules to language generation, allowing for
language modeling with any non-local scoring rules. Leveraging this strategy,
we train language generation models using two classic strictly proper scoring
rules, the Brier score and the Spherical score, as alternatives to the
logarithmic score. Experimental results indicate that simply substituting the
loss function, without adjusting other hyperparameters, can yield substantial
improvements in model's generation capabilities. Moreover, these improvements
can scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B.
Source code: \url{https://github.com/shaochenze/ScoringRulesLM}.",2024-05-29,"Chenze Shao, Fandong Meng, Yijin Liu, Jie Zhou",http://arxiv.org/pdf/2405.18906v1,cs.LG
A Causal Framework for Evaluating Deferring Systems,"Deferring systems extend supervised Machine Learning (ML) models with the
possibility to defer predictions to human experts. However, evaluating the
impact of a deferring strategy on system accuracy is still an overlooked area.
This paper fills this gap by evaluating deferring systems through a causal
lens. We link the potential outcomes framework for causal inference with
deferring systems, which allows to identify the causal impact of the deferring
strategy on predictive accuracy. We distinguish two scenarios. In the first
one, we have access to both the human and ML model predictions for the deferred
instances. Here, we can identify the individual causal effects for deferred
instances and the aggregates of them. In the second one, only human predictions
are available for the deferred instances. Here, we can resort to regression
discontinuity designs to estimate a local causal effect. We evaluate our
approach on synthetic and real datasets for seven deferring systems from the
literature.",2024-05-29,"Filippo Palomba, Andrea Pugnana, José Manuel Alvarez, Salvatore Ruggieri",http://arxiv.org/pdf/2405.18902v2,cs.LG
Unit-Aware Genetic Programming for the Development of Empirical Equations,"When developing empirical equations, domain experts require these to be
accurate and adhere to physical laws. Often, constants with unknown units need
to be discovered alongside the equations. Traditional unit-aware genetic
programming (GP) approaches cannot be used when unknown constants with
undetermined units are included. This paper presents a method for dimensional
analysis that propagates unknown units as ''jokers'' and returns the magnitude
of unit violations. We propose three methods, namely evolutive culling, a
repair mechanism, and a multi-objective approach, to integrate the dimensional
analysis in the GP algorithm. Experiments on datasets with ground truth
demonstrate comparable performance of evolutive culling and the multi-objective
approach to a baseline without dimensional analysis. Extensive analysis of the
results on datasets without ground truth reveals that the unit-aware algorithms
make only low sacrifices in accuracy, while producing unit-adherent solutions.
Overall, we presented a promising novel approach for developing unit-adherent
empirical equations.",2024-05-29,"Julia Reuter, Viktor Martinek, Roland Herzog, Sanaz Mostaghim",http://arxiv.org/pdf/2405.18896v1,cs.LG
Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural Networks Using One Bayesian Test Vector,"The performance of deep learning algorithms such as neural networks (NNs) has
increased tremendously recently, and they can achieve state-of-the-art
performance in many domains. However, due to memory and computation resource
constraints, implementing NNs on edge devices is a challenging task. Therefore,
hardware accelerators such as computation-in-memory (CIM) with memristive
devices have been developed to accelerate the most common operations, i.e.,
matrix-vector multiplication. However, due to inherent device properties,
external environmental factors such as temperature, and an immature fabrication
process, memristors suffer from various non-idealities, including defects and
variations occurring during manufacturing and runtime. Consequently, there is a
lack of complete confidence in the predictions made by the model. To improve
confidence in NN predictions made by hardware accelerators in the presence of
device non-idealities, in this paper, we propose a Bayesian test vector
generation framework that can estimate the model uncertainty of NNs implemented
on memristor-based CIM hardware. Compared to the conventional point estimate
test vector generation method, our method is more generalizable across
different model dimensions and requires storing only one test Bayesian vector
in the hardware. Our method is evaluated on different model dimensions, tasks,
fault rates, and variation noise to show that it can consistently achieve
$100\%$ coverage with only $0.024$ MB of memory overhead.",2024-05-29,"Soyed Tuhin Ahmed, Mehdi Tahoori",http://arxiv.org/pdf/2405.18894v1,cs.LG
Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation,"Money laundering presents a pervasive challenge, burdening society by
financing illegal activities. The use of network information is increasingly
being explored to more effectively combat money laundering, given it involves
connected parties. This led to a surge in research on network analytics (NA)
for anti-money laundering (AML). The literature on NA for AML is, however,
fragmented and a comprehensive overview of existing work is missing. This
results in limited understanding of the methods to apply and their comparative
detection power. Therefore, this paper presents an extensive and unique
literature review, based on 97 papers from Web of Science and Scopus, resulting
in a taxonomy following a recently proposed fraud analytics framework. We
conclude that most research relies on expert-based rules and manual features,
while deep learning methods have been gaining traction. This paper also
presents a comprehensive framework to evaluate and compare the performance of
prominent NA methods in a standardized setup. We apply it on two publicly
available data sets, comparing manual feature engineering, random walk-based,
and deep learning methods. We conclude that (1) network analytics increases the
predictive power, but caution is needed when applying GNNs based on the class
imbalance and network topology, and that (2) care should be taken with
open-source data as this can give overly optimistic results. The open-source
implementation facilitates researchers and practitioners to extend upon the
results and experiment on proprietary data, promoting a standardized approach
for the analysis and evaluation of network analytics for AML.",2024-05-29,"Bruno Deprez, Toon Vanderschueren, Bart Baesens, Tim Verdonck, Wouter Verbeke",http://arxiv.org/pdf/2405.19383v3,cs.LG
Locally Estimated Global Perturbations are Better than Local Perturbations for Federated Sharpness-aware Minimization,"In federated learning (FL), the multi-step update and data heterogeneity
among clients often lead to a loss landscape with sharper minima, degenerating
the performance of the resulted global model. Prevalent federated approaches
incorporate sharpness-aware minimization (SAM) into local training to mitigate
this problem. However, the local loss landscapes may not accurately reflect the
flatness of global loss landscape in heterogeneous environments; as a result,
minimizing local sharpness and calculating perturbations on client data might
not align the efficacy of SAM in FL with centralized training. To overcome this
challenge, we propose FedLESAM, a novel algorithm that locally estimates the
direction of global perturbation on client side as the difference between
global models received in the previous active and current rounds. Besides the
improved quality, FedLESAM also speed up federated SAM-based approaches since
it only performs once backpropagation in each iteration. Theoretically, we
prove a slightly tighter bound than its original FedSAM by ensuring consistent
perturbation. Empirically, we conduct comprehensive experiments on four
federated benchmark datasets under three partition strategies to demonstrate
the superior performance and efficiency of FedLESAM.",2024-05-29,"Ziqing Fan, Shengchao Hu, Jiangchao Yao, Gang Niu, Ya Zhang, Masashi Sugiyama, Yanfeng Wang",http://arxiv.org/pdf/2405.18890v1,cs.LG
Proactive Load-Shaping Strategies with Privacy-Cost Trade-offs in Residential Households based on Deep Reinforcement Learning,"Smart meters play a crucial role in enhancing energy management and
efficiency, but they raise significant privacy concerns by potentially
revealing detailed user behaviors through energy consumption patterns. Recent
scholarly efforts have focused on developing battery-aided load-shaping
techniques to protect user privacy while balancing costs. This paper proposes a
novel deep reinforcement learning-based load-shaping algorithm (PLS-DQN)
designed to protect user privacy by proactively creating artificial load
signatures that mislead potential attackers. We evaluate our proposed algorithm
against a non-intrusive load monitoring (NILM) adversary. The results
demonstrate that our approach not only effectively conceals real energy usage
patterns but also outperforms state-of-the-art methods in enhancing user
privacy while maintaining cost efficiency.",2024-05-29,"Ruichang Zhang, Youcheng Sun, Mustafa A. Mustafa",http://arxiv.org/pdf/2405.18888v1,cs.LG
Compressing Large Language Models using Low Rank and Low Precision Decomposition,"The prohibitive sizes of Large Language Models (LLMs) today make it difficult
to deploy them on memory-constrained edge devices. This work introduces $\rm
CALDERA$ -- a new post-training LLM compression algorithm that harnesses the
inherent low-rank structure of a weight matrix $\mathbf{W}$ by approximating it
via a low-rank, low-precision decomposition as $\mathbf{W} \approx \mathbf{Q} +
\mathbf{L}\mathbf{R}$. Here, $\mathbf{L}$ and $\mathbf{R}$ are low rank
factors, and the entries of $\mathbf{Q}$, $\mathbf{L}$ and $\mathbf{R}$ are
quantized. The model is compressed by substituting each layer with its
$\mathbf{Q} + \mathbf{L}\mathbf{R}$ decomposition, and the zero-shot
performance of the compressed model is evaluated. Additionally, $\mathbf{L}$
and $\mathbf{R}$ are readily amenable to low-rank adaptation, consequently
enhancing the zero-shot performance. $\rm CALDERA$ obtains this decomposition
by formulating it as an optimization problem
$\min_{\mathbf{Q},\mathbf{L},\mathbf{R}}\lVert(\mathbf{Q} +
\mathbf{L}\mathbf{R} - \mathbf{W})\mathbf{X}^\top\rVert_{\rm F}^2$, where
$\mathbf{X}$ is the calibration data, and $\mathbf{Q}, \mathbf{L}, \mathbf{R}$
are constrained to be representable using low-precision formats. Theoretical
upper bounds on the approximation error of $\rm CALDERA$ are established using
a rank-constrained regression framework, and the tradeoff between compression
ratio and model performance is studied by analyzing the impact of target rank
and quantization bit budget. Results illustrate that compressing LlaMa-$2$
$7$B/$13B$/$70$B and LlaMa-$3$ $8$B models using $\rm CALDERA$ outperforms
existing post-training LLM compression techniques in the regime of less than
$2.5$ bits per parameter. The implementation is available at:
https://github.com/pilancilab/caldera.",2024-05-29,"Rajarshi Saha, Naomi Sagan, Varun Srivastava, Andrea J. Goldsmith, Mert Pilanci",http://arxiv.org/pdf/2405.18886v2,cs.LG
Inference-Time Alignment of Diffusion Models with Direct Noise Optimization,"In this work, we focus on the alignment problem of diffusion models with a
continuous reward function, which represents specific objectives for downstream
tasks, such as increasing darkness or improving the aesthetics of images. The
central goal of the alignment problem is to adjust the distribution learned by
diffusion models such that the generated samples maximize the target reward
function. We propose a novel alignment approach, named Direct Noise
Optimization (DNO), that optimizes the injected noise during the sampling
process of diffusion models. By design, DNO operates at inference-time, and
thus is tuning-free and prompt-agnostic, with the alignment occurring in an
online fashion during generation. We rigorously study the theoretical
properties of DNO and also propose variants to deal with non-differentiable
reward functions. Furthermore, we identify that naive implementation of DNO
occasionally suffers from the out-of-distribution reward hacking problem, where
optimized samples have high rewards but are no longer in the support of the
pretrained distribution. To remedy this issue, we leverage classical
high-dimensional statistics theory to an effective probability regularization
technique. We conduct extensive experiments on several important reward
functions and demonstrate that the proposed DNO approach can achieve
state-of-the-art reward scores within a reasonable time budget for generation.",2024-05-29,"Zhiwei Tang, Jiangweizhi Peng, Jiasheng Tang, Mingyi Hong, Fan Wang, Tsung-Hui Chang",http://arxiv.org/pdf/2405.18881v3,cs.LG
Spatiotemporal Forecasting Meets Efficiency: Causal Graph Process Neural Networks,"Graph Neural Networks (GNNs) have advanced spatiotemporal forecasting by
leveraging relational inductive biases among sensors (or any other measuring
scheme) represented as nodes in a graph. However, current methods often rely on
Recurrent Neural Networks (RNNs), leading to increased runtimes and memory use.
Moreover, these methods typically operate within 1-hop neighborhoods,
exacerbating the reduction of the receptive field. Causal Graph Processes
(CGPs) offer an alternative, using graph filters instead of MLP layers to
reduce parameters and minimize memory consumption. This paper introduces the
Causal Graph Process Neural Network (CGProNet), a non-linear model combining
CGPs and GNNs for spatiotemporal forecasting. CGProNet employs higher-order
graph filters, optimizing the model with fewer parameters, reducing memory
usage, and improving runtime efficiency. We present a comprehensive theoretical
and experimental stability analysis, highlighting key aspects of CGProNet.
Experiments on synthetic and real data demonstrate CGProNet's superior
efficiency, minimizing memory and time requirements while maintaining
competitive forecasting performance.",2024-05-29,"Aref Einizade, Fragkiskos D. Malliaros, Jhony H. Giraldo",http://arxiv.org/pdf/2405.18879v1,cs.LG
Privacy Preserving Data Imputation via Multi-party Computation for Medical Applications,"Handling missing data is crucial in machine learning, but many datasets
contain gaps due to errors or non-response. Unlike traditional methods such as
listwise deletion, which are simple but inadequate, the literature offers more
sophisticated and effective methods, thereby improving sample size and
accuracy. However, these methods require accessing the whole dataset, which
contradicts the privacy regulations when the data is distributed among multiple
sources. Especially in the medical and healthcare domain, such access reveals
sensitive information about patients. This study addresses privacy-preserving
imputation methods for sensitive data using secure multi-party computation,
enabling secure computations without revealing any party's sensitive
information. In this study, we realized the mean, median, regression, and kNN
imputation methods in a privacy-preserving way. We specifically target the
medical and healthcare domains considering the significance of protection of
the patient data, showcasing our methods on a diabetes dataset. Experiments on
the diabetes dataset validated the correctness of our privacy-preserving
imputation methods, yielding the largest error around $3 \times 10^{-3}$,
closely matching plaintext methods. We also analyzed the scalability of our
methods to varying numbers of samples, showing their applicability to
real-world healthcare problems. Our analysis demonstrated that all our methods
scale linearly with the number of samples. Except for kNN, the runtime of all
our methods indicates that they can be utilized for large datasets.",2024-05-29,"Julia Jentsch, Ali Burak Ünal, Şeyma Selcan Mağara, Mete Akgün",http://arxiv.org/pdf/2405.18878v1,cs.LG
Continuous Product Graph Neural Networks,"Processing multidomain data defined on multiple graphs holds significant
potential in various practical applications in computer science. However,
current methods are mostly limited to discrete graph filtering operations.
Tensorial partial differential equations on graphs (TPDEGs) provide a
principled framework for modeling structured data across multiple interacting
graphs, addressing the limitations of the existing discrete methodologies. In
this paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that
emerge as a natural solution to the TPDEG. CITRUS leverages the separability of
continuous heat kernels from Cartesian graph products to efficiently implement
graph spectral decomposition. We conduct thorough theoretical analyses of the
stability and over-smoothing properties of CITRUS in response to
domain-specific graph perturbations and graph spectra effects on the
performance. We evaluate CITRUS on well-known traffic and weather
spatiotemporal forecasting datasets, demonstrating superior performance over
existing approaches. The implementation codes are available at
https://github.com/ArefEinizade2/CITRUS.",2024-05-29,"Aref Einizade, Fragkiskos D. Malliaros, Jhony H. Giraldo",http://arxiv.org/pdf/2405.18877v2,cs.LG
$ε$-Optimally Solving Zero-Sum POSGs,"A recent method for solving zero-sum partially observable stochastic games
(zs-POSGs) embeds the original game into a new one called the occupancy Markov
game. This reformulation allows applying Bellman's principle of optimality to
solve zs-POSGs. However, improving a current solution requires solving a linear
program with exponentially many potential constraints, which significantly
restricts the scalability of this approach. This paper exploits the optimal
value function's novel uniform continuity properties to overcome this
limitation. We first construct a new operator that is computationally more
efficient than the state-of-the-art update rules without compromising
optimality. In particular, improving a current solution now involves a linear
program with an exponential drop in constraints. We then also show that
point-based value iteration algorithms utilizing our findings improve the
scalability of existing methods while maintaining guarantees in various
domains.",2024-05-29,"Erwan Escudie, Matthia Sabatelli, Jilles Dibangoye",http://arxiv.org/pdf/2406.00054v1,cs.LG
DFAMiner: Mining minimal separating DFAs from labelled samples,"We propose DFAMiner, a passive learning tool for learning minimal separating
deterministic finite automata (DFA) from a set of labelled samples. Separating
automata are an interesting class of automata that occurs generally in regular
model checking and has raised interest in foundational questions of parity game
solving. We first propose a simple and linear-time algorithm that incrementally
constructs a three-valued DFA (3DFA) from a set of labelled samples given in
the usual lexicographical order. This 3DFA has accepting and rejecting states
as well as don't-care states, so that it can exactly recognise the labelled
examples. We then apply our tool to mining a minimal separating DFA for the
labelled samples by minimising the constructed automata via a reduction to
solving SAT problems. Empirical evaluation shows that our tool outperforms
current state-of-the-art tools significantly on standard benchmarks for
learning minimal separating DFAs from samples. Progress in the efficient
construction of separating DFAs can also lead to finding the lower bound of
parity game solving, where we show that DFAMiner can create optimal separating
automata for simple languages with up to 7 colours. Future improvements might
offer inroads to better data structures.",2024-05-29,"Daniele Dell'Erba, Yong Li, Sven Schewe",http://arxiv.org/pdf/2405.18871v1,cs.LG
Towards Data-Driven Electricity Management: Multi-Region Harmonized Data and Knowledge Graph,"Due to growing population and technological advances, global electricity
consumption, and consequently also CO2 emissions are increasing. The
residential sector makes up 25% of global electricity consumption and has great
potential to increase efficiency and reduce CO2 footprint without sacrificing
comfort. However, a lack of uniform consumption data at the household level
spanning multiple regions hinders large-scale studies and robust multi-region
model development. This paper introduces a multi-region dataset compiled from
publicly available sources and presented in a uniform format. This data enables
machine learning tasks such as disaggregation, demand forecasting, appliance
ON/OFF classification, etc. Furthermore, we develop an RDF knowledge graph that
characterizes the electricity consumption of the households and contextualizes
it with household related properties enabling semantic queries and
interoperability with other open knowledge bases like Wikidata and DBpedia.
This structured data can be utilized to inform various stakeholders towards
data-driven policy and business development.",2024-05-29,"Vid Hanžel, Blaž Bertalanič, Carolina Fortuna",http://arxiv.org/pdf/2405.18869v1,cs.LG
Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts,"This paper presents a Domain-Inspired Sharpness-Aware Minimization (DISAM)
algorithm for optimization under domain shifts. It is motivated by the
inconsistent convergence degree of SAM across different domains, which induces
optimization bias towards certain domains and thus impairs the overall
convergence. To address this issue, we consider the domain-level convergence
consistency in the sharpness estimation to prevent the overwhelming (deficient)
perturbations for less (well) optimized domains. Specifically, DISAM introduces
the constraint of minimizing variance in the domain loss, which allows the
elastic gradient calibration in perturbation generation: when one domain is
optimized above the averaging level \textit{w.r.t.} loss, the gradient
perturbation towards that domain will be weakened automatically, and vice
versa. Under this mechanism, we theoretically show that DISAM can achieve
faster overall convergence and improved generalization in principle when
inconsistent convergence emerges. Extensive experiments on various domain
generalization benchmarks show the superiority of DISAM over a range of
state-of-the-art methods. Furthermore, we show the superior efficiency of DISAM
in parameter-efficient fine-tuning combined with the pretraining models. The
source code is released at https://github.com/MediaBrain-SJTU/DISAM.",2024-05-29,"Ruipeng Zhang, Ziqing Fan, Jiangchao Yao, Ya Zhang, Yanfeng Wang",http://arxiv.org/pdf/2405.18861v1,cs.LG
Anomaly Detection by Context Contrasting,"Anomaly detection focuses on identifying samples that deviate from the norm.
When working with high-dimensional data such as images, a crucial requirement
for detecting anomalous patterns is learning lower-dimensional representations
that capture concepts of normality. Recent advances in self-supervised learning
have shown great promise in this regard. However, many successful
self-supervised anomaly detection methods assume prior knowledge about
anomalies to create synthetic outliers during training. Yet, in real-world
applications, we often do not know what to expect from unseen data, and we can
solely leverage knowledge about normal data. In this work, we propose Con$_2$,
which learns representations through context augmentations that allow us to
observe samples from two distinct perspectives while keeping the invariances of
normal data. Con$_2$ learns rich representations of context-augmented samples
by clustering them according to their context while simultaneously aligning
their positions across clusters. At test time, representations of anomalies
that do not adhere to the invariances of normal data then deviate from their
respective context cluster. Learning representations in such a way thus allows
us to detect anomalies without making assumptions about anomalous data.",2024-05-29,"Alain Ryser, Thomas M. Sutter, Alexander Marx, Julia E. Vogt",http://arxiv.org/pdf/2405.18848v2,cs.LG
"Simulation, Modelling and Classification of Wiki Contributors: Spotting The Good, The Bad, and The Ugly","Data crowdsourcing is a data acquisition process where groups of voluntary
contributors feed platforms with highly relevant data ranging from news,
comments, and media to knowledge and classifications. It typically processes
user-generated data streams to provide and refine popular services such as
wikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,
this modus operandi raises severe concerns regarding ill-intentioned data
manipulation in adversarial environments. This paper presents a simulation,
modelling, and classification approach to automatically identify human and
non-human (bots) as well as benign and malign contributors by using data
fabrication to balance classes within experimental data sets, data stream
modelling to build and update contributor profiles and, finally, autonomic data
stream classification. By employing WikiVoyage - a free worldwide wiki travel
guide open to contribution from the general public - as a testbed, our approach
proves to significantly boost the confidence and quality of the classifier by
using a class-balanced data stream, comprising both real and synthetic data.
Our empirical results show that the proposed method distinguishes between
benign and malign bots as well as human contributors with a classification
accuracy of up to 92 %.",2024-05-29,"Silvia García Méndez, Fátima Leal, Benedita Malheiro, Juan Carlos Burguillo Rial, Bruno Veloso, Adriana E. Chis, Horacio González Vélez",http://arxiv.org/pdf/2405.18845v1,cs.LG
Data-driven Machinery Fault Diagnosis: A Comprehensive Review,"In this era of advanced manufacturing, it's now more crucial than ever to
diagnose machine faults as early as possible to guarantee their safe and
efficient operation. With the massive surge in industrial big data and
advancement in sensing and computational technologies, data-driven Machinery
Fault Diagnosis (MFD) solutions based on machine/deep learning approaches have
been used ubiquitously in manufacturing. Timely and accurately identifying
faulty machine signals is vital in industrial applications for which many
relevant solutions have been proposed and are reviewed in many articles.
Despite the availability of numerous solutions and reviews on MFD, existing
works often lack several aspects. Most of the available literature has limited
applicability in a wide range of manufacturing settings due to their
concentration on a particular type of equipment or method of analysis.
Additionally, discussions regarding the challenges associated with implementing
data-driven approaches, such as dealing with noisy data, selecting appropriate
features, and adapting models to accommodate new or unforeseen faults, are
often superficial or completely overlooked. Thus, this survey provides a
comprehensive review of the articles using different types of machine learning
approaches for the detection and diagnosis of various types of machinery
faults, highlights their strengths and limitations, provides a review of the
methods used for condition-based analyses, comprehensively discusses the
available machinery fault datasets, introduces future researchers to the
possible challenges they have to encounter while using these approaches for MFD
and recommends the probable solutions to mitigate those problems. The future
research prospects are also pointed out for a better understanding of the
field. We believe this article will help researchers and contribute to the
further development of the field.",2024-05-29,"Dhiraj Neupane, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal",http://arxiv.org/pdf/2405.18843v2,cs.LG
Do Finetti: On Causal Effects for Exchangeable Data,"We study causal effect estimation in a setting where the data are not i.i.d.
(independent and identically distributed). We focus on exchangeable data
satisfying an assumption of independent causal mechanisms. Traditional causal
effect estimation frameworks, e.g., relying on structural causal models and
do-calculus, are typically limited to i.i.d. data and do not extend to more
general exchangeable generative processes, which naturally arise in
multi-environment data. To address this gap, we develop a generalized framework
for exchangeable data and introduce a truncated factorization formula that
facilitates both the identification and estimation of causal effects in our
setting. To illustrate potential applications, we introduce a causal P\'olya
urn model and demonstrate how intervention propagates effects in exchangeable
data settings. Finally, we develop an algorithm that performs simultaneous
causal discovery and effect estimation given multi-environment data.",2024-05-29,"Siyuan Guo, Chi Zhang, Karthika Mohan, Ferenc Huszár, Bernhard Schölkopf",http://arxiv.org/pdf/2405.18836v1,cs.LG
MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models,"Mixture-of-Experts (MoE) large language models (LLM) have memory requirements
that often exceed the GPU memory capacity, requiring costly parameter movement
from secondary memories to the GPU for expert computation. In this work, we
present Mixture of Near-Data Experts (MoNDE), a near-data computing solution
that efficiently enables MoE LLM inference. MoNDE reduces the volume of MoE
parameter movement by transferring only the $\textit{hot}$ experts to the GPU,
while computing the remaining $\textit{cold}$ experts inside the host memory
device. By replacing the transfers of massive expert parameters with the ones
of small activations, MoNDE enables far more communication-efficient MoE
inference, thereby resulting in substantial speedups over the existing
parameter offloading frameworks for both encoder and decoder operations.",2024-05-29,"Taehyun Kim, Kwanseok Choi, Youngmock Cho, Jaehoon Cho, Hyuk-Jae Lee, Jaewoong Sim",http://arxiv.org/pdf/2405.18832v1,cs.LG
Evaluating Zero-Shot GPT-4V Performance on 3D Visual Question Answering Benchmarks,"As interest in ""reformulating"" the 3D Visual Question Answering (VQA) problem
in the context of foundation models grows, it is imperative to assess how these
new paradigms influence existing closed-vocabulary datasets. In this case
study, we evaluate the zero-shot performance of foundational models (GPT-4
Vision and GPT-4) on well-established 3D VQA benchmarks, namely 3D-VQA and
ScanQA. We provide an investigation to contextualize the performance of
GPT-based agents relative to traditional modeling approaches. We find that
GPT-based agents without any fine-tuning perform on par with the closed
vocabulary approaches. Our findings corroborate recent results that ""blind""
models establish a surprisingly strong baseline in closed-vocabulary settings.
We demonstrate that agents benefit significantly from scene-specific vocabulary
via in-context textual grounding. By presenting a preliminary comparison with
previous baselines, we hope to inform the community's ongoing efforts to refine
multi-modal 3D benchmarks.",2024-05-29,"Simranjit Singh, Georgios Pavlakos, Dimitrios Stamoulis",http://arxiv.org/pdf/2405.18831v1,cs.LG
Flow Priors for Linear Inverse Problems via Iterative Corrupted Trajectory Matching,"Generative models based on flow matching have attracted significant attention
for their simplicity and superior performance in high-resolution image
synthesis. By leveraging the instantaneous change-of-variables formula, one can
directly compute image likelihoods from a learned flow, making them enticing
candidates as priors for downstream tasks such as inverse problems. In
particular, a natural approach would be to incorporate such image probabilities
in a maximum-a-posteriori (MAP) estimation problem. A major obstacle, however,
lies in the slow computation of the log-likelihood, as it requires
backpropagating through an ODE solver, which can be prohibitively slow for
high-dimensional problems. In this work, we propose an iterative algorithm to
approximate the MAP estimator efficiently to solve a variety of linear inverse
problems. Our algorithm is mathematically justified by the observation that the
MAP objective can be approximated by a sum of $N$ ``local MAP'' objectives,
where $N$ is the number of function evaluations. By leveraging Tweedie's
formula, we show that we can perform gradient steps to sequentially optimize
these objectives. We validate our approach for various linear inverse problems,
such as super-resolution, deblurring, inpainting, and compressed sensing, and
demonstrate that we can outperform other methods based on flow matching. Code
is available at https://github.com/YasminZhang/ICTM.",2024-05-29,"Yasi Zhang, Peiyu Yu, Yaxuan Zhu, Yingshan Chang, Feng Gao, Ying Nian Wu, Oscar Leong",http://arxiv.org/pdf/2405.18816v4,cs.LG
Semiring Activation in Neural Networks,"We introduce a class of trainable nonlinear operators based on semirings that
are suitable for use in neural networks. These operators generalize the
traditional alternation of linear operators with activation functions in neural
networks. Semirings are algebraic structures that describe a generalised
notation of linearity, greatly expanding the range of trainable operators that
can be included in neural networks. In fact, max- or min-pooling operations are
convolutions in the tropical semiring with a fixed kernel.
  We perform experiments where we replace the activation functions for
trainable semiring-based operators to show that these are viable operations to
include in fully connected as well as convolutional neural networks (ConvNeXt).
We discuss some of the challenges of replacing traditional activation functions
with trainable semiring activations and the trade-offs of doing so.",2024-05-29,"Bart M. N. Smets, Peter D. Donker, Jim W. Portegies",http://arxiv.org/pdf/2405.18805v4,cs.LG
Federated Q-Learning with Reference-Advantage Decomposition: Almost Optimal Regret and Logarithmic Communication Cost,"In this paper, we consider model-free federated reinforcement learning for
tabular episodic Markov decision processes. Under the coordination of a central
server, multiple agents collaboratively explore the environment and learn an
optimal policy without sharing their raw data. Despite recent advances in
federated Q-learning algorithms achieving near-linear regret speedup with low
communication cost, existing algorithms only attain suboptimal regrets compared
to the information bound. We propose a novel model-free federated Q-learning
algorithm, termed FedQ-Advantage. Our algorithm leverages reference-advantage
decomposition for variance reduction and operates under two distinct
mechanisms: synchronization between the agents and the server, and policy
update, both triggered by events. We prove that our algorithm not only requires
a lower logarithmic communication cost but also achieves an almost optimal
regret, reaching the information bound up to a logarithmic factor and
near-linear regret speedup compared to its single-agent counterpart when the
time horizon is sufficiently large.",2024-05-29,"Zhong Zheng, Haochen Zhang, Lingzhou Xue",http://arxiv.org/pdf/2405.18795v2,cs.LG
Policy Zooming: Adaptive Discretization-based Infinite-Horizon Average-Reward Reinforcement Learning,"We study Lipschitz MDPs in the infinite-horizon average-reward reinforcement
learning (RL) setup in which an agent can play policies from a given set
$\Phi$. The proposed algorithms ``zoom'' into ``promising'' regions of the
policy space, thereby achieving adaptivity gains. We upper bound their regret
as $\tilde{\mathcal{O}}\big(T^{1 - d_{\text{eff.}}^{-1}}\big)$, where
$d_{\text{eff.}} = d^\Phi_z+2$ for model-free algorithm~\textit{PZRL-MF} and
$d_{\text{eff.}} = 2d_\mathcal{S} + d^\Phi_z + 3$ for model-based
algorithm~\textit{PZRL-MB}. Here, $d_\mathcal{S}$ is the dimension of the state
space, and $d^\Phi_z$ is the zooming dimension. $d^\Phi_z$ is a
problem-dependent quantity that depends not only on the underlying MDP, but
also on the class $\Phi$. This yields us a low regret in case the agent
competes against a low-complexity $\Phi$ (that has a small $d^\Phi_z$). We note
that the preexisting notions of zooming dimension are inept at handling the
non-episodic RL and do not yield adaptivity gains. The current work shows how
to capture adaptivity gains for infinite-horizon average-reward RL in terms of
$d^\Phi_z$. When specialized to the case of finite-dimensional policy space, we
obtain that $d_{\text{eff.}}$ scales as the dimension of this space under mild
technical conditions; and also obtain $d_{\text{eff.}} = 0$, or equivalently
$\tilde{\mathcal{O}}(\sqrt{T})$ regret for \textit{PZRL-MF}, under a curvature
condition on the average reward function that is commonly used in the
multi-armed bandit (MAB) literature. Simulation experiments validate the gains
arising due to adaptivity.",2024-05-29,"Avik Kar, Rahul Singh",http://arxiv.org/pdf/2405.18793v3,cs.LG
Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies,"We consider off-policy evaluation (OPE) of deterministic target policies for
reinforcement learning (RL) in environments with continuous action spaces.
While it is common to use importance sampling for OPE, it suffers from high
variance when the behavior policy deviates significantly from the target
policy. In order to address this issue, some recent works on OPE proposed
in-sample learning with importance resampling. Yet, these approaches are not
applicable to deterministic target policies for continuous action spaces. To
address this limitation, we propose to relax the deterministic target policy
using a kernel and learn the kernel metrics that minimize the overall mean
squared error of the estimated temporal difference update vector of an action
value function, where the action value function is used for policy evaluation.
We derive the bias and variance of the estimation error due to this relaxation
and provide analytic solutions for the optimal kernel metric. In empirical
studies using various test domains, we show that the OPE with in-sample
learning using the kernel with optimized metric achieves significantly improved
accuracy than other baselines.",2024-05-29,"Haanvid Lee, Tri Wahyu Guntara, Jongmin Lee, Yung-Kyun Noh, Kee-Eung Kim",http://arxiv.org/pdf/2405.18792v1,cs.LG
A Machine Learning Approach for Identifying Anatomical Biomarkers of Early Mild Cognitive Impairment,"Alzheimer Disease poses a significant challenge, necessitating early
detection for effective intervention. MRI is a key neuroimaging tool due to its
ease of use and cost effectiveness. This study analyzes machine learning
methods for MRI based biomarker selection and classification to distinguish
between healthy controls and those who develop mild cognitive impairment within
five years. Using 3 Tesla MRI data from ADNI and OASIS 3, we applied various
machine learning techniques, including MATLAB Classification Learner app,
nested cross validation, and Bayesian optimization. Data harmonization with
polynomial regression improved performance. Consistent features identified were
the entorhinal, hippocampus, lateral ventricle, and lateral orbitofrontal
regions. For balanced ADNI data, Naive Bayes with z score harmonization
performed best. For balanced OASIS 3, SVM with z score correction excelled. In
imbalanced data, RUSBoost showed strong performance on ADNI and OASIS 3. Z
score harmonization highlighted the potential of a semi automatic pipeline for
early AD detection using MRI.",2024-05-29,"Alwani Liyana Ahmad, Jose Sanchez-Bornot, Roberto C. Sotero, Damien Coyle, Zamzuri Idris, Ibrahima Faye",http://arxiv.org/pdf/2407.00040v2,cs.LG
MOKD: Cross-domain Finetuning for Few-shot Classification via Maximizing Optimized Kernel Dependence,"In cross-domain few-shot classification, \emph{nearest centroid classifier}
(NCC) aims to learn representations to construct a metric space where few-shot
classification can be performed by measuring the similarities between samples
and the prototype of each class. An intuition behind NCC is that each sample is
pulled closer to the class centroid it belongs to while pushed away from those
of other classes. However, in this paper, we find that there exist high
similarities between NCC-learned representations of two samples from different
classes. In order to address this problem, we propose a bi-level optimization
framework, \emph{maximizing optimized kernel dependence} (MOKD) to learn a set
of class-specific representations that match the cluster structures indicated
by labeled data of the given task. Specifically, MOKD first optimizes the
kernel adopted in \emph{Hilbert-Schmidt independence criterion} (HSIC) to
obtain the optimized kernel HSIC (opt-HSIC) that can capture the dependence
more precisely. Then, an optimization problem regarding the opt-HSIC is
addressed to simultaneously maximize the dependence between representations and
labels and minimize the dependence among all samples. Extensive experiments on
Meta-Dataset demonstrate that MOKD can not only achieve better generalization
performance on unseen domains in most cases but also learn better data
representation clusters. The project repository of MOKD is available at:
\href{https://github.com/tmlr-group/MOKD}{https://github.com/tmlr-group/MOKD}.",2024-05-29,"Hongduan Tian, Feng Liu, Tongliang Liu, Bo Du, Yiu-ming Cheung, Bo Han",http://arxiv.org/pdf/2405.18786v1,cs.LG
On the Role of Attention Masks and LayerNorm in Transformers,"Self-attention is the key mechanism of transformers, which are the essential
building blocks of modern foundation models. Recent studies have shown that
pure self-attention suffers from an increasing degree of rank collapse as depth
increases, limiting model expressivity and further utilization of model depth.
The existing literature on rank collapse, however, has mostly overlooked other
critical components in transformers that may alleviate the rank collapse issue.
In this paper, we provide a general analysis of rank collapse under
self-attention, taking into account the effects of attention masks and layer
normalization (LayerNorm). In particular, we find that although pure masked
attention still suffers from exponential collapse to a rank one subspace,
sparse or local masked attention can provably slow down the collapse rate. In
the case of self-attention with LayerNorm, we first show that for certain
classes of value matrices, collapse to a rank one subspace still happens
exponentially. However, through construction of nontrivial counterexamples, we
then establish that with proper choice of value matrices, a general class of
sequences may not converge to a rank one subspace, and the self-attention
dynamics with LayerNorm can simultaneously possess a rich set of equilibria
with any possible rank between one and full. Our result refutes the previous
hypothesis that LayerNorm plays no role in the rank collapse of self-attention
and suggests that self-attention with LayerNorm constitutes a much more
expressive, versatile nonlinear dynamical system than what was originally
thought.",2024-05-29,"Xinyi Wu, Amir Ajorlou, Yifei Wang, Stefanie Jegelka, Ali Jadbabaie",http://arxiv.org/pdf/2405.18781v2,cs.LG
Certifying Counterfactual Bias in LLMs,"Large Language Models (LLMs) can produce biased responses that can cause
representational harms. However, conventional studies are insufficient to
thoroughly evaluate biases across LLM responses for different demographic
groups (a.k.a. counterfactual bias), as they do not scale to large number of
inputs and do not provide guarantees. Therefore, we propose the first
framework, LLMCert-B that certifies LLMs for counterfactual bias on
distributions of prompts. A certificate consists of high-confidence bounds on
the probability of unbiased LLM responses for any set of counterfactual prompts
- prompts differing by demographic groups, sampled from a distribution. We
illustrate counterfactual bias certification for distributions of
counterfactual prompts created by applying prefixes sampled from prefix
distributions, to a given set of prompts. We consider prefix distributions
consisting random token sequences, mixtures of manual jailbreaks, and
perturbations of jailbreaks in LLM's embedding space. We generate non-trivial
certificates for SOTA LLMs, exposing their vulnerabilities over distributions
of prompts generated from computationally inexpensive prefix distributions.",2024-05-29,"Isha Chaudhary, Qian Hu, Manoj Kumar, Morteza Ziyadi, Rahul Gupta, Gagandeep Singh",http://arxiv.org/pdf/2405.18780v3,cs.LG
SPABA: A Single-Loop and Probabilistic Stochastic Bilevel Algorithm Achieving Optimal Sample Complexity,"While stochastic bilevel optimization methods have been extensively studied
for addressing large-scale nested optimization problems in machine learning, it
remains an open question whether the optimal complexity bounds for solving
bilevel optimization are the same as those in single-level optimization. Our
main result resolves this question: SPABA, an adaptation of the PAGE method for
nonconvex optimization in (Li et al., 2021) to the bilevel setting, can achieve
optimal sample complexity in both the finite-sum and expectation settings. We
show the optimality of SPABA by proving that there is no gap in complexity
analysis between stochastic bilevel and single-level optimization when
implementing PAGE. Notably, as indicated by the results of (Dagr\'eou et al.,
2022), there might exist a gap in complexity analysis when implementing other
stochastic gradient estimators, like SGD and SAGA. In addition to SPABA, we
propose several other single-loop stochastic bilevel algorithms, that either
match or improve the state-of-the-art sample complexity results, leveraging our
convergence rate and complexity analysis. Numerical experiments demonstrate the
superior practical performance of the proposed methods.",2024-05-29,"Tianshu Chu, Dachuan Xu, Wei Yao, Jin Zhang",http://arxiv.org/pdf/2405.18777v1,cs.LG
LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models,"Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants
have been proposed to ensure rigorous privacy for fine-tuning large-scale
pre-trained language models. However, they rely heavily on the Gaussian
mechanism, which may overly perturb the gradients and degrade the accuracy,
especially in stronger privacy regimes (e.g., the privacy budget $\epsilon <
3$). To address such limitations, we propose a novel Language Model-based
Optimal Differential Privacy (LMO-DP) mechanism, which takes the first step to
enable the tight composition of accurately fine-tuning (large) language models
with a sub-optimal DP mechanism, even in strong privacy regimes (e.g., $0.1\leq
\epsilon<3$). Furthermore, we propose a novel offline optimal noise search
method to efficiently derive the sub-optimal DP that significantly reduces the
noise magnitude. For instance, fine-tuning RoBERTa-large (with 300M parameters)
on the SST-2 dataset can achieve an accuracy of 92.20% (given $\epsilon=0.3$,
$\delta=10^{-10}$) by drastically outperforming the Gaussian mechanism (e.g.,
$\sim 50\%$ for small $\epsilon$ and $\delta$). We also draw similar findings
on the text generation tasks on GPT-2. Finally, to our best knowledge, LMO-DP
is also the first solution to accurately fine-tune Llama-2 with strong
differential privacy guarantees. The code will be released soon and available
upon request.",2024-05-29,"Qin Yang, Meisam Mohammad, Han Wang, Ali Payani, Ashish Kundu, Kai Shu, Yan Yan, Yuan Hong",http://arxiv.org/pdf/2405.18776v1,cs.LG
RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching,"The growing significance of RNA engineering in diverse biological
applications has spurred interest in developing AI methods for structure-based
RNA design. While diffusion models have excelled in protein design, adapting
them for RNA presents new challenges due to RNA's conformational flexibility
and the computational cost of fine-tuning large structure prediction models. To
this end, we propose RNAFlow, a flow matching model for protein-conditioned RNA
sequence-structure design. Its denoising network integrates an RNA inverse
folding model and a pre-trained RosettaFold2NA network for generation of RNA
sequences and structures. The integration of inverse folding in the structure
denoising process allows us to simplify training by fixing the structure
prediction network. We further enhance the inverse folding model by
conditioning it on inferred conformational ensembles to model dynamic RNA
conformations. Evaluation on protein-conditioned RNA structure and sequence
generation tasks demonstrates RNAFlow's advantage over existing RNA design
methods.",2024-05-29,"Divya Nori, Wengong Jin",http://arxiv.org/pdf/2405.18768v2,cs.LG
Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI,"The current electroencephalogram (EEG) based deep learning models are
typically designed for specific datasets and applications in brain-computer
interaction (BCI), limiting the scale of the models and thus diminishing their
perceptual capabilities and generalizability. Recently, Large Language Models
(LLMs) have achieved unprecedented success in text processing, prompting us to
explore the capabilities of Large EEG Models (LEMs). We hope that LEMs can
break through the limitations of different task types of EEG datasets, and
obtain universal perceptual capabilities of EEG signals through unsupervised
pre-training. Then the models can be fine-tuned for different downstream tasks.
However, compared to text data, the volume of EEG datasets is generally small
and the format varies widely. For example, there can be mismatched numbers of
electrodes, unequal length data samples, varied task designs, and low
signal-to-noise ratio. To overcome these challenges, we propose a unified
foundation model for EEG called Large Brain Model (LaBraM). LaBraM enables
cross-dataset learning by segmenting the EEG signals into EEG channel patches.
Vector-quantized neural spectrum prediction is used to train a semantically
rich neural tokenizer that encodes continuous raw EEG channel patches into
compact neural codes. We then pre-train neural Transformers by predicting the
original neural codes for the masked EEG channel patches. The LaBraMs were
pre-trained on about 2,500 hours of various types of EEG signals from around 20
datasets and validated on multiple different types of downstream tasks.
Experiments on abnormal detection, event type classification, emotion
recognition, and gait prediction show that our LaBraM outperforms all compared
SOTA methods in their respective fields. Our code is available at
https://github.com/935963004/LaBraM.",2024-05-29,"Wei-Bang Jiang, Li-Ming Zhao, Bao-Liang Lu",http://arxiv.org/pdf/2405.18765v1,cs.LG
FDQN: A Flexible Deep Q-Network Framework for Game Automation,"In reinforcement learning, it is often difficult to automate
high-dimensional, rapid decision-making in dynamic environments, especially
when domains require real-time online interaction and adaptive strategies such
as web-based games. This work proposes a state-of-the-art Flexible Deep
Q-Network (FDQN) framework that can address this challenge with a selfadaptive
approach that is processing high-dimensional sensory data in realtime using a
CNN and dynamically adapting the model architecture to varying action spaces of
different gaming environments and outperforming previous baseline models in
various Atari games and the Chrome Dino game as baselines. Using the
epsilon-greedy policy, it effectively balances the new learning and
exploitation for improved performance, and it has been designed with a modular
structure that it can be easily adapted to other HTML-based games without
touching the core part of the framework. It is demonstrated that the FDQN
framework can successfully solve a well-defined task in a laboratory condition,
but more importantly it also discusses potential applications to more
challenging real-world cases and serve as the starting point for future further
exploration into automated game play and beyond.",2024-05-29,Prabhath Reddy Gujavarthy,http://arxiv.org/pdf/2405.18761v1,cs.LG
Learning to Continually Learn with the Bayesian Principle,"In the present era of deep learning, continual learning research is mainly
focused on mitigating forgetting when training a neural network with stochastic
gradient descent on a non-stationary stream of data. On the other hand, in the
more classical literature of statistical machine learning, many models have
sequential Bayesian update rules that yield the same learning outcome as the
batch training, i.e., they are completely immune to catastrophic forgetting.
However, they are often overly simple to model complex real-world data. In this
work, we adopt the meta-learning paradigm to combine the strong
representational power of neural networks and simple statistical models'
robustness to forgetting. In our novel meta-continual learning framework,
continual learning takes place only in statistical models via ideal sequential
Bayesian update rules, while neural networks are meta-learned to bridge the raw
data and the statistical models. Since the neural networks remain fixed during
continual learning, they are protected from catastrophic forgetting. This
approach not only achieves significantly improved performance but also exhibits
excellent scalability. Since our approach is domain-agnostic and
model-agnostic, it can be applied to a wide range of problems and easily
integrated with existing model architectures.",2024-05-29,"Soochan Lee, Hyeonseong Jeon, Jaehyeon Son, Gunhee Kim",http://arxiv.org/pdf/2405.18758v1,cs.LG
Provable Contrastive Continual Learning,"Continual learning requires learning incremental tasks with dynamic data
distributions. So far, it has been observed that employing a combination of
contrastive loss and distillation loss for training in continual learning
yields strong performance. To the best of our knowledge, however, this
contrastive continual learning framework lacks convincing theoretical
explanations. In this work, we fill this gap by establishing theoretical
performance guarantees, which reveal how the performance of the model is
bounded by training losses of previous tasks in the contrastive continual
learning framework. Our theoretical explanations further support the idea that
pre-training can benefit continual learning. Inspired by our theoretical
analysis of these guarantees, we propose a novel contrastive continual learning
algorithm called CILA, which uses adaptive distillation coefficients for
different tasks. These distillation coefficients are easily computed by the
ratio between average distillation losses and average contrastive losses from
previous tasks. Our method shows great improvement on standard benchmarks and
achieves new state-of-the-art performance.",2024-05-29,"Yichen Wen, Zhiquan Tan, Kaipeng Zheng, Chuanlong Xie, Weiran Huang",http://arxiv.org/pdf/2405.18756v1,cs.LG
GIST: Greedy Independent Set Thresholding for Diverse Data Summarization,"We introduce a novel subset selection problem called min-distance
diversification with monotone submodular utility ($\textsf{MDMS}$), which has a
wide variety of applications in machine learning, e.g., data sampling and
feature selection. Given a set of points in a metric space, the goal of
$\textsf{MDMS}$ is to maximize an objective function combining a monotone
submodular utility term and a min-distance diversity term between any pair of
selected points, subject to a cardinality constraint. We propose the
$\texttt{GIST}$ algorithm, which achieves a $\frac{1}{2}$-approximation
guarantee for $\textsf{MDMS}$ by approximating a series of maximum independent
set problems with a bicriteria greedy algorithm. We also prove that it is
NP-hard to approximate to within a factor of $0.5584$. Finally, we demonstrate
that $\texttt{GIST}$ outperforms existing benchmarks for on a real-world image
classification task that studies single-shot subset selection for ImageNet.",2024-05-29,"Matthew Fahrbach, Srikumar Ramalingam, Morteza Zadimoghaddam, Sara Ahmadian, Gui Citovsky, Giulia DeSalvo",http://arxiv.org/pdf/2405.18754v2,cs.LG
Confronting the Reproducibility Crisis: A Case Study of Challenges in Cybersecurity AI,"In the rapidly evolving field of cybersecurity, ensuring the reproducibility
of AI-driven research is critical to maintaining the reliability and integrity
of security systems. This paper addresses the reproducibility crisis within the
domain of adversarial robustness -- a key area in AI-based cybersecurity that
focuses on defending deep neural networks against malicious perturbations.
Through a detailed case study, we attempt to validate results from prior work
on certified robustness using the VeriGauge toolkit, revealing significant
challenges due to software and hardware incompatibilities, version conflicts,
and obsolescence. Our findings underscore the urgent need for standardized
methodologies, containerization, and comprehensive documentation to ensure the
reproducibility of AI models deployed in critical cybersecurity applications.
By tackling these reproducibility challenges, we aim to contribute to the
broader discourse on securing AI systems against advanced persistent threats,
enhancing network and IoT security, and protecting critical infrastructure.
This work advocates for a concerted effort within the research community to
prioritize reproducibility, thereby strengthening the foundation upon which
future cybersecurity advancements are built.",2024-05-29,"Richard H. Moulton, Gary A. McCully, John D. Hastings",http://arxiv.org/pdf/2405.18753v2,cs.LG
A SARS-CoV-2 Interaction Dataset and VHH Sequence Corpus for Antibody Language Models,"Antibodies are crucial proteins produced by the immune system to eliminate
harmful foreign substances and have become pivotal therapeutic agents for
treating human diseases. To accelerate the discovery of antibody therapeutics,
there is growing interest in constructing language models using antibody
sequences. However, the applicability of pre-trained language models for
antibody discovery has not been thoroughly evaluated due to the scarcity of
labeled datasets. To overcome these limitations, we introduce AVIDa-SARS-CoV-2,
a dataset featuring the antigen-variable domain of heavy chain of heavy chain
antibody (VHH) interactions obtained from two alpacas immunized with severe
acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike proteins.
AVIDa-SARS-CoV-2 includes binary labels indicating the binding or non-binding
of diverse VHH sequences to 12 SARS-CoV-2 mutants, such as the Delta and
Omicron variants. Furthermore, we release VHHCorpus-2M, a pre-training dataset
for antibody language models, containing over two million VHH sequences. We
report benchmark results for predicting SARS-CoV-2-VHH binding using VHHBERT
pre-trained on VHHCorpus-2M and existing general protein and antibody-specific
pre-trained language models. These results confirm that AVIDa-SARS-CoV-2
provides valuable benchmarks for evaluating the representation capabilities of
antibody language models for binding prediction, thereby facilitating the
development of AI-driven antibody discovery. The datasets are available at
https://datasets.cognanous.com.",2024-05-29,"Hirofumi Tsuruta, Hiroyuki Yamazaki, Ryota Maeda, Ryotaro Tamura, Akihiro Imura",http://arxiv.org/pdf/2405.18749v3,cs.LG
STIQ: Safeguarding Training and Inferencing of Quantum Neural Networks from Untrusted Cloud,"The high expenses imposed by current quantum cloud providers, coupled with
the escalating need for quantum resources, may incentivize the emergence of
cheaper cloud-based quantum services from potentially untrusted providers.
Deploying or hosting quantum models, such as Quantum Neural Networks (QNNs), on
these untrusted platforms introduces a myriad of security concerns, with the
most critical one being model theft. This vulnerability stems from the cloud
provider's full access to these circuits during training and/or inference. In
this work, we introduce STIQ, a novel ensemble-based strategy designed to
safeguard QNNs against such cloud-based adversaries. Our method innovatively
trains two distinct QNNs concurrently, hosting them on same or different
platforms, in a manner that each network yields obfuscated outputs rendering
the individual QNNs ineffective for adversaries operating within cloud
environments. However, when these outputs are combined locally (using an
aggregate function), they reveal the correct result. Through extensive
experiments across various QNNs and datasets, our technique has proven to
effectively masks the accuracy and losses of the individually hosted models by
upto $76\%$, albeit at the expense of $\leq 2\times$ increase in the total
computational overhead. This trade-off, however, is a small price to pay for
the enhanced security and integrity of QNNs in a cloud-based environment prone
to untrusted adversaries. We also demonstrated STIQ's practical application by
evaluating it on multiple real quantum hardwares, showing that STIQ achieves up
to $\approx 70\%$ obfuscation, with combined performance similar to an
unobfuscated model.",2024-05-29,"Satwik Kundu, Swaroop Ghosh",http://arxiv.org/pdf/2405.18746v2,cs.LG
Approximate Thompson Sampling for Learning Linear Quadratic Regulators with $O(\sqrt{T})$ Regret,"We propose an approximate Thompson sampling algorithm that learns linear
quadratic regulators (LQR) with an improved Bayesian regret bound of
$O(\sqrt{T})$. Our method leverages Langevin dynamics with a meticulously
designed preconditioner as well as a simple excitation mechanism. We show that
the excitation signal induces the minimum eigenvalue of the preconditioner to
grow over time, thereby accelerating the approximate posterior sampling
process. Moreover, we identify nontrivial concentration properties of the
approximate posteriors generated by our algorithm. These properties enable us
to bound the moments of the system state and attain an $O(\sqrt{T})$ regret
bound without the unrealistic restrictive assumptions on parameter sets that
are often used in the literature.",2024-05-29,"Yeoneung Kim, Gihun Kim, Insoon Yang",http://arxiv.org/pdf/2405.19380v1,cs.LG
Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts,"This paper presents a novel approach to extract scientifically valuable
information about Earth's physical phenomena from unconventional sources, such
as multi-modal social media posts. Employing a state-of-the-art large language
model (LLM), Gemini 1.5 Pro (Reid et al. 2024), we estimate earthquake ground
shaking intensity from these unstructured posts. The model's output, in the
form of Modified Mercalli Intensity (MMI) values, aligns well with independent
observational data. Furthermore, our results suggest that LLMs, trained on vast
internet data, may have developed a unique understanding of physical phenomena.
Specifically, Google's Gemini models demonstrate a simplified understanding of
the general relationship between earthquake magnitude, distance, and MMI
intensity, accurately describing observational data even though it's not
identical to established models. These findings raise intriguing questions
about the extent to which Gemini's training has led to a broader understanding
of the physical world and its phenomena. The ability of Generative AI models
like Gemini to generate results consistent with established scientific
knowledge highlights their potential to augment our understanding of complex
physical phenomena like earthquakes. The flexible and effective approach
proposed in this study holds immense potential for enriching our understanding
of the impact of physical phenomena and improving resilience during natural
disasters. This research is a significant step toward harnessing the power of
social media and AI for natural disaster mitigation, opening new avenues for
understanding the emerging capabilities of Generative AI and LLMs for
scientific applications.",2024-05-29,"S. Mostafa Mousavi, Marc Stogaitis, Tajinder Gadh, Richard M Allen, Alexei Barski, Robert Bosch, Patrick Robertson, Nivetha Thiruverahan, Youngmin Cho, Aman Raj",http://arxiv.org/pdf/2405.18732v3,cs.LG
Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning,"Offline reinforcement learning (RL) aims to learn optimal policies from
previously collected datasets. Recently, due to their powerful representational
capabilities, diffusion models have shown significant potential as policy
models for offline RL issues. However, previous offline RL algorithms based on
diffusion policies generally adopt weighted regression to improve the policy.
This approach optimizes the policy only using the collected actions and is
sensitive to Q-values, which limits the potential for further performance
enhancement. To this end, we propose a novel preferred-action-optimized
diffusion policy for offline RL. In particular, an expressive conditional
diffusion model is utilized to represent the diverse distribution of a behavior
policy. Meanwhile, based on the diffusion model, preferred actions within the
same behavior distribution are automatically generated through the critic
function. Moreover, an anti-noise preference optimization is designed to
achieve policy improvement by using the preferred actions, which can adapt to
noise-preferred actions for stable training. Extensive experiments demonstrate
that the proposed method provides competitive or superior performance compared
to previous state-of-the-art offline RL methods, particularly in sparse reward
tasks such as Kitchen and AntMaze. Additionally, we empirically prove the
effectiveness of anti-noise preference optimization.",2024-05-29,"Tianle Zhang, Jiayi Guan, Lin Zhao, Yihang Li, Dongjiang Li, Zecui Zeng, Lei Sun, Yue Chen, Xuelong Wei, Lusong Li, Xiaodong He",http://arxiv.org/pdf/2405.18729v1,cs.LG
Can We Enhance the Quality of Mobile Crowdsensing Data Without Ground Truth?,"Mobile crowdsensing (MCS) has emerged as a prominent trend across various
domains. However, ensuring the quality of the sensing data submitted by mobile
users (MUs) remains a complex and challenging problem. To address this
challenge, an advanced method is needed to detect low-quality sensing data and
identify malicious MUs that may disrupt the normal operations of an MCS system.
Therefore, this article proposes a prediction- and reputation-based truth
discovery (PRBTD) framework, which can separate low-quality data from
high-quality data in sensing tasks. First, we apply a correlation-focused
spatio-temporal Transformer network that learns from the historical sensing
data and predicts the ground truth of the data submitted by MUs. However, due
to the noise in historical data for training and the bursty values within
sensing data, the prediction results can be inaccurate. To address this issue,
we use the implications among the sensing data, which are learned from the
prediction results but are stable and less affected by inaccurate predictions,
to evaluate the quality of the data. Finally, we design a reputation-based
truth discovery (TD) module for identifying low-quality data with their
implications. Given the sensing data submitted by MUs, PRBTD can eliminate the
data with heavy noise and identify malicious MUs with high accuracy. Extensive
experimental results demonstrate that the PRBTD method outperforms existing
methods in terms of identification accuracy and data quality enhancement.",2024-05-29,"Jiajie Li, Bo Gu, Shimin Gong, Zhou Su, Mohsen Guizani",http://arxiv.org/pdf/2405.18725v2,cs.LG
Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction,"Accurate prediction of molecular properties is crucial in drug discovery.
Traditional methods often overlook that real-world molecules typically exhibit
multiple property labels with complex correlations. To this end, we propose a
novel framework, HiPM, which stands for hierarchical prompted molecular
representation learning framework. HiPM leverages task-aware prompts to enhance
the differential expression of tasks in molecular representations and mitigate
negative transfer caused by conflicts in individual task information. Our
framework comprises two core components: the Molecular Representation Encoder
(MRE) and the Task-Aware Prompter (TAP). MRE employs a hierarchical
message-passing network architecture to capture molecular features at both the
atom and motif levels. Meanwhile, TAP utilizes agglomerative hierarchical
clustering algorithm to construct a prompt tree that reflects task affinity and
distinctiveness, enabling the model to consider multi-granular correlation
information among tasks, thereby effectively handling the complexity of
multi-label property prediction. Extensive experiments demonstrate that HiPM
achieves state-of-the-art performance across various multi-label datasets,
offering a novel perspective on multi-label molecular representation learning.",2024-05-29,"Linjia Kang, Songhua Zhou, Shuyan Fang, Shichao Liu",http://arxiv.org/pdf/2405.18724v2,cs.LG
Conformal Depression Prediction,"While existing depression prediction methods based on deep learning show
promise, their practical application is hindered by the lack of
trustworthiness, as these deep models are often deployed as black box models,
leaving us uncertain on the confidence of their predictions. For high-risk
clinical applications like depression prediction, uncertainty quantification is
essential in decision-making. In this paper, we introduce conformal depression
prediction (CDP), a depression prediction method with uncertainty
quantification based on conformal prediction (CP), giving valid confidence
intervals with theoretical coverage guarantees for the model predictions. CDP
is a plug-and-play module that requires neither model retraining nor an
assumption about the depression data distribution. As CDP provides only an
average coverage guarantee across all inputs rather than per-input performance
guarantee, we further propose CDP-ACC, an improved conformal prediction with
approximate conditional coverage. CDP-ACC firstly estimates the prediction
distribution through neighborhood relaxation, and then introduces a conformal
score function by constructing nested sequences, so as to provide a tighter
prediction interval adaptive to specific input. We empirically demonstrate the
application of CDP in uncertainty-aware facial depression prediction, as well
as the effectiveness and superiority of CDP-ACC on the AVEC 2013 and AVEC 2014
datasets. Our code is publicly available at https://github.com/PushineLee/CDP.",2024-05-29,"Yonghong Li, Xiuzhuang Zhou",http://arxiv.org/pdf/2405.18723v3,cs.LG
To FP8 and Back Again: Quantifying Reduced Precision Effects on LLM Training Stability,"The massive computational costs associated with large language model (LLM)
pretraining have spurred great interest in reduced-precision floating-point
representations to accelerate the process. As a result, the BrainFloat16 (BF16)
precision has become the de facto standard for LLM training, with hardware
support included in recent generations of accelerators. This trend has gone
even further in the latest processors, where FP8 has recently been introduced.
However, prior experience with FP16, which was found to be less stable than
BF16, raises concerns as to whether FP8, with even fewer bits than FP16, can be
a cost-effective option for LLM training. We argue that reduced-precision
training schemes must have similar training stability and hyperparameter
sensitivities to their higher-precision counterparts in order to be
cost-effective. However, we find that currently available methods for FP8
training are not robust enough to allow their use as economical replacements.
This prompts us to investigate the stability of reduced-precision LLM training
in terms of robustness across random seeds, learning rates, and datasets. To
this end, we propose new evaluation techniques and a new metric for quantifying
loss landscape sharpness in autoregressive language models. By simulating
incremental bit reductions in floating-point representations, we analyze the
relationship between representational power and training stability with the
intent of aiding future research into the field.",2024-05-29,"Joonhyung Lee, Jeongin Bae, Byeongwook Kim, Se Jung Kwon, Dongsoo Lee",http://arxiv.org/pdf/2405.18710v2,cs.LG
Adaptive and Parallel Split Federated Learning in Vehicular Edge Computing,"Vehicular edge intelligence (VEI) is a promising paradigm for enabling future
intelligent transportation systems by accommodating artificial intelligence
(AI) at the vehicular edge computing (VEC) system. Federated learning (FL)
stands as one of the fundamental technologies facilitating collaborative model
training locally and aggregation, while safeguarding the privacy of vehicle
data in VEI. However, traditional FL faces challenges in adapting to vehicle
heterogeneity, training large models on resource-constrained vehicles, and
remaining susceptible to model weight privacy leakage. Meanwhile, split
learning (SL) is proposed as a promising collaborative learning framework which
can mitigate the risk of model wights leakage, and release the training
workload on vehicles. SL sequentially trains a model between a vehicle and an
edge cloud (EC) by dividing the entire model into a vehicle-side model and an
EC-side model at a given cut layer. In this work, we combine the advantages of
SL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular
Edge Computing (ASFV). The ASFV scheme adaptively splits the model and
parallelizes the training process, taking into account mobile vehicle selection
and resource allocation. Our extensive simulations, conducted on
non-independent and identically distributed data, demonstrate that the proposed
ASFV solution significantly reduces training latency compared to existing
benchmarks, while adapting to network dynamics and vehicles' mobility.",2024-05-29,"Xianke Qiang, Zheng Chang, Yun Hu, Lei Liu, Timo Hamalainen",http://arxiv.org/pdf/2405.18707v1,cs.LG
Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees,"The field of risk-constrained reinforcement learning (RCRL) has been
developed to effectively reduce the likelihood of worst-case scenarios by
explicitly handling risk-measure-based constraints. However, the nonlinearity
of risk measures makes it challenging to achieve convergence and optimality. To
overcome the difficulties posed by the nonlinearity, we propose a spectral risk
measure-constrained RL algorithm, spectral-risk-constrained policy optimization
(SRCPO), a bilevel optimization approach that utilizes the duality of spectral
risk measures. In the bilevel optimization structure, the outer problem
involves optimizing dual variables derived from the risk measures, while the
inner problem involves finding an optimal policy given these dual variables.
The proposed method, to the best of our knowledge, is the first to guarantee
convergence to an optimum in the tabular setting. Furthermore, the proposed
method has been evaluated on continuous control tasks and showed the best
performance among other RCRL algorithms satisfying the constraints.",2024-05-29,"Dohyeong Kim, Taehyun Cho, Seungyub Han, Hojun Chung, Kyungjae Lee, Songhwai Oh",http://arxiv.org/pdf/2405.18698v1,cs.LG
DeepHGNN: Study of Graph Neural Network based Forecasting Methods for Hierarchically Related Multivariate Time Series,"Graph Neural Networks (GNN) have gained significant traction in the
forecasting domain, especially for their capacity to simultaneously account for
intra-series temporal correlations and inter-series relationships. This paper
introduces a novel Hierarchical GNN (DeepHGNN) framework, explicitly designed
for forecasting in complex hierarchical structures. The uniqueness of DeepHGNN
lies in its innovative graph-based hierarchical interpolation and an end-to-end
reconciliation mechanism. This approach ensures forecast accuracy and coherence
across various hierarchical levels while sharing signals across them,
addressing a key challenge in hierarchical forecasting. A critical insight in
hierarchical time series is the variance in forecastability across levels, with
upper levels typically presenting more predictable components. DeepHGNN
capitalizes on this insight by pooling and leveraging knowledge from all
hierarchy levels, thereby enhancing the overall forecast accuracy. Our
comprehensive evaluation set against several state-of-the-art models confirm
the superior performance of DeepHGNN. This research not only demonstrates
DeepHGNN's effectiveness in achieving significantly improved forecast accuracy
but also contributes to the understanding of graph-based methods in
hierarchical time series forecasting.",2024-05-29,"Abishek Sriramulu, Nicolas Fourrier, Christoph Bergmeir",http://arxiv.org/pdf/2405.18693v1,cs.LG
Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation,"Preference-based reinforcement learning (PbRL) has shown impressive
capabilities in training agents without reward engineering. However, a notable
limitation of PbRL is its dependency on substantial human feedback. This
dependency stems from the learning loop, which entails accurate reward learning
compounded with value/policy learning, necessitating a considerable number of
samples. To boost the learning loop, we propose SEER, an efficient PbRL method
that integrates label smoothing and policy regularization techniques. Label
smoothing reduces overfitting of the reward model by smoothing human preference
labels. Additionally, we bootstrap a conservative estimate $\widehat{Q}$ using
well-supported state-action pairs from the current replay memory to mitigate
overestimation bias and utilize it for policy learning regularization. Our
experimental results across a variety of complex tasks, both in online and
offline settings, demonstrate that our approach improves feedback efficiency,
outperforming state-of-the-art methods by a large margin. Ablation studies
further reveal that SEER achieves a more accurate Q-function compared to prior
work.",2024-05-29,"Fengshuo Bai, Rui Zhao, Hongming Zhang, Sijia Cui, Ying Wen, Yaodong Yang, Bo Xu, Lei Han",http://arxiv.org/pdf/2405.18688v1,cs.LG
Advancing Household Robotics: Deep Interactive Reinforcement Learning for Efficient Training and Enhanced Performance,"The market for domestic robots made to perform household chores is growing as
these robots relieve people of everyday responsibilities. Domestic robots are
generally welcomed for their role in easing human labor, in contrast to
industrial robots, which are frequently criticized for displacing human
workers. But before these robots can carry out domestic chores, they need to
become proficient in several minor activities, such as recognizing their
surroundings, making decisions, and picking up on human behaviors.
Reinforcement learning, or RL, has emerged as a key robotics technology that
enables robots to interact with their environment and learn how to optimize
their actions to maximize rewards. However, the goal of Deep Reinforcement
Learning is to address more complicated, continuous action-state spaces in
real-world settings by combining RL with Neural Networks. The efficacy of
DeepRL can be further augmented through interactive feedback, in which a
trainer offers real-time guidance to expedite the robot's learning process.
Nevertheless, the current methods have drawbacks, namely the transient
application of guidance that results in repeated learning under identical
conditions. Therefore, we present a novel method to preserve and reuse
information and advice via Deep Interactive Reinforcement Learning, which
utilizes a persistent rule-based system. This method not only expedites the
training process but also lessens the number of repetitions that instructors
will have to carry out. This study has the potential to advance the development
of household robots and improve their effectiveness and efficiency as learners.",2024-05-29,"Arpita Soni, Sujatha Alla, Suresh Dodda, Hemanth Volikatla",http://arxiv.org/pdf/2405.18687v1,cs.LG
Rejection via Learning Density Ratios,"Classification with rejection emerges as a learning paradigm which allows
models to abstain from making predictions. The predominant approach is to alter
the supervised learning pipeline by augmenting typical loss functions, letting
model rejection incur a lower loss than an incorrect prediction. Instead, we
propose a different distributional perspective, where we seek to find an
idealized data distribution which maximizes a pretrained model's performance.
This can be formalized via the optimization of a loss's risk with a
$\varphi$-divergence regularization term. Through this idealized distribution,
a rejection decision can be made by utilizing the density ratio between this
distribution and the data distribution. We focus on the setting where our
$\varphi$-divergences are specified by the family of $\alpha$-divergence. Our
framework is tested empirically over clean and noisy datasets.",2024-05-29,"Alexander Soen, Hisham Husain, Philip Schulz, Vu Nguyen",http://arxiv.org/pdf/2405.18686v2,cs.LG
Improved Robustness and Hyperparameter Selection in the Dense Associative Memory,"The Dense Associative Memory generalizes the Hopfield network by allowing for
sharper interaction functions. This increases the capacity of the network as an
autoassociative memory as nearby learned attractors will not interfere with one
another. However, the implementation of the network relies on applying large
exponents to the dot product of memory vectors and probe vectors. If the
dimension of the data is large the calculation can be very large and result in
imprecisions and overflow when using floating point numbers in a practical
implementation. We describe the computational issues in detail, modify the
original network description to mitigate the problem, and show the modification
will not alter the networks' dynamics during update or training. We also show
our modification greatly improves hyperparameter selection for the Dense
Associative Memory, removing dependence on the interaction vertex and resulting
in an optimal region of hyperparameters that does not significantly change with
the interaction vertex as it does in the original network.",2024-05-29,"Hayden McAlister, Anthony Robins, Lech Szymanski",http://arxiv.org/pdf/2407.08742v4,cs.LG
Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension,"Large language models (LLMs) have shown remarkable performance on many tasks
in different domains. However, their performance in closed-book biomedical
machine reading comprehension (MRC) has not been evaluated in depth. In this
work, we evaluate GPT on four closed-book biomedical MRC benchmarks. We
experiment with different conventional prompting techniques as well as
introduce our own novel prompting method. To solve some of the retrieval
problems inherent to LLMs, we propose a prompting strategy named Implicit
Retrieval Augmented Generation (RAG) that alleviates the need for using vector
databases to retrieve important chunks in traditional RAG setups. Moreover, we
report qualitative assessments on the natural language generation outputs from
our approach. The results show that our new prompting technique is able to get
the best performance in two out of four datasets and ranks second in rest of
them. Experiments show that modern-day LLMs like GPT even in a zero-shot
setting can outperform supervised models, leading to new state-of-the-art
(SoTA) results on two of the benchmarks.",2024-05-29,"Shubham Vatsal, Ayush Singh",http://arxiv.org/pdf/2405.18682v2,cs.LG
Navigable Graphs for High-Dimensional Nearest Neighbor Search: Constructions and Limits,"There has been significant recent interest in graph-based nearest neighbor
search methods, many of which are centered on the construction of navigable
graphs over high-dimensional point sets. A graph is navigable if we can
successfully move from any starting node to any target node using a greedy
routing strategy where we always move to the neighbor that is closest to the
destination according to a given distance function. The complete graph is
navigable for any point set, but the important question for applications is if
sparser graphs can be constructed. While this question is fairly well
understood in low-dimensions, we establish some of the first upper and lower
bounds for high-dimensional point sets. First, we give a simple and efficient
way to construct a navigable graph with average degree $O(\sqrt{n \log n })$
for any set of $n$ points, in any dimension, for any distance function. We
compliment this result with a nearly matching lower bound: even under the
Euclidean metric in $O(\log n)$ dimensions, a random point set has no navigable
graph with average degree $O(n^{\alpha})$ for any $\alpha < 1/2$. Our lower
bound relies on sharp anti-concentration bounds for binomial random variables,
which we use to show that the near-neighborhoods of a set of random points do
not overlap significantly, forcing any navigable graph to have many edges.",2024-05-29,"Haya Diwan, Jinrui Gou, Cameron Musco, Christopher Musco, Torsten Suel",http://arxiv.org/pdf/2405.18680v4,cs.LG
Prototype Analysis in Hopfield Networks with Hebbian Learning,"We discuss prototype formation in the Hopfield network. Typically, Hebbian
learning with highly correlated states leads to degraded memory performance. We
show this type of learning can lead to prototype formation, where unlearned
states emerge as representatives of large correlated subsets of states,
alleviating capacity woes. This process has similarities to prototype learning
in human cognition. We provide a substantial literature review of prototype
learning in associative memories, covering contributions from psychology,
statistical physics, and computer science. We analyze prototype formation from
a theoretical perspective and derive a stability condition for these states
based on the number of examples of the prototype presented for learning, the
noise in those examples, and the number of non-example states presented. The
stability condition is used to construct a probability of stability for a
prototype state as the factors of stability change. We also note similarities
to traditional network analysis, allowing us to find a prototype capacity. We
corroborate these expectations of prototype formation with experiments using a
simple Hopfield network with standard Hebbian learning. We extend our
experiments to a Hopfield network trained on data with multiple prototypes and
find the network is capable of stabilizing multiple prototypes concurrently. We
measure the basins of attraction of the multiple prototype states, finding
attractor strength grows with the number of examples and the agreement of
examples. We link the stability and dominance of prototype states to the energy
profile of these states, particularly when comparing the profile shape to
target states or other spurious states.",2024-05-29,"Hayden McAlister, Anthony Robins, Lech Szymanski",http://arxiv.org/pdf/2407.03342v1,cs.LG
Deep Bayesian Filter for Bayes-faithful Data Assimilation,"State estimation for nonlinear state space models (SSMs) is a challenging
task. Existing assimilation methodologies predominantly assume Gaussian
posteriors on physical space, where true posteriors become inevitably
non-Gaussian. We propose Deep Bayesian Filtering (DBF) for data assimilation on
nonlinear SSMs. DBF constructs new latent variables $h_t$ in addition to the
original physical variables $z_t$ and assimilates observations $o_t$. By (i)
constraining the state transition on the new latent space to be linear and (ii)
learning a Gaussian inverse observation operator $r(h_t|o_t)$, posteriors
remain Gaussian. Notably, the structured design of test distributions enables
an analytical formula for the recursive computation, eliminating the
accumulation of Monte Carlo sampling errors across time steps. DBF trains the
Gaussian inverse observation operators $r(h_t|o_t)$ and other latent SSM
parameters (e.g., dynamics matrix) by maximizing the evidence lower bound.
Experiments demonstrate that DBF outperforms model-based approaches and latent
assimilation methods in tasks where the true posterior distribution on physical
space is significantly non-Gaussian.",2024-05-29,"Yuta Tarumi, Keisuke Fukuda, Shin-ichi Maeda",http://arxiv.org/pdf/2405.18674v2,cs.LG
Watermarking Counterfactual Explanations,"Counterfactual (CF) explanations for ML model predictions provide actionable
recourse recommendations to individuals adversely impacted by predicted
outcomes. However, despite being preferred by end-users, CF explanations have
been shown to pose significant security risks in real-world applications; in
particular, malicious adversaries can exploit CF explanations to perform
query-efficient model extraction attacks on the underlying proprietary ML
model. To address this security challenge, we propose CFMark, a novel
model-agnostic watermarking framework for detecting unauthorized model
extraction attacks relying on CF explanations. CFMark involves a novel bi-level
optimization problem to embed an indistinguishable watermark into the generated
CF explanation such that any future model extraction attacks using these
watermarked CF explanations can be detected using a null hypothesis
significance testing (NHST) scheme. At the same time, the embedded watermark
does not compromise the quality of the CF explanations. We evaluate CFMark
across diverse real-world datasets, CF explanation methods, and model
extraction techniques. Our empirical results demonstrate CFMark's
effectiveness, achieving an F-1 score of ~0.89 in identifying unauthorized
model extraction attacks using watermarked CF explanations. Importantly, this
watermarking incurs only a negligible degradation in the quality of generated
CF explanations (i.e., ~1.3% degradation in validity and ~1.6% in proximity).
Our work establishes a critical foundation for the secure deployment of CF
explanations in real-world applications.",2024-05-29,"Hangzhi Guo, Firdaus Ahmed Choudhury, Tinghua Chen, Amulya Yadav",http://arxiv.org/pdf/2405.18671v2,cs.LG
Differentially Private Synthetic Data Generation for Relational Databases,"Existing differentially private (DP) synthetic data generation mechanisms
typically assume a single-source table. In practice, data is often distributed
across multiple tables with relationships across tables. In this paper, we
introduce the first-of-its-kind algorithm that can be combined with any
existing DP mechanisms to generate synthetic relational databases. Our
algorithm iteratively refines the relationship between individual synthetic
tables to minimize their approximation errors in terms of low-order marginal
distributions while maintaining referential integrity. This algorithm
eliminates the need to flatten a relational database into a master table
(saving space), operates efficiently (saving time), and scales effectively to
high-dimensional data. We provide both DP and theoretical utility guarantees
for our algorithm. Through numerical experiments on real-world datasets, we
demonstrate the effectiveness of our method in preserving fidelity to the
original data.",2024-05-29,"Kaveh Alimohammadi, Hao Wang, Ojas Gulati, Akash Srivastava, Navid Azizan",http://arxiv.org/pdf/2405.18670v2,cs.LG
Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities,"Integrating multiple generative foundation models, especially those trained
on different modalities, into something greater than the sum of its parts poses
significant challenges. Two key hurdles are the availability of aligned data
(concepts that contain similar meaning but is expressed differently in
different modalities), and effectively leveraging unimodal representations in
cross-domain generative tasks, without compromising their original unimodal
capabilities.
  We propose Zipper, a multi-tower decoder architecture that addresses these
concerns by using cross-attention to flexibly compose multimodal generative
models from independently pre-trained unimodal decoders. In our experiments
fusing speech and text modalities, we show the proposed architecture performs
very competitively in scenarios with limited aligned text-speech data. We also
showcase the flexibility of our model to selectively maintain unimodal (e.g.,
text-to-text generation) generation performance by freezing the corresponding
modal tower (e.g. text). In cross-modal tasks such as automatic speech
recognition (ASR) where the output modality is text, we show that freezing the
text backbone results in negligible performance degradation. In cross-modal
tasks such as text-to-speech generation (TTS) where the output modality is
speech, we show that using a pre-trained speech backbone results in superior
performance to the baseline.",2024-05-29,"Vicky Zayats, Peter Chen, Melissa Ferrari, Dirk Padfield",http://arxiv.org/pdf/2405.18669v2,cs.LG
Pretrained Mobility Transformer: A Foundation Model for Human Mobility,"Ubiquitous mobile devices are generating vast amounts of location-based
service data that reveal how individuals navigate and utilize urban spaces in
detail. In this study, we utilize these extensive, unlabeled sequences of user
trajectories to develop a foundation model for understanding urban space and
human mobility. We introduce the \textbf{P}retrained \textbf{M}obility
\textbf{T}ransformer (PMT), which leverages the transformer architecture to
process user trajectories in an autoregressive manner, converting geographical
areas into tokens and embedding spatial and temporal information within these
representations. Experiments conducted in three U.S. metropolitan areas over a
two-month period demonstrate PMT's ability to capture underlying geographic and
socio-demographic characteristics of regions. The proposed PMT excels across
various downstream tasks, including next-location prediction, trajectory
imputation, and trajectory generation. These results support PMT's capability
and effectiveness in decoding complex patterns of human mobility, offering new
insights into urban spatial functionality and individual mobility preferences.",2024-05-29,"Xinhua Wu, Haoyu He, Yanchao Wang, Qi Wang",http://arxiv.org/pdf/2406.02578v1,cs.LG
Fast Explanations via Policy Gradient-Optimized Explainer,"The challenge of delivering efficient explanations is a critical barrier that
prevents the adoption of model explanations in real-world applications.
Existing approaches often depend on extensive model queries for sample-level
explanations or rely on expert's knowledge of specific model structures that
trade general applicability for efficiency. To address these limitations, this
paper introduces a novel framework Fast Explanation (FEX) that represents
attribution-based explanations via probability distributions, which are
optimized by leveraging the policy gradient method. The proposed framework
offers a robust, scalable solution for real-time, large-scale model
explanations, bridging the gap between efficiency and applicability. We
validate our framework on image and text classification tasks and the
experiments demonstrate that our method reduces inference time by over 97% and
memory usage by 70% compared to traditional model-agnostic approaches while
maintaining high-quality explanations and broad applicability.",2024-05-29,"Deng Pan, Nuno Moniz, Nitesh Chawla",http://arxiv.org/pdf/2405.18664v2,cs.LG
Understanding Intrinsic Socioeconomic Biases in Large Language Models,"Large Language Models (LLMs) are increasingly integrated into critical
decision-making processes, such as loan approvals and visa applications, where
inherent biases can lead to discriminatory outcomes. In this paper, we examine
the nuanced relationship between demographic attributes and socioeconomic
biases in LLMs, a crucial yet understudied area of fairness in LLMs. We
introduce a novel dataset of one million English sentences to systematically
quantify socioeconomic biases across various demographic groups. Our findings
reveal pervasive socioeconomic biases in both established models such as GPT-2
and state-of-the-art models like Llama 2 and Falcon. We demonstrate that these
biases are significantly amplified when considering intersectionality, with
LLMs exhibiting a remarkable capacity to extract multiple demographic
attributes from names and then correlate them with specific socioeconomic
biases. This research highlights the urgent necessity for proactive and robust
bias mitigation techniques to safeguard against discriminatory outcomes when
deploying these powerful models in critical real-world applications.",2024-05-28,"Mina Arzaghi, Florian Carichon, Golnoosh Farnadi",http://arxiv.org/pdf/2405.18662v1,cs.LG
CAVACHON: a hierarchical variational autoencoder to integrate multi-modal single-cell data,"Paired single-cell sequencing technologies enable the simultaneous
measurement of complementary modalities of molecular data at single-cell
resolution. Along with the advances in these technologies, many methods based
on variational autoencoders have been developed to integrate these data.
However, these methods do not explicitly incorporate prior biological
relationships between the data modalities, which could significantly enhance
modeling and interpretation. We propose a novel probabilistic learning
framework that explicitly incorporates conditional independence relationships
between multi-modal data as a directed acyclic graph using a generalized
hierarchical variational autoencoder. We demonstrate the versatility of our
framework across various applications pertinent to single-cell multi-omics data
integration. These include the isolation of common and distinct information
from different modalities, modality-specific differential analysis, and
integrated cell clustering. We anticipate that the proposed framework can
facilitate the construction of highly flexible graphical models that can
capture the complexities of biological hypotheses and unravel the connections
between different biological data types, such as different modalities of paired
single-cell multi-omics data. The implementation of the proposed framework can
be found in the repository https://github.com/kuijjerlab/CAVACHON.",2024-05-28,"Ping-Han Hsieh, Ru-Xiu Hsiao, Katalin Ferenc, Anthony Mathelier, Rebekka Burkholz, Chien-Yu Chen, Geir Kjetil Sandve, Tatiana Belova, Marieke Lydia Kuijjer",http://arxiv.org/pdf/2405.18655v1,cs.LG
Are PPO-ed Language Models Hackable?,"Numerous algorithms have been proposed to $\textit{align}$ language models to
remove undesirable behaviors. However, the challenges associated with a very
large state space and creating a proper reward function often result in various
jailbreaks. Our paper aims to examine this effect of reward in the controlled
setting of positive sentiment language generation. Instead of online training
of a reward model based on human feedback, we employ a statically learned
sentiment classifier. We also consider a setting where our model's weights and
activations are exposed to an end-user after training. We examine a pretrained
GPT-2 through the lens of mechanistic interpretability before and after
proximal policy optimization (PPO) has been applied to promote positive
sentiment responses. Using these insights, we (1) attempt to ""hack"" the PPO-ed
model to generate negative sentiment responses and (2) add a term to the reward
function to try and alter `negative' weights.",2024-05-28,"Suraj Anand, David Getzen",http://arxiv.org/pdf/2406.02577v1,cs.LG
Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack,"Recent studies show that Large Language Models (LLMs) with safety alignment
can be jail-broken by fine-tuning on a dataset mixed with harmful data. First
time in the literature, we show that the jail-broken effect can be mitigated by
separating states in the finetuning stage to optimize the alignment and user
datasets. Unfortunately, our subsequent study shows that this simple Bi-State
Optimization (BSO) solution experiences convergence instability when steps
invested in its alignment state is too small, leading to downgraded alignment
performance. By statistical analysis, we show that the \textit{excess drift}
towards consensus could be a probable reason for the instability. To remedy
this issue, we propose \textbf{L}azy(\textbf{i}) \textbf{s}afety
\textbf{a}lignment (\textbf{Lisa}), which introduces a proximal term to
constraint the drift of each state. Theoretically, the benefit of the proximal
term is supported by the convergence analysis, wherein we show that a
sufficient large proximal factor is necessary to guarantee Lisa's convergence.
Empirically, our results on four downstream finetuning tasks show that Lisa
with a proximal term can significantly increase alignment performance while
maintaining the LLM's accuracy on the user tasks. Code is available at
\url{https://github.com/git-disl/Lisa}.",2024-05-28,"Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu",http://arxiv.org/pdf/2405.18641v5,cs.LG
Improving Speech Decoding from ECoG with Self-Supervised Pretraining,"Recent work on intracranial brain-machine interfaces has demonstrated that
spoken speech can be decoded with high accuracy, essentially by treating the
problem as an instance of supervised learning and training deep neural networks
to map from neural activity to text. However, such networks pay for their
expressiveness with very large numbers of labeled data, a requirement that is
particularly burdensome for invasive neural recordings acquired from human
patients. On the other hand, these patients typically produce speech outside of
the experimental blocks used for training decoders. Making use of such data,
and data from other patients, to improve decoding would ease the burden of data
collection -- especially onerous for dys- and anarthric patients. Here we
demonstrate that this is possible, by reengineering wav2vec -- a simple,
self-supervised, fully convolutional model that learns latent representations
of audio using a noise-contrastive loss -- for electrocorticographic (ECoG)
data. We train this model on unlabelled ECoG recordings, and subsequently use
it to transform ECoG from labeled speech sessions into wav2vec's representation
space, before finally training a supervised encoder-decoder to map these
representations to text. We experiment with various numbers of labeled blocks;
for almost all choices, the new representations yield superior decoding
performance to the original ECoG data, and in no cases do they yield worse.
Performance can also be improved in some cases by pretraining wav2vec on
another patient's data. In the best cases, wav2vec's representations decrease
word error rates over the original data by upwards of 50%.",2024-05-28,"Brian A. Yuan, Joseph G. Makin",http://arxiv.org/pdf/2405.18639v1,cs.LG
When and How Does In-Distribution Label Help Out-of-Distribution Detection?,"Detecting data points deviating from the training distribution is pivotal for
ensuring reliable machine learning. Extensive research has been dedicated to
the challenge, spanning classical anomaly detection techniques to contemporary
out-of-distribution (OOD) detection approaches. While OOD detection commonly
relies on supervised learning from a labeled in-distribution (ID) dataset,
anomaly detection may treat the entire ID data as a single class and disregard
ID labels. This fundamental distinction raises a significant question that has
yet to be rigorously explored: when and how does ID label help OOD detection?
This paper bridges this gap by offering a formal understanding to theoretically
delineate the impact of ID labels on OOD detection. We employ a graph-theoretic
approach, rigorously analyzing the separability of ID data from OOD data in a
closed-form manner. Key to our approach is the characterization of data
representations through spectral decomposition on the graph. Leveraging these
representations, we establish a provable error bound that compares the OOD
detection performance with and without ID labels, unveiling conditions for
achieving enhanced OOD detection. Lastly, we present empirical results on both
simulated and real datasets, validating theoretical guarantees and reinforcing
our insights. Code is publicly available at
https://github.com/deeplearning-wisc/id_label.",2024-05-28,"Xuefeng Du, Yiyou Sun, Yixuan Li",http://arxiv.org/pdf/2405.18635v1,cs.LG
A Theoretical Understanding of Self-Correction through In-context Alignment,"Going beyond mimicking limited human experiences, recent studies show initial
evidence that, like humans, large language models (LLMs) are capable of
improving their abilities purely by self-correction, i.e., correcting previous
responses through self-examination, in certain circumstances. Nevertheless,
little is known about how such capabilities arise. In this work, based on a
simplified setup akin to an alignment task, we theoretically analyze
self-correction from an in-context learning perspective, showing that when LLMs
give relatively accurate self-examinations as rewards, they are capable of
refining responses in an in-context way. Notably, going beyond previous
theories on over-simplified linear transformers, our theoretical construction
underpins the roles of several key designs of realistic transformers for
self-correction: softmax attention, multi-head attention, and the MLP block. We
validate these findings extensively on synthetic datasets. Inspired by these
findings, we also illustrate novel applications of self-correction, such as
defending against LLM jailbreaks, where a simple self-correction step does make
a large difference. We believe that these findings will inspire further
research on understanding, exploiting, and enhancing self-correction for
building better foundation models.",2024-05-28,"Yifei Wang, Yuyang Wu, Zeming Wei, Stefanie Jegelka, Yisen Wang",http://arxiv.org/pdf/2405.18634v2,cs.LG
PureEBM: Universal Poison Purification via Mid-Run Dynamics of Energy-Based Models,"Data poisoning attacks pose a significant threat to the integrity of machine
learning models by leading to misclassification of target distribution data by
injecting adversarial examples during training. Existing state-of-the-art
(SoTA) defense methods suffer from limitations, such as significantly reduced
generalization performance and significant overhead during training, making
them impractical or limited for real-world applications. In response to this
challenge, we introduce a universal data purification method that defends
naturally trained classifiers from malicious white-, gray-, and black-box image
poisons by applying a universal stochastic preprocessing step $\Psi_{T}(x)$,
realized by iterative Langevin sampling of a convergent Energy Based Model
(EBM) initialized with an image $x.$ Mid-run dynamics of $\Psi_{T}(x)$ purify
poison information with minimal impact on features important to the
generalization of a classifier network. We show that EBMs remain universal
purifiers, even in the presence of poisoned EBM training data, and achieve SoTA
defense on leading triggered and triggerless poisons. This work is a subset of
a larger framework introduced in \pgen with a more detailed focus on EBM
purification and poison defense.",2024-05-28,"Omead Pooladzandi, Jeffrey Jiang, Sunay Bhat, Gregory Pottie",http://arxiv.org/pdf/2405.19376v2,cs.LG
Improving global awareness of linkset predictions using Cross-Attentive Modulation tokens,"This work introduces Cross-Attentive Modulation (CAM) tokens, which are
tokens whose initial value is learned, gather information through
cross-attention, and modulate the nodes and edges accordingly. These tokens are
meant to improve the global awareness of link predictions models which, based
on graph neural networks, can struggle to capture graph-level features. This
lack of ability to feature high level representations is particularly limiting
when predicting multiple or entire sets of links. We implement CAM tokens in a
simple attention-based link prediction model and in a graph transformer, which
we also use in a denoising diffusion framework. A brief introduction to our toy
datasets will then be followed by benchmarks which prove that CAM token improve
the performance of the model they supplement and outperform a baseline with
diverse statistical graph attributes.",2024-05-28,"Félix Marcoccia, Cédric Adjih, Paul Mühlethaler",http://arxiv.org/pdf/2405.19375v4,cs.LG
Hardware-Aware Parallel Prompt Decoding for Memory-Efficient Acceleration of LLM Inference,"The auto-regressive decoding of Large Language Models (LLMs) results in
significant overheads in their hardware performance. While recent research has
investigated various speculative decoding techniques for multi-token
generation, these efforts have primarily focused on improving processing speed
such as throughput. Crucially, they often neglect other metrics essential for
real-life deployments, such as memory consumption and training cost. To
overcome these limitations, we propose a novel parallel prompt decoding that
requires only $0.0002$% trainable parameters, enabling efficient training on a
single A100-40GB GPU in just 16 hours. Inspired by the human natural language
generation process, $PPD$ approximates outputs generated at future timesteps in
parallel by using multiple prompt tokens. This approach partially recovers the
missing conditional dependency information necessary for multi-token
generation, resulting in up to a 28% higher acceptance rate for long-range
predictions. Furthermore, we present a hardware-aware dynamic sparse tree
technique that adaptively optimizes this decoding scheme to fully leverage the
computational capacities on different GPUs. Through extensive experiments
across LLMs ranging from MobileLlama to Vicuna-13B on a wide range of
benchmarks, our approach demonstrates up to 2.49$\times$ speedup and maintains
a minimal runtime memory overhead of just $0.0004$%. More importantly, our
parallel prompt decoding can serve as an orthogonal optimization for
synergistic integration with existing speculative decoding, showing up to
$1.22\times$ further speed improvement. Our code is available at
https://github.com/hmarkc/parallel-prompt-decoding.",2024-05-28,"Hao Mark Chen, Wayne Luk, Ka Fai Cedric Yiu, Rui Li, Konstantin Mishchenko, Stylianos I. Venieris, Hongxiang Fan",http://arxiv.org/pdf/2405.18628v2,cs.LG
PureGen: Universal Data Purification for Train-Time Poison Defense via Generative Model Dynamics,"Train-time data poisoning attacks threaten machine learning models by
introducing adversarial examples during training, leading to misclassification.
Current defense methods often reduce generalization performance, are
attack-specific, and impose significant training overhead. To address this, we
introduce a set of universal data purification methods using a stochastic
transform, $\Psi(x)$, realized via iterative Langevin dynamics of Energy-Based
Models (EBMs), Denoising Diffusion Probabilistic Models (DDPMs), or both. These
approaches purify poisoned data with minimal impact on classifier
generalization. Our specially trained EBMs and DDPMs provide state-of-the-art
defense against various attacks (including Narcissus, Bullseye Polytope,
Gradient Matching) on CIFAR-10, Tiny-ImageNet, and CINIC-10, without needing
attack or classifier-specific information. We discuss performance trade-offs
and show that our methods remain highly effective even with poisoned or
distributionally shifted generative model training data.",2024-05-28,"Sunay Bhat, Jeffrey Jiang, Omead Pooladzandi, Alexander Branch, Gregory Pottie",http://arxiv.org/pdf/2405.18627v2,cs.LG
Causal Contextual Bandits with Adaptive Context,"We study a variant of causal contextual bandits where the context is chosen
based on an initial intervention chosen by the learner. At the beginning of
each round, the learner selects an initial action, depending on which a
stochastic context is revealed by the environment. Following this, the learner
then selects a final action and receives a reward. Given $T$ rounds of
interactions with the environment, the objective of the learner is to learn a
policy (of selecting the initial and the final action) with maximum expected
reward. In this paper we study the specific situation where every action
corresponds to intervening on a node in some known causal graph. We extend
prior work from the deterministic context setting to obtain simple regret
minimization guarantees. This is achieved through an instance-dependent causal
parameter, $\lambda$, which characterizes our upper bound. Furthermore, we
prove that our simple regret is essentially tight for a large class of
instances. A key feature of our work is that we use convex optimization to
address the bandit exploration problem. We also conduct experiments to validate
our theoretical results, and release our code at our project GitHub repository:
https://github.com/adaptiveContextualCausalBandits/aCCB.",2024-05-28,"Rahul Madhavan, Aurghya Maiti, Gaurav Sinha, Siddharth Barman",http://arxiv.org/pdf/2405.18626v2,cs.LG
Model-Based Diffusion for Trajectory Optimization,"Recent advances in diffusion models have demonstrated their strong
capabilities in generating high-fidelity samples from complex distributions
through an iterative refinement process. Despite the empirical success of
diffusion models in motion planning and control, the model-free nature of these
methods does not leverage readily available model information and limits their
generalization to new scenarios beyond the training data (e.g., new robots with
different dynamics). In this work, we introduce Model-Based Diffusion (MBD), an
optimization approach using the diffusion process to solve trajectory
optimization (TO) problems without data. The key idea is to explicitly compute
the score function by leveraging the model information in TO problems, which is
why we refer to our approach as model-based diffusion. Moreover, although MBD
does not require external data, it can be naturally integrated with data of
diverse qualities to steer the diffusion process. We also reveal that MBD has
interesting connections to sampling-based optimization. Empirical evaluations
show that MBD outperforms state-of-the-art reinforcement learning and
sampling-based TO methods in challenging contact-rich tasks. Additionally,
MBD's ability to integrate with data enhances its versatility and practical
applicability, even with imperfect and infeasible data (e.g., partial-state
demonstrations for high-dimensional humanoids), beyond the scope of standard
diffusion models.",2024-05-28,"Chaoyi Pan, Zeji Yi, Guanya Shi, Guannan Qu",http://arxiv.org/pdf/2407.01573v1,cs.LG
Biclustering a dataset using photonic quantum computing,"Biclustering is a problem in machine learning and data mining that seeks to
group together rows and columns of a dataset according to certain criteria. In
this work, we highlight the natural relation that quantum computing models like
boson and Gaussian boson sampling (GBS) have to this problem. We first explore
the use of boson sampling to identify biclusters based on matrix permanents. We
then propose a heuristic that finds clusters in a dataset using Gaussian boson
sampling by (i) converting the dataset into a bipartite graph and then (ii)
running GBS to find the densest sub-graph(s) within the larger bipartite graph.
Our simulations for the above proposed heuristics show promising results for
future exploration in this area.",2024-05-28,"Ajinkya Borle, Ameya Bhave",http://arxiv.org/pdf/2405.18622v1,cs.LG
Multi-Armed Bandits with Network Interference,"Online experimentation with interference is a common challenge in modern
applications such as e-commerce and adaptive clinical trials in medicine. For
example, in online marketplaces, the revenue of a good depends on discounts
applied to competing goods. Statistical inference with interference is widely
studied in the offline setting, but far less is known about how to adaptively
assign treatments to minimize regret. We address this gap by studying a
multi-armed bandit (MAB) problem where a learner (e-commerce platform)
sequentially assigns one of possible $\mathcal{A}$ actions (discounts) to $N$
units (goods) over $T$ rounds to minimize regret (maximize revenue). Unlike
traditional MAB problems, the reward of each unit depends on the treatments
assigned to other units, i.e., there is interference across the underlying
network of units. With $\mathcal{A}$ actions and $N$ units, minimizing regret
is combinatorially difficult since the action space grows as $\mathcal{A}^N$.
To overcome this issue, we study a sparse network interference model, where the
reward of a unit is only affected by the treatments assigned to $s$ neighboring
units. We use tools from discrete Fourier analysis to develop a sparse linear
representation of the unit-specific reward $r_n: [\mathcal{A}]^N \rightarrow
\mathbb{R} $, and propose simple, linear regression-based algorithms to
minimize regret. Importantly, our algorithms achieve provably low regret both
when the learner observes the interference neighborhood for all units and when
it is unknown. This significantly generalizes other works on this topic which
impose strict conditions on the strength of interference on a known network,
and also compare regret to a markedly weaker optimal action. Empirically, we
corroborate our theoretical findings via numerical simulations.",2024-05-28,"Abhineet Agarwal, Anish Agarwal, Lorenzo Masoero, Justin Whitehouse",http://arxiv.org/pdf/2405.18621v1,cs.LG
The Cost of Arbitrariness for Individuals: Examining the Legal and Technical Challenges of Model Multiplicity,"Model multiplicity, the phenomenon where multiple models achieve similar
performance despite different underlying learned functions, introduces
arbitrariness in model selection. While this arbitrariness may seem
inconsequential in expectation, its impact on individuals can be severe. This
paper explores various individual concerns stemming from multiplicity,
including the effects of arbitrariness beyond final predictions, disparate
arbitrariness for individuals belonging to protected groups, and the challenges
associated with the arbitrariness of a single algorithmic system creating a
monopoly across various contexts. It provides both an empirical examination of
these concerns and a comprehensive analysis from the legal standpoint,
addressing how these issues are perceived in the anti-discrimination law in
Canada. We conclude the discussion with technical challenges in the current
landscape of model multiplicity to meet legal requirements and the legal gap
between current law and the implications of arbitrariness in model selection,
highlighting relevant future research directions for both disciplines.",2024-05-28,"Prakhar Ganesh, Ihsan Ibrahim Daldaban, Ignacio Cofone, Golnoosh Farnadi",http://arxiv.org/pdf/2407.13070v2,cs.LG
Augmented Physics: Creating Interactive and Embedded Physics Simulations from Static Textbook Diagrams,"We introduce Augmented Physics, a machine learning-integrated authoring tool
designed for creating embedded interactive physics simulations from static
textbook diagrams. Leveraging recent advancements in computer vision, such as
Segment Anything and Multi-modal LLMs, our web-based system enables users to
semi-automatically extract diagrams from physics textbooks and generate
interactive simulations based on the extracted content. These interactive
diagrams are seamlessly integrated into scanned textbook pages, facilitating
interactive and personalized learning experiences across various physics
concepts, such as optics, circuits, and kinematics. Drawing from an elicitation
study with seven physics instructors, we explore four key augmentation
strategies: 1) augmented experiments, 2) animated diagrams, 3) bi-directional
binding, and 4) parameter visualization. We evaluate our system through
technical evaluation, a usability study (N=12), and expert interviews (N=12).
Study findings suggest that our system can facilitate more engaging and
personalized learning experiences in physics education.",2024-05-28,"Aditya Gunturu, Yi Wen, Nandi Zhang, Jarin Thundathil, Rubaiat Habib Kazi, Ryo Suzuki",http://arxiv.org/pdf/2405.18614v2,cs.LG
GLOCON Database: Design Decisions and User Manual (v1.0),"GLOCON is a database of contentious events automatically extracted from
national news sources from various countries in multiple languages. National
news sources are utilized, and complete news archives are processed to create
an event list for each source. Automation is achieved using a gold standard
corpus sampled randomly from complete news archives (Y\""or\""uk et al. 2022) and
all annotated by at least two domain experts based on the event definition
provided in Duru\c{s}an et al. (2022).",2024-05-28,"Ali Hürriyetoğlu, Osman Mutlu, Fırat Duruşan, Erdem Yörük",http://arxiv.org/pdf/2405.18613v1,cs.LG
DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime,"Reinforcement learning (RL) has garnered increasing recognition for its
potential to optimise dynamic treatment regimes (DTRs) in personalised
medicine, particularly for drug dosage prescriptions and medication
recommendations. However, a significant challenge persists: the absence of a
unified framework for simulating diverse healthcare scenarios and a
comprehensive analysis to benchmark the effectiveness of RL algorithms within
these contexts. To address this gap, we introduce \textit{DTR-Bench}, a
benchmarking platform comprising four distinct simulation environments tailored
to common DTR applications, including cancer chemotherapy, radiotherapy,
glucose management in diabetes, and sepsis treatment. We evaluate various
state-of-the-art RL algorithms across these settings, particularly highlighting
their performance amidst real-world challenges such as
pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.
Our experiments reveal varying degrees of performance degradation among RL
algorithms in the presence of noise and patient variability, with some
algorithms failing to converge. Additionally, we observe that using temporal
observation representations does not consistently lead to improved performance
in DTR settings. Our findings underscore the necessity of developing robust,
adaptive RL algorithms capable of effectively managing these complexities to
enhance patient-specific healthcare. We have open-sourced our benchmark and
code at https://github.com/GilesLuo/DTR-Bench.",2024-05-28,"Zhiyao Luo, Mingcheng Zhu, Fenglin Liu, Jiali Li, Yangchen Pan, Jiandong Zhou, Tingting Zhu",http://arxiv.org/pdf/2405.18610v1,cs.LG
Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting,"Language models have the ability to perform in-context learning (ICL),
allowing them to flexibly adapt their behavior based on context. This contrasts
with in-weights learning (IWL), where memorized information is encoded in model
parameters after iterated observations of data. An ideal model should be able
to flexibly deploy both of these abilities. Despite their apparent ability to
learn in-context, language models are known to struggle when faced with unseen
or rarely seen tokens (Land & Bartolo, 2024). Hence, we study
$\textbf{structural in-context learning}$, which we define as the ability of a
model to execute in-context learning on arbitrary novel tokens -- so called
because the model must generalize on the basis of e.g. sentence structure or
task structure, rather than content encoded in token embeddings. We study
structural in-context algorithms on both synthetic and naturalistic tasks using
toy models, masked language models, and autoregressive language models. We find
that structural ICL appears before quickly disappearing early in LM
pretraining. While it has been shown that ICL can diminish during training
(Singh et al., 2023), we find that prior work does not account for structural
ICL. Building on Chen et al. (2024) 's active forgetting method, we introduce
pretraining and finetuning methods that can modulate the preference for
structural ICL and IWL. Importantly, this allows us to induce a $\textit{dual
process strategy}$ where in-context and in-weights solutions coexist within a
single model.",2024-05-28,"Suraj Anand, Michael A. Lepori, Jack Merullo, Ellie Pavlick",http://arxiv.org/pdf/2406.00053v3,cs.LG
From Conformal Predictions to Confidence Regions,"Conformal prediction methodologies have significantly advanced the
quantification of uncertainties in predictive models. Yet, the construction of
confidence regions for model parameters presents a notable challenge, often
necessitating stringent assumptions regarding data distribution or merely
providing asymptotic guarantees. We introduce a novel approach termed CCR,
which employs a combination of conformal prediction intervals for the model
outputs to establish confidence regions for model parameters. We present
coverage guarantees under minimal assumptions on noise and that is valid in
finite sample regime. Our approach is applicable to both split conformal
predictions and black-box methodologies including full or cross-conformal
approaches. In the specific case of linear models, the derived confidence
region manifests as the feasible set of a Mixed-Integer Linear Program (MILP),
facilitating the deduction of confidence intervals for individual parameters
and enabling robust optimization. We empirically compare CCR to recent
advancements in challenging settings such as with heteroskedastic and
non-Gaussian noise.",2024-05-28,"Charles Guille-Escuret, Eugene Ndiaye",http://arxiv.org/pdf/2405.18601v1,cs.LG
A Margin-based Multiclass Generalization Bound via Geometric Complexity,"There has been considerable effort to better understand the generalization
capabilities of deep neural networks both as a means to unlock a theoretical
understanding of their success as well as providing directions for further
improvements. In this paper, we investigate margin-based multiclass
generalization bounds for neural networks which rely on a recent complexity
measure, the geometric complexity, developed for neural networks. We derive a
new upper bound on the generalization error which scales with the
margin-normalized geometric complexity of the network and which holds for a
broad family of data distributions and model classes. Our generalization bound
is empirically investigated for a ResNet-18 model trained with SGD on the
CIFAR-10 and CIFAR-100 datasets with both original and random labels.",2024-05-28,"Michael Munn, Benoit Dherin, Javier Gonzalvo",http://arxiv.org/pdf/2405.18590v1,cs.LG
Artificial Intelligence in Industry 4.0: A Review of Integration Challenges for Industrial Systems,"In Industry 4.0, Cyber-Physical Systems (CPS) generate vast data sets that
can be leveraged by Artificial Intelligence (AI) for applications including
predictive maintenance and production planning. However, despite the
demonstrated potential of AI, its widespread adoption in sectors like
manufacturing remains limited. Our comprehensive review of recent literature,
including standards and reports, pinpoints key challenges: system integration,
data-related issues, managing workforce-related concerns and ensuring
trustworthy AI. A quantitative analysis highlights particular challenges and
topics that are important for practitioners but still need to be sufficiently
investigated by academics. The paper briefly discusses existing solutions to
these challenges and proposes avenues for future research. We hope that this
survey serves as a resource for practitioners evaluating the cost-benefit
implications of AI in CPS and for researchers aiming to address these urgent
challenges.",2024-05-28,"Alexander Windmann, Philipp Wittenberg, Marvin Schieseck, Oliver Niggemann",http://arxiv.org/pdf/2405.18580v3,cs.LG
Single-Loop Stochastic Algorithms for Difference of Max-Structured Weakly Convex Functions,"In this paper, we study a class of non-smooth non-convex problems in the form
of $\min_{x}[\max_{y\in Y}\phi(x, y) - \max_{z\in Z}\psi(x, z)]$, where both
$\Phi(x) = \max_{y\in Y}\phi(x, y)$ and $\Psi(x)=\max_{z\in Z}\psi(x, z)$ are
weakly convex functions, and $\phi(x, y), \psi(x, z)$ are strongly concave
functions in terms of $y$ and $z$, respectively. It covers two families of
problems that have been studied but are missing single-loop stochastic
algorithms, i.e., difference of weakly convex functions and weakly convex
strongly-concave min-max problems. We propose a stochastic Moreau envelope
approximate gradient method dubbed SMAG, the first single-loop algorithm for
solving these problems, and provide a state-of-the-art non-asymptotic
convergence rate. The key idea of the design is to compute an approximate
gradient of the Moreau envelopes of $\Phi, \Psi$ using only one step of
stochastic gradient update of the primal and dual variables. Empirically, we
conduct experiments on positive-unlabeled (PU) learning and partial area under
ROC curve (pAUC) optimization with an adversarial fairness regularizer to
validate the effectiveness of our proposed algorithms.",2024-05-28,"Quanqi Hu, Qi Qi, Zhaosong Lu, Tianbao Yang",http://arxiv.org/pdf/2405.18577v4,cs.LG
Low-rank finetuning for LLMs: A fairness perspective,"Low-rank approximation techniques have become the de facto standard for
fine-tuning Large Language Models (LLMs) due to their reduced computational and
memory requirements. This paper investigates the effectiveness of these methods
in capturing the shift of fine-tuning datasets from the initial pre-trained
data distribution. Our findings reveal that there are cases in which low-rank
fine-tuning falls short in learning such shifts. This, in turn, produces
non-negligible side effects, especially when fine-tuning is adopted for
toxicity mitigation in pre-trained models, or in scenarios where it is
important to provide fair models. Through comprehensive empirical evidence on
several models, datasets, and tasks, we show that low-rank fine-tuning
inadvertently preserves undesirable biases and toxic behaviors. We also show
that this extends to sequential decision-making tasks, emphasizing the need for
careful evaluation to promote responsible LLMs development.",2024-05-28,"Saswat Das, Marco Romanelli, Cuong Tran, Zarreen Reza, Bhavya Kailkhura, Ferdinando Fioretto",http://arxiv.org/pdf/2405.18572v1,cs.LG
Optimal Multiclass U-Calibration Error and Beyond,"We consider the problem of online multiclass U-calibration, where a
forecaster aims to make sequential distributional predictions over $K$ classes
with low U-calibration error, that is, low regret with respect to all bounded
proper losses simultaneously. Kleinberg et al. (2023) developed an algorithm
with U-calibration error $O(K\sqrt{T})$ after $T$ rounds and raised the open
question of what the optimal bound is. We resolve this question by showing that
the optimal U-calibration error is $\Theta(\sqrt{KT})$ -- we start with a
simple observation that the Follow-the-Perturbed-Leader algorithm of Daskalakis
and Syrgkanis (2016) achieves this upper bound, followed by a matching lower
bound constructed with a specific proper loss (which, as a side result, also
proves the optimality of the algorithm of Daskalakis and Syrgkanis (2016) in
the context of online learning against an adversary with finite choices). We
also strengthen our results under natural assumptions on the loss functions,
including $\Theta(\log T)$ U-calibration error for Lipschitz proper losses,
$O(\log T)$ U-calibration error for a certain class of decomposable proper
losses, U-calibration error bounds for proper losses with a low covering
number, and others.",2024-05-28,"Haipeng Luo, Spandan Senapati, Vatsal Sharan",http://arxiv.org/pdf/2405.19374v1,cs.LG
It's Not a Modality Gap: Characterizing and Addressing the Contrastive Gap,"Multi-modal contrastive models such as CLIP achieve state-of-the-art
performance in zero-shot classification by embedding input images and texts on
a joint representational space. Recently, a modality gap has been reported in
two-encoder contrastive models like CLIP, meaning that the image and text
embeddings reside in disjoint areas of the latent space. Previous studies
suggest that this gap exists due to 1) the cone effect, 2) mismatched pairs in
the dataset, and 3) insufficient training. We show that, even when accounting
for all these factors, and even when using the same modality, the contrastive
loss actually creates a gap during training. As a result, We propose that the
modality gap is inherent to the two-encoder contrastive loss and rename it the
contrastive gap. We present evidence that attributes this contrastive gap to
low uniformity in CLIP space, resulting in embeddings that occupy only a small
portion of the latent space. To close the gap, we adapt the uniformity and
alignment properties of unimodal contrastive loss to the multi-modal setting
and show that simply adding these terms to the CLIP loss distributes the
embeddings more uniformly in the representational space, closing the gap. In
our experiments, we show that the modified representational space achieves
better performance than default CLIP loss in downstream tasks such as zero-shot
image classification and multi-modal arithmetic.",2024-05-28,"Abrar Fahim, Alex Murphy, Alona Fyshe",http://arxiv.org/pdf/2405.18570v3,cs.LG
Warm-starting Push-Relabel,"Push-Relabel is one of the most celebrated network flow algorithms.
Maintaining a pre-flow that saturates a cut, it enjoys better theoretical and
empirical running time than other flow algorithms, such as Ford-Fulkerson. In
practice, Push-Relabel is even faster than what theoretical guarantees can
promise, in part because of the use of good heuristics for seeding and updating
the iterative algorithm. However, it remains unclear how to run Push-Relabel on
an arbitrary initialization that is not necessarily a pre-flow or
cut-saturating. We provide the first theoretical guarantees for warm-starting
Push-Relabel with a predicted flow, where our learning-augmented version
benefits from fast running time when the predicted flow is close to an optimal
flow, while maintaining robust worst-case guarantees. Interestingly, our
algorithm uses the gap relabeling heuristic, which has long been employed in
practice, even though prior to our work there was no rigorous theoretical
justification for why it can lead to run-time improvements. We then provide
experiments that show our warm-started Push-Relabel also works well in
practice.",2024-05-28,"Sami Davies, Sergei Vassilvitskii, Yuyan Wang",http://arxiv.org/pdf/2405.18568v1,cs.LG
Counterfactual Explanations for Multivariate Time-Series without Training Datasets,"Machine learning (ML) methods have experienced significant growth in the past
decade, yet their practical application in high-impact real-world domains has
been hindered by their opacity. When ML methods are responsible for making
critical decisions, stakeholders often require insights into how to alter these
decisions. Counterfactual explanations (CFEs) have emerged as a solution,
offering interpretations of opaque ML models and providing a pathway to
transition from one decision to another. However, most existing CFE methods
require access to the model's training dataset, few methods can handle
multivariate time-series, and none can handle multivariate time-series without
training datasets. These limitations can be formidable in many scenarios. In
this paper, we present CFWoT, a novel reinforcement-learning-based CFE method
that generates CFEs when training datasets are unavailable. CFWoT is
model-agnostic and suitable for both static and multivariate time-series
datasets with continuous and discrete features. Users have the flexibility to
specify non-actionable, immutable, and preferred features, as well as causal
constraints which CFWoT guarantees will be respected. We demonstrate the
performance of CFWoT against four baselines on several datasets and find that,
despite not having access to a training dataset, CFWoT finds CFEs that make
significantly fewer and significantly smaller changes to the input time-series.
These properties make CFEs more actionable, as the magnitude of change required
to alter an outcome is vastly reduced.",2024-05-28,"Xiangyu Sun, Raquel Aoki, Kevin H. Wilson",http://arxiv.org/pdf/2405.18563v1,cs.LG
Potential Field Based Deep Metric Learning,"Deep metric learning (DML) involves training a network to learn a
semantically meaningful representation space. Many current approaches mine
n-tuples of examples and model interactions within each tuplets. We present a
novel, compositional DML model that instead of in tuples, represents the
influence of each example (embedding) by a continuous potential field, and
superposes the fields to obtain their combined global potential field. We use
attractive/repulsive potential fields to represent interactions among
embeddings from images of the same/different classes. Contrary to typical
learning methods, where mutual influence of samples is proportional to their
distance, we enforce reduction in such influence with distance, leading to a
decaying field. We show that such decay helps improve performance on real world
datasets with large intra-class variations and label noise. Like other
proxy-based methods, we also use proxies to succinctly represent
sub-populations of examples. We evaluate our method on three standard DML
benchmarks- Cars-196, CUB-200-2011, and SOP datasets where it outperforms
state-of-the-art baselines.",2024-05-28,"Shubhang Bhatnagar, Narendra Ahuja",http://arxiv.org/pdf/2405.18560v4,cs.LG
Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination,"In the rapidly changing healthcare landscape, the implementation of offline
reinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix
of unprecedented opportunities and challenges. This position paper offers a
critical examination of the current status of offline RL in the context of
DTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such
as inconsistent and potentially inconclusive evaluation metrics, the absence of
naive and supervised learning baselines, and the diverse choice of RL
formulation in existing research. Through a case study with more than 17,000
evaluation experiments using a publicly available Sepsis dataset, we
demonstrate that the performance of RL algorithms can significantly vary with
changes in evaluation metrics and Markov Decision Process (MDP) formulations.
Surprisingly, it is observed that in some instances, RL algorithms can be
surpassed by random baselines subjected to policy evaluation methods and reward
design. This calls for more careful policy evaluation and algorithm development
in future DTR works. Additionally, we discussed potential enhancements toward
more reliable development of RL-based dynamic treatment regimes and invited
further discussion within the community. Code is available at
https://github.com/GilesLuo/ReassessDTR.",2024-05-28,"Zhiyao Luo, Yangchen Pan, Peter Watkinson, Tingting Zhu",http://arxiv.org/pdf/2405.18556v2,cs.LG
Scalable Surrogate Verification of Image-based Neural Network Control Systems using Composition and Unrolling,"Verifying safety of neural network control systems that use images as input
is a difficult problem because, from a given system state, there is no known
way to mathematically model what images are possible in the real-world. We
build on recent work that considers a surrogate verification approach, training
a conditional generative adversarial network (cGAN) as an image generator in
place of the real world. This enables set-based formal analysis of the
closed-loop system, providing analysis beyond simulation and testing. While
existing work is effective on small examples, excessive overapproximation both
within a single control period and across multiple control periods limits its
scalability. We propose approaches to overcome these two sources of error.
First, we overcome one-step error by composing the system's dynamics along with
the cGAN and neural network controller, without losing the dependencies between
input states and the control outputs as in the monotonic analysis of the system
dynamics. Second, we reduce multi-step error by repeating the single-step
composition, essentially unrolling multiple steps of the control loop into a
large neural network. We then leverage existing network verification tools to
compute accurate reachable sets for multiple steps, avoiding the accumulation
of abstraction error at each step. We demonstrate the effectiveness of our
approach in terms of both accuracy and scalability using two case studies: an
autonomous aircraft taxiing system and an advanced emergency braking system. On
the aircraft taxiing system, the converged reachable set is 175% larger using
the prior baseline method compared with our proposed approach. On the emergency
braking system, with 24x the number of image output variables from the cGAN,
the baseline method fails to prove any states are safe, whereas our
improvements enable set-based safety analysis.",2024-05-28,"Feiyang Cai, Chuchu Fan, Stanley Bak",http://arxiv.org/pdf/2405.18554v3,cs.LG
SGD method for entropy error function with smoothing l0 regularization for neural networks,"The entropy error function has been widely used in neural networks.
Nevertheless, the network training based on this error function generally leads
to a slow convergence rate, and can easily be trapped in a local minimum or
even with the incorrect saturation problem in practice. In fact, there are many
results based on entropy error function in neural network and its applications.
However, the theory of such an algorithm and its convergence have not been
fully studied so far. To tackle the issue, we propose a novel entropy function
with smoothing l0 regularization for feed-forward neural networks. Using
real-world datasets, we performed an empirical evaluation to demonstrate that
the newly conceived algorithm allows us to substantially improve the prediction
performance of the considered neural networks. More importantly, the
experimental results also show that our proposed function brings in more
precise classifications, compared to well-founded baselines. Our work is novel
as it enables neural networks to learn effectively, producing more accurate
predictions compared to state-of-the-art algorithms. In this respect, we expect
that the algorithm will contribute to existing studies in the field, advancing
research in Machine Learning and Deep Learning.",2024-05-28,"Trong-Tuan Nguyen, Van-Dat Thang, Nguyen Van Thin, Phuong T. Nguyen",http://arxiv.org/pdf/2405.18552v1,cs.LG
Learning from Uncertain Data: From Possible Worlds to Possible Models,"We introduce an efficient method for learning linear models from uncertain
data, where uncertainty is represented as a set of possible variations in the
data, leading to predictive multiplicity. Our approach leverages abstract
interpretation and zonotopes, a type of convex polytope, to compactly represent
these dataset variations, enabling the symbolic execution of gradient descent
on all possible worlds simultaneously. We develop techniques to ensure that
this process converges to a fixed point and derive closed-form solutions for
this fixed point. Our method provides sound over-approximations of all possible
optimal models and viable prediction ranges. We demonstrate the effectiveness
of our approach through theoretical and empirical analysis, highlighting its
potential to reason about model and prediction uncertainty due to data quality
issues in training data.",2024-05-28,"Jiongli Zhu, Su Feng, Boris Glavic, Babak Salimi",http://arxiv.org/pdf/2405.18549v1,cs.LG
Transformer Encoder Satisfiability: Complexity and Impact on Formal Reasoning,"We analyse the complexity of the satisfiability problem, or similarly
feasibility problem, (trSAT) for transformer encoders (TE), which naturally
occurs in formal verification or interpretation, collectively referred to as
formal reasoning. We find that trSAT is undecidable when considering TE as they
are commonly studied in the expressiveness community. Furthermore, we identify
practical scenarios where trSAT is decidable and establish corresponding
complexity bounds. Beyond trivial cases, we find that quantized TE, those
restricted by fixed-width arithmetic, lead to the decidability of trSAT due to
their limited attention capabilities. However, the problem remains difficult,
as we establish scenarios where trSAT is NEXPTIME-hard and others where it is
solvable in NEXPTIME for quantized TE. To complement our complexity results, we
place our findings and their implications in the broader context of formal
reasoning.",2024-05-28,"Marco Sälzer, Eric Alsmann, Martin Lange",http://arxiv.org/pdf/2405.18548v3,cs.LG
Automatic detection of cognitive impairment in elderly people using an entertainment chatbot with Natural Language Processing capabilities,"Previous researchers have proposed intelligent systems for therapeutic
monitoring of cognitive impairments. However, most existing practical
approaches for this purpose are based on manual tests. This raises issues such
as excessive caretaking effort and the white-coat effect. To avoid these
issues, we present an intelligent conversational system for entertaining
elderly people with news of their interest that monitors cognitive impairment
transparently. Automatic chatbot dialogue stages allow assessing content
description skills and detecting cognitive impairment with Machine Learning
algorithms. We create these dialogue flows automatically from updated news
items using Natural Language Generation techniques. The system also infers the
gold standard of the answers to the questions, so it can assess cognitive
capabilities automatically by comparing these answers with the user responses.
It employs a similarity metric with values in [0, 1], in increasing level of
similarity. To evaluate the performance and usability of our approach, we have
conducted field tests with a test group of 30 elderly people in the earliest
stages of dementia, under the supervision of gerontologists. In the
experiments, we have analysed the effect of stress and concentration in these
users. Those without cognitive impairment performed up to five times better. In
particular, the similarity metric varied between 0.03, for stressed and
unfocused participants, and 0.36, for relaxed and focused users. Finally, we
developed a Machine Learning algorithm based on textual analysis features for
automatic cognitive impairment detection, which attained accuracy, F-measure
and recall levels above 80%. We have thus validated the automatic approach to
detect cognitive impairment in elderly people based on entertainment content.",2024-05-28,"Francisco de Arriba-Pérez, Silvia García-Méndez, Francisco J. González-Castaño, Enrique Costa-Montenegro",http://arxiv.org/pdf/2405.18542v1,cs.LG
Learning diverse attacks on large language models for robust red-teaming and safety tuning,"Red-teaming, or identifying prompts that elicit harmful responses, is a
critical step in ensuring the safe and responsible deployment of large language
models (LLMs). Developing effective protection against many modes of attack
prompts requires discovering diverse attacks. Automated red-teaming typically
uses reinforcement learning to fine-tune an attacker language model to generate
prompts that elicit undesirable responses from a target LLM, as measured, for
example, by an auxiliary toxicity classifier. We show that even with explicit
regularization to favor novelty and diversity, existing approaches suffer from
mode collapse or fail to generate effective attacks. As a flexible and
probabilistically principled alternative, we propose to use GFlowNet
fine-tuning, followed by a secondary smoothing phase, to train the attacker
model to generate diverse and effective attack prompts. We find that the
attacks generated by our method are effective against a wide range of target
LLMs, both with and without safety tuning, and transfer well between target
LLMs. Finally, we demonstrate that models safety-tuned using a dataset of
red-teaming prompts generated by our method are robust to attacks from other
RL-based red-teaming approaches.",2024-05-28,"Seanie Lee, Minsu Kim, Lynn Cherif, David Dobre, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi, Gauthier Gidel, Yoshua Bengio, Nikolay Malkin, Moksh Jain",http://arxiv.org/pdf/2405.18540v2,cs.LG
Augmented Conversation with Embedded Speech-Driven On-the-Fly Referencing in AR,"This paper introduces the concept of augmented conversation, which aims to
support co-located in-person conversations via embedded speech-driven
on-the-fly referencing in augmented reality (AR). Today computing technologies
like smartphones allow quick access to a variety of references during the
conversation. However, these tools often create distractions, reducing eye
contact and forcing users to focus their attention on phone screens and
manually enter keywords to access relevant information. In contrast, AR-based
on-the-fly referencing provides relevant visual references in real-time, based
on keywords extracted automatically from the spoken conversation. By embedding
these visual references in AR around the conversation partner, augmented
conversation reduces distraction and friction, allowing users to maintain eye
contact and supporting more natural social interactions. To demonstrate this
concept, we developed \system, a Hololens-based interface that leverages
real-time speech recognition, natural language processing and gaze-based
interactions for on-the-fly embedded visual referencing. In this paper, we
explore the design space of visual referencing for conversations, and describe
our our implementation -- building on seven design guidelines identified
through a user-centered design process. An initial user study confirms that our
system decreases distraction and friction in conversations compared to
smartphone searches, while providing highly useful and relevant information.",2024-05-28,"Shivesh Jadon, Mehrad Faridan, Edward Mah, Rajan Vaish, Wesley Willett, Ryo Suzuki",http://arxiv.org/pdf/2405.18537v1,cs.LG
Data-Driven Simulator for Mechanical Circulatory Support with Domain Adversarial Neural Process,"Mechanical Circulatory Support (MCS) devices, implemented as a probabilistic
deep sequence model. Existing mechanical simulators for MCS rely on
oversimplifying assumptions and are insensitive to patient-specific behavior,
limiting their applicability to real-world treatment scenarios. To address
these shortcomings, our model Domain Adversarial Neural Process (DANP) employs
a neural process architecture, allowing it to capture the probabilistic
relationship between MCS pump levels and aortic pressure measurements with
uncertainty. We use domain adversarial training to combine simulation data with
real-world observations, resulting in a more realistic and diverse
representation of potential outcomes. Empirical results with an improvement of
19% in non-stationary trend prediction establish DANP as an effective tool for
clinicians to understand and make informed decisions regarding MCS patient
treatment.",2024-05-28,"Sophia Sun, Wenyuan Chen, Zihao Zhou, Sonia Fereidooni, Elise Jortberg, Rose Yu",http://arxiv.org/pdf/2405.18536v1,cs.LG
Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation,"Supervised learning methods have been found to exhibit inductive biases
favoring simpler features. When such features are spuriously correlated with
the label, this can result in suboptimal performance on minority subgroups.
Despite the growing popularity of methods which learn from unlabeled data, the
extent to which these representations rely on spurious features for prediction
is unclear. In this work, we explore the impact of spurious features on
Self-Supervised Learning (SSL) for visual representation learning. We first
empirically show that commonly used augmentations in SSL can cause undesired
invariances in the image space, and illustrate this with a simple example. We
further show that classical approaches in combating spurious correlations, such
as dataset re-sampling during SSL, do not consistently lead to invariant
representations. Motivated by these findings, we propose LateTVG to remove
spurious information from these representations during pre-training, by
regularizing later layers of the encoder via pruning. We find that our method
produces representations which outperform the baselines on several benchmarks,
without the need for group or label information during SSL.",2024-05-28,"Kimia Hamidieh, Haoran Zhang, Swami Sankaranarayanan, Marzyeh Ghassemi",http://arxiv.org/pdf/2406.18562v1,cs.LG
Offline-Boosted Actor-Critic: Adaptively Blending Optimal Historical Behaviors in Deep Off-Policy RL,"Off-policy reinforcement learning (RL) has achieved notable success in
tackling many complex real-world tasks, by leveraging previously collected data
for policy learning. However, most existing off-policy RL algorithms fail to
maximally exploit the information in the replay buffer, limiting sample
efficiency and policy performance. In this work, we discover that concurrently
training an offline RL policy based on the shared online replay buffer can
sometimes outperform the original online learning policy, though the occurrence
of such performance gains remains uncertain. This motivates a new possibility
of harnessing the emergent outperforming offline optimal policy to improve
online policy learning. Based on this insight, we present Offline-Boosted
Actor-Critic (OBAC), a model-free online RL framework that elegantly identifies
the outperforming offline policy through value comparison, and uses it as an
adaptive constraint to guarantee stronger policy learning performance. Our
experiments demonstrate that OBAC outperforms other popular model-free RL
baselines and rivals advanced model-based RL methods in terms of sample
efficiency and asymptotic performance across 53 tasks spanning 6 task suites.",2024-05-28,"Yu Luo, Tianying Ji, Fuchun Sun, Jianwei Zhang, Huazhe Xu, Xianyuan Zhan",http://arxiv.org/pdf/2405.18520v1,cs.LG
"Modeling Long Sequences in Bladder Cancer Recurrence: A Comparative Evaluation of LSTM,Transformer,and Mamba","Traditional survival analysis methods often struggle with complex
time-dependent data,failing to capture and interpret dynamic characteristics
adequately.This study aims to evaluate the performance of three long-sequence
models,LSTM,Transformer,and Mamba,in analyzing recurrence event data and
integrating them with the Cox proportional hazards model.This study integrates
the advantages of deep learning models for handling long-sequence data with the
Cox proportional hazards model to enhance the performance in analyzing
recurrent events with dynamic time information.Additionally,this study compares
the ability of different models to extract and utilize features from
time-dependent clinical recurrence data.The LSTM-Cox model outperformed both
the Transformer-Cox and Mamba-Cox models in prediction accuracy and model
fit,achieving a Concordance index of up to 0.90 on the test set.Significant
predictors of bladder cancer recurrence,such as treatment stop time,maximum
tumor size at recurrence and recurrence frequency,were identified.The LSTM-Cox
model aligned well with clinical outcomes,effectively distinguishing between
high-risk and low-risk patient groups.This study demonstrates that the LSTM-Cox
model is a robust and efficient method for recurrent data analysis and feature
extraction,surpassing newer models like Transformer and Mamba.It offers a
practical approach for integrating deep learning technologies into clinical
risk prediction systems,thereby improving patient management and treatment
outcomes.",2024-05-28,"Runquan Zhang, Jiawen Jiang, Xiaoping Shi",http://arxiv.org/pdf/2405.18518v2,cs.LG
Atlas3D: Physically Constrained Self-Supporting Text-to-3D for Simulation and Fabrication,"Existing diffusion-based text-to-3D generation methods primarily focus on
producing visually realistic shapes and appearances, often neglecting the
physical constraints necessary for downstream tasks. Generated models
frequently fail to maintain balance when placed in physics-based simulations or
3D printed. This balance is crucial for satisfying user design intentions in
interactive gaming, embodied AI, and robotics, where stable models are needed
for reliable interaction. Additionally, stable models ensure that 3D-printed
objects, such as figurines for home decoration, can stand on their own without
requiring additional supports. To fill this gap, we introduce Atlas3D, an
automatic and easy-to-implement method that enhances existing Score
Distillation Sampling (SDS)-based text-to-3D tools. Atlas3D ensures the
generation of self-supporting 3D models that adhere to physical laws of
stability under gravity, contact, and friction. Our approach combines a novel
differentiable simulation-based loss function with physically inspired
regularization, serving as either a refinement or a post-processing module for
existing frameworks. We verify Atlas3D's efficacy through extensive generation
tasks and validate the resulting 3D models in both simulated and real-world
environments.",2024-05-28,"Yunuo Chen, Tianyi Xie, Zeshun Zong, Xuan Li, Feng Gao, Yin Yang, Ying Nian Wu, Chenfanfu Jiang",http://arxiv.org/pdf/2405.18515v2,cs.LG
Understanding Transformer Reasoning Capabilities via Graph Algorithms,"Which transformer scaling regimes are able to perfectly solve different
classes of algorithmic problems? While tremendous empirical advances have been
attained by transformer-based neural networks, a theoretical understanding of
their algorithmic reasoning capabilities in realistic parameter regimes is
lacking. We investigate this question in terms of the network's depth, width,
and number of extra tokens for algorithm execution. Our novel representational
hierarchy separates 9 algorithmic reasoning problems into classes solvable by
transformers in different realistic parameter scaling regimes. We prove that
logarithmic depth is necessary and sufficient for tasks like graph
connectivity, while single-layer transformers with small embedding dimensions
can solve contextual retrieval tasks. We also support our theoretical analysis
with ample empirical evidence using the GraphQA benchmark. These results show
that transformers excel at many graph reasoning tasks, even outperforming
specialized graph neural networks.",2024-05-28,"Clayton Sanford, Bahare Fatemi, Ethan Hall, Anton Tsitsulin, Mehran Kazemi, Jonathan Halcrow, Bryan Perozzi, Vahab Mirrokni",http://arxiv.org/pdf/2405.18512v1,cs.LG
Injecting Hierarchical Biological Priors into Graph Neural Networks for Flow Cytometry Prediction,"In the complex landscape of hematologic samples such as peripheral blood or
bone marrow derived from flow cytometry (FC) data, cell-level prediction
presents profound challenges. This work explores injecting hierarchical prior
knowledge into graph neural networks (GNNs) for single-cell multi-class
classification of tabular cellular data. By representing the data as graphs and
encoding hierarchical relationships between classes, we propose our
hierarchical plug-in method to be applied to several GNN models, namely,
FCHC-GNN, and effectively designed to capture neighborhood information crucial
for single-cell FC domain. Extensive experiments on our cohort of 19 distinct
patients, demonstrate that incorporating hierarchical biological constraints
boosts performance significantly across multiple metrics compared to baseline
GNNs without such priors. The proposed approach highlights the importance of
structured inductive biases for gaining improved generalization in complex
biological prediction tasks.",2024-05-28,"Fatemeh Nassajian Mojarrad, Lorenzo Bini, Thomas Matthes, Stéphane Marchand-Maillet",http://arxiv.org/pdf/2405.18507v4,cs.LG
SoundCTM: Unifying Score-based and Consistency Models for Full-band Text-to-Sound Generation,"Sound content creation, essential for multimedia works such as video games
and films, often involves extensive trial-and-error, enabling creators to
semantically reflect their artistic ideas and inspirations, which evolve
throughout the creation process, into the sound. Recent high-quality
diffusion-based Text-to-Sound (T2S) generative models provide valuable tools
for creators. However, these models often suffer from slow inference speeds,
imposing an undesirable burden that hinders the trial-and-error process. While
existing T2S distillation models address this limitation through 1-step
generation, the sample quality of $1$-step generation remains insufficient for
production use. Additionally, while multi-step sampling in those distillation
models improves sample quality itself, the semantic content changes due to
their lack of deterministic sampling capabilities. To address these issues, we
introduce Sound Consistency Trajectory Models (SoundCTM), which allow flexible
transitions between high-quality $1$-step sound generation and superior sound
quality through multi-step deterministic sampling. This allows creators to
efficiently conduct trial-and-error with 1-step generation to semantically
align samples with their intention, and subsequently refine sample quality with
preserving semantic content through deterministic multi-step sampling. To
develop SoundCTM, we reframe the CTM training framework, originally proposed in
computer vision, and introduce a novel feature distance using the teacher
network for a distillation loss. For production-level generation, we scale up
our model to 1B trainable parameters, making SoundCTM-DiT-1B the first
large-scale distillation model in the sound community to achieve both promising
high-quality 1-step and multi-step full-band (44.1kHz) generation.",2024-05-28,"Koichi Saito, Dongjun Kim, Takashi Shibuya, Chieh-Hsin Lai, Zhi Zhong, Yuhta Takida, Yuki Mitsufuji",http://arxiv.org/pdf/2405.18503v3,cs.LG
Large Margin Discriminative Loss for Classification,"In this paper, we introduce a novel discriminative loss function with large
margin in the context of Deep Learning. This loss boosts the discriminative
power of neural networks, represented by intra-class compactness and
inter-class separability. On the one hand, the class compactness is ensured by
close distance of samples of the same class to each other. On the other hand,
the inter-class separability is boosted by a margin loss that ensures the
minimum distance of each class to its closest boundary. All the terms in our
loss have an explicit meaning, giving a direct view of the obtained feature
space. We analyze mathematically the relation between compactness and margin
term, giving a guideline about the impact of the hyper-parameters on the
learned features. Moreover, we also analyze properties of the gradient of the
loss with respect to the parameters of the neural network. Based on this, we
design a strategy called partial momentum updating that enjoys simultaneously
stability and consistency in training. Furthermore, we provide theoretical
insights explaining why our method can avoid trivial solutions that do not
improve the generalization capability of the model. Besides, we also
investigate generalization errors to have better theoretical insights. The
experiments show promising results of our method.",2024-05-28,"Hai-Vy Nguyen, Fabrice Gamboa, Sixin Zhang, Reda Chhaibi, Serge Gratton, Thierry Giaccone",http://arxiv.org/pdf/2405.18499v2,cs.LG
The Unified Balance Theory of Second-Moment Exponential Scaling Optimizers in Visual Tasks,"We have identified a potential method for unifying first-order optimizers
through the use of variable Second-Moment Exponential Scaling(SMES). We begin
with back propagation, addressing classic phenomena such as gradient vanishing
and explosion, as well as issues related to dataset sparsity, and introduce the
theory of balance in optimization. Through this theory, we suggest that SGD and
adaptive optimizers can be unified under a broader inference, employing
variable moving exponential scaling to achieve a balanced approach within a
generalized formula for first-order optimizers. We conducted tests on some
classic datasets and networks to confirm the impact of different balance
coefficients on the overall training process.",2024-05-28,"Gongyue Zhang, Honghai Liu",http://arxiv.org/pdf/2405.18498v1,cs.LG
Predicting Ground State Properties: Constant Sample Complexity and Deep Learning Algorithms,"A fundamental problem in quantum many-body physics is that of finding ground
states of local Hamiltonians. A number of recent works gave provably efficient
machine learning (ML) algorithms for learning ground states. Specifically,
[Huang et al. Science 2022], introduced an approach for learning properties of
the ground state of an $n$-qubit gapped local Hamiltonian $H$ from only
$n^{\mathcal{O}(1)}$ data points sampled from Hamiltonians in the same phase of
matter. This was subsequently improved by [Lewis et al. Nature Communications
2024], to $\mathcal{O}(\log n)$ samples when the geometry of the $n$-qubit
system is known. In this work, we introduce two approaches that achieve a
constant sample complexity, independent of system size $n$, for learning ground
state properties. Our first algorithm consists of a simple modification of the
ML model used by Lewis et al. and applies to a property of interest known
beforehand. Our second algorithm, which applies even if a description of the
property is not known, is a deep neural network model. While empirical results
showing the performance of neural networks have been demonstrated, to our
knowledge, this is the first rigorous sample complexity bound on a neural
network model for predicting ground state properties. We also perform numerical
experiments that confirm the improved scaling of our approach compared to
earlier results.",2024-05-28,"Marc Wanner, Laura Lewis, Chiranjib Bhattacharyya, Devdatt Dubhashi, Alexandru Gheorghiu",http://arxiv.org/pdf/2405.18489v2,cs.LG
Symbolic Regression for Beyond the Standard Model Physics,"We propose symbolic regression as a powerful tool for studying Beyond the
Standard Model physics. As a benchmark model, we consider the so-called
Constrained Minimal Supersymmetric Standard Model, which has a four-dimensional
parameter space defined at the GUT scale. We provide a set of analytical
expressions that reproduce three low-energy observables of interest in terms of
the parameters of the theory: the Higgs mass, the contribution to the anomalous
magnetic moment of the muon, and the cold dark matter relic density. To
demonstrate the power of the approach, we employ the symbolic expressions in a
global fits analysis to derive the posterior probability densities of the
parameters, which are obtained extremely rapidly in comparison with
conventional methods.",2024-05-28,"Shehu AbdusSalam, Steve Abel, Miguel Crispim Romao",http://arxiv.org/pdf/2405.18471v2,cs.LG
Unsupervised Model Tree Heritage Recovery,"The number of models shared online has recently skyrocketed, with over one
million public models available on Hugging Face. Sharing models allows other
users to build on existing models, using them as initialization for
fine-tuning, improving accuracy, and saving compute and energy. However, it
also raises important intellectual property issues, as fine-tuning may violate
the license terms of the original model or that of its training data. A Model
Tree, i.e., a tree data structure rooted at a foundation model and having
directed edges between a parent model and other models directly fine-tuned from
it (children), would settle such disputes by making the model heritage
explicit. Unfortunately, current models are not well documented, with most
model metadata (e.g., ""model cards"") not providing accurate information about
heritage. In this paper, we introduce the task of Unsupervised Model Tree
Heritage Recovery (Unsupervised MoTHer Recovery) for collections of neural
networks. For each pair of models, this task requires: i) determining if they
are directly related, and ii) establishing the direction of the relationship.
Our hypothesis is that model weights encode this information, the challenge is
to decode the underlying tree structure given the weights. We discover several
properties of model weights that allow us to perform this task. By using these
properties, we formulate the MoTHer Recovery task as finding a directed minimal
spanning tree. In extensive experiments we demonstrate that our method
successfully reconstructs complex Model Trees.",2024-05-28,"Eliahu Horwitz, Asaf Shul, Yedid Hoshen",http://arxiv.org/pdf/2405.18432v2,cs.LG
Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets,"We derive closed-form expressions for the Bayes optimal decision boundaries
in binary classification of high dimensional overlapping Gaussian mixture model
(GMM) data, and show how they depend on the eigenstructure of the class
covariances, for particularly interesting structured data. We empirically
demonstrate, through experiments on synthetic GMMs inspired by real-world data,
that deep neural networks trained for classification, learn predictors which
approximate the derived optimal classifiers. We further extend our study to
networks trained on authentic data, observing that decision thresholds
correlate with the covariance eigenvectors rather than the eigenvalues,
mirroring our GMM analysis. This provides theoretical insights regarding neural
networks' ability to perform probabilistic inference and distill statistical
patterns from intricate distributions.",2024-05-28,"Khen Cohen, Noam Levi, Yaron Oz",http://arxiv.org/pdf/2405.18427v1,cs.LG
Hierarchical World Models as Visual Whole-Body Humanoid Controllers,"Whole-body control for humanoids is challenging due to the high-dimensional
nature of the problem, coupled with the inherent instability of a bipedal
morphology. Learning from visual observations further exacerbates this
difficulty. In this work, we explore highly data-driven approaches to visual
whole-body humanoid control based on reinforcement learning, without any
simplifying assumptions, reward design, or skill primitives. Specifically, we
propose a hierarchical world model in which a high-level agent generates
commands based on visual observations for a low-level agent to execute, both of
which are trained with rewards. Our approach produces highly performant control
policies in 8 tasks with a simulated 56-DoF humanoid, while synthesizing
motions that are broadly preferred by humans.",2024-05-28,"Nicklas Hansen, Jyothir S V, Vlad Sobal, Yann LeCun, Xiaolong Wang, Hao Su",http://arxiv.org/pdf/2405.18418v3,cs.LG
Why are Visually-Grounded Language Models Bad at Image Classification?,"Image classification is one of the most fundamental capabilities of machine
vision intelligence. In this work, we revisit the image classification task
using visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We
find that existing proprietary and public VLMs, despite often using CLIP as a
vision encoder and having many more parameters, significantly underperform CLIP
on standard image classification benchmarks like ImageNet. To understand the
reason, we explore several hypotheses concerning the inference algorithms,
training objectives, and data processing in VLMs. Our analysis reveals that the
primary cause is data-related: critical information for image classification is
encoded in the VLM's latent space but can only be effectively decoded with
enough training data. Specifically, there is a strong correlation between the
frequency of class exposure during VLM training and instruction-tuning and the
VLM's performance in those classes; when trained with sufficient data, VLMs can
match the accuracy of state-of-the-art classification models. Based on these
findings, we enhance a VLM by integrating classification-focused datasets into
its training, and demonstrate that the enhanced classification performance of
the VLM transfers to its general capabilities, resulting in an improvement of
11.8% on the newly collected ImageWikiQA dataset.",2024-05-28,"Yuhui Zhang, Alyssa Unell, Xiaohan Wang, Dhruba Ghosh, Yuchang Su, Ludwig Schmidt, Serena Yeung-Levy",http://arxiv.org/pdf/2405.18415v2,cs.LG
Don't Forget to Connect! Improving RAG with Graph-based Reranking,"Retrieval Augmented Generation (RAG) has greatly improved the performance of
Large Language Model (LLM) responses by grounding generation with context from
existing documents. These systems work well when documents are clearly relevant
to a question context. But what about when a document has partial information,
or less obvious connections to the context? And how should we reason about
connections between documents? In this work, we seek to answer these two core
questions about RAG generation. We introduce G-RAG, a reranker based on graph
neural networks (GNNs) between the retriever and reader in RAG. Our method
combines both connections between documents and semantic information (via
Abstract Meaning Representation graphs) to provide a context-informed ranker
for RAG. G-RAG outperforms state-of-the-art approaches while having smaller
computational footprint. Additionally, we assess the performance of PaLM 2 as a
reranker and find it to significantly underperform G-RAG. This result
emphasizes the importance of reranking for RAG even when using Large Language
Models.",2024-05-28,"Jialin Dong, Bahare Fatemi, Bryan Perozzi, Lin F. Yang, Anton Tsitsulin",http://arxiv.org/pdf/2405.18414v1,cs.LG
Exploring Sectoral Profitability in the Indian Stock Market Using Deep Learning,"This paper explores using a deep learning Long Short-Term Memory (LSTM) model
for accurate stock price prediction and its implications for portfolio design.
Despite the efficient market hypothesis suggesting that predicting stock prices
is impossible, recent research has shown the potential of advanced algorithms
and predictive models. The study builds upon existing literature on stock price
prediction methods, emphasizing the shift toward machine learning and deep
learning approaches. Using historical stock prices of 180 stocks across 18
sectors listed on the NSE, India, the LSTM model predicts future prices. These
predictions guide buy/sell decisions for each stock and analyze sector
profitability. The study's main contributions are threefold: introducing an
optimized LSTM model for robust portfolio design, utilizing LSTM predictions
for buy/sell transactions, and insights into sector profitability and
volatility. Results demonstrate the efficacy of the LSTM model in accurately
predicting stock prices and informing investment decisions. By comparing sector
profitability and prediction accuracy, the work provides valuable insights into
the dynamics of the current financial markets in India.",2024-05-28,"Jaydip Sen, Hetvi Waghela, Sneha Rakshit",http://arxiv.org/pdf/2407.01572v1,cs.LG
Why Algorithms Remain Unjust: Power Structures Surrounding Algorithmic Activity,"Algorithms are unavoidable in our social lives, yet often perpetuate social
injustices. The popular means of addressing this is through algorithmic
reformism: fine-tuning algorithms themselves to be more fair, accountable, and
transparent. However, reformism fails to curtail algorithmic injustice because
it ignores the power structure surrounding algorithms. Heeding calls from
critical algorithm studies, I employ a framework developed by Erik Olin Wright
to examine the configuration of power surrounding algorithmic systems in
society (Algorithmic Activity). Algorithmic Activity is unjust because it is
dominated by economic power. To create socially just Algorithmic Activity, the
power configuration must instead empower end users. I explore Wright's
symbiotic, interstitial, and raptural transformations in the context of just
Algorithmic Activity. My vision for social justice in algorithmic systems
requires a continuous (re)evaluation of how power can be transformed in light
of current structure, social theories, evolving methodologies, and one's
relationship to power itself.",2024-05-28,Andrew Balch,http://arxiv.org/pdf/2405.18461v2,cs.LG
Phased Consistency Models,"Consistency Models (CMs) have made significant progress in accelerating the
generation of diffusion models. However, their application to high-resolution,
text-conditioned image generation in the latent space remains unsatisfactory.
In this paper, we identify three key flaws in the current design of Latent
Consistency Models (LCMs). We investigate the reasons behind these limitations
and propose Phased Consistency Models (PCMs), which generalize the design space
and address the identified limitations. Our evaluations demonstrate that PCMs
outperform LCMs across 1--16 step generation settings. While PCMs are
specifically designed for multi-step refinement, they achieve comparable 1-step
generation results to previously state-of-the-art specifically designed 1-step
methods. Furthermore, we show the methodology of PCMs is versatile and
applicable to video generation, enabling us to train the state-of-the-art
few-step text-to-video generator. Our code is available at
https://github.com/G-U-N/Phased-Consistency-Model.",2024-05-28,"Fu-Yun Wang, Zhaoyang Huang, Alexander William Bergman, Dazhong Shen, Peng Gao, Michael Lingelbach, Keqiang Sun, Weikang Bian, Guanglu Song, Yu Liu, Xiaogang Wang, Hongsheng Li",http://arxiv.org/pdf/2405.18407v2,cs.LG
Probing the Information Theoretical Roots of Spatial Dependence Measures,"Intuitively, there is a relation between measures of spatial dependence and
information theoretical measures of entropy. For instance, we can provide an
intuition of why spatial data is special by stating that, on average, spatial
data samples contain less than expected information. Similarly, spatial data,
e.g., remotely sensed imagery, that is easy to compress is also likely to show
significant spatial autocorrelation. Formulating our (highly specific) core
concepts of spatial information theory in the widely used language of
information theory opens new perspectives on their differences and similarities
and also fosters cross-disciplinary collaboration, e.g., with the broader AI/ML
communities. Interestingly, however, this intuitive relation is challenging to
formalize and generalize, leading prior work to rely mostly on experimental
results, e.g., for describing landscape patterns. In this work, we will explore
the information theoretical roots of spatial autocorrelation, more specifically
Moran's I, through the lens of self-information (also known as surprisal) and
provide both formal proofs and experiments.",2024-05-28,"Zhangyu Wang, Krzysztof Janowicz, Gengchen Mai, Ivan Majic",http://arxiv.org/pdf/2405.18459v2,cs.LG
Explicit Formulae to Interchangeably use Hyperplanes and Hyperballs using Inversive Geometry,"Many algorithms require discriminative boundaries, such as separating
hyperplanes or hyperballs, or are specifically designed to work on spherical
data. By applying inversive geometry, we show that the two discriminative
boundaries can be used interchangeably, and that general Euclidean data can be
transformed into spherical data, whenever a change in point distances is
acceptable. We provide explicit formulae to embed general Euclidean data into
spherical data and to unembed it back. We further show a duality between
hyperspherical caps, i.e., the volume created by a separating hyperplane on
spherical data, and hyperballs and provide explicit formulae to map between the
two. We further provide equations to translate inner products and Euclidean
distances between the two spaces, to avoid explicit embedding and unembedding.
We also provide a method to enforce projections of the general Euclidean space
onto hemi-hyperspheres and propose an intrinsic dimensionality based method to
obtain ""all-purpose"" parameters. To show the usefulness of the
cap-ball-duality, we discuss example applications in machine learning and
vector similarity search.",2024-05-28,"Erik Thordsen, Erich Schubert",http://arxiv.org/pdf/2405.18401v1,cs.LG
Superposed Decoding: Multiple Generations from a Single Autoregressive Inference Pass,"Many applications today provide users with multiple auto-complete drafts as
they type, including GitHub's code completion, Gmail's smart compose, and
Apple's messaging auto-suggestions. Under the hood, language models support
this by running an autoregressive inference pass to provide a draft.
Consequently, providing $k$ drafts to the user requires running an expensive
language model $k$ times. To alleviate the computation cost of running $k$
inference passes, we propose Superposed Decoding, a new decoding algorithm that
generates $k$ drafts at the computation cost of one autoregressive inference
pass. We achieve this by feeding a superposition of the most recent token
embeddings from the $k$ drafts as input to the next decoding step of the
language model. At every inference step we combine the $k$ drafts with the
top-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,
using an n-gram interpolation with minimal compute overhead to filter out
incoherent generations. Our experiments show that $k$ drafts from Superposed
Decoding are at least as coherent and factual as Nucleus Sampling and Greedy
Decoding respectively, while being at least $2.44\times$ faster for $k\ge3$. In
a compute-normalized setting, user evaluations demonstrably favor text
generated by Superposed Decoding over Nucleus Sampling. Superposed Decoding can
also be combined with other decoding strategies, resulting in universal
coverage gains when scaling inference time compute. Code and more examples
open-sourced at https://github.com/RAIVNLab/SuperposedDecoding.",2024-05-28,"Ethan Shen, Alan Fan, Sarah M. Pratt, Jae Sung Park, Matthew Wallingford, Sham M. Kakade, Ari Holtzman, Ranjay Krishna, Ali Farhadi, Aditya Kusupati",http://arxiv.org/pdf/2405.18400v6,cs.LG
QUEST: Quality-Aware Metropolis-Hastings Sampling for Machine Translation,"An important challenge in machine translation (MT) is to generate
high-quality and diverse translations. Prior work has shown that the estimated
likelihood from the MT model correlates poorly with translation quality. In
contrast, quality evaluation metrics (such as COMET or BLEURT) exhibit high
correlations with human judgments, which has motivated their use as rerankers
(such as quality-aware and minimum Bayes risk decoding). However, relying on a
single translation with high estimated quality increases the chances of ""gaming
the metric''. In this paper, we address the problem of sampling a set of
high-quality and diverse translations. We provide a simple and effective way to
avoid over-reliance on noisy quality estimates by using them as the energy
function of a Gibbs distribution. Instead of looking for a mode in the
distribution, we generate multiple samples from high-density areas through the
Metropolis-Hastings algorithm, a simple Markov chain Monte Carlo approach. The
results show that our proposed method leads to high-quality and diverse outputs
across multiple language pairs (English$\leftrightarrow${German, Russian}) with
two strong decoder-only LLMs (Alma-7b, Tower-7b).",2024-05-28,"Gonçalo R. A. Faria, Sweta Agrawal, António Farinhas, Ricardo Rei, José G. C. de Souza, André F. T. Martins",http://arxiv.org/pdf/2406.00049v2,cs.LG
MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit Tests with Autocorrelations,"A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis
tasks, such as grouping vehicle sensor trajectories, can be formulated as
clustering with given metric constraints. Existing metric-constrained
clustering algorithms overlook the rich correlation between feature similarity
and metric distance, i.e., metric autocorrelation. The model-based variations
of these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance,
yet suffer from computational instability and complexity by using a
metric-constrained Expectation-Maximization procedure. In order to address
these two problems, we propose a novel clustering algorithm, MC-GTA
(Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Its
objective is only composed of pairwise weighted sums of feature similarity
terms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel
multivariate generalization of classic semivariogram). We show that MC-GTA is
effectively minimizing the total hinge loss for intra-cluster observation pairs
not passing goodness-of-fit tests, i.e., statistically not originating from the
same distribution. Experiments on 1D/2D synthetic and real-world datasets
demonstrate that MC-GTA successfully incorporates metric autocorrelation. It
outperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in
NMI) with faster and stabler optimization (>10x speedup).",2024-05-28,"Zhangyu Wang, Gengchen Mai, Krzysztof Janowicz, Ni Lao",http://arxiv.org/pdf/2405.18395v2,cs.LG
Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations,"Scale has become a main ingredient in obtaining strong machine learning
models. As a result, understanding a model's scaling properties is key to
effectively designing both the right training setup as well as future
generations of architectures. In this work, we argue that scale and training
research has been needlessly complex due to reliance on the cosine schedule,
which prevents training across different lengths for the same model size. We
investigate the training behavior of a direct alternative -- constant learning
rate and cooldowns -- and find that it scales predictably and reliably similar
to cosine. Additionally, we show that stochastic weight averaging yields
improved performance along the training trajectory, without additional training
costs, across different scales. Importantly, with these findings we demonstrate
that scaling experiments can be performed with significantly reduced compute
and GPU hours by utilizing fewer but reusable training runs. Our code is
available at \url{https://github.com/epfml/schedules-and-scaling/}.",2024-05-28,"Alexander Hägele, Elie Bakouch, Atli Kosson, Loubna Ben Allal, Leandro Von Werra, Martin Jaggi",http://arxiv.org/pdf/2405.18392v3,cs.LG
Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning,"Recent advances in text-to-music editing, which employ text queries to modify
music (e.g.\ by changing its style or adjusting instrumental components),
present unique challenges and opportunities for AI-assisted music creation.
Previous approaches in this domain have been constrained by the necessity to
train specific editing models from scratch, which is both resource-intensive
and inefficient; other research uses large language models to predict edited
music, resulting in imprecise audio reconstruction. To Combine the strengths
and address these limitations, we introduce Instruct-MusicGen, a novel approach
that finetunes a pretrained MusicGen model to efficiently follow editing
instructions such as adding, removing, or separating stems. Our approach
involves a modification of the original MusicGen architecture by incorporating
a text fusion module and an audio fusion module, which allow the model to
process instruction texts and audio inputs concurrently and yield the desired
edited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters
to the original MusicGen model and only trains for 5K steps, yet it achieves
superior performance across all tasks compared to existing baselines, and
demonstrates performance comparable to the models trained for specific tasks.
This advancement not only enhances the efficiency of text-to-music editing but
also broadens the applicability of music language models in dynamic music
production environments.",2024-05-28,"Yixiao Zhang, Yukara Ikemiya, Woosung Choi, Naoki Murata, Marco A. Martínez-Ramírez, Liwei Lin, Gus Xia, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon",http://arxiv.org/pdf/2405.18386v2,cs.LG
Asymmetrical estimator for training encapsulated deep photonic neural networks,"Photonic neural networks (PNNs) are fast in-propagation and high bandwidth
paradigms that aim to popularize reproducible NN acceleration with higher
efficiency and lower cost. However, the training of PNN is known to be
challenging, where the device-to-device and system-to-system variations create
imperfect knowledge of the PNN. Despite backpropagation (BP)-based training
algorithms being the industry standard for their robustness, generality, and
fast gradient convergence for digital training, existing PNN-BP methods rely
heavily on accurate intermediate state extraction or extensive computational
resources for deep PNNs (DPNNs). The truncated photonic signal propagation and
the computation overhead bottleneck DPNN's operation efficiency and increase
system construction cost. Here, we introduce the asymmetrical training (AsyT)
method, tailored for encapsulated DPNNs, where the signal is preserved in the
analogue photonic domain for the entire structure. AsyT offers a lightweight
solution for DPNNs with minimum readouts, fast and energy-efficient operation,
and minimum system footprint. AsyT's ease of operation, error tolerance, and
generality aim to promote PNN acceleration in a widened operational scenario
despite the fabrication variations and imperfect controls. We demonstrated AsyT
for encapsulated DPNN with integrated photonic chips, repeatably enhancing the
performance from in-silico BP for different network structures and datasets.",2024-05-28,"Yizhi Wang, Minjia Chen, Chunhui Yao, Jie Ma, Ting Yan, Richard Penty, Qixiang Cheng",http://arxiv.org/pdf/2405.18458v4,cs.LG
Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation,"The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)
challenge aims to advance automated segmentation algorithms using the largest
known multi-institutional dataset of radiotherapy planning brain MRIs with
expert-annotated target labels for patients with intact or postoperative
meningioma that underwent either conventional external beam radiotherapy or
stereotactic radiosurgery. Each case includes a defaced 3D post-contrast
T1-weighted radiotherapy planning MRI in its native acquisition space,
accompanied by a single-label ""target volume"" representing the gross tumor
volume (GTV) and any at-risk postoperative site. Target volume annotations
adhere to established radiotherapy planning protocols, ensuring consistency
across cases and institutions. For preoperative meningiomas, the target volume
encompasses the entire GTV and associated nodular dural tail, while for
postoperative cases, it includes at-risk resection cavity margins as determined
by the treating institution. Case annotations were reviewed and approved by
expert neuroradiologists and radiation oncologists. Participating teams will
develop, containerize, and evaluate automated segmentation models using this
comprehensive dataset. Model performance will be assessed using an adapted
lesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The
top-performing teams will be recognized at the Medical Image Computing and
Computer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is
expected to significantly advance automated radiotherapy planning by enabling
precise tumor segmentation and facilitating tailored treatment, ultimately
improving patient outcomes.",2024-05-28,"Dominic LaBella, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, Omar Al-Salihi, Justin Leu, Lia Halasz, Yury Velichko, Chunhao Wang, John Kirkpatrick, Scott Floyd, Zachary J. Reitman, Trey Mullikin, Ulas Bagci, Sean Sachdev, Jona A. Hattangadi-Gluth, Tyler Seibert, Nikdokht Farid, Connor Puett, Matthew W. Pease, Kevin Shiue, Syed Muhammad Anwar, Shahriar Faghani, Muhammad Ammar Haider, Pranav Warman, Jake Albrecht, András Jakab, Mana Moassefi, Verena Chung, Alejandro Aristizabal, Alexandros Karargyris, Hasan Kassem, Sarthak Pati, Micah Sheller, Christina Huang, Aaron Coley, Siddharth Ghanta, Alex Schneider, Conrad Sharp, Rachit Saluja, Florian Kofler, Philipp Lohmann, Phillipp Vollmuth, Louis Gagnon, Maruf Adewole, Hongwei Bran Li, Anahita Fathi Kazerooni, Nourel Hoda Tahon, Udunna Anazodo, Ahmed W. Moawad, Bjoern Menze, Marius George Linguraru, Mariam Aboian, Benedikt Wiestler, Ujjwal Baid, Gian-Marco Conte, Andreas M. Rauschecker, Ayman Nada, Aly H. Abayazeed, Raymond Huang, Maria Correia de Verdier, Jeffrey D. Rudie, Spyridon Bakas, Evan Calabrese",http://arxiv.org/pdf/2405.18383v2,cs.LG
OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning,"The rapid advancements in Large Language Models (LLMs) have revolutionized
various natural language processing tasks. However, the substantial size of
LLMs presents significant challenges in training or fine-tuning. While
parameter-efficient approaches such as low-rank adaptation (LoRA) have gained
popularity, they often compromise performance compared to full-rank
fine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled
Low-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,
inspired by the layerwise outlier distribution of LLMs. Unlike LoRA, which adds
extra adapters to all layers, OwLore strategically assigns higher sampling
probabilities to layers with more outliers, selectively sampling only a few
layers and fine-tuning their pre-trained weights. To further increase the
number of fine-tuned layers without a proportional rise in memory costs, we
incorporate gradient low-rank projection, further boosting the approach's
performance. Our extensive experiments across various architectures, including
LLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms
baseline approaches, including full fine-tuning. Specifically, it achieves up
to a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0%
improvement on MMLU, and a notable 10% boost on MT-Bench, while being more
memory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of
memory. Code is available at https://github.com/pixeli99/OwLore.",2024-05-28,"Pengxiang Li, Lu Yin, Xiaowei Gao, Shiwei Liu",http://arxiv.org/pdf/2405.18380v2,cs.LG
A Canonicalization Perspective on Invariant and Equivariant Learning,"In many applications, we desire neural networks to exhibit invariance or
equivariance to certain groups due to symmetries inherent in the data.
Recently, frame-averaging methods emerged to be a unified framework for
attaining symmetries efficiently by averaging over input-dependent subsets of
the group, i.e., frames. What we currently lack is a principled understanding
of the design of frames. In this work, we introduce a canonicalization
perspective that provides an essential and complete view of the design of
frames. Canonicalization is a classic approach for attaining invariance by
mapping inputs to their canonical forms. We show that there exists an inherent
connection between frames and canonical forms. Leveraging this connection, we
can efficiently compare the complexity of frames as well as determine the
optimality of certain frames. Guided by this principle, we design novel frames
for eigenvectors that are strictly superior to existing methods -- some are
even optimal -- both theoretically and empirically. The reduction to the
canonicalization perspective further uncovers equivalences between previous
methods. These observations suggest that canonicalization provides a
fundamental understanding of existing frame-averaging methods and unifies
existing equivariant and invariant learning methods. Code is available at
https://github.com/PKU-ML/canonicalization.",2024-05-28,"George Ma, Yifei Wang, Derek Lim, Stefanie Jegelka, Yisen Wang",http://arxiv.org/pdf/2405.18378v4,cs.LG
A Note on the Prediction-Powered Bootstrap,"We introduce PPBoot: a bootstrap-based method for prediction-powered
inference. PPBoot is applicable to arbitrary estimation problems and is very
simple to implement, essentially only requiring one application of the
bootstrap. Through a series of examples, we demonstrate that PPBoot often
performs nearly identically to (and sometimes better than) the earlier PPI(++)
method based on asymptotic normality$\unicode{x2013}$when the latter is
applicable$\unicode{x2013}$without requiring any asymptotic characterizations.
Given its versatility, PPBoot could simplify and expand the scope of
application of prediction-powered inference to problems where central limit
theorems are hard to prove.",2024-05-28,Tijana Zrnic,http://arxiv.org/pdf/2405.18379v3,cs.LG
Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning,"Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model
to a target domain using only unlabeled target data. Current SFDA methods face
challenges in effectively leveraging pre-trained knowledge and exploiting
target domain data. Multimodal Large Language Models (MLLMs) offer remarkable
capabilities in understanding visual and textual information, but their
applicability to SFDA poses challenges such as instruction-following failures,
intensive computational demands, and difficulties in performance measurement
prior to adaptation. To alleviate these issues, we propose
$\textbf{Reliability-based Curriculum Learning (RCL)}$, a novel framework that
integrates multiple MLLMs for knowledge exploitation via pseudo-labeling in
SFDA. Our framework incorporates Reliable Knowledge Transfer, Self-correcting
and MLLM-guided Knowledge Expansion, and Multi-hot Masking Refinement to
progressively exploit unlabeled data in the target domain. RCL achieves
state-of-the-art (SOTA) performance on multiple SFDA benchmarks, e.g.,
$\textbf{+9.4%}$ on DomainNet, demonstrating its effectiveness in enhancing
adaptability and robustness without requiring access to source data. Our code
is available at: https://github.com/Dong-Jie-Chen/RCL.",2024-05-28,"Dongjie Chen, Kartik Patwari, Zhengfeng Lai, Xiaoguang Zhu, Sen-ching Cheung, Chen-Nee Chuah",http://arxiv.org/pdf/2405.18376v2,cs.LG
A Hessian-Aware Stochastic Differential Equation for Modelling SGD,"Continuous-time approximation of Stochastic Gradient Descent (SGD) is a
crucial tool to study its escaping behaviors from stationary points. However,
existing stochastic differential equation (SDE) models fail to fully capture
these behaviors, even for simple quadratic objectives. Built on a novel
stochastic backward error analysis framework, we derive the Hessian-Aware
Stochastic Modified Equation (HA-SME), an SDE that incorporates Hessian
information of the objective function into both its drift and diffusion terms.
Our analysis shows that HA-SME matches the order-best approximation error
guarantee among existing SDE models in the literature, while achieving a
significantly reduced dependence on the smoothness parameter of the objective.
Further, for quadratic objectives, under mild conditions, HA-SME is proved to
be the first SDE model that recovers exactly the SGD dynamics in the
distributional sense. Consequently, when the local landscape near a stationary
point can be approximated by quadratics, HA-SME is expected to accurately
predict the local escaping behaviors of SGD.",2024-05-28,"Xiang Li, Zebang Shen, Liang Zhang, Niao He",http://arxiv.org/pdf/2405.18373v2,cs.LG
PromptWizard: Task-Aware Prompt Optimization Framework,"Large language models (LLMs) have transformed AI across diverse domains, with
prompting being central to their success in guiding model outputs. However,
manual prompt engineering is both labor-intensive and domain-specific,
necessitating the need for automated solutions. We introduce PromptWizard, a
novel, fully automated framework for discrete prompt optimization, utilizing a
self-evolving, self-adapting mechanism. Through a feedback-driven critique and
synthesis process, PromptWizard achieves an effective balance between
exploration and exploitation, iteratively refining both prompt instructions and
in-context examples to generate human-readable, task-specific prompts. This
guided approach systematically improves prompt quality, resulting in superior
performance across 45 tasks. PromptWizard excels even with limited training
data, smaller LLMs, and various LLM architectures. Additionally, our cost
analysis reveals a substantial reduction in API calls, token usage, and overall
cost, demonstrating PromptWizard's efficiency, scalability, and advantages over
existing prompt optimization strategies.",2024-05-28,"Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, Akshay Nambi",http://arxiv.org/pdf/2405.18369v2,cs.LG
Towards a theory of how the structure of language is acquired by deep neural networks,"How much data is required to learn the structure of a language via next-token
prediction? We study this question for synthetic datasets generated via a
Probabilistic Context-Free Grammar (PCFG) -- a tree-like generative model that
captures many of the hierarchical structures found in natural languages. We
determine token-token correlations analytically in our model and show that they
can be used to build a representation of the grammar's hidden variables, the
longer the range the deeper the variable. In addition, a finite training set
limits the resolution of correlations to an effective range, whose size grows
with that of the training set. As a result, a Language Model trained with
increasingly many examples can build a deeper representation of the grammar's
structure, thus reaching good performance despite the high dimensionality of
the problem. We conjecture that the relationship between training set size and
effective range of correlations holds beyond our synthetic datasets. In
particular, our conjecture predicts how the scaling law for the test loss
behaviour with training set size depends on the length of the context window,
which we confirm empirically in Shakespeare's plays and Wikipedia articles.",2024-05-28,"Francesco Cagnetta, Matthieu Wyart",http://arxiv.org/pdf/2406.00048v3,cs.LG
Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes,"Scaling hyperparameter optimisation to very large datasets remains an open
problem in the Gaussian process community. This paper focuses on iterative
methods, which use linear system solvers, like conjugate gradients, alternating
projections or stochastic gradient descent, to construct an estimate of the
marginal likelihood gradient. We discuss three key improvements which are
applicable across solvers: (i) a pathwise gradient estimator, which reduces the
required number of solver iterations and amortises the computational cost of
making predictions, (ii) warm starting linear system solvers with the solution
from the previous step, which leads to faster solver convergence at the cost of
negligible bias, (iii) early stopping linear system solvers after a limited
computational budget, which synergises with warm starting, allowing solver
progress to accumulate over multiple marginal likelihood steps. These
techniques provide speed-ups of up to $72\times$ when solving to tolerance, and
decrease the average residual norm by up to $7\times$ when stopping early.",2024-05-28,"Jihao Andreas Lin, Shreyas Padhy, Bruno Mlodozeniec, Javier Antorán, José Miguel Hernández-Lobato",http://arxiv.org/pdf/2405.18457v4,cs.LG
Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs,"Large language models (LLMs) are at the forefront of transforming numerous
domains globally. However, their inclusivity and effectiveness remain limited
for non-Latin scripts and low-resource languages. This paper tackles the
imperative challenge of enhancing the multilingual performance of LLMs without
extensive training or fine-tuning. Through systematic investigation and
evaluation of diverse languages using popular question-answering (QA) datasets,
we present novel techniques that unlock the true potential of LLMs in a
polyglot landscape. Our approach encompasses three key strategies that yield
significant improvements in multilingual proficiency. First, by meticulously
optimizing prompts tailored for polyglot LLMs, we unlock their latent
capabilities, resulting in substantial performance boosts across languages.
Second, we introduce a new hybrid approach that synergizes LLM Retrieval
Augmented Generation (RAG) with multilingual embeddings and achieves improved
multilingual task performance. Finally, we introduce a novel learning approach
that dynamically selects the optimal prompt strategy, LLM model, and embedding
model per query at run-time. This dynamic adaptation maximizes the efficacy of
LLMs across languages, outperforming best static and random strategies.
Additionally, our approach adapts configurations in both offline and online
settings, and can seamlessly adapt to new languages and datasets, leading to
substantial advancements in multilingual understanding and generation across
diverse languages.",2024-05-28,"Somnath Kumar, Vaibhav Balloli, Mercy Ranjit, Kabir Ahuja, Tanuja Ganu, Sunayana Sitaram, Kalika Bali, Akshay Nambi",http://arxiv.org/pdf/2405.18359v1,cs.LG
MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning,"Recent advancements in Multi-modal Large Language Models (MLLMs) have
significantly improved their performance in tasks combining vision and
language. However, challenges persist in detailed multi-modal understanding,
comprehension of complex tasks, and reasoning over multi-modal information.
This paper introduces MMCTAgent, a novel multi-modal critical thinking agent
framework designed to address the inherent limitations of current MLLMs in
complex visual reasoning tasks. Inspired by human cognitive processes and
critical thinking, MMCTAgent iteratively analyzes multi-modal information,
decomposes queries, plans strategies, and dynamically evolves its reasoning.
Additionally, MMCTAgent incorporates critical thinking elements such as
verification of final answers and self-reflection through a novel approach that
defines a vision-based critic and identifies task-specific evaluation criteria,
thereby enhancing its decision-making abilities. Through rigorous evaluations
across various image and video understanding benchmarks, we demonstrate that
MMCTAgent (with and without the critic) outperforms both foundational MLLMs and
other tool-augmented pipelines.",2024-05-28,"Somnath Kumar, Yash Gadhia, Tanuja Ganu, Akshay Nambi",http://arxiv.org/pdf/2405.18358v1,cs.LG
Infinite-dimensional Diffusion Bridge Simulation via Operator Learning,"The diffusion bridge, which is a diffusion process conditioned on hitting a
specific state within a finite period, has found broad applications in various
scientific and engineering fields. However, simulating diffusion bridges for
modeling natural data can be challenging due to both the intractability of the
drift term and continuous representations of the data. Although several methods
are available to simulate finite-dimensional diffusion bridges,
infinite-dimensional cases remain under explored. This paper presents a method
that merges score matching techniques with operator learning, enabling a direct
approach to learn the infinite-dimensional bridge and achieving a
discretization equivariant bridge simulation. We conduct a series of
experiments, ranging from synthetic examples with closed-form solutions to the
stochastic nonlinear evolution of real-world biological shape data. Our method
demonstrates high efficacy, particularly due to its ability to adapt to any
resolution without extra training.",2024-05-28,"Gefan Yang, Elizabeth Louise Baker, Michael L. Severinsen, Christy Anna Hipsley, Stefan Sommer",http://arxiv.org/pdf/2405.18353v3,cs.LG
Evaluating Bayesian deep learning for radio galaxy classification,"The radio astronomy community is rapidly adopting deep learning techniques to
deal with the huge data volumes expected from the next generation of radio
observatories. Bayesian neural networks (BNNs) provide a principled way to
model uncertainty in the predictions made by such deep learning models and will
play an important role in extracting well-calibrated uncertainty estimates on
their outputs. In this work, we evaluate the performance of different BNNs
against the following criteria: predictive performance, uncertainty calibration
and distribution-shift detection for the radio galaxy classification problem.",2024-05-28,"Devina Mohan, Anna M. M. Scaife",http://arxiv.org/pdf/2405.18351v1,cs.LG
Dataset Growth,"Deep learning benefits from the growing abundance of available data.
Meanwhile, efficiently dealing with the growing data scale has become a
challenge. Data publicly available are from different sources with various
qualities, and it is impractical to do manual cleaning against noise and
redundancy given today's data scale. There are existing techniques for
cleaning/selecting the collected data. However, these methods are mainly
proposed for offline settings that target one of the cleanness and redundancy
problems. In practice, data are growing exponentially with both problems. This
leads to repeated data curation with sub-optimal efficiency. To tackle this
challenge, we propose InfoGrowth, an efficient online algorithm for data
cleaning and selection, resulting in a growing dataset that keeps up to date
with awareness of cleanliness and diversity. InfoGrowth can improve data
quality/efficiency on both single-modal and multi-modal tasks, with an
efficient and scalable design. Its framework makes it practical for real-world
data engines.",2024-05-28,"Ziheng Qin, Zhaopan Xu, Yukun Zhou, Zangwei Zheng, Zebang Cheng, Hao Tang, Lei Shang, Baigui Sun, Xiaojiang Peng, Radu Timofte, Hongxun Yao, Kai Wang, Yang You",http://arxiv.org/pdf/2405.18347v2,cs.LG
Interpretable classification of wiki-review streams,"Wiki articles are created and maintained by a crowd of editors, producing a
continuous stream of reviews. Reviews can take the form of additions, reverts,
or both. This crowdsourcing model is exposed to manipulation since neither
reviews nor editors are automatically screened and purged. To protect articles
against vandalism or damage, the stream of reviews can be mined to classify
reviews and profile editors in real-time. The goal of this work is to
anticipate and explain which reviews to revert. This way, editors are informed
why their edits will be reverted. The proposed method employs stream-based
processing, updating the profiling and classification models on each incoming
event. The profiling uses side and content-based features employing Natural
Language Processing, and editor profiles are incrementally updated based on
their reviews. Since the proposed method relies on self-explainable
classification algorithms, it is possible to understand why a review has been
classified as a revert or a non-revert. In addition, this work contributes an
algorithm for generating synthetic data for class balancing, making the final
classification fairer. The proposed online method was tested with a real data
set from Wikivoyage, which was balanced through the aforementioned synthetic
data generation. The results attained near-90 % values for all evaluation
metrics (accuracy, precision, recall, and F-measure).",2024-05-28,"Silvia García Méndez, Fátima Leal, Benedita Malheiro, Juan Carlos Burguillo Rial",http://arxiv.org/pdf/2405.18335v1,cs.LG
SketchQL Demonstration: Zero-shot Video Moment Querying with Sketches,"In this paper, we will present SketchQL, a video database management system
(VDBMS) for retrieving video moments with a sketch-based query interface. This
novel interface allows users to specify object trajectory events with simple
mouse drag-and-drop operations. Users can use trajectories of single objects as
building blocks to compose complex events. Using a pre-trained model that
encodes trajectory similarity, SketchQL achieves zero-shot video moments
retrieval by performing similarity searches over the video to identify clips
that are the most similar to the visual query. In this demonstration, we
introduce the graphic user interface of SketchQL and detail its functionalities
and interaction mechanisms. We also demonstrate the end-to-end usage of
SketchQL from query composition to video moments retrieval using real-world
scenarios.",2024-05-28,"Renzhi Wu, Pramod Chunduri, Dristi J Shah, Ashmitha Julius Aravind, Ali Payani, Xu Chu, Joy Arulraj, Kexin Rong",http://arxiv.org/pdf/2405.18334v3,cs.LG
Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes,"Gaussian processes are a versatile probabilistic machine learning model whose
effectiveness often depends on good hyperparameters, which are typically
learned by maximising the marginal likelihood. In this work, we consider
iterative methods, which use iterative linear system solvers to approximate
marginal likelihood gradients up to a specified numerical precision, allowing a
trade-off between compute time and accuracy of a solution. We introduce a
three-level hierarchy of marginal likelihood optimisation for iterative
Gaussian processes, and identify that the computational costs are dominated by
solving sequential batches of large positive-definite systems of linear
equations. We then propose to amortise computations by reusing solutions of
linear system solvers as initialisations in the next step, providing a
$\textit{warm start}$. Finally, we discuss the necessary conditions and
quantify the consequences of warm starts and demonstrate their effectiveness on
regression tasks, where warm starts achieve the same results as the
conventional procedure while providing up to a $16 \times$ average speed-up
among datasets.",2024-05-28,"Jihao Andreas Lin, Shreyas Padhy, Bruno Mlodozeniec, José Miguel Hernández-Lobato",http://arxiv.org/pdf/2405.18328v1,cs.LG
Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial,"Predictive biomarkers of treatment response are lacking for metastatic clear
cell renal cell carcinoma (ccRCC), a tumor type that is treated with
angiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a
HIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is
arguably the best candidate to predict anti-angiogenic (AA) response. However,
the clinical adoption of transcriptomic assays faces several challenges
including standardization, time delay, and high cost. Further, ccRCC tumors are
highly heterogenous, and sampling multiple areas for sequencing is impractical.
Here we present a novel deep learning (DL) approach to predict the Angioscore
from ubiquitous histopathology slides. To overcome the lack of
interpretability, one of the biggest limitations of typical DL models, our
model produces a visual vascular network which is the basis of the model's
prediction. To test its reliability, we applied this model to multiple cohorts
including a clinical trial dataset. Our model accurately predicts the RNA-based
Angioscore on multiple independent cohorts (spearman correlations of 0.77 and
0.73). Further, the predictions help unravel meaningful biology such as
association of angiogenesis with grade, stage, and driver mutation status.
Finally, we find our model can predict response to AA therapy, in both a
real-world cohort and the IMmotion150 clinical trial. The predictive power of
our model vastly exceeds that of CD31, a marker of vasculature, and nearly
rivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based
Angioscore at a fraction of the cost. By providing a robust yet interpretable
prediction of the Angioscore from histopathology slides alone, our approach
offers insights into angiogenesis biology and AA treatment response.",2024-05-28,"Jay Jasti, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jeffrey Miyata, Deyssy Carrillo, Alana Christie, Dinesh Rakheja, Zora Modrusan, Edward Ernest Kadel III, Niha Beig, Mahrukh Huseni, James Brugarolas, Payal Kapur, Satwik Rajaram",http://arxiv.org/pdf/2405.18327v1,cs.LG
Deriving Causal Order from Single-Variable Interventions: Guarantees & Algorithm,"Targeted and uniform interventions to a system are crucial for unveiling
causal relationships. While several methods have been developed to leverage
interventional data for causal structure learning, their practical application
in real-world scenarios often remains challenging. Recent benchmark studies
have highlighted these difficulties, even when large numbers of single-variable
intervention samples are available. In this work, we demonstrate, both
theoretically and empirically, that such datasets contain a wealth of causal
information that can be effectively extracted under realistic assumptions about
the data distribution. More specifically, we introduce a novel variant of
interventional faithfulness, which relies on comparisons between the marginal
distributions of each variable across observational and interventional
settings, and we introduce a score on causal orders. Under this assumption, we
are able to prove strong theoretical guarantees on the optimum of our score
that also hold for large-scale settings. To empirically verify our theory, we
introduce Intersort, an algorithm designed to infer the causal order from
datasets containing large numbers of single-variable interventions by
approximately optimizing our score. Intersort outperforms baselines (GIES,
DCDI, PC and EASE) on almost all simulated data settings replicating common
benchmarks in the field. Our proposed novel approach to modeling interventional
datasets thus offers a promising avenue for advancing causal inference,
highlighting significant potential for further enhancements under realistic
assumptions.",2024-05-28,"Mathieu Chevalley, Patrick Schwab, Arash Mehrjou",http://arxiv.org/pdf/2405.18314v3,cs.LG
Deterministic and statistical calibration of constitutive models from full-field data with parametric physics-informed neural networks,"The calibration of constitutive models from full-field data has recently
gained increasing interest due to improvements in full-field measurement
capabilities. In addition to the experimental characterization of novel
materials, continuous structural health monitoring is another application that
is of great interest. However, monitoring is usually associated with severe
time constraints, difficult to meet with standard numerical approaches.
Therefore, parametric physics-informed neural networks (PINNs) for constitutive
model calibration from full-field displacement data are investigated. In an
offline stage, a parametric PINN can be trained to learn a parameterized
solution of the underlying partial differential equation. In the subsequent
online stage, the parametric PINN then acts as a surrogate for the
parameters-to-state map in calibration. We test the proposed approach for the
deterministic least-squares calibration of a linear elastic as well as a
hyperelastic constitutive model from noisy synthetic displacement data. We
further carry out Markov chain Monte Carlo-based Bayesian inference to quantify
the uncertainty. A proper statistical evaluation of the results underlines the
high accuracy of the deterministic calibration and that the estimated
uncertainty is valid. Finally, we consider experimental data and show that the
results are in good agreement with a finite element method-based calibration.
Due to the fast evaluation of PINNs, calibration can be performed in near
real-time. This advantage is particularly evident in many-query applications
such as Markov chain Monte Carlo-based Bayesian inference.",2024-05-28,"David Anton, Jendrik-Alexander Tröger, Henning Wessels, Ulrich Römer, Alexander Henkes, Stefan Hartmann",http://arxiv.org/pdf/2405.18311v2,cs.LG
Learning Staged Trees from Incomplete Data,"Staged trees are probabilistic graphical models capable of representing any
class of non-symmetric independence via a coloring of its vertices. Several
structural learning routines have been defined and implemented to learn staged
trees from data, under the frequentist or Bayesian paradigm. They assume a data
set has been observed fully and, in practice, observations with missing entries
are either dropped or imputed before learning the model. Here, we introduce the
first algorithms for staged trees that handle missingness within the learning
of the model. To this end, we characterize the likelihood of staged tree models
in the presence of missing data and discuss pseudo-likelihoods that approximate
it. A structural expectation-maximization algorithm estimating the model
directly from the full likelihood is also implemented and evaluated. A
computational experiment showcases the performance of the novel learning
algorithms, demonstrating that it is feasible to account for different
missingness patterns when learning staged trees.",2024-05-28,"Jack Storror Carter, Manuele Leonelli, Eva Riccomagno, Gherardo Varando",http://arxiv.org/pdf/2405.18306v1,cs.LG
Deep Learning Innovations for Underwater Waste Detection: An In-Depth Analysis,"Addressing the issue of submerged underwater trash is crucial for
safeguarding aquatic ecosystems and preserving marine life. While identifying
debris present on the surface of water bodies is straightforward, assessing the
underwater submerged waste is a challenge due to the image distortions caused
by factors such as light refraction, absorption, suspended particles, color
shifts, and occlusion. This paper conducts a comprehensive review of
state-of-the-art architectures and on the existing datasets to establish a
baseline for submerged waste and trash detection. The primary goal remains to
establish the benchmark of the object localization techniques to be leveraged
by advanced underwater sensors and autonomous underwater vehicles. The ultimate
objective is to explore the underwater environment, to identify, and remove
underwater debris. The absence of benchmarks (dataset or algorithm) in many
researches emphasizes the need for a more robust algorithmic solution. Through
this research, we aim to give performance comparative analysis of various
underwater trash detection algorithms.",2024-05-28,"Jaskaran Singh Walia, Pavithra L K",http://arxiv.org/pdf/2405.18299v4,cs.LG
Context-Specific Refinements of Bayesian Network Classifiers,"Supervised classification is one of the most ubiquitous tasks in machine
learning. Generative classifiers based on Bayesian networks are often used
because of their interpretability and competitive accuracy. The widely used
naive and TAN classifiers are specific instances of Bayesian network
classifiers with a constrained underlying graph. This paper introduces novel
classes of generative classifiers extending TAN and other famous types of
Bayesian network classifiers. Our approach is based on staged tree models,
which extend Bayesian networks by allowing for complex, context-specific
patterns of dependence. We formally study the relationship between our novel
classes of classifiers and Bayesian networks. We introduce and implement
data-driven learning routines for our models and investigate their accuracy in
an extensive computational study. The study demonstrates that models embedding
asymmetric information can enhance classification accuracy.",2024-05-28,"Manuele Leonelli, Gherardo Varando",http://arxiv.org/pdf/2405.18298v1,cs.LG
Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD Training,"Machine learning systems often acquire biases by leveraging undesired
features in the data, impacting accuracy variably across different
sub-populations. Current understanding of bias formation mostly focuses on the
initial and final stages of learning, leaving a gap in knowledge regarding the
transient dynamics. To address this gap, this paper explores the evolution of
bias in a teacher-student setup modeling different data sub-populations with a
Gaussian-mixture model. We provide an analytical description of the stochastic
gradient descent dynamics of a linear classifier in this setting, which we
prove to be exact in high dimension. Notably, our analysis reveals how
different properties of sub-populations influence bias at different timescales,
showing a shifting preference of the classifier during training. Applying our
findings to fairness and robustness, we delineate how and when heterogeneous
data and spurious features can generate and amplify bias. We empirically
validate our results in more complex scenarios by training deeper networks on
synthetic and real datasets, including CIFAR10, MNIST, and CelebA.",2024-05-28,"Anchit Jain, Rozhin Nobahari, Aristide Baratin, Stefano Sarao Mannelli",http://arxiv.org/pdf/2405.18296v2,cs.LG
CF-OPT: Counterfactual Explanations for Structured Prediction,"Optimization layers in deep neural networks have enjoyed a growing popularity
in structured learning, improving the state of the art on a variety of
applications. Yet, these pipelines lack interpretability since they are made of
two opaque layers: a highly non-linear prediction model, such as a deep neural
network, and an optimization layer, which is typically a complex black-box
solver. Our goal is to improve the transparency of such methods by providing
counterfactual explanations. We build upon variational autoencoders a
principled way of obtaining counterfactuals: working in the latent space leads
to a natural notion of plausibility of explanations. We finally introduce a
variant of the classic loss for VAE training that improves their performance in
our specific structured context. These provide the foundations of CF-OPT, a
first-order optimization algorithm that can find counterfactual explanations
for a broad class of structured learning architectures. Our numerical results
show that both close and plausible explanations can be obtained for problems
from the recent literature.",2024-05-28,"Germain Vivier-Ardisson, Alexandre Forel, Axel Parmentier, Thibaut Vidal",http://arxiv.org/pdf/2405.18293v2,cs.LG
FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in Federated Learning,"Collaborative fairness stands as an essential element in federated learning
to encourage client participation by equitably distributing rewards based on
individual contributions. Existing methods primarily focus on adjusting
gradient allocations among clients to achieve collaborative fairness. However,
they frequently overlook crucial factors such as maintaining consistency across
local models and catering to the diverse requirements of high-contributing
clients. This oversight inevitably decreases both fairness and model accuracy
in practice. To address these issues, we propose FedSAC, a novel Federated
learning framework with dynamic Submodel Allocation for Collaborative fairness,
backed by a theoretical convergence guarantee. First, we present the concept of
""bounded collaborative fairness (BCF)"", which ensures fairness by tailoring
rewards to individual clients based on their contributions. Second, to
implement the BCF, we design a submodel allocation module with a theoretical
guarantee of fairness. This module incentivizes high-contributing clients with
high-performance submodels containing a diverse range of crucial neurons,
thereby preserving consistency across local models. Third, we further develop a
dynamic aggregation module to adaptively aggregate submodels, ensuring the
equitable treatment of low-frequency neurons and consequently enhancing overall
model accuracy. Extensive experiments conducted on three public benchmarks
demonstrate that FedSAC outperforms all baseline methods in both fairness and
model accuracy. We see this work as a significant step towards incentivizing
broader client participation in federated learning. The source code is
available at https://github.com/wangzihuixmu/FedSAC.",2024-05-28,"Zihui Wang, Zheng Wang, Lingjuan Lyu, Zhaopeng Peng, Zhicheng Yang, Chenglu Wen, Rongshan Yu, Cheng Wang, Xiaoliang Fan",http://arxiv.org/pdf/2405.18291v1,cs.LG
Highway Reinforcement Learning,"Learning from multi-step off-policy data collected by a set of policies is a
core problem of reinforcement learning (RL). Approaches based on importance
sampling (IS) often suffer from large variances due to products of IS ratios.
Typical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ time
steps along the trajectory of actions (where $n$ is called the lookahead depth)
and utilize off-policy data directly without any additional adjustment. They
work well for proper choices of $n$. We show, however, that such IS-free
methods underestimate the optimal value function (VF), especially for large
$n$, restricting their capacity to efficiently utilize information from distant
future time steps. To overcome this problem, we introduce a novel, IS-free,
multi-step off-policy method that avoids the underestimation issue and
converges to the optimal VF. At its core lies a simple but non-trivial
\emph{highway gate}, which controls the information flow from the distant
future by comparing it to a threshold. The highway gate guarantees convergence
to the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It gives
rise to a novel family of off-policy RL algorithms that safely learn even when
$n$ is very large, facilitating rapid credit assignment from the far future to
the past. On tasks with greatly delayed rewards, including video games where
the reward is given only at the end of the game, our new methods outperform
many existing multi-step off-policy algorithms.",2024-05-28,"Yuhui Wang, Miroslav Strupl, Francesco Faccio, Qingyuan Wu, Haozhe Liu, Michał Grudzień, Xiaoyang Tan, Jürgen Schmidhuber",http://arxiv.org/pdf/2405.18289v1,cs.LG
A Theoretical Framework for an Efficient Normalizing Flow-Based Solution to the Electronic Schrodinger Equation,"A central problem in quantum mechanics involves solving the Electronic
Schrodinger Equation for a molecule or material. The Variational Monte Carlo
approach to this problem approximates a particular variational objective via
sampling, and then optimizes this approximated objective over a chosen
parameterized family of wavefunctions, known as the ansatz. Recently neural
networks have been used as the ansatz, with accompanying success. However,
sampling from such wavefunctions has required the use of a Markov Chain Monte
Carlo approach, which is inherently inefficient. In this work, we propose a
solution to this problem via an ansatz which is cheap to sample from, yet
satisfies the requisite quantum mechanical properties. We prove that a
normalizing flow using the following two essential ingredients satisfies our
requirements: (a) a base distribution which is constructed from Determinantal
Point Processes; (b) flow layers which are equivariant to a particular subgroup
of the permutation group. We then show how to construct both continuous and
discrete normalizing flows which satisfy the requisite equivariance. We further
demonstrate the manner in which the non-smooth nature (""cusps"") of the
wavefunction may be captured, and how the framework may be generalized to
provide induction across multiple molecules. The resulting theoretical
framework entails an efficient approach to solving the Electronic Schrodinger
Equation.",2024-05-28,"Daniel Freedman, Eyal Rozenberg, Alex Bronstein",http://arxiv.org/pdf/2406.00047v3,cs.LG
A General Approach for Determining Applicability Domain of Machine Learning Models,"Knowledge of the domain of applicability of a machine learning model is
essential to ensuring accurate and reliable model predictions. In this work, we
develop a new and general approach of assessing model domain and demonstrate
that our approach provides accurate and meaningful domain designation across
multiple model types and material property data sets. Our approach assesses the
distance between data in feature space using kernel density estimation, where
this distance provides an effective tool for domain determination. We show that
chemical groups considered unrelated based on chemical knowledge exhibit
significant dissimilarities by our measure. We also show that high measures of
dissimilarity are associated with poor model performance (i.e., high residual
magnitudes) and poor estimates of model uncertainty (i.e., unreliable
uncertainty estimation). Automated tools are provided to enable researchers to
establish acceptable dissimilarity thresholds to identify whether new
predictions of their own machine learning models are in-domain versus
out-of-domain.",2024-05-28,"Lane E. Schultz, Yiqi Wang, Ryan Jacobs, Dane Morgan",http://arxiv.org/pdf/2406.05143v2,cs.LG
Adaptive debiased SGD in high-dimensional GLMs with streaming data,"Online statistical inference facilitates real-time analysis of sequentially
collected data, making it different from traditional methods that rely on
static datasets. This paper introduces a novel approach to online inference in
high-dimensional generalized linear models, where we update regression
coefficient estimates and their standard errors upon each new data arrival. In
contrast to existing methods that either require full dataset access or
large-dimensional summary statistics storage, our method operates in a
single-pass mode, significantly reducing both time and space complexity. The
core of our methodological innovation lies in an adaptive stochastic gradient
descent algorithm tailored for dynamic objective functions, coupled with a
novel online debiasing procedure. This allows us to maintain low-dimensional
summary statistics while effectively controlling the optimization error
introduced by the dynamically changing loss functions. We establish the
asymptotic normality of our proposed Adaptive Debiased Lasso (ADL) estimator.
We conduct extensive simulation experiments to show the statistical validity
and computational efficiency of our ADL estimator across various settings. Its
computational efficiency is further demonstrated via a real data application to
the spam email classification.",2024-05-28,"Ruijian Han, Lan Luo, Yuanhang Luo, Yuanyuan Lin, Jian Huang",http://arxiv.org/pdf/2405.18284v3,cs.LG
MODL: Multilearner Online Deep Learning,"Online deep learning tackles the challenge of learning from data streams by
balancing two competing goals: fast learning and deep learning. However,
existing research primarily emphasizes deep learning solutions, which are more
adept at handling the ``deep'' aspect than the ``fast'' aspect of online
learning. In this work, we introduce an alternative paradigm through a hybrid
multilearner approach. We begin by developing a fast online logistic regression
learner, which operates without relying on backpropagation. It leverages
closed-form recursive updates of model parameters, efficiently addressing the
fast learning component of the online learning challenge. This approach is
further integrated with a cascaded multilearner design, where shallow and deep
learners are co-trained in a cooperative, synergistic manner to solve the
online learning problem. We demonstrate that this approach achieves
state-of-the-art performance on standard online learning datasets. We make our
code available: https://github.com/AntonValk/MODL",2024-05-28,"Antonios Valkanas, Boris N. Oreshkin, Mark Coates",http://arxiv.org/pdf/2405.18281v2,cs.LG
Interpret3C: Interpretable Student Clustering Through Individualized Feature Selection,"Clustering in education, particularly in large-scale online environments like
MOOCs, is essential for understanding and adapting to diverse student needs.
However, the effectiveness of clustering depends on its interpretability, which
becomes challenging with high-dimensional data. Existing clustering approaches
often neglect individual differences in feature importance and rely on a
homogenized feature set. Addressing this gap, we introduce Interpret3C
(Interpretable Conditional Computation Clustering), a novel clustering pipeline
that incorporates interpretable neural networks (NNs) in an unsupervised
learning context. This method leverages adaptive gating in NNs to select
features for each student. Then, clustering is performed using the most
relevant features per student, enhancing clusters' relevance and
interpretability. We use Interpret3C to analyze the behavioral clusters
considering individual feature importances in a MOOC with over 5,000 students.
This research contributes to the field by offering a scalable, robust
clustering methodology and an educational case study that respects individual
student differences and improves interpretability for high-dimensional data.",2024-05-28,"Isadora Salles, Paola Mejia-Domenzain, Vinitra Swamy, Julian Blackwell, Tanja Käser",http://arxiv.org/pdf/2407.11979v1,cs.LG
NotPlaNET: Removing False Positives from Planet Hunters TESS with Machine Learning,"Differentiating between real transit events and false positive signals in
photometric time series data is a bottleneck in the identification of
transiting exoplanets, particularly long-period planets. This differentiation
typically requires visual inspection of a large number of transit-like signals
to rule out instrumental and astrophysical false positives that mimic planetary
transit signals. We build a one-dimensional convolutional neural network (CNN)
to separate eclipsing binaries and other false positives from potential planet
candidates, reducing the number of light curves that require human vetting. Our
CNN is trained using the TESS light curves that were identified by Planet
Hunters citizen scientists as likely containing a transit. We also include the
background flux and centroid information. The light curves are visually
inspected and labeled by project scientists and are minimally pre-processed,
with only normalization and data augmentation taking place before training. The
median percentage of contaminants flagged across the test sectors is 18% with a
maximum of 37% and a minimum of 10%. Our model keeps 100% of the planets for 16
of the 18 test sectors, while incorrectly flagging one planet candidate (0.3%)
for one sector and two (0.6%) for the remaining sector. Our method shows
potential to reduce the number of light curves requiring manual vetting by up
to a third with minimal misclassification of planet candidates.",2024-05-28,"Valentina Tardugno Poleo, Nora Eisner, David W. Hogg",http://arxiv.org/pdf/2405.18278v1,cs.LG
Signal-Plus-Noise Decomposition of Nonlinear Spiked Random Matrix Models,"In this paper, we study a nonlinear spiked random matrix model where a
nonlinear function is applied element-wise to a noise matrix perturbed by a
rank-one signal. We establish a signal-plus-noise decomposition for this model
and identify precise phase transitions in the structure of the signal
components at critical thresholds of signal strength. To demonstrate the
applicability of this decomposition, we then utilize it to study new phenomena
in the problems of signed signal recovery in nonlinear models and community
detection in transformed stochastic block models. Finally, we validate our
results through a series of numerical simulations.",2024-05-28,"Behrad Moniri, Hamed Hassani",http://arxiv.org/pdf/2405.18274v1,cs.LG
Synchronization on circles and spheres with nonlinear interactions,"We consider the dynamics of $n$ points on a sphere in $\mathbb{R}^d$ ($d \geq
2$) which attract each other according to a function $\varphi$ of their inner
products. When $\varphi$ is linear ($\varphi(t) = t$), the points converge to a
common value (i.e., synchronize) in various connectivity scenarios: this is
part of classical work on Kuramoto oscillator networks. When $\varphi$ is
exponential ($\varphi(t) = e^{\beta t}$), these dynamics correspond to a limit
of how idealized transformers process data, as described by Geshkovski et al.
(2024). Accordingly, they ask whether synchronization occurs for exponential
$\varphi$.
  In the context of consensus for multi-agent control, Markdahl et al. (2018)
show that for $d \geq 3$ (spheres), if the interaction graph is connected and
$\varphi$ is increasing and convex, then the system synchronizes. What is the
situation on circles ($d=2$)? First, we show that $\varphi$ being increasing
and convex is no longer sufficient. Then we identify a new condition (that the
Taylor coefficients of $\varphi'$ are decreasing) under which we do have
synchronization on the circle. In so doing, we provide some answers to the open
problems posed by Geshkovski et al. (2024).",2024-05-28,"Christopher Criscitiello, Quentin Rebjock, Andrew D. McRae, Nicolas Boumal",http://arxiv.org/pdf/2405.18273v1,cs.LG
CT-based brain ventricle segmentation via diffusion Schrödinger Bridge without target domain ground truths,"Efficient and accurate brain ventricle segmentation from clinical CT scans is
critical for emergency surgeries like ventriculostomy. With the challenges in
poor soft tissue contrast and a scarcity of well-annotated databases for
clinical brain CTs, we introduce a novel uncertainty-aware ventricle
segmentation technique without the need of CT segmentation ground truths by
leveraging diffusion-model-based domain adaptation. Specifically, our method
employs the diffusion Schr\""odinger Bridge and an attention recurrent residual
U-Net to capitalize on unpaired CT and MRI scans to derive automatic CT
segmentation from those of the MRIs, which are more accessible. Importantly, we
propose an end-to-end, joint training framework of image translation and
segmentation tasks, and demonstrate its benefit over training individual tasks
separately. By comparing the proposed method against similar setups using two
different GAN models for domain adaptation (CycleGAN and CUT), we also reveal
the advantage of diffusion models towards improved segmentation and image
translation quality. With a Dice score of 0.78$\pm$0.27, our proposed method
outperformed the compared methods, including SynSeg-Net, while providing
intuitive uncertainty measures to further facilitate quality control of the
automatic segmentation outcomes. The implementation of our proposed method is
available at: https://github.com/HealthX-Lab/DiffusionSynCTSeg.",2024-05-28,"Reihaneh Teimouri, Marta Kersten-Oertel, Yiming Xiao",http://arxiv.org/pdf/2405.18267v2,cs.LG
Proper Dataset Valuation by Pointwise Mutual Information,"Data plays a central role in the development of modern artificial
intelligence, with high-quality data emerging as a key driver of model
performance. This has prompted the development of various data curation methods
in recent years. However, measuring the effectiveness of these data curation
techniques remains a major challenge. Traditional evaluation methods, which
assess a trained model's performance on specific benchmarks, risk promoting
practices that merely make the data more similar to the test data. This issue
exemplifies Goodhart's law: when a measure becomes a target, it ceases to be a
good measure. To address this, we propose an information-theoretic framework
for evaluating data curation methods, where dataset quality is measured by its
informativeness about the true model parameters using the Blackwell ordering.
We compare informativeness by the Shannon mutual information of the evaluated
data and the test data, and we propose a novel method for estimating the mutual
information of datasets by training Bayesian models on embedded data and
computing the mutual information from the model's parameter posteriors.
Experiments on real-world data demonstrate that our mutual information-based
evaluation assigns appropriately lower scores to data curation strategies that
reduce dataset informativeness, while traditional test score-based evaluation
methods may favor data curation strategies that overfit to the test set but
compromise the training data's informativeness.",2024-05-28,"Shuran Zheng, Xuan Qi, Rui Ray Chen, Yongchan Kwon, James Zou",http://arxiv.org/pdf/2405.18253v2,cs.LG
Unveiling the Cycloid Trajectory of EM Iterations in Mixed Linear Regression,"We study the trajectory of iterations and the convergence rates of the
Expectation-Maximization (EM) algorithm for two-component Mixed Linear
Regression (2MLR). The fundamental goal of MLR is to learn the regression
models from unlabeled observations. The EM algorithm finds extensive
applications in solving the mixture of linear regressions. Recent results have
established the super-linear convergence of EM for 2MLR in the noiseless and
high SNR settings under some assumptions and its global convergence rate with
random initialization has been affirmed. However, the exponent of convergence
has not been theoretically estimated and the geometric properties of the
trajectory of EM iterations are not well-understood. In this paper, first,
using Bessel functions we provide explicit closed-form expressions for the EM
updates under all SNR regimes. Then, in the noiseless setting, we completely
characterize the behavior of EM iterations by deriving a recurrence relation at
the population level and notably show that all the iterations lie on a certain
cycloid. Based on this new trajectory-based analysis, we exhibit the
theoretical estimate for the exponent of super-linear convergence and further
improve the statistical error bound at the finite-sample level. Our analysis
provides a new framework for studying the behavior of EM for Mixed Linear
Regression.",2024-05-28,"Zhankun Luo, Abolfazl Hashemi",http://arxiv.org/pdf/2405.18237v2,cs.LG
"Position Paper: Think Globally, React Locally -- Bringing Real-time Reference-based Website Phishing Detection on macOS","Background. The recent surge in phishing attacks keeps undermining the
effectiveness of the traditional anti-phishing blacklist approaches. On-device
anti-phishing solutions are gaining popularity as they offer faster phishing
detection locally. Aim. We aim to eliminate the delay in recognizing and
recording phishing campaigns in databases via on-device solutions that identify
phishing sites immediately when encountered by the user rather than waiting for
a web crawler's scan to finish. Additionally, utilizing operating
system-specific resources and frameworks, we aim to minimize the impact on
system performance and depend on local processing to protect user privacy.
Method. We propose a phishing detection solution that uses a combination of
computer vision and on-device machine learning models to analyze websites in
real time. Our reference-based approach analyzes the visual content of
webpages, identifying phishing attempts through layout analysis, credential
input areas detection, and brand impersonation criteria combination. Results.
Our case study shows it's feasible to perform background processing on-device
continuously, for the case of the web browser requiring the resource use of 16%
of a single CPU core and less than 84MB of RAM on Apple M1 while maintaining
the accuracy of brand logo detection at 46.6% (comparable with baselines), and
of Credential Requiring Page detection at 98.1% (improving the baseline by
3.1%), within the test dataset. Conclusions. Our results demonstrate the
potential of on-device, real-time phishing detection systems to enhance
cybersecurity defensive technologies and extend the scope of phishing detection
to more similar regions of interest, e.g., email clients and messenger windows.",2024-05-28,"Ivan Petrukha, Nataliia Stulova, Sergii Kryvoblotskyi",http://arxiv.org/pdf/2405.18236v2,cs.LG
Multi-modal Mood Reader: Pre-trained Model Empowers Cross-Subject Emotion Recognition,"Emotion recognition based on Electroencephalography (EEG) has gained
significant attention and diversified development in fields such as neural
signal processing and affective computing. However, the unique brain anatomy of
individuals leads to non-negligible natural differences in EEG signals across
subjects, posing challenges for cross-subject emotion recognition. While recent
studies have attempted to address these issues, they still face limitations in
practical effectiveness and model framework unity. Current methods often
struggle to capture the complex spatial-temporal dynamics of EEG signals and
fail to effectively integrate multimodal information, resulting in suboptimal
performance and limited generalizability across subjects. To overcome these
limitations, we develop a Pre-trained model based Multimodal Mood Reader for
cross-subject emotion recognition that utilizes masked brain signal modeling
and interlinked spatial-temporal attention mechanism. The model learns
universal latent representations of EEG signals through pre-training on large
scale dataset, and employs Interlinked spatial-temporal attention mechanism to
process Differential Entropy(DE) features extracted from EEG data.
Subsequently, a multi-level fusion layer is proposed to integrate the
discriminative features, maximizing the advantages of features across different
dimensions and modalities. Extensive experiments on public datasets demonstrate
Mood Reader's superior performance in cross-subject emotion recognition tasks,
outperforming state-of-the-art methods. Additionally, the model is dissected
from attention perspective, providing qualitative analysis of emotion-related
brain areas, offering valuable insights for affective research in neural signal
processing.",2024-05-28,"Yihang Dong, Xuhang Chen, Yanyan Shen, Michael Kwok-Po Ng, Tao Qian, Shuqiang Wang",http://arxiv.org/pdf/2405.19373v1,cs.LG
From Learning to Optimize to Learning Optimization Algorithms,"Towards designing learned optimization algorithms that are usable beyond
their training setting, we identify key principles that classical algorithms
obey, but have up to now, not been used for Learning to Optimize (L2O).
Following these principles, we provide a general design pipeline, taking into
account data, architecture and learning strategy, and thereby enabling a
synergy between classical optimization and L2O, resulting in a philosophy of
Learning Optimization Algorithms. As a consequence our learned algorithms
perform well far beyond problems from the training distribution. We demonstrate
the success of these novel principles by designing a new learning-enhanced BFGS
algorithm and provide numerical experiments evidencing its adaptation to many
settings at test time.",2024-05-28,"Camille Castera, Peter Ochs",http://arxiv.org/pdf/2405.18222v2,cs.LG
Recurrent Natural Policy Gradient for POMDPs,"In this paper, we study a natural policy gradient method based on recurrent
neural networks (RNNs) for partially-observable Markov decision processes,
whereby RNNs are used for policy parameterization and policy evaluation to
address curse of dimensionality in non-Markovian reinforcement learning. We
present finite-time and finite-width analyses for both the critic (recurrent
temporal difference learning), and correspondingly-operated recurrent natural
policy gradient method in the near-initialization regime. Our analysis
demonstrates the efficiency of RNNs for problems with short-term memory with
explicit bounds on the required network widths and sample complexity, and
points out the challenges in the case of long-term dependencies.",2024-05-28,"Semih Cayci, Atilla Eryilmaz",http://arxiv.org/pdf/2405.18221v1,cs.LG
E$^2$M: Double Bounded $α$-Divergence Optimization for Tensor-based Discrete Density Estimation,"Tensor-based discrete density estimation requires flexible modeling and
proper divergence criteria to enable effective learning; however, traditional
approaches using $\alpha$-divergence face analytical challenges due to the
$\alpha$-power terms in the objective function, which hinder the derivation of
closed-form update rules. We present a generalization of the
expectation-maximization (EM) algorithm, called E$^2$M algorithm. It
circumvents this issue by first relaxing the optimization into minimization of
a surrogate objective based on the Kullback-Leibler (KL) divergence, which is
tractable via the standard EM algorithm, and subsequently applying a tensor
many-body approximation in the M-step to enable simultaneous closed-form
updates of all parameters. Our approach offers flexible modeling for not only a
variety of low-rank structures, including the CP, Tucker, and Tensor Train
formats, but also their mixtures, thus allowing us to leverage the strengths of
different low-rank structures. We demonstrate the effectiveness of our approach
in classification and density estimation tasks.",2024-05-28,"Kazu Ghalamkari, Jesper Løve Hinrich, Morten Mørup",http://arxiv.org/pdf/2405.18220v3,cs.LG
Optimizing Sharpe Ratio: Risk-Adjusted Decision-Making in Multi-Armed Bandits,"Sharpe Ratio (SR) is a critical parameter in characterizing financial time
series as it jointly considers the reward and the volatility of any
stock/portfolio through its variance. Deriving online algorithms for optimizing
the SR is particularly challenging since even offline policies experience
constant regret with respect to the best expert Even-Dar et al (2006). Thus,
instead of optimizing the usual definition of SR, we optimize regularized
square SR (RSSR). We consider two settings for the RSSR, Regret Minimization
(RM) and Best Arm Identification (BAI). In this regard, we propose a novel
multi-armed bandit (MAB) algorithm for RM called UCB-RSSR for RSSR
maximization. We derive a path-dependent concentration bound for the estimate
of the RSSR. Based on that, we derive the regret guarantees of UCB-RSSR and
show that it evolves as O(log n) for the two-armed bandit case played for a
horizon n. We also consider a fixed budget setting for well-known BAI
algorithms, i.e., sequential halving and successive rejects, and propose SHVV,
SHSR, and SuRSR algorithms. We derive the upper bound for the error probability
of all proposed BAI algorithms. We demonstrate that UCB-RSSR outperforms the
only other known SR optimizing bandit algorithm, U-UCB Cassel et al (2023). We
also establish its efficacy with respect to other benchmarks derived from the
GRA-UCB and MVTS algorithms. We further demonstrate the performance of proposed
BAI algorithms for multiple different setups. Our research highlights that our
proposed algorithms will find extensive applications in risk-aware portfolio
management problems. Consequently, our research highlights that our proposed
algorithms will find extensive applications in risk-aware portfolio management
problems.",2024-05-28,"Sabrina Khurshid, Mohammed Shahid Abdulla, Gourab Ghatak",http://arxiv.org/pdf/2406.06552v1,cs.LG
FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models,"Overparametrized transformer networks are the state-of-the-art architecture
for Large Language Models (LLMs). However, such models contain billions of
parameters making large compute a necessity, while raising environmental
concerns. To address these issues, we propose FinerCut, a new form of
fine-grained layer pruning, which in contrast to prior work at the transformer
block level, considers all self-attention and feed-forward network (FFN) layers
within blocks as individual pruning candidates. FinerCut prunes layers whose
removal causes minimal alternation to the model's output -- contributing to a
new, lean, interpretable, and task-agnostic pruning method. Tested across 9
benchmarks, our approach retains 90% performance of Llama3-8B with 25% layers
removed, and 95% performance of Llama3-70B with 30% layers removed, all without
fine-tuning or post-pruning reconstruction. Strikingly, we observe intriguing
results with FinerCut: 42% (34 out of 80) of the self-attention layers in
Llama3-70B can be removed while preserving 99% of its performance -- without
additional fine-tuning after removal. Moreover, FinerCut provides a tool to
inspect the types and locations of pruned layers, allowing to observe
interesting pruning behaviors. For instance, we observe a preference for
pruning self-attention layers, often at deeper consecutive decoder layers. We
hope our insights inspire future efficient LLM architecture designs.",2024-05-28,"Yang Zhang, Yawei Li, Xinpeng Wang, Qianli Shen, Barbara Plank, Bernd Bischl, Mina Rezaei, Kenji Kawaguchi",http://arxiv.org/pdf/2405.18218v2,cs.LG
Understanding Inter-Concept Relationships in Concept-Based Models,"Concept-based explainability methods provide insight into deep learning
systems by constructing explanations using human-understandable concepts. While
the literature on human reasoning demonstrates that we exploit relationships
between concepts when solving tasks, it is unclear whether concept-based
methods incorporate the rich structure of inter-concept relationships. We
analyse the concept representations learnt by concept-based models to
understand whether these models correctly capture inter-concept relationships.
First, we empirically demonstrate that state-of-the-art concept-based models
produce representations that lack stability and robustness, and such methods
fail to capture inter-concept relationships. Then, we develop a novel algorithm
which leverages inter-concept relationships to improve concept intervention
accuracy, demonstrating how correctly capturing inter-concept relationships can
improve downstream tasks.",2024-05-28,"Naveen Raman, Mateo Espinosa Zarlenga, Mateja Jamnik",http://arxiv.org/pdf/2405.18217v1,cs.LG
Safe Multi-Agent Reinforcement Learning with Bilevel Optimization in Autonomous Driving,"Ensuring safety in MARL, particularly when deploying it in real-world
applications such as autonomous driving, emerges as a critical challenge. To
address this challenge, traditional safe MARL methods extend MARL approaches to
incorporate safety considerations, aiming to minimize safety risk values.
However, these safe MARL algorithms often fail to model other agents and lack
convergence guarantees, particularly in dynamically complex environments. In
this study, we propose a safe MARL method grounded in a Stackelberg model with
bi-level optimization, for which convergence analysis is provided. Derived from
our theoretical analysis, we develop two practical algorithms, namely
Constrained Stackelberg Q-learning (CSQ) and Constrained Stackelberg
Multi-Agent Deep Deterministic Policy Gradient (CS-MADDPG), designed to
facilitate MARL decision-making in autonomous driving applications. To evaluate
the effectiveness of our algorithms, we developed a safe MARL autonomous
driving benchmark and conducted experiments on challenging autonomous driving
scenarios, such as merges, roundabouts, intersections, and racetracks. The
experimental results indicate that our algorithms, CSQ and CS-MADDPG,
outperform several strong MARL baselines, such as Bi-AC, MACPO, and MAPPO-L,
regarding reward and safety performance. The demos and source code are
available at
{https://github.com/SafeRL-Lab/Safe-MARL-in-Autonomous-Driving.git}.",2024-05-28,"Zhi Zheng, Shangding Gu",http://arxiv.org/pdf/2405.18209v1,cs.LG
A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models,"Recent studies have highlighted their proficiency in some simple tasks like
writing and coding through various reasoning strategies. However, LLM agents
still struggle with tasks that require comprehensive planning, a process that
challenges current models and remains a critical research issue. In this study,
we concentrate on travel planning, a Multi-Phases planning problem, that
involves multiple interconnected stages, such as outlining, information
gathering, and planning, often characterized by the need to manage various
constraints and uncertainties. Existing reasoning approaches have struggled to
effectively address this complex task. Our research aims to address this
challenge by developing a human-like planning framework for LLM agents, i.e.,
guiding the LLM agent to simulate various steps that humans take when solving
Multi-Phases problems. Specifically, we implement several strategies to enable
LLM agents to generate a coherent outline for each travel query, mirroring
human planning patterns. Additionally, we integrate Strategy Block and
Knowledge Block into our framework: Strategy Block facilitates information
collection, while Knowledge Block provides essential information for detailed
planning. Through our extensive experiments, we demonstrate that our framework
significantly improves the planning capabilities of LLM agents, enabling them
to tackle the travel planning task with improved efficiency and effectiveness.
Our experimental results showcase the exceptional performance of the proposed
framework; when combined with GPT-4-Turbo, it attains $10\times$ the
performance gains in comparison to the baseline framework deployed on
GPT-4-Turbo.",2024-05-28,"Chengxing Xie, Difan Zou",http://arxiv.org/pdf/2405.18208v1,cs.LG
Multi-CATE: Multi-Accurate Conditional Average Treatment Effect Estimation Robust to Unknown Covariate Shifts,"Estimating heterogeneous treatment effects is important to tailor treatments
to those individuals who would most likely benefit. However, conditional
average treatment effect predictors may often be trained on one population but
possibly deployed on different, possibly unknown populations. We use
methodology for learning multi-accurate predictors to post-process CATE
T-learners (differenced regressions) to become robust to unknown covariate
shifts at the time of deployment. The method works in general for
pseudo-outcome regression, such as the DR-learner. We show how this approach
can combine (large) confounded observational and (smaller) randomized datasets
by learning a confounded predictor from the observational dataset, and auditing
for multi-accuracy on the randomized controlled trial. We show improvements in
bias and mean squared error in simulations with increasingly larger covariate
shift, and on a semi-synthetic case study of a parallel large observational
study and smaller randomized controlled experiment. Overall, we establish a
connection between methods developed for multi-distribution learning and
achieve appealing desiderata (e.g. external validity) in causal inference and
machine learning.",2024-05-28,"Christoph Kern, Michael Kim, Angela Zhou",http://arxiv.org/pdf/2405.18206v2,cs.LG
IM-Context: In-Context Learning for Imbalanced Regression Tasks,"Regression models often fail to generalize effectively in regions
characterized by highly imbalanced label distributions. Previous methods for
deep imbalanced regression rely on gradient-based weight updates, which tend to
overfit in underrepresented regions. This paper proposes a paradigm shift
towards in-context learning as an effective alternative to conventional
in-weight learning methods, particularly for addressing imbalanced regression.
In-context learning refers to the ability of a model to condition itself, given
a prompt sequence composed of in-context samples (input-label pairs) alongside
a new query input to generate predictions, without requiring any parameter
updates. In this paper, we study the impact of the prompt sequence on the model
performance from both theoretical and empirical perspectives. We emphasize the
importance of localized context in reducing bias within regions of high
imbalance. Empirical evaluations across a variety of real-world datasets
demonstrate that in-context learning substantially outperforms existing
in-weight learning methods in scenarios with high levels of imbalance.",2024-05-28,"Ismail Nejjar, Faez Ahmed, Olga Fink",http://arxiv.org/pdf/2405.18202v2,cs.LG
Adam with model exponential moving average is effective for nonconvex optimization,"In this work, we offer a theoretical analysis of two modern optimization
techniques for training large and complex models: (i) adaptive optimization
algorithms, such as Adam, and (ii) the model exponential moving average (EMA).
Specifically, we demonstrate that a clipped version of Adam with model EMA
achieves the optimal convergence rates in various nonconvex optimization
settings, both smooth and nonsmooth. Moreover, when the scale varies
significantly across different coordinates, we demonstrate that the
coordinate-wise adaptivity of Adam is provably advantageous. Notably, unlike
previous analyses of Adam, our analysis crucially relies on its core elements
-- momentum and discounting factors -- as well as model EMA, motivating their
wide applications in practice.",2024-05-28,"Kwangjun Ahn, Ashok Cutkosky",http://arxiv.org/pdf/2405.18199v2,cs.LG
Render and Diffuse: Aligning Image and Action Spaces for Diffusion-based Behaviour Cloning,"In the field of Robot Learning, the complex mapping between high-dimensional
observations such as RGB images and low-level robotic actions, two inherently
very different spaces, constitutes a complex learning problem, especially with
limited amounts of data. In this work, we introduce Render and Diffuse (R&D) a
method that unifies low-level robot actions and RGB observations within the
image space using virtual renders of the 3D model of the robot. Using this
joint observation-action representation it computes low-level robot actions
using a learnt diffusion process that iteratively updates the virtual renders
of the robot. This space unification simplifies the learning problem and
introduces inductive biases that are crucial for sample efficiency and spatial
generalisation. We thoroughly evaluate several variants of R&D in simulation
and showcase their applicability on six everyday tasks in the real world. Our
results show that R&D exhibits strong spatial generalisation capabilities and
is more sample efficient than more common image-to-action methods.",2024-05-28,"Vitalis Vosylius, Younggyo Seo, Jafar Uruç, Stephen James",http://arxiv.org/pdf/2405.18196v1,cs.LG
Delving into Differentially Private Transformer,"Deep learning with differential privacy (DP) has garnered significant
attention over the past years, leading to the development of numerous methods
aimed at enhancing model accuracy and training efficiency. This paper delves
into the problem of training Transformer models with differential privacy. Our
treatment is modular: the logic is to `reduce' the problem of training DP
Transformer to the more basic problem of training DP vanilla neural nets. The
latter is better understood and amenable to many model-agnostic methods. Such
`reduction' is done by first identifying the hardness unique to DP Transformer
training: the attention distraction phenomenon and a lack of compatibility with
existing techniques for efficient gradient clipping. To deal with these two
issues, we propose the Re-Attention Mechanism and Phantom Clipping,
respectively. We believe that our work not only casts new light on training DP
Transformers but also promotes a modular treatment to advance research in the
field of differentially private deep learning.",2024-05-28,"Youlong Ding, Xueyang Wu, Yining Meng, Yonggang Luo, Hao Wang, Weike Pan",http://arxiv.org/pdf/2405.18194v3,cs.LG
In-Context Symmetries: Self-Supervised Learning through Contextual World Models,"At the core of self-supervised learning for vision is the idea of learning
invariant or equivariant representations with respect to a set of data
transformations. This approach, however, introduces strong inductive biases,
which can render the representations fragile in downstream tasks that do not
conform to these symmetries. In this work, drawing insights from world models,
we propose to instead learn a general representation that can adapt to be
invariant or equivariant to different transformations by paying attention to
context -- a memory module that tracks task-specific states, actions, and
future states. Here, the action is the transformation, while the current and
future states respectively represent the input's representation before and
after the transformation. Our proposed algorithm, Contextual Self-Supervised
Learning (ContextSSL), learns equivariance to all transformations (as opposed
to invariance). In this way, the model can learn to encode all relevant
features as general representations while having the versatility to tail down
to task-wise symmetries when given a few examples as the context. Empirically,
we demonstrate significant performance gains over existing methods on
equivariance-related tasks, supported by both qualitative and quantitative
evaluations.",2024-05-28,"Sharut Gupta, Chenyu Wang, Yifei Wang, Tommi Jaakkola, Stefanie Jegelka",http://arxiv.org/pdf/2405.18193v1,cs.LG
Mutation-Bias Learning in Games,"We present two variants of a multi-agent reinforcement learning algorithm
based on evolutionary game theoretic considerations. The intentional simplicity
of one variant enables us to prove results on its relationship to a system of
ordinary differential equations of replicator-mutator dynamics type, allowing
us to present proofs on the algorithm's convergence conditions in various
settings via its ODE counterpart. The more complicated variant enables
comparisons to Q-learning based algorithms. We compare both variants
experimentally to WoLF-PHC and frequency-adjusted Q-learning on a range of
settings, illustrating cases of increasing dimensionality where our variants
preserve convergence in contrast to more complicated algorithms. The
availability of analytic results provides a degree of transferability of
results as compared to purely empirical case studies, illustrating the general
utility of a dynamical systems perspective on multi-agent reinforcement
learning when addressing questions of convergence and reliable generalisation.",2024-05-28,"Johann Bauer, Sheldon West, Eduardo Alonso, Mark Broom",http://arxiv.org/pdf/2405.18190v1,cs.LG
AlignIQL: Policy Alignment in Implicit Q-Learning through Constrained Optimization,"Implicit Q-learning (IQL) serves as a strong baseline for offline RL, which
learns the value function using only dataset actions through quantile
regression. However, it is unclear how to recover the implicit policy from the
learned implicit Q-function and why IQL can utilize weighted regression for
policy extraction. IDQL reinterprets IQL as an actor-critic method and gets
weights of implicit policy, however, this weight only holds for the optimal
value function. In this work, we introduce a different way to solve the
implicit policy-finding problem (IPF) by formulating this problem as an
optimization problem. Based on this optimization problem, we further propose
two practical algorithms AlignIQL and AlignIQL-hard, which inherit the
advantages of decoupling actor from critic in IQL and provide insights into why
IQL can use weighted regression for policy extraction. Compared with IQL and
IDQL, we find our method keeps the simplicity of IQL and solves the implicit
policy-finding problem. Experimental results on D4RL datasets show that our
method achieves competitive or superior results compared with other SOTA
offline RL methods. Especially in complex sparse reward tasks like Antmaze and
Adroit, our method outperforms IQL and IDQL by a significant margin.",2024-05-28,"Longxiang He, Li Shen, Junbo Tan, Xueqian Wang",http://arxiv.org/pdf/2405.18187v1,cs.LG
Safe Reinforcement Learning in Black-Box Environments via Adaptive Shielding,"Empowering safe exploration of reinforcement learning (RL) agents during
training is a critical challenge towards their deployment in many real-world
scenarios. When prior knowledge of the domain or task is unavailable, training
RL agents in unknown, \textit{black-box} environments presents an even greater
safety risk. We introduce \mbox{ADVICE} (Adaptive Shielding with a Contrastive
Autoencoder), a novel post-shielding technique that distinguishes safe and
unsafe features of state-action pairs during training, and uses this knowledge
to protect the RL agent from executing actions that yield likely hazardous
outcomes. Our comprehensive experimental evaluation against state-of-the-art
safe RL exploration techniques shows that ADVICE significantly reduces safety
violations ($\approx\!\!50\%$) during training, with a competitive outcome
reward compared to other techniques.",2024-05-28,"Daniel Bethell, Simos Gerasimou, Radu Calinescu, Calum Imrie",http://arxiv.org/pdf/2405.18180v2,cs.LG
SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals,"This work introduces the Supervised Expectation-Maximization Framework
(SEMF), a versatile and model-agnostic approach for generating prediction
intervals with any ML model. SEMF extends the Expectation-Maximization
algorithm, traditionally used in unsupervised learning, to a supervised
context, leveraging latent variable modeling for uncertainty estimation.
Through extensive empirical evaluation of diverse simulated distributions and
11 real-world tabular datasets, SEMF consistently produces narrower prediction
intervals while maintaining the desired coverage probability, outperforming
traditional quantile regression methods. Furthermore, without using the
quantile (pinball) loss, SEMF allows point predictors, including
gradient-boosted trees and neural networks, to be calibrated with conformal
quantile regression. The results indicate that SEMF enhances uncertainty
quantification under diverse data distributions and is particularly effective
for models that otherwise struggle with inherent uncertainty representation.",2024-05-28,"Ilia Azizi, Marc-Olivier Boldi, Valérie Chavez-Demoulin",http://arxiv.org/pdf/2405.18176v4,cs.LG
AnyFit: Controllable Virtual Try-on for Any Combination of Attire Across Any Scenario,"While image-based virtual try-on has made significant strides, emerging
approaches still fall short of delivering high-fidelity and robust fitting
images across various scenarios, as their models suffer from issues of
ill-fitted garment styles and quality degrading during the training process,
not to mention the lack of support for various combinations of attire.
Therefore, we first propose a lightweight, scalable, operator known as Hydra
Block for attire combinations. This is achieved through a parallel attention
mechanism that facilitates the feature injection of multiple garments from
conditionally encoded branches into the main network. Secondly, to
significantly enhance the model's robustness and expressiveness in real-world
scenarios, we evolve its potential across diverse settings by synthesizing the
residuals of multiple models, as well as implementing a mask region boost
strategy to overcome the instability caused by information leakage in existing
models. Equipped with the above design, AnyFit surpasses all baselines on
high-resolution benchmarks and real-world data by a large gap, excelling in
producing well-fitting garments replete with photorealistic and rich details.
Furthermore, AnyFit's impressive performance on high-fidelity virtual try-ons
in any scenario from any image, paves a new path for future research within the
fashion community.",2024-05-28,"Yuhan Li, Hao Zhou, Wenxiang Shang, Ran Lin, Xuanhong Chen, Bingbing Ni",http://arxiv.org/pdf/2405.18172v1,cs.LG
Time Series Representation Models,"Time series analysis remains a major challenge due to its sparse
characteristics, high dimensionality, and inconsistent data quality. Recent
advancements in transformer-based techniques have enhanced capabilities in
forecasting and imputation; however, these methods are still resource-heavy,
lack adaptability, and face difficulties in integrating both local and global
attributes of time series. To tackle these challenges, we propose a new
architectural concept for time series analysis based on introspection. Central
to this concept is the self-supervised pretraining of Time Series
Representation Models (TSRMs), which once learned can be easily tailored and
fine-tuned for specific tasks, such as forecasting and imputation, in an
automated and resource-efficient manner. Our architecture is equipped with a
flexible and hierarchical representation learning process, which is robust
against missing data and outliers. It can capture and learn both local and
global features of the structure, semantics, and crucial patterns of a given
time series category, such as heart rate data. Our learned time series
representation models can be efficiently adapted to a specific task, such as
forecasting or imputation, without manual intervention. Furthermore, our
architecture's design supports explainability by highlighting the significance
of each input value for the task at hand. Our empirical study using four
benchmark datasets shows that, compared to investigated state-of-the-art
baseline methods, our architecture improves imputation and forecasting errors
by up to 90.34% and 71.54%, respectively, while reducing the required trainable
parameters by up to 92.43%. The source code is available at
https://github.com/RobertLeppich/TSRM.",2024-05-28,"Robert Leppich, Vanessa Borst, Veronika Lesch, Samuel Kounev",http://arxiv.org/pdf/2405.18165v1,cs.LG
Back to the Drawing Board for Fair Representation Learning,"The goal of Fair Representation Learning (FRL) is to mitigate biases in
machine learning models by learning data representations that enable high
accuracy on downstream tasks while minimizing discrimination based on sensitive
attributes. The evaluation of FRL methods in many recent works primarily
focuses on the tradeoff between downstream fairness and accuracy with respect
to a single task that was used to approximate the utility of representations
during training (proxy task). This incentivizes retaining only features
relevant to the proxy task while discarding all other information. In extreme
cases, this can cause the learned representations to collapse to a trivial,
binary value, rendering them unusable in transfer settings. In this work, we
argue that this approach is fundamentally mismatched with the original
motivation of FRL, which arises from settings with many downstream tasks
unknown at training time (transfer tasks). To remedy this, we propose to
refocus the evaluation protocol of FRL methods primarily around the performance
on transfer tasks. A key challenge when conducting such an evaluation is the
lack of adequate benchmarks. We address this by formulating four criteria that
a suitable evaluation procedure should fulfill. Based on these, we propose
TransFair, a benchmark that satisfies these criteria, consisting of novel
variations of popular FRL datasets with carefully calibrated transfer tasks. In
this setting, we reevaluate state-of-the-art FRL methods, observing that they
often overfit to the proxy task, which causes them to underperform on certain
transfer tasks. We further highlight the importance of task-agnostic learning
signals for FRL methods, as they can lead to more transferrable
representations.",2024-05-28,"Angéline Pouget, Nikola Jovanović, Mark Vero, Robin Staab, Martin Vechev",http://arxiv.org/pdf/2405.18161v1,cs.LG
A Data-Centric Framework for Machine Listening Projects: Addressing Large-Scale Data Acquisition and Labeling through Active Learning,"Machine Listening focuses on developing technologies to extract relevant
information from audio signals. A critical aspect of these projects is the
acquisition and labeling of contextualized data, which is inherently complex
and requires specific resources and strategies. Despite the availability of
some audio datasets, many are unsuitable for commercial applications. The paper
emphasizes the importance of Active Learning (AL) using expert labelers over
crowdsourcing, which often lacks detailed insights into dataset structures. AL
is an iterative process combining human labelers and AI models to optimize the
labeling budget by intelligently selecting samples for human review. This
approach addresses the challenge of handling large, constantly growing datasets
that exceed available computational resources and memory. The paper presents a
comprehensive data-centric framework for Machine Listening projects, detailing
the configuration of recording nodes, database structure, and labeling budget
optimization in resource-constrained scenarios. Applied to an industrial port
in Valencia, Spain, the framework successfully labeled 6540 ten-second audio
samples over five months with a small team, demonstrating its effectiveness and
adaptability to various resource availability situations.
  Acknowledgments: The participation of Javier Naranjo-Alcazar, Jordi Grau-Haro
and Pedro Zuccarello in this research was funded by the Valencian Institute for
Business Competitiveness (IVACE) and the FEDER funds by means of project
Soroll-IA2 (IMDEEA/2023/91). The research carried out for this publication has
been partially funded by the project STARRING-NEURO (PID2022-137048OA-C44)
funded by the Ministry of Science, Innovation and Universities of Spain and the
European Union.",2024-05-28,"Javier Naranjo-Alcazar, Jordi Grau-Haro, Ruben Ribes-Serrano, Pedro Zuccarello",http://arxiv.org/pdf/2405.18153v3,cs.LG
Hate Speech Detection with Generalizable Target-aware Fairness,"To counter the side effect brought by the proliferation of social media
platforms, hate speech detection (HSD) plays a vital role in halting the
dissemination of toxic online posts at an early stage. However, given the
ubiquitous topical communities on social media, a trained HSD classifier easily
becomes biased towards specific targeted groups (e.g., female and black
people), where a high rate of false positive/negative results can significantly
impair public trust in the fairness of content moderation mechanisms, and
eventually harm the diversity of online society. Although existing
fairness-aware HSD methods can smooth out some discrepancies across targeted
groups, they are mostly specific to a narrow selection of targets that are
assumed to be known and fixed. This inevitably prevents those methods from
generalizing to real-world use cases where new targeted groups constantly
emerge over time. To tackle this defect, we propose Generalizable target-aware
Fairness (GetFair), a new method for fairly classifying each post that contains
diverse and even unseen targets during inference. To remove the HSD
classifier's spurious dependence on target-related features, GetFair trains a
series of filter functions in an adversarial pipeline, so as to deceive the
discriminator that recovers the targeted group from filtered post embeddings.
To maintain scalability and generalizability, we innovatively parameterize all
filter functions via a hypernetwork that is regularized by the semantic
affinity among targets. Taking a target's pretrained word embedding as input,
the hypernetwork generates the weights used by each target-specific filter
on-the-fly without storing dedicated filter parameters. Finally, comparative
experiments on two HSD datasets have shown advantageous performance of GetFair
on out-of-sample targets.",2024-05-28,"Tong Chen, Danny Wang, Xurong Liang, Marten Risius, Gianluca Demartini, Hongzhi Yin",http://arxiv.org/pdf/2406.00046v2,cs.LG
Unified Low-rank Compression Framework for Click-through Rate Prediction,"Deep Click-Through Rate (CTR) prediction models play an important role in
modern industrial recommendation scenarios. However, high memory overhead and
computational costs limit their deployment in resource-constrained
environments. Low-rank approximation is an effective method for computer vision
and natural language processing models, but its application in compressing CTR
prediction models has been less explored. Due to the limited memory and
computing resources, compression of CTR prediction models often confronts three
fundamental challenges, i.e., (1). How to reduce the model sizes to adapt to
edge devices? (2). How to speed up CTR prediction model inference? (3). How to
retain the capabilities of original models after compression? Previous low-rank
compression research mostly uses tensor decomposition, which can achieve a high
parameter compression ratio, but brings in AUC degradation and additional
computing overhead. To address these challenges, we propose a unified low-rank
decomposition framework for compressing CTR prediction models. We find that
even with the most classic matrix decomposition SVD method, our framework can
achieve better performance than the original model. To further improve the
effectiveness of our framework, we locally compress the output features instead
of compressing the model weights. Our unified low-rank compression framework
can be applied to embedding tables and MLP layers in various CTR prediction
models. Extensive experiments on two academic datasets and one real industrial
benchmark demonstrate that, with 3-5x model size reduction, our compressed
models can achieve both faster inference and higher AUC than the uncompressed
original models. Our code is at
https://github.com/yuhao318/Atomic_Feature_Mimicking.",2024-05-28,"Hao Yu, Minghao Fu, Jiandong Ding, Yusheng Zhou, Jianxin Wu",http://arxiv.org/pdf/2405.18146v2,cs.LG
4-bit Shampoo for Memory-Efficient Network Training,"Second-order optimizers, maintaining a matrix termed a preconditioner, are
superior to first-order optimizers in both theory and practice. The states
forming the preconditioner and its inverse root restrict the maximum size of
models trained by second-order optimizers. To address this, compressing 32-bit
optimizer states to lower bitwidths has shown promise in reducing memory usage.
However, current approaches only pertain to first-order optimizers. In this
paper, we propose the first 4-bit second-order optimizers, exemplified by 4-bit
Shampoo, maintaining performance similar to that of 32-bit ones. We show that
quantizing the eigenvector matrix of the preconditioner in 4-bit Shampoo is
remarkably better than quantizing the preconditioner itself both theoretically
and experimentally. By rectifying the orthogonality of the quantized
eigenvector matrix, we enhance the approximation of the preconditioner's
eigenvector matrix, which also benefits the computation of its inverse 4-th
root. Besides, we find that linear square quantization slightly outperforms
dynamic tree quantization when quantizing second-order optimizer states.
Evaluation on various networks for image classification and natural language
modeling demonstrates that our 4-bit Shampoo achieves comparable performance to
its 32-bit counterpart while being more memory-efficient.",2024-05-28,"Sike Wang, Pan Zhou, Jia Li, Hua Huang",http://arxiv.org/pdf/2405.18144v3,cs.LG
Exploiting LLM Quantization,"Quantization leverages lower-precision weights to reduce the memory usage of
large language models (LLMs) and is a key technique for enabling their
deployment on commodity hardware. While LLM quantization's impact on utility
has been extensively explored, this work for the first time studies its adverse
effects from a security perspective. We reveal that widely used quantization
methods can be exploited to produce a harmful quantized LLM, even though the
full-precision counterpart appears benign, potentially tricking users into
deploying the malicious quantized model. We demonstrate this threat using a
three-staged attack framework: (i) first, we obtain a malicious LLM through
fine-tuning on an adversarial task; (ii) next, we quantize the malicious model
and calculate constraints that characterize all full-precision models that map
to the same quantized model; (iii) finally, using projected gradient descent,
we tune out the poisoned behavior from the full-precision model while ensuring
that its weights satisfy the constraints computed in step (ii). This procedure
results in an LLM that exhibits benign behavior in full precision but when
quantized, it follows the adversarial behavior injected in step (i). We
experimentally demonstrate the feasibility and severity of such an attack
across three diverse scenarios: vulnerable code generation, content injection,
and over-refusal attack. In practice, the adversary could host the resulting
full-precision model on an LLM community hub such as Hugging Face, exposing
millions of users to the threat of deploying its malicious quantized version on
their devices.",2024-05-28,"Kazuki Egashira, Mark Vero, Robin Staab, Jingxuan He, Martin Vechev",http://arxiv.org/pdf/2405.18137v2,cs.LG
Graph Coarsening with Message-Passing Guarantees,"Graph coarsening aims to reduce the size of a large graph while preserving
some of its key properties, which has been used in many applications to reduce
computational load and memory footprint. For instance, in graph machine
learning, training Graph Neural Networks (GNNs) on coarsened graphs leads to
drastic savings in time and memory. However, GNNs rely on the Message-Passing
(MP) paradigm, and classical spectral preservation guarantees for graph
coarsening do not directly lead to theoretical guarantees when performing naive
message-passing on the coarsened graph. In this work, we propose a new
message-passing operation specific to coarsened graphs, which exhibit
theoretical guarantees on the preservation of the propagated signal.
Interestingly, and in a sharp departure from previous proposals, this operation
on coarsened graphs is oriented, even when the original graph is undirected. We
conduct node classification tasks on synthetic and real data and observe
improved results compared to performing naive message-passing on the coarsened
graph.",2024-05-28,"Antonin Joly, Nicolas Keriven",http://arxiv.org/pdf/2405.18127v1,cs.LG
Low-Resource Crop Classification from Multi-Spectral Time Series Using Lossless Compressors,"Deep learning has significantly improved the accuracy of crop classification
using multispectral temporal data. However, these models have complex
structures with numerous parameters, requiring large amounts of data and costly
training. In low-resource situations with fewer labeled samples, deep learning
models perform poorly due to insufficient data. Conversely, compressors are
data-type agnostic, and non-parametric methods do not bring underlying
assumptions. Inspired by this insight, we propose a non-training alternative to
deep learning models, aiming to address these situations. Specifically, the
Symbolic Representation Module is proposed to convert the reflectivity into
symbolic representations. The symbolic representations are then
cross-transformed in both the channel and time dimensions to generate symbolic
embeddings. Next, the Multi-scale Normalised Compression Distance (MNCD) is
designed to measure the correlation between any two symbolic embeddings.
Finally, based on the MNCDs, high quality crop classification can be achieved
using only a k-nearest-neighbor classifier kNN. The entire framework is
ready-to-use and lightweight. Without any training, it outperformed, on
average, 7 advanced deep learning models trained at scale on three benchmark
datasets. It also outperforms more than half of these models in the few-shot
setting with sparse crop labels. Therefore, the high performance and robustness
of our non-training framework makes it truly applicable to real-world crop
mapping. Codes are available at:
https://github.com/qinfengsama/Compressor-Based-Crop-Mapping.",2024-05-28,"Wei Cheng, Hongrui Ye, Xiao Wen, Jiachen Zhang, Jiping Xu, Feifan Zhang",http://arxiv.org/pdf/2405.18119v2,cs.LG
Individual Contributions as Intrinsic Exploration Scaffolds for Multi-agent Reinforcement Learning,"In multi-agent reinforcement learning (MARL), effective exploration is
critical, especially in sparse reward environments. Although introducing global
intrinsic rewards can foster exploration in such settings, it often complicates
credit assignment among agents. To address this difficulty, we propose
Individual Contributions as intrinsic Exploration Scaffolds (ICES), a novel
approach to motivate exploration by assessing each agent's contribution from a
global view. In particular, ICES constructs exploration scaffolds with Bayesian
surprise, leveraging global transition information during centralized training.
These scaffolds, used only in training, help to guide individual agents towards
actions that significantly impact the global latent state transitions.
Additionally, ICES separates exploration policies from exploitation policies,
enabling the former to utilize privileged global information during training.
Extensive experiments on cooperative benchmark tasks with sparse rewards,
including Google Research Football (GRF) and StarCraft Multi-agent Challenge
(SMAC), demonstrate that ICES exhibits superior exploration capabilities
compared with baselines. The code is publicly available at
https://github.com/LXXXXR/ICES.",2024-05-28,"Xinran Li, Zifan Liu, Shibo Chen, Jun Zhang",http://arxiv.org/pdf/2405.18110v1,cs.LG
A Pontryagin Perspective on Reinforcement Learning,"Reinforcement learning has traditionally focused on learning state-dependent
policies to solve optimal control problems in a closed-loop fashion. In this
work, we introduce the paradigm of open-loop reinforcement learning where a
fixed action sequence is learned instead. We present three new algorithms: one
robust model-based method and two sample-efficient model-free methods. Rather
than basing our algorithms on Bellman's equation from dynamic programming, our
work builds on Pontryagin's principle from the theory of open-loop optimal
control. We provide convergence guarantees and evaluate all methods empirically
on a pendulum swing-up task, as well as on two high-dimensional MuJoCo tasks,
significantly outperforming existing baselines.",2024-05-28,"Onno Eberhard, Claire Vernade, Michael Muehlebach",http://arxiv.org/pdf/2405.18100v3,cs.LG
Is machine learning good or bad for the natural sciences?,"Machine learning (ML) methods are having a huge impact across all of the
sciences. However, ML has a strong ontology - in which only the data exist -
and a strong epistemology - in which a model is considered good if it performs
well on held-out training data. These philosophies are in strong conflict with
both standard practices and key philosophies in the natural sciences. Here we
identify some locations for ML in the natural sciences at which the ontology
and epistemology are valuable. For example, when an expressive machine learning
model is used in a causal inference to represent the effects of confounders,
such as foregrounds, backgrounds, or instrument calibration parameters, the
model capacity and loose philosophy of ML can make the results more
trustworthy. We also show that there are contexts in which the introduction of
ML introduces strong, unwanted statistical biases. For one, when ML models are
used to emulate physical (or first-principles) simulations, they amplify
confirmation biases. For another, when expressive regressions are used to label
datasets, those labels cannot be used in downstream joint or ensemble analyses
without taking on uncontrolled biases. The question in the title is being asked
of all of the natural sciences; that is, we are calling on the scientific
communities to take a step back and consider the role and value of ML in their
fields; the (partial) answers we give here come from the particular perspective
of physics.",2024-05-28,"David W. Hogg, Soledad Villar",http://arxiv.org/pdf/2405.18095v2,cs.LG
Pipette: Automatic Fine-grained Large Language Model Training Configurator for Real-World Clusters,"Training large language models (LLMs) is known to be challenging because of
the huge computational and memory capacity requirements. To address these
issues, it is common to use a cluster of GPUs with 3D parallelism, which splits
a model along the data batch, pipeline stage, and intra-layer tensor
dimensions. However, the use of 3D parallelism produces the additional
challenge of finding the optimal number of ways on each dimension and mapping
the split models onto the GPUs. Several previous studies have attempted to
automatically find the optimal configuration, but many of these lacked several
important aspects. For instance, the heterogeneous nature of the interconnect
speeds is often ignored. While the peak bandwidths for the interconnects are
usually made equal, the actual attained bandwidth varies per link in real-world
clusters. Combined with the critical path modeling that does not properly
consider the communication, they easily fall into sub-optimal configurations.
In addition, they often fail to consider the memory requirement per GPU, often
recommending solutions that could not be executed. To address these challenges,
we propose Pipette, which is an automatic fine-grained LLM training
configurator for real-world clusters. By devising better performance models
along with the memory estimator and fine-grained individual GPU assignment,
Pipette achieves faster configurations that satisfy the memory constraints. We
evaluated Pipette on large clusters to show that it provides a significant
speedup over the prior art. The implementation of Pipette is available at
https://github.com/yimjinkyu1/date2024_pipette.",2024-05-28,"Jinkyu Yim, Jaeyong Song, Yerim Choi, Jaebeen Lee, Jaewon Jung, Hongsun Jang, Jinho Lee",http://arxiv.org/pdf/2405.18093v1,cs.LG
An adaptive transfer learning perspective on classification in non-stationary environments,"We consider a semi-supervised classification problem with non-stationary
label-shift in which we observe a labelled data set followed by a sequence of
unlabelled covariate vectors in which the marginal probabilities of the class
labels may change over time. Our objective is to predict the corresponding
class-label for each covariate vector, without ever observing the ground-truth
labels, beyond the initial labelled data set. Previous work has demonstrated
the potential of sophisticated variants of online gradient descent to perform
competitively with the optimal dynamic strategy (Bai et al. 2022). In this work
we explore an alternative approach grounded in statistical methods for adaptive
transfer learning. We demonstrate the merits of this alternative methodology by
establishing a high-probability regret bound on the test error at any given
individual test-time, which adapt automatically to the unknown dynamics of the
marginal label probabilities. Further more, we give bounds on the average
dynamic regret which match the average guarantees of the online learning
perspective for any given time interval.",2024-05-28,Henry W J Reeve,http://arxiv.org/pdf/2405.18091v1,cs.LG
Guidance and Control Networks with Periodic Activation Functions,"Inspired by the versatility of sinusoidal representation networks (SIRENs),
we present a modified Guidance & Control Networks (G&CNETs) variant using
periodic activation functions in the hidden layers. We demonstrate that the
resulting G&CNETs train faster and achieve a lower overall training error on
three different control scenarios on which G&CNETs have been tested previously.
A preliminary analysis is presented in an attempt to explain the superior
performance of the SIREN architecture for the particular types of tasks that
G&CNETs excel on.",2024-05-28,"Sebastien Origer, Dario Izzo",http://arxiv.org/pdf/2405.18084v1,cs.LG
HarmoDT: Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning,"The purpose of offline multi-task reinforcement learning (MTRL) is to develop
a unified policy applicable to diverse tasks without the need for online
environmental interaction. Recent advancements approach this through sequence
modeling, leveraging the Transformer architecture's scalability and the
benefits of parameter sharing to exploit task similarities. However, variations
in task content and complexity pose significant challenges in policy
formulation, necessitating judicious parameter sharing and management of
conflicting gradients for optimal policy performance. In this work, we
introduce the Harmony Multi-Task Decision Transformer (HarmoDT), a novel
solution designed to identify an optimal harmony subspace of parameters for
each task. We approach this as a bi-level optimization problem, employing a
meta-learning framework that leverages gradient-based techniques. The upper
level of this framework is dedicated to learning a task-specific mask that
delineates the harmony subspace, while the inner level focuses on updating
parameters to enhance the overall performance of the unified policy. Empirical
evaluations on a series of benchmarks demonstrate the superiority of HarmoDT,
verifying the effectiveness of our approach.",2024-05-28,"Shengchao Hu, Ziqing Fan, Li Shen, Ya Zhang, Yanfeng Wang, Dacheng Tao",http://arxiv.org/pdf/2405.18080v1,cs.LG
"Design Principles for Falsifiable, Replicable and Reproducible Empirical ML Research","Empirical research plays a fundamental role in the machine learning domain.
At the heart of impactful empirical research lies the development of clear
research hypotheses, which then shape the design of experiments. The execution
of experiments must be carried out with precision to ensure reliable results,
followed by statistical analysis to interpret these outcomes. This process is
key to either supporting or refuting initial hypotheses. Despite its
importance, there is a high variability in research practices across the
machine learning community and no uniform understanding of quality criteria for
empirical research. To address this gap, we propose a model for the empirical
research process, accompanied by guidelines to uphold the validity of empirical
research. By embracing these recommendations, greater consistency, enhanced
reliability and increased impact can be achieved.",2024-05-28,"Daniel Vranješ, Oliver Niggemann",http://arxiv.org/pdf/2405.18077v1,cs.LG
Implicitly Guided Design with PropEn: Match your Data to Follow the Gradient,"Across scientific domains, generating new models or optimizing existing ones
while meeting specific criteria is crucial. Traditional machine learning
frameworks for guided design use a generative model and a surrogate model
(discriminator), requiring large datasets. However, real-world scientific
applications often have limited data and complex landscapes, making data-hungry
models inefficient or impractical. We propose a new framework, PropEn, inspired
by ``matching'', which enables implicit guidance without training a
discriminator. By matching each sample with a similar one that has a better
property value, we create a larger training dataset that inherently indicates
the direction of improvement. Matching, combined with an encoder-decoder
architecture, forms a domain-agnostic generative framework for property
enhancement. We show that training with a matched dataset approximates the
gradient of the property of interest while remaining within the data
distribution, allowing efficient design optimization. Extensive evaluations in
toy problems and scientific applications, such as therapeutic protein design
and airfoil optimization, demonstrate PropEn's advantages over common
baselines. Notably, the protein design results are validated with wet lab
experiments, confirming the competitiveness and effectiveness of our approach.",2024-05-28,"Nataša Tagasovska, Vladimir Gligorijević, Kyunghyun Cho, Andreas Loukas",http://arxiv.org/pdf/2405.18075v1,cs.LG
An Empirical Analysis of Forgetting in Pre-trained Models with Incremental Low-Rank Updates,"Broad, open source availability of large pretrained foundation models on the
internet through platforms such as HuggingFace has taken the world of practical
deep learning by storm. A classical pipeline for neural network training now
typically consists of finetuning these pretrained network on a small target
dataset instead of training from scratch. In the case of large models this can
be done even on modest hardware using a low rank training technique known as
Low-Rank Adaptation (LoRA). While Low Rank training has already been studied in
the continual learning setting, existing works often consider storing the
learned adapter along with the existing model but rarely attempt to modify the
weights of the pretrained model by merging the LoRA with the existing weights
after finishing the training of each task. In this article we investigate this
setting and study the impact of LoRA rank on the forgetting of the pretraining
foundation task and on the plasticity and forgetting of subsequent ones. We
observe that this rank has an important impact on forgetting of both the
pretraining and downstream tasks. We also observe that vision transformers
finetuned in that way exhibit a sort of ``contextual'' forgetting, a behaviour
that we do not observe for residual networks and that we believe has not been
observed yet in previous continual learning works.",2024-05-28,"Albin Soutif--Cormerais, Simone Magistri, Joost van de Weijer, Andew D. Bagdanov",http://arxiv.org/pdf/2405.18069v2,cs.LG
A Survey of Latent Factor Models in Recommender Systems,"Recommender systems are essential tools in the digital era, providing
personalized content to users in areas like e-commerce, entertainment, and
social media. Among the many approaches developed to create these systems,
latent factor models have proven particularly effective. This survey
systematically reviews latent factor models in recommender systems, focusing on
their core principles, methodologies, and recent advancements. The literature
is examined through a structured framework covering learning data, model
architecture, learning strategies, and optimization techniques. The analysis
includes a taxonomy of contributions and detailed discussions on the types of
learning data used, such as implicit feedback, trust, and content data, various
models such as probabilistic, nonlinear, and neural models, and an exploration
of diverse learning strategies like online learning, transfer learning, and
active learning. Furthermore, the survey addresses the optimization strategies
used to train latent factor models, improving their performance and
scalability. By identifying trends, gaps, and potential research directions,
this survey aims to provide valuable insights for researchers and practitioners
looking to advance the field of recommender systems.",2024-05-28,"Hind I. Alshbanat, Hafida Benhidour, Said Kerrache",http://arxiv.org/pdf/2405.18068v1,cs.LG
Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs,"Anomaly detection in continuous-time dynamic graphs is an emerging field yet
under-explored in the context of learning algorithms. In this paper, we pioneer
structured analyses of link-level anomalies and graph representation learning
for identifying categorically anomalous graph links. First, we introduce a
fine-grained taxonomy for edge-level anomalies leveraging structural, temporal,
and contextual graph properties. Based on these properties, we introduce a
method for generating and injecting typed anomalies into graphs. Next, we
introduce a novel method to generate continuous-time dynamic graphs featuring
consistencies across either or combinations of time, structure, and context. To
enable temporal graph learning methods to detect specific types of anomalous
links rather than the bare existence of a link, we extend the generic link
prediction setting by: (1) conditioning link existence on contextual edge
attributes; and (2) refining the training regime to accommodate diverse
perturbations in the negative edge sampler. Comprehensive benchmarks on
synthetic and real-world datasets -- featuring synthetic and labeled organic
anomalies and employing six state-of-the-art link prediction methods --
validate our taxonomy and generation processes for anomalies and benign graphs,
as well as our approach to adapting methods for anomaly detection. Our results
reveal that different learning methods excel in capturing different aspects of
graph normality and detecting different types of anomalies. We conclude with a
comprehensive list of findings highlighting opportunities for future research.",2024-05-28,"Tim Poštuvan, Claas Grohnfeldt, Michele Russo, Giulio Lovisotto",http://arxiv.org/pdf/2405.18050v2,cs.LG
2BP: 2-Stage Backpropagation,"As Deep Neural Networks (DNNs) grow in size and complexity, they often exceed
the memory capacity of a single accelerator, necessitating the sharding of
model parameters across multiple accelerators. Pipeline parallelism is a
commonly used sharding strategy for training large DNNs. However, current
implementations of pipeline parallelism are being unintentionally bottlenecked
by the automatic differentiation tools provided by ML frameworks. This paper
introduces 2-stage backpropagation (2BP). By splitting the backward propagation
step into two separate stages, we can reduce idle compute time. We tested 2BP
on various model architectures and pipelining schedules, achieving increases in
throughput in all cases. Using 2BP, we were able to achieve a 1.70x increase in
throughput compared to traditional methods when training a LLaMa-like
transformer with 7 billion parameters across 4 GPUs.",2024-05-28,"Christopher Rae, Joseph K. L. Lee, James Richings",http://arxiv.org/pdf/2405.18047v1,cs.LG
Bridging Mini-Batch and Asymptotic Analysis in Contrastive Learning: From InfoNCE to Kernel-Based Losses,"What do different contrastive learning (CL) losses actually optimize for?
Although multiple CL methods have demonstrated remarkable representation
learning capabilities, the differences in their inner workings remain largely
opaque. In this work, we analyse several CL families and prove that, under
certain conditions, they admit the same minimisers when optimizing either their
batch-level objectives or their expectations asymptotically. In both cases, an
intimate connection with the hyperspherical energy minimisation (HEM) problem
resurfaces. Drawing inspiration from this, we introduce a novel CL objective,
coined Decoupled Hyperspherical Energy Loss (DHEL). DHEL simplifies the problem
by decoupling the target hyperspherical energy from the alignment of positive
examples while preserving the same theoretical guarantees. Going one step
further, we show the same results hold for another relevant CL family, namely
kernel contrastive learning (KCL), with the additional advantage of the
expected loss being independent of batch size, thus identifying the minimisers
in the non-asymptotic regime. Empirical results demonstrate improved downstream
performance and robustness across combinations of different batch sizes and
hyperparameters and reduced dimensionality collapse, on several computer vision
datasets.",2024-05-28,"Panagiotis Koromilas, Giorgos Bouritsas, Theodoros Giannakopoulos, Mihalis Nicolaou, Yannis Panagakis",http://arxiv.org/pdf/2405.18045v1,cs.LG
Visualizing the loss landscape of Self-supervised Vision Transformer,"The Masked autoencoder (MAE) has drawn attention as a representative
self-supervised approach for masked image modeling with vision transformers.
However, even though MAE shows better generalization capability than fully
supervised training from scratch, the reason why has not been explored. In
another line of work, the Reconstruction Consistent Masked Auto Encoder
(RC-MAE), has been proposed which adopts a self-distillation scheme in the form
of an exponential moving average (EMA) teacher into MAE, and it has been shown
that the EMA-teacher performs a conditional gradient correction during
optimization. To further investigate the reason for better generalization of
the self-supervised ViT when trained by MAE (MAE-ViT) and the effect of the
gradient correction of RC-MAE from the perspective of optimization, we
visualize the loss landscapes of the self-supervised vision transformer by both
MAE and RC-MAE and compare them with the supervised ViT (Sup-ViT). Unlike
previous loss landscape visualizations of neural networks based on
classification task loss, we visualize the loss landscape of ViT by computing
pre-training task loss. Through the lens of loss landscapes, we find two
interesting observations: (1) MAE-ViT has a smoother and wider overall loss
curvature than Sup-ViT. (2) The EMA-teacher allows MAE to widen the region of
convexity in both pretraining and linear probing, leading to quicker
convergence. To the best of our knowledge, this work is the first to
investigate the self-supervised ViT through the lens of the loss landscape.",2024-05-28,"Youngwan Lee, Jeffrey Ryan Willette, Jonghee Kim, Sung Ju Hwang",http://arxiv.org/pdf/2405.18042v1,cs.LG
Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew Resilience,"Federated learning (FL) has recently emerged as a compelling machine learning
paradigm, prioritizing the protection of privacy for training data. The
increasing demand to address issues such as ``the right to be forgotten'' and
combat data poisoning attacks highlights the importance of techniques, known as
\textit{unlearning}, which facilitate the removal of specific training data
from trained FL models. Despite numerous unlearning methods proposed for
centralized learning, they often prove inapplicable to FL due to fundamental
differences in the operation of the two learning paradigms. Consequently,
unlearning in FL remains in its early stages, presenting several challenges.
Many existing unlearning solutions in FL require a costly retraining process,
which can be burdensome for clients. Moreover, these methods are primarily
validated through experiments, lacking theoretical assurances. In this study,
we introduce Fast-FedUL, a tailored unlearning method for FL, which eliminates
the need for retraining entirely. Through meticulous analysis of the target
client's influence on the global model in each round, we develop an algorithm
to systematically remove the impact of the target client from the trained
model. In addition to presenting empirical findings, we offer a theoretical
analysis delineating the upper bound of our unlearned model and the exact
retrained model (the one obtained through retraining using untargeted clients).
Experimental results with backdoor attack scenarios indicate that Fast-FedUL
effectively removes almost all traces of the target client, while retaining the
knowledge of untargeted clients (obtaining a high accuracy of up to 98\% on the
main task). Significantly, Fast-FedUL attains the lowest time complexity,
providing a speed that is 1000 times faster than retraining. Our source code is
publicly available at \url{https://github.com/thanhtrunghuynh93/fastFedUL}.",2024-05-28,"Thanh Trung Huynh, Trong Bang Nguyen, Phi Le Nguyen, Thanh Tam Nguyen, Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Aberer",http://arxiv.org/pdf/2405.18040v1,cs.LG
Large Language Model-Driven Curriculum Design for Mobile Networks,"This study introduces an innovative framework that employs large language
models (LLMs) to automate the design and generation of curricula for
reinforcement learning (RL). As mobile networks evolve towards the 6G era,
managing their increasing complexity and dynamic nature poses significant
challenges. Conventional RL approaches often suffer from slow convergence and
poor generalization due to conflicting objectives and the large state and
action spaces associated with mobile networks. To address these shortcomings,
we introduce curriculum learning, a method that systematically exposes the RL
agent to progressively challenging tasks, improving convergence and
generalization. However, curriculum design typically requires extensive domain
knowledge and manual human effort. Our framework mitigates this by utilizing
the generative capabilities of LLMs to automate the curriculum design process,
significantly reducing human effort while improving the RL agent's convergence
and performance. We deploy our approach within a simulated mobile network
environment and demonstrate improved RL convergence rates, generalization to
unseen scenarios, and overall performance enhancements. As a case study, we
consider autonomous coordination and user association in mobile networks. Our
obtained results highlight the potential of combining LLM-based curriculum
generation with RL for managing next-generation wireless networks, marking a
significant step towards fully autonomous network operations.",2024-05-28,"Omar Erak, Omar Alhussein, Shimaa Naser, Nouf Alabbasi, De Mi, Sami Muhaidat",http://arxiv.org/pdf/2405.18039v2,cs.LG
ForecastGrapher: Redefining Multivariate Time Series Forecasting with Graph Neural Networks,"The challenge of effectively learning inter-series correlations for
multivariate time series forecasting remains a substantial and unresolved
problem. Traditional deep learning models, which are largely dependent on the
Transformer paradigm for modeling long sequences, often fail to integrate
information from multiple time series into a coherent and universally
applicable model. To bridge this gap, our paper presents ForecastGrapher, a
framework reconceptualizes multivariate time series forecasting as a node
regression task, providing a unique avenue for capturing the intricate temporal
dynamics and inter-series correlations. Our approach is underpinned by three
pivotal steps: firstly, generating custom node embeddings to reflect the
temporal variations within each series; secondly, constructing an adaptive
adjacency matrix to encode the inter-series correlations; and thirdly,
augmenting the GNNs' expressive power by diversifying the node feature
distribution. To enhance this expressive power, we introduce the Group Feature
Convolution GNN (GFC-GNN). This model employs a learnable scaler to segment
node features into multiple groups and applies one-dimensional convolutions
with different kernel lengths to each group prior to the aggregation phase.
Consequently, the GFC-GNN method enriches the diversity of node feature
distribution in a fully end-to-end fashion. Through extensive experiments and
ablation studies, we show that ForecastGrapher surpasses strong baselines and
leading published techniques in the domain of multivariate time series
forecasting.",2024-05-28,"Wanlin Cai, Kun Wang, Hao Wu, Xiaoxu Chen, Yuankai Wu",http://arxiv.org/pdf/2405.18036v1,cs.LG
Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks,"We consider the task of minimizing the sum of convex functions stored in a
decentralized manner across the nodes of a communication network. This problem
is relatively well-studied in the scenario when the objective functions are
smooth, or the links of the network are fixed in time, or both. In particular,
lower bounds on the number of decentralized communications and (sub)gradient
computations required to solve the problem have been established, along with
matching optimal algorithms. However, the remaining and most challenging
setting of non-smooth decentralized optimization over time-varying networks is
largely underexplored, as neither lower bounds nor optimal algorithms are known
in the literature. We resolve this fundamental gap with the following
contributions: (i) we establish the first lower bounds on the communication and
subgradient computation complexities of solving non-smooth convex decentralized
optimization problems over time-varying networks; (ii) we develop the first
optimal algorithm that matches these lower bounds and offers substantially
improved theoretical performance compared to the existing state of the art.",2024-05-28,"Dmitry Kovalev, Ekaterina Borodich, Alexander Gasnikov, Dmitrii Feoktistov",http://arxiv.org/pdf/2405.18031v1,cs.LG
Are Images Indistinguishable to Humans Also Indistinguishable to Classifiers?,"The ultimate goal of generative models is to perfectly capture the data
distribution. For image generation, common metrics of visual quality (e.g.,
FID) and the perceived truthfulness of generated images seem to suggest that we
are nearing this goal. However, through distribution classification tasks, we
reveal that, from the perspective of neural network-based classifiers, even
advanced diffusion models are still far from this goal. Specifically,
classifiers are able to consistently and effortlessly distinguish real images
from generated ones across various settings. Moreover, we uncover an intriguing
discrepancy: classifiers can easily differentiate between diffusion models with
comparable performance (e.g., U-ViT-H vs. DiT-XL), but struggle to distinguish
between models within the same family but of different scales (e.g., EDM2-XS
vs. EDM2-XXL). Our methodology carries several important implications. First,
it naturally serves as a diagnostic tool for diffusion models by analyzing
specific features of generated data. Second, it sheds light on the model
autophagy disorder and offers insights into the use of generated data:
augmenting real data with generated data is more effective than replacing it.
Third, classifier guidance can significantly enhance the realism of generated
images.",2024-05-28,"Zebin You, Xinyu Zhang, Hanzhong Guo, Jingdong Wang, Chongxuan Li",http://arxiv.org/pdf/2405.18029v4,cs.LG
Exploring Context Window of Large Language Models via Decomposed Positional Vectors,"Transformer-based large language models (LLMs) typically have a limited
context window, resulting in significant performance degradation when
processing text beyond the length of the context window. Extensive studies have
been proposed to extend the context window and achieve length extrapolation of
LLMs, but there is still a lack of in-depth interpretation of these approaches.
In this study, we explore the positional information within and beyond the
context window for deciphering the underlying mechanism of LLMs. By using a
mean-based decomposition method, we disentangle positional vectors from hidden
states of LLMs and analyze their formation and effect on attention.
Furthermore, when texts exceed the context window, we analyze the change of
positional vectors in two settings, i.e., direct extrapolation and context
window extension. Based on our findings, we design two training-free context
window extension methods, positional vector replacement and attention window
extension. Experimental results show that our methods can effectively extend
the context window length.",2024-05-28,"Zican Dong, Junyi Li, Xin Men, Wayne Xin Zhao, Bingbing Wang, Zhen Tian, Weipeng Chen, Ji-Rong Wen",http://arxiv.org/pdf/2405.18009v2,cs.LG
DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive Architecture,"The joint-embedding predictive architecture (JEPA) recently has shown
impressive results in extracting visual representations from unlabeled imagery
under a masking strategy. However, we reveal its disadvantages, notably its
insufficient understanding of local semantics. This deficiency originates from
masked modeling in the embedding space, resulting in a reduction of
discriminative power and can even lead to the neglect of critical local
semantics. To bridge this gap, we introduce DMT-JEPA, a novel masked modeling
objective rooted in JEPA, specifically designed to generate discriminative
latent targets from neighboring information. Our key idea is simple: we
consider a set of semantically similar neighboring patches as a target of a
masked patch. To be specific, the proposed DMT-JEPA (a) computes feature
similarities between each masked patch and its corresponding neighboring
patches to select patches having semantically meaningful relations, and (b)
employs lightweight cross-attention heads to aggregate features of neighboring
patches as the masked targets. Consequently, DMT-JEPA demonstrates strong
discriminative power, offering benefits across a diverse spectrum of downstream
tasks. Through extensive experiments, we demonstrate our effectiveness across
various visual benchmarks, including ImageNet-1K image classification, ADE20K
semantic segmentation, and COCO object detection tasks. Code is available at:
\url{https://github.com/DMTJEPA/DMTJEPA}.",2024-05-28,"Shentong Mo, Sukmin Yun",http://arxiv.org/pdf/2405.17995v1,cs.LG
Cross-Context Backdoor Attacks against Graph Prompt Learning,"Graph Prompt Learning (GPL) bridges significant disparities between
pretraining and downstream applications to alleviate the knowledge transfer
bottleneck in real-world graph learning. While GPL offers superior
effectiveness in graph knowledge transfer and computational efficiency, the
security risks posed by backdoor poisoning effects embedded in pretrained
models remain largely unexplored. Our study provides a comprehensive analysis
of GPL's vulnerability to backdoor attacks. We introduce \textit{CrossBA}, the
first cross-context backdoor attack against GPL, which manipulates only the
pretraining phase without requiring knowledge of downstream applications. Our
investigation reveals both theoretically and empirically that tuning trigger
graphs, combined with prompt transformations, can seamlessly transfer the
backdoor threat from pretrained encoders to downstream applications. Through
extensive experiments involving 3 representative GPL methods across 5 distinct
cross-context scenarios and 5 benchmark datasets of node and graph
classification tasks, we demonstrate that \textit{CrossBA} consistently
achieves high attack success rates while preserving the functionality of
downstream applications over clean input. We also explore potential
countermeasures against \textit{CrossBA} and conclude that current defenses are
insufficient to mitigate \textit{CrossBA}. Our study highlights the persistent
backdoor threats to GPL systems, raising trustworthiness concerns in the
practices of GPL techniques.",2024-05-28,"Xiaoting Lyu, Yufei Han, Wei Wang, Hangwei Qian, Ivor Tsang, Xiangliang Zhang",http://arxiv.org/pdf/2405.17984v1,cs.LG
Reinforced Model Predictive Control via Trust-Region Quasi-Newton Policy Optimization,"Model predictive control can optimally deal with nonlinear systems under
consideration of constraints. The control performance depends on the model
accuracy and the prediction horizon. Recent advances propose to use
reinforcement learning applied to a parameterized model predictive controller
to recover the optimal control performance even if an imperfect model or short
prediction horizons are used. However, common reinforcement learning algorithms
rely on first order updates, which only have a linear convergence rate and
hence need an excessive amount of dynamic data. Higher order updates are
typically intractable if the policy is approximated with neural networks due to
the large number of parameters.
  In this work, we use a parameterized model predictive controller as policy,
and leverage the small amount of necessary parameters to propose a trust-region
constrained Quasi-Newton training algorithm for policy optimization with a
superlinear convergence rate. We show that the required second order derivative
information can be calculated by the solution of a linear system of equations.
A simulation study illustrates that the proposed training algorithm outperforms
other algorithms in terms of data efficiency and accuracy.",2024-05-28,"Dean Brandner, Sergio Lucia",http://arxiv.org/pdf/2405.17983v2,cs.LG
Knowledge Circuits in Pretrained Transformers,"The remarkable capabilities of modern large language models are rooted in
their vast repositories of knowledge encoded within their parameters, enabling
them to perceive the world and engage in reasoning. The inner workings of how
these models store knowledge have long been a subject of intense interest and
investigation among researchers. To date, most studies have concentrated on
isolated components within these models, such as the Multilayer Perceptrons and
attention head. In this paper, we delve into the computation graph of the
language model to uncover the knowledge circuits that are instrumental in
articulating specific knowledge. The experiments, conducted with GPT2 and
TinyLLAMA, have allowed us to observe how certain information heads, relation
heads, and Multilayer Perceptrons collaboratively encode knowledge within the
model. Moreover, we evaluate the impact of current knowledge editing techniques
on these knowledge circuits, providing deeper insights into the functioning and
constraints of these editing methodologies. Finally, we utilize knowledge
circuits to analyze and interpret language model behaviors such as
hallucinations and in-context learning. We believe the knowledge circuits hold
potential for advancing our understanding of Transformers and guiding the
improved design of knowledge editing. Code and data are available in
https://github.com/zjunlp/KnowledgeCircuits.",2024-05-28,"Yunzhi Yao, Ningyu Zhang, Zekun Xi, Mengru Wang, Ziwen Xu, Shumin Deng, Huajun Chen",http://arxiv.org/pdf/2405.17969v4,cs.LG
Matroid Semi-Bandits in Sublinear Time,"We study the matroid semi-bandits problem, where at each round the learner
plays a subset of $K$ arms from a feasible set, and the goal is to maximize the
expected cumulative linear rewards. Existing algorithms have per-round time
complexity at least $\Omega(K)$, which becomes expensive when $K$ is large. To
address this computational issue, we propose FasterCUCB whose sampling rule
takes time sublinear in $K$ for common classes of matroids: $O(D\text{
polylog}(K)\text{ polylog}(T))$ for uniform matroids, partition matroids, and
graphical matroids, and $O(D\sqrt{K}\text{ polylog}(T))$ for transversal
matroids. Here, $D$ is the maximum number of elements in any feasible subset of
arms, and $T$ is the horizon. Our technique is based on dynamic maintenance of
an approximate maximum-weight basis over inner-product weights. Although the
introduction of an approximate maximum-weight basis presents a challenge in
regret analysis, we can still guarantee an upper bound on regret as tight as
CUCB in the sense that it matches the gap-dependent lower bound by Kveton et
al. (2014a) asymptotically.",2024-05-28,"Ruo-Chun Tzeng, Naoto Ohsaka, Kaito Ariu",http://arxiv.org/pdf/2405.17968v1,cs.LG
Black-Box Detection of Language Model Watermarks,"Watermarking has emerged as a promising way to detect LLM-generated text, by
augmenting LLM generations with later detectable signals. Recent work has
proposed multiple families of watermarking schemes, several of which focus on
preserving the LLM distribution. This distribution-preservation property is
motivated by the fact that it is a tractable proxy for retaining LLM
capabilities, as well as the inherently implied undetectability of the
watermark by downstream users. Yet, despite much discourse around
undetectability, no prior work has investigated the practical detectability of
any of the current watermarking schemes in a realistic black-box setting. In
this work we tackle this for the first time, developing rigorous statistical
tests to detect the presence, and estimate parameters, of all three popular
watermarking scheme families, using only a limited number of black-box queries.
We experimentally confirm the effectiveness of our methods on a range of
schemes and a diverse set of open-source models. Further, we validate the
feasibility of our tests on real-world APIs. Our findings indicate that current
watermarking schemes are more detectable than previously believed.",2024-05-28,"Thibaud Gloaguen, Nikola Jovanović, Robin Staab, Martin Vechev",http://arxiv.org/pdf/2405.20777v3,cs.LG
Efficient Prior Calibration From Indirect Data,"Bayesian inversion is central to the quantification of uncertainty within
problems arising from numerous applications in science and engineering. To
formulate the approach, four ingredients are required: a forward model mapping
the unknown parameter to an element of a solution space, often the solution
space for a differential equation; an observation operator mapping an element
of the solution space to the data space; a noise model describing how noise
pollutes the observations; and a prior model describing knowledge about the
unknown parameter before the data is acquired. This paper is concerned with
learning the prior model from data; in particular, learning the prior from
multiple realizations of indirect data obtained through the noisy observation
process. The prior is represented, using a generative model, as the pushforward
of a Gaussian in a latent space; the pushforward map is learned by minimizing
an appropriate loss function. A metric that is well-defined under empirical
approximation is used to define the loss function for the pushforward map to
make an implementable methodology. Furthermore, an efficient residual-based
neural operator approximation of the forward model is proposed and it is shown
that this may be learned concurrently with the pushforward map, using a bilevel
optimization formulation of the problem; this use of neural operator
approximation has the potential to make prior learning from indirect data more
computationally efficient, especially when the observation process is
expensive, non-smooth or not known. The ideas are illustrated with the Darcy
flow inverse problem of finding permeability from piezometric head
measurements.",2024-05-28,"O. Deniz Akyildiz, Mark Girolami, Andrew M. Stuart, Arnaud Vadeboncoeur",http://arxiv.org/pdf/2405.17955v2,cs.LG
Efficient Time Series Processing for Transformers and State-Space Models through Token Merging,"Despite recent advances in subquadratic attention mechanisms or state-space
models, processing long token sequences still imposes significant computational
requirements. Token merging has emerged as a solution to increase computational
efficiency in computer vision architectures. In this work, we perform the first
investigations of token merging in time series analysis on both transformers
and state-space models. We further introduce local merging, a domain-specific
token merging algorithm that selectively combines tokens within a local
neighborhood, achieving two major benefits: a) Local merging can adjust its
computational complexity from quadratic to linear based on the neighborhood
size to effectively scale to long sequences; b) Local merging is the first
causal merging scheme enabling token merging in transformer decoders. Further,
we identify spectral properties of the input data that reliably predict the
potential benefits of local merging without requiring evaluation on downstream
tasks. Our comprehensive empirical evaluation demonstrates that local merging
offers substantial efficiency gains with minimal impact on accuracy, achieving
up to 5400% acceleration on the recently proposed Chronos foundation model.",2024-05-28,"Leon Götz, Marcel Kollovieh, Stephan Günnemann, Leo Schwinn",http://arxiv.org/pdf/2405.17951v2,cs.LG
RC-Mixup: A Data Augmentation Strategy against Noisy Data for Regression Tasks,"We study the problem of robust data augmentation for regression tasks in the
presence of noisy data. Data augmentation is essential for generalizing deep
learning models, but most of the techniques like the popular Mixup are
primarily designed for classification tasks on image data. Recently, there are
also Mixup techniques that are specialized to regression tasks like C-Mixup. In
comparison to Mixup, which takes linear interpolations of pairs of samples,
C-Mixup is more selective in which samples to mix based on their label
distances for better regression performance. However, C-Mixup does not
distinguish noisy versus clean samples, which can be problematic when mixing
and lead to suboptimal model performance. At the same time, robust training has
been heavily studied where the goal is to train accurate models against noisy
data through multiple rounds of model training. We thus propose our data
augmentation strategy RC-Mixup, which tightly integrates C-Mixup with
multi-round robust training methods for a synergistic effect. In particular,
C-Mixup improves robust training in identifying clean data, while robust
training provides cleaner data to C-Mixup for it to perform better. A key
advantage of RC-Mixup is that it is data-centric where the robust model
training algorithm itself does not need to be modified, but can simply benefit
from data mixing. We show in our experiments that RC-Mixup significantly
outperforms C-Mixup and robust training baselines on noisy data benchmarks and
can be integrated with various robust training methods.",2024-05-28,"Seong-Hyeon Hwang, Minsu Kim, Steven Euijong Whang",http://arxiv.org/pdf/2405.17938v2,cs.LG
Towards Communication-efficient Federated Learning via Sparse and Aligned Adaptive Optimization,"Adaptive moment estimation (Adam), as a Stochastic Gradient Descent (SGD)
variant, has gained widespread popularity in federated learning (FL) due to its
fast convergence. However, federated Adam (FedAdam) algorithms suffer from a
threefold increase in uplink communication overhead compared to federated SGD
(FedSGD) algorithms, which arises from the necessity to transmit both local
model updates and first and second moment estimates from distributed devices to
the centralized server for aggregation. Driven by this issue, we propose a
novel sparse FedAdam algorithm called FedAdam-SSM, wherein distributed devices
sparsify the updates of local model parameters and moment estimates and
subsequently upload the sparse representations to the centralized server. To
further reduce the communication overhead, the updates of local model
parameters and moment estimates incorporate a shared sparse mask (SSM) into the
sparsification process, eliminating the need for three separate sparse masks.
Theoretically, we develop an upper bound on the divergence between the local
model trained by FedAdam-SSM and the desired model trained by centralized Adam,
which is related to sparsification error and imbalanced data distribution. By
minimizing the divergence bound between the model trained by FedAdam-SSM and
centralized Adam, we optimize the SSM to mitigate the learning performance
degradation caused by sparsification error. Additionally, we provide
convergence bounds for FedAdam-SSM in both convex and non-convex objective
function settings, and investigate the impact of local epoch, learning rate and
sparsification ratio on the convergence rate of FedAdam-SSM. Experimental
results show that FedAdam-SSM outperforms baselines in terms of convergence
rate (over 1.1$\times$ faster than the sparse FedAdam baselines) and test
accuracy (over 14.5\% ahead of the quantized FedAdam baselines).",2024-05-28,"Xiumei Deng, Jun Li, Kang Wei, Long Shi, Zeihui Xiong, Ming Ding, Wen Chen, Shi Jin, H. Vincent Poor",http://arxiv.org/pdf/2405.17932v1,cs.LG
Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment,"Effectively aligning Large Language Models (LLMs) with human-centric values
while preventing the degradation of abilities acquired through Pre-training and
Supervised Fine-tuning (SFT) poses a central challenge in Reinforcement
Learning from Human Feedback (RLHF). In this paper, we first discover that
interpolating RLHF and SFT model parameters can adjust the trade-off between
human preference and basic capabilities, thereby reducing the alignment tax at
the cost of alignment reward. Inspired by this, we propose integrating the RL
policy and SFT models at each optimization step in RLHF to continuously
regulate the training direction, introducing the Online Merging Optimizer.
Specifically, we merge gradients with the parameter differences between SFT and
pretrained models, effectively steering the gradient towards maximizing rewards
in the direction of SFT optimization. We demonstrate that our optimizer works
well with different LLM families, such as Qwen and LLaMA, across various model
sizes ranging from 1.8B to 8B, various RLHF algorithms like DPO and KTO, and
existing model merging methods. It significantly enhances alignment reward
while mitigating alignment tax, achieving higher overall performance across 14
benchmarks.",2024-05-28,"Keming Lu, Bowen Yu, Fei Huang, Yang Fan, Runji Lin, Chang Zhou",http://arxiv.org/pdf/2405.17931v1,cs.LG
The Evolution of Multimodal Model Architectures,"This work uniquely identifies and characterizes four prevalent multimodal
model architectural patterns in the contemporary multimodal landscape.
Systematically categorizing models by architecture type facilitates monitoring
of developments in the multimodal domain. Distinct from recent survey papers
that present general information on multimodal architectures, this research
conducts a comprehensive exploration of architectural details and identifies
four specific architectural types. The types are distinguished by their
respective methodologies for integrating multimodal inputs into the deep neural
network model. The first two types (Type A and B) deeply fuses multimodal
inputs within the internal layers of the model, whereas the following two types
(Type C and D) facilitate early fusion at the input stage. Type-A employs
standard cross-attention, whereas Type-B utilizes custom-designed layers for
modality fusion within the internal layers. On the other hand, Type-C utilizes
modality-specific encoders, while Type-D leverages tokenizers to process the
modalities at the model's input stage. The identified architecture types aid
the monitoring of any-to-any multimodal model development. Notably, Type-C and
Type-D are currently favored in the construction of any-to-any multimodal
models. Type-C, distinguished by its non-tokenizing multimodal model
architecture, is emerging as a viable alternative to Type-D, which utilizes
input-tokenizing techniques. To assist in model selection, this work highlights
the advantages and disadvantages of each architecture type based on data and
compute requirements, architecture complexity, scalability, simplification of
adding modalities, training objectives, and any-to-any multimodal generation
capability.",2024-05-28,"Shakti N. Wadekar, Abhishek Chaurasia, Aman Chadha, Eugenio Culurciello",http://arxiv.org/pdf/2405.17927v1,cs.LG
Cost-Sensitive Multi-Fidelity Bayesian Optimization with Transfer of Learning Curve Extrapolation,"In this paper, we address the problem of cost-sensitive multi-fidelity
Bayesian Optimization (BO) for efficient hyperparameter optimization (HPO).
Specifically, we assume a scenario where users want to early-stop the BO when
the performance improvement is not satisfactory with respect to the required
computational cost. Motivated by this scenario, we introduce utility, which is
a function predefined by each user and describes the trade-off between cost and
performance of BO. This utility function, combined with our novel acquisition
function and stopping criterion, allows us to dynamically choose for each BO
step the best configuration that we expect to maximally improve the utility in
future, and also automatically stop the BO around the maximum utility. Further,
we improve the sample efficiency of existing learning curve (LC) extrapolation
methods with transfer learning, while successfully capturing the correlations
between different configurations to develop a sensible surrogate function for
multi-fidelity BO. We validate our algorithm on various LC datasets and found
it outperform all the previous multi-fidelity BO and transfer-BO baselines we
consider, achieving significantly better trade-off between cost and performance
of BO.",2024-05-28,"Dong Bok Lee, Aoxuan Silvia Zhang, Byungjoo Kim, Junhyeon Park, Juho Lee, Sung Ju Hwang, Hae Beom Lee",http://arxiv.org/pdf/2405.17918v1,cs.LG
Trustworthy DNN Partition for Blockchain-enabled Digital Twin in Wireless IIoT Networks,"Digital twin (DT) has emerged as a promising solution to enhance
manufacturing efficiency in industrial Internet of Things (IIoT) networks. To
promote the efficiency and trustworthiness of DT for wireless IIoT networks, we
propose a blockchain-enabled DT (B-DT) framework that employs deep neural
network (DNN) partitioning technique and reputation-based consensus mechanism,
wherein the DTs maintained at the gateway side execute DNN inference tasks
using the data collected from their associated IIoT devices. First, we employ
DNN partitioning technique to offload the top-layer DNN inference tasks to the
access point (AP) side, which alleviates the computation burden at the gateway
side and thereby improves the efficiency of DNN inference. Second, we propose a
reputation-based consensus mechanism that integrates Proof of Work (PoW) and
Proof of Stake (PoS). Specifically, the proposed consensus mechanism evaluates
the off-chain reputation of each AP according to its computation resource
contributions to the DNN inference tasks, and utilizes the off-chain reputation
as a stake to adjust the block generation difficulty. Third, we formulate a
stochastic optimization problem of communication resource (i.e., partition
point) and computation resource allocation (i.e., computation frequency of APs
for top-layer DNN inference and block generation) to minimize system latency
under the time-varying channel state and long-term constraints of off-chain
reputation, and solve the problem using Lyapunov optimization method.
Experimental results show that the proposed dynamic DNN partitioning and
resource allocation (DPRA) algorithm outperforms the baselines in terms of
reducing the overall latency while guaranteeing the trustworthiness of the B-DT
system.",2024-05-28,"Xiumei Deng, Jun Li, Long Shi, Kang Wei, Ming Ding, Yumeng Shao, Wen Chen, Shi Jin",http://arxiv.org/pdf/2405.17914v1,cs.LG
Cycle-YOLO: A Efficient and Robust Framework for Pavement Damage Detection,"With the development of modern society, traffic volume continues to increase
in most countries worldwide, leading to an increase in the rate of pavement
damage Therefore, the real-time and highly accurate pavement damage detection
and maintenance have become the current need. In this paper, an enhanced
pavement damage detection method with CycleGAN and improved YOLOv5 algorithm is
presented. We selected 7644 self-collected images of pavement damage samples as
the initial dataset and augmented it by CycleGAN. Due to a substantial
difference between the images generated by CycleGAN and real road images, we
proposed a data enhancement method based on an improved Scharr filter,
CycleGAN, and Laplacian pyramid. To improve the target recognition effect on a
complex background and solve the problem that the spatial pyramid pooling-fast
module in the YOLOv5 network cannot handle multiscale targets, we introduced
the convolutional block attention module attention mechanism and proposed the
atrous spatial pyramid pooling with squeeze-and-excitation structure. In
addition, we optimized the loss function of YOLOv5 by replacing the CIoU with
EIoU. The experimental results showed that our algorithm achieved a precision
of 0.872, recall of 0.854, and mean average precision@0.5 of 0.882 in detecting
three main types of pavement damage: cracks, potholes, and patching. On the
GPU, its frames per second reached 68, meeting the requirements for real-time
detection. Its overall performance even exceeded the current more advanced
YOLOv7 and achieved good results in practical applications, providing a basis
for decision-making in pavement damage detection and prevention.",2024-05-28,"Zhengji Li, Xi Xiao, Jiacheng Xie, Yuxiao Fan, Wentao Wang, Gang Chen, Liqiang Zhang, Tianyang Wang",http://arxiv.org/pdf/2405.17905v1,cs.LG
Boosting Protein Language Models with Negative Sample Mining,"We introduce a pioneering methodology for boosting large language models in
the domain of protein representation learning. Our primary contribution lies in
the refinement process for correlating the over-reliance on co-evolution
knowledge, in a way that networks are trained to distill invaluable insights
from negative samples, constituted by protein pairs sourced from disparate
categories. By capitalizing on this novel approach, our technique steers the
training of transformer-based models within the attention score space. This
advanced strategy not only amplifies performance but also reflects the nuanced
biological behaviors exhibited by proteins, offering aligned evidence with
traditional biological mechanisms such as protein-protein interaction. We
experimentally observed improved performance on various tasks over datasets, on
top of several well-established large protein models. This innovative paradigm
opens up promising horizons for further progress in the realms of protein
research and computational biology.",2024-05-28,"Yaoyao Xu, Xinjian Zhao, Xiaozhuang Song, Benyou Wang, Tianshu Yu",http://arxiv.org/pdf/2405.17902v2,cs.LG
FlashST: A Simple and Universal Prompt-Tuning Framework for Traffic Prediction,"The objective of traffic prediction is to accurately forecast and analyze the
dynamics of transportation patterns, considering both space and time. However,
the presence of distribution shift poses a significant challenge in this field,
as existing models struggle to generalize well when faced with test data that
significantly differs from the training distribution. To tackle this issue,
this paper introduces a simple and universal spatio-temporal prompt-tuning
framework-FlashST, which adapts pre-trained models to the specific
characteristics of diverse downstream datasets, improving generalization in
diverse traffic prediction scenarios. Specifically, the FlashST framework
employs a lightweight spatio-temporal prompt network for in-context learning,
capturing spatio-temporal invariant knowledge and facilitating effective
adaptation to diverse scenarios. Additionally, we incorporate a distribution
mapping mechanism to align the data distributions of pre-training and
downstream data, facilitating effective knowledge transfer in spatio-temporal
forecasting. Empirical evaluations demonstrate the effectiveness of our FlashST
across different spatio-temporal prediction tasks using diverse urban datasets.
Code is available at https://github.com/HKUDS/FlashST.",2024-05-28,"Zhonghang Li, Lianghao Xia, Yong Xu, Chao Huang",http://arxiv.org/pdf/2405.17898v1,cs.LG
$C^2M^3$: Cycle-Consistent Multi-Model Merging,"In this paper, we present a novel data-free method for merging neural
networks in weight space. Differently from most existing works, our method
optimizes for the permutations of network neurons globally across all layers.
This allows us to enforce cycle consistency of the permutations when merging $N
\geq 3$ models, allowing circular compositions of permutations to be computed
without accumulating error along the path. We qualitatively and quantitatively
motivate the need for such a constraint, showing its benefits when merging sets
of models in scenarios spanning varying architectures and datasets. We finally
show that, when coupled with activation renormalization, our approach yields
the best results in the task.",2024-05-28,"Donato Crisostomi, Marco Fumero, Daniele Baieri, Florian Bernard, Emanuele Rodolà",http://arxiv.org/pdf/2405.17897v2,cs.LG
SLMRec: Distilling Large Language Models into Small for Sequential Recommendation,"Sequential Recommendation (SR) task involves predicting the next item a user
is likely to interact with, given their past interactions. The SR models
examine the sequence of a user's actions to discern more complex behavioral
patterns and temporal dynamics. Recent research demonstrates the great impact
of LLMs on sequential recommendation systems, either viewing sequential
recommendation as language modeling or serving as the backbone for user
representation. Although these methods deliver outstanding performance, there
is scant evidence of the necessity of a large language model and how large the
language model is needed, especially in the sequential recommendation scene.
Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to
apply a LLM-based model in real-world platforms that often need to process
billions of traffic logs daily. In this paper, we explore the influence of
LLMs' depth by conducting extensive experiments on large-scale industry
datasets. Surprisingly, our motivational experiments reveal that most
intermediate layers of LLMs are redundant, indicating that pruning the
remaining layers can still maintain strong performance. Motivated by this
insight, we empower small language models for SR, namely SLMRec, which adopt a
simple yet effective knowledge distillation method. Moreover, SLMRec is
orthogonal to other post-training efficiency techniques, such as quantization
and pruning, so that they can be leveraged in combination. Comprehensive
experimental results illustrate that the proposed SLMRec model attains the best
performance using only 13% of the parameters found in LLM-based recommendation
models while simultaneously achieving up to 6.6x and 8.0x speedups in training
and inference time costs, respectively. Besides, we provide a theoretical
justification for why small language models can perform comparably to large
language models in SR.",2024-05-28,"Wujiang Xu, Qitian Wu, Zujie Liang, Jiaojiao Han, Xuying Ning, Yunxiao Shi, Wenfang Lin, Yongfeng Zhang",http://arxiv.org/pdf/2405.17890v4,cs.LG
Improving Discrete Diffusion Models via Structured Preferential Generation,"In the domains of image and audio, diffusion models have shown impressive
performance. However, their application to discrete data types, such as
language, has often been suboptimal compared to autoregressive generative
models. This paper tackles the challenge of improving discrete diffusion models
by introducing a structured forward process that leverages the inherent
information hierarchy in discrete categories, such as words in text. Our
approach biases the generative process to produce certain categories before
others, resulting in a notable improvement in log-likelihood scores on the
text8 dataset. This work paves the way for more advances in discrete diffusion
models with potentially significant enhancements in performance.",2024-05-28,"Severi Rissanen, Markus Heinonen, Arno Solin",http://arxiv.org/pdf/2405.17889v1,cs.LG
Achieving Exponential Asymptotic Optimality in Average-Reward Restless Bandits without Global Attractor Assumption,"We consider the infinite-horizon average-reward restless bandit problem. We
propose a novel \emph{two-set policy} that maintains two dynamic subsets of
arms: one subset of arms has a nearly optimal state distribution and takes
actions according to an Optimal Local Control routine; the other subset of arms
is driven towards the optimal state distribution and gradually merged into the
first subset. We show that our two-set policy is asymptotically optimal with an
$O(\exp(-C N))$ optimality gap for an $N$-armed problem, under the mild
assumptions of aperiodic-unichain, non-degeneracy, and local stability. Our
policy is the first to achieve \emph{exponential asymptotic optimality} under
the above set of easy-to-verify assumptions, whereas prior work either requires
a strong \emph{global attractor} assumption or only achieves an $O(1/\sqrt{N})$
optimality gap. We further discuss obstacles in weakening the assumptions by
demonstrating examples where exponential asymptotic optimality is not
achievable when any of the three assumptions is violated. Notably, we prove a
lower bound for a large class of locally unstable restless bandits, showing
that local stability is particularly fundamental for exponential asymptotic
optimality. Finally, we use simulations to demonstrate that the two-set policy
outperforms previous policies on certain RB problems and performs competitively
overall.",2024-05-28,"Yige Hong, Qiaomin Xie, Yudong Chen, Weina Wang",http://arxiv.org/pdf/2405.17882v2,cs.LG
Crystal-LSBO: Automated Design of De Novo Crystals with Latent Space Bayesian Optimization,"Generative modeling of crystal structures is significantly challenged by the
complexity of input data, which constrains the ability of these models to
explore and discover novel crystals. This complexity often confines de novo
design methodologies to merely small perturbations of known crystals and
hampers the effective application of advanced optimization techniques. One such
optimization technique, Latent Space Bayesian Optimization (LSBO) has
demonstrated promising results in uncovering novel objects across various
domains, especially when combined with Variational Autoencoders (VAEs).
Recognizing LSBO's potential and the critical need for innovative crystal
discovery, we introduce Crystal-LSBO, a de novo design framework for crystals
specifically tailored to enhance explorability within LSBO frameworks.
Crystal-LSBO employs multiple VAEs, each dedicated to a distinct aspect of
crystal structure: lattice, coordinates, and chemical elements, orchestrated by
an integrative model that synthesizes these components into a cohesive output.
This setup not only streamlines the learning process but also produces
explorable latent spaces thanks to the decreased complexity of the learning
task for each model, enabling LSBO approaches to operate. Our study pioneers
the use of LSBO for de novo crystal design, demonstrating its efficacy through
optimization tasks focused mainly on formation energy values. Our results
highlight the effectiveness of our methodology, offering a new perspective for
de novo crystal discovery.",2024-05-28,"Onur Boyar, Yanheng Gu, Yuji Tanaka, Shunsuke Tonogai, Tomoya Itakura, Ichiro Takeuchi",http://arxiv.org/pdf/2405.17881v2,cs.LG
Diffusion Rejection Sampling,"Recent advances in powerful pre-trained diffusion models encourage the
development of methods to improve the sampling performance under well-trained
diffusion models. This paper introduces Diffusion Rejection Sampling (DiffRS),
which uses a rejection sampling scheme that aligns the sampling transition
kernels with the true ones at each timestep. The proposed method can be viewed
as a mechanism that evaluates the quality of samples at each intermediate
timestep and refines them with varying effort depending on the sample.
Theoretical analysis shows that DiffRS can achieve a tighter bound on sampling
error compared to pre-trained models. Empirical results demonstrate the
state-of-the-art performance of DiffRS on the benchmark datasets and the
effectiveness of DiffRS for fast diffusion samplers and large-scale
text-to-image diffusion models. Our code is available at
https://github.com/aailabkaist/DiffRS.",2024-05-28,"Byeonghu Na, Yeongmin Kim, Minsang Park, Donghyeok Shin, Wanmo Kang, Il-Chul Moon",http://arxiv.org/pdf/2405.17880v1,cs.LG
Imitating from auxiliary imperfect demonstrations via Adversarial Density Weighted Regression,"We propose a novel one-step supervised imitation learning (IL) framework
called Adversarial Density Regression (ADR). This IL framework aims to correct
the policy learned on unknown-quality to match the expert distribution by
utilizing demonstrations, without relying on the Bellman operator.
Specifically, ADR addresses several limitations in previous IL algorithms:
First, most IL algorithms are based on the Bellman operator, which inevitably
suffer from cumulative offsets from sub-optimal rewards during multi-step
update processes. Additionally, off-policy training frameworks suffer from
Out-of-Distribution (OOD) state-actions. Second, while conservative terms help
solve the OOD issue, balancing the conservative term is difficult. To address
these limitations, we fully integrate a one-step density-weighted Behavioral
Cloning (BC) objective for IL with auxiliary imperfect demonstration.
Theoretically, we demonstrate that this adaptation can effectively correct the
distribution of policies trained on unknown-quality datasets to align with the
expert policy's distribution. Moreover, the difference between the empirical
and the optimal value function is proportional to the upper bound of ADR's
objective, indicating that minimizing ADR's objective is akin to approaching
the optimal value. Experimentally, we validated the performance of ADR by
conducting extensive evaluations. Specifically, ADR outperforms all of the
selected IL algorithms on tasks from the Gym-Mujoco domain. Meanwhile, it
achieves an 89.5% improvement over IQL when utilizing ground truth rewards on
tasks from the Adroit and Kitchen domains. Our codebase will be released at:
https://github.com/stevezhangzA/Adverserial_Density_Regression.",2024-05-28,"Ziqi Zhang, Zifeng Zhuang, Jingzehua Xu, Yiyuan Yang, Yubo Huang, Donglin Wang, Shuai Zhang",http://arxiv.org/pdf/2405.20351v3,cs.LG
Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree,"Diffusion planners have shown promise in handling long-horizon and
sparse-reward tasks due to the non-autoregressive plan generation. However,
their inherent stochastic risk of generating infeasible trajectories presents
significant challenges to their reliability and stability. We introduce a novel
approach, the Trajectory Aggregation Tree (TAT), to address this issue in
diffusion planners. Compared to prior methods that rely solely on raw
trajectory predictions, TAT aggregates information from both historical and
current trajectories, forming a dynamic tree-like structure. Each trajectory is
conceptualized as a branch and individual states as nodes. As the structure
evolves with the integration of new trajectories, unreliable states are
marginalized, and the most impactful nodes are prioritized for decision-making.
TAT can be deployed without modifying the original training and sampling
pipelines of diffusion planners, making it a training-free, ready-to-deploy
solution. We provide both theoretical analysis and empirical evidence to
support TAT's effectiveness. Our results highlight its remarkable ability to
resist the risk from unreliable trajectories, guarantee the performance
boosting of diffusion planners in $100\%$ of tasks, and exhibit an appreciable
tolerance margin for sample quality, thereby enabling planning with a more than
$3\times$ acceleration.",2024-05-28,"Lang Feng, Pengjie Gu, Bo An, Gang Pan",http://arxiv.org/pdf/2405.17879v2,cs.LG
An Information Theoretic Evaluation Metric For Strong Unlearning,"Machine unlearning (MU) aims to remove the influence of specific data from
trained models, addressing privacy concerns and ensuring compliance with
regulations such as the ""right to be forgotten."" Evaluating strong unlearning,
where the unlearned model is indistinguishable from one retrained without the
forgetting data, remains a significant challenge in deep neural networks
(DNNs). Common black-box metrics, such as variants of membership inference
attacks and accuracy comparisons, primarily assess model outputs but often fail
to capture residual information in intermediate layers. To bridge this gap, we
introduce the Information Difference Index (IDI), a novel white-box metric
inspired by information theory. IDI quantifies retained information in
intermediate features by measuring mutual information between those features
and the labels to be forgotten, offering a more comprehensive assessment of
unlearning efficacy. Our experiments demonstrate that IDI effectively measures
the degree of unlearning across various datasets and architectures, providing a
reliable tool for evaluating strong unlearning in DNNs.",2024-05-28,"Dongjae Jeon, Wonje Jeung, Taeheon Kim, Albert No, Jonghyun Choi",http://arxiv.org/pdf/2405.17878v2,cs.LG
SelMatch: Effectively Scaling Up Dataset Distillation via Selection-Based Initialization and Partial Updates by Trajectory Matching,"Dataset distillation aims to synthesize a small number of images per class
(IPC) from a large dataset to approximate full dataset training with minimal
performance loss. While effective in very small IPC ranges, many distillation
methods become less effective, even underperforming random sample selection, as
IPC increases. Our examination of state-of-the-art trajectory-matching based
distillation methods across various IPC scales reveals that these methods
struggle to incorporate the complex, rare features of harder samples into the
synthetic dataset even with the increased IPC, resulting in a persistent
coverage gap between easy and hard test samples. Motivated by such
observations, we introduce SelMatch, a novel distillation method that
effectively scales with IPC. SelMatch uses selection-based initialization and
partial updates through trajectory matching to manage the synthetic dataset's
desired difficulty level tailored to IPC scales. When tested on CIFAR-10/100
and TinyImageNet, SelMatch consistently outperforms leading selection-only and
distillation-only methods across subset ratios from 5% to 30%.",2024-05-28,"Yongmin Lee, Hye Won Chung",http://arxiv.org/pdf/2406.18561v1,cs.LG
Decentralized Directed Collaboration for Personalized Federated Learning,"Personalized Federated Learning (PFL) is proposed to find the greatest
personalized models for each client. To avoid the central failure and
communication bottleneck in the server-based FL, we concentrate on the
Decentralized Personalized Federated Learning (DPFL) that performs distributed
model training in a Peer-to-Peer (P2P) manner. Most personalized works in DPFL
are based on undirected and symmetric topologies, however, the data,
computation and communication resources heterogeneity result in large variances
in the personalized models, which lead the undirected aggregation to suboptimal
personalized performance and unguaranteed convergence. To address these issues,
we propose a directed collaboration DPFL framework by incorporating stochastic
gradient push and partial model personalized, called \textbf{D}ecentralized
\textbf{Fed}erated \textbf{P}artial \textbf{G}radient \textbf{P}ush
(\textbf{DFedPGP}). It personalizes the linear classifier in the modern deep
model to customize the local solution and learns a consensus representation in
a fully decentralized manner. Clients only share gradients with a subset of
neighbors based on the directed and asymmetric topologies, which guarantees
flexible choices for resource efficiency and better convergence. Theoretically,
we show that the proposed DFedPGP achieves a superior convergence rate of
$\mathcal{O}(\frac{1}{\sqrt{T}})$ in the general non-convex setting, and prove
the tighter connectivity among clients will speed up the convergence. The
proposed method achieves state-of-the-art (SOTA) accuracy in both data and
computation heterogeneity scenarios, demonstrating the efficiency of the
directed collaboration and partial gradient push.",2024-05-28,"Yingqi Liu, Yifan Shi, Qinglun Li, Baoyuan Wu, Xueqian Wang, Li Shen",http://arxiv.org/pdf/2405.17876v1,cs.LG
BO4IO: A Bayesian optimization approach to inverse optimization with uncertainty quantification,"This work addresses data-driven inverse optimization (IO), where the goal is
to estimate unknown parameters in an optimization model from observed decisions
that can be assumed to be optimal or near-optimal solutions to the optimization
problem. The IO problem is commonly formulated as a large-scale bilevel program
that is notoriously difficult to solve. Deviating from traditional exact
solution methods, we propose a derivative-free optimization approach based on
Bayesian optimization, which we call BO4IO, to solve general IO problems. We
treat the IO loss function as a black box and approximate it with a Gaussian
process model. Using the predicted posterior function, an acquisition function
is minimized at each iteration to query new candidate solutions and
sequentially converge to the optimal parameter estimates. The main advantages
of using Bayesian optimization for IO are two-fold: (i) it circumvents the need
of complex reformulations of the bilevel program or specialized algorithms and
can hence enable computational tractability even when the underlying
optimization problem is nonconvex or involves discrete variables, and (ii) it
allows approximations of the profile likelihood, which provide uncertainty
quantification on the IO parameter estimates. We apply the proposed method to
three computational case studies, covering different classes of forward
optimization problems ranging from convex nonlinear to nonconvex mixed-integer
nonlinear programs. Our extensive computational results demonstrate the
efficacy and robustness of BO4IO to accurately estimate unknown model
parameters from small and noisy datasets. In addition, the proposed profile
likelihood analysis has proven to be effective in providing good approximations
of the confidence intervals on the parameter estimates and assessing the
identifiability of the unknown parameters.",2024-05-28,"Yen-An Lu, Wei-Shou Hu, Joel A. Paulson, Qi Zhang",http://arxiv.org/pdf/2405.17875v1,cs.LG
"NUTS, NARS, and Speech","To investigate whether ""Intelligence is the capacity of an
information-processing system to adapt to its environment while operating with
insufficient knowledge and resources"", we look at utilising the non axiomatic
reasoning system (NARS) for speech recognition. This article presents NUTS:
raNdom dimensionality redUction non axiomaTic reasoning few Shot learner for
perception. NUTS consists of naive dimensionality reduction, some
pre-processing, and then non axiomatic reasoning (NARS). With only 2 training
examples NUTS performs similarly to the Whisper Tiny model for discrete word
identification.",2024-05-28,D. van der Sluis,http://arxiv.org/pdf/2405.17874v1,cs.LG
Towards robust prediction of material properties for nuclear reactor design under scarce data -- a study in creep rupture property,"Advances in Deep Learning bring further investigation into credibility and
robustness, especially for safety-critical engineering applications such as the
nuclear industry. The key challenges include the availability of data set
(often scarce and sparse) and insufficient consideration of the uncertainty in
the data, model, and prediction. This paper therefore presents a meta-learning
based approach that is both uncertainty- and prior knowledge-informed, aiming
at trustful predictions of material properties for the nuclear reactor design.
It is suited for robust learning under limited data. Uncertainty has been
accounted for where a distribution of predictor functions are produced for
extrapolation. Results suggest it achieves superior performance than existing
empirical methods in rupture life prediction, a case which is typically under a
small data regime. While demonstrated herein with rupture properties, this
learning approach is transferable to solve similar problems of data scarcity
across the nuclear industry. It is of great importance to boosting the AI
analytics in the nuclear industry by proving the applicability and robustness
while providing tools that can be trusted.",2024-05-28,"Yu Chen, Edoardo Patelli, Zhen Yang, Adolphus Lye",http://arxiv.org/pdf/2405.17862v1,cs.LG
Improved Generation of Adversarial Examples Against Safety-aligned LLMs,"Adversarial prompts generated using gradient-based methods exhibit
outstanding performance in performing automatic jailbreak attacks against
safety-aligned LLMs. Nevertheless, due to the discrete nature of texts, the
input gradient of LLMs struggles to precisely reflect the magnitude of loss
change that results from token replacements in the prompt, leading to limited
attack success rates against safety-aligned LLMs, even in the white-box
setting. In this paper, we explore a new perspective on this problem,
suggesting that it can be alleviated by leveraging innovations inspired in
transfer-based attacks that were originally proposed for attacking black-box
image classification models. For the first time, we appropriate the ideologies
of effective methods among these transfer-based attacks, i.e., Skip Gradient
Method and Intermediate Level Attack, into gradient-based adversarial prompt
generation and achieve significant performance gains without introducing
obvious computational cost. Meanwhile, by discussing mechanisms behind the
gains, new insights are drawn, and proper combinations of these methods are
also developed. Our empirical results show that 87% of the query-specific
adversarial suffixes generated by the developed combination can induce
Llama-2-7B-Chat to produce the output that exactly matches the target string on
AdvBench. This match rate is 33% higher than that of a very strong baseline
known as GCG, demonstrating advanced discrete optimization for adversarial
prompt generation against LLMs. In addition, without introducing obvious cost,
the combination achieves >30% absolute increase in attack success rates
compared with GCG when generating both query-specific (38% -> 68%) and
universal adversarial prompts (26.68% -> 60.32%) for attacking the
Llama-2-7B-Chat model on AdvBench. Code at:
https://github.com/qizhangli/Gradient-based-Jailbreak-Attacks.",2024-05-28,"Qizhang Li, Yiwen Guo, Wangmeng Zuo, Hao Chen",http://arxiv.org/pdf/2405.20778v2,cs.LG
I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit Large Language Models,"Post-training quantization (PTQ) serves as a potent technique to accelerate
the inference of large language models (LLMs). Nonetheless, existing works
still necessitate a considerable number of floating-point (FP) operations
during inference, including additional quantization and de-quantization, as
well as non-linear operators such as RMSNorm and Softmax. This limitation
hinders the deployment of LLMs on the edge and cloud devices. In this paper, we
identify the primary obstacle to integer-only quantization for LLMs lies in the
large fluctuation of activations across channels and tokens in both linear and
non-linear operations. To address this issue, we propose I-LLM, a novel
integer-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)
we develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smooth
inter-channel variations of all activations and weights. (2) to alleviate
degradation caused by inter-token variations, we introduce a novel approach
called Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamic
quantization in full-integer matrix multiplication by dynamically quantizing
the input and outputs with integer-only operations. (3) we design
DI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift to
execute non-linear operators efficiently while maintaining accuracy. The
experiment shows that our I-LLM achieves comparable accuracy to the FP baseline
and outperforms non-integer quantization methods. For example, I-LLM can
operate at W4A4 with negligible loss of accuracy. To our knowledge, we are the
first to bridge the gap between integer-only quantization and LLMs. We've
published our code on anonymous.4open.science, aiming to contribute to the
advancement of this field.",2024-05-28,"Xing Hu, Yuan Cheng, Dawei Yang, Zhihang Yuan, Jiangyong Yu, Chen Xu, Sifan Zhou",http://arxiv.org/pdf/2405.17849v2,cs.LG
MMDisCo: Multi-Modal Discriminator-Guided Cooperative Diffusion for Joint Audio and Video Generation,"This study aims to construct an audio-video generative model with minimal
computational cost by leveraging pre-trained single-modal generative models for
audio and video. To achieve this, we propose a novel method that guides
single-modal models to cooperatively generate well-aligned samples across
modalities. Specifically, given two pre-trained base diffusion models, we train
a lightweight joint guidance module to adjust scores separately estimated by
the base models to match the score of joint distribution over audio and video.
We show that this guidance can be computed using the gradient of the optimal
discriminator, which distinguishes real audio-video pairs from fake ones
independently generated by the base models. Based on this analysis, we
construct a joint guidance module by training this discriminator. Additionally,
we adopt a loss function to stabilize the discriminator's gradient and make it
work as a noise estimator, as in standard diffusion models. Empirical
evaluations on several benchmark datasets demonstrate that our method improves
both single-modal fidelity and multimodal alignment with relatively few
parameters. The code is available at: https://github.com/SonyResearch/MMDisCo.",2024-05-28,"Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji",http://arxiv.org/pdf/2405.17842v2,cs.LG
Trust and Terror: Hazards in Text Reveal Negatively Biased Credulity and Partisan Negativity Bias,"Socio-linguistic indicators of text, such as emotion or sentiment, are often
extracted using neural networks in order to better understand features of
social media. One indicator that is often overlooked, however, is the presence
of hazards within text. Recent psychological research suggests that statements
about hazards are more believable than statements about benefits (a property
known as negatively biased credulity), and that political liberals and
conservatives differ in how often they share hazards. Here, we develop a new
model to detect information concerning hazards, trained on a new collection of
annotated X posts, as well as urban legends annotated in previous work. We show
that not only does this model perform well (outperforming, e.g., zero-shot
human annotator proxies, such as GPT-4) but that the hazard information it
extracts is not strongly correlated with other indicators, namely moral
outrage, sentiment, emotions, and threat words. (That said, consonant with
expectations, hazard information does correlate positively with such emotions
as fear, and negatively with emotions like joy.) We then apply this model to
three datasets: X posts about COVID-19, X posts about the 2023 Hamas-Israel
war, and a new expanded collection of urban legends. From these data, we
uncover words associated with hazards unique to each dataset as well as
differences in this language between groups of users, such as conservatives and
liberals, which informs what these groups perceive as hazards. We further show
that information about hazards peaks in frequency after major hazard events,
and therefore acts as an automated indicator of such events. Finally, we find
that information about hazards is especially prevalent in urban legends, which
is consistent with previous work that finds that reports of hazards are more
likely to be both believed and transmitted.",2024-05-28,"Keith Burghardt, Daniel M. T. Fessler, Chyna Tang, Anne Pisor, Kristina Lerman",http://arxiv.org/pdf/2405.17838v1,cs.LG
An Innovative Networks in Federated Learning,"This paper presents the development and application of Wavelet
Kolmogorov-Arnold Networks (Wav-KAN) in federated learning. We implemented
Wav-KAN \cite{wav-kan} in the clients. Indeed, we have considered both
continuous wavelet transform (CWT) and also discrete wavelet transform (DWT) to
enable multiresolution capabaility which helps in heteregeneous data
distribution across clients. Extensive experiments were conducted on different
datasets, demonstrating Wav-KAN's superior performance in terms of
interpretability, computational speed, training and test accuracy. Our
federated learning algorithm integrates wavelet-based activation functions,
parameterized by weight, scale, and translation, to enhance local and global
model performance. Results show significant improvements in computational
efficiency, robustness, and accuracy, highlighting the effectiveness of wavelet
selection in scalable neural network design.",2024-05-28,"Zavareh Bozorgasl, Hao Chen",http://arxiv.org/pdf/2405.17836v1,cs.LG
Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization,"Researchers have been studying approaches to steer the behavior of Large
Language Models (LLMs) and build personalized LLMs tailored for various
applications. While fine-tuning seems to be a direct solution, it requires
substantial computational resources and may significantly affect the utility of
the original LLM. Recent endeavors have introduced more lightweight strategies,
focusing on extracting ""steering vectors"" to guide the model's output toward
desired behaviors by adjusting activations within specific layers of the LLM's
transformer architecture. However, such steering vectors are directly extracted
from the activations of human preference data and thus often lead to suboptimal
results and occasional failures, especially in alignment-related scenarios.
This work proposes an innovative approach that could produce more effective
steering vectors through bi-directional preference optimization. Our method is
designed to allow steering vectors to directly influence the generation
probability of contrastive human preference data pairs, thereby offering a more
precise representation of the target behavior. By carefully adjusting the
direction and magnitude of the steering vector, we enabled personalized control
over the desired behavior across a spectrum of intensities. Extensive
experimentation across various open-ended generation tasks, particularly
focusing on steering AI personas, has validated the efficacy of our approach.
Moreover, we comprehensively investigate critical alignment-concerning
scenarios, such as managing truthfulness, mitigating hallucination, and
addressing jailbreaking attacks. Remarkably, our method can still demonstrate
outstanding steering effectiveness across these scenarios. Furthermore, we
showcase the transferability of our steering vectors across different
models/LoRAs and highlight the synergistic benefits of applying multiple
vectors simultaneously.",2024-05-28,"Yuanpu Cao, Tianrong Zhang, Bochuan Cao, Ziyi Yin, Lu Lin, Fenglong Ma, Jinghui Chen",http://arxiv.org/pdf/2406.00045v2,cs.LG
Machine Learning-Driven Optimization of TPMS Architected Materials Using Simulated Annealing,"The research paper presents a novel approach to optimizing the tensile stress
of Triply Periodic Minimal Surface (TPMS) structures through machine learning
and Simulated Annealing (SA). The study evaluates the performance of Random
Forest, Decision Tree, and XGBoost models in predicting tensile stress, using a
dataset generated from finite element analysis of TPMS models. The objective
function minimized the negative R-squared value on the validation set to
enhance model accuracy. The SA-XGBoost model outperformed the others, achieving
an R-squared value of 0.96. In contrast, the SA-Random Forest model achieved an
R squared value of 0.89 while the SA-Decision Tree model exhibited greater
fluctuations in validation scores. This demonstrates that the SA-XGBoost model
is most effective in capturing the complex relationships within the data. The
integration of SA helps in optimizing the hyperparameters of these machine
learning models, thereby enhancing their predictive capabilities.",2024-05-28,Akshansh Mishra,http://arxiv.org/pdf/2406.05142v1,cs.LG
Mollification Effects of Policy Gradient Methods,"Policy gradient methods have enabled deep reinforcement learning (RL) to
approach challenging continuous control problems, even when the underlying
systems involve highly nonlinear dynamics that generate complex non-smooth
optimization landscapes. We develop a rigorous framework for understanding how
policy gradient methods mollify non-smooth optimization landscapes to enable
effective policy search, as well as the downside of it: while making the
objective function smoother and easier to optimize, the stochastic objective
deviates further from the original problem. We demonstrate the equivalence
between policy gradient methods and solving backward heat equations. Following
the ill-posedness of backward heat equations from PDE theory, we present a
fundamental challenge to the use of policy gradient under stochasticity.
Moreover, we make the connection between this limitation and the uncertainty
principle in harmonic analysis to understand the effects of exploration with
stochastic policies in RL. We also provide experimental results to illustrate
both the positive and negative aspects of mollification effects in practice.",2024-05-28,"Tao Wang, Sylvia Herbert, Sicun Gao",http://arxiv.org/pdf/2405.17832v1,cs.LG
LDMol: Text-to-Molecule Diffusion Model with Structurally Informative Latent Space,"With the emergence of diffusion models as the frontline of generative models,
many researchers have proposed molecule generation techniques with conditional
diffusion models. However, the unavoidable discreteness of a molecule makes it
difficult for a diffusion model to connect raw data with highly complex
conditions like natural language. To address this, we present a novel latent
diffusion model dubbed LDMol for text-conditioned molecule generation. LDMol
comprises a molecule autoencoder that produces a learnable and structurally
informative feature space, and a natural language-conditioned latent diffusion
model. In particular, recognizing that multiple SMILES notations can represent
the same molecule, we employ a contrastive learning strategy to extract feature
space that is aware of the unique characteristics of the molecule structure.
LDMol outperforms the existing baselines on the text-to-molecule generation
benchmark, suggesting a potential for diffusion models can outperform
autoregressive models in text data generation with a better choice of the
latent domain. Furthermore, we show that LDMol can be applied to downstream
tasks such as molecule-to-text retrieval and text-guided molecule editing,
demonstrating its versatility as a diffusion model.",2024-05-28,"Jinho Chang, Jong Chul Ye",http://arxiv.org/pdf/2405.17829v2,cs.LG
Spectral Truncation Kernels: Noncommutativity in $C^*$-algebraic Kernel Machines,"$C^*$-algebra-valued kernels could pave the way for the next generation of
kernel machines. To further our fundamental understanding of learning with
$C^*$-algebraic kernels, we propose a new class of positive definite kernels
based on the spectral truncation. We focus on kernels whose inputs and outputs
are vectors or functions and generalize typical kernels by introducing the
noncommutativity of the products appearing in the kernels. The noncommutativity
induces interactions along the data function domain. We show that the proposed
kernels fill the gap between existing separable and commutative kernels. We
also propose a deep learning perspective to obtain a more flexible framework.
The flexibility of the proposed class of kernels allows us to go beyond
previous separable and commutative kernels, addressing two of the foremost
issues regarding learning in vector-valued RKHSs, namely the choice of the
kernel and the computational cost.",2024-05-28,"Yuka Hashimoto, Ayoub Hafid, Masahiro Ikeda, Hachem Kadri",http://arxiv.org/pdf/2405.17823v4,cs.LG
The Impossibility of Fair LLMs,"The need for fair AI is increasingly clear in the era of general-purpose
systems such as ChatGPT, Gemini, and other large language models (LLMs).
However, the increasing complexity of human-AI interaction and its social
impacts have raised questions of how fairness standards could be applied. Here,
we review the technical frameworks that machine learning researchers have used
to evaluate fairness, such as group fairness and fair representations, and find
that their application to LLMs faces inherent limitations. We show that each
framework either does not logically extend to LLMs or presents a notion of
fairness that is intractable for LLMs, primarily due to the multitudes of
populations affected, sensitive attributes, and use cases. To address these
challenges, we develop guidelines for the more realistic goal of achieving
fairness in particular use cases: the criticality of context, the
responsibility of LLM developers, and the need for stakeholder participation in
an iterative process of design and evaluation. Moreover, it may eventually be
possible and even necessary to use the general-purpose capabilities of AI
systems to address fairness challenges as a form of scalable AI-assisted
alignment.",2024-05-28,"Jacy Anthis, Kristian Lum, Michael Ekstrand, Avi Feller, Alexander D'Amour, Chenhao Tan",http://arxiv.org/pdf/2406.03198v1,cs.LG
Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection,"In the open world, detecting out-of-distribution (OOD) data, whose labels are
disjoint with those of in-distribution (ID) samples, is important for reliable
deep neural networks (DNNs). To achieve better detection performance, one type
of approach proposes to fine-tune the model with auxiliary OOD datasets to
amplify the difference between ID and OOD data through a separation loss
defined on model outputs. However, none of these studies consider enlarging the
feature disparity, which should be more effective compared to outputs. The main
difficulty lies in the diversity of OOD samples, which makes it hard to
describe their feature distribution, let alone design losses to separate them
from ID features. In this paper, we neatly fence off the problem based on an
aggregation property of ID features named Neural Collapse (NC). NC means that
the penultimate features of ID samples within a class are nearly identical to
the last layer weight of the corresponding class. Based on this property, we
propose a simple but effective loss called Separation Loss, which binds the
features of OOD data in a subspace orthogonal to the principal subspace of ID
features formed by NC. In this way, the features of ID and OOD samples are
separated by different dimensions. By optimizing the feature separation loss
rather than purely enlarging output differences, our detection achieves SOTA
performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional
data augmentation or sampling, demonstrating the importance of feature
separation in OOD detection. Code is available at
https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.",2024-05-28,"Yingwen Wu, Ruiji Yu, Xinwen Cheng, Zhengbao He, Xiaolin Huang",http://arxiv.org/pdf/2405.17816v2,cs.LG
Judgement Citation Retrieval using Contextual Similarity,"Traditionally in the domain of legal research, the retrieval of pertinent
citations from intricate case descriptions has demanded manual effort and
keyword-based search applications that mandate expertise in understanding legal
jargon. Legal case descriptions hold pivotal information for legal
professionals and researchers, necessitating more efficient and automated
approaches. We propose a methodology that combines natural language processing
(NLP) and machine learning techniques to enhance the organization and
utilization of legal case descriptions. This approach revolves around the
creation of textual embeddings with the help of state-of-art embedding models.
Our methodology addresses two primary objectives: unsupervised clustering and
supervised citation retrieval, both designed to automate the citation
extraction process. Although the proposed methodology can be used for any
dataset, we employed the Supreme Court of The United States (SCOTUS) dataset,
yielding remarkable results. Our methodology achieved an impressive accuracy
rate of 90.9%. By automating labor-intensive processes, we pave the way for a
more efficient, time-saving, and accessible landscape in legal research,
benefiting legal professionals, academics, and researchers.",2024-05-28,"Akshat Mohan Dasula, Hrushitha Tigulla, Preethika Bhukya",http://arxiv.org/pdf/2406.01609v2,cs.LG
Multi-level Interaction Modeling for Protein Mutational Effect Prediction,"Protein-protein interactions are central mediators in many biological
processes. Accurately predicting the effects of mutations on interactions is
crucial for guiding the modulation of these interactions, thereby playing a
significant role in therapeutic development and drug discovery. Mutations
generally affect interactions hierarchically across three levels: mutated
residues exhibit different sidechain conformations, which lead to changes in
the backbone conformation, eventually affecting the binding affinity between
proteins. However, existing methods typically focus only on sidechain-level
interaction modeling, resulting in suboptimal predictions. In this work, we
propose a self-supervised multi-level pre-training framework, ProMIM, to fully
capture all three levels of interactions with well-designed pretraining
objectives. Experiments show ProMIM outperforms all the baselines on the
standard benchmark, especially on mutations where significant changes in
backbone conformations may occur. In addition, leading results from zero-shot
evaluations for SARS-CoV-2 mutational effect prediction and antibody
optimization underscore the potential of ProMIM as a powerful next-generation
tool for developing novel therapeutic approaches and new drugs.",2024-05-28,"Yuanle Mo, Xin Hong, Bowen Gao, Yinjun Jia, Yanyan Lan",http://arxiv.org/pdf/2405.17802v1,cs.LG
Exploring Activation Patterns of Parameters in Language Models,"Most work treats large language models as black boxes without in-depth
understanding of their internal working mechanism. In order to explain the
internal representations of LLMs, we propose a gradient-based metric to assess
the activation level of model parameters. Based on this metric, we obtain three
preliminary findings. (1) When the inputs are in the same domain, parameters in
the shallow layers will be activated densely, which means a larger portion of
parameters will have great impacts on the outputs. In contrast, parameters in
the deep layers are activated sparsely. (2) When the inputs are across
different domains, parameters in shallow layers exhibit higher similarity in
the activation behavior than deep layers. (3) In deep layers, the similarity of
the distributions of activated parameters is positively correlated to the
empirical data relevance. Further, we develop three validation experiments to
solidify these findings. (1) Firstly, starting from the first finding, we
attempt to configure different prune ratios for different layers, and find this
method can benefit model pruning. (2) Secondly, we find that a pruned model
based on one calibration set can better handle tasks related to the calibration
task than those not related, which validate the second finding. (3) Thirdly,
Based on the STS-B and SICK benchmark, we find that two sentences with
consistent semantics tend to share similar parameter activation patterns in
deep layers, which aligns with our third finding. Our work sheds light on the
behavior of parameter activation in LLMs, and we hope these findings will have
the potential to inspire more practical applications.",2024-05-28,"Yudong Wang, Damai Dai, Zhifang Sui",http://arxiv.org/pdf/2405.17799v1,cs.LG
Offline Oracle-Efficient Learning for Contextual MDPs via Layerwise Exploration-Exploitation Tradeoff,"Motivated by the recent discovery of a statistical and computational
reduction from contextual bandits to offline regression (Simchi-Levi and Xu,
2021), we address the general (stochastic) Contextual Markov Decision Process
(CMDP) problem with horizon H (as known as CMDP with H layers). In this paper,
we introduce a reduction from CMDPs to offline density estimation under the
realizability assumption, i.e., a model class M containing the true underlying
CMDP is provided in advance. We develop an efficient, statistically
near-optimal algorithm requiring only O(HlogT) calls to an offline density
estimation algorithm (or oracle) across all T rounds of interaction. This
number can be further reduced to O(HloglogT) if T is known in advance. Our
results mark the first efficient and near-optimal reduction from CMDPs to
offline density estimation without imposing any structural assumptions on the
model class. A notable feature of our algorithm is the design of a layerwise
exploration-exploitation tradeoff tailored to address the layerwise structure
of CMDPs. Additionally, our algorithm is versatile and applicable to pure
exploration tasks in reward-free reinforcement learning.",2024-05-28,"Jian Qian, Haichen Hu, David Simchi-Levi",http://arxiv.org/pdf/2405.17796v1,cs.LG
Use of Boosting Algorithms in Household-Level Poverty Measurement: A Machine Learning Approach to Predict and Classify Household Wealth Quintiles in the Philippines,"This study assessed the effectiveness of machine learning models in
predicting poverty levels in the Philippines using five boosting algorithms:
Adaptive Boosting (AdaBoost), CatBoosting (CatBoost), Gradient Boosting Machine
(GBM), Light Gradient Boosting Machine (LightGBM), and Extreme Gradient
Boosting (XGBoost). CatBoost emerged as the superior model and achieved the
highest scores across accuracy, precision, recall, and F1-score at 91 percent,
while XGBoost and GBM followed closely with 89 percent and 88 percent
respectively. Additionally, the research examined the computational efficiency
of these models to analyze the balance between training time, testing speed,
and model size factors crucial for real-world applications. Despite its longer
training duration, CatBoost demonstrated high testing efficiency. These results
indicate that machine learning can aid in poverty prediction and in the
development of targeted policy interventions. Future studies should focus on
incorporating a wider variety of data to enhance the predictive accuracy and
policy utility of these models.",2024-05-28,Erika Lynet Salvador,http://arxiv.org/pdf/2407.13061v1,cs.LG
Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation,"Model-Free Reinforcement Learning (MFRL), leveraging the policy gradient
theorem, has demonstrated considerable success in continuous control tasks.
However, these approaches are plagued by high gradient variance due to
zeroth-order gradient estimation, resulting in suboptimal policies. Conversely,
First-Order Model-Based Reinforcement Learning (FO-MBRL) methods employing
differentiable simulation provide gradients with reduced variance but are
susceptible to sampling error in scenarios involving stiff dynamics, such as
physical contact. This paper investigates the source of this error and
introduces Adaptive Horizon Actor-Critic (AHAC), an FO-MBRL algorithm that
reduces gradient error by adapting the model-based horizon to avoid stiff
dynamics. Empirical findings reveal that AHAC outperforms MFRL baselines,
attaining 40% more reward across a set of locomotion tasks and efficiently
scaling to high-dimensional control environments with improved wall-clock-time
efficiency.",2024-05-28,"Ignat Georgiev, Krishnan Srinivasan, Jie Xu, Eric Heiden, Animesh Garg",http://arxiv.org/pdf/2405.17784v2,cs.LG
Post-Fair Federated Learning: Achieving Group and Community Fairness in Federated Learning via Post-processing,"Federated Learning (FL) is a distributed machine learning framework in which
a set of local communities collaboratively learn a shared global model while
retaining all training data locally within each community. Two notions of
fairness have recently emerged as important issues for federated learning:
group fairness and community fairness. Group fairness requires that a model's
decisions do not favor any particular group based on a set of legally protected
attributes such as race or gender. Community fairness requires that global
models exhibit similar levels of performance (accuracy) across all
collaborating communities. Both fairness concepts can coexist within an FL
framework, but the existing literature has focused on either one concept or the
other. This paper proposes and analyzes a post-processing fair federated
learning (FFL) framework called post-FFL. Post-FFL uses a linear program to
simultaneously enforce group and community fairness while maximizing the
utility of the global model. Because Post-FFL is a post-processing approach, it
can be used with existing FL training pipelines whose convergence properties
are well understood. This paper uses post-FFL on real-world datasets to mimic
how hospital networks, for example, use federated learning to deliver community
health care. Theoretical results bound the accuracy lost when post-FFL enforces
both notion of fairness. Experimental results illustrate that post-FFL
simultaneously improves both group and community fairness in FL. Moreover,
post-FFL outperforms the existing in-processing fair federated learning in
terms of improving both notions of fairness, communication efficiency and
computation cost.",2024-05-28,"Yuying Duan, Yijun Tian, Nitesh Chawla, Michael Lemmon",http://arxiv.org/pdf/2405.17782v1,cs.LG
Online Analytic Exemplar-Free Continual Learning with Large Models for Imbalanced Autonomous Driving Task,"In autonomous driving, even a meticulously trained model can encounter
failures when facing unfamiliar scenarios. One of these scenarios can be
formulated as an online continual learning (OCL) problem. That is, data come in
an online fashion, and models are updated according to these streaming data.
Two major OCL challenges are catastrophic forgetting and data imbalance. To
address these challenges, in this paper, we propose an Analytic Exemplar-Free
Online Continual Learning algorithm (AEF-OCL). The AEF-OCL leverages analytic
continual learning principles and employs ridge regression as a classifier for
features extracted by a large backbone network. It solves the OCL problem by
recursively calculating the analytical solution, ensuring an equalization
between the continual learning and its joint-learning counterpart, and works
without the need to save any used samples (i.e., exemplar-free). Additionally,
we introduce a Pseudo-Features Generator (PFG) module that recursively
estimates the mean and the variance of real features for each class. It
over-samples offset pseudo-features from the same normal distribution as the
real features, thereby addressing the data imbalance issue. Experimental
results demonstrate that despite being an exemplar-free strategy, our method
outperforms various methods on the autonomous driving SODA10M dataset. Source
code is available at https://github.com/ZHUANGHP/Analytic-continual-learning.",2024-05-28,"Huiping Zhuang, Di Fang, Kai Tong, Yuchen Liu, Ziqian Zeng, Xu Zhou, Cen Chen",http://arxiv.org/pdf/2405.17779v2,cs.LG
The Binary Quantized Neural Network for Dense Prediction via Specially Designed Upsampling and Attention,"Deep learning-based information processing consumes long time and requires
huge computing resources, especially for dense prediction tasks which require
an output for each pixel, like semantic segmentation and salient object
detection. There are mainly two challenges for quantization of dense prediction
tasks. Firstly, directly applying the upsampling operation that dense
prediction tasks require is extremely crude and causes unacceptable accuracy
reduction. Secondly, the complex structure of dense prediction networks means
it is difficult to maintain a fast speed as well as a high accuracy when
performing quantization. In this paper, we propose an effective upsampling
method and an efficient attention computation strategy to transfer the success
of the binary neural networks (BNN) from single prediction tasks to dense
prediction tasks. Firstly, we design a simple and robust multi-branch parallel
upsampling structure to achieve the high accuracy. Then we further optimize the
attention method which plays an important role in segmentation but has huge
computation complexity. Our attention method can reduce the computational
complexity by a factor of one hundred times but retain the original effect.
Experiments on Cityscapes, KITTI road, and ECSSD fully show the effectiveness
of our work.",2024-05-28,"Xingyu Ding, Lianlei Shan, Guiqin Zhao, Meiqi Wu, Wenzhang Zhou, Wei Li",http://arxiv.org/pdf/2405.17776v1,cs.LG
Adaptive Multiscale Retinal Diagnosis: A Hybrid Trio-Model Approach for Comprehensive Fundus Multi-Disease Detection Leveraging Transfer Learning and Siamese Networks,"WHO has declared that more than 2.2 billion people worldwide are suffering
from visual disorders, such as media haze, glaucoma, and drusen. At least 1
billion of these cases could have been either prevented or successfully
treated, yet they remain unaddressed due to poverty, a lack of specialists,
inaccurate ocular fundus diagnoses by ophthalmologists, or the presence of a
rare disease. To address this, the research has developed the Hybrid
Trio-Network Model Algorithm for accurately diagnosing 12 distinct common and
rare eye diseases. This algorithm utilized the RFMiD dataset of 3,200 fundus
images and the Binary Relevance Method to detect diseases separately, ensuring
expandability and avoiding incorrect correlations. Each detector, incorporating
finely tuned hyperparameters to optimize performance, consisted of three
feature components: A classical transfer learning CNN model, a two-stage CNN
model, and a Siamese Network. The diagnosis was made using features extracted
through this Trio-Model with Ensembled Machine Learning algorithms. The
proposed model achieved an average accuracy of 97% and an AUC score of 0.96.
Compared to past benchmark studies, an increase of over 10% in the F1-score was
observed for most diseases. Furthermore, using the Siamese Network, the model
successfully made predictions in diseases like optic disc pallor, which past
studies failed to predict due to low confidence. This diagnostic tool presents
a stable, adaptive, cost-effective, efficient, accessible, and fast solution
for globalizing early detection of both common and rare diseases.",2024-05-28,Yavuz Selim Inan,http://arxiv.org/pdf/2405.18449v1,cs.LG
Revisiting the Message Passing in Heterophilous Graph Neural Networks,"Graph Neural Networks (GNNs) have demonstrated strong performance in graph
mining tasks due to their message-passing mechanism, which is aligned with the
homophily assumption that adjacent nodes exhibit similar behaviors. However, in
many real-world graphs, connected nodes may display contrasting behaviors,
termed as heterophilous patterns, which has attracted increased interest in
heterophilous GNNs (HTGNNs). Although the message-passing mechanism seems
unsuitable for heterophilous graphs due to the propagation of class-irrelevant
information, it is still widely used in many existing HTGNNs and consistently
achieves notable success. This raises the question: why does message passing
remain effective on heterophilous graphs? To answer this question, in this
paper, we revisit the message-passing mechanisms in heterophilous graph neural
networks and reformulate them into a unified heterophilious message-passing
(HTMP) mechanism. Based on HTMP and empirical analysis, we reveal that the
success of message passing in existing HTGNNs is attributed to implicitly
enhancing the compatibility matrix among classes. Moreover, we argue that the
full potential of the compatibility matrix is not completely achieved due to
the existence of incomplete and noisy semantic neighborhoods in real-world
heterophilous graphs. To bridge this gap, we introduce a new approach named
CMGNN, which operates within the HTMP mechanism to explicitly leverage and
improve the compatibility matrix. A thorough evaluation involving 10 benchmark
datasets and comparative analysis against 13 well-established baselines
highlights the superior performance of the HTMP mechanism and CMGNN method.",2024-05-28,"Zhuonan Zheng, Yuanchen Bei, Sheng Zhou, Yao Ma, Ming Gu, HongJia XU, Chengyu Lai, Jiawei Chen, Jiajun Bu",http://arxiv.org/pdf/2405.17768v1,cs.LG
Linguistic Collapse: Neural Collapse in (Large) Language Models,"Neural collapse ($\mathcal{NC}$) is a phenomenon observed in classification
tasks where top-layer representations collapse into their class means, which
become equinorm, equiangular and aligned with the classifiers. These behaviours
-- associated with generalization and robustness -- would manifest under
specific conditions: models are trained towards zero loss, with noise-free
labels belonging to balanced classes, which do not outnumber the model's hidden
dimension. Recent studies have explored $\mathcal{NC}$ in the absence of one or
more of these conditions to extend and capitalize on the associated benefits of
ideal geometries. Language modelling presents a curious frontier, as
\textit{training by token prediction} constitutes a classification task where
none of the conditions exist: the vocabulary is imbalanced and exceeds the
embedding dimension; different tokens might correspond to similar contextual
embeddings; and large language models (LLMs) in particular are typically only
trained for a few epochs. This paper empirically investigates the impact of
scaling the architectures and training of causal language models (CLMs) on
their progression towards $\mathcal{NC}$. We find that $\mathcal{NC}$
properties that develop with scale (and regularization) are linked to
generalization. Moreover, there is evidence of some relationship between
$\mathcal{NC}$ and generalization independent of scale. Our work thereby
underscores the generality of $\mathcal{NC}$ as it extends to the novel and
more challenging setting of language modelling. Downstream, we seek to inspire
further research on the phenomenon to deepen our understanding of LLMs -- and
neural networks at large -- and improve existing architectures based on
$\mathcal{NC}$-related properties. Our code is hosted on GitHub at
https://github.com/rhubarbwu/linguistic-collapse .",2024-05-28,"Robert Wu, Vardan Papyan",http://arxiv.org/pdf/2405.17767v3,cs.LG
"SleepFM: Multi-modal Representation Learning for Sleep Across Brain Activity, ECG and Respiratory Signals","Sleep is a complex physiological process evaluated through various modalities
recording electrical brain, cardiac, and respiratory activities. We curate a
large polysomnography dataset from over 14,000 participants comprising over
100,000 hours of multi-modal sleep recordings. Leveraging this extensive
dataset, we developed SleepFM, the first multi-modal foundation model for sleep
analysis. We show that a novel leave-one-out approach for contrastive learning
significantly improves downstream task performance compared to representations
from standard pairwise contrastive learning. A logistic regression model
trained on SleepFM's learned embeddings outperforms an end-to-end trained
convolutional neural network (CNN) on sleep stage classification (macro AUROC
0.88 vs 0.72 and macro AUPRC 0.72 vs 0.48) and sleep disordered breathing
detection (AUROC 0.85 vs 0.69 and AUPRC 0.77 vs 0.61). Notably, the learned
embeddings achieve 48% top-1 average accuracy in retrieving the corresponding
recording clips of other modalities from 90,000 candidates. This work
demonstrates the value of holistic multi-modal sleep modeling to fully capture
the richness of sleep recordings. SleepFM is open source and available at
https://github.com/rthapa84/sleepfm-codebase.",2024-05-28,"Rahul Thapa, Bryan He, Magnus Ruud Kjaer, Hyatt Moore, Gauri Ganjoo, Emmanuel Mignot, James Zou",http://arxiv.org/pdf/2405.17766v1,cs.LG
Double Variance Reduction: A Smoothing Trick for Composite Optimization Problems without First-Order Gradient,"Variance reduction techniques are designed to decrease the sampling variance,
thereby accelerating convergence rates of first-order (FO) and zeroth-order
(ZO) optimization methods. However, in composite optimization problems, ZO
methods encounter an additional variance called the coordinate-wise variance,
which stems from the random gradient estimation. To reduce this variance, prior
works require estimating all partial derivatives, essentially approximating FO
information. This approach demands O(d) function evaluations (d is the
dimension size), which incurs substantial computational costs and is
prohibitive in high-dimensional scenarios. This paper proposes the Zeroth-order
Proximal Double Variance Reduction (ZPDVR) method, which utilizes the averaging
trick to reduce both sampling and coordinate-wise variances. Compared to prior
methods, ZPDVR relies solely on random gradient estimates, calls the stochastic
zeroth-order oracle (SZO) in expectation $\mathcal{O}(1)$ times per iteration,
and achieves the optimal $\mathcal{O}(d(n + \kappa)\log (\frac{1}{\epsilon}))$
SZO query complexity in the strongly convex and smooth setting, where $\kappa$
represents the condition number and $\epsilon$ is the desired accuracy.
Empirical results validate ZPDVR's linear convergence and demonstrate its
superior performance over other related methods.",2024-05-28,"Hao Di, Haishan Ye, Yueling Zhang, Xiangyu Chang, Guang Dai, Ivor W. Tsang",http://arxiv.org/pdf/2405.17761v1,cs.LG
Motion-Informed Deep Learning for Brain MR Image Reconstruction Framework,"Motion artifacts in Magnetic Resonance Imaging (MRI) are one of the
frequently occurring artifacts due to patient movements during scanning. Motion
is estimated to be present in approximately 30% of clinical MRI scans; however,
motion has not been explicitly modeled within deep learning image
reconstruction models. Deep learning (DL) algorithms have been demonstrated to
be effective for both the image reconstruction task and the motion correction
task, but the two tasks are considered separately. The image reconstruction
task involves removing undersampling artifacts such as noise and aliasing
artifacts, whereas motion correction involves removing artifacts including
blurring, ghosting, and ringing. In this work, we propose a novel method to
simultaneously accelerate imaging and correct motion. This is achieved by
integrating a motion module into the deep learning-based MRI reconstruction
process, enabling real-time detection and correction of motion. We model motion
as a tightly integrated auxiliary layer in the deep learning model during
training, making the deep learning model 'motion-informed'. During inference,
image reconstruction is performed from undersampled raw k-space data using a
trained motion-informed DL model. Experimental results demonstrate that the
proposed motion-informed deep learning image reconstruction network
outperformed the conventional image reconstruction network for motion-degraded
MRI datasets.",2024-05-28,"Zhifeng Chen, Kamlesh Pawar, Kh Tohidul Islam, Himashi Peiris, Gary Egan, Zhaolin Chen",http://arxiv.org/pdf/2405.17756v1,cs.LG
Magnitude-based Neuron Pruning for Backdoor Defens,"Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,
posing concerning threats to their reliable deployment. Recent research reveals
that backdoors can be erased from infected DNNs by pruning a specific group of
neurons, while how to effectively identify and remove these backdoor-associated
neurons remains an open challenge. In this paper, we investigate the
correlation between backdoor behavior and neuron magnitude, and find that
backdoor neurons deviate from the magnitude-saliency correlation of the model.
The deviation inspires us to propose a Magnitude-based Neuron Pruning (MNP)
method to detect and prune backdoor neurons. Specifically, MNP uses three
magnitude-guided objective functions to manipulate the magnitude-saliency
correlation of backdoor neurons, thus achieving the purpose of exposing
backdoor behavior, eliminating backdoor neurons and preserving clean neurons,
respectively. Experiments show our pruning strategy achieves state-of-the-art
backdoor defense performance against a variety of backdoor attacks with a
limited amount of clean data, demonstrating the crucial role of magnitude for
guiding backdoor defenses.",2024-05-28,"Nan Li, Haoyu Jiang, Ping Yi",http://arxiv.org/pdf/2405.17750v1,cs.LG
Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective,"Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,
posing concerning threats to their reliable deployment. Recent research reveals
that backdoors can be erased from infected DNNs by pruning a specific group of
neurons, while how to effectively identify and remove these backdoor-associated
neurons remains an open challenge. Most of the existing defense methods rely on
defined rules and focus on neuron's local properties, ignoring the exploration
and optimization of pruning policies. To address this gap, we propose an
Optimized Neuron Pruning (ONP) method combined with Graph Neural Network (GNN)
and Reinforcement Learning (RL) to repair backdoor models. Specifically, ONP
first models the target DNN as graphs based on neuron connectivity, and then
uses GNN-based RL agents to learn graph embeddings and find a suitable pruning
policy. To the best of our knowledge, this is the first attempt to employ GNN
and RL for optimizing pruning policies in the field of backdoor defense.
Experiments show, with a small amount of clean data, ONP can effectively prune
the backdoor neurons implanted by a set of backdoor attacks at the cost of
negligible performance degradation, achieving a new state-of-the-art
performance for backdoor mitigation.",2024-05-28,"Nan Li, Haiyang Yu, Ping Yi",http://arxiv.org/pdf/2405.17746v1,cs.LG
ORLM: A Customizable Framework in Training Large Models for Automated Optimization Modeling,"Optimization modeling plays a critical role in the application of Operations
Research (OR) tools to address real-world problems, yet they pose challenges
and require extensive expertise from OR experts. With the advent of large
language models (LLMs), new opportunities have emerged to streamline and
automate such task. However, current research predominantly relies on
closed-source LLMs such as GPT-4, along with extensive prompt engineering
techniques. This reliance stems from the scarcity of high-quality training
datasets for optimization modeling, resulting in elevated costs, prolonged
processing times, and privacy concerns. To address these challenges, our work
is the first to propose a viable path for training open-source LLMs that are
capable of optimization modeling and developing solver codes, eventually
leading to a superior ability for automating optimization modeling and solving.
Particularly, we design the {\sc OR-Instruct}, a semi-automated data synthesis
framework for optimization modeling that enables customizable enhancements for
specific scenarios or model types. This work also introduces IndustryOR, the
first industrial benchmark for evaluating LLMs in solving practical OR
problems. We train several 7B-scale open-source LLMs using synthesized data
(dubbed ORLMs{https://github.com/Cardinal-Operations/ORLM}), which exhibit
significantly enhanced optimization modeling capabilities, achieving
competitive performance across the NL4OPT, MAMO, and IndustryOR benchmarks.
Additionally, our experiments highlight the potential of scaling law and
reinforcement learning to further enhance the performance of ORLMs. The
workflows and human-machine interaction paradigms of ORLMs in practical
industrial applications are also discussed in the paper.",2024-05-28,"Chenyu Huang, Zhengyang Tang, Shixi Hu, Ruoqing Jiang, Xin Zheng, Dongdong Ge, Benyou Wang, Zizhuo Wang",http://arxiv.org/pdf/2405.17743v5,cs.LG
Towards Efficient Disaster Response via Cost-effective Unbiased Class Rate Estimation through Neyman Allocation Stratified Sampling Active Learning,"With the rapid development of earth observation technology, we have entered
an era of massively available satellite remote-sensing data. However, a large
amount of satellite remote sensing data lacks a label or the label cost is too
high to hinder the potential of AI technology mining satellite data. Especially
in such an emergency response scenario that uses satellite data to evaluate the
degree of disaster damage. Disaster damage assessment encountered bottlenecks
due to excessive focus on the damage of a certain building in a specific
geographical space or a certain area on a larger scale. In fact, in the early
days of disaster emergency response, government departments were more concerned
about the overall damage rate of the disaster area instead of single-building
damage, because this helps the government decide the level of emergency
response. We present an innovative algorithm that constructs Neyman stratified
random sampling trees for binary classification and extends this approach to
multiclass problems. Through extensive experimentation on various datasets and
model structures, our findings demonstrate that our method surpasses both
passive and conventional active learning techniques in terms of class rate
estimation and model enhancement with only 30\%-60\% of the annotation cost of
simple sampling. It effectively addresses the 'sampling bias' challenge in
traditional active learning strategies and mitigates the 'cold start' dilemma.
The efficacy of our approach is further substantiated through application to
disaster evaluation tasks using Xview2 Satellite imagery, showcasing its
practical utility in real-world contexts.",2024-05-28,"Yanbing Bai, Xinyi Wu, Lai Xu, Jihan Pei, Erick Mas, Shunichi Koshimura",http://arxiv.org/pdf/2405.17734v1,cs.LG
MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance,"Multimodal learning methods with targeted unimodal learning objectives have
exhibited their superior efficacy in alleviating the imbalanced multimodal
learning problem. However, in this paper, we identify the previously ignored
gradient conflict between multimodal and unimodal learning objectives,
potentially misleading the unimodal encoder optimization. To well diminish
these conflicts, we observe the discrepancy between multimodal loss and
unimodal loss, where both gradient magnitude and covariance of the
easier-to-learn multimodal loss are smaller than the unimodal one. With this
property, we analyze Pareto integration under our multimodal scenario and
propose MMPareto algorithm, which could ensure a final gradient with direction
that is common to all learning objectives and enhanced magnitude to improve
generalization, providing innocent unimodal assistance. Finally, experiments
across multiple types of modalities and frameworks with dense cross-modal
interaction indicate our superior and extendable method performance. Our method
is also expected to facilitate multi-task cases with a clear discrepancy in
task difficulty, demonstrating its ideal scalability. The source code and
dataset are available at https://github.com/GeWu-Lab/MMPareto_ICML2024.",2024-05-28,"Yake Wei, Di Hu",http://arxiv.org/pdf/2405.17730v1,cs.LG
Interpretable DRL-based Maneuver Decision of UCAV Dogfight,"This paper proposes a three-layer unmanned combat aerial vehicle (UCAV)
dogfight frame where Deep reinforcement learning (DRL) is responsible for
high-level maneuver decision. A four-channel low-level control law is firstly
constructed, followed by a library containing eight basic flight maneuvers
(BFMs). Double deep Q network (DDQN) is applied for BFM selection in UCAV
dogfight, where the opponent strategy during the training process is
constructed with DT. Our simulation result shows that, the agent can achieve a
win rate of 85.75% against the DT strategy, and positive results when facing
various unseen opponents. Based on the proposed frame, interpretability of the
DRL-based dogfight is significantly improved. The agent performs yo-yo to
adjust its turn rate and gain higher maneuverability. Emergence of ""Dive and
Chase"" behavior also indicates the agent can generate a novel tactic that
utilizes the drawback of its opponent.",2024-05-28,"Haoran Han, Jian Cheng, Maolong Lv",http://arxiv.org/pdf/2407.01571v1,cs.LG
MindFormer: Semantic Alignment of Multi-Subject fMRI for Brain Decoding,"Research efforts for visual decoding from fMRI signals have attracted
considerable attention in research community. Still multi-subject fMRI decoding
with one model has been considered intractable due to the drastic variations in
fMRI signals between subjects and even within the same subject across different
trials. To address current limitations in multi-subject brain decoding, here we
introduce a novel semantic alignment method of multi-subject fMRI signals using
so-called MindFormer. This model is specifically designed to generate
fMRI-conditioned feature vectors that can be used for conditioning Stable
Diffusion model for fMRI- to-image generation or large language model (LLM) for
fMRI-to-text generation. More specifically, MindFormer incorporates two key
innovations: 1) a subject specific token that effectively capture individual
differences in fMRI signals while synergistically combines multi subject fMRI
data for training, and 2) a novel feature embedding and training scheme based
on the IP-Adapter to extract semantically meaningful features from fMRI
signals. Our experimental results demonstrate that MindFormer generates
semantically consistent images and text across different subjects. Since our
MindFormer maintains semantic fidelity by fully utilizing the training data
across different subjects by significantly surpassing existing models in
multi-subject brain decoding, this may help deepening our understanding of
neural processing variations among individuals.",2024-05-28,"Inhwa Han, Jaayeon Lee, Jong Chul Ye",http://arxiv.org/pdf/2405.17720v2,cs.LG
AdapNet: Adaptive Noise-Based Network for Low-Quality Image Retrieval,"Image retrieval aims to identify visually similar images within a database
using a given query image. Traditional methods typically employ both global and
local features extracted from images for matching, and may also apply
re-ranking techniques to enhance accuracy. However, these methods often fail to
account for the noise present in query images, which can stem from natural or
human-induced factors, thereby negatively impacting retrieval performance. To
mitigate this issue, we introduce a novel setting for low-quality image
retrieval, and propose an Adaptive Noise-Based Network (AdapNet) to learn
robust abstract representations. Specifically, we devise a quality compensation
block trained to compensate for various low-quality factors in input images.
Besides, we introduce an innovative adaptive noise-based loss function, which
dynamically adjusts its focus on the gradient in accordance with image quality,
thereby augmenting the learning of unknown noisy samples during training and
enhancing intra-class compactness. To assess the performance, we construct two
datasets with low-quality queries, which is built by applying various types of
noise on clean query images on the standard Revisited Oxford and Revisited
Paris datasets. Comprehensive experimental results illustrate that AdapNet
surpasses state-of-the-art methods on the Noise Revisited Oxford and Noise
Revisited Paris benchmarks, while maintaining competitive performance on
high-quality datasets. The code and constructed datasets will be made
available.",2024-05-28,"Sihe Zhang, Qingdong He, Jinlong Peng, Yuxi Li, Zhengkai Jiang, Jiafu Wu, Mingmin Chi, Yabiao Wang, Chengjie Wang",http://arxiv.org/pdf/2405.17718v1,cs.LG
AI Alignment with Changing and Influenceable Reward Functions,"Existing AI alignment approaches assume that preferences are static, which is
unrealistic: our preferences change, and may even be influenced by our
interactions with AI systems themselves. To clarify the consequences of
incorrectly assuming static preferences, we introduce Dynamic Reward Markov
Decision Processes (DR-MDPs), which explicitly model preference changes and the
AI's influence on them. We show that despite its convenience, the
static-preference assumption may undermine the soundness of existing alignment
techniques, leading them to implicitly reward AI systems for influencing user
preferences in ways users may not truly want. We then explore potential
solutions. First, we offer a unifying perspective on how an agent's
optimization horizon may partially help reduce undesirable AI influence. Then,
we formalize different notions of AI alignment that account for preference
change from the outset. Comparing the strengths and limitations of 8 such
notions of alignment, we find that they all either err towards causing
undesirable AI influence, or are overly risk-averse, suggesting that a
straightforward solution to the problems of changing preferences may not exist.
As there is no avoiding grappling with changing preferences in real-world
settings, this makes it all the more important to handle these issues with
care, balancing risks and capabilities. We hope our work can provide conceptual
clarity and constitute a first step towards AI alignment practices which
explicitly account for (and contend with) the changing and influenceable nature
of human preferences.",2024-05-28,"Micah Carroll, Davis Foote, Anand Siththaranjan, Stuart Russell, Anca Dragan",http://arxiv.org/pdf/2405.17713v1,cs.LG
A Context-Aware Approach for Enhancing Data Imputation with Pre-trained Language Models,"This paper presents a novel approach named \textbf{C}ontextually
\textbf{R}elevant \textbf{I}mputation leveraging pre-trained \textbf{L}anguage
\textbf{M}odels (\textbf{CRILM}) for handling missing data in tabular datasets.
Instead of relying on traditional numerical estimations, CRILM uses pre-trained
language models (LMs) to create contextually relevant descriptors for missing
values. This method aligns datasets with LMs' strengths, allowing large LMs to
generate these descriptors and small LMs to be fine-tuned on the enriched
datasets for enhanced downstream task performance. Our evaluations demonstrate
CRILM's superior performance and robustness across MCAR, MAR, and challenging
MNAR scenarios, with up to a 10\% improvement over the best-performing
baselines. By mitigating biases, particularly in MNAR settings, CRILM improves
downstream task performance and offers a cost-effective solution for
resource-constrained environments.",2024-05-28,"Ahatsham Hayat, Mohammad Rashedul Hasan",http://arxiv.org/pdf/2405.17712v2,cs.LG
Stochastic Adversarial Networks for Multi-Domain Text Classification,"Adversarial training has been instrumental in advancing multi-domain text
classification (MDTC). Traditionally, MDTC methods employ a shared-private
paradigm, with a shared feature extractor for domain-invariant knowledge and
individual private feature extractors for domain-specific knowledge. Despite
achieving state-of-the-art results, these methods grapple with the escalating
model parameters due to the continuous addition of new domains. To address this
challenge, we introduce the Stochastic Adversarial Network (SAN), which
innovatively models the parameters of the domain-specific feature extractor as
a multivariate Gaussian distribution, as opposed to a traditional weight
vector. This design allows for the generation of numerous domain-specific
feature extractors without a substantial increase in model parameters,
maintaining the model's size on par with that of a single domain-specific
extractor. Furthermore, our approach integrates domain label smoothing and
robust pseudo-label regularization to fortify the stability of adversarial
training and to refine feature discriminability, respectively. The performance
of our SAN, evaluated on two leading MDTC benchmarks, demonstrates its
competitive edge against the current state-of-the-art methodologies. The code
is available at https://github.com/wangxu0820/SAN.",2024-05-28,"Xu Wang, Yuan Wu",http://arxiv.org/pdf/2406.00044v1,cs.LG
OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators,"Offline policy evaluation (OPE) allows us to evaluate and estimate a new
sequential decision-making policy's performance by leveraging historical
interaction data collected from other policies. Evaluating a new policy online
without a confident estimate of its performance can lead to costly, unsafe, or
hazardous outcomes, especially in education and healthcare. Several OPE
estimators have been proposed in the last decade, many of which have
hyperparameters and require training. Unfortunately, choosing the best OPE
algorithm for each task and domain is still unclear. In this paper, we propose
a new algorithm that adaptively blends a set of OPE estimators given a dataset
without relying on an explicit selection using a statistical procedure. We
prove that our estimator is consistent and satisfies several desirable
properties for policy evaluation. Additionally, we demonstrate that when
compared to alternative approaches, our estimator can be used to select
higher-performing policies in healthcare and robotics. Our work contributes to
improving ease of use for a general-purpose, estimator-agnostic, off-policy
evaluation framework for offline RL.",2024-05-27,"Allen Nie, Yash Chandak, Christina J. Yuan, Anirudhan Badrinath, Yannis Flet-Berliac, Emma Brunskil",http://arxiv.org/pdf/2405.17708v2,cs.LG
Mechanistic Interpretability of Binary and Ternary Transformers,"Recent research (arXiv:2310.11453, arXiv:2402.17764) has proposed binary and
ternary transformer networks as a way to significantly reduce memory and
improve inference speed in Large Language Models (LLMs) while maintaining
accuracy. In this work, we apply techniques from mechanistic interpretability
to investigate whether such networks learn distinctly different or similar
algorithms when compared to full-precision transformer networks. In particular,
we reverse engineer the algorithms learned for the toy problem of modular
addition where we find that binary and ternary networks learn similar
algorithms as full precision networks. This provides evidence against the
possibility of using binary and ternary networks as a more interpretable
alternative in the LLM setting.",2024-05-27,Jason Li,http://arxiv.org/pdf/2405.17703v1,cs.LG
Learning Social Welfare Functions,"Is it possible to understand or imitate a policy maker's rationale by looking
at past decisions they made? We formalize this question as the problem of
learning social welfare functions belonging to the well-studied family of power
mean functions. We focus on two learning tasks; in the first, the input is
vectors of utilities of an action (decision or policy) for individuals in a
group and their associated social welfare as judged by a policy maker, whereas
in the second, the input is pairwise comparisons between the welfares
associated with a given pair of utility vectors. We show that power mean
functions are learnable with polynomial sample complexity in both cases, even
if the comparisons are social welfare information is noisy. Finally, we design
practical algorithms for these tasks and evaluate their performance.",2024-05-27,"Kanad Shrikar Pardeshi, Itai Shapira, Ariel D. Procaccia, Aarti Singh",http://arxiv.org/pdf/2405.17700v2,cs.LG
"P4: Towards private, personalized, and Peer-to-Peer learning","Personalized learning is a proposed approach to address the problem of data
heterogeneity in collaborative machine learning. In a decentralized setting,
the two main challenges of personalization are client clustering and data
privacy. In this paper, we address these challenges by developing P4
(Personalized Private Peer-to-Peer) a method that ensures that each client
receives a personalized model while maintaining differential privacy guarantee
of each client's local dataset during and after the training. Our approach
includes the design of a lightweight algorithm to identify similar clients and
group them in a private, peer-to-peer (P2P) manner. Once grouped, we develop
differentially-private knowledge distillation for clients to co-train with
minimal impact on accuracy. We evaluate our proposed method on three benchmark
datasets (FEMNIST or Federated EMNIST, CIFAR-10 and CIFAR-100) and two
different neural network architectures (Linear and CNN-based networks) across a
range of privacy parameters. The results demonstrate the potential of P4, as it
outperforms the state-of-the-art of differential private P2P by up to 40
percent in terms of accuracy. We also show the practicality of P4 by
implementing it on resource constrained devices, and validating that it has
minimal overhead, e.g., about 7 seconds to run collaborative training between
two clients.",2024-05-27,"Mohammad Mahdi Maheri, Sandra Siby, Sina Abdollahi, Anastasia Borovykh, Hamed Haddadi",http://arxiv.org/pdf/2405.17697v2,cs.LG
Physics-guided Full Waveform Inversion using Encoder-Solver Convolutional Neural Networks,"Full Waveform Inversion (FWI) is an inverse problem for estimating the wave
velocity distribution in a given domain, based on observed data on the
boundaries. The inversion is computationally demanding because we are required
to solve multiple forward problems, either in time or frequency domains, to
simulate data that are then iteratively fitted to the observed data. We
consider FWI in the frequency domain, where the Helmholtz equation is used as a
forward model, and its repeated solution is the main computational bottleneck
of the inversion process. To ease this cost, we integrate a learning process of
an encoder-solver preconditioner that is based on convolutional neural networks
(CNNs). The encoder-solver is trained to effectively precondition the
discretized Helmholtz operator given velocity medium parameters. Then, by
re-training the CNN between the iterations of the optimization process, the
encoder-solver is adapted to the iteratively evolving velocity medium as part
of the inversion. Without retraining, the performance of the solver
deteriorates as the medium changes. Using our light retraining procedures, we
obtain the forward simulations effectively throughout the process. We
demonstrate our approach to solving FWI problems using 2D geophysical models
with high-frequency data.",2024-05-27,"Matan Goren, Eran Treister",http://arxiv.org/pdf/2405.17696v1,cs.LG
Reinforcement Learning Based Escape Route Generation in Low Visibility Environments,"Structure fires are responsible for the majority of fire-related deaths
nationwide. In order to assist with the rapid evacuation of trapped people,
this paper proposes the use of a system that determines optimal search paths
for firefighters and exit paths for civilians in real time based on
environmental measurements. Through the use of a LiDAR mapping system evaluated
and verified by a trust range derived from sonar and smoke concentration data,
a proposed solution to low visibility mapping is tested. These independent
point clouds are then used to create distinct maps, which are merged through
the use of a RANSAC based alignment methodology and simplified into a
visibility graph. Temperature and humidity data are then used to label each
node with a danger score, creating an environment tensor. After demonstrating
how a Linear Function Approximation based Natural Policy Gradient RL
methodology outperforms more complex competitors with respect to robustness and
speed, this paper outlines two systems (savior and refugee) that process the
environment tensor to create safe rescue and escape routes, respectively.",2024-05-27,Hari Srikanth,http://arxiv.org/pdf/2406.07568v1,cs.LG
Tamed Langevin sampling under weaker conditions,"Motivated by applications to deep learning which often fail standard
Lipschitz smoothness requirements, we examine the problem of sampling from
distributions that are not log-concave and are only weakly dissipative, with
log-gradients allowed to grow superlinearly at infinity. In terms of structure,
we only assume that the target distribution satisfies either a log-Sobolev or a
Poincar\'e inequality and a local Lipschitz smoothness assumption with modulus
growing possibly polynomially at infinity. This set of assumptions greatly
exceeds the operational limits of the ""vanilla"" unadjusted Langevin algorithm
(ULA), making sampling from such distributions a highly involved affair. To
account for this, we introduce a taming scheme which is tailored to the growth
and decay properties of the target distribution, and we provide explicit
non-asymptotic guarantees for the proposed sampler in terms of the
Kullback-Leibler (KL) divergence, total variation, and Wasserstein distance to
the target distribution.",2024-05-27,"Iosif Lytras, Panayotis Mertikopoulos",http://arxiv.org/pdf/2405.17693v1,cs.LG
Ontology-Enhanced Decision-Making for Autonomous Agents in Dynamic and Partially Observable Environments,"Agents, whether software or hardware, perceive their environment through
sensors and act using actuators, often operating in dynamic, partially
observable settings. They face challenges like incomplete and noisy data,
unforeseen situations, and the need to adapt goals in real-time. Traditional
reasoning and ML methods, including Reinforcement Learning (RL), help but are
limited by data needs, predefined goals, and extensive exploration periods.
Ontologies offer a solution by integrating diverse information sources,
enhancing decision-making in complex environments. This thesis introduces an
ontology-enhanced decision-making model (OntoDeM) for autonomous agents.
OntoDeM enriches agents' domain knowledge, allowing them to interpret
unforeseen events, generate or adapt goals, and make better decisions. Key
contributions include: 1. An ontology-based method to improve agents' real-time
observations using prior knowledge. 2. The OntoDeM model for handling dynamic,
unforeseen situations by evolving or generating new goals. 3. Implementation
and evaluation in four real-world applications, demonstrating its
effectiveness. Compared to traditional and advanced learning algorithms,
OntoDeM shows superior performance in improving agents' observations and
decision-making in dynamic, partially observable environments.",2024-05-27,"Saeedeh Ghanadbashi, Fatemeh Golpayegani",http://arxiv.org/pdf/2405.17691v1,cs.LG
Linear Function Approximation as a Computationally Efficient Method to Solve Classical Reinforcement Learning Challenges,"Neural Network based approximations of the Value function make up the core of
leading Policy Based methods such as Trust Regional Policy Optimization (TRPO)
and Proximal Policy Optimization (PPO). While this adds significant value when
dealing with very complex environments, we note that in sufficiently low State
and action space environments, a computationally expensive Neural Network
architecture offers marginal improvement over simpler Value approximation
methods. We present an implementation of Natural Actor Critic algorithms with
actor updates through Natural Policy Gradient methods. This paper proposes that
Natural Policy Gradient (NPG) methods with Linear Function Approximation as a
paradigm for value approximation may surpass the performance and speed of
Neural Network based models such as TRPO and PPO within these environments.
Over Reinforcement Learning benchmarks Cart Pole and Acrobot, we observe that
our algorithm trains much faster than complex neural network architectures, and
obtains an equivalent or greater result. This allows us to recommend the use of
NPG methods with Linear Function Approximation over TRPO and PPO for both
traditional and sparse reward low dimensional problems.",2024-05-27,Hari Srikanth,http://arxiv.org/pdf/2405.20350v1,cs.LG
Fast Samplers for Inverse Problems in Iterative Refinement Models,"Constructing fast samplers for unconditional diffusion and flow-matching
models has received much attention recently; however, existing methods for
solving inverse problems, such as super-resolution, inpainting, or deblurring,
still require hundreds to thousands of iterative steps to obtain high-quality
results. We propose a plug-and-play framework for constructing efficient
samplers for inverse problems, requiring only pre-trained diffusion or
flow-matching models. We present Conditional Conjugate Integrators, which
leverage the specific form of the inverse problem to project the respective
conditional diffusion/flow dynamics into a more amenable space for sampling.
Our method complements popular posterior approximation methods for solving
inverse problems using diffusion/flow models. We evaluate the proposed method's
performance on various linear image restoration tasks across multiple datasets,
employing diffusion and flow-matching models. Notably, on challenging inverse
problems like 4x super-resolution on the ImageNet dataset, our method can
generate high-quality samples in as few as 5 conditional sampling steps and
outperforms competing baselines requiring 20-1000 steps. Our code will be
publicly available at https://github.com/mandt-lab/c-pigdm",2024-05-27,"Kushagra Pandey, Ruihan Yang, Stephan Mandt",http://arxiv.org/pdf/2405.17673v2,cs.LG
Exploring Loss Design Techniques For Decision Tree Robustness To Label Noise,"In the real world, data is often noisy, affecting not only the quality of
features but also the accuracy of labels. Current research on mitigating label
errors stems primarily from advances in deep learning, and a gap exists in
exploring interpretable models, particularly those rooted in decision trees. In
this study, we investigate whether ideas from deep learning loss design can be
applied to improve the robustness of decision trees. In particular, we show
that loss correction and symmetric losses, both standard approaches, are not
effective. We argue that other directions need to be explored to improve the
robustness of decision trees to label noise.",2024-05-27,"Lukasz Sztukiewicz, Jack Henry Good, Artur Dubrawski",http://arxiv.org/pdf/2405.17672v1,cs.LG
Hunting for Polluted White Dwarfs and Other Treasures with Gaia XP Spectra and Unsupervised Machine Learning,"White dwarfs (WDs) polluted by exoplanetary material provide the
unprecedented opportunity to directly observe the interiors of exoplanets.
However, spectroscopic surveys are often limited by brightness constraints, and
WDs tend to be very faint, making detections of large populations of polluted
WDs difficult. In this paper, we aim to increase considerably the number of WDs
with multiple metals in their atmospheres. Using 96,134 WDs with Gaia DR3 BP/RP
(XP) spectra, we constructed a 2D map using an unsupervised machine learning
technique called Uniform Manifold Approximation and Projection (UMAP) to
organize the WDs into identifiable spectral regions. The polluted WDs are among
the distinct spectral groups identified in our map. We have shown that this
selection method could potentially increase the number of known WDs with 5 or
more metal species in their atmospheres by an order of magnitude. Such systems
are essential for characterizing exoplanet diversity and geology.",2024-05-27,"Malia L. Kao, Keith Hawkins, Laura K. Rogers, Amy Bonsor, Bart H. Dunlap, Jason L. Sanders, M. H. Montgomery, D. E. Winget",http://arxiv.org/pdf/2405.17667v2,cs.LG
Structured Partial Stochasticity in Bayesian Neural Networks,"Bayesian neural network posterior distributions have a great number of modes
that correspond to the same network function. The abundance of such modes can
make it difficult for approximate inference methods to do their job. Recent
work has demonstrated the benefits of partial stochasticity for approximate
inference in Bayesian neural networks; inference can be less costly and
performance can sometimes be improved. I propose a structured way to select the
deterministic subset of weights that removes neuron permutation symmetries, and
therefore the corresponding redundant posterior modes. With a drastically
simplified posterior distribution, the performance of existing approximate
inference schemes is found to be greatly improved.",2024-05-27,Tommy Rochussen,http://arxiv.org/pdf/2405.17666v2,cs.LG
Finding Shared Decodable Concepts and their Negations in the Brain,"Prior work has offered evidence for functional localization in the brain;
different anatomical regions preferentially activate for certain types of
visual input. For example, the fusiform face area preferentially activates for
visual stimuli that include a face. However, the spectrum of visual semantics
is extensive, and only a few semantically-tuned patches of cortex have so far
been identified in the human brain. Using a multimodal (natural language and
image) neural network architecture (CLIP) we train a highly accurate
contrastive model that maps brain responses during naturalistic image viewing
to CLIP embeddings. We then use a novel adaptation of the DBSCAN clustering
algorithm to cluster the parameters of these participant-specific contrastive
models. This reveals what we call Shared Decodable Concepts (SDCs): clusters in
CLIP space that are decodable from common sets of voxels across multiple
participants.
  Examining the images most and least associated with each SDC cluster gives us
additional insight into the semantic properties of each SDC. We note SDCs for
previously reported visual features (e.g. orientation tuning in early visual
cortex) as well as visual semantic concepts such as faces, places and bodies.
In cases where our method finds multiple clusters for a visuo-semantic concept,
the least associated images allow us to dissociate between confounding factors.
For example, we discovered two clusters of food images, one driven by color,
the other by shape. We also uncover previously unreported areas such as regions
of extrastriate body area (EBA) tuned for legs/hands and sensitivity to
numerosity in right intraparietal sulcus, and more. Thus, our
contrastive-learning methodology better characterizes new and existing
visuo-semantic representations in the brain by leveraging multimodal neural
network representations and a novel adaptation of clustering algorithms.",2024-05-27,"Cory Efird, Alex Murphy, Joel Zylberberg, Alona Fyshe",http://arxiv.org/pdf/2405.17663v2,cs.LG
Alignment is Key for Applying Diffusion Models to Retrosynthesis,"Retrosynthesis, the task of identifying precursors for a given molecule, can
be naturally framed as a conditional graph generation task. Diffusion models
are a particularly promising modelling approach, enabling post-hoc conditioning
and trading off quality for speed during generation. We show mathematically
that permutation equivariant denoisers severely limit the expressiveness of
graph diffusion models and thus their adaptation to retrosynthesis. To address
this limitation, we relax the equivariance requirement such that it only
applies to aligned permutations of the conditioning and the generated graphs
obtained through atom mapping. Our new denoiser achieves the highest top-$1$
accuracy ($54.7$\%) across template-free and template-based methods on
USPTO-50k. We also demonstrate the ability for flexible post-training
conditioning and good sample quality with small diffusion step counts,
highlighting the potential for interactive applications and additional controls
for multi-step planning.",2024-05-27,"Najwa Laabid, Severi Rissanen, Markus Heinonen, Arno Solin, Vikas Garg",http://arxiv.org/pdf/2405.17656v1,cs.LG
InversionView: A General-Purpose Method for Reading Information from Neural Activations,"The inner workings of neural networks can be better understood if we can
fully decipher the information encoded in neural activations. In this paper, we
argue that this information is embodied by the subset of inputs that give rise
to similar activations. We propose InversionView, which allows us to
practically inspect this subset by sampling from a trained decoder model
conditioned on activations. This helps uncover the information content of
activation vectors, and facilitates understanding of the algorithms implemented
by transformer models. We present four case studies where we investigate models
ranging from small transformers to GPT-2. In these studies, we show that
InversionView can reveal clear information contained in activations, including
basic information about tokens appearing in the context, as well as more
complex information, such as the count of certain tokens, their relative
positions, and abstract knowledge about the subject. We also provide causally
verified circuits to confirm the decoded information.",2024-05-27,"Xinting Huang, Madhur Panwar, Navin Goyal, Michael Hahn",http://arxiv.org/pdf/2405.17653v4,cs.LG
"Unifying Perspectives: Plausible Counterfactual Explanations on Global, Group-wise, and Local Levels","Growing regulatory and societal pressures demand increased transparency in
AI, particularly in understanding the decisions made by complex machine
learning models. Counterfactual Explanations (CFs) have emerged as a promising
technique within Explainable AI (xAI), offering insights into individual model
predictions. However, to understand the systemic biases and disparate impacts
of AI models, it is crucial to move beyond local CFs and embrace global
explanations, which offer a~holistic view across diverse scenarios and
populations. Unfortunately, generating Global Counterfactual Explanations
(GCEs) faces challenges in computational complexity, defining the scope of
""global,"" and ensuring the explanations are both globally representative and
locally plausible. We introduce a novel unified approach for generating Local,
Group-wise, and Global Counterfactual Explanations for differentiable
classification models via gradient-based optimization to address these
challenges. This framework aims to bridge the gap between individual and
systemic insights, enabling a deeper understanding of model decisions and their
potential impact on diverse populations. Our approach further innovates by
incorporating a probabilistic plausibility criterion, enhancing actionability
and trustworthiness. By offering a cohesive solution to the optimization and
plausibility challenges in GCEs, our work significantly advances the
interpretability and accountability of AI models, marking a step forward in the
pursuit of transparent AI.",2024-05-27,"Patryk Wielopolski, Oleksii Furman, Jerzy Stefanowski, Maciej Zięba",http://arxiv.org/pdf/2405.17642v1,cs.LG
Avoiding Pitfalls for Privacy Accounting of Subsampled Mechanisms under Composition,"We consider the problem of computing tight privacy guarantees for the
composition of subsampled differentially private mechanisms. Recent algorithms
can numerically compute the privacy parameters to arbitrary precision but must
be carefully applied.
  Our main contribution is to address two common points of confusion. First,
some privacy accountants assume that the privacy guarantees for the composition
of a subsampled mechanism are determined by self-composing the worst-case
datasets for the uncomposed mechanism. We show that this is not true in
general. Second, Poisson subsampling is sometimes assumed to have similar
privacy guarantees compared to sampling without replacement. We show that the
privacy guarantees may in fact differ significantly between the two sampling
schemes. In particular, we give an example of hyperparameters that result in
$\varepsilon \approx 1$ for Poisson subsampling and $\varepsilon > 10$ for
sampling without replacement. This occurs for some parameters that could
realistically be chosen for DP-SGD.",2024-05-27,"Christian Janos Lebeda, Matthew Regehr, Gautam Kamath, Thomas Steinke",http://arxiv.org/pdf/2405.20769v2,cs.LG
Cross-Modal Safety Alignment: Is textual unlearning all you need?,"Recent studies reveal that integrating new modalities into Large Language
Models (LLMs), such as Vision-Language Models (VLMs), creates a new attack
surface that bypasses existing safety training techniques like Supervised
Fine-tuning (SFT) and Reinforcement Learning with Human Feedback (RLHF). While
further SFT and RLHF-based safety training can be conducted in multi-modal
settings, collecting multi-modal training datasets poses a significant
challenge. Inspired by the structural design of recent multi-modal models,
where, regardless of the combination of input modalities, all inputs are
ultimately fused into the language space, we aim to explore whether unlearning
solely in the textual domain can be effective for cross-modality safety
alignment. Our evaluation across six datasets empirically demonstrates the
transferability -- textual unlearning in VLMs significantly reduces the Attack
Success Rate (ASR) to less than 8\% and in some cases, even as low as nearly
2\% for both text-based and vision-text-based attacks, alongside preserving the
utility. Moreover, our experiments show that unlearning with a multi-modal
dataset offers no potential benefits but incurs significantly increased
computational demands, possibly up to 6 times higher.",2024-05-27,"Trishna Chakraborty, Erfan Shayegani, Zikui Cai, Nael Abu-Ghazaleh, M. Salman Asif, Yue Dong, Amit K. Roy-Chowdhury, Chengyu Song",http://arxiv.org/pdf/2406.02575v1,cs.LG
Probabilistically Plausible Counterfactual Explanations with Normalizing Flows,"We present PPCEF, a novel method for generating probabilistically plausible
counterfactual explanations (CFs). PPCEF advances beyond existing methods by
combining a probabilistic formulation that leverages the data distribution with
the optimization of plausibility within a unified framework. Compared to
reference approaches, our method enforces plausibility by directly optimizing
the explicit density function without assuming a particular family of
parametrized distributions. This ensures CFs are not only valid (i.e., achieve
class change) but also align with the underlying data's probability density.
For that purpose, our approach leverages normalizing flows as powerful density
estimators to capture the complex high-dimensional data distribution.
Furthermore, we introduce a novel loss that balances the trade-off between
achieving class change and maintaining closeness to the original instance while
also incorporating a probabilistic plausibility term. PPCEF's unconstrained
formulation allows for efficient gradient-based optimization with batch
processing, leading to orders of magnitude faster computation compared to prior
methods. Moreover, the unconstrained formulation of PPCEF allows for the
seamless integration of future constraints tailored to specific counterfactual
properties. Finally, extensive evaluations demonstrate PPCEF's superiority in
generating high-quality, probabilistically plausible counterfactual
explanations in high-dimensional tabular settings. This makes PPCEF a powerful
tool for not only interpreting complex machine learning models but also for
improving fairness, accountability, and trust in AI systems.",2024-05-27,"Patryk Wielopolski, Oleksii Furman, Jerzy Stefanowski, Maciej Zięba",http://arxiv.org/pdf/2405.17640v2,cs.LG
The surprising efficiency of temporal difference learning for rare event prediction,"We quantify the efficiency of temporal difference (TD) learning over the
direct, or Monte Carlo (MC), estimator for policy evaluation in reinforcement
learning, with an emphasis on estimation of quantities related to rare events.
Policy evaluation is complicated in the rare event setting by the long
timescale of the event and by the need for \emph{relative accuracy} in
estimates of very small values. Specifically, we focus on least-squares TD
(LSTD) prediction for finite state Markov chains, and show that LSTD can
achieve relative accuracy far more efficiently than MC. We prove a central
limit theorem for the LSTD estimator and upper bound the \emph{relative
asymptotic variance} by simple quantities characterizing the connectivity of
states relative to the transition probabilities between them. Using this bound,
we show that, even when both the timescale of the rare event and the relative
accuracy of the MC estimator are exponentially large in the number of states,
LSTD maintains a fixed level of relative accuracy with a total number of
observed transitions of the Markov chain that is only \emph{polynomially} large
in the number of states.",2024-05-27,"Xiaoou Cheng, Jonathan Weare",http://arxiv.org/pdf/2405.17638v3,cs.LG
Tensor Low-rank Approximation of Finite-horizon Value Functions,"The goal of reinforcement learning is estimating a policy that maps states to
actions and maximizes the cumulative reward of a Markov Decision Process (MDP).
This is oftentimes achieved by estimating first the optimal (reward) value
function (VF) associated with each state-action pair. When the MDP has an
infinite horizon, the optimal VFs and policies are stationary under mild
conditions. However, in finite-horizon MDPs, the VFs (hence, the policies) vary
with time. This poses a challenge since the number of VFs to estimate grows not
only with the size of the state-action space but also with the time horizon.
This paper proposes a non-parametric low-rank stochastic algorithm to
approximate the VFs of finite-horizon MDPs. First, we represent the (unknown)
VFs as a multi-dimensional array, or tensor, where time is one of the
dimensions. Then, we use rewards sampled from the MDP to estimate the optimal
VFs. More precisely, we use the (truncated) PARAFAC decomposition to design an
online low-rank algorithm that recovers the entries of the tensor of VFs. The
size of the low-rank PARAFAC model grows additively with respect to each of its
dimensions, rendering our approach efficient, as demonstrated via numerical
experiments.",2024-05-27,"Sergio Rozada, Antonio G. Marques",http://arxiv.org/pdf/2405.17628v1,cs.LG
Salutary Labeling with Zero Human Annotation,"Active learning strategically selects informative unlabeled data points and
queries their ground truth labels for model training. The prevailing assumption
underlying this machine learning paradigm is that acquiring these ground truth
labels will optimally enhance model performance. However, this assumption may
not always hold true or maximize learning capacity, particularly considering
the costly labor annotations required for ground truth labels. In contrast to
traditional ground truth labeling, this paper proposes salutary labeling, which
automatically assigns the most beneficial labels to the most informative
samples without human annotation. Specifically, we utilize the influence
function, a tool for estimating sample influence, to select newly added samples
and assign their salutary labels by choosing the category that maximizes their
positive influence. This process eliminates the need for human annotation.
Extensive experiments conducted on nine benchmark datasets demonstrate the
superior performance of our salutary labeling approach over traditional active
learning strategies. Additionally, we provide several in-depth explorations and
practical applications of large language model (LLM) fine-tuning.",2024-05-27,"Wenxiao Xiao, Hongfu Liu",http://arxiv.org/pdf/2405.17627v2,cs.LG
Matrix Low-Rank Approximation For Policy Gradient Methods,"Estimating a policy that maps states to actions is a central problem in
reinforcement learning. Traditionally, policies are inferred from the so called
value functions (VFs), but exact VF computation suffers from the curse of
dimensionality. Policy gradient (PG) methods bypass this by learning directly a
parametric stochastic policy. Typically, the parameters of the policy are
estimated using neural networks (NNs) tuned via stochastic gradient descent.
However, finding adequate NN architectures can be challenging, and convergence
issues are common as well. In this paper, we put forth low-rank matrix-based
models to estimate efficiently the parameters of PG algorithms. We collect the
parameters of the stochastic policy into a matrix, and then, we leverage
matrix-completion techniques to promote (enforce) low rank. We demonstrate via
numerical studies how low-rank matrix-based policy models reduce the
computational and sample complexities relative to NN models, while achieving a
similar aggregated reward.",2024-05-27,"Sergio Rozada, Antonio G. Marques",http://arxiv.org/pdf/2405.17626v1,cs.LG
Matrix Low-Rank Trust Region Policy Optimization,"Most methods in reinforcement learning use a Policy Gradient (PG) approach to
learn a parametric stochastic policy that maps states to actions. The standard
approach is to implement such a mapping via a neural network (NN) whose
parameters are optimized using stochastic gradient descent. However, PG methods
are prone to large policy updates that can render learning inefficient. Trust
region algorithms, like Trust Region Policy Optimization (TRPO), constrain the
policy update step, ensuring monotonic improvements. This paper introduces
low-rank matrix-based models as an efficient alternative for estimating the
parameters of TRPO algorithms. By gathering the stochastic policy's parameters
into a matrix and applying matrix-completion techniques, we promote and enforce
low rank. Our numerical studies demonstrate that low-rank matrix-based policy
models effectively reduce both computational and sample complexities compared
to NN models, while maintaining comparable aggregated rewards.",2024-05-27,"Sergio Rozada, Antonio G. Marques",http://arxiv.org/pdf/2405.17625v1,cs.LG
A Multi-resolution Low-rank Tensor Decomposition,"The (efficient and parsimonious) decomposition of higher-order tensors is a
fundamental problem with numerous applications in a variety of fields. Several
methods have been proposed in the literature to that end, with the Tucker and
PARAFAC decompositions being the most prominent ones. Inspired by the latter,
in this work we propose a multi-resolution low-rank tensor decomposition to
describe (approximate) a tensor in a hierarchical fashion. The central idea of
the decomposition is to recast the tensor into \emph{multiple}
lower-dimensional tensors to exploit the structure at different levels of
resolution. The method is first explained, an alternating least squares
algorithm is discussed, and preliminary simulations illustrating the potential
practical relevance are provided.",2024-05-27,"Sergio Rozada, Antonio G. Marques",http://arxiv.org/pdf/2406.18560v1,cs.LG
Symmetric Reinforcement Learning Loss for Robust Learning on Diverse Tasks and Model Scales,"Reinforcement learning (RL) training is inherently unstable due to factors
such as moving targets and high gradient variance. Reinforcement Learning from
Human Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) can
introduce additional difficulty. Differing preferences can complicate the
alignment process, and prediction errors in a trained reward model can become
more severe as the LLM generates unseen outputs. To enhance training
robustness, RL has adopted techniques from supervised learning, such as
ensembles and layer normalization. In this work, we improve the stability of RL
training by adapting the reverse cross entropy (RCE) from supervised learning
for noisy data to define a symmetric RL loss. We demonstrate performance
improvements across various tasks and scales. We conduct experiments in
discrete action tasks (Atari games) and continuous action space tasks (MuJoCo
benchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with
and without added noise with especially notable performance in SPPO across
different hyperparameters. Furthermore, we validate the benefits of the
symmetric RL loss when using SPPO for large language models through improved
performance in RLHF tasks, such as IMDB positive sentiment sentiment and TL;DR
summarization tasks.",2024-05-27,"Ju-Seung Byun, Andrew Perrault",http://arxiv.org/pdf/2405.17618v2,cs.LG
Listenable Maps for Zero-Shot Audio Classifiers,"Interpreting the decisions of deep learning models, including audio
classifiers, is crucial for ensuring the transparency and trustworthiness of
this technology. In this paper, we introduce LMAC-ZS (Listenable Maps for Audio
Classifiers in the Zero-Shot context), which, to the best of our knowledge, is
the first decoder-based post-hoc interpretation method for explaining the
decisions of zero-shot audio classifiers. The proposed method utilizes a novel
loss function that maximizes the faithfulness to the original similarity
between a given text-and-audio pair. We provide an extensive evaluation using
the Contrastive Language-Audio Pretraining (CLAP) model to showcase that our
interpreter remains faithful to the decisions in a zero-shot classification
context. Moreover, we qualitatively show that our method produces meaningful
explanations that correlate well with different text prompts.",2024-05-27,"Francesco Paissan, Luca Della Libera, Mirco Ravanelli, Cem Subakan",http://arxiv.org/pdf/2405.17615v2,cs.LG
Jointly Modeling Inter- & Intra-Modality Dependencies for Multi-modal Learning,"Supervised multi-modal learning involves mapping multiple modalities to a
target label. Previous studies in this field have concentrated on capturing in
isolation either the inter-modality dependencies (the relationships between
different modalities and the label) or the intra-modality dependencies (the
relationships within a single modality and the label). We argue that these
conventional approaches that rely solely on either inter- or intra-modality
dependencies may not be optimal in general. We view the multi-modal learning
problem from the lens of generative models where we consider the target as a
source of multiple modalities and the interaction between them. Towards that
end, we propose inter- & intra-modality modeling (I2M2) framework, which
captures and integrates both the inter- and intra-modality dependencies,
leading to more accurate predictions. We evaluate our approach using real-world
healthcare and vision-and-language datasets with state-of-the-art models,
demonstrating superior performance over traditional methods focusing only on
one type of modality dependency.",2024-05-27,"Divyam Madaan, Taro Makino, Sumit Chopra, Kyunghyun Cho",http://arxiv.org/pdf/2405.17613v2,cs.LG
A note on the error analysis of data-driven closure models for large eddy simulations of turbulence,"In this work, we provide a mathematical formulation for error propagation in
flow trajectory prediction using data-driven turbulence closure modeling. Under
the assumption that the predicted state of a large eddy simulation prediction
must be close to that of a subsampled direct numerical simulation, we retrieve
an upper bound for the prediction error when utilizing a data-driven closure
model. We also demonstrate that this error is significantly affected by the
time step size and the Jacobian which play a role in amplifying the initial
one-step error made by using the closure. Our analysis also shows that the
error propagates exponentially with rollout time and the upper bound of the
system Jacobian which is itself influenced by the Jacobian of the closure
formulation. These findings could enable the development of new regularization
techniques for ML models based on the identified error-bound terms, improving
their robustness and reducing error propagation.",2024-05-27,"Dibyajyoti Chakraborty, Shivam Barwey, Hong Zhang, Romit Maulik",http://arxiv.org/pdf/2405.17612v2,cs.LG
Explainable machine learning multi-label classification of Spanish legal judgements,"Artificial Intelligence techniques such as Machine Learning (ML) have not
been exploited to their maximum potential in the legal domain. This has been
partially due to the insufficient explanations they provided about their
decisions. Automatic expert systems with explanatory capabilities can be
specially useful when legal practitioners search jurisprudence to gather
contextual knowledge for their cases. Therefore, we propose a hybrid system
that applies ML for multi-label classification of judgements (sentences) and
visual and natural language descriptions for explanation purposes, boosted by
Natural Language Processing techniques and deep legal reasoning to identify the
entities, such as the parties, involved. We are not aware of any prior work on
automatic multi-label classification of legal judgements also providing natural
language explanations to the end-users with comparable overall quality. Our
solution achieves over 85 % micro precision on a labelled data set annotated by
legal experts. This endorses its interest to relieve human experts from
monotonous labour-intensive legal classification tasks.",2024-05-27,"Francisco de Arriba-Pérez, Silvia García-Méndez, Francisco J. González-Castaño, Jaime González-González",http://arxiv.org/pdf/2405.17610v1,cs.LG
Advancing Cultural Inclusivity: Optimizing Embedding Spaces for Balanced Music Recommendations,"Popularity bias in music recommendation systems -- where artists and tracks
with the highest listen counts are recommended more often -- can also propagate
biases along demographic and cultural axes. In this work, we identify these
biases in recommendations for artists from underrepresented cultural groups in
prototype-based matrix factorization methods. Unlike traditional matrix
factorization methods, prototype-based approaches are interpretable. This
allows us to directly link the observed bias in recommendations for minority
artists (the effect) to specific properties of the embedding space (the cause).
We mitigate popularity bias in music recommendation through capturing both
users' and songs' cultural nuances in the embedding space. To address these
challenges while maintaining recommendation quality, we propose two novel
enhancements to the embedding space: i) we propose an approach to filter-out
the irrelevant prototypes used to represent each user and item to improve
generalizability, and ii) we introduce regularization techniques to reinforce a
more uniform distribution of prototypes within the embedding space. Our results
demonstrate significant improvements in reducing popularity bias and enhancing
demographic and cultural fairness in music recommendations while achieving
competitive -- if not better -- overall performance.",2024-05-27,"Armin Moradi, Nicola Neophytou, Golnoosh Farnadi",http://arxiv.org/pdf/2405.17607v1,cs.LG
LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters,"The rapid expansion of large language models (LLMs) has underscored the need
for parameter-efficient fine-tuning methods, with LoRA (Low-Rank Adaptation)
emerging as a popular solution. Although LoRA reduces the number of trainable
parameters, serving multiple (task or user-specific) LoRA modules on top of a
base model still creates significant storage challenges. To address this, using
theoretical derivation, we introduce LoRA-XS (Low-Rank Adaptation with
eXtremely Small number of parameters), a novel low-rank adaptation method that
considerably reduces the trainable parameters while showing superior or
competitive performance. LoRA-XS achieves this by inserting a small, trainable
r x r weight matrix between frozen low-rank matrices, which are constructed by
Singular Value Decomposition (SVD) of the original weight matrix. This
lightweight matrix enables fine-tuning with drastically reduced storage
requirements, making it feasible to deploy millions of personalized models
while minimizing memory overhead. For instance, LoRA-XS achieves a remarkable
reduction of trainable parameters by over 100x in 7B models compared to LoRA.
Our evaluations across various benchmarks (including GLUE, GSM8K, MATH, and
eight commonsense reasoning datasets) demonstrate that LoRA-XS performs
competitively or better than LoRA and other recent methods like VeRA while
being significantly more parameter efficient. We also provide an extensive
ablation study on the importance of singular vectors in transformer weights,
shedding light on the underlying mechanisms driving LoRA-XS's enhanced
efficiency. These findings suggest that LoRA-XS is not only a storage-efficient
alternative, but also a powerful tool for scaling and personalizing LLMs at
unprecedented scales.",2024-05-27,"Klaudia Bałazy, Mohammadreza Banaei, Karl Aberer, Jacek Tabor",http://arxiv.org/pdf/2405.17604v2,cs.LG
RAGSys: Item-Cold-Start Recommender as RAG System,"Large Language Models (LLM) hold immense promise for real-world applications,
but their generic knowledge often falls short of domain-specific needs.
Fine-tuning, a common approach, can suffer from catastrophic forgetting and
hinder generalizability. In-Context Learning (ICL) offers an alternative, which
can leverage Retrieval-Augmented Generation (RAG) to provide LLMs with relevant
demonstrations for few-shot learning tasks. This paper explores the desired
qualities of a demonstration retrieval system for ICL. We argue that ICL
retrieval in this context resembles item-cold-start recommender systems,
prioritizing discovery and maximizing information gain over strict relevance.
We propose a novel evaluation method that measures the LLM's subsequent
performance on NLP tasks, eliminating the need for subjective diversity scores.
Our findings demonstrate the critical role of diversity and quality bias in
retrieved demonstrations for effective ICL, and highlight the potential of
recommender system techniques in this domain.",2024-05-27,"Emile Contal, Garrin McGoldrick",http://arxiv.org/pdf/2405.17587v2,cs.LG
Understanding Forgetting in Continual Learning with Linear Regression,"Continual learning, focused on sequentially learning multiple tasks, has
gained significant attention recently. Despite the tremendous progress made in
the past, the theoretical understanding, especially factors contributing to
catastrophic forgetting, remains relatively unexplored. In this paper, we
provide a general theoretical analysis of forgetting in the linear regression
model via Stochastic Gradient Descent (SGD) applicable to both
underparameterized and overparameterized regimes. Our theoretical framework
reveals some interesting insights into the intricate relationship between task
sequence and algorithmic parameters, an aspect not fully captured in previous
studies due to their restrictive assumptions. Specifically, we demonstrate
that, given a sufficiently large data size, the arrangement of tasks in a
sequence, where tasks with larger eigenvalues in their population data
covariance matrices are trained later, tends to result in increased forgetting.
Additionally, our findings highlight that an appropriate choice of step size
will help mitigate forgetting in both underparameterized and overparameterized
settings. To validate our theoretical analysis, we conducted simulation
experiments on both linear regression models and Deep Neural Networks (DNNs).
Results from these simulations substantiate our theoretical findings.",2024-05-27,"Meng Ding, Kaiyi Ji, Di Wang, Jinhui Xu",http://arxiv.org/pdf/2405.17583v1,cs.LG
Building a temperature forecasting model for the city with the regression neural network (RNN),"In recent years, a study by environmental organizations in the world and
Vietnam shows that weather change is quite complex. global warming has become a
serious problem in the modern world, which is a concern for scientists. last
century, it was difficult to forecast the weather due to missing weather
monitoring stations and technological limitations. this made it hard to collect
data for building predictive models to make accurate simulations. in Vietnam,
research on weather forecast models is a recent development, having only begun
around 2000. along with advancements in computer science, mathematical models
are being built and applied with machine learning techniques to create more
accurate and reliable predictive models. this article will summarize the
research and solutions for applying recurrent neural networks to forecast urban
temperatures.",2024-05-27,"Nguyen Phuc Tran, Duy Thanh Tran, Thi Thuy Nga Duong",http://arxiv.org/pdf/2405.17582v1,cs.LG
Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes,"The training dynamics of linear networks are well studied in two distinct
setups: the lazy regime and balanced/active regime, depending on the
initialization and width of the network. We provide a surprisingly simple
unifying formula for the evolution of the learned matrix that contains as
special cases both lazy and balanced regimes but also a mixed regime in between
the two. In the mixed regime, a part of the network is lazy while the other is
balanced. More precisely the network is lazy along singular values that are
below a certain threshold and balanced along those that are above the same
threshold. At initialization, all singular values are lazy, allowing for the
network to align itself with the task, so that later in time, when some of the
singular value cross the threshold and become active they will converge rapidly
(convergence in the balanced regime is notoriously difficult in the absence of
alignment). The mixed regime is the `best of both worlds': it converges from
any random initialization (in contrast to balanced dynamics which require
special initialization), and has a low rank bias (absent in the lazy dynamics).
This allows us to prove an almost complete phase diagram of training behavior
as a function of the variance at initialization and the width, for a MSE
training task.",2024-05-27,"Zhenfeng Tu, Santiago Aranguri, Arthur Jacot",http://arxiv.org/pdf/2405.17580v2,cs.LG
Interpretable Prognostics with Concept Bottleneck Models,"Deep learning approaches have recently been extensively explored for the
prognostics of industrial assets. However, they still suffer from a lack of
interpretability, which hinders their adoption in safety-critical applications.
To improve their trustworthiness, explainable AI (XAI) techniques have been
applied in prognostics, primarily to quantify the importance of input variables
for predicting the remaining useful life (RUL) using post-hoc attribution
methods. In this work, we propose the application of Concept Bottleneck Models
(CBMs), a family of inherently interpretable neural network architectures based
on concept explanations, to the task of RUL prediction. Unlike attribution
methods, which explain decisions in terms of low-level input features, concepts
represent high-level information that is easily understandable by users.
Moreover, once verified in actual applications, CBMs enable domain experts to
intervene on the concept activations at test-time. We propose using the
different degradation modes of an asset as intermediate concepts. Our case
studies on the New Commercial Modular AeroPropulsion System Simulation
(N-CMAPSS) aircraft engine dataset for RUL prediction demonstrate that the
performance of CBMs can be on par or superior to black-box models, while being
more interpretable, even when the available labeled concepts are limited. Code
available at
\href{https://github.com/EPFL-IMOS/concept-prognostics/}{\url{github.com/EPFL-IMOS/concept-prognostics/}}.",2024-05-27,"Florent Forest, Katharina Rombach, Olga Fink",http://arxiv.org/pdf/2405.17575v1,cs.LG
Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky ResNets,"We study Leaky ResNets, which interpolate between ResNets and Fully-Connected
nets depending on an 'effective depth' hyper-parameter $\tilde{L}$. In the
infinite depth limit, we study 'representation geodesics' $A_{p}$: continuous
paths in representation space (similar to NeuralODEs) from input $p=0$ to
output $p=1$ that minimize the parameter norm of the network. We give a
Lagrangian and Hamiltonian reformulation, which highlight the importance of two
terms: a kinetic energy which favors small layer derivatives
$\partial_{p}A_{p}$ and a potential energy that favors low-dimensional
representations, as measured by the 'Cost of Identity'. The balance between
these two forces offers an intuitive understanding of feature learning in
ResNets. We leverage this intuition to explain the emergence of a bottleneck
structure, as observed in previous work: for large $\tilde{L}$ the potential
energy dominates and leads to a separation of timescales, where the
representation jumps rapidly from the high dimensional inputs to a
low-dimensional representation, move slowly inside the space of low-dimensional
representations, before jumping back to the potentially high-dimensional
outputs. Inspired by this phenomenon, we train with an adaptive layer step-size
to adapt to the separation of timescales.",2024-05-27,"Arthur Jacot, Alexandre Kaiser",http://arxiv.org/pdf/2405.17573v2,cs.LG
Discriminant audio properties in deep learning based respiratory insufficiency detection in Brazilian Portuguese,"This work investigates Artificial Intelligence (AI) systems that detect
respiratory insufficiency (RI) by analyzing speech audios, thus treating speech
as a RI biomarker. Previous works collected RI data (P1) from COVID-19 patients
during the first phase of the pandemic and trained modern AI models, such as
CNNs and Transformers, which achieved $96.5\%$ accuracy, showing the
feasibility of RI detection via AI. Here, we collect RI patient data (P2) with
several causes besides COVID-19, aiming at extending AI-based RI detection. We
also collected control data from hospital patients without RI. We show that the
considered models, when trained on P1, do not generalize to P2, indicating that
COVID-19 RI has features that may not be found in all RI types.",2024-05-27,"Marcelo Matheus Gauy, Larissa Cristina Berti, Arnaldo Cândido Jr, Augusto Camargo Neto, Alfredo Goldman, Anna Sara Shafferman Levin, Marcus Martins, Beatriz Raposo de Medeiros, Marcelo Queiroz, Ester Cerdeira Sabino, Flaviane Romani Fernandes Svartman, Marcelo Finger",http://arxiv.org/pdf/2405.17569v1,cs.LG
A deep-learning algorithm to disentangle self-interacting dark matter and AGN feedback models,"Different models of dark matter can alter the distribution of mass in galaxy
clusters in a variety of ways. However, so can uncertain astrophysical feedback
mechanisms. Here we present a Machine Learning method that ''learns'' how the
impact of dark matter self-interactions differs from that of astrophysical
feedback in order to break this degeneracy and make inferences on dark matter.
We train a Convolutional Neural Network on images of galaxy clusters from
hydro-dynamic simulations. In the idealised case our algorithm is 80% accurate
at identifying if a galaxy cluster harbours collisionless dark matter, dark
matter with ${\sigma}_{\rm DM}/m = 0.1$cm$^2/$g or with ${\sigma}_{DM}/m =
1$cm$^2$/g. Whilst we find adding X-ray emissivity maps does not improve the
performance in differentiating collisional dark matter, it does improve the
ability to disentangle different models of astrophysical feedback. We include
noise to resemble data expected from Euclid and Chandra and find our model has
a statistical error of < 0.01cm$^2$/g and that our algorithm is insensitive to
shape measurement bias and photometric redshift errors. This method represents
a new way to analyse data from upcoming telescopes that is an order of
magnitude more precise and many orders faster, enabling us to explore the dark
matter parameter space like never before.",2024-05-27,David Harvey,http://arxiv.org/pdf/2405.17566v1,cs.LG
Probabilistic Verification of Neural Networks using Branch and Bound,"Probabilistic verification of neural networks is concerned with formally
analysing the output distribution of a neural network under a probability
distribution of the inputs. Examples of probabilistic verification include
verifying the demographic parity fairness notion or quantifying the safety of a
neural network. We present a new algorithm for the probabilistic verification
of neural networks based on an algorithm for computing and iteratively refining
lower and upper bounds on probabilities over the outputs of a neural network.
By applying state-of-the-art bound propagation and branch and bound techniques
from non-probabilistic neural network verification, our algorithm significantly
outpaces existing probabilistic verification algorithms, reducing solving times
for various benchmarks from the literature from tens of minutes to tens of
seconds. Furthermore, our algorithm compares favourably even to dedicated
algorithms for restricted subsets of probabilistic verification. We complement
our empirical evaluation with a theoretical analysis, proving that our
algorithm is sound and, under mildly restrictive conditions, also complete when
using a suitable set of heuristics.",2024-05-27,"David Boetius, Stefan Leue, Tobias Sutter",http://arxiv.org/pdf/2405.17556v2,cs.LG
Bayesian RG Flow in Neural Network Field Theories,"The Neural Network Field Theory correspondence (NNFT) is a mapping from
neural network (NN) architectures into the space of statistical field theories
(SFTs). The Bayesian renormalization group (BRG) is an information-theoretic
coarse graining scheme that generalizes the principles of the exact
renormalization group (ERG) to arbitrarily parameterized probability
distributions, including those of NNs. In BRG, coarse graining is performed in
parameter space with respect to an information-theoretic distinguishability
scale set by the Fisher information metric. In this paper, we unify NNFT and
BRG to form a powerful new framework for exploring the space of NNs and SFTs,
which we coin BRG-NNFT. With BRG-NNFT, NN training dynamics can be interpreted
as inducing a flow in the space of SFTs from the information-theoretic `IR'
$\rightarrow$ `UV'. Conversely, applying an information-shell coarse graining
to the trained network's parameters induces a flow in the space of SFTs from
the information-theoretic `UV' $\rightarrow$ `IR'. When the
information-theoretic cutoff scale coincides with a standard momentum scale,
BRG is equivalent to ERG. We demonstrate the BRG-NNFT correspondence on two
analytically tractable examples. First, we construct BRG flows for trained,
infinite-width NNs, of arbitrary depth, with generic activation functions. As a
special case, we then restrict to architectures with a single infinitely-wide
layer, scalar outputs, and generalized cos-net activations. In this case, we
show that BRG coarse-graining corresponds exactly to the momentum-shell ERG
flow of a free scalar SFT. Our analytic results are corroborated by a numerical
experiment in which an ensemble of asymptotically wide NNs are trained and
subsequently renormalized using an information-shell BRG scheme.",2024-05-27,"Jessica N. Howard, Marc S. Klinger, Anindita Maiti, Alexander G. Stapleton",http://arxiv.org/pdf/2405.17538v3,cs.LG
Approximately-symmetric neural networks for quantum spin liquids,"We propose and analyze a family of approximately-symmetric neural networks
for quantum spin liquid problems. These tailored architectures are
parameter-efficient, scalable, and significantly out-perform existing
symmetry-unaware neural network architectures. Utilizing the mixed-field toric
code model, we demonstrate that our approach is competitive with the
state-of-the-art tensor network and quantum Monte Carlo methods. Moreover, at
the largest system sizes (N=480), our method allows us to explore Hamiltonians
with sign problems beyond the reach of both quantum Monte Carlo and finite-size
matrix-product states. The network comprises an exactly symmetric block
following a non-symmetric block, which we argue learns a transformation of the
ground state analogous to quasiadiabatic continuation. Our work paves the way
toward investigating quantum spin liquid problems within interpretable neural
network architectures",2024-05-27,"Dominik S. Kufel, Jack Kemp, Simon M. Linsel, Chris R. Laumann, Norman Y. Yao",http://arxiv.org/pdf/2405.17541v1,cs.LG
Towards Human-AI Complementarity with Prediction Sets,"Decision support systems based on prediction sets have proven to be effective
at helping human experts solve classification tasks. Rather than providing
single-label predictions, these systems provide sets of label predictions
constructed using conformal prediction, namely prediction sets, and ask human
experts to predict label values from these sets. In this paper, we first show
that the prediction sets constructed using conformal prediction are, in
general, suboptimal in terms of average accuracy. Then, we show that the
problem of finding the optimal prediction sets under which the human experts
achieve the highest average accuracy is NP-hard. More strongly, unless P = NP,
we show that the problem is hard to approximate to any factor less than the
size of the label set. However, we introduce a simple and efficient greedy
algorithm that, for a large class of expert models and non-conformity scores,
is guaranteed to find prediction sets that provably offer equal or greater
performance than those constructed using conformal prediction. Further, using a
simulation study with both synthetic and real expert predictions, we
demonstrate that, in practice, our greedy algorithm finds near-optimal
prediction sets offering greater performance than conformal prediction.",2024-05-27,"Giovanni De Toni, Nastaran Okati, Suhas Thejaswi, Eleni Straitouri, Manuel Gomez-Rodriguez",http://arxiv.org/pdf/2405.17544v2,cs.LG
Matryoshka Multimodal Models,"Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in
visual-linguistic reasoning. These models first embed images into a fixed large
number of visual tokens and then feed them into a Large Language Model (LLM).
However, this design causes an excessive number of tokens for dense visual
scenarios such as high-resolution images and videos, leading to great
inefficiency. While token pruning/merging methods do exist, they produce a
single length output for each image and do not afford flexibility in trading
off information density v.s. efficiency. Inspired by the concept of Matryoshka
Dolls, we propose M3: Matryoshka Multimodal Models, which learns to represent
visual content as nested sets of visual tokens that capture information across
multiple coarse-to-fine granularities. Our approach offers several unique
benefits for LMMs: (1) One can explicitly control the visual granularity per
test instance during inference, e.g. , adjusting the number of tokens used to
represent an image based on the anticipated complexity or simplicity of the
content; (2) M3 provides a framework for analyzing the granularity needed for
existing datasets, where we find that COCO-style benchmarks only need around ~9
visual tokens to obtain accuracy similar to that of using all 576 tokens; (3)
Our approach provides a foundation to explore the best trade-off between
performance and visual token length at sample level, where our investigation
reveals that a large gap exists between the oracle upper bound and current
fixed-scale representations.",2024-05-27,"Mu Cai, Jianwei Yang, Jianfeng Gao, Yong Jae Lee",http://arxiv.org/pdf/2405.17430v2,cs.LG
NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models,"Decoder-only LLM-based embedding models are beginning to outperform BERT or
T5-based embedding models in general-purpose text embedding tasks, including
dense vector-based retrieval. In this work, we introduce NV-Embed,
incorporating architectural designs, training procedures, and curated datasets
to significantly enhance the performance of LLM as a versatile embedding model,
while maintaining its simplicity and reproducibility. For model architecture,
we propose a latent attention layer to obtain pooled embeddings, which
consistently improves retrieval and downstream task accuracy compared to mean
pooling or using the last <EOS> token embedding from LLMs. To enhance
representation learning, we remove the causal attention mask of LLMs during
contrastive training. For training algorithm, we introduce a two-stage
contrastive instruction-tuning method. It first applies contrastive training
with instructions on retrieval datasets, utilizing in-batch negatives and
curated hard negative examples. At stage-2, it blends various non-retrieval
into instruction tuning, which not only enhances non-retrieval task accuracy
but also improves retrieval performance. For training data, we utilize the
hard-negative mining, synthetic data generation and existing public available
datasets to boost the performance of embedding model. By combining these
techniques, our NV-Embed-v1 and NV-Embed-v2 models obtained the No.1 position
on the MTEB leaderboard (as of May 24 and August 30, 2024, respectively) across
56 tasks, demonstrating the sustained effectiveness of the proposed methods
over time. It also achieved the highest scores in the Long Doc section and the
second-highest scores in the QA section of the AIR Benchmark, which covers a
range of out-of-domain information retrieval topics beyond those in MTEB. We
further provide the analysis of model compression techniques for generalist
embedding models.",2024-05-27,"Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping",http://arxiv.org/pdf/2405.17428v3,cs.LG
From Neurons to Neutrons: A Case Study in Interpretability,"Mechanistic Interpretability (MI) promises a path toward fully understanding
how neural networks make their predictions. Prior work demonstrates that even
when trained to perform simple arithmetic, models can implement a variety of
algorithms (sometimes concurrently) depending on initialization and
hyperparameters. Does this mean neuron-level interpretability techniques have
limited applicability? We argue that high-dimensional neural networks can learn
low-dimensional representations of their training data that are useful beyond
simply making good predictions. Such representations can be understood through
the mechanistic interpretability lens and provide insights that are
surprisingly faithful to human-derived domain knowledge. This indicates that
such approaches to interpretability can be useful for deriving a new
understanding of a problem from models trained to solve it. As a case study, we
extract nuclear physics concepts by studying models trained to reproduce
nuclear data.",2024-05-27,"Ouail Kitouni, Niklas Nolte, Víctor Samuel Pérez-Díaz, Sokratis Trifinopoulos, Mike Williams",http://arxiv.org/pdf/2405.17425v1,cs.LG
Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection,"3D object detection aims to recover the 3D information of concerning objects
and serves as the fundamental task of autonomous driving perception. Its
performance greatly depends on the scale of labeled training data, yet it is
costly to obtain high-quality annotations for point cloud data. While
conventional methods focus on generating pseudo-labels for unlabeled samples as
supplements for training, the structural nature of 3D point cloud data
facilitates the composition of objects and backgrounds to synthesize realistic
scenes. Motivated by this, we propose a hardness-aware scene synthesis (HASS)
method to generate adaptive synthetic scenes to improve the generalization of
the detection models. We obtain pseudo-labels for unlabeled objects and
generate diverse scenes with different compositions of objects and backgrounds.
As the scene synthesis is sensitive to the quality of pseudo-labels, we further
propose a hardness-aware strategy to reduce the effect of low-quality
pseudo-labels and maintain a dynamic pseudo-database to ensure the diversity
and quality of synthetic scenes. Extensive experimental results on the widely
used KITTI and Waymo datasets demonstrate the superiority of the proposed HASS
method, which outperforms existing semi-supervised learning methods on 3D
object detection. Code: https://github.com/wzzheng/HASS.",2024-05-27,"Shuai Zeng, Wenzhao Zheng, Jiwen Lu, Haibin Yan",http://arxiv.org/pdf/2405.17422v1,cs.LG
Survival of the Fittest Representation: A Case Study with Modular Addition,"When a neural network can learn multiple distinct algorithms to solve a task,
how does it ""choose"" between them during training? To approach this question,
we take inspiration from ecology: when multiple species coexist, they
eventually reach an equilibrium where some survive while others die out.
Analogously, we suggest that a neural network at initialization contains many
solutions (representations and algorithms), which compete with each other under
pressure from resource constraints, with the ""fittest"" ultimately prevailing.
To investigate this Survival of the Fittest hypothesis, we conduct a case study
on neural networks performing modular addition, and find that these networks'
multiple circular representations at different Fourier frequencies undergo such
competitive dynamics, with only a few circles surviving at the end. We find
that the frequencies with high initial signals and gradients, the ""fittest,""
are more likely to survive. By increasing the embedding dimension, we also
observe more surviving frequencies. Inspired by the Lotka-Volterra equations
describing the dynamics between species, we find that the dynamics of the
circles can be nicely characterized by a set of linear differential equations.
Our results with modular addition show that it is possible to decompose
complicated representations into simpler components, along with their basic
interactions, to offer insight on the training dynamics of representations.",2024-05-27,"Xiaoman Delores Ding, Zifan Carl Guo, Eric J. Michaud, Ziming Liu, Max Tegmark",http://arxiv.org/pdf/2405.17420v1,cs.LG
MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities,"Detecting out-of-distribution (OOD) samples is important for deploying
machine learning models in safety-critical applications such as autonomous
driving and robot-assisted surgery. Existing research has mainly focused on
unimodal scenarios on image data. However, real-world applications are
inherently multimodal, which makes it essential to leverage information from
multiple modalities to enhance the efficacy of OOD detection. To establish a
foundation for more realistic Multimodal OOD Detection, we introduce the
first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes
and varying modality combinations. We first evaluate existing unimodal OOD
detection algorithms on MultiOOD, observing that the mere inclusion of
additional modalities yields substantial improvements. This underscores the
importance of utilizing multiple modalities for OOD detection. Based on the
observation of Modality Prediction Discrepancy between in-distribution (ID) and
OOD data, and its strong correlation with OOD performance, we propose the
Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during
training. Moreover, we introduce a novel outlier synthesis method, NP-Mix,
which explores broader feature spaces by leveraging the information from
nearest neighbor classes and complements A2D to strengthen OOD detection
performance. Extensive experiments on MultiOOD demonstrate that training with
A2D and NP-Mix improves existing OOD detection algorithms by a large margin.
Our source code and MultiOOD benchmark are available at
https://github.com/donghao51/MultiOOD.",2024-05-27,"Hao Dong, Yue Zhao, Eleni Chatzi, Olga Fink",http://arxiv.org/pdf/2405.17419v2,cs.LG
A Recipe for Unbounded Data Augmentation in Visual Reinforcement Learning,"Q-learning algorithms are appealing for real-world applications due to their
data-efficiency, but they are very prone to overfitting and training
instabilities when trained from visual observations. Prior work, namely SVEA,
finds that selective application of data augmentation can improve the visual
generalization of RL agents without destabilizing training. We revisit its
recipe for data augmentation, and find an assumption that limits its
effectiveness to augmentations of a photometric nature. Addressing these
limitations, we propose a generalized recipe, SADA, that works with wider
varieties of augmentations. We benchmark its effectiveness on DMC-GB2 - our
proposed extension of the popular DMControl Generalization Benchmark - as well
as tasks from Meta-World and the Distracting Control Suite, and find that our
method, SADA, greatly improves training stability and generalization of RL
agents across a diverse set of augmentations. For visualizations, code and
benchmark: see https://aalmuzairee.github.io/SADA/",2024-05-27,"Abdulaziz Almuzairee, Nicklas Hansen, Henrik I. Christensen",http://arxiv.org/pdf/2405.17416v2,cs.LG
Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE,"This paper shows that dimensionality reduction methods such as UMAP and
t-SNE, can be approximately recast as MAP inference methods corresponding to a
model introduced in Ravuri et al. (2023), that describes the graph Laplacian
(an estimate of the data precision matrix) using a Wishart distribution, with a
mean given by a non-linear covariance function evaluated on the latents. This
interpretation offers deeper theoretical and semantic insights into such
algorithms, and forging a connection to Gaussian process latent variable models
by showing that well-known kernels can be used to describe covariances implied
by graph Laplacians. We also introduce tools with which similar dimensionality
reduction methods can be studied.",2024-05-27,"Aditya Ravuri, Neil D. Lawrence",http://arxiv.org/pdf/2405.17412v5,cs.LG
Deep Learning Calabi-Yau four folds with hybrid and recurrent neural network architectures,"In this work, we report the results of applying deep learning based on hybrid
convolutional-recurrent and purely recurrent neural network architectures to
the dataset of almost one million complete intersection Calabi-Yau four-folds
(CICY4) to machine-learn their four Hodge numbers $h^{1,1}, h^{2,1}, h^{3,1},
h^{2,2}$. In particular, we explored and experimented with twelve different
neural network models, nine of which are convolutional-recurrent (CNN-RNN)
hybrids with the RNN unit being either GRU (Gated Recurrent Unit) or Long Short
Term Memory (LSTM). The remaining four models are purely recurrent neural
networks based on LSTM. In terms of the $h^{1,1}, h^{2,1}, h^{3,1}, h^{2,2}$
prediction accuracies, at 72% training ratio, our best performing individual
model is CNN-LSTM-400, a hybrid CNN-LSTM with the LSTM hidden size of 400,
which obtained 99.74%, 98.07%, 95.19%, 81.01%, our second best performing
individual model is LSTM-448, an LSTM-based model with the hidden size of 448,
which obtained 99.74%, 97.51%, 94.24%, and 78.63%. These results were improved
by forming ensembles of the top two, three or even four models. Our best
ensemble, consisting of the top four models, achieved the accuracies of 99.84%,
98.71%, 96.26%, 85.03%. At 80% training ratio, the top two performing models
LSTM-448 and LSTM-424 are both LSTM-based with the hidden sizes of 448 and 424.
Compared with the 72% training ratio, there is a significant improvement of
accuracies, which reached 99.85%, 98.66%, 96.26%, 84.77% for the best
individual model and 99.90%, 99.03%, 97.97%, 87.34% for the best ensemble. By
nature a proof of concept, the results of this work conclusively established
the utility of RNN-based architectures and demonstrated their effective
performances compared to the well-explored purely CNN-based architectures in
the problem of deep learning Calabi Yau manifolds.",2024-05-27,H. L. Dao,http://arxiv.org/pdf/2405.17406v3,cs.LG
Calibrated Dataset Condensation for Faster Hyperparameter Search,"Dataset condensation can be used to reduce the computational cost of training
multiple models on a large dataset by condensing the training dataset into a
small synthetic set. State-of-the-art approaches rely on matching the model
gradients between the real and synthetic data. However, there is no theoretical
guarantee of the generalizability of the condensed data: data condensation
often generalizes poorly across hyperparameters/architectures in practice. This
paper considers a different condensation objective specifically geared toward
hyperparameter search. We aim to generate a synthetic validation dataset so
that the validation-performance rankings of the models, with different
hyperparameters, on the condensed and original datasets are comparable. We
propose a novel hyperparameter-calibrated dataset condensation (HCDC)
algorithm, which obtains the synthetic validation dataset by matching the
hyperparameter gradients computed via implicit differentiation and efficient
inverse Hessian approximation. Experiments demonstrate that the proposed
framework effectively maintains the validation-performance rankings of models
and speeds up hyperparameter/architecture search for tasks on both images and
graphs.",2024-05-27,"Mucong Ding, Yuancheng Xu, Tahseen Rabbani, Xiaoyu Liu, Brian Gravelle, Teresa Ranadive, Tai-Ching Tuan, Furong Huang",http://arxiv.org/pdf/2405.17535v1,cs.LG
Revision Matters: Generative Design Guided by Revision Edits,"Layout design, such as user interface or graphical layout in general, is
fundamentally an iterative revision process. Through revising a design
repeatedly, the designer converges on an ideal layout. In this paper, we
investigate how revision edits from human designer can benefit a multimodal
generative model. To do so, we curate an expert dataset that traces how human
designers iteratively edit and improve a layout generation with a prompted
language goal. Based on such data, we explore various supervised fine-tuning
task setups on top of a Gemini multimodal backbone, a large multimodal model.
Our results show that human revision plays a critical role in iterative layout
refinement. While being noisy, expert revision edits lead our model to a
surprisingly strong design FID score ~10 which is close to human performance
(~6). In contrast, self-revisions that fully rely on model's own judgement,
lead to an echo chamber that prevents iterative improvement, and sometimes
leads to generative degradation. Fortunately, we found that providing human
guidance plays at early stage plays a critical role in final generation. In
such human-in-the-loop scenario, our work paves the way for iterative design
revision based on pre-trained large multimodal models.",2024-05-27,"Tao Li, Chin-Yi Cheng, Amber Xie, Gang Li, Yang Li",http://arxiv.org/pdf/2406.18559v1,cs.LG
SMR: State Memory Replay for Long Sequence Modeling,"Despite the promising performance of state space models (SSMs) in long
sequence modeling, limitations still exist. Advanced SSMs like S5 and S6
(Mamba) in addressing non-uniform sampling, their recursive structures impede
efficient SSM computation via convolution. To overcome compatibility
limitations in parallel convolutional computation, this paper proposes a novel
non-recursive non-uniform sample processing strategy. Theoretical analysis of
SSMs through the lens of Event-Triggered Control (ETC) theory reveals the
Non-Stable State (NSS) problem, where deviations from sampling point
requirements lead to error transmission and accumulation, causing the
divergence of the SSM's hidden state. Our analysis further reveals that
adjustments of input sequences with early memories can mitigate the NSS
problem, achieving Sampling Step Adaptation (SSA). Building on this insight, we
introduce a simple yet effective plug-and-play mechanism, State Memory Replay
(SMR), which utilizes learnable memories to adjust the current state with
multi-step information for generalization at sampling points different from
those in the training data. This enables SSMs to stably model varying sampling
points. Experiments on long-range modeling tasks in autoregressive language
modeling and Long Range Arena demonstrate the general effectiveness of the SMR
mechanism for a series of SSM models.",2024-05-27,"Biqing Qi, Junqi Gao, Kaiyan Zhang, Dong Li, Jianxing Liu, Ligang Wu, Bowen Zhou",http://arxiv.org/pdf/2405.17534v2,cs.LG
Spectral Greedy Coresets for Graph Neural Networks,"The ubiquity of large-scale graphs in node-classification tasks significantly
hinders the real-world applications of Graph Neural Networks (GNNs). Node
sampling, graph coarsening, and dataset condensation are effective strategies
for enhancing data efficiency. However, owing to the interdependence of graph
nodes, coreset selection, which selects subsets of the data examples, has not
been successfully applied to speed up GNN training on large graphs, warranting
special treatment. This paper studies graph coresets for GNNs and avoids the
interdependence issue by selecting ego-graphs (i.e., neighborhood subgraphs
around a node) based on their spectral embeddings. We decompose the coreset
selection problem for GNNs into two phases: a coarse selection of widely spread
ego graphs and a refined selection to diversify their topologies. We design a
greedy algorithm that approximately optimizes both objectives. Our spectral
greedy graph coreset (SGGC) scales to graphs with millions of nodes, obviates
the need for model pre-training, and applies to low-homophily graphs. Extensive
experiments on ten datasets demonstrate that SGGC outperforms other coreset
methods by a wide margin, generalizes well across GNN architectures, and is
much faster than graph condensation.",2024-05-27,"Mucong Ding, Yinhan He, Jundong Li, Furong Huang",http://arxiv.org/pdf/2405.17404v1,cs.LG
A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion Model Training,"Training diffusion models is always a computation-intensive task. In this
paper, we introduce a novel speed-up method for diffusion model training,
called, which is based on a closer look at time steps. Our key findings are: i)
Time steps can be empirically divided into acceleration, deceleration, and
convergence areas based on the process increment. ii) These time steps are
imbalanced, with many concentrated in the convergence area. iii) The
concentrated steps provide limited benefits for diffusion training. To address
this, we design an asymmetric sampling strategy that reduces the frequency of
steps from the convergence area while increasing the sampling probability for
steps from other areas. Additionally, we propose a weighting strategy to
emphasize the importance of time steps with rapid-change process increments. As
a plug-and-play and architecture-agnostic approach, SpeeD consistently achieves
3-times acceleration across various diffusion architectures, datasets, and
tasks. Notably, due to its simple design, our approach significantly reduces
the cost of diffusion model training with minimal overhead. Our research
enables more researchers to train diffusion models at a lower cost.",2024-05-27,"Kai Wang, Mingjia Shi, Yukun Zhou, Zekai Li, Zhihang Yuan, Yuzhang Shang, Xiaojiang Peng, Hanwang Zhang, Yang You",http://arxiv.org/pdf/2405.17403v3,cs.LG
RB-Modulation: Training-Free Personalization of Diffusion Models using Stochastic Optimal Control,"We propose Reference-Based Modulation (RB-Modulation), a new plug-and-play
solution for training-free personalization of diffusion models. Existing
training-free approaches exhibit difficulties in (a) style extraction from
reference images in the absence of additional style or content text
descriptions, (b) unwanted content leakage from reference style images, and (c)
effective composition of style and content. RB-Modulation is built on a novel
stochastic optimal controller where a style descriptor encodes the desired
attributes through a terminal cost. The resulting drift not only overcomes the
difficulties above, but also ensures high fidelity to the reference style and
adheres to the given text prompt. We also introduce a cross-attention-based
feature aggregation scheme that allows RB-Modulation to decouple content and
style from the reference image. With theoretical justification and empirical
evidence, our framework demonstrates precise extraction and control of content
and style in a training-free manner. Further, our method allows a seamless
composition of content and style, which marks a departure from the dependency
on external adapters or ControlNets.",2024-05-27,"Litu Rout, Yujia Chen, Nataniel Ruiz, Abhishek Kumar, Constantine Caramanis, Sanjay Shakkottai, Wen-Sheng Chu",http://arxiv.org/pdf/2405.17401v1,cs.LG
PAE: LLM-based Product Attribute Extraction for E-Commerce Fashion Trends,"Product attribute extraction is an growing field in e-commerce business, with
several applications including product ranking, product recommendation, future
assortment planning and improving online shopping customer experiences.
Understanding the customer needs is critical part of online business,
specifically fashion products. Retailers uses assortment planning to determine
the mix of products to offer in each store and channel, stay responsive to
market dynamics and to manage inventory and catalogs. The goal is to offer the
right styles, in the right sizes and colors, through the right channels. When
shoppers find products that meet their needs and desires, they are more likely
to return for future purchases, fostering customer loyalty. Product attributes
are a key factor in assortment planning. In this paper we present PAE, a
product attribute extraction algorithm for future trend reports consisting text
and images in PDF format. Most existing methods focus on attribute extraction
from titles or product descriptions or utilize visual information from existing
product images. Compared to the prior works, our work focuses on attribute
extraction from PDF files where upcoming fashion trends are explained. This
work proposes a more comprehensive framework that fully utilizes the different
modalities for attribute extraction and help retailers to plan the assortment
in advance. Our contributions are three-fold: (a) We develop PAE, an efficient
framework to extract attributes from unstructured data (text and images); (b)
We provide catalog matching methodology based on BERT representations to
discover the existing attributes using upcoming attribute values; (c) We
conduct extensive experiments with several baselines and show that PAE is an
effective, flexible and on par or superior (avg 92.5% F1-Score) framework to
existing state-of-the-art for attribute value extraction task.",2024-05-27,"Apurva Sinha, Ekta Gujral",http://arxiv.org/pdf/2405.17533v1,cs.LG
Transformers Can Do Arithmetic with the Right Embeddings,"The poor performance of transformers on arithmetic tasks seems to stem in
large part from their inability to keep track of the exact position of each
digit inside of a large span of digits. We mend this problem by adding an
embedding to each digit that encodes its position relative to the start of the
number. In addition to the boost these embeddings provide on their own, we show
that this fix enables architectural modifications such as input injection and
recurrent layers to improve performance even further.
  With positions resolved, we can study the logical extrapolation ability of
transformers. Can they solve arithmetic problems that are larger and more
complex than those in their training data? We find that training on only 20
digit numbers with a single GPU for one day, we can reach state-of-the-art
performance, achieving up to 99% accuracy on 100 digit addition problems.
Finally, we show that these gains in numeracy also unlock improvements on other
multi-step reasoning tasks including sorting and multiplication.",2024-05-27,"Sean McLeish, Arpit Bansal, Alex Stein, Neel Jain, John Kirchenbauer, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Jonas Geiping, Avi Schwarzschild, Tom Goldstein",http://arxiv.org/pdf/2405.17399v2,cs.LG
The Expressive Capacity of State Space Models: A Formal Language Perspective,"Recently, recurrent models based on linear state space models (SSMs) have
shown promising performance in language modeling (LM), competititve with
transformers. However, there is little understanding of the in-principle
abilities of such models, which could provide useful guidance to the search for
better LM architectures. We present a comprehensive theoretical study of the
capacity of such SSMs as it compares to that of transformers and traditional
RNNs. We find that SSMs and transformers have overlapping but distinct
strengths. In star-free state tracking, SSMs implement straightforward and
exact solutions to problems that transformers struggle to represent exactly.
They can also model bounded hierarchical structure with optimal memory even
without simulating a stack. On the other hand, we identify a design choice in
current SSMs that limits their expressive power. We discuss implications for
SSM and LM research, and verify results empirically on a recent SSM, Mamba.",2024-05-27,"Yash Sarrof, Yana Veitsman, Michael Hahn",http://arxiv.org/pdf/2405.17394v2,cs.LG
Dataset-learning duality and emergent criticality,"In artificial neural networks, the activation dynamics of non-trainable
variables is strongly coupled to the learning dynamics of trainable variables.
During the activation pass, the boundary neurons (e.g., input neurons) are
mapped to the bulk neurons (e.g., hidden neurons), and during the learning
pass, both bulk and boundary neurons are mapped to changes in trainable
variables (e.g., weights and biases). For example, in feed-forward neural
networks, forward propagation is the activation pass and backward propagation
is the learning pass. We show that a composition of the two maps establishes a
duality map between a subspace of non-trainable boundary variables (e.g.,
dataset) and a tangent subspace of trainable variables (i.e., learning). In
general, the dataset-learning duality is a complex non-linear map between
high-dimensional spaces. We use duality to study the emergence of criticality,
or the power-law distribution of fluctuations of the trainable variables, using
a toy model at learning equilibrium. In particular, we show that criticality
can emerge in the learning system even from the dataset in a non-critical
state, and that the power-law distribution can be modified by changing either
the activation function or the loss function.",2024-05-27,"Ekaterina Kukleva, Vitaly Vanchurin",http://arxiv.org/pdf/2405.17391v3,cs.LG
ReMoDetect: Reward Models Recognize Aligned LLM's Generations,"The remarkable capabilities and easy accessibility of large language models
(LLMs) have significantly increased societal risks (e.g., fake news
generation), necessitating the development of LLM-generated text (LGT)
detection methods for safe usage. However, detecting LGTs is challenging due to
the vast number of LLMs, making it impractical to account for each LLM
individually; hence, it is crucial to identify the common characteristics
shared by these models. In this paper, we draw attention to a common feature of
recent powerful LLMs, namely the alignment training, i.e., training LLMs to
generate human-preferable texts. Our key finding is that as these aligned LLMs
are trained to maximize the human preferences, they generate texts with higher
estimated preferences even than human-written texts; thus, such texts are
easily detected by using the reward model (i.e., an LLM trained to model human
preference distribution). Based on this finding, we propose two training
schemes to further improve the detection ability of the reward model, namely
(i) continual preference fine-tuning to make the reward model prefer aligned
LGTs even further and (ii) reward modeling of Human/LLM mixed texts (a
rephrased texts from human-written texts using aligned LLMs), which serves as a
median preference text corpus between LGTs and human-written texts to learn the
decision boundary better. We provide an extensive evaluation by considering six
text domains across twelve aligned LLMs, where our method demonstrates
state-of-the-art results. Code is available at
https://github.com/hyunseoklee-ai/ReMoDetect.",2024-05-27,"Hyunseok Lee, Jihoon Tack, Jinwoo Shin",http://arxiv.org/pdf/2405.17382v2,cs.LG
RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design Projects,"Large Language Models (LLMs) have demonstrated potential in assisting with
Register Transfer Level (RTL) design tasks. Nevertheless, there remains to be a
significant gap in benchmarks that accurately reflect the complexity of
real-world RTL projects. To address this, this paper presents RTL-Repo, a
benchmark specifically designed to evaluate LLMs on large-scale RTL design
projects. RTL-Repo includes a comprehensive dataset of more than 4000 Verilog
code samples extracted from public GitHub repositories, with each sample
providing the full context of the corresponding repository. We evaluate several
state-of-the-art models on the RTL-Repo benchmark, including GPT-4, GPT-3.5,
Starcoder2, alongside Verilog-specific models like VeriGen and RTLCoder, and
compare their performance in generating Verilog code for complex projects. The
RTL-Repo benchmark provides a valuable resource for the hardware design
community to assess and compare LLMs' performance in real-world RTL design
scenarios and train LLMs specifically for Verilog code generation in complex,
multi-file RTL projects. RTL-Repo is open-source and publicly available on
Github.",2024-05-27,"Ahmed Allam, Mohamed Shalan",http://arxiv.org/pdf/2405.17378v1,cs.LG
How Do the Architecture and Optimizer Affect Representation Learning? On the Training Dynamics of Representations in Deep Neural Networks,"In this paper, we elucidate how representations in deep neural networks
(DNNs) evolve during training. Our focus is on overparameterized learning
settings where the training continues much after the trained DNN starts to
perfectly fit its training data. We examine the evolution of learned
representations along the entire training process. We explore the
representational similarity of DNN layers, each layer with respect to its own
representations throughout the training process. For this, we use two
similarity metrics: (1) The centered kernel alignment (CKA) similarity; (2)
Similarity of decision regions of linear classifier probes that we train for
the DNN layers. We visualize and analyze the decision regions of the DNN output
and the layer probes during the DNN training to show how they geometrically
evolve. Our extensive experiments discover training dynamics patterns that can
emerge in layers depending on the relative layer-depth, architecture and
optimizer. Among our findings: (i) The training phases, including those related
to memorization, are more distinguishable in SGD training than in Adam
training, and for Vision Transformer (ViT) than for ResNet; (ii) Unlike ResNet,
the ViT layers have synchronized dynamics of representation learning.",2024-05-27,"Yuval Sharon, Yehuda Dar",http://arxiv.org/pdf/2405.17377v2,cs.LG
Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models,"Safety alignment is crucial to ensure that large language models (LLMs)
behave in ways that align with human preferences and prevent harmful actions
during inference. However, recent studies show that the alignment can be easily
compromised through finetuning with only a few adversarially designed training
examples. We aim to measure the risks in finetuning LLMs through navigating the
LLM safety landscape. We discover a new phenomenon observed universally in the
model parameter space of popular open-source LLMs, termed as ""safety basin"":
random perturbations to model weights maintain the safety level of the original
aligned model within its local neighborhood. However, outside this local
region, safety is fully compromised, exhibiting a sharp, step-like drop. This
safety basin contrasts sharply with the LLM capability landscape, where model
performance peaks at the origin and gradually declines as random perturbation
increases. Our discovery inspires us to propose the new VISAGE safety metric
that measures the safety in LLM finetuning by probing its safety landscape.
Visualizing the safety landscape of the aligned model enables us to understand
how finetuning compromises safety by dragging the model away from the safety
basin. The LLM safety landscape also highlights the system prompt's critical
role in protecting a model, and that such protection transfers to its perturbed
variants within the safety basin. These observations from our safety landscape
research provide new insights for future work on LLM safety community. Our code
is publicly available at https://github.com/ShengYun-Peng/llm-landscape.",2024-05-27,"ShengYun Peng, Pin-Yu Chen, Matthew Hull, Duen Horng Chau",http://arxiv.org/pdf/2405.17374v3,cs.LG
BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction,"Simulating realistic behaviors of traffic agents is pivotal for efficiently
validating the safety of autonomous driving systems. Existing data-driven
simulators primarily use an encoder-decoder architecture to encode the
historical trajectories before decoding the future. However, the heterogeneity
between encoders and decoders complicates the models, and the manual separation
of historical and future trajectories leads to low data utilization. Given
these limitations, we propose BehaviorGPT, a homogeneous and fully
autoregressive Transformer designed to simulate the sequential behavior of
multiple agents. Crucially, our approach discards the traditional separation
between ""history"" and ""future"" by modeling each time step as the ""current"" one
for motion generation, leading to a simpler, more parameter- and data-efficient
agent simulator. We further introduce the Next-Patch Prediction Paradigm (NP3)
to mitigate the negative effects of autoregressive modeling, in which models
are trained to reason at the patch level of trajectories and capture long-range
spatial-temporal interactions. Despite having merely 3M model parameters,
BehaviorGPT won first place in the 2024 Waymo Open Sim Agents Challenge with a
realism score of 0.7473 and a minADE score of 1.4147, demonstrating its
exceptional performance in traffic agent simulation.",2024-05-27,"Zikang Zhou, Haibo Hu, Xinhong Chen, Jianping Wang, Nan Guan, Kui Wu, Yung-Hui Li, Yu-Kai Huang, Chun Jason Xue",http://arxiv.org/pdf/2405.17372v3,cs.LG
Model-Agnostic Zeroth-Order Policy Optimization for Meta-Learning of Ergodic Linear Quadratic Regulators,"Meta-learning has been proposed as a promising machine learning topic in
recent years, with important applications to image classification, robotics,
computer games, and control systems. In this paper, we study the problem of
using meta-learning to deal with uncertainty and heterogeneity in ergodic
linear quadratic regulators. We integrate the zeroth-order optimization
technique with a typical meta-learning method, proposing an algorithm that
omits the estimation of policy Hessian, which applies to tasks of learning a
set of heterogeneous but similar linear dynamic systems. The induced
meta-objective function inherits important properties of the original cost
function when the set of linear dynamic systems are meta-learnable, allowing
the algorithm to optimize over a learnable landscape without projection onto
the feasible set. We provide a convergence result for the exact gradient
descent process by analyzing the boundedness and smoothness of the gradient for
the meta-objective, which justify the proposed algorithm with gradient
estimation error being small. We also provide a numerical example to
corroborate this perspective.",2024-05-27,"Yunian Pan, Quanyan Zhu",http://arxiv.org/pdf/2405.17370v1,cs.LG
EM-GANSim: Real-time and Accurate EM Simulation Using Conditional GANs for 3D Indoor Scenes,"We present a novel machine-learning (ML) approach (EM-GANSim) for real-time
electromagnetic (EM) propagation that is used for wireless communication
simulation in 3D indoor environments. Our approach uses a modified conditional
Generative Adversarial Network (GAN) that incorporates encoded geometry and
transmitter location while adhering to the electromagnetic propagation theory.
The overall physically-inspired learning is able to predict the power
distribution in 3D scenes, which is represented using heatmaps. We evaluated
our method on 15 complex 3D indoor environments, with 4 additional scenarios
later included in the results, showcasing the generalizability of the model
across diverse conditions. Our overall accuracy is comparable to ray
tracing-based EM simulation, as evidenced by lower mean squared error values.
Furthermore, our GAN-based method drastically reduces the computation time,
achieving a 5X speedup on complex benchmarks. In practice, it can compute the
signal strength in a few milliseconds on any location in 3D indoor
environments. We also present a large dataset of 3D models and EM ray
tracing-simulated heatmaps. To the best of our knowledge, EM-GANSim is the
first real-time algorithm for EM simulation in complex 3D indoor environments.
We plan to release the code and the dataset.",2024-05-27,"Ruichen Wang, Dinesh Manocha",http://arxiv.org/pdf/2405.17366v2,cs.LG
Rethinking Transformers in Solving POMDPs,"Sequential decision-making algorithms such as reinforcement learning (RL) in
real-world scenarios inevitably face environments with partial observability.
This paper scrutinizes the effectiveness of a popular architecture, namely
Transformers, in Partially Observable Markov Decision Processes (POMDPs) and
reveals its theoretical limitations. We establish that regular languages, which
Transformers struggle to model, are reducible to POMDPs. This poses a
significant challenge for Transformers in learning POMDP-specific inductive
biases, due to their lack of inherent recurrence found in other models like
RNNs. This paper casts doubt on the prevalent belief in Transformers as
sequence models for RL and proposes to introduce a point-wise recurrent
structure. The Deep Linear Recurrent Unit (LRU) emerges as a well-suited
alternative for Partially Observable RL, with empirical results highlighting
the sub-optimal performance of the Transformer and considerable strength of
LRU.",2024-05-27,"Chenhao Lu, Ruizhe Shi, Yuyao Liu, Kaizhe Hu, Simon S. Du, Huazhe Xu",http://arxiv.org/pdf/2405.17358v3,cs.LG
Assessing the significance of longitudinal data in Alzheimer's Disease forecasting,"In this study, we employ a transformer encoder model to characterize the
significance of longitudinal patient data for forecasting the progression of
Alzheimer's Disease (AD). Our model, Longitudinal Forecasting Model for
Alzheimer's Disease (LongForMAD), harnesses the comprehensive temporal
information embedded in sequences of patient visits that incorporate multimodal
data, providing a deeper understanding of disease progression than can be drawn
from single-visit data alone. We present an empirical analysis across two
patient groups-Cognitively Normal (CN) and Mild Cognitive Impairment (MCI)-over
a span of five follow-up years. Our findings reveal that models incorporating
more extended patient histories can outperform those relying solely on present
information, suggesting a deeper historical context is critical in enhancing
predictive accuracy for future AD progression. Our results support the
incorporation of longitudinal data in clinical settings to enhance the early
detection and monitoring of AD. Our code is available at
\url{https://github.com/batuhankmkaraman/LongForMAD}.",2024-05-27,"Batuhan K. Karaman, Mert R. Sabuncu",http://arxiv.org/pdf/2405.17352v1,cs.LG
Prompt Optimization with Human Feedback,"Large language models (LLMs) have demonstrated remarkable performances in
various tasks. However, the performance of LLMs heavily depends on the input
prompt, which has given rise to a number of recent works on prompt
optimization. However, previous works often require the availability of a
numeric score to assess the quality of every prompt. Unfortunately, when a
human user interacts with a black-box LLM, attaining such a score is often
infeasible and unreliable. Instead, it is usually significantly easier and more
reliable to obtain preference feedback from a human user, i.e., showing the
user the responses generated from a pair of prompts and asking the user which
one is preferred. Therefore, in this paper, we study the problem of prompt
optimization with human feedback (POHF), in which we aim to optimize the prompt
for a black-box LLM using only human preference feedback. Drawing inspiration
from dueling bandits, we design a theoretically principled strategy to select a
pair of prompts to query for preference feedback in every iteration, and hence
introduce our algorithm named automated POHF (APOHF). We apply our APOHF
algorithm to various tasks, including optimizing user instructions, prompt
optimization for text-to-image generative models, and response optimization
with human feedback (i.e., further refining the response using a variant of our
APOHF). The results demonstrate that our APOHF can efficiently find a good
prompt using a small number of preference feedback instances. Our code can be
found at \url{https://github.com/xqlin98/APOHF}.",2024-05-27,"Xiaoqiang Lin, Zhongxiang Dai, Arun Verma, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2405.17346v1,cs.LG
Physics-Informed Real NVP for Satellite Power System Fault Detection,"The unique challenges posed by the space environment, characterized by
extreme conditions and limited accessibility, raise the need for robust and
reliable techniques to identify and prevent satellite faults. Fault detection
methods in the space sector are required to ensure mission success and to
protect valuable assets. In this context, this paper proposes an Artificial
Intelligence (AI) based fault detection methodology and evaluates its
performance on ADAPT (Advanced Diagnostics and Prognostics Testbed), an
Electrical Power System (EPS) dataset, crafted in laboratory by NASA. Our study
focuses on the application of a physics-informed (PI) real-valued non-volume
preserving (Real NVP) model for fault detection in space systems. The efficacy
of this method is systematically compared against other AI approaches such as
Gated Recurrent Unit (GRU) and Autoencoder-based techniques. Results show that
our physics-informed approach outperforms existing methods of fault detection,
demonstrating its suitability for addressing the unique challenges of satellite
EPS sub-system faults. Furthermore, we unveil the competitive advantage of
physics-informed loss in AI models to address specific space needs, namely
robustness, reliability, and power constraints, crucial for space exploration
and satellite missions.",2024-05-27,"Carlo Cena, Umberto Albertin, Mauro Martini, Silvia Bucci, Marcello Chiaberge",http://arxiv.org/pdf/2405.17339v2,cs.LG
Conditioning on Time is All You Need for Synthetic Survival Data Generation,"Synthetic data generation holds considerable promise, offering avenues to
enhance privacy, fairness, and data accessibility. Despite the availability of
various methods for generating synthetic tabular data, challenges persist,
particularly in specialized applications such as survival analysis. One
significant obstacle in survival data generation is censoring, which manifests
as not knowing the precise timing of observed (target) events for certain
instances. Existing methods face difficulties in accurately reproducing the
real distribution of event times for both observed (uncensored) events and
censored events, i.e., the generated event-time distributions do not accurately
match the underlying distributions of the real data. So motivated, we propose a
simple paradigm to produce synthetic survival data by generating covariates
conditioned on event times (and censoring indicators), thus allowing one to
reuse existing conditional generative models for tabular data without
significant computational overhead, and without making assumptions about the
(usually unknown) generation mechanism underlying censoring. We evaluate this
method via extensive experiments on real-world datasets. Our methodology
outperforms multiple competitive baselines at generating survival data, while
improving the performance of downstream survival models trained on it and
tested on real data.",2024-05-27,"Mohd Ashhad, Ricardo Henao",http://arxiv.org/pdf/2405.17333v1,cs.LG
Clip Body and Tail Separately: High Probability Guarantees for DPSGD with Heavy Tails,"Differentially Private Stochastic Gradient Descent (DPSGD) is widely utilized
to preserve training data privacy in deep learning, which first clips the
gradients to a predefined norm and then injects calibrated noise into the
training procedure. Existing DPSGD works typically assume the gradients follow
sub-Gaussian distributions and design various clipping mechanisms to optimize
training performance. However, recent studies have shown that the gradients in
deep learning exhibit a heavy-tail phenomenon, that is, the tails of the
gradient have infinite variance, which may lead to excessive clipping loss to
the gradients with existing DPSGD mechanisms. To address this problem, we
propose a novel approach, Discriminative Clipping~(DC)-DPSGD, with two key
designs. First, we introduce a subspace identification technique to distinguish
between body and tail gradients. Second, we present a discriminative clipping
mechanism that applies different clipping thresholds for body and tail
gradients to reduce the clipping loss. Under the non-convex condition,
\ourtech{} reduces the empirical gradient norm from
{${\mathbb{O}\left(\log^{\max(0,\theta-1)}(T/\delta)\log^{2\theta}(\sqrt{T})\right)}$}
to {${\mathbb{O}\left(\log(\sqrt{T})\right)}$} with heavy-tailed index
$\theta\geq 1/2$, iterations $T$, and arbitrary probability $\delta$. Extensive
experiments on four real-world datasets demonstrate that our approach
outperforms three baselines by up to 9.72\% in terms of accuracy.",2024-05-27,"Haichao Sha, Yang Cao, Yong Liu, Yuncheng Wu, Ruixuan Liu, Hong Chen",http://arxiv.org/pdf/2405.17529v1,cs.LG
Novel Approaches for ML-Assisted Particle Track Reconstruction and Hit Clustering,"Track reconstruction is a vital aspect of High-Energy Physics (HEP) and plays
a critical role in major experiments. In this study, we delve into unexplored
avenues for particle track reconstruction and hit clustering. Firstly, we
enhance the algorithmic design effort by utilising a simplified simulator
(REDVID) to generate training data that is specifically composed for
simplicity. We demonstrate the effectiveness of this data in guiding the
development of optimal network architectures. Additionally, we investigate the
application of image segmentation networks for this task, exploring their
potential for accurate track reconstruction. Moreover, we approach the task
from a different perspective by treating it as a hit sequence to track sequence
translation problem. Specifically, we explore the utilisation of Transformer
architectures for tracking purposes. Our preliminary findings are covered in
detail. By considering this novel approach, we aim to uncover new insights and
potential advancements in track reconstruction. This research sheds light on
previously unexplored methods and provides valuable insights for the field of
particle track reconstruction and hit clustering in HEP.",2024-05-27,"Uraz Odyurt, Nadezhda Dobreva, Zef Wolffs, Yue Zhao, Antonio Ferrer Sánchez, Roberto Ruiz de Austri Bazan, José D. Martín-Guerrero, Ana-Lucia Varbanescu, Sascha Caron",http://arxiv.org/pdf/2405.17325v1,cs.LG
Leveraging Offline Data in Linear Latent Bandits,"Sequential decision-making domains such as recommender systems, healthcare
and education often have unobserved heterogeneity in the population that can be
modeled using latent bandits $-$ a framework where an unobserved latent state
determines the model for a trajectory. While the latent bandit framework is
compelling, the extent of its generality is unclear. We first address this by
establishing a de Finetti theorem for decision processes, and show that
$\textit{every}$ exchangeable and coherent stateless decision process is a
latent bandit. The latent bandit framework lends itself particularly well to
online learning with offline datasets, a problem of growing interest in
sequential decision-making. One can leverage offline latent bandit data to
learn a complex model for each latent state, so that an agent can simply learn
the latent state online to act optimally. We focus on a linear model for a
latent bandit with $d_A$-dimensional actions, where the latent states lie in an
unknown $d_K$-dimensional subspace for $d_K \ll d_A$. We present SOLD, a novel
principled method to learn this subspace from short offline trajectories with
guarantees. We then provide two methods to leverage this subspace online:
LOCAL-UCB and ProBALL-UCB. We demonstrate that LOCAL-UCB enjoys $\tilde
O(\min(d_A\sqrt{T}, d_K\sqrt{T}(1+\sqrt{d_AT/d_KN})))$ regret guarantees, where
the effective dimension is lower when the size $N$ of the offline dataset is
larger. ProBALL-UCB enjoys a slightly weaker guarantee, but is more practical
and computationally efficient. Finally, we establish the efficacy of our
methods using experiments on both synthetic data and real-life movie
recommendation data from MovieLens.",2024-05-27,"Chinmaya Kausik, Kevin Tan, Ambuj Tewari",http://arxiv.org/pdf/2405.17324v1,cs.LG
Probabilistic Graph Rewiring via Virtual Nodes,"Message-passing graph neural networks (MPNNs) have emerged as a powerful
paradigm for graph-based machine learning. Despite their effectiveness, MPNNs
face challenges such as under-reaching and over-squashing, where limited
receptive fields and structural bottlenecks hinder information flow in the
graph. While graph transformers hold promise in addressing these issues, their
scalability is limited due to quadratic complexity regarding the number of
nodes, rendering them impractical for larger graphs. Here, we propose
implicitly rewired message-passing neural networks (IPR-MPNNs), a novel
approach that integrates implicit probabilistic graph rewiring into MPNNs. By
introducing a small number of virtual nodes, i.e., adding additional nodes to a
given graph and connecting them to existing nodes, in a differentiable,
end-to-end manner, IPR-MPNNs enable long-distance message propagation,
circumventing quadratic complexity. Theoretically, we demonstrate that
IPR-MPNNs surpass the expressiveness of traditional MPNNs. Empirically, we
validate our approach by showcasing its ability to mitigate under-reaching and
over-squashing effects, achieving state-of-the-art performance across multiple
graph datasets. Notably, IPR-MPNNs outperform graph transformers while
maintaining significantly faster computational efficiency.",2024-05-27,"Chendi Qian, Andrei Manolache, Christopher Morris, Mathias Niepert",http://arxiv.org/pdf/2405.17311v3,cs.LG
Survey of Graph Neural Network for Internet of Things and NextG Networks,"The exponential increase in Internet of Things (IoT) devices coupled with 6G
pushing towards higher data rates and connected devices has sparked a surge in
data. Consequently, harnessing the full potential of data-driven machine
learning has become one of the important thrusts. In addition to the
advancement in wireless technology, it is important to efficiently use the
resources available and meet the users' requirements. Graph Neural Networks
(GNNs) have emerged as a promising paradigm for effectively modeling and
extracting insights which inherently exhibit complex network structures due to
its high performance and accuracy, scalability, adaptability, and resource
efficiency. There is a lack of a comprehensive survey that focuses on the
applications and advances GNN has made in the context of IoT and Next
Generation (NextG) networks. To bridge that gap, this survey starts by
providing a detailed description of GNN's terminologies, architecture, and the
different types of GNNs. Then we provide a comprehensive survey of the
advancements in applying GNNs for IoT from the perspective of data fusion and
intrusion detection. Thereafter, we survey the impact GNN has made in improving
spectrum awareness. Next, we provide a detailed account of how GNN has been
leveraged for networking and tactical systems. Through this survey, we aim to
provide a comprehensive resource for researchers to learn more about GNN in the
context of wireless networks, and understand its state-of-the-art use cases
while contrasting to other machine learning approaches. Finally, we also
discussed the challenges and wide range of future research directions to
further motivate the use of GNN for IoT and NextG Networks.",2024-05-27,"Sabarish Krishna Moorthy, Jithin Jagannath",http://arxiv.org/pdf/2405.17309v1,cs.LG
Simplicity Bias of Two-Layer Networks beyond Linearly Separable Data,"Simplicity bias, the propensity of deep models to over-rely on simple
features, has been identified as a potential reason for limited
out-of-distribution generalization of neural networks (Shah et al., 2020).
Despite the important implications, this phenomenon has been theoretically
confirmed and characterized only under strong dataset assumptions, such as
linear separability (Lyu et al., 2021). In this work, we characterize
simplicity bias for general datasets in the context of two-layer neural
networks initialized with small weights and trained with gradient flow.
Specifically, we prove that in the early training phases, network features
cluster around a few directions that do not depend on the size of the hidden
layer. Furthermore, for datasets with an XOR-like pattern, we precisely
identify the learned features and demonstrate that simplicity bias intensifies
during later training stages. These results indicate that features learned in
the middle stages of training may be more useful for OOD transfer. We support
this hypothesis with experiments on image data.",2024-05-27,"Nikita Tsoy, Nikola Konstantinov",http://arxiv.org/pdf/2405.17299v2,cs.LG
Efficient Ensembles Improve Training Data Attribution,"Training data attribution (TDA) methods aim to quantify the influence of
individual training data points on the model predictions, with broad
applications in data-centric AI, such as mislabel detection, data selection,
and copyright compensation. However, existing methods in this field, which can
be categorized as retraining-based and gradient-based, have struggled with the
trade-off between computational efficiency and attribution efficacy.
Retraining-based methods can accurately attribute complex non-convex models but
are computationally prohibitive, while gradient-based methods are efficient but
often fail for non-convex models. Recent research has shown that augmenting
gradient-based methods with ensembles of multiple independently trained models
can achieve significantly better attribution efficacy. However, this approach
remains impractical for very large-scale applications.
  In this work, we discover that expensive, fully independent training is
unnecessary for ensembling the gradient-based methods, and we propose two
efficient ensemble strategies, DROPOUT ENSEMBLE and LORA ENSEMBLE, alternative
to naive independent ensemble. These strategies significantly reduce training
time (up to 80%), serving time (up to 60%), and space cost (up to 80%) while
maintaining similar attribution efficacy to the naive independent ensemble. Our
extensive experimental results demonstrate that the proposed strategies are
effective across multiple TDA methods on diverse datasets and models, including
generative settings, significantly advancing the Pareto frontier of TDA methods
with better computational efficiency and attribution efficacy.",2024-05-27,"Junwei Deng, Ting-Wei Li, Shichang Zhang, Jiaqi Ma",http://arxiv.org/pdf/2405.17293v1,cs.LG
Opinion-Guided Reinforcement Learning,"Human guidance is often desired in reinforcement learning to improve the
performance of the learning agent. However, human insights are often mere
opinions and educated guesses rather than well-formulated arguments. While
opinions are subject to uncertainty, e.g., due to partial informedness or
ignorance about a problem, they also emerge earlier than hard evidence can be
produced. Thus, guiding reinforcement learning agents by way of opinions offers
the potential for more performant learning processes, but comes with the
challenge of modeling and managing opinions in a formal way. In this article,
we present a method to guide reinforcement learning agents through opinions. To
this end, we provide an end-to-end method to model and manage advisors'
opinions. To assess the utility of the approach, we evaluate it with synthetic
(oracle) and human advisors, at different levels of uncertainty, and under
multiple advice strategies. Our results indicate that opinions, even if
uncertain, improve the performance of reinforcement learning agents, resulting
in higher rewards, more efficient exploration, and a better reinforced policy.
Although we demonstrate our approach through a two-dimensional topological
running example, our approach is applicable to complex problems with higher
dimensions as well.",2024-05-27,"Kyanna Dagenais, Istvan David",http://arxiv.org/pdf/2405.17287v2,cs.LG
Recurrent Complex-Weighted Autoencoders for Unsupervised Object Discovery,"Current state-of-the-art synchrony-based models encode object bindings with
complex-valued activations and compute with real-valued weights in feedforward
architectures. We argue for the computational advantages of a recurrent
architecture with complex-valued weights. We propose a fully convolutional
autoencoder, SynCx, that performs iterative constraint satisfaction: at each
iteration, a hidden layer bottleneck encodes statistically regular
configurations of features in particular phase relationships; over iterations,
local constraints propagate and the model converges to a globally consistent
configuration of phase assignments. Binding is achieved simply by the
matrix-vector product operation between complex-valued weights and activations,
without the need for additional mechanisms that have been incorporated into
current synchrony-based models. SynCx outperforms or is strongly competitive
with current models for unsupervised object discovery. SynCx also avoids
certain systematic grouping errors of current models, such as the inability to
separate similarly colored objects without additional supervision.",2024-05-27,"Anand Gopalakrishnan, Aleksandar Stanić, Jürgen Schmidhuber, Michael Curtis Mozer",http://arxiv.org/pdf/2405.17283v3,cs.LG
R-ODE: Ricci Curvature Tells When You Will be Informed,"Information diffusion prediction is fundamental to understand the structure
and organization of the online social networks, and plays a crucial role to
blocking rumor spread, influence maximization, political propaganda, etc. So
far, most existing solutions primarily predict the next user who will be
informed with historical cascades, but ignore an important factor in the
diffusion process - the time. Such limitation motivates us to pose the problem
of the time-aware personalized information diffusion prediction for the first
time, telling the time when the target user will be informed. In this paper, we
address this problem from a fresh geometric perspective of Ricci curvature, and
propose a novel Ricci-curvature regulated Ordinary Differential Equation
(R-ODE). In the diffusion process, R-ODE considers that the inter-correlated
users are organized in a dynamic system in the representation space, and the
cascades give the observations sampled from the continuous realm. At each
infection time, the message diffuses along the largest Ricci curvature,
signifying less transportation effort. In the continuous realm, the message
triggers users' movement, whose trajectory in the space is parameterized by an
ODE with graph neural network. Consequently, R-ODE predicts the infection time
of a target user by the movement trajectory learnt from the observations.
Extensive experiments evaluate the personalized time prediction ability of
R-ODE, and show R-ODE outperforms the state-of-the-art baselines.",2024-05-27,"Li Sun, Jingbin Hu, Mengjie Li, Hao Peng",http://arxiv.org/pdf/2405.17282v1,cs.LG
Gradients of Functions of Large Matrices,"Tuning scientific and probabilistic machine learning models $-$ for example,
partial differential equations, Gaussian processes, or Bayesian neural networks
$-$ often relies on evaluating functions of matrices whose size grows with the
data set or the number of parameters. While the state-of-the-art for evaluating
these quantities is almost always based on Lanczos and Arnoldi iterations, the
present work is the first to explain how to differentiate these workhorses of
numerical linear algebra efficiently. To get there, we derive previously
unknown adjoint systems for Lanczos and Arnoldi iterations, implement them in
JAX, and show that the resulting code can compete with Diffrax when it comes to
differentiating PDEs, GPyTorch for selecting Gaussian process models and beats
standard factorisation methods for calibrating Bayesian neural networks. All
this is achieved without any problem-specific code optimisation. Find the code
at https://github.com/pnkraemer/experiments-lanczos-adjoints and install the
library with pip install matfree.",2024-05-27,"Nicholas Krämer, Pablo Moreno-Muñoz, Hrittik Roy, Søren Hauberg",http://arxiv.org/pdf/2405.17277v2,cs.LG
Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers,"Deep models have recently emerged as a promising tool to solve partial
differential equations (PDEs), known as neural PDE solvers. While neural
solvers trained from either simulation data or physics-informed loss can solve
PDEs reasonably well, they are mainly restricted to a few instances of PDEs,
e.g. a certain equation with a limited set of coefficients. This limits the
generalization of neural solvers to diverse PDEs, impeding them from being
practical surrogate models for numerical solvers. In this paper, we present the
Universal PDE Solver (Unisolver) capable of solving a wide scope of PDEs by
training a novel Transformer model on diverse data and conditioned on diverse
PDEs. Instead of purely scaling up data and parameters, Unisolver stems from
the theoretical analysis of the PDE-solving process. Our key finding is that a
PDE solution is fundamentally under the control of a series of PDE components,
e.g. equation symbols, coefficients, and boundary conditions. Inspired by the
mathematical structure of PDEs, we define a complete set of PDE components and
flexibly embed them as domain-wise (e.g. equation symbols) and point-wise (e.g.
boundaries) conditions for Transformer PDE solvers. Integrating physical
insights with recent Transformer advances, Unisolver achieves consistent
state-of-the-art results on three challenging large-scale benchmarks, showing
impressive performance gains and favorable PDE generalizability.",2024-05-27,"Hang Zhou, Yuezhou Ma, Haixu Wu, Haowen Wang, Mingsheng Long",http://arxiv.org/pdf/2405.17527v3,cs.LG
DPN: Decoupling Partition and Navigation for Neural Solvers of Min-max Vehicle Routing Problems,"The min-max vehicle routing problem (min-max VRP) traverses all given
customers by assigning several routes and aims to minimize the length of the
longest route. Recently, reinforcement learning (RL)-based sequential planning
methods have exhibited advantages in solving efficiency and optimality.
However, these methods fail to exploit the problem-specific properties in
learning representations, resulting in less effective features for decoding
optimal routes. This paper considers the sequential planning process of min-max
VRPs as two coupled optimization tasks: customer partition for different routes
and customer navigation in each route (i.e., partition and navigation). To
effectively process min-max VRP instances, we present a novel attention-based
Partition-and-Navigation encoder (P&N Encoder) that learns distinct embeddings
for partition and navigation. Furthermore, we utilize an inherent symmetry in
decoding routes and develop an effective agent-permutation-symmetric (APS) loss
function. Experimental results demonstrate that the proposed
Decoupling-Partition-Navigation (DPN) method significantly surpasses existing
learning-based methods in both single-depot and multi-depot min-max VRPs. Our
code is available at",2024-05-27,"Zhi Zheng, Shunyu Yao, Zhenkun Wang, Xialiang Tong, Mingxuan Yuan, Ke Tang",http://arxiv.org/pdf/2405.17272v2,cs.LG
FedHPL: Efficient Heterogeneous Federated Learning with Prompt Tuning and Logit Distillation,"Federated learning (FL) is a popular privacy-preserving paradigm that enables
distributed clients to collaboratively train models with a central server while
keeping raw data locally. In practice, distinct model architectures, varying
data distributions, and limited resources across local clients inevitably cause
model performance degradation and a slowdown in convergence speed. However,
existing FL methods can only solve some of the above heterogeneous challenges
and have obvious performance limitations. Notably, a unified framework has not
yet been explored to overcome these challenges. Accordingly, we propose FedHPL,
a parameter-efficient unified $\textbf{Fed}$erated learning framework for
$\textbf{H}$eterogeneous settings based on $\textbf{P}$rompt tuning and
$\textbf{L}$ogit distillation. Specifically, we employ a local prompt tuning
scheme that leverages a few learnable visual prompts to efficiently fine-tune
the frozen pre-trained foundation model for downstream tasks, thereby
accelerating training and improving model performance under limited local
resources and data heterogeneity. Moreover, we design a global logit
distillation scheme to handle the model heterogeneity and guide the local
training. In detail, we leverage logits to implicitly capture local knowledge
and design a weighted knowledge aggregation mechanism to generate global
client-specific logits. We provide a theoretical guarantee on the
generalization error bound for FedHPL. The experiments on various benchmark
datasets under diverse settings of models and data demonstrate that our
framework outperforms state-of-the-art FL approaches, with less computation
overhead and training rounds.",2024-05-27,"Yuting Ma, Lechao Cheng, Yaxiong Wang, Zhun Zhong, Xiaohua Xu, Meng Wang",http://arxiv.org/pdf/2405.17267v1,cs.LG
On the Noise Robustness of In-Context Learning for Text Generation,"Large language models (LLMs) have shown impressive performance on downstream
tasks by in-context learning (ICL), which heavily relies on the quality of
demonstrations selected from a large set of annotated examples. Recent works
claim that in-context learning is robust to noisy demonstrations in text
classification. In this work, we show that, on text generation tasks, noisy
annotations significantly hurt the performance of in-context learning. To
circumvent the issue, we propose a simple and effective approach called Local
Perplexity Ranking (LPR), which replaces the ""noisy"" candidates with their
nearest neighbors that are more likely to be clean. Our method is motivated by
analyzing the perplexity deviation caused by noisy labels and decomposing
perplexity into inherent perplexity and matching perplexity. Our key idea
behind LPR is thus to decouple the matching perplexity by performing the
ranking among the neighbors in semantic space. Our approach can prevent the
selected demonstrations from including mismatched input-label pairs while
preserving the effectiveness of the original selection methods. Extensive
experiments demonstrate the effectiveness of LPR, improving the EM score by up
to 18.75 on common benchmarks with noisy annotations. Our code is available at
https://github.com/ml-stat-Sustech/Local-Perplexity-Ranking.",2024-05-27,"Hongfu Gao, Feipeng Zhang, Wenyu Jiang, Jun Shu, Feng Zheng, Hongxin Wei",http://arxiv.org/pdf/2405.17264v3,cs.LG
Accelerating Simulation of Two-Phase Flows with Neural PDE Surrogates,"Simulation is a powerful tool to better understand physical systems, but
generally requires computationally expensive numerical methods. Downstream
applications of such simulations can become computationally infeasible if they
require many forward solves, for example in the case of inverse design with
many degrees of freedom. In this work, we investigate and extend neural PDE
solvers as a tool to aid in scaling simulations for two-phase flow problems,
and simulations of oil expulsion from a pore specifically. We extend existing
numerical methods for this problem to a more complex setting involving varying
geometries of the domain to generate a challenging dataset. Further, we
investigate three prominent neural PDE solver methods, namely the UNet, DRN,
and U-FNO, and extend them for characteristics of the oil-expulsion problem:
(1) spatial conditioning on the geometry; (2) periodicity in the boundary; (3)
approximate mass conservation. We scale all methods and benchmark their
speed-accuracy trade-off, evaluate qualitative properties, and perform an
ablation study. We find that the investigated methods can accurately model the
droplet dynamics with up to three orders of magnitude speed-up, that our
extensions improve performance over the baselines, and that the introduced
varying geometries constitute a significantly more challenging setting over the
previously considered oil expulsion problem.",2024-05-27,"Yoeri Poels, Koen Minartz, Harshit Bansal, Vlado Menkovski",http://arxiv.org/pdf/2405.17260v2,cs.LG
$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning,"Low-rank adapters (LoRA) and their variants are popular parameter-efficient
fine-tuning (PEFT) techniques that closely match full model fine-tune
performance while requiring only a small number of additional parameters. These
additional LoRA parameters are specific to the base model being adapted. When
the base model needs to be deprecated and replaced with a new one, all the
associated LoRA modules need to be re-trained. Such re-training requires access
to the data used to train the LoRA for the original base model. This is
especially problematic for commercial cloud applications where the LoRA modules
and the base models are hosted by service providers who may not be allowed to
host proprietary client task data. To address this challenge, we propose
$\textit{Trans-LoRA}$ -- a novel method for lossless, nearly data-free transfer
of LoRAs across base models. Our approach relies on synthetic data to transfer
LoRA modules. Using large language models, we design a synthetic data generator
to approximate the data-generating process of the $\textit{observed}$ task data
subset. Training on the resulting synthetic dataset transfers LoRA modules to
new models. We show the effectiveness of our approach using both LLama and
Gemma model families. Our approach achieves lossless (mostly improved) LoRA
transfer between models within and across different base model families, and
even between different PEFT methods, on a wide variety of tasks.",2024-05-27,"Runqian Wang, Soumya Ghosh, David Cox, Diego Antognini, Aude Oliva, Rogerio Feris, Leonid Karlinsky",http://arxiv.org/pdf/2405.17258v1,cs.LG
Gaussian Embedding of Temporal Networks,"Representing the nodes of continuous-time temporal graphs in a
low-dimensional latent space has wide-ranging applications, from prediction to
visualization. Yet, analyzing continuous-time relational data with timestamped
interactions introduces unique challenges due to its sparsity. Merely embedding
nodes as trajectories in the latent space overlooks this sparsity, emphasizing
the need to quantify uncertainty around the latent positions. In this paper, we
propose TGNE (\textbf{T}emporal \textbf{G}aussian \textbf{N}etwork
\textbf{E}mbedding), an innovative method that bridges two distinct strands of
literature: the statistical analysis of networks via Latent Space Models
(LSM)\cite{Hoff2002} and temporal graph machine learning. TGNE embeds nodes as
piece-wise linear trajectories of Gaussian distributions in the latent space,
capturing both structural information and uncertainty around the trajectories.
We evaluate TGNE's effectiveness in reconstructing the original graph and
modelling uncertainty. The results demonstrate that TGNE generates competitive
time-varying embedding locations compared to common baselines for
reconstructing unobserved edge interactions based on observed edges.
Furthermore, the uncertainty estimates align with the time-varying degree
distribution in the network, providing valuable insights into the temporal
dynamics of the graph. To facilitate reproducibility, we provide an open-source
implementation of TGNE at \url{https://github.com/aida-ugent/tgne}.",2024-05-27,"Raphaël Romero, Jefrey Lijffijt, Riccardo Rastelli, Marco Corneli, Tijl De Bie",http://arxiv.org/pdf/2405.17253v1,cs.LG
On Understanding Attention-Based In-Context Learning for Categorical Data,"In-context learning based on attention models is examined for data with
categorical outcomes, with inference in such models viewed from the perspective
of functional gradient descent (GD). We develop a network composed of attention
blocks, with each block employing a self-attention layer followed by a
cross-attention layer, with associated skip connections. This model can exactly
perform multi-step functional GD inference for in-context inference with
categorical observations. We perform a theoretical analysis of this setup,
generalizing many prior assumptions in this line of work, including the class
of attention mechanisms for which it is appropriate. We demonstrate the
framework empirically on synthetic data, image classification and language
generation.",2024-05-27,"Aaron T. Wang, William Convertino, Xiang Cheng, Ricardo Henao, Lawrence Carin",http://arxiv.org/pdf/2405.17248v2,cs.LG
An Introduction to Vision-Language Modeling,"Following the recent popularity of Large Language Models (LLMs), several
attempts have been made to extend them to the visual domain. From having a
visual assistant that could guide us through unfamiliar environments to
generative models that produce images using only a high-level text description,
the vision-language model (VLM) applications will significantly impact our
relationship with technology. However, there are many challenges that need to
be addressed to improve the reliability of those models. While language is
discrete, vision evolves in a much higher dimensional space in which concepts
cannot always be easily discretized. To better understand the mechanics behind
mapping vision to language, we present this introduction to VLMs which we hope
will help anyone who would like to enter the field. First, we introduce what
VLMs are, how they work, and how to train them. Then, we present and discuss
approaches to evaluate VLMs. Although this work primarily focuses on mapping
images to language, we also discuss extending VLMs to videos.",2024-05-27,"Florian Bordes, Richard Yuanzhe Pang, Anurag Ajay, Alexander C. Li, Adrien Bardes, Suzanne Petryk, Oscar Mañas, Zhiqiu Lin, Anas Mahmoud, Bargav Jayaraman, Mark Ibrahim, Melissa Hall, Yunyang Xiong, Jonathan Lebensold, Candace Ross, Srihari Jayakumar, Chuan Guo, Diane Bouchacourt, Haider Al-Tahan, Karthik Padthe, Vasu Sharma, Hu Xu, Xiaoqing Ellen Tan, Megan Richards, Samuel Lavoie, Pietro Astolfi, Reyhane Askari Hemmat, Jun Chen, Kushal Tirumala, Rim Assouel, Mazda Moayeri, Arjang Talattof, Kamalika Chaudhuri, Zechun Liu, Xilun Chen, Quentin Garrido, Karen Ullrich, Aishwarya Agrawal, Kate Saenko, Asli Celikyilmaz, Vikas Chandra",http://arxiv.org/pdf/2405.17247v1,cs.LG
Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ Transformer Inference,"Transformer-based models have unlocked a plethora of powerful intelligent
applications at the edge, such as voice assistant in smart home. Traditional
deployment approaches offload the inference workloads to the remote cloud
server, which would induce substantial pressure on the backbone network as well
as raise users' privacy concerns. To address that, in-situ inference has been
recently recognized for edge intelligence, but it still confronts significant
challenges stemming from the conflict between intensive workloads and limited
on-device computing resources. In this paper, we leverage our observation that
many edge environments usually comprise a rich set of accompanying trusted edge
devices with idle resources and propose Galaxy, a collaborative edge AI system
that breaks the resource walls across heterogeneous edge devices for efficient
Transformer inference acceleration. Galaxy introduces a novel hybrid model
parallelism to orchestrate collaborative inference, along with a
heterogeneity-aware parallelism planning for fully exploiting the resource
potential. Furthermore, Galaxy devises a tile-based fine-grained overlapping of
communication and computation to mitigate the impact of tensor synchronizations
on inference latency under bandwidth-constrained edge environments. Extensive
evaluation based on prototype implementation demonstrates that Galaxy
remarkably outperforms state-of-the-art approaches under various edge
environment setups, achieving up to 2.5x end-to-end latency reduction.",2024-05-27,"Shengyuan Ye, Jiangsu Du, Liekang Zeng, Wenzhong Ou, Xiaowen Chu, Yutong Lu, Xu Chen",http://arxiv.org/pdf/2405.17245v1,cs.LG
Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement Learning,"Both entropy-minimizing and entropy-maximizing (curiosity) objectives for
unsupervised reinforcement learning (RL) have been shown to be effective in
different environments, depending on the environment's level of natural
entropy. However, neither method alone results in an agent that will
consistently learn intelligent behavior across environments. In an effort to
find a single entropy-based method that will encourage emergent behaviors in
any environment, we propose an agent that can adapt its objective online,
depending on the entropy conditions by framing the choice as a multi-armed
bandit problem. We devise a novel intrinsic feedback signal for the bandit,
which captures the agent's ability to control the entropy in its environment.
We demonstrate that such agents can learn to control entropy and exhibit
emergent behaviors in both high- and low-entropy regimes and can learn skillful
behaviors in benchmark tasks. Videos of the trained agents and summarized
findings can be found on our project page
https://sites.google.com/view/surprise-adaptive-agents",2024-05-27,"Adriana Hugessen, Roger Creus Castanyer, Faisal Mohamed, Glen Berseth",http://arxiv.org/pdf/2405.17243v2,cs.LG
Benchmarking General-Purpose In-Context Learning,"In-context learning (ICL) empowers generative models to address new tasks
effectively and efficiently on the fly, without relying on any artificially
crafted optimization techniques. In this paper, we study extending ICL to
address a broader range of tasks with an extended learning horizon and higher
improvement potential, namely General Purpose In-Context Learning (GPICL). To
this end, we introduce two lightweight benchmarks specifically crafted to train
and evaluate GPICL functionalities. Each benchmark encompasses a vast number of
tasks characterized by significant task variance. These tasks are also crafted
to promote long-horizon in-context learning through continuous generation and
interaction, covering domains such as language modeling, decision-making, and
world modeling. The benchmarks necessitate the models to leverage contexts and
history interactions to enhance their capabilities, which we believe to be the
key characteristics of GPICL. Our experiments indicate that the diversity of
training tasks is positively correlated with the ability to generalize with
ICL, but inversely correlated with zero-shot capabilities. Additionally, our
findings indicate that the scale of parameters alone may not be crucial for ICL
or GPICL, suggesting alternative approaches such as increasing the scale of
contexts and memory states.",2024-05-27,"Fan Wang, Chuan Lin, Yang Cao, Yu Kang",http://arxiv.org/pdf/2405.17234v6,cs.LG
CLAQ: Pushing the Limits of Low-Bit Post-Training Quantization for LLMs,"Parameter quantization for Large Language Models (LLMs) has attracted
increasing attentions recently in reducing memory costs and improving
computational efficiency. Early approaches have been widely adopted. However,
the existing methods suffer from poor performance in low-bit (such as 2 to 3
bits) scenarios. In this paper, we present a novel and effective Column-Level
Adaptive weight Quantization (CLAQ) framework by introducing three different
types of adaptive strategies for LLM quantization. Firstly, a K-Means
clustering based algorithm is proposed that allows dynamic generation of
quantization centroids for each column of a parameter matrix. Secondly, we
design an outlier-guided adaptive precision search strategy which can
dynamically assign varying bit-widths to different columns. Finally, a dynamic
outlier reservation scheme is developed to retain some parameters in their
original float point precision, in trade off of boosted model performance.
Experiments on various mainstream open source LLMs including LLaMA-1, LLaMA-2
and Yi demonstrate that our methods achieve the state-of-the-art results across
different bit settings, especially in extremely low-bit scenarios. Code is
available at https://github.com/fayuge/CLAQ.",2024-05-27,"Haoyu Wang, Bei Liu, Hang Shao, Bo Xiao, Ke Zeng, Guanglu Wan, Yanmin Qian",http://arxiv.org/pdf/2405.17233v2,cs.LG
A Retrospective of the Tutorial on Opportunities and Challenges of Online Deep Learning,"Machine learning algorithms have become indispensable in today's world. They
support and accelerate the way we make decisions based on the data at hand.
This acceleration means that data structures that were valid at one moment
could no longer be valid in the future. With these changing data structures, it
is necessary to adapt machine learning (ML) systems incrementally to the new
data. This is done with the use of online learning or continuous ML
technologies. While deep learning technologies have shown exceptional
performance on predefined datasets, they have not been widely applied to
online, streaming, and continuous learning. In this retrospective of our
tutorial titled Opportunities and Challenges of Online Deep Learning held at
ECML PKDD 2023, we provide a brief overview of the opportunities but also the
potential pitfalls for the application of neural networks in online learning
environments using the frameworks River and Deep-River.",2024-05-27,"Cedric Kulbach, Lucas Cazzonelli, Hoang-Anh Ngo, Minh-Huong Le-Nguyen, Albert Bifet",http://arxiv.org/pdf/2405.17222v2,cs.LG
Autoformalizing Euclidean Geometry,"Autoformalization involves automatically translating informal math into
formal theorems and proofs that are machine-verifiable. Euclidean geometry
provides an interesting and controllable domain for studying autoformalization.
In this paper, we introduce a neuro-symbolic framework for autoformalizing
Euclidean geometry, which combines domain knowledge, SMT solvers, and large
language models (LLMs). One challenge in Euclidean geometry is that informal
proofs rely on diagrams, leaving gaps in texts that are hard to formalize. To
address this issue, we use theorem provers to fill in such diagrammatic
information automatically, so that the LLM only needs to autoformalize the
explicit textual steps, making it easier for the model. We also provide
automatic semantic evaluation for autoformalized theorem statements. We
construct LeanEuclid, an autoformalization benchmark consisting of problems
from Euclid's Elements and the UniGeo dataset formalized in the Lean proof
assistant. Experiments with GPT-4 and GPT-4V show the capability and
limitations of state-of-the-art LLMs on autoformalizing geometry problems. The
data and code are available at https://github.com/loganrjmurphy/LeanEuclid.",2024-05-27,"Logan Murphy, Kaiyu Yang, Jialiang Sun, Zhaoyu Li, Anima Anandkumar, Xujie Si",http://arxiv.org/pdf/2405.17216v1,cs.LG
Spectral-Refiner: Accurate Fine-Tuning of Spatiotemporal Fourier Neural Operator for Turbulent Flows,"Recent advancements in operator-type neural networks have shown promising
results in approximating the solutions of spatiotemporal Partial Differential
Equations (PDEs). However, these neural networks often entail considerable
training expenses, and may not always achieve the desired accuracy required in
many scientific and engineering disciplines. In this paper, we propose a new
learning framework to address these issues. A new spatiotemporal adaptation is
proposed to generalize any Fourier Neural Operator (FNO) variant to learn maps
between Bochner spaces, which can perform an arbitrary-length temporal
super-resolution for the first time. To better exploit this capacity, a new
paradigm is proposed to refine the commonly adopted end-to-end neural operator
training and evaluations with the help from the wisdom from traditional
numerical PDE theory and techniques. Specifically, in the learning problems for
the turbulent flow modeled by the Navier-Stokes Equations (NSE), the proposed
paradigm trains an FNO only for a few epochs. Then, only the newly proposed
spatiotemporal spectral convolution layer is fine-tuned without the frequency
truncation. The spectral fine-tuning loss function uses a negative Sobolev norm
for the first time in operator learning, defined through a reliable
functional-type a posteriori error estimator whose evaluation is exact thanks
to the Parseval identity. Moreover, unlike the difficult nonconvex optimization
problems in the end-to-end training, this fine-tuning loss is convex. Numerical
experiments on commonly used NSE benchmarks demonstrate significant
improvements in both computational efficiency and accuracy, compared to
end-to-end evaluation and traditional numerical PDE solvers under certain
conditions. The source code is publicly available at
https://github.com/scaomath/torch-cfd.",2024-05-27,"Shuhao Cao, Francesco Brarda, Ruipeng Li, Yuanzhe Xi",http://arxiv.org/pdf/2405.17211v3,cs.LG
Efficient multi-prompt evaluation of LLMs,"Most popular benchmarks for comparing LLMs rely on a limited set of prompt
templates, which may not fully capture the LLMs' abilities and can affect the
reproducibility of results on leaderboards. Many recent works empirically
verify prompt sensitivity and advocate for changes in LLM evaluation. In this
paper, we consider the problem of estimating the performance distribution
across many prompt variants instead of finding a single prompt to evaluate
with. We introduce PromptEval, a method for estimating performance across a
large set of prompts borrowing strength across prompts and examples to produce
accurate estimates under practical evaluation budgets. The resulting
distribution can be used to obtain performance quantiles to construct various
robust performance metrics (e.g., top 95% quantile or median). We prove that
PromptEval consistently estimates the performance distribution and demonstrate
its efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench
Hard, and LMentry; for example, PromptEval can accurately estimate performance
quantiles across 100 prompt templates on MMLU with a budget equivalent to two
single-prompt evaluations. Moreover, we show how PromptEval can be useful in
LLM-as-a-judge and best prompt identification applications.",2024-05-27,"Felipe Maia Polo, Ronald Xu, Lucas Weber, Mírian Silva, Onkar Bhardwaj, Leshem Choshen, Allysson Flavio Melo de Oliveira, Yuekai Sun, Mikhail Yurochkin",http://arxiv.org/pdf/2405.17202v3,cs.LG
SmoothGNN: Smoothing-aware GNN for Unsupervised Node Anomaly Detection,"The smoothing issue in graph learning leads to indistinguishable node
representations, posing significant challenges for graph-related tasks.
However, our experiments reveal that this problem can uncover underlying
properties of node anomaly detection (NAD) that previous research has missed.
We introduce Individual Smoothing Patterns (ISP) and Neighborhood Smoothing
Patterns (NSP), which indicate that the representations of anomalous nodes are
harder to smooth than those of normal ones. In addition, we explore the
theoretical implications of these patterns, demonstrating the potential
benefits of ISP and NSP for NAD tasks. Motivated by these findings, we propose
SmoothGNN, a novel unsupervised NAD framework. First, we design a learning
component to explicitly capture ISP for detecting node anomalies. Second, we
design a spectral graph neural network to implicitly learn ISP to enhance
detection. Third, we design an effective coefficient based on our findings that
NSP can serve as coefficients for node representations, aiding in the
identification of anomalous nodes. Furthermore, we devise a novel anomaly
measure to calculate loss functions and anomalous scores for nodes, reflecting
the properties of NAD using ISP and NSP. Extensive experiments on 9 real
datasets show that SmoothGNN outperforms the best rival by an average of 14.66%
in AUC and 7.28% in Average Precision, with 75x running time speedup,
validating the effectiveness and efficiency of our framework.",2024-05-27,"Xiangyu Dong, Xingyi Zhang, Yanni Sun, Lei Chen, Mingxuan Yuan, Sibo Wang",http://arxiv.org/pdf/2405.17525v2,cs.LG
Convex Relaxation for Solving Large-Margin Classifiers in Hyperbolic Space,"Hyperbolic spaces have increasingly been recognized for their outstanding
performance in handling data with inherent hierarchical structures compared to
their Euclidean counterparts. However, learning in hyperbolic spaces poses
significant challenges. In particular, extending support vector machines to
hyperbolic spaces is in general a constrained non-convex optimization problem.
Previous and popular attempts to solve hyperbolic SVMs, primarily using
projected gradient descent, are generally sensitive to hyperparameters and
initializations, often leading to suboptimal solutions. In this work, by first
rewriting the problem into a polynomial optimization, we apply semidefinite
relaxation and sparse moment-sum-of-squares relaxation to effectively
approximate the optima. From extensive empirical experiments, these methods are
shown to perform better than the projected gradient descent approach.",2024-05-27,"Sheng Yang, Peihan Liu, Cengiz Pehlevan",http://arxiv.org/pdf/2405.17198v1,cs.LG
Spectral regularization for adversarially-robust representation learning,"The vulnerability of neural network classifiers to adversarial attacks is a
major obstacle to their deployment in safety-critical applications.
Regularization of network parameters during training can be used to improve
adversarial robustness and generalization performance. Usually, the network is
regularized end-to-end, with parameters at all layers affected by
regularization. However, in settings where learning representations is key,
such as self-supervised learning (SSL), layers after the feature representation
will be discarded when performing inference. For these models, regularizing up
to the feature space is more suitable. To this end, we propose a new spectral
regularizer for representation learning that encourages black-box adversarial
robustness in downstream classification tasks. In supervised classification
settings, we show empirically that this method is more effective in boosting
test accuracy and robustness than previously-proposed methods that regularize
all layers of the network. We then show that this method improves the
adversarial robustness of classifiers using representations learned with
self-supervised training or transferred from another classification task. In
all, our work begins to unveil how representational structure affects
adversarial robustness.",2024-05-27,"Sheng Yang, Jacob A. Zavatone-Veth, Cengiz Pehlevan",http://arxiv.org/pdf/2405.17181v1,cs.LG
Forecasting Four Business Cycle Phases Using Machine Learning: A Case Study of US and EuroZone,"Understanding the business cycle is crucial for building economic stability,
guiding business planning, and informing investment decisions. The business
cycle refers to the recurring pattern of expansion and contraction in economic
activity over time. Economic analysis is inherently complex, incorporating a
myriad of factors (such as macroeconomic indicators, political decisions). This
complexity makes it challenging to fully account for all variables when
determining the current state of the economy and predicting its future
trajectory in the upcoming months. The objective of this study is to
investigate the capacity of machine learning models in automatically analyzing
the state of the economic, with the goal of forecasting business phases
(expansion, slowdown, recession and recovery) in the United States and the
EuroZone. We compared three different machine learning approaches to classify
the phases of the business cycle, and among them, the Multinomial Logistic
Regression (MLR) achieved the best results. Specifically, MLR got the best
results by achieving the accuracy of 65.25% (Top1) and 84.74% (Top2) for the
EuroZone and 75% (Top1) and 92.14% (Top2) for the United States. These results
demonstrate the potential of machine learning techniques to predict business
cycles accurately, which can aid in making informed decisions in the fields of
economics and finance.",2024-05-27,"Elvys Linhares Pontes, Mohamed Benjannet, Raymond Yung",http://arxiv.org/pdf/2405.17170v2,cs.LG
WeiPer: OOD Detection using Weight Perturbations of Class Projections,"Recent advances in out-of-distribution (OOD) detection on image data show
that pre-trained neural network classifiers can separate in-distribution (ID)
from OOD data well, leveraging the class-discriminative ability of the model
itself. Methods have been proposed that either use logit information directly
or that process the model's penultimate layer activations. With ""WeiPer"", we
introduce perturbations of the class projections in the final fully connected
layer which creates a richer representation of the input. We show that this
simple trick can improve the OOD detection performance of a variety of methods
and additionally propose a distance-based method that leverages the properties
of the augmented WeiPer space. We achieve state-of-the-art OOD detection
results across multiple benchmarks of the OpenOOD framework, especially
pronounced in difficult settings in which OOD samples are positioned close to
the training set distribution. We support our findings with theoretical
motivations and empirical observations, and run extensive ablations to provide
insights into why WeiPer works.",2024-05-27,"Maximilian Granz, Manuel Heurich, Tim Landgraf",http://arxiv.org/pdf/2405.17164v2,cs.LG
Port-Hamiltonian Architectural Bias for Long-Range Propagation in Deep Graph Networks,"The dynamics of information diffusion within graphs is a critical open issue
that heavily influences graph representation learning, especially when
considering long-range propagation. This calls for principled approaches that
control and regulate the degree of propagation and dissipation of information
throughout the neural flow. Motivated by this, we introduce (port-)Hamiltonian
Deep Graph Networks, a novel framework that models neural information flow in
graphs by building on the laws of conservation of Hamiltonian dynamical
systems. We reconcile under a single theoretical and practical framework both
non-dissipative long-range propagation and non-conservative behaviors,
introducing tools from mechanical systems to gauge the equilibrium between the
two components. Our approach can be applied to general message-passing
architectures, and it provides theoretical guarantees on information
conservation in time. Empirical results prove the effectiveness of our
port-Hamiltonian scheme in pushing simple graph convolutional architectures to
state-of-the-art performance in long-range benchmarks.",2024-05-27,"Simon Heilig, Alessio Gravina, Alessandro Trenta, Claudio Gallicchio, Davide Bacciu",http://arxiv.org/pdf/2405.17163v2,cs.LG
The Scaling Law in Stellar Light Curves,"Analyzing time series of fluxes from stars, known as stellar light curves,
can reveal valuable information about stellar properties. However, most current
methods rely on extracting summary statistics, and studies using deep learning
have been limited to supervised approaches. In this research, we investigate
the scaling law properties that emerge when learning from astronomical time
series data using self-supervised techniques. By employing the GPT-2
architecture, we show the learned representation improves as the number of
parameters increases from $10^4$ to $10^9$, with no signs of performance
plateauing. We demonstrate that a self-supervised Transformer model achieves
3-10 times the sample efficiency compared to the state-of-the-art supervised
learning model when inferring the surface gravity of stars as a downstream
task. Our research lays the groundwork for analyzing stellar light curves by
examining them through large-scale auto-regressive generative models.",2024-05-27,"Jia-Shu Pan, Yuan-Sen Ting, Yang Huang, Jie Yu, Ji-Feng Liu",http://arxiv.org/pdf/2405.17156v2,cs.LG
Smoke and Mirrors in Causal Downstream Tasks,"Machine Learning and AI have the potential to transform data-driven
scientific discovery, enabling accurate predictions for several scientific
phenomena. As many scientific questions are inherently causal, this paper looks
at the causal inference task of treatment effect estimation, where the outcome
of interest is recorded in high-dimensional observations in a Randomized
Controlled Trial (RCT). Despite being the simplest possible causal setting and
a perfect fit for deep learning, we theoretically find that many common choices
in the literature may lead to biased estimates. To test the practical impact of
these considerations, we recorded ISTAnt, the first real-world benchmark for
causal inference downstream tasks on high-dimensional observations as an RCT
studying how garden ants (Lasius neglectus) respond to microparticles applied
onto their colony members by hygienic grooming. Comparing 6 480 models
fine-tuned from state-of-the-art visual backbones, we find that the sampling
and modeling choices significantly affect the accuracy of the causal estimate,
and that classification accuracy is not a proxy thereof. We further validated
the analysis, repeating it on a synthetically generated visual data set
controlling the causal model. Our results suggest that future benchmarks should
carefully consider real downstream scientific questions, especially causal
ones. Further, we highlight guidelines for representation learning methods to
help answer causal questions in the sciences.",2024-05-27,"Riccardo Cadei, Lukas Lindorfer, Sylvia Cremer, Cordelia Schmid, Francesco Locatello",http://arxiv.org/pdf/2405.17151v4,cs.LG
Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive Backbone Ensembling,"Contrastive Language-Image Pretraining (CLIP) stands out as a prominent
method for image representation learning. Various architectures, from vision
transformers (ViTs) to convolutional networks (ResNets) have been trained with
CLIP to serve as general solutions to diverse vision tasks. This paper explores
the differences across various CLIP-trained vision backbones. Despite using the
same data and training objective, we find that these architectures have notably
different representations, different classification performance across
datasets, and different robustness properties to certain types of image
perturbations. Our findings indicate a remarkable possible synergy across
backbones by leveraging their respective strengths. In principle,
classification accuracy could be improved by over 40 percentage with an
informed selection of the optimal backbone per test example.Using this insight,
we develop a straightforward yet powerful approach to adaptively ensemble
multiple backbones. The approach uses as few as one labeled example per class
to tune the adaptive combination of backbones. On a large collection of
datasets, the method achieves a remarkable increase in accuracy of up to 39.1%
over the best single backbone, well beyond traditional ensembles",2024-05-27,"Cristian Rodriguez-Opazo, Ehsan Abbasnejad, Damien Teney, Hamed Damirchi, Edison Marrese-Taylor, Anton van den Hengel",http://arxiv.org/pdf/2405.17139v2,cs.LG
Locally Testing Model Detections for Semantic Global Concepts,"Ensuring the quality of black-box Deep Neural Networks (DNNs) has become ever
more significant, especially in safety-critical domains such as automated
driving. While global concept encodings generally enable a user to test a model
for a specific concept, linking global concept encodings to the local
processing of single network inputs reveals their strengths and limitations.
Our proposed framework global-to-local Concept Attribution (glCA) uses
approaches from local (why a specific prediction originates) and global (how a
model works generally) eXplainable Artificial Intelligence (xAI) to test DNNs
for a predefined semantical concept locally. The approach allows for
conditioning local, post-hoc explanations on predefined semantic concepts
encoded as linear directions in the model's latent space. Pixel-exact scoring
concerning the global concept usage assists the tester in further understanding
the model processing of single data points for the selected concept. Our
approach has the advantage of fully covering the model-internal encoding of the
semantic concept and allowing the localization of relevant concept-related
information. The results show major differences in the local perception and
usage of individual global concept encodings and demand for further
investigations regarding obtaining thorough semantic concept encodings.",2024-05-27,"Franz Motzkus, Georgii Mikriukov, Christian Hellert, Ute Schmid",http://arxiv.org/pdf/2405.17523v2,cs.LG
Your decision path does matter in pre-training industrial recommenders with multi-source behaviors,"Online service platforms offering a wide range of services through miniapps
have become crucial for users who visit these platforms with clear intentions
to find services they are interested in. Aiming at effective content delivery,
cross-domain recommendation are introduced to learn high-quality
representations by transferring behaviors from data-rich scenarios. However,
these methods overlook the impact of the decision path that users take when
conduct behaviors, that is, users ultimately exhibit different behaviors based
on various intents. To this end, we propose HIER, a novel Hierarchical decIsion
path Enhanced Representation learning for cross-domain recommendation. With the
help of graph neural networks for high-order topological information of the
knowledge graph between multi-source behaviors, we further adaptively learn
decision paths through well-designed exemplar-level and information bottleneck
based contrastive learning. Extensive experiments in online and offline
environments show the superiority of HIER.",2024-05-27,"Chunjing Gan, Binbin Hu, Bo Huang, Ziqi Liu, Jian Ma, Zhiqiang Zhang, Wenliang Zhong, Jun Zhou",http://arxiv.org/pdf/2405.17132v1,cs.LG
Explaining the role of Intrinsic Dimensionality in Adversarial Training,"Adversarial Training (AT) impacts different architectures in distinct ways:
vision models gain robustness but face reduced generalization, encoder-based
models exhibit limited robustness improvements with minimal generalization
loss, and recent work in latent-space adversarial training (LAT) demonstrates
that decoder-based models achieve improved robustness by applying AT across
multiple layers. We provide the first explanation for these trends by
leveraging the manifold conjecture: off-manifold adversarial examples (AEs)
enhance robustness, while on-manifold AEs improve generalization. We show that
vision and decoder-based models exhibit low intrinsic dimensionality in earlier
layers (favoring off-manifold AEs), whereas encoder-based models do so in later
layers (favoring on-manifold AEs). Exploiting this property, we introduce
SMAAT, which improves the scalability of AT for encoder-based models by
perturbing the layer with the lowest intrinsic dimensionality. This reduces the
projected gradient descent (PGD) chain length required for AE generation,
cutting GPU time by 25-33% while significantly boosting robustness. We validate
SMAAT across multiple tasks, including text generation, sentiment
classification, safety filtering, and retrieval augmented generation setups,
demonstrating superior robustness with comparable generalization to standard
training.",2024-05-27,"Enes Altinisik, Safa Messaoud, Husrev Taha Sencar, Hassan Sajjad, Sanjay Chawla",http://arxiv.org/pdf/2405.17130v2,cs.LG
Dual VC Dimension Obstructs Sample Compression by Embeddings,"This work studies embedding of arbitrary VC classes in well-behaved VC
classes, focusing particularly on extremal classes. Our main result expresses
an impossibility: such embeddings necessarily require a significant increase in
dimension. In particular, we prove that for every $d$ there is a class with VC
dimension $d$ that cannot be embedded in any extremal class of VC dimension
smaller than exponential in $d$.
  In addition to its independent interest, this result has an important
implication in learning theory, as it reveals a fundamental limitation of one
of the most extensively studied approaches to tackling the long-standing sample
compression conjecture. Concretely, the approach proposed by Floyd and Warmuth
entails embedding any given VC class into an extremal class of a comparable
dimension, and then applying an optimal sample compression scheme for extremal
classes. However, our results imply that this strategy would in some cases
result in a sample compression scheme at least exponentially larger than what
is predicted by the sample compression conjecture.
  The above implications follow from a general result we prove: any extremal
class with VC dimension $d$ has dual VC dimension at most $2d+1$. This bound is
exponentially smaller than the classical bound $2^{d+1}-1$ of Assouad, which
applies to general concept classes (and is known to be unimprovable for some
classes). We in fact prove a stronger result, establishing that $2d+1$ upper
bounds the dual Radon number of extremal classes. This theorem represents an
abstraction of the classical Radon theorem for convex sets, extending its
applicability to a wider combinatorial framework, without relying on the
specifics of Euclidean convexity. The proof utilizes the topological method and
is primarily based on variants of the Topological Radon Theorem.",2024-05-27,"Zachary Chase, Bogdan Chornomaz, Steve Hanneke, Shay Moran, Amir Yehudayoff",http://arxiv.org/pdf/2405.17120v1,cs.LG
Mixtures of Unsupervised Lexicon Classification,"This paper presents a mixture version of the method-of-moment unsupervised
lexicon classification by an incorporation of a Dirichlet process.",2024-05-27,Peratham Wiriyathammabhum,http://arxiv.org/pdf/2405.17116v1,cs.LG
Diffusion Bridge AutoEncoders for Unsupervised Representation Learning,"Diffusion-based representation learning has achieved substantial attention
due to its promising capabilities in latent representation and sample
generation. Recent studies have employed an auxiliary encoder to identify a
corresponding representation from a sample and to adjust the dimensionality of
a latent variable z. Meanwhile, this auxiliary structure invokes information
split problem because the diffusion and the auxiliary encoder would divide the
information from the sample into two representations for each model.
Particularly, the information modeled by the diffusion becomes over-regularized
because of the static prior distribution on xT. To address this problem, we
introduce Diffusion Bridge AuteEncoders (DBAE), which enable z-dependent
endpoint xT inference through a feed-forward architecture. This structure
creates an information bottleneck at z, so xT becomes dependent on z in its
generation. This results in two consequences: 1) z holds the full information
of samples, and 2) xT becomes a learnable distribution, not static any further.
We propose an objective function for DBAE to enable both reconstruction and
generative modeling, with their theoretical justification. Empirical evidence
supports the effectiveness of the intended design in DBAE, which notably
enhances downstream inference quality, reconstruction, and disentanglement.
Additionally, DBAE generates high-fidelity samples in the unconditional
generation. Our code is available at https://github.com/aailab-kaist/DBAE.",2024-05-27,"Yeongmin Kim, Kwanghyeon Lee, Minsang Park, Byeonghu Na, Il-Chul Moon",http://arxiv.org/pdf/2405.17111v2,cs.LG
Finding good policies in average-reward Markov Decision Processes without prior knowledge,"We revisit the identification of an $\varepsilon$-optimal policy in
average-reward Markov Decision Processes (MDP). In such MDPs, two measures of
complexity have appeared in the literature: the diameter, $D$, and the optimal
bias span, $H$, which satisfy $H\leq D$. Prior work have studied the complexity
of $\varepsilon$-optimal policy identification only when a generative model is
available. In this case, it is known that there exists an MDP with $D \simeq H$
for which the sample complexity to output an $\varepsilon$-optimal policy is
$\Omega(SAD/\varepsilon^2)$ where $S$ and $A$ are the sizes of the state and
action spaces. Recently, an algorithm with a sample complexity of order
$SAH/\varepsilon^2$ has been proposed, but it requires the knowledge of $H$. We
first show that the sample complexity required to estimate $H$ is not bounded
by any function of $S,A$ and $H$, ruling out the possibility to easily make the
previous algorithm agnostic to $H$. By relying instead on a diameter estimation
procedure, we propose the first algorithm for $(\varepsilon,\delta)$-PAC policy
identification that does not need any form of prior knowledge on the MDP. Its
sample complexity scales in $SAD/\varepsilon^2$ in the regime of small
$\varepsilon$, which is near-optimal. In the online setting, our first
contribution is a lower bound which implies that a sample complexity polynomial
in $H$ cannot be achieved in this setting. Then, we propose an online algorithm
with a sample complexity in $SAD^2/\varepsilon^2$, as well as a novel approach
based on a data-dependent stopping rule that we believe is promising to further
reduce this bound.",2024-05-27,"Adrienne Tuynman, Rémy Degenne, Emilie Kaufmann",http://arxiv.org/pdf/2405.17108v1,cs.LG
Efficient Model Compression for Hierarchical Federated Learning,"Federated learning (FL), as an emerging collaborative learning paradigm, has
garnered significant attention due to its capacity to preserve privacy within
distributed learning systems. In these systems, clients collaboratively train a
unified neural network model using their local datasets and share model
parameters rather than raw data, enhancing privacy. Predominantly, FL systems
are designed for mobile and edge computing environments where training
typically occurs over wireless networks. Consequently, as model sizes increase,
the conventional FL frameworks increasingly consume substantial communication
resources. To address this challenge and improve communication efficiency, this
paper introduces a novel hierarchical FL framework that integrates the benefits
of clustered FL and model compression. We present an adaptive clustering
algorithm that identifies a core client and dynamically organizes clients into
clusters. Furthermore, to enhance transmission efficiency, each core client
implements a local aggregation with compression (LC aggregation) algorithm
after collecting compressed models from other clients within the same cluster.
Simulation results affirm that our proposed algorithms not only maintain
comparable predictive accuracy but also significantly reduce energy consumption
relative to existing FL mechanisms.",2024-05-27,"Xi Zhu, Songcan Yu, Junbo Wang, Qinglin Yang",http://arxiv.org/pdf/2405.17522v1,cs.LG
Q-value Regularized Transformer for Offline Reinforcement Learning,"Recent advancements in offline reinforcement learning (RL) have underscored
the capabilities of Conditional Sequence Modeling (CSM), a paradigm that learns
the action distribution based on history trajectory and target returns for each
state. However, these methods often struggle with stitching together optimal
trajectories from sub-optimal ones due to the inconsistency between the sampled
returns within individual trajectories and the optimal returns across multiple
trajectories. Fortunately, Dynamic Programming (DP) methods offer a solution by
leveraging a value function to approximate optimal future returns for each
state, while these techniques are prone to unstable learning behaviors,
particularly in long-horizon and sparse-reward scenarios. Building upon these
insights, we propose the Q-value regularized Transformer (QT), which combines
the trajectory modeling ability of the Transformer with the predictability of
optimal future returns from DP methods. QT learns an action-value function and
integrates a term maximizing action-values into the training loss of CSM, which
aims to seek optimal actions that align closely with the behavior policy.
Empirical evaluations on D4RL benchmark datasets demonstrate the superiority of
QT over traditional DP and CSM methods, highlighting the potential of QT to
enhance the state-of-the-art in offline RL.",2024-05-27,"Shengchao Hu, Ziqing Fan, Chaoqin Huang, Li Shen, Ya Zhang, Yanfeng Wang, Dacheng Tao",http://arxiv.org/pdf/2405.17098v1,cs.LG
A Comparative Study on Multi-task Uncertainty Quantification in Semantic Segmentation and Monocular Depth Estimation,"Deep neural networks excel in perception tasks such as semantic segmentation
and monocular depth estimation, making them indispensable in safety-critical
applications like autonomous driving and industrial inspection. However, they
often suffer from overconfidence and poor explainability, especially for
out-of-domain data. While uncertainty quantification has emerged as a promising
solution to these challenges, multi-task settings have yet to be explored. In
an effort to shed light on this, we evaluate Monte Carlo Dropout, Deep
Sub-Ensembles, and Deep Ensembles for joint semantic segmentation and monocular
depth estimation. Thereby, we reveal that Deep Ensembles stand out as the
preferred choice, particularly in out-of-domain scenarios, and show the
potential benefit of multi-task learning with regard to the uncertainty quality
in comparison to solving both tasks separately. Additionally, we highlight the
impact of employing different uncertainty thresholds to classify pixels as
certain or uncertain, with the median uncertainty emerging as a robust default.",2024-05-27,"Steven Landgraf, Markus Hillemann, Theodor Kapler, Markus Ulrich",http://arxiv.org/pdf/2405.17097v2,cs.LG
Dual feature reduction for the sparse-group lasso and its adaptive variant,"The sparse-group lasso performs both variable and group selection, making
simultaneous use of the strengths of the lasso and group lasso. It has found
widespread use in genetics, a field that regularly involves the analysis of
high-dimensional data, due to its sparse-group penalty, which allows it to
utilize grouping information. However, the sparse-group lasso can be
computationally more expensive than both the lasso and group lasso, due to the
added shrinkage complexity, and its additional hyper-parameter that needs
tuning. In this paper a novel dual feature reduction method, Dual Feature
Reduction (DFR), is presented that uses strong screening rules for the
sparse-group lasso and the adaptive sparse-group lasso to reduce their input
space before optimization. DFR applies two layers of screening and is based on
the dual norms of the sparse-group lasso and adaptive sparse-group lasso.
Through synthetic and real numerical studies, it is shown that the proposed
feature reduction approach is able to drastically reduce the computational cost
in many different scenarios.",2024-05-27,"Fabio Feser, Marina Evangelou",http://arxiv.org/pdf/2405.17094v1,cs.LG
Phase Transitions in the Output Distribution of Large Language Models,"In a physical system, changing parameters such as temperature can induce a
phase transition: an abrupt change from one state of matter to another.
Analogous phenomena have recently been observed in large language models.
Typically, the task of identifying phase transitions requires human analysis
and some prior understanding of the system to narrow down which low-dimensional
properties to monitor and analyze. Statistical methods for the automated
detection of phase transitions from data have recently been proposed within the
physics community. These methods are largely system agnostic and, as shown
here, can be adapted to study the behavior of large language models. In
particular, we quantify distributional changes in the generated output via
statistical distances, which can be efficiently estimated with access to the
probability distribution over next-tokens. This versatile approach is capable
of discovering new phases of behavior and unexplored transitions -- an ability
that is particularly exciting in light of the rapid development of language
models and their emergent capabilities.",2024-05-27,"Julian Arnold, Flemming Holtorf, Frank Schäfer, Niels Lörch",http://arxiv.org/pdf/2405.17088v1,cs.LG
Effective Layer Pruning Through Similarity Metric Perspective,"Deep neural networks have been the predominant paradigm in machine learning
for solving cognitive tasks. Such models, however, are restricted by a high
computational overhead, limiting their applicability and hindering advancements
in the field. Extensive research demonstrated that pruning structures from
these models is a straightforward approach to reducing network complexity. In
this direction, most efforts focus on removing weights or filters. Studies have
also been devoted to layer pruning as it promotes superior computational gains.
However, layer pruning often hurts the network predictive ability (i.e.,
accuracy) at high compression rates. This work introduces an effective
layer-pruning strategy that meets all underlying properties pursued by pruning
methods. Our method estimates the relative importance of a layer using the
Centered Kernel Alignment (CKA) metric, employed to measure the similarity
between the representations of the unpruned model and a candidate layer for
pruning. We confirm the effectiveness of our method on standard architectures
and benchmarks, in which it outperforms existing layer-pruning strategies and
other state-of-the-art pruning techniques. Particularly, we remove more than
75% of computation while improving predictive ability. At higher compression
regimes, our method exhibits negligible accuracy drop, while other methods
notably deteriorate model accuracy. Apart from these benefits, our pruned
models exhibit robustness to adversarial and out-of-distribution samples.",2024-05-27,"Ian Pons, Bruno Yamamoto, Anna H. Reali Costa, Artur Jordao",http://arxiv.org/pdf/2405.17081v2,cs.LG
Learning with User-Level Local Differential Privacy,"User-level privacy is important in distributed systems. Previous research
primarily focuses on the central model, while the local models have received
much less attention. Under the central model, user-level DP is strictly
stronger than the item-level one. However, under the local model, the
relationship between user-level and item-level LDP becomes more complex, thus
the analysis is crucially different. In this paper, we first analyze the mean
estimation problem and then apply it to stochastic optimization,
classification, and regression. In particular, we propose adaptive strategies
to achieve optimal performance at all privacy levels. Moreover, we also obtain
information-theoretic lower bounds, which show that the proposed methods are
minimax optimal up to logarithmic factors. Unlike the central DP model, where
user-level DP always leads to slower convergence, our result shows that under
the local model, the convergence rates are nearly the same between user-level
and item-level cases for distributions with bounded support. For heavy-tailed
distributions, the user-level rate is even faster than the item-level one.",2024-05-27,"Puning Zhao, Li Shen, Rongfei Fan, Qingming Li, Huiwen Wu, Jiafei Wu, Zhe Liu",http://arxiv.org/pdf/2405.17079v1,cs.LG
Interaction-Force Transport Gradient Flows,"This paper presents a new gradient flow dissipation geometry over
non-negative and probability measures. This is motivated by a principled
construction that combines the unbalanced optimal transport and interaction
forces modeled by reproducing kernels. Using a precise connection between the
Hellinger geometry and the maximum mean discrepancy (MMD), we propose the
interaction-force transport (IFT) gradient flows and its spherical variant via
an infimal convolution of the Wasserstein and spherical MMD tensors. We then
develop a particle-based optimization algorithm based on the JKO-splitting
scheme of the mass-preserving spherical IFT gradient flows. Finally, we provide
both theoretical global exponential convergence guarantees and improved
empirical simulation results for applying the IFT gradient flows to the
sampling task of MMD-minimization. Furthermore, we prove that the spherical IFT
gradient flow enjoys the best of both worlds by providing the global
exponential convergence guarantee for both the MMD and KL energy.",2024-05-27,"Egor Gladin, Pavel Dvurechensky, Alexander Mielke, Jia-Jie Zhu",http://arxiv.org/pdf/2405.17075v2,cs.LG
Efficient mid-term forecasting of hourly electricity load using generalized additive models,"Accurate mid-term (weeks to one year) hourly electricity load forecasts are
essential for strategic decision-making in power plant operation, ensuring
supply security and grid stability, planning and building energy storage
systems, and energy trading. While numerous models effectively predict
short-term (hours to a few days) hourly load, mid-term forecasting solutions
remain scarce. In mid-term load forecasting, capturing the multifaceted
characteristics of load, including daily, weekly and annual seasonal patterns,
as well as autoregressive effects, weather and holiday impacts, and
socio-economic non-stationarities, presents significant modeling challenges. To
address these challenges, we propose a novel forecasting method using
Generalized Additive Models (GAMs) built from interpretable P-splines that is
enhanced with autoregressive post-processing. This model incorporates smoothed
temperatures, Error-Trend-Seasonal (ETS) modeled and persistently forecasted
non-stationary socio-economic states, a nuanced representation of effects from
vacation periods, fixed date and weekday holidays, and seasonal information as
inputs. The proposed model is evaluated using load data from 24 European
countries over more than 9 years (2015-2024). This analysis demonstrates that
the model not only has significantly enhanced forecasting accuracy compared to
state-of-the-art methods but also offers valuable insights into the influence
of individual components on predicted load, given its full interpretability.
Achieving performance akin to day-ahead Transmission System Operator (TSO)
forecasts, with computation times of just a few seconds for several years of
hourly data, underscores the potential of the model for practical application
in the power system industry.",2024-05-27,"Monika Zimmermann, Florian Ziel",http://arxiv.org/pdf/2405.17070v2,cs.LG
Training-free Editioning of Text-to-Image Models,"Inspired by the software industry's practice of offering different editions
or versions of a product tailored to specific user groups or use cases, we
propose a novel task, namely, training-free editioning, for text-to-image
models. Specifically, we aim to create variations of a base text-to-image model
without retraining, enabling the model to cater to the diverse needs of
different user groups or to offer distinct features and functionalities. To
achieve this, we propose that different editions of a given text-to-image model
can be formulated as concept subspaces in the latent space of its text encoder
(e.g., CLIP). In such a concept subspace, all points satisfy a specific user
need (e.g., generating images of a cat lying on the grass/ground/falling
leaves). Technically, we apply Principal Component Analysis (PCA) to obtain the
desired concept subspaces from representative text embedding that correspond to
a specific user need or requirement. Projecting the text embedding of a given
prompt into these low-dimensional subspaces enables efficient model editioning
without retraining. Intuitively, our proposed editioning paradigm enables a
service provider to customize the base model into its ""cat edition"" (or other
editions) that restricts image generation to cats, regardless of the user's
prompt (e.g., dogs, people, etc.). This introduces a new dimension for product
differentiation, targeted functionality, and pricing strategies, unlocking
novel business models for text-to-image generators. Extensive experimental
results demonstrate the validity of our approach and its potential to enable a
wide range of customized text-to-image model editions across various domains
and applications.",2024-05-27,"Jinqi Wang, Yunfei Fu, Zhangcan Ding, Bailin Deng, Yu-Kun Lai, Yipeng Qin",http://arxiv.org/pdf/2405.17069v1,cs.LG
The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models,"Langevin Dynamics is a Stochastic Differential Equation (SDE) central to
sampling and generative modeling and is implemented via time discretization.
Langevin Monte Carlo (LMC), based on the Euler-Maruyama discretization, is the
simplest and most studied algorithm. LMC can suffer from slow convergence -
requiring a large number of steps of small step-size to obtain good quality
samples. This becomes stark in the case of diffusion models where a large
number of steps gives the best samples, but the quality degrades rapidly with
smaller number of steps. Randomized Midpoint Method has been recently proposed
as a better discretization of Langevin dynamics for sampling from strongly
log-concave distributions. However, important applications such as diffusion
models involve non-log concave densities and contain time varying drift. We
propose its variant, the Poisson Midpoint Method, which approximates a small
step-size LMC with large step-sizes. We prove that this can obtain a quadratic
speed up of LMC under very weak assumptions. We apply our method to diffusion
models for image generation and show that it maintains the quality of DDPM with
1000 neural network calls with just 50-80 neural network calls and outperforms
ODE based methods with similar compute.",2024-05-27,"Saravanan Kandasamy, Dheeraj Nagaraj",http://arxiv.org/pdf/2405.17068v2,cs.LG
Saturn: Sample-efficient Generative Molecular Design using Memory Manipulation,"Generative molecular design for drug discovery has very recently achieved a
wave of experimental validation, with language-based backbones being the most
common architectures employed. The most important factor for downstream success
is whether an in silico oracle is well correlated with the desired end-point.
To this end, current methods use cheaper proxy oracles with higher throughput
before evaluating the most promising subset with high-fidelity oracles. The
ability to directly optimize high-fidelity oracles would greatly enhance
generative design and be expected to improve hit rates. However, current models
are not efficient enough to consider such a prospect, exemplifying the sample
efficiency problem. In this work, we introduce Saturn, which leverages the
Augmented Memory algorithm and demonstrates the first application of the Mamba
architecture for generative molecular design. We elucidate how experience
replay with data augmentation improves sample efficiency and how Mamba
synergistically exploits this mechanism. Saturn outperforms 22 models on
multi-parameter optimization tasks relevant to drug discovery and may possess
sufficient sample efficiency to consider the prospect of directly optimizing
high-fidelity oracles.",2024-05-27,"Jeff Guo, Philippe Schwaller",http://arxiv.org/pdf/2405.17066v1,cs.LG
Provably Efficient Reinforcement Learning with Multinomial Logit Function Approximation,"We study a new class of MDPs that employs multinomial logit (MNL) function
approximation to ensure valid probability distributions over the state space.
Despite its significant benefits, incorporating the non-linear function raises
substantial challenges in both statistical and computational efficiency. The
best-known result of Hwang and Oh [2023] has achieved an
$\widetilde{\mathcal{O}}(\kappa^{-1}dH^2\sqrt{K})$ regret upper bound, where
$\kappa$ is a problem-dependent quantity, $d$ is the feature dimension, $H$ is
the episode length, and $K$ is the number of episodes. However, we observe that
$\kappa^{-1}$ exhibits polynomial dependence on the number of reachable states,
which can be as large as the state space size in the worst case and thus
undermines the motivation for function approximation. Additionally, their
method requires storing all historical data and the time complexity scales
linearly with the episode count, which is computationally expensive. In this
work, we propose a statistically efficient algorithm that achieves a regret of
$\widetilde{\mathcal{O}}(dH^2\sqrt{K} + \kappa^{-1}d^2H^2)$, eliminating the
dependence on $\kappa^{-1}$ in the dominant term for the first time. We then
address the computational challenges by introducing an enhanced algorithm that
achieves the same regret guarantee but with only constant cost. Finally, we
establish the first lower bound for this problem, justifying the optimality of
our results in $d$ and $K$.",2024-05-27,"Long-Fei Li, Yu-Jie Zhang, Peng Zhao, Zhi-Hua Zhou",http://arxiv.org/pdf/2405.17061v3,cs.LG
Graph Neural Networks on Quantum Computers,"Graph Neural Networks (GNNs) are powerful machine learning models that excel
at analyzing structured data represented as graphs, demonstrating remarkable
performance in applications like social network analysis and recommendation
systems. However, classical GNNs face scalability challenges when dealing with
large-scale graphs. This paper proposes frameworks for implementing GNNs on
quantum computers to potentially address the challenges. We devise quantum
algorithms corresponding to the three fundamental types of classical GNNs:
Graph Convolutional Networks, Graph Attention Networks, and Message-Passing
GNNs. A complexity analysis of our quantum implementation of the Simplified
Graph Convolutional (SGC) Network shows potential quantum advantages over its
classical counterpart, with significant improvements in time and space
complexities. Our complexities can have trade-offs between the two: when
optimizing for minimal circuit depth, our quantum SGC achieves logarithmic time
complexity in the input sizes (albeit at the cost of linear space complexity).
When optimizing for minimal qubit usage, the quantum SGC exhibits space
complexity logarithmic in the input sizes, offering an exponential reduction
compared to classical SGCs, while still maintaining better time complexity.
These results suggest our Quantum GNN frameworks could efficiently process
large-scale graphs. This work paves the way for implementing more advanced
Graph Neural Network models on quantum computers, opening new possibilities in
quantum machine learning for analyzing graph-structured data.",2024-05-27,"Yidong Liao, Xiao-Ming Zhang, Chris Ferrie",http://arxiv.org/pdf/2405.17060v1,cs.LG
Comparative Study of Machine Learning Algorithms in Detecting Cardiovascular Diseases,"The detection of cardiovascular diseases (CVD) using machine learning
techniques represents a significant advancement in medical diagnostics, aiming
to enhance early detection, accuracy, and efficiency. This study explores a
comparative analysis of various machine learning algorithms, including Logistic
Regression, Decision Tree, Random Forest, Gradient Boosting, Support Vector
Machine (SVM), K-Nearest Neighbors (KNN), and XGBoost. By utilising a
structured workflow encompassing data collection, preprocessing, model
selection and hyperparameter tuning, training, evaluation, and choice of the
optimal model, this research addresses the critical need for improved
diagnostic tools. The findings highlight the efficacy of ensemble methods and
advanced algorithms in providing reliable predictions, thereby offering a
comprehensive framework for CVD detection that can be readily implemented and
adapted in clinical settings.",2024-05-27,"Dayana K, S. Nandini, Sanjjushri Varshini R",http://arxiv.org/pdf/2405.17059v1,cs.LG
Improving Data-aware and Parameter-aware Robustness for Continual Learning,"The goal of Continual Learning (CL) task is to continuously learn multiple
new tasks sequentially while achieving a balance between the plasticity and
stability of new and old knowledge. This paper analyzes that this insufficiency
arises from the ineffective handling of outliers, leading to abnormal gradients
and unexpected model updates. To address this issue, we enhance the data-aware
and parameter-aware robustness of CL, proposing a Robust Continual Learning
(RCL) method. From the data perspective, we develop a contrastive loss based on
the concepts of uniformity and alignment, forming a feature distribution that
is more applicable to outliers. From the parameter perspective, we present a
forward strategy for worst-case perturbation and apply robust gradient
projection to the parameters. The experimental results on three benchmarks show
that the proposed method effectively maintains robustness and achieves new
state-of-the-art (SOTA) results. The code is available at:
https://github.com/HanxiXiao/RCL",2024-05-27,"Hanxi Xiao, Fan Lyu",http://arxiv.org/pdf/2405.17054v1,cs.LG
WirelessLLM: Empowering Large Language Models Towards Wireless Intelligence,"The rapid evolution of wireless technologies and the growing complexity of
network infrastructures necessitate a paradigm shift in how communication
networks are designed, configured, and managed. Recent advancements in Large
Language Models (LLMs) have sparked interest in their potential to
revolutionize wireless communication systems. However, existing studies on LLMs
for wireless systems are limited to a direct application for telecom language
understanding. To empower LLMs with knowledge and expertise in the wireless
domain, this paper proposes WirelessLLM, a comprehensive framework for adapting
and enhancing LLMs to address the unique challenges and requirements of
wireless communication networks. We first identify three foundational
principles that underpin WirelessLLM: knowledge alignment, knowledge fusion,
and knowledge evolution. Then, we investigate the enabling technologies to
build WirelessLLM, including prompt engineering, retrieval augmented
generation, tool usage, multi-modal pre-training, and domain-specific
fine-tuning. Moreover, we present three case studies to demonstrate the
practical applicability and benefits of WirelessLLM for solving typical
problems in wireless networks. Finally, we conclude this paper by highlighting
key challenges and outlining potential avenues for future research.",2024-05-27,"Jiawei Shao, Jingwen Tong, Qiong Wu, Wei Guo, Zijian Li, Zehong Lin, Jun Zhang",http://arxiv.org/pdf/2405.17053v2,cs.LG
BeamVQ: Aligning Space-Time Forecasting Model via Self-training on Physics-aware Metrics,"Data-driven deep learning has emerged as the new paradigm to model complex
physical space-time systems. These data-driven methods learn patterns by
optimizing statistical metrics and tend to overlook the adherence to physical
laws, unlike traditional model-driven numerical methods. Thus, they often
generate predictions that are not physically realistic. On the other hand, by
sampling a large amount of high quality predictions from a data-driven model,
some predictions will be more physically plausible than the others and closer
to what will happen in the future. Based on this observation, we propose
\emph{Beam search by Vector Quantization} (BeamVQ) to enhance the physical
alignment of data-driven space-time forecasting models. The key of BeamVQ is to
train model on self-generated samples filtered with physics-aware metrics. To
be flexibly support different backbone architectures, BeamVQ leverages a code
bank to transform any encoder-decoder model to the continuous state space into
discrete codes. Afterwards, it iteratively employs beam search to sample
high-quality sequences, retains those with the highest physics-aware scores,
and trains model on the new dataset. Comprehensive experiments show that BeamVQ
not only gave an average statistical skill score boost for more than 32% for
ten backbones on five datasets, but also significantly enhances physics-aware
metrics.",2024-05-27,"Hao Wu, Xingjian Shi, Ziyue Huang, Penghao Zhao, Wei Xiong, Jinbao Xue, Yangyu Tao, Xiaomeng Huang, Weiyan Wang",http://arxiv.org/pdf/2405.17051v1,cs.LG
HeNCler: Node Clustering in Heterophilous Graphs through Learned Asymmetric Similarity,"Clustering nodes in heterophilous graphs presents unique challenges due to
the asymmetric relationships often overlooked by traditional methods, which
moreover assume that good clustering corresponds to high intra-cluster and low
inter-cluster connectivity. To address these issues, we introduce HeNCler - a
novel approach for Heterophilous Node Clustering. Our method begins by defining
a weighted kernel singular value decomposition to create an asymmetric
similarity graph, applicable to both directed and undirected graphs. We further
establish that the dual problem of this formulation aligns with asymmetric
kernel spectral clustering, interpreting learned graph similarities without
relying on homophily. We demonstrate the ability to solve the primal problem
directly, circumventing the computational difficulties of the dual approach.
Experimental evidence confirms that HeNCler significantly enhances performance
in node clustering tasks within heterophilous graph contexts.",2024-05-27,"Sonny Achten, Francesco Tonin, Volkan Cevher, Johan A. K. Suykens",http://arxiv.org/pdf/2405.17050v1,cs.LG
Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization,"This paper explores methods for verifying the properties of Binary Neural
Networks (BNNs), focusing on robustness against adversarial attacks. Despite
their lower computational and memory needs, BNNs, like their full-precision
counterparts, are also sensitive to input perturbations. Established methods
for solving this problem are predominantly based on Satisfiability Modulo
Theories and Mixed-Integer Linear Programming techniques, which are
characterized by NP complexity and often face scalability issues.
  We introduce an alternative approach using Semidefinite Programming
relaxations derived from sparse Polynomial Optimization. Our approach,
compatible with continuous input space, not only mitigates numerical issues
associated with floating-point calculations but also enhances verification
scalability through the strategic use of tighter first-order semidefinite
relaxations. We demonstrate the effectiveness of our method in verifying
robustness against both $\|.\|_\infty$ and $\|.\|_2$-based adversarial attacks.",2024-05-27,"Jianting Yang, Srećko Ðurašinović, Jean-Bernard Lasserre, Victor Magron, Jun Zhao",http://arxiv.org/pdf/2405.17049v2,cs.LG
Interpretable Robotic Manipulation from Language,"Humans naturally employ linguistic instructions to convey knowledge, a
process that proves significantly more complex for machines, especially within
the context of multitask robotic manipulation environments. Natural language,
moreover, serves as the primary medium through which humans acquire new
knowledge, presenting a potentially intuitive bridge for translating concepts
understandable by humans into formats that can be learned by machines. In
pursuit of facilitating this integration, we introduce an explainable behavior
cloning agent, named Ex-PERACT, specifically designed for manipulation tasks.
This agent is distinguished by its hierarchical structure, which incorporates
natural language to enhance the learning process. At the top level, the model
is tasked with learning a discrete skill code, while at the bottom level, the
policy network translates the problem into a voxelized grid and maps the
discretized actions to voxel grids. We evaluate our method across eight
challenging manipulation tasks utilizing the RLBench benchmark, demonstrating
that Ex-PERACT not only achieves competitive policy performance but also
effectively bridges the gap between human instructions and machine execution in
complex environments.",2024-05-27,"Boyuan Zheng, Jianlong Zhou, Fang Chen",http://arxiv.org/pdf/2405.17047v1,cs.LG
Interesting Scientific Idea Generation using Knowledge Graphs and LLMs: Evaluations with 100 Research Group Leaders,"The rapid growth of scientific literature makes it challenging for
researchers to identify novel and impactful ideas, especially across
disciplines. Modern artificial intelligence (AI) systems offer new approaches,
potentially inspiring ideas not conceived by humans alone. But how compelling
are these AI-generated ideas, and how can we improve their quality? Here, we
introduce SciMuse, which uses 58 million research papers and a large-language
model to generate research ideas. We conduct a large-scale evaluation in which
over 100 research group leaders -- from natural sciences to humanities --
ranked more than 4,400 personalized ideas based on their interest. This data
allows us to predict research interest using (1) supervised neural networks
trained on human evaluations, and (2) unsupervised zero-shot ranking with
large-language models. Our results demonstrate how future systems can help
generating compelling research ideas and foster unforeseen interdisciplinary
collaborations.",2024-05-27,"Xuemei Gu, Mario Krenn",http://arxiv.org/pdf/2405.17044v3,cs.LG
LabObf: A Label Protection Scheme for Vertical Federated Learning Through Label Obfuscation,"Split Neural Network, as one of the most common architectures used in
vertical federated learning, is popular in industry due to its
privacy-preserving characteristics. In this architecture, the party holding the
labels seeks cooperation from other parties to improve model performance due to
insufficient feature data. Each of these participants has a self-defined bottom
model to learn hidden representations from its own feature data and uploads the
embedding vectors to the top model held by the label holder for final
predictions. This design allows participants to conduct joint training without
directly exchanging data. However, existing research points out that malicious
participants may still infer label information from the uploaded embeddings,
leading to privacy leakage. In this paper, we first propose an embedding
extension attack manipulating embeddings to undermine existing defense
strategies, which rely on constraining the correlation between the embeddings
uploaded by participants and the labels. Subsequently, we propose a new label
obfuscation defense strategy, called `LabObf', which randomly maps each
original integer-valued label to multiple real-valued soft labels with values
intertwined, significantly increasing the difficulty for attackers to infer the
labels. We conduct experiments on four different types of datasets, and the
results show that LabObf significantly reduces the attacker's success rate
compared to raw models while maintaining desirable model accuracy.",2024-05-27,"Ying He, Mingyang Niu, Jingyu Hua, Yunlong Mao, Xu Huang, Chen Li, Sheng Zhong",http://arxiv.org/pdf/2405.17042v2,cs.LG
EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation,"The integration of multimodal Electronic Health Records (EHR) data has
significantly advanced clinical predictive capabilities. Existing models, which
utilize clinical notes and multivariate time-series EHR data, often fall short
of incorporating the necessary medical context for accurate clinical tasks,
while previous approaches with knowledge graphs (KGs) primarily focus on
structured knowledge extraction. In response, we propose EMERGE, a
Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR
predictive modeling. We extract entities from both time-series data and
clinical notes by prompting Large Language Models (LLMs) and align them with
professional PrimeKG, ensuring consistency. In addition to triplet
relationships, we incorporate entities' definitions and descriptions for richer
semantics. The extracted knowledge is then used to generate task-relevant
summaries of patients' health statuses. Finally, we fuse the summary with other
modalities using an adaptive multimodal fusion network with cross-attention.
Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital
mortality and 30-day readmission tasks demonstrate the superior performance of
the EMERGE framework over baseline models. Comprehensive ablation studies and
analysis highlight the efficacy of each designed module and robustness to data
sparsity. EMERGE contributes to refining the utilization of multimodal EHR data
in healthcare, bridging the gap with nuanced medical contexts essential for
informed clinical predictions. We have publicly released the code at
https://github.com/yhzhu99/EMERGE.",2024-05-27,"Yinghao Zhu, Changyu Ren, Zixiang Wang, Xiaochen Zheng, Shiyun Xie, Junlan Feng, Xi Zhu, Zhoujun Li, Liantao Ma, Chengwei Pan",http://arxiv.org/pdf/2406.00036v2,cs.LG
"BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation","Large language models (LLMs) have catalyzed a paradigm shift in natural
language processing, yet their limited controllability poses a significant
challenge for downstream applications. We aim to address this by drawing
inspiration from the neural mechanisms of the human brain, specifically Broca's
and Wernicke's areas, which are crucial for language generation and
comprehension, respectively. In particular, Broca's area receives cognitive
decision signals from Wernicke's area, treating the language generation as an
intricate decision-making process, which differs from the fully auto-regressive
language generation of existing LLMs. In a similar vein, our proposed system,
the BWArea model, conceptualizes language generation as a decision-making task.
This model has three components: a language world model, an inverse dynamics
model, and a cognitive policy. Like Wernicke's area, the inverse dynamics model
is designed to deduce the underlying cognitive intentions, or latent actions,
behind each token. The BWArea model is amenable to both pre-training and
fine-tuning like existing LLMs. With 30B clean pre-training tokens, we have
trained a BWArea model, which achieves competitive performance with LLMs of
equal size (1B parameters). Unlike fully auto-regressive LLMs, its pre-training
performance does not degenerate if dirty data unintentionally appears. This
shows the advantage of a decomposed structure of BWArea model in reducing
efforts in laborious data selection and labeling. Finally, we reveal that the
BWArea model offers enhanced controllability via fine-tuning the cognitive
policy with downstream reward metrics, thereby facilitating alignment with
greater simplicity. On 9 out of 10 tasks from two suites, TextWorld and
BigBench Hard, our method shows superior performance to auto-regressive LLMs.",2024-05-27,"Chengxing Jia, Pengyuan Wang, Ziniu Li, Yi-Chen Li, Zhilong Zhang, Nan Tang, Yang Yu",http://arxiv.org/pdf/2405.17039v1,cs.LG
Glauber Generative Model: Discrete Diffusion Models via Binary Classification,"We introduce the Glauber Generative Model (GGM), a new class of discrete
diffusion models, to obtain new samples from a distribution given samples from
a discrete space. GGM deploys a discrete Markov chain called the heat bath
dynamics (or the Glauber dynamics) to denoise a sequence of noisy tokens to a
sample from a joint distribution of discrete tokens. Our novel conceptual
framework provides an exact reduction of the task of learning the denoising
Markov chain to solving a class of binary classification tasks. More
specifically, the model learns to classify a given token in a noisy sequence as
signal or noise. In contrast, prior works on discrete diffusion models either
solve regression problems to learn importance ratios, or minimize loss
functions given by variational approximations. We apply GGM to language
modeling and image generation, where images are discretized using image
tokenizers like VQGANs. We show that it outperforms existing discrete diffusion
models in language generation, and demonstrates strong performance for image
generation without using dataset-specific image tokenizers. We also show that
our model is capable of performing well in zero-shot control settings like text
and image infilling.",2024-05-27,"Harshit Varma, Dheeraj Nagaraj, Karthikeyan Shanmugam",http://arxiv.org/pdf/2405.17035v4,cs.LG
FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks,"Fairness-aware Graph Neural Networks (GNNs) often face a challenging
trade-off, where prioritizing fairness may require compromising utility. In
this work, we re-examine fairness through the lens of spectral graph theory,
aiming to reconcile fairness and utility within the framework of spectral graph
learning. We explore the correlation between sensitive features and spectrum in
GNNs, using theoretical analysis to delineate the similarity between original
sensitive features and those after convolution under different spectra. Our
analysis reveals a reduction in the impact of similarity when the eigenvectors
associated with the largest magnitude eigenvalue exhibit directional
similarity. Based on these theoretical insights, we propose FUGNN, a novel
spectral graph learning approach that harmonizes the conflict between fairness
and utility. FUGNN ensures algorithmic fairness and utility by truncating the
spectrum and optimizing eigenvector distribution during the encoding process.
The fairness-aware eigenvector selection reduces the impact of convolution on
sensitive features while concurrently minimizing the sacrifice of utility.
FUGNN further optimizes the distribution of eigenvectors through a transformer
architecture. By incorporating the optimized spectrum into the graph
convolution network, FUGNN effectively learns node representations. Experiments
on six real-world datasets demonstrate the superiority of FUGNN over baseline
methods. The codes are available at https://github.com/yushuowiki/FUGNN.",2024-05-27,"Renqiang Luo, Huafei Huang, Shuo Yu, Zhuoyang Han, Estrid He, Xiuzhen Zhang, Feng Xia",http://arxiv.org/pdf/2405.17034v2,cs.LG
Any-step Dynamics Model Improves Future Predictions for Online and Offline Reinforcement Learning,"Model-based methods in reinforcement learning offer a promising approach to
enhance data efficiency by facilitating policy exploration within a dynamics
model. However, accurately predicting sequential steps in the dynamics model
remains a challenge due to the bootstrapping prediction, which attributes the
next state to the prediction of the current state. This leads to accumulated
errors during model roll-out. In this paper, we propose the Any-step Dynamics
Model (ADM) to mitigate the compounding error by reducing bootstrapping
prediction to direct prediction. ADM allows for the use of variable-length
plans as inputs for predicting future states without frequent bootstrapping. We
design two algorithms, ADMPO-ON and ADMPO-OFF, which apply ADM in online and
offline model-based frameworks, respectively. In the online setting, ADMPO-ON
demonstrates improved sample efficiency compared to previous state-of-the-art
methods. In the offline setting, ADMPO-OFF not only demonstrates superior
performance compared to recent state-of-the-art offline approaches but also
offers better quantification of model uncertainty using only a single ADM.",2024-05-27,"Haoxin Lin, Yu-Yan Xu, Yihao Sun, Zhilong Zhang, Yi-Chen Li, Chengxing Jia, Junyin Ye, Jiaji Zhang, Yang Yu",http://arxiv.org/pdf/2405.17031v1,cs.LG
SCaRL- A Synthetic Multi-Modal Dataset for Autonomous Driving,"We present a novel synthetically generated multi-modal dataset, SCaRL, to
enable the training and validation of autonomous driving solutions. Multi-modal
datasets are essential to attain the robustness and high accuracy required by
autonomous systems in applications such as autonomous driving. As deep
learning-based solutions are becoming more prevalent for object detection,
classification, and tracking tasks, there is great demand for datasets
combining camera, lidar, and radar sensors. Existing real/synthetic datasets
for autonomous driving lack synchronized data collection from a complete sensor
suite. SCaRL provides synchronized Synthetic data from RGB, semantic/instance,
and depth Cameras; Range-Doppler-Azimuth/Elevation maps and raw data from
Radar; and 3D point clouds/2D maps of semantic, depth and Doppler data from
coherent Lidar. SCaRL is a large dataset based on the CARLA Simulator, which
provides data for diverse, dynamic scenarios and traffic conditions. SCaRL is
the first dataset to include synthetic synchronized data from coherent Lidar
and MIMO radar sensors.
  The dataset can be accessed here:
https://fhr-ihs-sva.pages.fraunhofer.de/asp/scarl/",2024-05-27,"Avinash Nittur Ramesh, Aitor Correas-Serrano, María González-Huici",http://arxiv.org/pdf/2405.17030v1,cs.LG
Supervised Batch Normalization,"Batch Normalization (BN), a widely-used technique in neural networks,
enhances generalization and expedites training by normalizing each mini-batch
to the same mean and variance. However, its effectiveness diminishes when
confronted with diverse data distributions. To address this challenge, we
propose Supervised Batch Normalization (SBN), a pioneering approach. We expand
normalization beyond traditional single mean and variance parameters, enabling
the identification of data modes prior to training. This ensures effective
normalization for samples sharing common features. We define contexts as modes,
categorizing data with similar characteristics. These contexts are explicitly
defined, such as domains in domain adaptation or modalities in multimodal
systems, or implicitly defined through clustering algorithms based on data
similarity. We illustrate the superiority of our approach over BN and other
commonly employed normalization techniques through various experiments on both
single and multi-task datasets. Integrating SBN with Vision Transformer results
in a remarkable \textit{15.13}\% accuracy enhancement on CIFAR-100.
Additionally, in domain adaptation scenarios, employing AdaMatch demonstrates
an impressive \textit{22.25}\% accuracy improvement on MNIST and SVHN compared
to BN.",2024-05-27,"Bilal Faye, Mustapha Lebbah, Hanane Azzag",http://arxiv.org/pdf/2405.17027v1,cs.LG
Analysis of Multiscale Reinforcement Q-Learning Algorithms for Mean Field Control Games,"Mean Field Control Games (MFCG), introduced in [Angiuli et al., 2022a],
represent competitive games between a large number of large collaborative
groups of agents in the infinite limit of number and size of groups. In this
paper, we prove the convergence of a three-timescale Reinforcement Q-Learning
(RL) algorithm to solve MFCG in a model-free approach from the point of view of
representative agents. Our analysis uses a Q-table for finite state and action
spaces updated at each discrete time-step over an infinite horizon. In [Angiuli
et al., 2023], we proved convergence of two-timescale algorithms for MFG and
MFC separately highlighting the need to follow multiple population
distributions in the MFC case. Here, we integrate this feature for MFCG as well
as three rates of update decreasing to zero in the proper ratios. Our technique
of proof uses a generalization to three timescales of the two-timescale
analysis in [Borkar, 1997]. We give a simple example satisfying the various
hypothesis made in the proof of convergence and illustrating the performance of
the algorithm.",2024-05-27,"Andrea Angiuli, Jean-Pierre Fouque, Mathieu Laurière, Mengrui Zhang",http://arxiv.org/pdf/2405.17017v3,cs.LG
Graph Condensation for Open-World Graph Learning,"The burgeoning volume of graph data presents significant computational
challenges in training graph neural networks (GNNs), critically impeding their
efficiency in various applications. To tackle this challenge, graph
condensation (GC) has emerged as a promising acceleration solution, focusing on
the synthesis of a compact yet representative graph for efficiently training
GNNs while retaining performance. Despite the potential to promote scalable use
of GNNs, existing GC methods are limited to aligning the condensed graph with
merely the observed static graph distribution. This limitation significantly
restricts the generalization capacity of condensed graphs, particularly in
adapting to dynamic distribution changes. In real-world scenarios, however,
graphs are dynamic and constantly evolving, with new nodes and edges being
continually integrated. Consequently, due to the limited generalization
capacity of condensed graphs, applications that employ GC for efficient GNN
training end up with sub-optimal GNNs when confronted with evolving graph
structures and distributions in dynamic real-world situations. To overcome this
issue, we propose open-world graph condensation (OpenGC), a robust GC framework
that integrates structure-aware distribution shift to simulate evolving graph
patterns and exploit the temporal environments for invariance condensation.
This approach is designed to extract temporal invariant patterns from the
original graph, thereby enhancing the generalization capabilities of the
condensed graph and, subsequently, the GNNs trained on it. Extensive
experiments on both real-world and synthetic evolving graphs demonstrate that
OpenGC outperforms state-of-the-art (SOTA) GC methods in adapting to dynamic
changes in open-world graph environments.",2024-05-27,"Xinyi Gao, Tong Chen, Wentao Zhang, Yayong Li, Xiangguo Sun, Hongzhi Yin",http://arxiv.org/pdf/2405.17003v2,cs.LG
OSLO: One-Shot Label-Only Membership Inference Attacks,"We introduce One-Shot Label-Only (OSLO) membership inference attacks (MIAs),
which accurately infer a given sample's membership in a target model's training
set with high precision using just \emph{a single query}, where the target
model only returns the predicted hard label. This is in contrast to
state-of-the-art label-only attacks which require $\sim6000$ queries, yet get
attack precisions lower than OSLO's. OSLO leverages transfer-based black-box
adversarial attacks. The core idea is that a member sample exhibits more
resistance to adversarial perturbations than a non-member. We compare OSLO
against state-of-the-art label-only attacks and demonstrate that, despite
requiring only one query, our method significantly outperforms previous attacks
in terms of precision and true positive rate (TPR) under the same false
positive rates (FPR). For example, compared to previous label-only MIAs, OSLO
achieves a TPR that is at least 7$\times$ higher under a 1\% FPR and at least
22$\times$ higher under a 0.1\% FPR on CIFAR100 for a ResNet18 model. We
evaluated multiple defense mechanisms against OSLO.",2024-05-27,"Yuefeng Peng, Jaechul Roh, Subhransu Maji, Amir Houmansadr",http://arxiv.org/pdf/2405.16978v3,cs.LG
A Correlation- and Mean-Aware Loss Function and Benchmarking Framework to Improve GAN-based Tabular Data Synthesis,"Advancements in science rely on data sharing. In medicine, where personal
data are often involved, synthetic tabular data generated by generative
adversarial networks (GANs) offer a promising avenue. However, existing GANs
struggle to capture the complexities of real-world tabular data, which often
contain a mix of continuous and categorical variables with potential imbalances
and dependencies. We propose a novel correlation- and mean-aware loss function
designed to address these challenges as a regularizer for GANs. To ensure a
rigorous evaluation, we establish a comprehensive benchmarking framework using
ten real-world datasets and eight established tabular GAN baselines. The
proposed loss function demonstrates statistically significant improvements over
existing methods in capturing the true data distribution, significantly
enhancing the quality of synthetic data generated with GANs. The benchmarking
framework shows that the enhanced synthetic data quality leads to improved
performance in downstream machine learning (ML) tasks, ultimately paving the
way for easier data sharing.",2024-05-27,"Minh H. Vu, Daniel Edler, Carl Wibom, Tommy Löfstedt, Beatrice Melin, Martin Rosvall",http://arxiv.org/pdf/2405.16971v1,cs.LG
"WASH: Train your Ensemble with Communication-Efficient Weight Shuffling, then Average","The performance of deep neural networks is enhanced by ensemble methods,
which average the output of several models. However, this comes at an increased
cost at inference. Weight averaging methods aim at balancing the generalization
of ensembling and the inference speed of a single model by averaging the
parameters of an ensemble of models. Yet, naive averaging results in poor
performance as models converge to different loss basins, and aligning the
models to improve the performance of the average is challenging. Alternatively,
inspired by distributed training, methods like DART and PAPA have been proposed
to train several models in parallel such that they will end up in the same
basin, resulting in good averaging accuracy. However, these methods either
compromise ensembling accuracy or demand significant communication between
models during training. In this paper, we introduce WASH, a novel distributed
method for training model ensembles for weight averaging that achieves
state-of-the-art image classification accuracy. WASH maintains models within
the same basin by randomly shuffling a small percentage of weights during
training, resulting in diverse models and lower communication costs compared to
standard parameter averaging methods.",2024-05-27,"Louis Fournier, Adel Nabli, Masih Aminbeidokhti, Marco Pedersoli, Eugene Belilovsky, Edouard Oyallon",http://arxiv.org/pdf/2405.17517v1,cs.LG
Time Elastic Neural Networks,"We introduce and detail an atypical neural network architecture, called time
elastic neural network (teNN), for multivariate time series classification. The
novelty compared to classical neural network architecture is that it explicitly
incorporates time warping ability, as well as a new way of considering
attention. In addition, this architecture is capable of learning a dropout
strategy, thus optimizing its own architecture.Behind the design of this
architecture, our overall objective is threefold: firstly, we are aiming at
improving the accuracy of instance based classification approaches that shows
quite good performances as far as enough training data is available. Secondly
we seek to reduce the computational complexity inherent to these methods to
improve their scalability. Ideally, we seek to find an acceptable balance
between these first two criteria. And finally, we seek to enhance the
explainability of the decision provided by this kind of neural architecture.The
experiment demonstrates that the stochastic gradient descent implemented to
train a teNN is quite effective. To the extent that the selection of some
critical meta-parameters is correct, convergence is generally smooth and
fast.While maintaining good accuracy, we get a drastic gain in scalability by
first reducing the required number of reference time series, i.e. the number of
teNN cells required. Secondly, we demonstrate that, during the training
process, the teNN succeeds in reducing the number of neurons required within
each cell. Finally, we show that the analysis of the activation and attention
matrices as well as the reference time series after training provides relevant
information to interpret and explain the classification results.The comparative
study that we have carried out and which concerns around thirty diverse and
multivariate datasets shows that the teNN obtains results comparable to those
of the state of the art, in particular similar to those of a network mixing
LSTM and CNN architectures for example.",2024-05-27,Pierre-François Marteau,http://arxiv.org/pdf/2405.17516v2,cs.LG
Dual-Delayed Asynchronous SGD for Arbitrarily Heterogeneous Data,"We consider the distributed learning problem with data dispersed across
multiple workers under the orchestration of a central server. Asynchronous
Stochastic Gradient Descent (SGD) has been widely explored in such a setting to
reduce the synchronization overhead associated with parallelization. However,
the performance of asynchronous SGD algorithms often depends on a bounded
dissimilarity condition among the workers' local data, a condition that can
drastically affect their efficiency when the workers' data are highly
heterogeneous. To overcome this limitation, we introduce the
\textit{dual-delayed asynchronous SGD (DuDe-ASGD)} algorithm designed to
neutralize the adverse effects of data heterogeneity. DuDe-ASGD makes full use
of stale stochastic gradients from all workers during asynchronous training,
leading to two distinct time lags in the model parameters and data samples
utilized in the server's iterations. Furthermore, by adopting an incremental
aggregation strategy, DuDe-ASGD maintains a per-iteration computational cost
that is on par with traditional asynchronous SGD algorithms. Our analysis
demonstrates that DuDe-ASGD achieves a near-minimax-optimal convergence rate
for smooth nonconvex problems, even when the data across workers are extremely
heterogeneous. Numerical experiments indicate that DuDe-ASGD compares favorably
with existing asynchronous and synchronous SGD-based algorithms.",2024-05-27,"Xiaolu Wang, Yuchang Sun, Hoi-To Wai, Jun Zhang",http://arxiv.org/pdf/2405.16966v1,cs.LG
Large Deviations of Gaussian Neural Networks with ReLU activation,"We prove a large deviation principle for deep neural networks with Gaussian
weights and (at most linearly growing) activation functions. This generalises
earlier work, in which bounded and continuous activation functions were
considered. In practice, linearly growing activation functions such as ReLU are
most commonly used. We furthermore simplify previous expressions for the rate
function and a give power-series expansions for the ReLU case.",2024-05-27,Quirin Vogel,http://arxiv.org/pdf/2405.16958v1,cs.LG
CNN-based Compressor Mass Flow Estimator in Industrial Aircraft Vapor Cycle System,"In Vapor Cycle Systems, the mass flow sensor playsa key role for different
monitoring and control purposes. However,physical sensors can be inaccurate,
heavy, cumbersome, expensive orhighly sensitive to vibrations, which is
especially problematic whenembedded into an aircraft. The conception of a
virtual sensor, basedon other standard sensors, is a good alternative. This
paper has twomain objectives. Firstly, a data-driven model using a
ConvolutionalNeural Network is proposed to estimate the mass flow of
thecompressor. We show that it significantly outperforms the standardPolynomial
Regression model (thermodynamic maps), in terms of thestandard MSE metric and
Engineer Performance metrics. Secondly,a semi-automatic segmentation method is
proposed to compute theEngineer Performance metrics for real datasets, as the
standard MSEmetric may pose risks in analyzing the dynamic behavior of
VaporCycle Systems.",2024-05-27,"Justin Reverdi, Sixin Zhang, Saïd Aoues, Fabrice Gamboa, Serge Gratton, Thomas Pellegrini",http://arxiv.org/pdf/2406.17788v1,cs.LG
Functional Programming Paradigm of Python for Scientific Computation Pipeline Integration,"The advent of modern data processing has led to an increasing tendency
towards interdisciplinarity, which frequently involves the importation of
different technical approaches. Consequently, there is an urgent need for a
unified data control system to facilitate the integration of varying libraries.
This integration is of profound significance in accelerating prototype
verification, optimising algorithm performance and minimising maintenance
costs. This paper presents a novel functional programming (FP) paradigm based
on the Python architecture and associated suites in programming practice,
designed for the integration of pipelines of different data mapping operations.
In particular, the solution is intended for the integration of scientific
computation flows, which affords a robust yet flexible solution for the
aforementioned challenges.",2024-05-27,"Chen Zhang, Lecheng Jia, Wei Zhang, Ning Wen",http://arxiv.org/pdf/2405.16956v2,cs.LG
Convergence of SGD with momentum in the nonconvex case: A time window-based analysis,"The stochastic gradient descent method with momentum (SGDM) is a common
approach for solving large-scale and stochastic optimization problems. Despite
its popularity, the convergence behavior of SGDM remains less understood in
nonconvex scenarios. This is primarily due to the absence of a sufficient
descent property and challenges in simultaneously controlling the momentum and
stochastic errors in an almost sure sense. To address these challenges, we
investigate the behavior of SGDM over specific time windows, rather than
examining the descent of consecutive iterates as in traditional studies. This
time window-based approach simplifies the convergence analysis and enables us
to establish the iterate convergence result for SGDM under the {\L}ojasiewicz
property. We further provide local convergence rates which depend on the
underlying {\L}ojasiewicz exponent and the utilized step size schemes.",2024-05-27,"Junwen Qiu, Bohao Ma, Andre Milzarek",http://arxiv.org/pdf/2405.16954v3,cs.LG
Fast ML-driven Analog Circuit Layout using Reinforcement Learning and Steiner Trees,"This paper presents an artificial intelligence driven methodology to reduce
the bottleneck often encountered in the analog ICs layout phase. We frame the
floorplanning problem as a Markov Decision Process and leverage reinforcement
learning for automatic placement generation under established topological
constraints. Consequently, we introduce Steiner tree-based methods for the
global routing step and generate guiding paths to be used to connect every
circuit block. Finally, by integrating these solutions into a procedural
generation framework, we present a unified pipeline that bridges the divide
between circuit design and verification steps. Experimental results demonstrate
the efficacy in generating complete layouts, eventually reducing runtimes to
1.5% compared to manual efforts.",2024-05-27,"Davide Basso, Luca Bortolussi, Mirjana Videnovic-Misic, Husni Habal",http://arxiv.org/pdf/2405.16951v1,cs.LG
Demystifying amortized causal discovery with transformers,"Supervised learning approaches for causal discovery from observational data
often achieve competitive performance despite seemingly avoiding explicit
assumptions that traditional methods make for identifiability. In this work, we
investigate CSIvA (Ke et al., 2023), a transformer-based model promising to
train on synthetic data and transfer to real data. First, we bridge the gap
with existing identifiability theory and show that constraints on the training
data distribution implicitly define a prior on the test observations.
Consistent with classical approaches, good performance is achieved when we have
a good prior on the test data, and the underlying model is identifiable. At the
same time, we find new trade-offs. Training on datasets generated from
different classes of causal models, unambiguously identifiable in isolation,
improves the test generalization. Performance is still guaranteed, as the
ambiguous cases resulting from the mixture of identifiable causal models are
unlikely to occur (which we formally prove). Overall, our study finds that
amortized causal discovery still needs to obey identifiability theory, but it
also differs from classical methods in how the assumptions are formulated,
trading more reliance on assumptions on the noise type for fewer hypotheses on
the mechanisms.",2024-05-27,"Francesco Montagna, Max Cairney-Leeming, Dhanya Sridhar, Francesco Locatello",http://arxiv.org/pdf/2405.16924v2,cs.LG
Theories of synaptic memory consolidation and intelligent plasticity for continual learning,"Humans and animals learn throughout life. Such continual learning is crucial
for intelligence. In this chapter, we examine the pivotal role plasticity
mechanisms with complex internal synaptic dynamics could play in enabling this
ability in neural networks. By surveying theoretical research, we highlight two
fundamental enablers for continual learning. First, synaptic plasticity
mechanisms must maintain and evolve an internal state over several behaviorally
relevant timescales. Second, plasticity algorithms must leverage the internal
state to intelligently regulate plasticity at individual synapses to facilitate
the seamless integration of new memories while avoiding detrimental
interference with existing ones. Our chapter covers successful applications of
these principles to deep neural networks and underscores the significance of
synaptic metaplasticity in sustaining continual learning capabilities. Finally,
we outline avenues for further research to understand the brain's superb
continual learning abilities and harness similar mechanisms for artificial
intelligence systems.",2024-05-27,"Friedemann Zenke, Axel Laborieux",http://arxiv.org/pdf/2405.16922v2,cs.LG
The Uncanny Valley: Exploring Adversarial Robustness from a Flatness Perspective,"Flatness of the loss surface not only correlates positively with
generalization, but is also related to adversarial robustness since
perturbations of inputs relate non-linearly to perturbations of weights. In
this paper, we empirically analyze the relation between adversarial examples
and relative flatness with respect to the parameters of one layer. We observe a
peculiar property of adversarial examples in the context of relative flatness:
during an iterative first-order white-box attack, the flatness of the loss
surface measured around the adversarial example first becomes sharper until the
label is flipped, but if we keep the attack running, it runs into a flat
uncanny valley where the label remains flipped. In extensive experiments, we
observe this phenomenon across various model architectures and datasets, even
for adversarially trained models. Our results also extend to large language
models (LLMs), but due to the discrete nature of the input space and
comparatively weak attacks, adversarial examples rarely reach truly flat
regions. Most importantly, this phenomenon shows that flatness alone cannot
explain adversarial robustness unless we can also guarantee the behavior of the
function around the examples. We, therefore theoretically connect relative
flatness to adversarial robustness by bounding the third derivative of the loss
surface, underlining the need for flatness in combination with a low global
Lipschitz constant for a robust model.",2024-05-27,"Nils Philipp Walter, Linara Adilova, Jilles Vreeken, Michael Kamp",http://arxiv.org/pdf/2405.16918v2,cs.LG
Multilingual Diversity Improves Vision-Language Representations,"Massive web-crawled image-text datasets lay the foundation for recent
progress in multimodal learning. These datasets are designed with the goal of
training a model to do well on standard computer vision benchmarks, many of
which, however, have been shown to be English-centric (e.g., ImageNet).
Consequently, existing data curation techniques gravitate towards using
predominantly English image-text pairs and discard many potentially useful
non-English samples. Our work questions this practice. Multilingual data is
inherently enriching not only because it provides a gateway to learn about
culturally salient concepts, but also because it depicts common concepts
differently from monolingual data. We thus conduct a systematic study to
explore the performance benefits of using more samples of non-English origins
with respect to English vision tasks. By translating all multilingual
image-text pairs from a raw web crawl to English and re-filtering them, we
increase the prevalence of (translated) multilingual data in the resulting
training set. Pre-training on this dataset outperforms using English-only or
English-dominated datasets on ImageNet, ImageNet distribution shifts,
image-English-text retrieval and on average across 38 tasks from the DataComp
benchmark. On a geographically diverse task like GeoDE, we also observe
improvements across all regions, with the biggest gain coming from Africa. In
addition, we quantitatively show that English and non-English data are
significantly different in both image and (translated) text space. We hope that
our findings motivate future work to be more intentional about including
multicultural and multilingual data, not just when non-English or
geographically diverse tasks are involved, but to enhance model capabilities at
large.",2024-05-27,"Thao Nguyen, Matthew Wallingford, Sebastin Santy, Wei-Chiu Ma, Sewoong Oh, Ludwig Schmidt, Pang Wei Koh, Ranjay Krishna",http://arxiv.org/pdf/2405.16915v2,cs.LG
GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning,"Offline Reinforcement Learning (Offline RL) presents challenges of learning
effective decision-making policies from static datasets without any online
interactions. Data augmentation techniques, such as noise injection and data
synthesizing, aim to improve Q-function approximation by smoothing the learned
state-action region. However, these methods often fall short of directly
improving the quality of offline datasets, leading to suboptimal results. In
response, we introduce GTA, Generative Trajectory Augmentation, a novel
generative data augmentation approach designed to enrich offline data by
augmenting trajectories to be both high-rewarding and dynamically plausible.
GTA applies a diffusion model within the data augmentation framework. GTA
partially noises original trajectories and then denoises them with
classifier-free guidance via conditioning on amplified return value. Our
results show that GTA, as a general data augmentation strategy, enhances the
performance of widely used offline RL algorithms across various tasks with
unique challenges. Furthermore, we conduct a quality analysis of data augmented
by GTA and demonstrate that GTA improves the quality of the data. Our code is
available at https://github.com/Jaewoopudding/GTA",2024-05-27,"Jaewoo Lee, Sujin Yun, Taeyoung Yun, Jinkyoo Park",http://arxiv.org/pdf/2405.16907v5,cs.LG
Harnessing the Power of Vicinity-Informed Analysis for Classification under Covariate Shift,"Transfer learning enhances prediction accuracy on a target distribution by
leveraging data from a source distribution, demonstrating significant benefits
in various applications. This paper introduces a novel dissimilarity measure
that utilizes vicinity information, i.e., the local structure of data points,
to analyze the excess error in classification under covariate shift, a transfer
learning setting where marginal feature distributions differ but conditional
label distributions remain the same. We characterize the excess error using the
proposed measure and demonstrate faster or competitive convergence rates
compared to previous techniques. Notably, our approach is effective in the
support non-containment assumption, which often appears in real-world
applications, holds. Our theoretical analysis bridges the gap between current
theoretical findings and empirical observations in transfer learning,
particularly in scenarios with significant differences between source and
target distributions.",2024-05-27,"Mitsuhiro Fujikawa, Yohei Akimoto, Jun Sakuma, Kazuto Fukuchi",http://arxiv.org/pdf/2405.16906v2,cs.LG
Predicting from a Different Perspective: A Re-ranking Model for Inductive Knowledge Graph Completion,"Rule-induction models have demonstrated great power in the inductive setting
of knowledge graph completion. In this setting, the models are tested on a
knowledge graph entirely composed of unseen entities. These models learn
relation patterns as rules by utilizing subgraphs. Providing the same inputs
with different rules leads to differences in the model's predictions. In this
paper, we focus on the behavior of such models. We propose a re-ranking-based
model called ReDistLP (Re-ranking with a Distinct Model for Link Prediction).
This model enhances the effectiveness of re-ranking by leveraging the
difference in the predictions between the initial retriever and the re-ranker.
ReDistLP outperforms the state-of-the-art methods in 2 out of 3 benchmarks.",2024-05-27,"Yuki Iwamoto, Ken Kaneiwa",http://arxiv.org/pdf/2405.16902v2,cs.LG
Recurrent and Convolutional Neural Networks in Classification of EEG Signal for Guided Imagery and Mental Workload Detection,"The Guided Imagery technique is reported to be used by therapists all over
the world in order to increase the comfort of patients suffering from a variety
of disorders from mental to oncology ones and proved to be successful in
numerous of ways. Possible support for the therapists can be estimation of the
time at which subject goes into deep relaxation. This paper presents the
results of the investigations of a cohort of 26 students exposed to Guided
Imagery relaxation technique and mental task workloads conducted with the use
of dense array electroencephalographic amplifier. The research reported herein
aimed at verification whether it is possible to detect differences between
those two states and to classify them using deep learning methods and recurrent
neural networks such as EEGNet, Long Short-Term Memory-based classifier, 1D
Convolutional Neural Network and hybrid model of 1D Convolutional Neural
Network and Long Short-Term Memory. The data processing pipeline was presented
from the data acquisition, through the initial data cleaning, preprocessing and
postprocessing. The classification was based on two datasets: one of them using
26 so-called cognitive electrodes and the other one using signal collected from
256 channels. So far there have not been such comparisons in the application
being discussed. The classification results are presented by the validation
metrics such as: accuracy, recall, precision, F1-score and loss for each case.
It turned out that it is not necessary to collect signals from all electrodes
as classification of the cognitive ones gives the results similar to those
obtained for the full signal and extending input to 256 channels does not add
much value. In Disscussion there were proposed an optimal classifier as well as
some suggestions concerning the prospective development of the project.",2024-05-27,"Filip Postepski, Grzegorz M. Wojcik, Krzysztof Wrobel, Andrzej Kawiak, Katarzyna Zemla, Grzegorz Sedek",http://arxiv.org/pdf/2405.16901v2,cs.LG
Partial Models for Building Adaptive Model-Based Reinforcement Learning Agents,"In neuroscience, one of the key behavioral tests for determining whether a
subject of study exhibits model-based behavior is to study its adaptiveness to
local changes in the environment. In reinforcement learning, however, recent
studies have shown that modern model-based agents display poor adaptivity to
such changes. The main reason for this is that modern agents are typically
designed to improve sample efficiency in single task settings and thus do not
take into account the challenges that can arise in other settings. In local
adaptation settings, one particularly important challenge is in quickly
building and maintaining a sufficiently accurate model after a local change.
This is challenging for deep model-based agents as their models and replay
buffers are monolithic structures lacking distribution shift handling
capabilities. In this study, we show that the conceptually simple idea of
partial models can allow deep model-based agents to overcome this challenge and
thus allow for building locally adaptive model-based agents. By modeling the
different parts of the state space through different models, the agent can not
only maintain a model that is accurate across the state space, but it can also
quickly adapt it in the presence of a local change in the environment. We
demonstrate this by showing that the use of partial models in agents such as
deep Dyna-Q, PlaNet and Dreamer can allow for them to effectively adapt to the
local changes in their environments.",2024-05-27,"Safa Alver, Ali Rahimi-Kalahroudi, Doina Precup",http://arxiv.org/pdf/2405.16899v1,cs.LG
On Fairness of Low-Rank Adaptation of Large Models,"Low-rank adaptation of large models, particularly LoRA, has gained traction
due to its computational efficiency. This efficiency, contrasted with the
prohibitive costs of full-model fine-tuning, means that practitioners often
turn to LoRA and sometimes without a complete understanding of its
ramifications. In this study, we focus on fairness and ask whether LoRA has an
unexamined impact on utility, calibration, and resistance to membership
inference across different subgroups (e.g., genders, races, religions) compared
to a full-model fine-tuning baseline. We present extensive experiments across
vision and language domains and across classification and generation tasks
using ViT-Base, Swin-v2-Large, Llama-2 7B, and Mistral 7B. Intriguingly,
experiments suggest that while one can isolate cases where LoRA exacerbates
model bias across subgroups, the pattern is inconsistent -- in many cases, LoRA
has equivalent or even improved fairness compared to the base model or its full
fine-tuning baseline. We also examine the complications of evaluating
fine-tuning fairness relating to task design and model token bias, calling for
more careful fairness evaluations in future work.",2024-05-27,"Zhoujie Ding, Ken Ziyu Liu, Pura Peetathawatchai, Berivan Isik, Sanmi Koyejo",http://arxiv.org/pdf/2405.17512v2,cs.LG
Scorch: A Library for Sparse Deep Learning,"The rapid growth in the size of deep learning models strains the capabilities
of traditional dense computation paradigms. Leveraging sparse computation has
become increasingly popular for training and deploying large-scale models, but
existing deep learning frameworks lack extensive support for sparse operations.
To bridge this gap, we introduce Scorch, a library that seamlessly integrates
efficient sparse tensor computation into the PyTorch ecosystem, with an initial
focus on inference workloads on CPUs. Scorch provides a flexible and intuitive
interface for sparse tensors, supporting diverse sparse data structures. Scorch
introduces a compiler stack that automates key optimizations, including
automatic loop ordering, tiling, and format inference. Combined with a runtime
that adapts its execution to both dense and sparse data, Scorch delivers
substantial speedups over hand-written PyTorch Sparse (torch.sparse) operations
without sacrificing usability. More importantly, Scorch enables efficient
computation of complex sparse operations that lack hand-optimized PyTorch
implementations. This flexibility is crucial for exploring novel sparse
architectures. We demonstrate Scorch's ease of use and performance gains on
diverse deep learning models across multiple domains. With only minimal code
changes, Scorch achieves 1.05-5.78x speedups over PyTorch Sparse on end-to-end
tasks. Scorch's seamless integration and performance gains make it a valuable
addition to the PyTorch ecosystem. We believe Scorch will enable wider
exploration of sparsity as a tool for scaling deep learning and inform the
development of other sparse libraries.",2024-05-27,"Bobby Yan, Alexander J. Root, Trevor Gale, David Broman, Fredrik Kjolstad",http://arxiv.org/pdf/2405.16883v2,cs.LG
Reference Neural Operators: Learning the Smooth Dependence of Solutions of PDEs on Geometric Deformations,"For partial differential equations on domains of arbitrary shapes, existing
works of neural operators attempt to learn a mapping from geometries to
solutions. It often requires a large dataset of geometry-solution pairs in
order to obtain a sufficiently accurate neural operator. However, for many
industrial applications, e.g., engineering design optimization, it can be
prohibitive to satisfy the requirement since even a single simulation may take
hours or days of computation. To address this issue, we propose reference
neural operators (RNO), a novel way of implementing neural operators, i.e., to
learn the smooth dependence of solutions on geometric deformations.
Specifically, given a reference solution, RNO can predict solutions
corresponding to arbitrary deformations of the referred geometry. This approach
turns out to be much more data efficient. Through extensive experiments, we
show that RNO can learn the dependence across various types and different
numbers of geometry objects with relatively small datasets. RNO outperforms
baseline models in accuracy by a large lead and achieves up to 80% error
reduction.",2024-05-27,"Ze Cheng, Zhongkai Hao, Xiaoqiang Wang, Jianing Huang, Youjia Wu, Xudan Liu, Yiru Zhao, Songming Liu, Hang Su",http://arxiv.org/pdf/2405.17509v1,cs.LG
Unsupervised Generative Feature Transformation via Graph Contrastive Pre-training and Multi-objective Fine-tuning,"Feature transformation is to derive a new feature set from original features
to augment the AI power of data. In many science domains such as material
performance screening, while feature transformation can model material formula
interactions and compositions and discover performance drivers, supervised
labels are collected from expensive and lengthy experiments. This issue
motivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior
literature, such as manual transformation, supervised feedback guided search,
and PCA, either relies on domain knowledge or expensive supervised feedback, or
suffers from large search space, or overlooks non-linear feature-feature
interactions. UFTL imposes a major challenge on existing methods: how to design
a new unsupervised paradigm that captures complex feature interactions and
avoids large search space? To fill this gap, we connect graph, contrastive, and
generative learning to develop a measurement-pretrain-finetune paradigm for
UFTL. For unsupervised feature set utility measurement, we propose a feature
value consistency preservation perspective and develop a mean discounted
cumulative gain like unsupervised metric to evaluate feature set utility. For
unsupervised feature set representation pretraining, we regard a feature set as
a feature-feature interaction graph, and develop an unsupervised graph
contrastive learning encoder to embed feature sets into vectors. For generative
transformation finetuning, we regard a feature set as a feature cross sequence
and feature transformation as sequential generation. We develop a deep
generative feature transformation model that coordinates the pretrained feature
set encoder and the gradient information extracted from a feature set utility
evaluator to optimize a transformed feature generator.",2024-05-27,"Wangyang Ying, Dongjie Wang, Xuanming Hu, Yuanchun Zhou, Charu C. Aggarwal, Yanjie Fu",http://arxiv.org/pdf/2405.16879v1,cs.LG
Are Self-Attentions Effective for Time Series Forecasting?,"Time series forecasting is crucial for applications across multiple domains
and various scenarios. Although Transformer models have dramatically advanced
the landscape of forecasting, their effectiveness remains debated. Recent
findings have indicated that simpler linear models might outperform complex
Transformer-based approaches, highlighting the potential for more streamlined
architectures. In this paper, we shift the focus from evaluating the overall
Transformer architecture to specifically examining the effectiveness of
self-attention for time series forecasting. To this end, we introduce a new
architecture, Cross-Attention-only Time Series transformer (CATS), that
rethinks the traditional Transformer framework by eliminating self-attention
and leveraging cross-attention mechanisms instead. By establishing future
horizon-dependent parameters as queries and enhanced parameter sharing, our
model not only improves long-term forecasting accuracy but also reduces the
number of parameters and memory usage. Extensive experiment across various
datasets demonstrates that our model achieves superior performance with the
lowest mean squared error and uses fewer parameters compared to existing
models. The implementation of our model is available at:
https://github.com/dongbeank/CATS.",2024-05-27,"Dongbin Kim, Jinseong Park, Jaewook Lee, Hoki Kim",http://arxiv.org/pdf/2405.16877v3,cs.LG
Transfer Learning for Diffusion Models,"Diffusion models, a specific type of generative model, have achieved
unprecedented performance in recent years and consistently produce high-quality
synthetic samples. A critical prerequisite for their notable success lies in
the presence of a substantial number of training samples, which can be
impractical in real-world applications due to high collection costs or
associated risks. Consequently, various finetuning and regularization
approaches have been proposed to transfer knowledge from existing pre-trained
models to specific target domains with limited data. This paper introduces the
Transfer Guided Diffusion Process (TGDP), a novel approach distinct from
conventional finetuning and regularization methods. We prove that the optimal
diffusion model for the target domain integrates pre-trained diffusion models
on the source domain with additional guidance from a domain classifier. We
further extend TGDP to a conditional version for modeling the joint
distribution of data and its corresponding labels, together with two additional
regularization terms to enhance the model performance. We validate the
effectiveness of TGDP on both simulated and real-world datasets.",2024-05-27,"Yidong Ouyang, Liyan Xie, Hongyuan Zha, Guang Cheng",http://arxiv.org/pdf/2405.16876v3,cs.LG
On Conformal Isometry of Grid Cells: Learning Distance-Preserving Position Embedding,"This paper investigates the conformal isometry hypothesis as a potential
explanation for the hexagonal periodic patterns in grid cell response maps. We
posit that grid cell activities form a high-dimensional vector in neural space,
encoding the agent's position in 2D physical space. As the agent moves, this
vector rotates within a 2D manifold in the neural space, driven by a recurrent
neural network. The conformal hypothesis proposes that this neural manifold is
a conformal isometric embedding of 2D physical space, where local physical
distance is preserved by the embedding up to a scaling factor (or unit of
metric). Such distance-preserving position embedding is indispensable for path
planning in navigation, especially planning local straight path segments. We
conduct numerical experiments to show that this hypothesis leads to the
hexagonal grid firing patterns by learning maximally distance-preserving
position embedding, agnostic to the choice of the recurrent neural network.
Furthermore, we present a theoretical explanation of why hexagon periodic
patterns emerge by minimizing our loss function by showing that hexagon flat
torus is maximally distance preserving.",2024-05-27,"Dehong Xu, Ruiqi Gao, Wen-Hao Zhang, Xue-Xin Wei, Ying Nian Wu",http://arxiv.org/pdf/2405.16865v4,cs.LG
BInD: Bond and Interaction-generating Diffusion Model for Multi-objective Structure-based Drug Design,"A remarkable advance in geometric deep generative models with accumulated
structural data enables structure-based drug design (SBDD) with target protein
information only. However, most existing models struggle to address
multi-objectives simultaneously while performing well only in their specialized
tasks. Here, we present BInD, a diffusion model with knowledge-based guidance
for multi-objective SBDD. BInD is designed to co-generate molecules and their
interactions with a target protein to consider all key objectives equally well,
including target-specific interactions, molecular properties, and local
geometry. Comprehensive evaluations show that BInD achieves robust performance
for all objectives while outperforming or matching state-of-the-art methods for
each. Finally, we propose a train-free optimization method empowered by
retrieving target-specific interactions, highlighting the role of non-covalent
interactions in achieving higher selectivity and binding affinities to a target
protein.",2024-05-27,"Joongwon Lee, Wonho Zhung, Jisu Seo, Woo Youn Kim",http://arxiv.org/pdf/2405.16861v2,cs.LG
EM Distillation for One-step Diffusion Models,"While diffusion models can learn complex distributions, sampling requires a
computationally expensive iterative process. Existing distillation methods
enable efficient sampling, but have notable limitations, such as performance
degradation with very few sampling steps, reliance on training data access, or
mode-seeking optimization that may fail to capture the full distribution. We
propose EM Distillation (EMD), a maximum likelihood-based approach that
distills a diffusion model to a one-step generator model with minimal loss of
perceptual quality. Our approach is derived through the lens of
Expectation-Maximization (EM), where the generator parameters are updated using
samples from the joint distribution of the diffusion teacher prior and inferred
generator latents. We develop a reparametrized sampling scheme and a noise
cancellation technique that together stabilizes the distillation process. We
further reveal an interesting connection of our method with existing methods
that minimize mode-seeking KL. EMD outperforms existing one-step generative
methods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares
favorably with prior work on distilling text-to-image diffusion models.",2024-05-27,"Sirui Xie, Zhisheng Xiao, Diederik P Kingma, Tingbo Hou, Ying Nian Wu, Kevin Patrick Murphy, Tim Salimans, Ben Poole, Ruiqi Gao",http://arxiv.org/pdf/2405.16852v2,cs.LG
Temporal Spiking Neural Networks with Synaptic Delay for Graph Reasoning,"Spiking neural networks (SNNs) are investigated as biologically inspired
models of neural computation, distinguished by their computational capability
and energy efficiency due to precise spiking times and sparse spikes with
event-driven computation. A significant question is how SNNs can emulate
human-like graph-based reasoning of concepts and relations, especially
leveraging the temporal domain optimally. This paper reveals that SNNs, when
amalgamated with synaptic delay and temporal coding, are proficient in
executing (knowledge) graph reasoning. It is elucidated that spiking time can
function as an additional dimension to encode relation properties via a
neural-generalized path formulation. Empirical results highlight the efficacy
of temporal delay in relation processing and showcase exemplary performance in
diverse graph reasoning tasks. The spiking model is theoretically estimated to
achieve $20\times$ energy savings compared to non-spiking counterparts,
deepening insights into the capabilities and potential of biologically inspired
SNNs for efficient reasoning. The code is available at
https://github.com/pkuxmq/GRSNN.",2024-05-27,"Mingqing Xiao, Yixin Zhu, Di He, Zhouchen Lin",http://arxiv.org/pdf/2405.16851v1,cs.LG
UniCompress: Enhancing Multi-Data Medical Image Compression with Knowledge Distillation,"In the field of medical image compression, Implicit Neural Representation
(INR) networks have shown remarkable versatility due to their flexible
compression ratios, yet they are constrained by a one-to-one fitting approach
that results in lengthy encoding times. Our novel method,
``\textbf{UniCompress}'', innovatively extends the compression capabilities of
INR by being the first to compress multiple medical data blocks using a single
INR network. By employing wavelet transforms and quantization, we introduce a
codebook containing frequency domain information as a prior input to the INR
network. This enhances the representational power of INR and provides
distinctive conditioning for different image blocks. Furthermore, our research
introduces a new technique for the knowledge distillation of implicit
representations, simplifying complex model knowledge into more manageable
formats to improve compression ratios. Extensive testing on CT and electron
microscopy (EM) datasets has demonstrated that UniCompress outperforms
traditional INR methods and commercial compression solutions like HEVC,
especially in complex and high compression scenarios. Notably, compared to
existing INR techniques, UniCompress achieves a 4$\sim$5 times increase in
compression speed, marking a significant advancement in the field of medical
image compression. Codes will be publicly available.",2024-05-27,"Runzhao Yang, Yinda Chen, Zhihong Zhang, Xiaoyu Liu, Zongren Li, Kunlun He, Zhiwei Xiong, Jinli Suo, Qionghai Dai",http://arxiv.org/pdf/2405.16850v1,cs.LG
On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability,"Autoregressively trained transformers have brought a profound revolution to
the world, especially with their in-context learning (ICL) ability to address
downstream tasks. Recently, several studies suggest that transformers learn a
mesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely,
the forward pass of the trained transformer is equivalent to optimizing an
inner objective function in-context. However, whether the practical non-convex
training dynamics will converge to the ideal mesa-optimizer is still unclear.
Towards filling this gap, we investigate the non-convex dynamics of a one-layer
linear causal self-attention model autoregressively trained by gradient flow,
where the sequences are generated by an AR process $x_{t+1} = W x_t$. First,
under a certain condition of data distribution, we prove that an
autoregressively trained transformer learns $W$ by implementing one step of
gradient descent to minimize an ordinary least squares (OLS) problem
in-context. It then applies the learned $\widehat{W}$ for next-token
prediction, thereby verifying the mesa-optimization hypothesis. Next, under the
same data conditions, we explore the capability limitations of the obtained
mesa-optimizer. We show that a stronger assumption related to the moments of
data is the sufficient and necessary condition that the learned mesa-optimizer
recovers the distribution. Besides, we conduct exploratory analyses beyond the
first data condition and prove that generally, the trained transformer will not
perform vanilla gradient descent for the OLS problem. Finally, our simulation
results verify the theoretical results.",2024-05-27,"Chenyu Zheng, Wei Huang, Rongzhen Wang, Guoqiang Wu, Jun Zhu, Chongxuan Li",http://arxiv.org/pdf/2405.16845v2,cs.LG
Non-stochastic Bandits With Evolving Observations,"We introduce a novel online learning framework that unifies and generalizes
pre-established models, such as delayed and corrupted feedback, to encompass
adversarial environments where action feedback evolves over time. In this
setting, the observed loss is arbitrary and may not correlate with the true
loss incurred, with each round updating previous observations adversarially. We
propose regret minimization algorithms for both the full-information and bandit
settings, with regret bounds quantified by the average feedback accuracy
relative to the true loss. Our algorithms match the known regret bounds across
many special cases, while also introducing previously unknown bounds.",2024-05-27,"Yogev Bar-On, Yishay Mansour",http://arxiv.org/pdf/2405.16843v1,cs.LG
Enhancing Accuracy in Generative Models via Knowledge Transfer,"This paper investigates the accuracy of generative models and the impact of
knowledge transfer on their generation precision. Specifically, we examine a
generative model for a target task, fine-tuned using a pre-trained model from a
source task. Building on the ""Shared Embedding"" concept, which bridges the
source and target tasks, we introduce a novel framework for transfer learning
under distribution metrics such as the Kullback-Leibler divergence. This
framework underscores the importance of leveraging inherent similarities
between diverse tasks despite their distinct data distributions. Our theory
suggests that the shared structures can augment the generation accuracy for a
target task, reliant on the capability of a source model to identify shared
structures and effective knowledge transfer from source to target learning. To
demonstrate the practical utility of this framework, we explore the theoretical
implications for two specific generative models: diffusion and normalizing
flows. The results show enhanced performance in both models over their
non-transfer counterparts, indicating advancements for diffusion models and
providing fresh insights into normalizing flows in transfer and non-transfer
settings. These results highlight the significant contribution of knowledge
transfer in boosting the generation capabilities of these models.",2024-05-27,"Xinyu Tian, Xiaotong Shen",http://arxiv.org/pdf/2405.16837v2,cs.LG
Enhancing Fast Feed Forward Networks with Load Balancing and a Master Leaf Node,"Fast feedforward networks (FFFs) are a class of neural networks that exploit
the observation that different regions of the input space activate distinct
subsets of neurons in wide networks. FFFs partition the input space into
separate sections using a differentiable binary tree of neurons and during
inference descend the binary tree in order to improve computational efficiency.
Inspired by Mixture of Experts (MoE) research, we propose the incorporation of
load balancing and Master Leaf techniques into the FFF architecture to improve
performance and simplify the training process. We reproduce experiments found
in literature and present results on FFF models enhanced using these
techniques. The proposed architecture and training recipe achieves up to 16.3%
and 3% absolute classification accuracy increase in training and test accuracy,
respectively, compared to the original FFF architecture. Additionally, we
observe a smaller variance in the results compared to those reported in prior
research. These findings demonstrate the potential of integrating MoE-inspired
techniques into FFFs for developing more accurate and efficient models.",2024-05-27,"Andreas Charalampopoulos, Nikolas Chatzis, Foivos Ntoulas-Panagiotopoulos, Charilaos Papaioannou, Alexandros Potamianos",http://arxiv.org/pdf/2405.16836v1,cs.LG
Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models,"While large language models (LLMs) such as Llama-2 or GPT-4 have shown
impressive zero-shot performance, fine-tuning is still necessary to enhance
their performance for customized datasets, domain-specific tasks, or other
private needs. However, fine-tuning all parameters of LLMs requires significant
hardware resources, which can be impractical for typical users. Therefore,
parameter-efficient fine-tuning such as LoRA have emerged, allowing users to
fine-tune LLMs without the need for considerable computing resources, with
little performance degradation compared to fine-tuning all parameters.
Unfortunately, recent studies indicate that fine-tuning can increase the risk
to the safety of LLMs, even when data does not contain malicious content. To
address this challenge, we propose Safe LoRA, a simple one-liner patch to the
original LoRA implementation by introducing the projection of LoRA weights from
selected layers to the safety-aligned subspace, effectively reducing the safety
risks in LLM fine-tuning while maintaining utility. It is worth noting that
Safe LoRA is a training-free and data-free approach, as it only requires the
knowledge of the weights from the base and aligned LLMs. Our extensive
experiments demonstrate that when fine-tuning on purely malicious data, Safe
LoRA retains similar safety performance as the original aligned model.
Moreover, when the fine-tuning dataset contains a mixture of both benign and
malicious data, Safe LoRA mitigates the negative effect made by malicious data
while preserving performance on downstream tasks. Our codes are available at
\url{https://github.com/IBM/SafeLoRA}.",2024-05-27,"Chia-Yi Hsu, Yu-Lin Tsai, Chih-Hsun Lin, Pin-Yu Chen, Chia-Mu Yu, Chun-Ying Huang",http://arxiv.org/pdf/2405.16833v2,cs.LG
Structured Graph Network for Constrained Robot Crowd Navigation with Low Fidelity Simulation,"We investigate the feasibility of deploying reinforcement learning (RL)
policies for constrained crowd navigation using a low-fidelity simulator. We
introduce a representation of the dynamic environment, separating human and
obstacle representations. Humans are represented through detected states, while
obstacles are represented as computed point clouds based on maps and robot
localization. This representation enables RL policies trained in a low-fidelity
simulator to deploy in real world with a reduced sim2real gap. Additionally, we
propose a spatio-temporal graph to model the interactions between agents and
obstacles. Based on the graph, we use attention mechanisms to capture the
robot-human, human-human, and human-obstacle interactions. Our method
significantly improves navigation performance in both simulated and real-world
environments. Video demonstrations can be found at
https://sites.google.com/view/constrained-crowdnav/home.",2024-05-27,"Shuijing Liu, Kaiwen Hong, Neeloy Chakraborty, Katherine Driggs-Campbell",http://arxiv.org/pdf/2405.16830v2,cs.LG
Kernel-based optimally weighted conformal prediction intervals,"Conformal prediction has been a popular distribution-free framework for
uncertainty quantification. In this paper, we present a novel conformal
prediction method for time-series, which we call Kernel-based Optimally
Weighted Conformal Prediction Intervals (KOWCPI). Specifically, KOWCPI adapts
the classic Reweighted Nadaraya-Watson (RNW) estimator for quantile regression
on dependent data and learns optimal data-adaptive weights. Theoretically, we
tackle the challenge of establishing a conditional coverage guarantee for
non-exchangeable data under strong mixing conditions on the non-conformity
scores. We demonstrate the superior performance of KOWCPI on real time-series
against state-of-the-art methods, where KOWCPI achieves narrower confidence
intervals without losing coverage.",2024-05-27,"Jonghyeok Lee, Chen Xu, Yao Xie",http://arxiv.org/pdf/2405.16828v1,cs.LG
Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings,"The rapid proliferation of generative AI has raised questions about the
competitiveness of lower-parameter, locally tunable, open-weight models
relative to high-parameter, API-guarded, closed-weight models in terms of
performance, domain adaptation, cost, and generalization. Centering
under-resourced yet risk-intolerant settings in government, research, and
healthcare, we see for-profit closed-weight models as incompatible with
requirements for transparency, privacy, adaptability, and standards of
evidence. Yet the performance penalty in using open-weight models, especially
in low-data and low-resource settings, is unclear.
  We assess the feasibility of using smaller, open-weight models to replace
GPT-4-Turbo in zero-shot, few-shot, and fine-tuned regimes, assuming access to
only a single, low-cost GPU. We assess value-sensitive issues around bias,
privacy, and abstention on three additional tasks relevant to those topics. We
find that with relatively low effort, very low absolute monetary cost, and
relatively little data for fine-tuning, small open-weight models can achieve
competitive performance in domain-adapted tasks without sacrificing generality.
We then run experiments considering practical issues in bias, privacy, and
hallucination risk, finding that open models offer several benefits over closed
models. We intend this work as a case study in understanding the opportunity
cost of reproducibility and transparency over for-profit state-of-the-art zero
shot performance, finding this cost to be marginal under realistic settings.",2024-05-27,"Robert Wolfe, Isaac Slaughter, Bin Han, Bingbing Wen, Yiwei Yang, Lucas Rosenblatt, Bernease Herman, Eva Brown, Zening Qu, Nic Weber, Bill Howe",http://arxiv.org/pdf/2405.16820v1,cs.LG
Federated Learning with Blockchain-Enhanced Machine Unlearning: A Trustworthy Approach,"With the growing need to comply with privacy regulations and respond to user
data deletion requests, integrating machine unlearning into IoT-based federated
learning has become imperative. Traditional unlearning methods, however, often
lack verifiable mechanisms, leading to challenges in establishing trust. This
paper delves into the innovative integration of blockchain technology with
federated learning to surmount these obstacles. Blockchain fortifies the
unlearning process through its inherent qualities of immutability,
transparency, and robust security. It facilitates verifiable certification,
harmonizes security with privacy, and sustains system efficiency. We introduce
a framework that melds blockchain with federated learning, thereby ensuring an
immutable record of unlearning requests and actions. This strategy not only
bolsters the trustworthiness and integrity of the federated learning model but
also adeptly addresses efficiency and security challenges typical in IoT
environments. Our key contributions encompass a certification mechanism for the
unlearning process, the enhancement of data security and privacy, and the
optimization of data management to ensure system responsiveness in IoT
scenarios.",2024-05-27,"Xuhan Zuo, Minghao Wang, Tianqing Zhu, Lefeng Zhang, Shui Yu, Wanlei Zhou",http://arxiv.org/pdf/2405.20776v1,cs.LG
Automatic Domain Adaptation by Transformers in In-Context Learning,"Selecting or designing an appropriate domain adaptation algorithm for a given
problem remains challenging. This paper presents a Transformer model that can
provably approximate and opt for domain adaptation methods for a given dataset
in the in-context learning framework, where a foundation model performs new
tasks without updating its parameters at test time. Specifically, we prove that
Transformers can approximate instance-based and feature-based unsupervised
domain adaptation algorithms and automatically select an algorithm suited for a
given dataset. Numerical results indicate that in-context learning demonstrates
an adaptive domain adaptation surpassing existing methods.",2024-05-27,"Ryuichiro Hataya, Kota Matsui, Masaaki Imaizumi",http://arxiv.org/pdf/2405.16819v1,cs.LG
Trajectory Data Suffices for Statistically Efficient Learning in Offline RL with Linear $q^π$-Realizability and Concentrability,"We consider offline reinforcement learning (RL) in $H$-horizon Markov
decision processes (MDPs) under the linear $q^\pi$-realizability assumption,
where the action-value function of every policy is linear with respect to a
given $d$-dimensional feature function. The hope in this setting is that
learning a good policy will be possible without requiring a sample size that
scales with the number of states in the MDP. Foster et al. [2021] have shown
this to be impossible even under $\textit{concentrability}$, a data coverage
assumption where a coefficient $C_\text{conc}$ bounds the extent to which the
state-action distribution of any policy can veer off the data distribution.
However, the data in this previous work was in the form of a sequence of
individual transitions. This leaves open the question of whether the negative
result mentioned could be overcome if the data was composed of sequences of
full trajectories. In this work we answer this question positively by proving
that with trajectory data, a dataset of size
$\text{poly}(d,H,C_\text{conc})/\epsilon^2$ is sufficient for deriving an
$\epsilon$-optimal policy, regardless of the size of the state space. The main
tool that makes this result possible is due to Weisz et al. [2023], who
demonstrate that linear MDPs can be used to approximate linearly
$q^\pi$-realizable MDPs. The connection to trajectory data is that the linear
MDP approximation relies on ""skipping"" over certain states. The associated
estimation problems are thus easy when working with trajectory data, while they
remain nontrivial when working with individual transitions. The question of
computational efficiency under our assumptions remains open.",2024-05-27,"Volodymyr Tkachuk, Gellért Weisz, Csaba Szepesvári",http://arxiv.org/pdf/2405.16809v1,cs.LG
Gradient Compressed Sensing: A Query-Efficient Gradient Estimator for High-Dimensional Zeroth-Order Optimization,"We study nonconvex zeroth-order optimization (ZOO) in a high-dimensional
space $\mathbb R^d$ for functions with approximately $s$-sparse gradients. To
reduce the dependence on the dimensionality $d$ in the query complexity,
high-dimensional ZOO methods seek to leverage gradient sparsity to design
gradient estimators. The previous best method needs $O\big(s\log\frac ds\big)$
queries per step to achieve $O\big(\frac1T\big)$ rate of convergence w.r.t. the
number T of steps. In this paper, we propose *Gradient Compressed Sensing*
(GraCe), a query-efficient and accurate estimator for sparse gradients that
uses only $O\big(s\log\log\frac ds\big)$ queries per step and still achieves
$O\big(\frac1T\big)$ rate of convergence. To our best knowledge, we are the
first to achieve a *double-logarithmic* dependence on $d$ in the query
complexity under weaker assumptions. Our proposed GraCe generalizes the
Indyk--Price--Woodruff (IPW) algorithm in compressed sensing from linear
measurements to nonlinear functions. Furthermore, since the IPW algorithm is
purely theoretical due to its impractically large constant, we improve the IPW
algorithm via our *dependent random partition* technique together with our
corresponding novel analysis and successfully reduce the constant by a factor
of nearly 4300. Our GraCe is not only theoretically query-efficient but also
achieves strong empirical performance. We benchmark our GraCe against 12
existing ZOO methods with 10000-dimensional functions and demonstrate that
GraCe significantly outperforms existing methods.",2024-05-27,"Ruizhong Qiu, Hanghang Tong",http://arxiv.org/pdf/2405.16805v2,cs.LG
AutoPSV: Automated Process-Supervised Verifier,"In this work, we propose a novel method named \textbf{Auto}mated
\textbf{P}rocess-\textbf{S}upervised \textbf{V}erifier
(\textbf{\textsc{AutoPSV}}) to enhance the reasoning capabilities of large
language models (LLMs) by automatically annotating the reasoning steps.
\textsc{AutoPSV} begins by training a verification model on the correctness of
final answers, enabling it to generate automatic process annotations. This
verification model assigns a confidence score to each reasoning step,
indicating the probability of arriving at the correct final answer from that
point onward. We detect relative changes in the verification's confidence
scores across reasoning steps to automatically annotate the reasoning process,
enabling error detection even in scenarios where ground truth answers are
unavailable. This alleviates the need for numerous manual annotations or the
high computational costs associated with model-induced annotation approaches.
We experimentally validate that the step-level confidence changes learned by
the verification model trained on the final answer correctness can effectively
identify errors in the reasoning steps. We demonstrate that the verification
model, when trained on process annotations generated by \textsc{AutoPSV},
exhibits improved performance in selecting correct answers from multiple
LLM-generated outputs. Notably, we achieve substantial improvements across five
datasets in mathematics and commonsense reasoning. The source code of
\textsc{AutoPSV} is available at \url{https://github.com/rookie-joe/AutoPSV}.",2024-05-27,"Jianqiao Lu, Zhiyang Dou, Hongru Wang, Zeyu Cao, Jianbo Dai, Yingjia Wan, Zhijiang Guo",http://arxiv.org/pdf/2405.16802v4,cs.LG
TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations,"Text-Attributed Graphs (TAGs) enhance graph structures with natural language
descriptions, enabling detailed representation of data and their relationships
across a broad spectrum of real-world scenarios. Despite the potential for
deeper insights, existing TAG representation learning primarily relies on
supervised methods, necessitating extensive labeled data and limiting
applicability across diverse contexts. This paper introduces a new
self-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),
which overcomes these constraints by integrating TAGs' structural and semantic
dimensions. TAGA constructs two complementary views: Text-of-Graph view, which
organizes node texts into structured documents based on graph topology, and the
Graph-of-Text view, which converts textual nodes and connections into graph
data. By aligning representations from both views, TAGA captures joint textual
and structural information. In addition, a novel structure-preserving random
walk algorithm is proposed for efficient training on large-sized TAGs. Our
framework demonstrates strong performance in zero-shot and few-shot scenarios
across eight real-world datasets.",2024-05-27,"Zheng Zhang, Yuntong Hu, Bo Pan, Chen Ling, Liang Zhao",http://arxiv.org/pdf/2405.16800v1,cs.LG
Dual-State Personalized Knowledge Tracing with Emotional Incorporation,"Knowledge tracing has been widely used in online learning systems to guide
the students' future learning. However, most existing KT models primarily focus
on extracting abundant information from the question sets and explore the
relationships between them, but ignore the personalized student behavioral
information in the learning process. This will limit the model's ability to
accurately capture the personalized knowledge states of students and reasonably
predict their performances. To alleviate this limitation, we explicitly models
the personalized learning process by incorporating the emotions, a
representative personalized behavior in the learning process, into KT
framework. Specifically, we present a novel Dual-State Personalized Knowledge
Tracing with Emotional Incorporation model to achieve this goal: Firstly, we
incorporate emotional information into the modeling process of knowledge state,
resulting in the Knowledge State Boosting Module. Secondly, we design an
Emotional State Tracing Module to monitor students' personalized emotional
states, and propose an emotion prediction method based on personalized
emotional states. Finally, we apply the predicted emotions to enhance students'
response prediction. Furthermore, to extend the generalization capability of
our model across different datasets, we design a transferred version of DEKT,
named Transfer Learning-based Self-loop model (T-DEKT). Extensive experiments
show our method achieves the state-of-the-art performance.",2024-05-27,"Shanshan Wang, Fangzheng Yuan, Keyang Wang, Xun Yang, Xingyi Zhang, Meng Wang",http://arxiv.org/pdf/2405.16799v1,cs.LG
Exploring Fairness in Educational Data Mining in the Context of the Right to be Forgotten,"In education data mining (EDM) communities, machine learning has achieved
remarkable success in discovering patterns and structures to tackle educational
challenges. Notably, fairness and algorithmic bias have gained attention in
learning analytics of EDM. With the increasing demand for the right to be
forgotten, there is a growing need for machine learning models to forget
sensitive data and its impact, particularly within the realm of EDM. The
paradigm of selective forgetting, also known as machine unlearning, has been
extensively studied to address this need by eliminating the influence of
specific data from a pre-trained model without complete retraining. However,
existing research assumes that interactive data removal operations are
conducted in secure and reliable environments, neglecting potential malicious
unlearning requests to undermine the fairness of machine learning systems. In
this paper, we introduce a novel class of selective forgetting attacks designed
to compromise the fairness of learning models while maintaining their
predictive accuracy, thereby preventing the model owner from detecting the
degradation in model performance. Additionally, we propose an innovative
optimization framework for selective forgetting attacks, capable of generating
malicious unlearning requests across various attack scenarios. We validate the
effectiveness of our proposed selective forgetting attacks on fairness through
extensive experiments using diverse EDM datasets.",2024-05-27,"Wei Qian, Aobo Chen, Chenxu Zhao, Yangyi Li, Mengdi Huai",http://arxiv.org/pdf/2405.16798v2,cs.LG
TrojFM: Resource-efficient Backdoor Attacks against Very Large Foundation Models,"One key challenge in backdoor attacks against large foundation models is the
resource limits. Backdoor attacks usually require retraining the target model,
which is impractical for very large foundation models. Existing backdoor
attacks are mainly designed for supervised classifiers or small foundation
models (e.g., BERT). None of these attacks has successfully compromised a very
large foundation model, such as Llama-3-70B, especially with limited
computational resources. In this paper, we propose TrojFM, a novel backdoor
attack tailored for very large foundation models. Our primary technical
contribution is the development of a novel backdoor injection method. This
method forces a backdoored model to generate similar hidden representations for
poisoned inputs regardless of their actual semantics. Our approach injects such
backdoors by fine-tuning only a very small proportion of model parameters. This
enables TrojFM to efficiently launch downstream task-agnostic backdoor attacks
against very large foundation models under limited computational resources.
Moreover, we optimize the fine-tuning process with our customized QLoRA
technique, enabling launching our attack via only~\textit{one A100 GPU}.
Furthermore, we design a new trigger injection method to ensure our attack
stealthiness. Through extensive experiments, we first demonstrate that TrojFM
can launch effective backdoor attacks against widely used large GPT-style
models without jeopardizing their normal functionalities (and outperforming
existing attacks on BERT-style models). Furthermore, we show that TrojFM is
resilient to SOTA defenses and is insensitive to changes in key
hyper-parameters. Finally, we conduct a resource analysis to quantify that our
method can significantly save computational and memory costs compared to
existing backdoor attacks.",2024-05-27,"Yuzhou. Nie, Yanting. Wang, Jinyuan. Jia, Michael J. De Lucia, Nathaniel D. Bastian, Wenbo. Guo, Dawn. Song",http://arxiv.org/pdf/2405.16783v1,cs.LG
Balancing User Preferences by Social Networks: A Condition-Guided Social Recommendation Model for Mitigating Popularity Bias,"Social recommendation models weave social interactions into their design to
provide uniquely personalized recommendation results for users. However, social
networks not only amplify the popularity bias in recommendation models,
resulting in more frequent recommendation of hot items and fewer long-tail
items, but also include a substantial amount of redundant information that is
essentially meaningless for the model's performance. Existing social
recommendation models fail to address the issues of popularity bias and the
redundancy of social information, as they directly characterize social
influence across the entire social network without making targeted adjustments.
In this paper, we propose a Condition-Guided Social Recommendation Model (named
CGSoRec) to mitigate the model's popularity bias by denoising the social
network and adjusting the weights of user's social preferences. More
specifically, CGSoRec first includes a Condition-Guided Social Denoising Model
(CSD) to remove redundant social relations in the social network for capturing
users' social preferences with items more precisely. Then, CGSoRec calculates
users' social preferences based on denoised social network and adjusts the
weights in users' social preferences to make them can counteract the popularity
bias present in the recommendation model. At last, CGSoRec includes a
Condition-Guided Diffusion Recommendation Model (CGD) to introduce the adjusted
social preferences as conditions to control the recommendation results for a
debiased direction. Comprehensive experiments on three real-world datasets
demonstrate the effectiveness of our proposed method. The code is in:
https://github.com/hexin5515/CGSoRec.",2024-05-27,"Xin He, Wenqi Fan, Ruobing Wang, Yili Wang, Ying Wang, Shirui Pan, Xin Wang",http://arxiv.org/pdf/2405.16772v1,cs.LG
ARC: A Generalist Graph Anomaly Detector with In-Context Learning,"Graph anomaly detection (GAD), which aims to identify abnormal nodes that
differ from the majority within a graph, has garnered significant attention.
However, current GAD methods necessitate training specific to each dataset,
resulting in high training costs, substantial data requirements, and limited
generalizability when being applied to new datasets and domains. To address
these limitations, this paper proposes ARC, a generalist GAD approach that
enables a ``one-for-all'' GAD model to detect anomalies across various graph
datasets on-the-fly. Equipped with in-context learning, ARC can directly
extract dataset-specific patterns from the target dataset using few-shot normal
samples at the inference stage, without the need for retraining or fine-tuning
on the target dataset. ARC comprises three components that are well-crafted for
capturing universal graph anomaly patterns: 1) smoothness-based feature
Alignment module that unifies the features of different datasets into a common
and anomaly-sensitive space; 2) ego-neighbor Residual graph encoder that learns
abnormality-related node embeddings; and 3) cross-attentive in-Context anomaly
scoring module that predicts node abnormality by leveraging few-shot normal
samples. Extensive experiments on multiple benchmark datasets from various
domains demonstrate the superior anomaly detection performance, efficiency, and
generalizability of ARC.",2024-05-27,"Yixin Liu, Shiyuan Li, Yu Zheng, Qingfeng Chen, Chengqi Zhang, Shirui Pan",http://arxiv.org/pdf/2405.16771v2,cs.LG
Physics informed cell representations for variational formulation of multiscale problems,"With the rapid advancement of graphical processing units, Physics-Informed
Neural Networks (PINNs) are emerging as a promising tool for solving partial
differential equations (PDEs). However, PINNs are not well suited for solving
PDEs with multiscale features, particularly suffering from slow convergence and
poor accuracy. To address this limitation of PINNs, this article proposes
physics-informed cell representations for resolving multiscale Poisson problems
using a model architecture consisting of multilevel multiresolution grids
coupled with a multilayer perceptron (MLP). The grid parameters (i.e., the
level-dependent feature vectors) and the MLP parameters (i.e., the weights and
biases) are determined using gradient-descent based optimization. The
variational (weak) form based loss function accelerates computation by allowing
the linear interpolation of feature vectors within grid cells. This cell-based
MLP model also facilitates the use of a decoupled training scheme for Dirichlet
boundary conditions and a parameter-sharing scheme for periodic boundary
conditions, delivering superior accuracy compared to conventional PINNs.
Furthermore, the numerical examples highlight improved speed and accuracy in
solving PDEs with nonlinear or high-frequency boundary conditions and provide
insights into hyperparameter selection. In essence, by cell-based MLP model
along with the parallel tiny-cuda-nn library, our implementation improves
convergence speed and numerical accuracy.",2024-05-27,"Yuxiang Gao, Soheil Kolouri, Ravindra Duddu",http://arxiv.org/pdf/2405.16770v1,cs.LG
Concept Matching with Agent for Out-of-Distribution Detection,"The remarkable achievements of Large Language Models (LLMs) have captivated
the attention of both academia and industry, transcending their initial role in
dialogue generation. To expand the usage scenarios of LLM, some works enhance
the effectiveness and capabilities of the model by introducing more external
information, which is called the agent paradigm. Based on this idea, we propose
a new method that integrates the agent paradigm into out-of-distribution (OOD)
detection task, aiming to improve its robustness and adaptability. Our proposed
method, Concept Matching with Agent (CMA), employs neutral prompts as agents to
augment the CLIP-based OOD detection process. These agents function as dynamic
observers and communication hubs, interacting with both In-distribution (ID)
labels and data inputs to form vector triangle relationships. This triangular
framework offers a more nuanced approach than the traditional binary
relationship, allowing for better separation and identification of ID and OOD
inputs. Our extensive experimental results showcase the superior performance of
CMA over both zero-shot and training-required methods in a diverse array of
real-world scenarios.",2024-05-27,"Yuxiao Lee, Xiaofeng Cao, Jingcai Guo, Wei Ye, Qing Guo, Yi Chang",http://arxiv.org/pdf/2405.16766v2,cs.LG
Study of Robust Direction Finding Based on Joint Sparse Representation,"Standard Direction of Arrival (DOA) estimation methods are typically derived
based on the Gaussian noise assumption, making them highly sensitive to
outliers. Therefore, in the presence of impulsive noise, the performance of
these methods may significantly deteriorate. In this paper, we model impulsive
noise as Gaussian noise mixed with sparse outliers. By exploiting their
statistical differences, we propose a novel DOA estimation method based on
sparse signal recovery (SSR). Furthermore, to address the issue of grid
mismatch, we utilize an alternating optimization approach that relies on the
estimated outlier matrix and the on-grid DOA estimates to obtain the off-grid
DOA estimates. Simulation results demonstrate that the proposed method exhibits
robustness against large outliers.",2024-05-27,"Y. Li, W. Xiao, L. Zhao, Z. Huang, Q. Li, L. Li, R. C. de Lamare",http://arxiv.org/pdf/2405.16765v1,cs.LG
Transport of Algebraic Structure to Latent Embeddings,"Machine learning often aims to produce latent embeddings of inputs which lie
in a larger, abstract mathematical space. For example, in the field of 3D
modeling, subsets of Euclidean space can be embedded as vectors using implicit
neural representations. Such subsets also have a natural algebraic structure
including operations (e.g., union) and corresponding laws (e.g.,
associativity). How can we learn to ""union"" two sets using only their latent
embeddings while respecting associativity? We propose a general procedure for
parameterizing latent space operations that are provably consistent with the
laws on the input space. This is achieved by learning a bijection from the
latent space to a carefully designed mirrored algebra which is constructed on
Euclidean space in accordance with desired laws. We evaluate these structural
transport nets for a range of mirrored algebras against baselines that operate
directly on the latent space. Our experiments provide strong evidence that
respecting the underlying algebraic structure of the input space is key for
learning accurate and self-consistent operations.",2024-05-27,"Samuel Pfrommer, Brendon G. Anderson, Somayeh Sojoudi",http://arxiv.org/pdf/2405.16763v1,cs.LG
Addressing Discretization-Induced Bias in Demographic Prediction,"Racial and other demographic imputation is necessary for many applications,
especially in auditing disparities and outreach targeting in political
campaigns. The canonical approach is to construct continuous predictions --
e.g., based on name and geography -- and then to $\textit{discretize}$ the
predictions by selecting the most likely class (argmax). We study how this
practice produces $\textit{discretization bias}$. In particular, we show that
argmax labeling, as used by a prominent commercial voter file vendor to impute
race/ethnicity, results in a substantial under-count of African-American
voters, e.g., by 28.2% points in North Carolina. This bias can have substantial
implications in downstream tasks that use such labels.
  We then introduce a $\textit{joint optimization}$ approach -- and a tractable
$\textit{data-driven thresholding}$ heuristic -- that can eliminate this bias,
with negligible individual-level accuracy loss. Finally, we theoretically
analyze discretization bias, show that calibrated continuous models are
insufficient to eliminate it, and that an approach such as ours is necessary.
Broadly, we warn researchers and practitioners against discretizing continuous
demographic predictions without considering downstream consequences.",2024-05-27,"Evan Dong, Aaron Schein, Yixin Wang, Nikhil Garg",http://arxiv.org/pdf/2405.16762v1,cs.LG
Masked Face Recognition with Generative-to-Discriminative Representations,"Masked face recognition is important for social good but challenged by
diverse occlusions that cause insufficient or inaccurate representations. In
this work, we propose a unified deep network to learn
generative-to-discriminative representations for facilitating masked face
recognition. To this end, we split the network into three modules and learn
them on synthetic masked faces in a greedy module-wise pretraining manner.
First, we leverage a generative encoder pretrained for face inpainting and
finetune it to represent masked faces into category-aware descriptors.
Attribute to the generative encoder's ability in recovering context
information, the resulting descriptors can provide occlusion-robust
representations for masked faces, mitigating the effect of diverse masks. Then,
we incorporate a multi-layer convolutional network as a discriminative reformer
and learn it to convert the category-aware descriptors into identity-aware
vectors, where the learning is effectively supervised by distilling relation
knowledge from off-the-shelf face recognition model. In this way, the
discriminative reformer together with the generative encoder serves as the
pretrained backbone, providing general and discriminative representations
towards masked faces. Finally, we cascade one fully-connected layer following
by one softmax layer into a feature classifier and finetune it to identify the
reformed identity-aware vectors. Extensive experiments on synthetic and
realistic datasets demonstrate the effectiveness of our approach in recognizing
masked faces.",2024-05-27,"Shiming Ge, Weijia Guo, Chenyu Li, Junzheng Zhang, Yong Li, Dan Zeng",http://arxiv.org/pdf/2405.16761v1,cs.LG
Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models,"We address the long-standing problem of how to learn effective pixel-based
image diffusion models at scale, introducing a remarkably simple greedy growing
method for stable training of large-scale, high-resolution models. without the
needs for cascaded super-resolution components. The key insight stems from
careful pre-training of core components, namely, those responsible for
text-to-image alignment {\it vs.} high-resolution rendering. We first
demonstrate the benefits of scaling a {\it Shallow UNet}, with no
down(up)-sampling enc(dec)oder. Scaling its deep core layers is shown to
improve alignment, object structure, and composition. Building on this core
model, we propose a greedy algorithm that grows the architecture into
high-resolution end-to-end models, while preserving the integrity of the
pre-trained representation, stabilizing training, and reducing the need for
large high-resolution datasets. This enables a single stage model capable of
generating high-resolution images without the need of a super-resolution
cascade. Our key results rely on public datasets and show that we are able to
train non-cascaded models up to 8B parameters with no further regularization
schemes. Vermeer, our full pipeline model trained with internal datasets to
produce 1024x1024 images, without cascades, is preferred by 44.0% vs. 21.4%
human evaluators over SDXL.",2024-05-27,"Cristina N. Vasconcelos, Abdullah Rashwan, Austin Waters, Trevor Walker, Keyang Xu, Jimmy Yan, Rui Qian, Shixin Luo, Zarana Parekh, Andrew Bunner, Hongliang Fei, Roopal Garg, Mandy Guo, Ivana Kajic, Yeqing Li, Henna Nandwani, Jordi Pont-Tuset, Yasumasa Onoe, Sarah Rosston, Su Wang, Wenlei Zhou, Kevin Swersky, David J. Fleet, Jason M. Baldridge, Oliver Wang",http://arxiv.org/pdf/2405.16759v1,cs.LG
Symmetry-Informed Governing Equation Discovery,"Despite the advancements in learning governing differential equations from
observations of dynamical systems, data-driven methods are often unaware of
fundamental physical laws, such as frame invariance. As a result, these
algorithms may search an unnecessarily large space and discover less accurate
or overly complex equations. In this paper, we propose to leverage symmetry in
automated equation discovery to compress the equation search space and improve
the accuracy and simplicity of the learned equations. Specifically, we derive
equivariance constraints from the time-independent symmetries of ODEs.
Depending on the types of symmetries, we develop a pipeline for incorporating
symmetry constraints into various equation discovery algorithms, including
sparse regression and genetic programming. In experiments across diverse
dynamical systems, our approach demonstrates better robustness against noise
and recovers governing equations with significantly higher probability than
baselines without symmetry. Our codebase is available at
https://github.com/Rose-STL-Lab/symmetry-ode-discovery.",2024-05-27,"Jianke Yang, Wang Rao, Nima Dehmamy, Robin Walters, Rose Yu",http://arxiv.org/pdf/2405.16756v2,cs.LG
CHESS: Contextual Harnessing for Efficient SQL Synthesis,"Translating natural language questions into SQL queries, known as
text-to-SQL, is a long-standing research problem. Effective text-to-SQL
synthesis can become very challenging due to (i) the extensive size of database
catalogs (descriptions of tables and their columns) and database values, (ii)
reasoning over large database schemas, (iii) ensuring the functional validity
of the generated queries, and (iv) navigating the ambiguities of natural
language questions. We introduce CHESS, a Large Language Model (LLM) based
multi-agent framework for efficient and scalable SQL synthesis, comprising four
specialized agents, each targeting one of the aforementioned challenges: the
Information Retriever (IR) extracts relevant data, the Schema Selector (SS)
prunes large schemas, the Candidate Generator (CG) generates high-quality
candidates and refines queries iteratively, and the Unit Tester (UT) validates
queries through LLM-based natural language unit tests. Our framework offers
configurable features that adapt to various deployment constraints, including
1) Supporting industrial-scale databases: leveraging the Schema Selector agent,
CHESS efficiently narrows down very large database schemas into manageable
sub-schemas, boosting system accuracy by approximately $2\%$ and reducing the
number of LLM tokens by $\times 5$. 2) State-of-the-Art privacy-preserving
performance: Among the methods using open-source models, CHESS achieves
state-of-the-art performance, resulting in a high-performing,
privacy-preserving system suitable for industrial deployment. 3) Scalablity
with additional compute budget: In settings with high computational budgets,
CHESS achieves $71.10\%$ accuracy on the BIRD test set, within $2\%$ of the
leading proprietary method, while requiring approximately $83\%$ fewer LLM
calls.",2024-05-27,"Shayan Talaei, Mohammadreza Pourreza, Yu-Chen Chang, Azalia Mirhoseini, Amin Saberi",http://arxiv.org/pdf/2405.16755v3,cs.LG
Model Ensembling for Constrained Optimization,"There is a long history in machine learning of model ensembling, beginning
with boosting and bagging and continuing to the present day. Much of this
history has focused on combining models for classification and regression, but
recently there is interest in more complex settings such as ensembling policies
in reinforcement learning. Strong connections have also emerged between
ensembling and multicalibration techniques. In this work, we further
investigate these themes by considering a setting in which we wish to ensemble
models for multidimensional output predictions that are in turn used for
downstream optimization. More precisely, we imagine we are given a number of
models mapping a state space to multidimensional real-valued predictions. These
predictions form the coefficients of a linear objective that we would like to
optimize under specified constraints. The fundamental question we address is
how to improve and combine such models in a way that outperforms the best of
them in the downstream optimization problem. We apply multicalibration
techniques that lead to two provably efficient and convergent algorithms. The
first of these (the white box approach) requires being given models that map
states to output predictions, while the second (the \emph{black box} approach)
requires only policies (mappings from states to solutions to the optimization
problem). For both, we provide convergence and utility guarantees. We conclude
by investigating the performance and behavior of the two algorithms in a
controlled experimental setting.",2024-05-27,"Ira Globus-Harris, Varun Gupta, Michael Kearns, Aaron Roth",http://arxiv.org/pdf/2405.16752v1,cs.LG
DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion Models,"Pretrained diffusion models (DMs) have recently been popularly used in
solving inverse problems (IPs). The existing methods mostly interleave
iterative steps in the reverse diffusion process and iterative steps to bring
the iterates closer to satisfying the measurement constraint. However, such
interleaving methods struggle to produce final results that look like natural
objects of interest (i.e., manifold feasibility) and fit the measurement (i.e.,
measurement feasibility), especially for nonlinear IPs. Moreover, their
capabilities to deal with noisy IPs with unknown types and levels of
measurement noise are unknown. In this paper, we advocate viewing the reverse
process in DMs as a function and propose a novel plug-in method for solving IPs
using pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold
feasibility and measurement feasibility in a principled manner, and also shows
great potential for being robust to unknown types and levels of noise. Through
extensive experiments across various IP tasks, including two linear and three
nonlinear IPs, we demonstrate that DMPlug consistently outperforms
state-of-the-art methods, often by large margins especially for nonlinear IPs.
The code is available at https://github.com/sun-umn/DMPlug.",2024-05-27,"Hengkang Wang, Xu Zhang, Taihui Li, Yuxiang Wan, Tiancong Chen, Ju Sun",http://arxiv.org/pdf/2405.16749v2,cs.LG
Hypergraph Laplacian Eigenmaps and Face Recognition Problems,"Face recognition is a very important topic in data science and biometric
security research areas. It has multiple applications in military, finance, and
retail, to name a few. In this paper, the novel hypergraph Laplacian Eigenmaps
will be proposed and combine with the k nearest-neighbor method and/or with the
kernel ridge regression method to solve the face recognition problem.
Experimental results illustrate that the accuracy of the combination of the
novel hypergraph Laplacian Eigenmaps and one specific classification system is
similar to the accuracy of the combination of the old symmetric normalized
hypergraph Laplacian Eigenmaps method and one specific classification system.",2024-05-27,Loc Hoang Tran,http://arxiv.org/pdf/2405.16748v1,cs.LG
Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective,"The two-stage fine-tuning (FT) method, linear probing (LP) then fine-tuning
(LP-FT), outperforms linear probing and FT alone. This holds true for both
in-distribution (ID) and out-of-distribution (OOD) data. One key reason for its
success is the preservation of pre-trained features, achieved by obtaining a
near-optimal linear head during LP. However, despite the widespread use of
large language models, there has been limited exploration of more complex
architectures such as Transformers. In this paper, we analyze the training
dynamics of LP-FT for classification tasks on the basis of the neural tangent
kernel (NTK) theory. Our analysis decomposes the NTK matrix into two
components. This decomposition highlights the importance of the linear head
norm alongside the prediction accuracy at the start of the FT stage. We also
observe a significant increase in the linear head norm during LP, which stems
from training with the cross-entropy (CE) loss. This increase in the linear
head norm effectively reduces changes in learned features. Furthermore, we find
that this increased norm can adversely affect model calibration, which can be
corrected using temperature scaling. Additionally, we extend our analysis with
the NTK to the low-rank adaptation (LoRA) method and validate its
effectiveness. Our experiments using a Transformer-based model on multiple
natural language processing datasets confirm our theoretical analysis. Our
study demonstrates the effectiveness of LP-FT for fine-tuning language models.
Code is available at https://github.com/tom4649/lp-ft_ntk.",2024-05-27,"Akiyoshi Tomihari, Issei Sato",http://arxiv.org/pdf/2405.16747v2,cs.LG
Oracle-Efficient Reinforcement Learning for Max Value Ensembles,"Reinforcement learning (RL) in large or infinite state spaces is notoriously
challenging, both theoretically (where worst-case sample and computational
complexities must scale with state space cardinality) and experimentally (where
function approximation and policy gradient techniques often scale poorly and
suffer from instability and high variance). One line of research attempting to
address these difficulties makes the natural assumption that we are given a
collection of heuristic base or $\textit{constituent}$ policies upon which we
would like to improve in a scalable manner. In this work we aim to compete with
the $\textit{max-following policy}$, which at each state follows the action of
whichever constituent policy has the highest value. The max-following policy is
always at least as good as the best constituent policy, and may be considerably
better. Our main result is an efficient algorithm that learns to compete with
the max-following policy, given only access to the constituent policies (but
not their value functions). In contrast to prior work in similar settings, our
theoretical results require only the minimal assumption of an ERM oracle for
value function approximation for the constituent policies (and not the global
optimal policy or the max-following policy itself) on samplable distributions.
We illustrate our algorithm's experimental effectiveness and behavior on
several robotic simulation testbeds.",2024-05-27,"Marcel Hussing, Michael Kearns, Aaron Roth, Sikata Bela Sengupta, Jessica Sorrell",http://arxiv.org/pdf/2405.16739v1,cs.LG
Renal digital pathology visual knowledge search platform based on language large model and book knowledge,"Large models have become mainstream, yet their applications in digital
pathology still require exploration. Meanwhile renal pathology images play an
important role in the diagnosis of renal diseases. We conducted image
segmentation and paired corresponding text descriptions based on 60 books for
renal pathology, clustering analysis for all image and text description
features based on large models, ultimately building a retrieval system based on
the semantic features of large models. Based above analysis, we established a
knowledge base of 10,317 renal pathology images and paired corresponding text
descriptions, and then we evaluated the semantic feature capabilities of 4
large models, including GPT2, gemma, LLma and Qwen, and the image-based feature
capabilities of dinov2 large model. Furthermore, we built a semantic retrieval
system to retrieve pathological images based on text descriptions, and named
RppD (aidp.zjsru.edu.cn).",2024-05-27,"Xiaomin Lv, Chong Lai, Liya Ding, Maode Lai, Qingrong Sun",http://arxiv.org/pdf/2406.18556v1,cs.LG
Faster Sampling via Stochastic Gradient Proximal Sampler,"Stochastic gradients have been widely integrated into Langevin-based methods
to improve their scalability and efficiency in solving large-scale sampling
problems. However, the proximal sampler, which exhibits much faster convergence
than Langevin-based algorithms in the deterministic setting Lee et al. (2021),
has yet to be explored in its stochastic variants. In this paper, we study the
Stochastic Proximal Samplers (SPS) for sampling from non-log-concave
distributions. We first establish a general framework for implementing
stochastic proximal samplers and establish the convergence theory accordingly.
We show that the convergence to the target distribution can be guaranteed as
long as the second moment of the algorithm trajectory is bounded and restricted
Gaussian oracles can be well approximated. We then provide two implementable
variants based on Stochastic gradient Langevin dynamics (SGLD) and
Metropolis-adjusted Langevin algorithm (MALA), giving rise to SPS-SGLD and
SPS-MALA. We further show that SPS-SGLD and SPS-MALA can achieve
$\epsilon$-sampling error in total variation (TV) distance within
$\tilde{\mathcal{O}}(d\epsilon^{-2})$ and
$\tilde{\mathcal{O}}(d^{1/2}\epsilon^{-2})$ gradient complexities, which
outperform the best-known result by at least an $\tilde{\mathcal{O}}(d^{1/3})$
factor. This enhancement in performance is corroborated by our empirical
studies on synthetic data with various dimensions, demonstrating the efficiency
of our proposed algorithm.",2024-05-27,"Xunpeng Huang, Difan Zou, Yi-An Ma, Hanze Dong, Tong Zhang",http://arxiv.org/pdf/2405.16734v1,cs.LG
The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize,"In this work, we investigate stochastic approximation (SA) with Markovian
data and nonlinear updates under constant stepsize $\alpha>0$. Existing work
has primarily focused on either i.i.d. data or linear update rules. We take a
new perspective and carefully examine the simultaneous presence of Markovian
dependency of data and nonlinear update rules, delineating how the interplay
between these two structures leads to complications that are not captured by
prior techniques. By leveraging the smoothness and recurrence properties of the
SA updates, we develop a fine-grained analysis of the correlation between the
SA iterates $\theta_k$ and Markovian data $x_k$. This enables us to overcome
the obstacles in existing analysis and establish for the first time the weak
convergence of the joint process $(x_k, \theta_k)_{k\geq0}$. Furthermore, we
present a precise characterization of the asymptotic bias of the SA iterates,
given by
$\mathbb{E}[\theta_\infty]-\theta^\ast=\alpha(b_\text{m}+b_\text{n}+b_\text{c})+O(\alpha^{3/2})$.
Here, $b_\text{m}$ is associated with the Markovian noise, $b_\text{n}$ is tied
to the nonlinearity, and notably, $b_\text{c}$ represents a multiplicative
interaction between the Markovian noise and nonlinearity, which is absent in
previous works. As a by-product of our analysis, we derive finite-time bounds
on higher moment $\mathbb{E}[\|\theta_k-\theta^\ast\|^{2p}]$ and present
non-asymptotic geometric convergence rates for the iterates, along with a
Central Limit Theorem.",2024-05-27,"Dongyan Huo, Yixuan Zhang, Yudong Chen, Qiaomin Xie",http://arxiv.org/pdf/2405.16732v1,cs.LG
Pretraining with Random Noise for Fast and Robust Learning without Weight Transport,"The brain prepares for learning even before interacting with the environment,
by refining and optimizing its structures through spontaneous neural activity
that resembles random noise. However, the mechanism of such a process has yet
to be thoroughly understood, and it is unclear whether this process can benefit
the algorithm of machine learning. Here, we study this issue using a neural
network with a feedback alignment algorithm, demonstrating that pretraining
neural networks with random noise increases the learning efficiency as well as
generalization abilities without weight transport. First, we found that random
noise training modifies forward weights to match backward synaptic feedback,
which is necessary for teaching errors by feedback alignment. As a result, a
network with pre-aligned weights learns notably faster than a network without
random noise training, even reaching a convergence speed comparable to that of
a backpropagation algorithm. Sequential training with both random noise and
data brings weights closer to synaptic feedback than training solely with data,
enabling more precise credit assignment and faster learning. We also found that
each readout probability approaches the chance level and that the effective
dimensionality of weights decreases in a network pretrained with random noise.
This pre-regularization allows the network to learn simple solutions of a low
rank, reducing the generalization loss during subsequent training. This also
enables the network robustly to generalize a novel, out-of-distribution
dataset. Lastly, we confirmed that random noise pretraining reduces the amount
of meta-loss, enhancing the network ability to adapt to various tasks. Overall,
our results suggest that random noise training with feedback alignment offers a
straightforward yet effective method of pretraining that facilitates quick and
reliable learning without weight transport.",2024-05-27,"Jeonghwan Cheon, Sang Wan Lee, Se-Bum Paik",http://arxiv.org/pdf/2405.16731v2,cs.LG
Latent Energy-Based Odyssey: Black-Box Optimization via Expanded Exploration in the Energy-Based Latent Space,"Offline Black-Box Optimization (BBO) aims at optimizing a black-box function
using the knowledge from a pre-collected offline dataset of function values and
corresponding input designs. However, the high-dimensional and
highly-multimodal input design space of black-box function pose inherent
challenges for most existing methods that model and operate directly upon input
designs. These issues include but are not limited to high sample complexity,
which relates to inaccurate approximation of black-box function; and
insufficient coverage and exploration of input design modes, which leads to
suboptimal proposal of new input designs. In this work, we consider finding a
latent space that serves as a compressed yet accurate representation of the
design-value joint space, enabling effective latent exploration of high-value
input design modes. To this end, we formulate an learnable energy-based latent
space, and propose Noise-intensified Telescoping density-Ratio Estimation
(NTRE) scheme for variational learning of an accurate latent space model
without costly Markov Chain Monte Carlo. The optimization process is then
exploration of high-value designs guided by the learned energy-based model in
the latent space, formulated as gradient-based sampling from a
latent-variable-parameterized inverse model. We show that our particular
parameterization encourages expanded exploration around high-value design
modes, motivated by inversion thinking of a fundamental result of conditional
covariance matrix typically used for variance reduction. We observe that our
method, backed by an accurately learned informative latent space and an
expanding-exploration model design, yields significant improvements over strong
previous methods on both synthetic and real world datasets such as the
design-bench suite.",2024-05-27,"Peiyu Yu, Dinghuai Zhang, Hengzhi He, Xiaojian Ma, Ruiyao Miao, Yifan Lu, Yasi Zhang, Deqian Kong, Ruiqi Gao, Jianwen Xie, Guang Cheng, Ying Nian Wu",http://arxiv.org/pdf/2405.16730v1,cs.LG
Free-Space Optical Channel Turbulence Prediction: A Machine Learning Approach,"Channel turbulence is a formidable obstacle for free-space optical (FSO)
communication. Anticipation of turbulence levels is highly important for
mitigating disruptions but has not been demonstrated without dedicated,
auxiliary hardware. We show that machine learning (ML) can be applied to raw
FSO data streams to rapidly predict channel turbulence levels with no
additional sensing hardware. FSO was conducted through a controlled channel in
the lab under six distinct turbulence levels, and the efficacy of using ML to
classify turbulence levels was examined. ML-based turbulence level
classification was found to be >98% accurate with multiple ML training
parameters. Classification effectiveness was found to depend on the timescale
of changes between turbulence levels but converges when turbulence stabilizes
over about a one minute timescale.",2024-05-27,"Md Zobaer Islam, Ethan Abele, Fahim Ferdous Hossain, Arsalan Ahmad, Sabit Ekin, John F. O'Hara",http://arxiv.org/pdf/2405.16729v2,cs.LG
Towards Multi-Task Multi-Modal Models: A Video Generative Perspective,"Advancements in language foundation models have primarily fueled the recent
surge in artificial intelligence. In contrast, generative learning of
non-textual modalities, especially videos, significantly trails behind language
modeling. This thesis chronicles our endeavor to build multi-task models for
generating videos and other modalities under diverse conditions, as well as for
understanding and compression applications. Given the high dimensionality of
visual data, we pursue concise and accurate latent representations. Our
video-native spatial-temporal tokenizers preserve high fidelity. We unveil a
novel approach to mapping bidirectionally between visual observation and
interpretable lexical terms. Furthermore, our scalable visual token
representation proves beneficial across generation, compression, and
understanding tasks. This achievement marks the first instances of language
models surpassing diffusion models in visual synthesis and a video tokenizer
outperforming industry-standard codecs. Within these multi-modal latent spaces,
we study the design of multi-task generative models. Our masked multi-task
transformer excels at the quality, efficiency, and flexibility of video
generation. We enable a frozen language model, trained solely on text, to
generate visual content. Finally, we build a scalable generative multi-modal
transformer trained from scratch, enabling the generation of videos containing
high-fidelity motion with the corresponding audio given diverse conditions.
Throughout the course, we have shown the effectiveness of integrating multiple
tasks, crafting high-fidelity latent representation, and generating multiple
modalities. This work suggests intriguing potential for future exploration in
generating non-textual data and enabling real-time, interactive experiences
across various media forms.",2024-05-26,Lijun Yu,http://arxiv.org/pdf/2405.16728v1,cs.LG
Disentangling and Integrating Relational and Sensory Information in Transformer Architectures,"Relational reasoning is a central component of generally intelligent systems,
enabling robust and data-efficient inductive generalization. Recent empirical
evidence shows that many existing neural architectures, including Transformers,
struggle with tasks requiring relational reasoning. In this work, we
distinguish between two types of information: sensory information about the
properties of individual objects, and relational information about the
relationships between objects. While neural attention provides a powerful
mechanism for controlling the flow of sensory information between objects, the
Transformer lacks an explicit computational mechanism for routing and
processing relational information. To address this limitation, we propose an
architectural extension of the Transformer framework that we call the Dual
Attention Transformer (DAT), featuring two distinct attention mechanisms:
sensory attention for directing the flow of sensory information, and a novel
relational attention mechanism for directing the flow of relational
information. We empirically evaluate DAT on a diverse set of tasks ranging from
synthetic relational benchmarks to complex real-world tasks such as language
modeling and visual processing. Our results demonstrate that integrating
explicit relational computational mechanisms into the Transformer architecture
leads to significant performance gains in terms of data efficiency and
parameter efficiency.",2024-05-26,"Awni Altabaa, John Lafferty",http://arxiv.org/pdf/2405.16727v2,cs.LG
"Exploring Edge Probability Graph Models Beyond Edge Independency: Concepts, Analyses, and Algorithms","Desirable random graph models (RGMs) should (i) generate realistic structures
such as high clustering (i.e., high subgraph densities), (ii) generate variable
(i.e., not overly similar) graphs, and (iii) remain tractable to compute and
control graph statistics. A common class of RGMs (e.g., Erd\H{o}s-R'{e}nyi and
stochastic Kronecker) outputs edge probabilities, and we need to realize (i.e.,
sample from) the edge probabilities to generate graphs. Typically, each edge's
existence is assumed to be determined independently for simplicity and
tractability. However, with edge independency, RGMs theoretically cannot
produce high subgraph densities and high output variability simultaneously. In
this work, we explore realization beyond edge independence that can produce
more realistic structures while maintaining high traceability and variability.
Theoretically, we propose an edge-dependent realization framework called
binding that provably preserves output variability, and derive closed-form
tractability results on subgraph (e.g., triangle) densities in generated
graphs. Practically, we propose algorithms for graph generation with binding
and parameter fitting of binding. Our empirical results demonstrate that
binding exhibits high tractability and generates realistic graphs with high
clustering, significantly improving upon existing RGMs assuming edge
independency.",2024-05-26,"Fanchen Bu, Ruochen Yang, Paul Bogdan, Kijung Shin",http://arxiv.org/pdf/2405.16726v2,cs.LG
Amortized Active Causal Induction with Deep Reinforcement Learning,"We present Causal Amortized Active Structure Learning (CAASL), an active
intervention design policy that can select interventions that are adaptive,
real-time and that does not require access to the likelihood. This policy, an
amortized network based on the transformer, is trained with reinforcement
learning on a simulator of the design environment, and a reward function that
measures how close the true causal graph is to a causal graph posterior
inferred from the gathered data. On synthetic data and a single-cell gene
expression simulator, we demonstrate empirically that the data acquired through
our policy results in a better estimate of the underlying causal graph than
alternative strategies. Our design policy successfully achieves amortized
intervention design on the distribution of the training environment while also
generalizing well to distribution shifts in test-time design environments.
Further, our policy also demonstrates excellent zero-shot generalization to
design environments with dimensionality higher than that during training, and
to intervention types that it has not been trained on.",2024-05-26,"Yashas Annadani, Panagiotis Tigas, Stefan Bauer, Adam Foster",http://arxiv.org/pdf/2405.16718v1,cs.LG
Crafting Interpretable Embeddings by Asking LLMs Questions,"Large language models (LLMs) have rapidly improved text embeddings for a
growing array of natural-language processing tasks. However, their opaqueness
and proliferation into scientific domains such as neuroscience have created a
growing need for interpretability. Here, we ask whether we can obtain
interpretable embeddings through LLM prompting. We introduce question-answering
embeddings (QA-Emb), embeddings where each feature represents an answer to a
yes/no question asked to an LLM. Training QA-Emb reduces to selecting a set of
underlying questions rather than learning model weights.
  We use QA-Emb to flexibly generate interpretable models for predicting fMRI
voxel responses to language stimuli. QA-Emb significantly outperforms an
established interpretable baseline, and does so while requiring very few
questions. This paves the way towards building flexible feature spaces that can
concretize and evaluate our understanding of semantic brain representations. We
additionally find that QA-Emb can be effectively approximated with an efficient
model, and we explore broader applications in simple NLP tasks.",2024-05-26,"Vinamra Benara, Chandan Singh, John X. Morris, Richard Antonello, Ion Stoica, Alexander G. Huth, Jianfeng Gao",http://arxiv.org/pdf/2405.16714v1,cs.LG
Zamba: A Compact 7B SSM Hybrid Model,"In this technical report, we present Zamba, a novel 7B SSM-transformer hybrid
model which achieves competitive performance against leading open-weight models
at a comparable scale. Zamba is trained on 1T tokens from openly available
datasets and is the best non-transformer model at this scale. Zamba pioneers a
unique architecture combining a Mamba backbone with a single shared attention
module, thus obtaining the benefits of attention at minimal parameter cost. Due
to its architecture, Zamba is significantly faster at inference than comparable
transformer models and requires substantially less memory for generation of
long sequences. Zamba is pretrained in two phases: the first phase is based on
existing web datasets, while the second one consists of annealing the model
over high-quality instruct and synthetic datasets, and is characterized by a
rapid learning rate decay. We open-source the weights and all checkpoints for
Zamba, through both phase 1 and annealing phases.",2024-05-26,"Paolo Glorioso, Quentin Anthony, Yury Tokpanov, James Whittington, Jonathan Pilault, Adam Ibrahim, Beren Millidge",http://arxiv.org/pdf/2405.16712v1,cs.LG
Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to Multimodal Inputs,"Large Language Models (LLMs) have demonstrated impressive performance on
multimodal tasks, without any multimodal finetuning. They are the building
block for Large Multimodal Models, yet, we still lack a proper understanding of
their success. In this work, we expose frozen LLMs to image, video, audio and
text inputs and analyse their internal representation aiming to understand
their generalization beyond textual inputs.
  Findings. Perceptual tokens (1) are easily distinguishable from textual ones
inside LLMs, with significantly different representations, and complete
translation to textual tokens does not exist. Yet, (2) both perceptual and
textual tokens activate similar LLM weights. Despite being different, (3)
perceptual and textual tokens are implicitly aligned inside LLMs, we call this
the implicit multimodal alignment (IMA), and argue that this is linked to
architectural design, helping LLMs to generalize. This provide more evidence to
believe that the generalization of LLMs to multimodal inputs is mainly due to
their architecture.
  Implications. (1) We find a positive correlation between the implicit
alignment score and the task performance, suggesting that this could act as a
proxy metric for model evaluation and selection. (2) A negative correlation
exists regarding hallucinations, revealing that this problem is mainly due to
misalignment between the internal perceptual and textual representations. (3)
Perceptual tokens change slightly throughout the model, thus, we propose
different approaches to skip computations (e.g. in FFN layers), and
significantly reduce the inference cost. (4) Due to the slowly changing
embeddings across layers, and the high overlap between textual and multimodal
activated weights, we compress LLMs by keeping only 1 subnetwork that works
well across a wide range of multimodal tasks. Paper code:
https://github.com/mshukor/ima-lmms.",2024-05-26,"Mustafa Shukor, Matthieu Cord",http://arxiv.org/pdf/2405.16700v2,cs.LG
CNN Autoencoder Resizer: A Power-Efficient LoS/NLoS Detector in MIMO-enabled UAV Networks,"Optimizing the design, performance, and resource efficiency of wireless
networks (WNs) necessitates the ability to discern Line of Sight (LoS) and
Non-Line of Sight (NLoS) scenarios across diverse applications and
environments. Unmanned Aerial Vehicles (UAVs) exhibit significant potential in
this regard due to their rapid mobility, aerial capabilities, and payload
characteristics. Particularly, UAVs can serve as vital non-terrestrial base
stations (NTBS) in the event of terrestrial base station (TBS) failures or
downtime. In this paper, we propose CNN autoencoder resizer (CAR) as a
framework that improves the accuracy of LoS/NLoS detection without demanding
extra power consumption. Our proposed method increases the mean accuracy of
detecting LoS/NLoS signals from 66% to 86%, while maintaining consistent power
consumption levels. In addition, the resolution provided by CAR shows that it
can be employed as a preprocessing tool in other methods to enhance the quality
of signals.",2024-05-26,"Azim Akhtarshenas, Navid Ayoobi, David Lopez-Perez, Ramin Toosi, Matin Amoozadeh",http://arxiv.org/pdf/2405.16697v1,cs.LG
gzip Predicts Data-dependent Scaling Laws,"Past work has established scaling laws that predict the performance of a
neural language model (LM) as a function of its parameter count and the number
of tokens it's trained on, enabling optimal allocation of a fixed compute
budget. Are these scaling laws agnostic to training data as some prior work
suggests? We generate training datasets of varying complexities by modulating
the syntactic properties of a PCFG, finding that 1) scaling laws are sensitive
to differences in data complexity and that 2) gzip, a compression algorithm, is
an effective predictor of how data complexity impacts scaling properties. We
propose a new data-dependent scaling law for LM's that accounts for the
training data's gzip-compressibility; its compute-optimal frontier increases in
dataset size preference (over parameter count preference) as training data
becomes harder to compress.",2024-05-26,Rohan Pandey,http://arxiv.org/pdf/2405.16684v1,cs.LG
Toward Digitalization: A Secure Approach to Find a Missing Person Using Facial Recognition Technology,"Facial Recognition is a technique, based on machine learning technology that
can recognize a human being analyzing his facial profile, and is applied in
solving various types of realworld problems nowadays. In this paper, a common
real-world problem, finding a missing person has been solved in a secure and
effective way with the help of facial recognition technology. Although there
exist a few works on solving the problem, the proposed work is unique with
respect to its security, design, and feasibility. Impeding intruders in
participating in the processes and giving importance to both finders and family
members of a missing person are two of the major features of this work. The
proofs of the works of our system in finding a missing person have been
described in the result section of the paper. The advantages that our system
provides over the other existing systems can be realized from the comparisons,
described in the result summary section of the paper. The work is capable of
providing a worthy solution to find a missing person on the digital platform.",2024-05-26,"Abid Faisal Ayon, S M Maksudul Alam",http://arxiv.org/pdf/2405.16683v1,cs.LG
A Systematic Review of Federated Generative Models,"Federated Learning (FL) has emerged as a solution for distributed systems
that allow clients to train models on their data and only share models instead
of local data. Generative Models are designed to learn the distribution of a
dataset and generate new data samples that are similar to the original data.
Many prior works have tried proposing Federated Generative Models. Using
Federated Learning and Generative Models together can be susceptible to
attacks, and designing the optimal architecture remains challenging.
  This survey covers the growing interest in the intersection of FL and
Generative Models by comprehensively reviewing research conducted from 2019 to
2024. We systematically compare nearly 100 papers, focusing on their FL and
Generative Model methods and privacy considerations. To make this field more
accessible to newcomers, we highlight the state-of-the-art advancements and
identify unresolved challenges, offering insights for future research in this
evolving field.",2024-05-26,"Ashkan Vedadi Gargary, Emiliano De Cristofaro",http://arxiv.org/pdf/2405.16682v1,cs.LG
Limits of Deep Learning: Sequence Modeling through the Lens of Complexity Theory,"Despite their successes, deep learning models struggle with tasks requiring
complex reasoning and function composition. We present a theoretical and
empirical investigation into the limitations of Structured State Space Models
(SSMs) and Transformers in such tasks. We prove that one-layer SSMs cannot
efficiently perform function composition over large domains without
impractically large state sizes, and even with Chain-of-Thought prompting, they
require a number of steps that scale unfavorably with the complexity of the
function composition. Also, the language of a finite-precision SSM is within
the class of regular languages. Our experiments corroborate these theoretical
findings. Evaluating models on tasks including various function composition
settings, multi-digit multiplication, dynamic programming, and Einstein's
puzzle, we find significant performance degradation even with advanced
prompting techniques. Models often resort to shortcuts, leading to compounding
errors. These findings highlight fundamental barriers within current deep
learning architectures rooted in their computational capacities. We underscore
the need for innovative solutions to transcend these constraints and achieve
reliable multi-step reasoning and compositional task-solving, which is critical
for advancing toward general artificial intelligence.",2024-05-26,"Nikola Zubić, Federico Soldá, Aurelio Sulser, Davide Scaramuzza",http://arxiv.org/pdf/2405.16674v3,cs.LG
Transfer Learning Under High-Dimensional Graph Convolutional Regression Model for Node Classification,"Node classification is a fundamental task, but obtaining node classification
labels can be challenging and expensive in many real-world scenarios. Transfer
learning has emerged as a promising solution to address this challenge by
leveraging knowledge from source domains to enhance learning in a target
domain. Existing transfer learning methods for node classification primarily
focus on integrating Graph Convolutional Networks (GCNs) with various transfer
learning techniques. While these approaches have shown promising results, they
often suffer from a lack of theoretical guarantees, restrictive conditions, and
high sensitivity to hyperparameter choices. To overcome these limitations, we
propose a Graph Convolutional Multinomial Logistic Regression (GCR) model and a
transfer learning method based on the GCR model, called Trans-GCR. We provide
theoretical guarantees of the estimate obtained under GCR model in
high-dimensional settings. Moreover, Trans-GCR demonstrates superior empirical
performance, has a low computational cost, and requires fewer hyperparameters
than existing methods.",2024-05-26,"Jiachen Chen, Danyang Huang, Liyuan Wang, Kathryn L. Lunetta, Debarghya Mukherjee, Huimin Cheng",http://arxiv.org/pdf/2405.16672v1,cs.LG
Mixture of Latent Experts Using Tensor Products,"In multi-task learning, the conventional approach involves training a model
on multiple tasks simultaneously. However, the training signals from different
tasks can interfere with one another, potentially leading to \textit{negative
transfer}. To mitigate this, we investigate if modular language models can
facilitate positive transfer and systematic generalization. Specifically, we
propose a novel modular language model (\texttt{TensorPoly}), that balances
parameter efficiency with nuanced routing methods. For \textit{modules}, we
reparameterize Low-Rank Adaptation (\texttt{LoRA}) by employing an entangled
tensor through the use of tensor product operations and name the resulting
approach \texttt{TLoRA}. For \textit{routing function}, we tailor two
innovative routing functions according to the granularity:
\texttt{TensorPoly-I} which directs to each rank within the entangled tensor
while \texttt{TensorPoly-II} offers a finer-grained routing approach targeting
each order of the entangled tensor. The experimental results from the
multi-task T0-benchmark demonstrate that: 1) all modular LMs surpass the
corresponding dense approaches, highlighting the potential of modular language
models to mitigate negative inference in multi-task learning and deliver
superior outcomes. 2) \texttt{TensorPoly-I} achieves higher parameter
efficiency in adaptation and outperforms other modular LMs, which shows the
potential of our approach in multi-task transfer learning.",2024-05-26,"Zhan Su, Fengran Mo, Prayag Tiwari, Benyou Wang, Jian-Yun Nie, Jakob Grue Simonsen",http://arxiv.org/pdf/2405.16671v2,cs.LG
Provably Efficient Off-Policy Adversarial Imitation Learning with Convergence Guarantees,"Adversarial Imitation Learning (AIL) faces challenges with sample
inefficiency because of its reliance on sufficient on-policy data to evaluate
the performance of the current policy during reward function updates. In this
work, we study the convergence properties and sample complexity of off-policy
AIL algorithms. We show that, even in the absence of importance sampling
correction, reusing samples generated by the $o(\sqrt{K})$ most recent
policies, where $K$ is the number of iterations of policy updates and reward
updates, does not undermine the convergence guarantees of this class of
algorithms. Furthermore, our results indicate that the distribution shift error
induced by off-policy updates is dominated by the benefits of having more data
available. This result provides theoretical support for the sample efficiency
of off-policy AIL algorithms. To the best of our knowledge, this is the first
work that provides theoretical guarantees for off-policy AIL algorithms.",2024-05-26,"Yilei Chen, Vittorio Giammarino, James Queeney, Ioannis Ch. Paschalidis",http://arxiv.org/pdf/2405.16668v1,cs.LG
Comments on Friedman's Method for Class Distribution Estimation,"The purpose of class distribution estimation (also known as quantification)
is to determine the values of the prior class probabilities in a test dataset
without class label observations. A variety of methods to achieve this have
been proposed in the literature, most of them based on the assumption that the
distributions of the training and test data are related through prior
probability shift (also known as label shift). Among these methods, Friedman's
method has recently been found to perform relatively well both for binary and
multi-class quantification. We discuss the properties of Friedman's method and
another approach mentioned by Friedman (called DeBias method in the literature)
in the context of a general framework for designing linear equation systems for
class distribution estimation.",2024-05-26,Dirk Tasche,http://arxiv.org/pdf/2405.16666v2,cs.LG
"Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust","We give the first polynomial-time, differentially node-private, and robust
algorithm for estimating the edge density of Erd\H{o}s-R\'enyi random graphs
and their generalization, inhomogeneous random graphs. We further prove
information-theoretical lower bounds, showing that the error rate of our
algorithm is optimal up to logarithmic factors. Previous algorithms incur
either exponential running time or suboptimal error rates.
  Two key ingredients of our algorithm are (1) a new sum-of-squares algorithm
for robust edge density estimation, and (2) the reduction from privacy to
robustness based on sum-of-squares exponential mechanisms due to Hopkins et al.
(STOC 2023).",2024-05-26,"Hongjie Chen, Jingqiu Ding, Yiding Hua, David Steurer",http://arxiv.org/pdf/2405.16663v2,cs.LG
RLSF: Reinforcement Learning via Symbolic Feedback,"Reinforcement Learning with Human Feedback (RLHF) is considered a standard
approach to fine-tuning Large Language Models (LLMs). However, such methods
often face limitations such as unsound black-box reward models, difficulties in
collecting human preference data, and the reliance on sparse scalar rewards.
These methods often fall short when applied to tasks that require complex
domain-specific understanding.
  To address these challenges, we propose a new fine-tuning paradigm we refer
to as Reinforcement Learning via Symbolic Feedback (RLSF), which aims to
improve domain-specific understanding of LLMs more effectively than traditional
reward signals. In the RLSF setting, the LLM being fine-tuned is considered an
RL agent, while the environment is allowed access to reasoning or domain
knowledge tools (e.g., solvers, provers, algebra systems, or knowledge bases).
Crucially, in RLSF, these reasoning tools can provide feedback to the LLMs via
poly-sized certificates (e.g., proofs), that characterize errors in the
LLM-generated object with respect to some correctness specification. As a
bonus, our RLSF approach does not require the reasoning systems we use to be
differentiable. The ability of RLSF-based fine-tuning to leverage
certificate-generating symbolic tools enables sound fine-grained (token-level)
reward signals to LLMs, and thus addresses the limitations of traditional
reward models mentioned above.
  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs
outperforms traditional approaches on five different applications, namely,
program synthesis from natural language pseudo-code to programming language,
three chemistry tasks, and solving the Game of 24. A takeaway is that
fine-tuning via RLSF enables relatively smaller LLMs to significantly
outperform closed-source models that are orders of magnitude larger (e.g.,
GPT-4).",2024-05-26,"Piyush Jha, Prithwish Jana, Pranavkrishna Suresh, Arnav Arora, Vijay Ganesh",http://arxiv.org/pdf/2405.16661v2,cs.LG
Acceleration of Grokking in Learning Arithmetic Operations via Kolmogorov-Arnold Representation,"We propose novel methodologies aimed at accelerating the grokking phenomenon,
which refers to the rapid increment of test accuracy after a long period of
overfitting as reported in~\cite{power2022grokking}. Focusing on the grokking
phenomenon that arises in learning arithmetic binary operations via the
transformer model, we begin with a discussion on data augmentation in the case
of commutative binary operations. To further accelerate, we elucidate
arithmetic operations through the lens of the Kolmogorov-Arnold (KA)
representation theorem, revealing its correspondence to the transformer
architecture: embedding, decoder block, and classifier. Observing the shared
structure between KA representations associated with binary operations, we
suggest various transfer learning mechanisms that expedite grokking. This
interpretation is substantiated through a series of rigorous experiments. In
addition, our approach is successful in learning two nonstandard arithmetic
tasks: composition of operations and a system of equations. Furthermore, we
reveal that the model is capable of learning arithmetic operations using a
limited number of tokens under embedding transfer, which is supported by a set
of experiments as well.",2024-05-26,"Yeachan Park, Minseok Kim, Yeoneung Kim",http://arxiv.org/pdf/2405.16658v1,cs.LG
Predicting Likely-Vulnerable Code Changes: Machine Learning-based Vulnerability Protections for Android Open Source Project,"This paper presents a framework that selectively triggers security reviews
for incoming source code changes. Functioning as a review bot within a code
review service, the framework can automatically request additional security
reviews at pre-submit time before the code changes are submitted to a source
code repository. Because performing such secure code reviews add cost, the
framework employs a classifier trained to identify code changes with a high
likelihood of vulnerabilities. The online classifier leverages various types of
input features to analyze the review patterns, track the software engineering
process, and mine specific text patterns within given code changes. The
classifier and its features are meticulously chosen and optimized using data
from the submitted code changes and reported vulnerabilities in Android Open
Source Project (AOSP). The evaluation results demonstrate that our
Vulnerability Prevention (VP) framework identifies approximately 80% of the
vulnerability-inducing code changes in the dataset with a precision ratio of
around 98% and a false positive rate of around 1.7%. We discuss the
implications of deploying the VP framework in multi-project settings and future
directions for Android security research. This paper explores and validates our
approach to code change-granularity vulnerability prediction, offering a
preventive technique for software security by preemptively detecting vulnerable
code changes before submission.",2024-05-26,Keun Soo Yim,http://arxiv.org/pdf/2405.16655v1,cs.LG
Beyond Random Missingness: Clinically Rethinking for Healthcare Time Series Imputation,"This study investigates the impact of masking strategies on time series
imputation models in healthcare settings. While current approaches
predominantly rely on random masking for model evaluation, this practice fails
to capture the structured nature of missing patterns in clinical data. Using
the PhysioNet Challenge 2012 dataset, we analyse how different masking
implementations affect both imputation accuracy and downstream clinical
predictions across eleven imputation methods. Our results demonstrate that
masking choices significantly influence model performance, while recurrent
architectures show more consistent performance across strategies. Analysis of
downstream mortality prediction reveals that imputation accuracy doesn't
necessarily translate to optimal clinical prediction capabilities. Our findings
emphasise the need for clinically-informed masking strategies that better
reflect real-world missing patterns in healthcare data, suggesting current
evaluation frameworks may need reconsideration for reliable clinical
deployment.",2024-05-26,"Linglong Qian, Yiyuan Yang, Wenjie Du, Jun Wang, Richard Dobsoni, Zina Ibrahim",http://arxiv.org/pdf/2405.17508v3,cs.LG
A Provably Effective Method for Pruning Experts in Fine-tuned Sparse Mixture-of-Experts,"The sparsely gated mixture of experts (MoE) architecture sends different
inputs to different subnetworks, i.e., experts, through trainable routers. MoE
reduces the training computation significantly for large models, but its
deployment can be still memory or computation expensive for some downstream
tasks. Model pruning is a popular approach to reduce inference computation, but
its application in MoE architecture is largely unexplored. To the best of our
knowledge, this paper provides the first provably efficient technique for
pruning experts in finetuned MoE models. We theoretically prove that
prioritizing the pruning of the experts with a smaller change of the routers l2
norm from the pretrained model guarantees the preservation of test accuracy,
while significantly reducing the model size and the computational requirements.
Although our theoretical analysis is centered on binary classification tasks on
simplified MoE architecture, our expert pruning method is verified on large
vision MoE models such as VMoE and E3MoE finetuned on benchmark datasets such
as CIFAR10, CIFAR100, and ImageNet.",2024-05-26,"Mohammed Nowaz Rabbani Chowdhury, Meng Wang, Kaoutar El Maghraoui, Naigang Wang, Pin-Yu Chen, Christopher Carothers",http://arxiv.org/pdf/2405.16646v3,cs.LG
Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning,"In this paper, we obtain the Berry-Esseen bound for multivariate normal
approximation for the Polyak-Ruppert averaged iterates of the linear stochastic
approximation (LSA) algorithm with decreasing step size. Moreover, we prove the
non-asymptotic validity of the confidence intervals for parameter estimation
with LSA based on multiplier bootstrap. This procedure updates the LSA estimate
together with a set of randomly perturbed LSA estimates upon the arrival of
subsequent observations. We illustrate our findings in the setting of temporal
difference learning with linear function approximation.",2024-05-26,"Sergey Samsonov, Eric Moulines, Qi-Man Shao, Zhuo-Song Zhang, Alexey Naumov",http://arxiv.org/pdf/2405.16644v2,cs.LG
Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning,"A key challenge in lifelong reinforcement learning (RL) is the loss of
plasticity, where previous learning progress hinders an agent's adaptation to
new tasks. While regularization and resetting can help, they require precise
hyperparameter selection at the outset and environment-dependent adjustments.
Building on the principled theory of online convex optimization, we present a
parameter-free optimizer for lifelong RL, called TRAC, which requires no tuning
or prior knowledge about the distribution shifts. Extensive experiments on
Procgen, Atari, and Gym Control environments show that TRAC works surprisingly
well-mitigating loss of plasticity and rapidly adapting to challenging
distribution shifts-despite the underlying optimization problem being nonconvex
and nonstationary.",2024-05-26,"Aneesh Muppidi, Zhiyu Zhang, Heng Yang",http://arxiv.org/pdf/2405.16642v3,cs.LG
A direct proof of a unified law of robustness for Bregman divergence losses,"In contemporary deep learning practice, models are often trained to near zero
loss i.e. to nearly interpolate the training data. However, the number of
parameters in the model is usually far more than the number of data points n,
the theoretical minimum needed for interpolation: a phenomenon referred to as
overparameterization. In an interesting piece of work, Bubeck and Sellke
considered a natural notion of interpolation: the model is said to interpolate
when the model's training loss goes below the loss of the conditional
expectation of the response given the covariate. For this notion of
interpolation and for a broad class of covariate distributions (specifically
those satisfying a natural notion of concentration of measure), they showed
that overparameterization is necessary for robust interpolation i.e. if the
interpolating function is required to be Lipschitz. Their main proof technique
applies to regression with square loss against a scalar response, but they
remark that via a connection to Rademacher complexity and using tools such as
the Ledoux-Talagrand contraction inequality, their result can be extended to
more general losses, at least in the case of scalar response variables. In this
work, we recast the original proof technique of Bubeck and Sellke in terms of a
bias-variance type decomposition, and show that this view directly unlocks a
generalization to Bregman divergence losses (even for vector-valued responses),
without the use of tools such as Rademacher complexity or the Ledoux-Talagrand
contraction principle. Bregman divergences are a natural class of losses since
for these, the best estimator is the conditional expectation of the response
given the covariate, and include other practical losses such as the cross
entropy loss. Our work thus gives a more general understanding of the main
proof technique of Bubeck and Sellke and demonstrates its broad utility.",2024-05-26,"Santanu Das, Jatin Batra, Piyush Srivastava",http://arxiv.org/pdf/2405.16639v4,cs.LG
Enhancing Sustainable Urban Mobility Prediction with Telecom Data: A Spatio-Temporal Framework Approach,"Traditional traffic prediction, limited by the scope of sensor data, falls
short in comprehensive traffic management. Mobile networks offer a promising
alternative using network activity counts, but these lack crucial
directionality. Thus, we present the TeltoMob dataset, featuring undirected
telecom counts and corresponding directional flows, to predict directional
mobility flows on roadways. To address this, we propose a two-stage
spatio-temporal graph neural network (STGNN) framework. The first stage uses a
pre-trained STGNN to process telecom data, while the second stage integrates
directional and geographic insights for accurate prediction. Our experiments
demonstrate the framework's compatibility with various STGNN models and confirm
its effectiveness. We also show how to incorporate the framework into
real-world transportation systems, enhancing sustainable urban mobility.",2024-05-26,"ChungYi Lin, Shen-Lung Tung, Hung-Ting Su, Winston H. Hsu",http://arxiv.org/pdf/2405.17507v1,cs.LG
Bayesian Inference with Deep Weakly Nonlinear Networks,"We show at a physics level of rigor that Bayesian inference with a fully
connected neural network and a shaped nonlinearity of the form $\phi(t) = t +
\psi t^3/L$ is (perturbatively) solvable in the regime where the number of
training datapoints $P$ , the input dimension $N_0$, the network layer widths
$N$, and the network depth $L$ are simultaneously large. Our results hold with
weak assumptions on the data; the main constraint is that $P < N_0$. We provide
techniques to compute the model evidence and posterior to arbitrary order in
$1/N$ and at arbitrary temperature. We report the following results from the
first-order computation:
  1. When the width $N$ is much larger than the depth $L$ and training set size
$P$, neural network Bayesian inference coincides with Bayesian inference using
a kernel. The value of $\psi$ determines the curvature of a sphere, hyperbola,
or plane into which the training data is implicitly embedded under the feature
map.
  2. When $LP/N$ is a small constant, neural network Bayesian inference departs
from the kernel regime. At zero temperature, neural network Bayesian inference
is equivalent to Bayesian inference using a data-dependent kernel, and $LP/N$
serves as an effective depth that controls the extent of feature learning.
  3. In the restricted case of deep linear networks ($\psi=0$) and noisy data,
we show a simple data model for which evidence and generalization error are
optimal at zero temperature. As $LP/N$ increases, both evidence and
generalization further improve, demonstrating the benefit of depth in benign
overfitting.",2024-05-26,"Boris Hanin, Alexander Zlokapa",http://arxiv.org/pdf/2405.16630v1,cs.LG
Competing for pixels: a self-play algorithm for weakly-supervised segmentation,"Weakly-supervised segmentation (WSS) methods, reliant on image-level labels
indicating object presence, lack explicit correspondence between labels and
regions of interest (ROIs), posing a significant challenge. Despite this, WSS
methods have attracted attention due to their much lower annotation costs
compared to fully-supervised segmentation. Leveraging reinforcement learning
(RL) self-play, we propose a novel WSS method that gamifies image segmentation
of a ROI. We formulate segmentation as a competition between two agents that
compete to select ROI-containing patches until exhaustion of all such patches.
The score at each time-step, used to compute the reward for agent training,
represents likelihood of object presence within the selection, determined by an
object presence detector pre-trained using only image-level binary
classification labels of object presence. Additionally, we propose a game
termination condition that can be called by either side upon exhaustion of all
ROI-containing patches, followed by the selection of a final patch from each.
Upon termination, the agent is incentivised if ROI-containing patches are
exhausted or disincentivised if an ROI-containing patch is found by the
competitor. This competitive setup ensures minimisation of over- or
under-segmentation, a common problem with WSS methods. Extensive
experimentation across four datasets demonstrates significant performance
improvements over recent state-of-the-art methods. Code:
https://github.com/s-sd/spurl/tree/main/wss",2024-05-26,"Shaheer U. Saeed, Shiqi Huang, João Ramalhinho, Iani J. M. B. Gayo, Nina Montaña-Brown, Ester Bonmati, Stephen P. Pereira, Brian Davidson, Dean C. Barratt, Matthew J. Clarkson, Yipeng Hu",http://arxiv.org/pdf/2405.16628v1,cs.LG
Graph neural networks with configuration cross-attention for tensor compilers,"With the recent popularity of neural networks comes the need for efficient
serving of inference workloads. A neural network inference workload can be
represented as a computational graph with nodes as operators transforming
multidimensional tensors. The tensors can be transposed and/or tiled in a
combinatorially large number of ways, some configurations leading to
accelerated inference. We propose TGraph, a neural graph architecture that
allows screening for fast configurations of the target computational graph,
thus representing an artificial intelligence (AI) tensor compiler in contrast
to the traditional heuristics-based compilers. The proposed solution improves
mean Kendall's $\tau$ across layout collections of TpuGraphs from 29.8% of the
reliable baseline to 67.4% of TGraph. We estimate the potential CO$_2$ emission
reduction associated with our work to be equivalent to over 50% of the total
household emissions in the areas hosting AI-oriented data centers.",2024-05-26,"Dmitrii Khizbullin, Eduardo Rocha de Andrade, Thanh Hau Nguyen, Matheus Pedroza Ferreira, David R. Pugh",http://arxiv.org/pdf/2405.16623v2,cs.LG
DPHGNN: A Dual Perspective Hypergraph Neural Networks,"Message passing on hypergraphs has been a standard framework for learning
higher-order correlations between hypernodes. Recently-proposed hypergraph
neural networks (HGNNs) can be categorized into spatial and spectral methods
based on their design choices. In this work, we analyze the impact of change in
hypergraph topology on the suboptimal performance of HGNNs and propose DPHGNN,
a novel dual-perspective HGNN that introduces equivariant operator learning to
capture lower-order semantics by inducing topology-aware spatial and spectral
inductive biases. DPHGNN employs a unified framework to dynamically fuse
lower-order explicit feature representations from the underlying graph into the
super-imposed hypergraph structure. We benchmark DPHGNN over eight benchmark
hypergraph datasets for the semi-supervised hypernode classification task and
obtain superior performance compared to seven state-of-the-art baselines. We
also provide a theoretical framework and a synthetic hypergraph isomorphism
test to express the power of spatial HGNNs and quantify the expressivity of
DPHGNN beyond the Generalized Weisfeiler Leman (1-GWL) test. Finally, DPHGNN
was deployed by our partner e-commerce company for the Return-to-Origin (RTO)
prediction task, which shows ~7% higher macro F1-Score than the best baseline.",2024-05-26,"Siddhant Saxena, Shounak Ghatak, Raghu Kolla, Debashis Mukherjee, Tanmoy Chakraborty",http://arxiv.org/pdf/2405.16616v1,cs.LG
The devil is in discretization discrepancy. Robustifying Differentiable NAS with Single-Stage Searching Protocol,"Neural Architecture Search (NAS) has been widely adopted to design neural
networks for various computer vision tasks. One of its most promising
subdomains is differentiable NAS (DNAS), where the optimal architecture is
found in a differentiable manner. However, gradient-based methods suffer from
the discretization error, which can severely damage the process of obtaining
the final architecture. In our work, we first study the risk of discretization
error and show how it affects an unregularized supernet. Then, we present that
penalizing high entropy, a common technique of architecture regularization, can
hinder the supernet's performance. Therefore, to robustify the DNAS framework,
we introduce a novel single-stage searching protocol, which is not reliant on
decoding a continuous architecture. Our results demonstrate that this approach
outperforms other DNAS methods by achieving 75.3% in the searching stage on the
Cityscapes validation dataset and attains performance 1.1% higher than the
optimal network of DCNAS on the non-dense search space comprising short
connections. The entire training process takes only 5.5 GPU days due to the
weight reuse, and yields a computationally efficient architecture.
Additionally, we propose a new dataset split procedure, which substantially
improves results and prevents architecture degeneration in DARTS.",2024-05-26,"Konstanty Subbotko, Wojciech Jablonski, Piotr Bilinski",http://arxiv.org/pdf/2405.16610v1,cs.LG
Efficient Probabilistic Modeling of Crystallization at Mesoscopic Scale,"Crystallization processes at the mesoscopic scale, where faceted, dendritic
growth, and multigrain formation can be observed, are of particular interest
within materials science and metallurgy. These processes are highly nonlinear,
stochastic, and sensitive to small perturbations of system parameters and
initial conditions. Methods for the simulation of these processes have been
developed using discrete numerical models, but these are computationally
expensive. This work aims to scale crystal growth simulation with a machine
learning emulator. Specifically, autoregressive latent variable models are well
suited for modeling the joint distribution over system parameters and the
crystallization trajectories. However, successfully training such models is
challenging due to the stochasticity and sensitivity of the system. Existing
approaches consequently fail to produce diverse and faithful crystallization
trajectories. In this paper, we introduce the Crystal Growth Neural Emulator
(CGNE), a probabilistic model for efficient crystal growth emulation at the
mesoscopic scale that overcomes these challenges. We validate CGNE results
using the morphological properties of the crystals produced by numerical
simulation. CGNE delivers a factor of 11 improvement in inference time and
performance gains compared with recent state-of-the-art probabilistic models
for dynamical systems.",2024-05-26,"Pol Timmer, Koen Minartz, Vlado Menkovski",http://arxiv.org/pdf/2405.16608v1,cs.LG
A CMDP-within-online framework for Meta-Safe Reinforcement Learning,"Meta-reinforcement learning has widely been used as a learning-to-learn
framework to solve unseen tasks with limited experience. However, the aspect of
constraint violations has not been adequately addressed in the existing works,
making their application restricted in real-world settings. In this paper, we
study the problem of meta-safe reinforcement learning (Meta-SRL) through the
CMDP-within-online framework to establish the first provable guarantees in this
important setting. We obtain task-averaged regret bounds for the reward
maximization (optimality gap) and constraint violations using gradient-based
meta-learning and show that the task-averaged optimality gap and constraint
satisfaction improve with task-similarity in a static environment or
task-relatedness in a dynamic environment. Several technical challenges arise
when making this framework practical. To this end, we propose a meta-algorithm
that performs inexact online learning on the upper bounds of within-task
optimality gap and constraint violations estimated by off-policy stationary
distribution corrections. Furthermore, we enable the learning rates to be
adapted for every task and extend our approach to settings with a competing
dynamically changing oracle. Finally, experiments are conducted to demonstrate
the effectiveness of our approach.",2024-05-26,"Vanshaj Khattar, Yuhao Ding, Bilgehan Sel, Javad Lavaei, Ming Jin",http://arxiv.org/pdf/2405.16601v1,cs.LG
Regularized Projection Matrix Approximation with Applications to Community Detection,"This paper introduces a regularized projection matrix approximation framework
designed to recover cluster information from the affinity matrix. The model is
formulated as a projection approximation problem, incorporating an entry-wise
penalty function. We investigate three distinct penalty functions, each
specifically tailored to address bounded, positive, and sparse scenarios. To
solve this problem, we propose direct optimization on the Stiefel manifold,
utilizing the Cayley transformation along with the Alternating Direction Method
of Multipliers (ADMM) algorithm. Additionally, we provide a theoretical
analysis that establishes the convergence properties of ADMM, demonstrating
that the convergence point satisfies the KKT conditions of the original
problem. Numerical experiments conducted on both synthetic and real-world
datasets reveal that our regularized projection matrix approximation approach
significantly outperforms state-of-the-art methods in clustering performance.",2024-05-26,"Zheng Zhai, Jialu Xu, Mingxin Wu, Xiaohui Li",http://arxiv.org/pdf/2405.16598v2,cs.LG
Training-Conditional Coverage Bounds under Covariate Shift,"Training-conditional coverage guarantees in conformal prediction concern the
concentration of the error distribution, conditional on the training data,
below some nominal level. The conformal prediction methodology has recently
been generalized to the covariate shift setting, namely, the covariate
distribution changes between the training and test data. In this paper, we
study the training-conditional coverage properties of a range of conformal
prediction methods under covariate shift via a weighted version of the
Dvoretzky-Kiefer-Wolfowitz (DKW) inequality tailored for distribution change.
The result for the split conformal method is almost assumption-free, while the
results for the full conformal and jackknife+ methods rely on strong
assumptions including the uniform stability of the training algorithm.",2024-05-26,"Mehrdad Pournaderi, Yu Xiang",http://arxiv.org/pdf/2405.16594v1,cs.LG
Cost-Effective Online Multi-LLM Selection with Versatile Reward Models,"With the rapid advancement of large language models (LLMs), the diversity of
multi-LLM tasks and the variability in their pricing structures have become
increasingly important, as costs can vary greatly between different LLMs. To
tackle these challenges, we introduce the \textit{C2MAB-V}, a
\underline{C}ost-effective \underline{C}ombinatorial \underline{M}ulti-armed
\underline{B}andit with \underline{V}ersatile reward models for optimal LLM
selection and usage. This online model differs from traditional static
approaches or those reliant on a single LLM without cost consideration. With
multiple LLMs deployed on a scheduling cloud and a local server dedicated to
handling user queries, \textit{C2MAB-V} facilitates the selection of multiple
LLMs over a combinatorial search space, specifically tailored for various
collaborative task types with different reward models. Based on our designed
online feedback mechanism and confidence bound technique, \textit{C2MAB-V} can
effectively address the multi-LLM selection challenge by managing the
exploration-exploitation trade-off across different models, while also
balancing cost and reward for diverse tasks. The NP-hard integer linear
programming problem for selecting multiple LLMs with trade-off dilemmas is
addressed by: i) decomposing the integer problem into a relaxed form by the
local server, ii) utilizing a discretization rounding scheme that provides
optimal LLM combinations by the scheduling cloud, and iii) continual online
updates based on feedback. Theoretically, we prove that \textit{C2MAB-V} offers
strict guarantees over versatile reward models, matching state-of-the-art
results for regret and violations in some degenerate cases. Empirically, we
show that \textit{C2MAB-V} effectively balances performance and cost-efficiency
with nine LLMs for three application scenarios.",2024-05-26,"Xiangxiang Dai, Jin Li, Xutong Liu, Anqi Yu, John C. S. Lui",http://arxiv.org/pdf/2405.16587v2,cs.LG
Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity,"Federated learning (FL) has emerged as a new paradigm for privacy-preserving
collaborative training. Under domain skew, the current FL approaches are biased
and face two fairness problems. 1) Parameter Update Conflict: data disparity
among clients leads to varying parameter importance and inconsistent update
directions. These two disparities cause important parameters to potentially be
overwhelmed by unimportant ones of dominant updates. It consequently results in
significant performance decreases for lower-performing clients. 2) Model
Aggregation Bias: existing FL approaches introduce unfair weight allocation and
neglect domain diversity. It leads to biased model convergence objective and
distinct performance among domains. We discover a pronounced directional update
consistency in Federated Learning and propose a novel framework to tackle above
issues. First, leveraging the discovered characteristic, we selectively discard
unimportant parameter updates to prevent updates from clients with lower
performance overwhelmed by unimportant parameters, resulting in fairer
generalization performance. Second, we propose a fair aggregation objective to
prevent global model bias towards some domains, ensuring that the global model
continuously aligns with an unbiased model. The proposed method is generic and
can be combined with other existing FL methods to enhance fairness.
Comprehensive experiments on Digits and Office-Caltech demonstrate the high
fairness and performance of our method.",2024-05-26,"Yuhang Chen, Wenke Huang, Mang Ye",http://arxiv.org/pdf/2405.16585v1,cs.LG
Subspace Node Pruning,"Efficiency of neural network inference is undeniably important in a time
where commercial use of AI models increases daily. Node pruning is the art of
removing computational units such as neurons, filters, attention heads, or even
entire layers to significantly reduce inference time while retaining network
performance. In this work, we propose the projection of unit activations to an
orthogonal subspace in which there is no redundant activity and within which we
may prune nodes while simultaneously recovering the impact of lost units via
linear least squares. We identify that, for effective node pruning, this
subspace must be constructed using a triangular transformation matrix, a
transformation which is equivalent to and unnormalized Gram-Schmidt
orthogonalization. We furthermore show that the order in which units are
orthogonalized can be optimised to maximally reduce node activations in our
subspace and thereby form a more optimal ranking of nodes. Finally, we leverage
these orthogonal subspaces to automatically determine layer-wise pruning ratios
based upon the relative scale of node activations in our subspace, equivalent
to cumulative variance. Our proposed method reaches state of the art when
pruning ImageNet trained VGG-16 and rivals more complex state of the art
methods when pruning ResNet-50 networks across a range of pruning ratios.",2024-05-26,"Joshua Offergeld, Marcel van Gerven, Nasir Ahmad",http://arxiv.org/pdf/2405.17506v2,cs.LG
On Bits and Bandits: Quantifying the Regret-Information Trade-off,"In many sequential decision problems, an agent performs a repeated task. He
then suffers regret and obtains information that he may use in the following
rounds. However, sometimes the agent may also obtain information and avoid
suffering regret by querying external sources. We study the trade-off between
the information an agent accumulates and the regret it suffers. We invoke
information-theoretic methods for obtaining regret lower bounds, that also
allow us to easily re-derive several known lower bounds. We introduce the first
Bayesian regret lower bounds that depend on the information an agent
accumulates. We also prove regret upper bounds using the amount of information
the agent accumulates. These bounds show that information measured in bits, can
be traded off for regret, measured in reward. Finally, we demonstrate the
utility of these bounds in improving the performance of a question-answering
task with large language models, allowing us to obtain valuable insights.",2024-05-26,"Itai Shufaro, Nadav Merlis, Nir Weinberger, Shie Mannor",http://arxiv.org/pdf/2405.16581v4,cs.LG
A Study on Unsupervised Anomaly Detection and Defect Localization using Generative Model in Ultrasonic Non-Destructive Testing,"In recent years, the deterioration of artificial materials used in structures
has become a serious social issue, increasing the importance of inspections.
Non-destructive testing is gaining increased demand due to its capability to
inspect for defects and deterioration in structures while preserving their
functionality. Among these, Laser Ultrasonic Visualization Testing (LUVT)
stands out because it allows the visualization of ultrasonic propagation. This
makes it visually straightforward to detect defects, thereby enhancing
inspection efficiency. With the increasing number of the deterioration
structures, challenges such as a shortage of inspectors and increased workload
in non-destructive testing have become more apparent. Efforts to address these
challenges include exploring automated inspection using machine learning.
However, the lack of anomalous data with defects poses a barrier to improving
the accuracy of automated inspection through machine learning. Therefore, in
this study, we propose a method for automated LUVT inspection using an anomaly
detection approach with a diffusion model that can be trained solely on
negative examples (defect-free data). We experimentally confirmed that our
proposed method improves defect detection and localization compared to general
object detection algorithms used previously.",2024-05-26,"Yusaku Ando, Miya Nakajima, Takahiro Saitoh, Tsuyoshi Kato",http://arxiv.org/pdf/2405.16580v1,cs.LG
Reflected Flow Matching,"Continuous normalizing flows (CNFs) learn an ordinary differential equation
to transform prior samples into data. Flow matching (FM) has recently emerged
as a simulation-free approach for training CNFs by regressing a velocity model
towards the conditional velocity field. However, on constrained domains, the
learned velocity model may lead to undesirable flows that result in highly
unnatural samples, e.g., oversaturated images, due to both flow matching error
and simulation error. To address this, we add a boundary constraint term to
CNFs, which leads to reflected CNFs that keep trajectories within the
constrained domains. We propose reflected flow matching (RFM) to train the
velocity model in reflected CNFs by matching the conditional velocity fields in
a simulation-free manner, similar to the vanilla FM. Moreover, the analytical
form of conditional velocity fields in RFM avoids potentially biased
approximations, making it superior to existing score-based generative models on
constrained domains. We demonstrate that RFM achieves comparable or better
results on standard image benchmarks and produces high-quality
class-conditioned samples under high guidance weight.",2024-05-26,"Tianyu Xie, Yu Zhu, Longlin Yu, Tong Yang, Ziheng Cheng, Shiyue Zhang, Xiangyu Zhang, Cheng Zhang",http://arxiv.org/pdf/2405.16577v1,cs.LG
Contextual Linear Optimization with Bandit Feedback,"Contextual linear optimization (CLO) uses predictive contextual features to
reduce uncertainty in random cost coefficients and thereby improve average-cost
performance. An example is the stochastic shortest path problem with random
edge costs (e.g., traffic) and contextual features (e.g., lagged traffic,
weather). Existing work on CLO assumes the data has fully observed cost
coefficient vectors, but in many applications, we can only see the realized
cost of a historical decision, that is, just one projection of the random cost
coefficient vector, to which we refer as bandit feedback. We study a class of
offline learning algorithms for CLO with bandit feedback, which we term induced
empirical risk minimization (IERM), where we fit a predictive model to directly
optimize the downstream performance of the policy it induces. We show a
fast-rate regret bound for IERM that allows for misspecified model classes and
flexible choices of the optimization estimate, and we develop computationally
tractable surrogate losses. A byproduct of our theory of independent interest
is fast-rate regret bound for IERM with full feedback and misspecified policy
class. We compare the performance of different modeling choices numerically
using a stochastic shortest path example and provide practical insights from
the empirical results.",2024-05-26,"Yichun Hu, Nathan Kallus, Xiaojie Mao, Yanchen Wu",http://arxiv.org/pdf/2405.16564v2,cs.LG
Higher-Order Transformer Derivative Estimates for Explicit Pathwise Learning Guarantees,"An inherent challenge in computing fully-explicit generalization bounds for
transformers involves obtaining covering number estimates for the given
transformer class $T$. Crude estimates rely on a uniform upper bound on the
local-Lipschitz constants of transformers in $T$, and finer estimates require
an analysis of their higher-order partial derivatives. Unfortunately, these
precise higher-order derivative estimates for (realistic) transformer models
are not currently available in the literature as they are combinatorially
delicate due to the intricate compositional structure of transformer blocks.
  This paper fills this gap by precisely estimating all the higher-order
derivatives of all orders for the transformer model. We consider realistic
transformers with multiple (non-linearized) attention heads per block and layer
normalization. We obtain fully-explicit estimates of all constants in terms of
the number of attention heads, the depth and width of each transformer block,
and the number of normalization layers. Further, we explicitly analyze the
impact of various standard activation function choices (e.g. SWISH and GeLU).
As an application, we obtain explicit pathwise generalization bounds for
transformers on a single trajectory of an exponentially-ergodic Markov process
valid at a fixed future time horizon. We conclude that real-world transformers
can learn from $N$ (non-i.i.d.) samples of a single Markov process's trajectory
at a rate of ${O}(\operatorname{polylog}(N)/\sqrt{N})$.",2024-05-26,"Yannick Limmer, Anastasis Kratsios, Xuwei Yang, Raeid Saqur, Blanka Horvath",http://arxiv.org/pdf/2405.16563v2,cs.LG
Task Groupings Regularization: Data-Free Meta-Learning with Heterogeneous Pre-trained Models,"Data-Free Meta-Learning (DFML) aims to derive knowledge from a collection of
pre-trained models without accessing their original data, enabling the rapid
adaptation to new unseen tasks. Current methods often overlook the
heterogeneity among pre-trained models, which leads to performance degradation
due to task conflicts. In this paper, we empirically and theoretically identify
and analyze the model heterogeneity in DFML. We find that model heterogeneity
introduces a heterogeneity-homogeneity trade-off, where homogeneous models
reduce task conflicts but also increase the overfitting risk. Balancing this
trade-off is crucial for learning shared representations across tasks. Based on
our findings, we propose Task Groupings Regularization that benefits from model
heterogeneity by grouping and aligning conflicting tasks. Specifically, we
embed pre-trained models into a task space to compute dissimilarity, and group
heterogeneous models together based on this measure. Then, we introduce
implicit gradient regularization within each group to mitigate potential
conflicts. By encouraging a gradient direction suitable for all tasks, the
meta-model captures shared representations that generalize across tasks.
Comprehensive experiments showcase the superiority of our approach in multiple
benchmarks, effectively tackling the model heterogeneity in challenging
multi-domain and multi-architecture scenarios.",2024-05-26,"Yongxian Wei, Zixuan Hu, Li Shen, Zhenyi Wang, Yu Li, Chun Yuan, Dacheng Tao",http://arxiv.org/pdf/2405.16560v2,cs.LG
Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning,"Multivariate time series (MTS) data, when sampled irregularly and
asynchronously, often present extensive missing values. Conventional
methodologies for MTS analysis tend to rely on temporal embeddings based on
timestamps that necessitate subsequent imputations, yet these imputed values
frequently deviate substantially from their actual counterparts, thereby
compromising prediction accuracy. Furthermore, these methods typically fail to
provide robust initial embeddings for values infrequently observed or even
absent within the training set, posing significant challenges to model
generalizability. In response to these challenges, we propose SCAlable
Numerical Embedding (SCANE), a novel framework that treats each feature value
as an independent token, effectively bypassing the need for imputation. SCANE
regularizes the traits of distinct feature embeddings and enhances
representational learning through a scalable embedding mechanism. Coupling
SCANE with the Transformer Encoder architecture, we develop the Scalable
nUMerical eMbeddIng Transformer (SUMMIT), which is engineered to deliver
precise predictive outputs for MTS characterized by prevalent missing entries.
Our experimental validation, conducted across three disparate electronic health
record (EHR) datasets marked by elevated missing value frequencies, confirms
the superior performance of SUMMIT over contemporary state-of-the-art
approaches addressing similar challenges. These results substantiate the
efficacy of SCANE and SUMMIT, underscoring their potential applicability across
a broad spectrum of MTS data analytical tasks.",2024-05-26,"Chun-Kai Huang, Yi-Hsien Hsieh, Ta-Jung Chien, Li-Cheng Chien, Shao-Hua Sun, Tung-Hung Su, Jia-Horng Kao, Che Lin",http://arxiv.org/pdf/2405.16557v1,cs.LG
Variance-Reducing Couplings for Random Features,"Random features (RFs) are a popular technique to scale up kernel methods in
machine learning, replacing exact kernel evaluations with stochastic Monte
Carlo estimates. They underpin models as diverse as efficient transformers (by
approximating attention) to sparse spectrum Gaussian processes (by
approximating the covariance function). Efficiency can be further improved by
speeding up the convergence of these estimates: a variance reduction problem.
We tackle this through the unifying lens of optimal transport, finding
couplings to improve RFs defined on both Euclidean and discrete input spaces.
They enjoy theoretical guarantees and sometimes provide strong downstream
gains, including for scalable approximate inference on graphs. We reach
surprising conclusions about the benefits and limitations of variance reduction
as a paradigm, showing that other properties of the coupling should be
optimised for attention estimation in efficient transformers.",2024-05-26,"Isaac Reid, Stratis Markou, Krzysztof Choromanski, Richard E. Turner, Adrian Weller",http://arxiv.org/pdf/2405.16541v2,cs.LG
LoQT: Low-Rank Adapters for Quantized Pretraining,"Despite advances using low-rank adapters and quantization, pretraining of
large models on consumer hardware has not been possible without model sharding,
offloading during training, or per-layer gradient updates. To address these
limitations, we propose Low-Rank Adapters for Quantized Training (LoQT), a
method for efficiently training quantized models. LoQT uses gradient-based
tensor factorization to initialize low-rank trainable weight matrices that are
periodically merged into quantized full-rank weight matrices. Our approach is
suitable for both pretraining and fine-tuning models. We demonstrate this for
language modeling and downstream task adaptation, finding that LoQT enables
efficient training of models up to 7B parameters on a 24GB GPU. We also
demonstrate the feasibility of training a 13B model using per-layer gradient
updates on the same hardware.",2024-05-26,"Sebastian Loeschcke, Mads Toftrup, Michael J. Kastoryano, Serge Belongie, Vésteinn Snæbjarnarson",http://arxiv.org/pdf/2405.16528v4,cs.LG
Multi-State TD Target for Model-Free Reinforcement Learning,"Temporal difference (TD) learning is a fundamental technique in reinforcement
learning that updates value estimates for states or state-action pairs using a
TD target. This target represents an improved estimate of the true value by
incorporating both immediate rewards and the estimated value of subsequent
states. Traditionally, TD learning relies on the value of a single subsequent
state. We propose an enhanced multi-state TD (MSTD) target that utilizes the
estimated values of multiple subsequent states. Building on this new MSTD
concept, we develop complete actor-critic algorithms that include management of
replay buffers in two modes, and integrate with deep deterministic policy
optimization (DDPG) and soft actor-critic (SAC). Experimental results
demonstrate that algorithms employing the MSTD target significantly improve
learning performance compared to traditional methods.The code is provided on
GitHub.",2024-05-26,"Wuhao Wang, Zhiyong Chen, Lepeng Zhang",http://arxiv.org/pdf/2405.16522v4,cs.LG
Fourier Sliced-Wasserstein Embedding for Multisets and Measures,"We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to
embed multisets and measures over R^d into Euclidean space.
  Our proposed embedding approximately preserves the sliced Wasserstein
distance on distributions, thereby yielding geometrically meaningful
representations that better capture the structure of the input. Moreover, it is
injective on measures and bi-Lipschitz on multisets - a significant advantage
over prevalent methods based on sum- or max-pooling, which are provably not
bi-Lipschitz, and, in many cases, not even injective. The required output
dimension for these guarantees is near-optimal: roughly 2Nd, where N is the
maximal input multiset size.
  Furthermore, we prove that it is impossible to embed distributions over R^d
into Euclidean space in a bi-Lipschitz manner. Thus, the metric properties of
our embedding are, in a sense, the best possible.
  Through numerical experiments, we demonstrate that our method yields superior
multiset representations that improve performance in practical learning tasks.
Specifically, we show that (a) a simple combination of the FSW embedding with
an MLP achieves state-of-the-art performance in learning the (non-sliced)
Wasserstein distance; and (b) replacing max-pooling with the FSW embedding
makes PointNet significantly more robust to parameter reduction, with only
minor performance degradation even after a 40-fold reduction.",2024-05-26,"Tal Amir, Nadav Dym",http://arxiv.org/pdf/2405.16519v3,cs.LG
SE3Set: Harnessing equivariant hypergraph neural networks for molecular representation learning,"In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural
network architecture tailored for advanced molecular representation learning.
Hypergraphs are not merely an extension of traditional graphs; they are pivotal
for modeling high-order relationships, a capability that conventional
equivariant graph-based methods lack due to their inherent limitations in
representing intricate many-body interactions. To achieve this, we first
construct hypergraphs via proposing a new fragmentation method that considers
both chemical and three-dimensional spatial information of molecular system. We
then design SE3Set, which incorporates equivariance into the hypergragh neural
network. This ensures that the learned molecular representations are invariant
to spatial transformations, thereby providing robustness essential for accurate
prediction of molecular properties. SE3Set has shown performance on par with
state-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17.
It excels on the MD22 dataset, achieving a notable improvement of approximately
20% in accuracy across all molecules, which highlights the prevalence of
complex many-body interactions in larger molecules. This exceptional
performance of SE3Set across diverse molecular structures underscores its
transformative potential in computational chemistry, offering a route to more
accurate and physically nuanced modeling.",2024-05-26,"Hongfei Wu, Lijun Wu, Guoqing Liu, Zhirong Liu, Bin Shao, Zun Wang",http://arxiv.org/pdf/2405.16511v1,cs.LG
Planning with Multi-Constraints via Collaborative Language Agents,"The rapid advancement of neural language models has sparked a new surge of
intelligent agent research. Unlike traditional agents, large language
model-based agents (LLM agents) have emerged as a promising paradigm for
achieving artificial general intelligence (AGI) due to their superior reasoning
and generalization capabilities. Effective planning is crucial for the success
of LLM agents in real-world tasks, making it a highly pursued topic in the
community. Current planning methods typically translate tasks into executable
action sequences. However, determining a feasible or optimal sequence for
complex tasks with multiple constraints at fine granularity, which often
requires compositing long chains of heterogeneous actions, remains challenging.
This paper introduces Planning with Multi-Constraints (PMC), a zero-shot
methodology for collaborative LLM-based multi-agent systems that simplifies
complex task planning with constraints by decomposing it into a hierarchy of
subordinate tasks. Each subtask is then mapped into executable actions. PMC was
assessed on two constraint-intensive benchmarks, TravelPlanner and API-Bank.
Notably, PMC achieved an average 42.68% success rate on TravelPlanner,
significantly higher than GPT-4 (2.92%), and outperforming GPT-4 with ReAct on
API-Bank by 13.64%, showing the immense potential of integrating LLM with
multi-agent systems. We also show that PMC works with small LLM as the planning
core, e.g., LLaMA-3.1-8B.",2024-05-26,"Cong Zhang, Derrick Goh Xin Deik, Dexun Li, Hao Zhang, Yong Liu",http://arxiv.org/pdf/2405.16510v4,cs.LG
AnyCBMs: How to Turn Any Black Box into a Concept Bottleneck Model,"Interpretable deep learning aims at developing neural architectures whose
decision-making processes could be understood by their users. Among these
techniqes, Concept Bottleneck Models enhance the interpretability of neural
networks by integrating a layer of human-understandable concepts. These models,
however, necessitate training a new model from the beginning, consuming
significant resources and failing to utilize already trained large models. To
address this issue, we introduce ""AnyCBM"", a method that transforms any
existing trained model into a Concept Bottleneck Model with minimal impact on
computational resources. We provide both theoretical and experimental insights
showing the effectiveness of AnyCBMs in terms of classification performances
and effectivenss of concept-based interventions on downstream tasks.",2024-05-26,"Gabriele Dominici, Pietro Barbiero, Francesco Giannini, Martin Gjoreski, Marc Langhenirich",http://arxiv.org/pdf/2405.16508v1,cs.LG
Causal Concept Graph Models: Beyond Causal Opacity in Deep Learning,"Causal opacity denotes the difficulty in understanding the ""hidden"" causal
structure underlying the decisions of deep neural network (DNN) models. This
leads to the inability to rely on and verify state-of-the-art DNN-based
systems, especially in high-stakes scenarios. For this reason, circumventing
causal opacity in DNNs represents a key open challenge at the intersection of
deep learning, interpretability, and causality. This work addresses this gap by
introducing Causal Concept Graph Models (Causal CGMs), a class of interpretable
models whose decision-making process is causally transparent by design. Our
experiments show that Causal CGMs can: (i) match the generalisation performance
of causally opaque models, (ii) enable human-in-the-loop corrections to
mispredicted intermediate reasoning steps, boosting not just downstream
accuracy after corrections but also the reliability of the explanations
provided for specific instances, and (iii) support the analysis of
interventional and counterfactual scenarios, thereby improving the model's
causal interpretability and supporting the effective verification of its
reliability and fairness.",2024-05-26,"Gabriele Dominici, Pietro Barbiero, Mateo Espinosa Zarlenga, Alberto Termine, Martin Gjoreski, Giuseppe Marra, Marc Langheinrich",http://arxiv.org/pdf/2405.16507v6,cs.LG
GRAG: Graph Retrieval-Augmented Generation,"Naive Retrieval-Augmented Generation (RAG) focuses on individual documents
during retrieval and, as a result, falls short in handling networked documents
which are very popular in many applications such as citation graphs, social
media, and knowledge graphs. To overcome this limitation, we introduce Graph
Retrieval-Augmented Generation (GRAG), which tackles the fundamental challenges
in retrieving textual subgraphs and integrating the joint textual and
topological information into Large Language Models (LLMs) to enhance its
generation. To enable efficient textual subgraph retrieval, we propose a novel
divide-and-conquer strategy that retrieves the optimal subgraph structure in
linear time. To achieve graph context-aware generation, incorporate textual
graphs into LLMs through two complementary views-the text view and the graph
view-enabling LLMs to more effectively comprehend and utilize the graph
context. Extensive experiments on graph reasoning benchmarks demonstrate that
in scenarios requiring multi-hop reasoning on textual graphs, our GRAG approach
significantly outperforms current state-of-the-art RAG methods.",2024-05-26,"Yuntong Hu, Zhihan Lei, Zheng Zhang, Bo Pan, Chen Ling, Liang Zhao",http://arxiv.org/pdf/2405.16506v2,cs.LG
Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation,"Recent advances in efficient sequence modeling have led to attention-free
layers, such as Mamba, RWKV, and various gated RNNs, all featuring
sub-quadratic complexity in sequence length and excellent scaling properties,
enabling the construction of a new type of foundation models. In this paper, we
present a unified view of these models, formulating such layers as implicit
causal self-attention layers. The formulation includes most of their
sub-components and is not limited to a specific part of the architecture. The
framework compares the underlying mechanisms on similar grounds for different
layers and provides a direct means for applying explainability methods. Our
experiments show that our attention matrices and attribution method outperform
an alternative and a more limited formulation that was recently proposed for
Mamba. For the other architectures for which our method is the first to provide
such a view, our method is effective and competitive in the relevant metrics
compared to the results obtained by state-of-the-art Transformer explainability
methods. Our code is publicly available.",2024-05-26,"Itamar Zimerman, Ameen Ali, Lior Wolf",http://arxiv.org/pdf/2405.16504v2,cs.LG
Integrating GNN and Neural ODEs for Estimating Non-Reciprocal Two-Body Interactions in Mixed-Species Collective Motion,"Analyzing the motion of multiple biological agents, be it cells or individual
animals, is pivotal for the understanding of complex collective behaviors. With
the advent of advanced microscopy, detailed images of complex tissue formations
involving multiple cell types have become more accessible in recent years.
However, deciphering the underlying rules that govern cell movements is far
from trivial. Here, we present a novel deep learning framework for estimating
the underlying equations of motion from observed trajectories, a pivotal step
in decoding such complex dynamics. Our framework integrates graph neural
networks with neural differential equations, enabling effective prediction of
two-body interactions based on the states of the interacting entities. We
demonstrate the efficacy of our approach through two numerical experiments.
First, we used simulated data from a toy model to tune the hyperparameters.
Based on the obtained hyperparameters, we then applied this approach to a more
complex model with non-reciprocal forces that mimic the collective dynamics of
the cells of slime molds. Our results show that the proposed method can
accurately estimate the functional forms of two-body interactions -- even when
they are nonreciprocal -- thereby precisely replicating both individual and
collective behaviors within these systems.",2024-05-26,"Masahito Uwamichi, Simon K. Schnyder, Tetsuya J. Kobayashi, Satoshi Sawai",http://arxiv.org/pdf/2405.16503v2,cs.LG
On Sequential Maximum a Posteriori Inference for Continual Learning,"We formulate sequential maximum a posteriori inference as a recursion of loss
functions and reduce the problem of continual learning to approximating the
previous loss function. We then propose two coreset-free methods: autodiff
quadratic consolidation, which uses an accurate and full quadratic
approximation, and neural consolidation, which uses a neural network
approximation. These methods are not scalable with respect to the neural
network size, and we study them for classification tasks in combination with a
fixed pre-trained feature extractor. We also introduce simple but challenging
classical task sequences based on Iris and Wine datasets. We find that neural
consolidation performs well in the classical task sequences, where the input
dimension is small, while autodiff quadratic consolidation performs
consistently well in image task sequences with a fixed pre-trained feature
extractor, achieving comparable performance to joint maximum a posteriori
training in many cases.",2024-05-26,"Menghao Waiyan William Zhu, Ercan Engin Kuruoğlu",http://arxiv.org/pdf/2405.16498v4,cs.LG
Exploring a Multimodal Fusion-based Deep Learning Network for Detecting Facial Palsy,"Algorithmic detection of facial palsy offers the potential to improve current
practices, which usually involve labor-intensive and subjective assessment by
clinicians. In this paper, we present a multimodal fusion-based deep learning
model that utilizes unstructured data (i.e. an image frame with facial line
segments) and structured data (i.e. features of facial expressions) to detect
facial palsy. We then contribute to a study to analyze the effect of different
data modalities and the benefits of a multimodal fusion-based approach using
videos of 21 facial palsy patients. Our experimental results show that among
various data modalities (i.e. unstructured data - RGB images and images of
facial line segments and structured data - coordinates of facial landmarks and
features of facial expressions), the feed-forward neural network using features
of facial expression achieved the highest precision of 76.22 while the
ResNet-based model using images of facial line segments achieved the highest
recall of 83.47. When we leveraged both images of facial line segments and
features of facial expressions, our multimodal fusion-based deep learning model
slightly improved the precision score to 77.05 at the expense of a decrease in
the recall score.",2024-05-26,"Heng Yim Nicole Oo, Min Hun Lee, Jeong Hoon Lim",http://arxiv.org/pdf/2405.16496v2,cs.LG
Causal-aware Graph Neural Architecture Search under Distribution Shifts,"Graph NAS has emerged as a promising approach for autonomously designing GNN
architectures by leveraging the correlations between graphs and architectures.
Existing methods fail to generalize under distribution shifts that are
ubiquitous in real-world graph scenarios, mainly because the graph-architecture
correlations they exploit might be spurious and varying across distributions.
We propose to handle the distribution shifts in the graph architecture search
process by discovering and exploiting the causal relationship between graphs
and architectures to search for the optimal architectures that can generalize
under distribution shifts. The problem remains unexplored with following
challenges: how to discover the causal graph-architecture relationship that has
stable predictive abilities across distributions, and how to handle
distribution shifts with the discovered causal graph-architecture relationship
to search the generalized graph architectures. To address these challenges, we
propose Causal-aware Graph Neural Architecture Search (CARNAS), which is able
to capture the causal graph-architecture relationship during the architecture
search process and discover the generalized graph architecture under
distribution shifts. Specifically, we propose Disentangled Causal Subgraph
Identification to capture the causal subgraphs that have stable prediction
abilities across distributions. Then, we propose Graph Embedding Intervention
to intervene on causal subgraphs within the latent space, ensuring that these
subgraphs encapsulate essential features for prediction while excluding
non-causal elements. Additionally, we propose Invariant Architecture
Customization to reinforce the causal invariant nature of the causal subgraphs,
which are utilized to tailor generalized graph architectures. Extensive
experiments demonstrate that CARNAS achieves advanced out-of-distribution
generalization ability.",2024-05-26,"Peiwen Li, Xin Wang, Zeyang Zhang, Yijian Qin, Ziwei Zhang, Jialong Wang, Yang Li, Wenwu Zhu",http://arxiv.org/pdf/2405.16489v2,cs.LG
KiNETGAN: Enabling Distributed Network Intrusion Detection through Knowledge-Infused Synthetic Data Generation,"In the realm of IoT/CPS systems connected over mobile networks, traditional
intrusion detection methods analyze network traffic across multiple devices
using anomaly detection techniques to flag potential security threats. However,
these methods face significant privacy challenges, particularly with deep
packet inspection and network communication analysis. This type of monitoring
is highly intrusive, as it involves examining the content of data packets,
which can include personal and sensitive information. Such data scrutiny is
often governed by stringent laws and regulations, especially in environments
like smart homes where data privacy is paramount. Synthetic data offers a
promising solution by mimicking real network behavior without revealing
sensitive details. Generative models such as Generative Adversarial Networks
(GANs) can produce synthetic data, but they often struggle to generate
realistic data in specialized domains like network activity. This limitation
stems from insufficient training data, which impedes the model's ability to
grasp the domain's rules and constraints adequately. Moreover, the scarcity of
training data exacerbates the problem of class imbalance in intrusion detection
methods. To address these challenges, we propose a Privacy-Driven framework
that utilizes a knowledge-infused Generative Adversarial Network for generating
synthetic network activity data (KiNETGAN). This approach enhances the
resilience of distributed intrusion detection while addressing privacy
concerns. Our Knowledge Guided GAN produces realistic representations of
network activity, validated through rigorous experimentation. We demonstrate
that KiNETGAN maintains minimal accuracy loss in downstream tasks, effectively
balancing data privacy and utility.",2024-05-26,"Anantaa Kotal, Brandon Luton, Anupam Joshi",http://arxiv.org/pdf/2405.16476v1,cs.LG
Looks Too Good To Be True: An Information-Theoretic Analysis of Hallucinations in Generative Restoration Models,"The pursuit of high perceptual quality in image restoration has driven the
development of revolutionary generative models, capable of producing results
often visually indistinguishable from real data. However, as their perceptual
quality continues to improve, these models also exhibit a growing tendency to
generate hallucinations - realistic-looking details that do not exist in the
ground truth images. Hallucinations in these models create uncertainty about
their reliability, raising major concerns about their practical application.
This paper investigates this phenomenon through the lens of information theory,
revealing a fundamental tradeoff between uncertainty and perception. We
rigorously analyze the relationship between these two factors, proving that the
global minimal uncertainty in generative models grows in tandem with
perception. In particular, we define the inherent uncertainty of the
restoration problem and show that attaining perfect perceptual quality entails
at least twice this uncertainty. Additionally, we establish a relation between
distortion, uncertainty and perception, through which we prove the
aforementioned uncertainly-perception tradeoff induces the well-known
perception-distortion tradeoff. We demonstrate our theoretical findings through
experiments with super-resolution and inpainting algorithms. This work uncovers
fundamental limitations of generative models in achieving both high perceptual
quality and reliable predictions for image restoration. Thus, we aim to raise
awareness among practitioners about this inherent tradeoff, empowering them to
make informed decisions and potentially prioritize safety over perceptual
performance.",2024-05-26,"Regev Cohen, Idan Kligvasser, Ehud Rivlin, Daniel Freedman",http://arxiv.org/pdf/2405.16475v3,cs.LG
Inaccurate Label Distribution Learning with Dependency Noise,"In this paper, we introduce the Dependent Noise-based Inaccurate Label
Distribution Learning (DN-ILDL) framework to tackle the challenges posed by
noise in label distribution learning, which arise from dependencies on
instances and labels. We start by modeling the inaccurate label distribution
matrix as a combination of the true label distribution and a noise matrix
influenced by specific instances and labels. To address this, we develop a
linear mapping from instances to their true label distributions, incorporating
label correlations, and decompose the noise matrix using feature and label
representations, applying group sparsity constraints to accurately capture the
noise. Furthermore, we employ graph regularization to align the topological
structures of the input and output spaces, ensuring accurate reconstruction of
the true label distribution matrix. Utilizing the Alternating Direction Method
of Multipliers (ADMM) for efficient optimization, we validate our method's
capability to recover true labels accurately and establish a generalization
error bound. Extensive experiments demonstrate that DN-ILDL effectively
addresses the ILDL problem and outperforms existing LDL methods.",2024-05-26,"Zhiqiang Kou, Jing Wang, Yuheng Jia, Xin Geng",http://arxiv.org/pdf/2405.16474v1,cs.LG
Multi-Level Additive Modeling for Structured Non-IID Federated Learning,"The primary challenge in Federated Learning (FL) is to model non-IID
distributions across clients, whose fine-grained structure is important to
improve knowledge sharing. For example, some knowledge is globally shared
across all clients, some is only transferable within a subgroup of clients, and
some are client-specific. To capture and exploit this structure, we train
models organized in a multi-level structure, called ``Multi-level Additive
Models (MAM)'', for better knowledge-sharing across heterogeneous clients and
their personalization. In federated MAM (FeMAM), each client is assigned to at
most one model per level and its personalized prediction sums up the outputs of
models assigned to it across all levels. For the top level, FeMAM trains one
global model shared by all clients as FedAvg. For every mid-level, it learns
multiple models each assigned to a subgroup of clients, as clustered FL. Every
bottom-level model is trained for one client only. In the training objective,
each model aims to minimize the residual of the additive predictions by the
other models assigned to each client. To approximate the arbitrary structure of
non-IID across clients, FeMAM introduces more flexibility and adaptivity to FL
by incrementally adding new models to the prediction of each client and
reassigning another if necessary, automatically optimizing the
knowledge-sharing structure. Extensive experiments show that FeMAM surpasses
existing clustered FL and personalized FL methods in various non-IID settings.
Our code is available at https://github.com/shutong043/FeMAM.",2024-05-26,"Shutong Chen, Tianyi Zhou, Guodong Long, Jie Ma, Jing Jiang, Chengqi Zhang",http://arxiv.org/pdf/2405.16472v1,cs.LG
Probabilistic Contrastive Learning with Explicit Concentration on the Hypersphere,"Self-supervised contrastive learning has predominantly adopted deterministic
methods, which are not suited for environments characterized by uncertainty and
noise. This paper introduces a new perspective on incorporating uncertainty
into contrastive learning by embedding representations within a spherical
space, inspired by the von Mises-Fisher distribution (vMF). We introduce an
unnormalized form of vMF and leverage the concentration parameter, kappa, as a
direct, interpretable measure to quantify uncertainty explicitly. This approach
not only provides a probabilistic interpretation of the embedding space but
also offers a method to calibrate model confidence against varying levels of
data corruption and characteristics. Our empirical results demonstrate that the
estimated concentration parameter correlates strongly with the degree of
unforeseen data corruption encountered at test time, enables failure analysis,
and enhances existing out-of-distribution detection methods.",2024-05-26,"Hongwei Bran Li, Cheng Ouyang, Tamaz Amiranashvili, Matthew S. Rosen, Bjoern Menze, Juan Eugenio Iglesias",http://arxiv.org/pdf/2405.16460v1,cs.LG
Predicting Rental Price of Lane Houses in Shanghai with Machine Learning Methods and Large Language Models,"Housing has emerged as a crucial concern among young individuals residing in
major cities, including Shanghai. Given the unprecedented surge in property
prices in this metropolis, young people have increasingly resorted to the
rental market to address their housing needs. This study utilizes five
traditional machine learning methods: multiple linear regression (MLR), ridge
regression (RR), lasso regression (LR), decision tree (DT), and random forest
(RF), along with a Large Language Model (LLM) approach using ChatGPT, for
predicting the rental prices of lane houses in Shanghai. It applies these
methods to examine a public data sample of about 2,609 lane house rental
transactions in 2021 in Shanghai, and then compares the results of these
methods. In terms of predictive power, RF has achieved the best performance
among the traditional methods. However, the LLM approach, particularly in the
10-shot scenario, shows promising results that surpass traditional methods in
terms of R-Squared value. The three performance metrics: mean squared error
(MSE), mean absolute error (MAE), and R-Squared, are used to evaluate the
models. Our conclusion is that while traditional machine learning models offer
robust techniques for rental price prediction, the integration of LLM such as
ChatGPT holds significant potential for enhancing predictive accuracy.",2024-05-26,"Tingting Chen, Shijing Si",http://arxiv.org/pdf/2405.17505v1,cs.LG
Dominant Shuffle: A Simple Yet Powerful Data Augmentation for Time-series Prediction,"Recent studies have suggested frequency-domain Data augmentation (DA) is
effec tive for time series prediction. Existing frequency-domain augmentations
disturb the original data with various full-spectrum noises, leading to excess
domain gap between augmented and original data. Although impressive performance
has been achieved in certain cases, frequency-domain DA has yet to be
generalized to time series prediction datasets. In this paper, we found that
frequency-domain augmentations can be significantly improved by two
modifications that limit the perturbations. First, we found that limiting the
perturbation to only dominant frequencies significantly outperforms
full-spectrum perturbations. Dominant fre quencies represent the main
periodicity and trends of the signal and are more important than other
frequencies. Second, we found that simply shuffling the dominant frequency
components is superior over sophisticated designed random perturbations.
Shuffle rearranges the original components (magnitudes and phases) and limits
the external noise. With these two modifications, we proposed dominant shuffle,
a simple yet effective data augmentation for time series prediction. Our method
is very simple yet powerful and can be implemented with just a few lines of
code. Extensive experiments with eight datasets and six popular time series
models demonstrate that our method consistently improves the baseline
performance under various settings and significantly outperforms other DA
methods. Code can be accessed at https://kaizhao.net/time-series.",2024-05-26,"Kai Zhao, Zuojie He, Alex Hung, Dan Zeng",http://arxiv.org/pdf/2405.16456v1,cs.LG
On the Algorithmic Bias of Aligning Large Language Models with RLHF: Preference Collapse and Matching Regularization,"Accurately aligning large language models (LLMs) with human preferences is
crucial for informing fair, economically sound, and statistically efficient
decision-making processes. However, we argue that reinforcement learning from
human feedback (RLHF) -- the predominant approach for aligning LLMs with human
preferences through a reward model -- suffers from an inherent algorithmic bias
due to its Kullback--Leibler-based regularization in optimization. In extreme
cases, this bias could lead to a phenomenon we term preference collapse, where
minority preferences are virtually disregarded. To mitigate this algorithmic
bias, we introduce preference matching (PM) RLHF, a novel approach that
provably aligns LLMs with the preference distribution of the reward model under
the Bradley--Terry--Luce/Plackett--Luce model. Central to our approach is a PM
regularizer that takes the form of the negative logarithm of the LLM's policy
probability distribution over responses, which helps the LLM balance response
diversification and reward maximization. Notably, we obtain this regularizer by
solving an ordinary differential equation that is necessary for the PM
property. For practical implementation, we introduce a conditional variant of
PM RLHF that is tailored to natural language generation. Finally, we
empirically validate the effectiveness of conditional PM RLHF through
experiments on the OPT-1.3B and Llama-2-7B models, demonstrating a 29% to 41%
improvement in alignment with human preferences, as measured by a certain
metric, compared to standard RLHF.",2024-05-26,"Jiancong Xiao, Ziniu Li, Xingyu Xie, Emily Getzen, Cong Fang, Qi Long, Weijie J. Su",http://arxiv.org/pdf/2405.16455v1,cs.LG
A Slices Perspective for Incremental Nonparametric Inference in High Dimensional State Spaces,"We introduce an innovative method for incremental nonparametric probabilistic
inference in high-dimensional state spaces. Our approach leverages \slices from
high-dimensional surfaces to efficiently approximate posterior distributions of
any shape. Unlike many existing graph-based methods, our \slices perspective
eliminates the need for additional intermediate reconstructions, maintaining a
more accurate representation of posterior distributions. Additionally, we
propose a novel heuristic to balance between accuracy and efficiency, enabling
real-time operation in nonparametric scenarios. In empirical evaluations on
synthetic and real-world datasets, our \slices approach consistently
outperforms other state-of-the-art methods. It demonstrates superior accuracy
and achieves a significant reduction in computational complexity, often by an
order of magnitude.",2024-05-26,"Moshe Shienman, Ohad Levy-Or, Michael Kaess, Vadim Indelman",http://arxiv.org/pdf/2405.16453v1,cs.LG
Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search,"Programmatic reinforcement learning (PRL) has been explored for representing
policies through programs as a means to achieve interpretability and
generalization. Despite promising outcomes, current state-of-the-art PRL
methods are hindered by sample inefficiency, necessitating tens of millions of
program-environment interactions. To tackle this challenge, we introduce a
novel LLM-guided search framework (LLM-GS). Our key insight is to leverage the
programming expertise and common sense reasoning of LLMs to enhance the
efficiency of assumption-free, random-guessing search methods. We address the
challenge of LLMs' inability to generate precise and grammatically correct
programs in domain-specific languages (DSLs) by proposing a Pythonic-DSL
strategy - an LLM is instructed to initially generate Python codes and then
convert them into DSL programs. To further optimize the LLM-generated programs,
we develop a search algorithm named Scheduled Hill Climbing, designed to
efficiently explore the programmatic search space to improve the programs
consistently. Experimental results in the Karel domain demonstrate our LLM-GS
framework's superior effectiveness and efficiency. Extensive ablation studies
further verify the critical role of our Pythonic-DSL strategy and Scheduled
Hill Climbing algorithm. Moreover, we conduct experiments with two novel tasks,
showing that LLM-GS enables users without programming skills and knowledge of
the domain or DSL to describe the tasks in natural language to obtain
performant programs.",2024-05-26,"Max Liu, Chan-Hung Yu, Wei-Hsu Lee, Cheng-Wei Hung, Yen-Chun Chen, Shao-Hua Sun",http://arxiv.org/pdf/2405.16450v3,cs.LG
"Reinforcement Learning for Jump-Diffusions, with Financial Applications","We study continuous-time reinforcement learning (RL) for stochastic control
in which system dynamics are governed by jump-diffusion processes. We formulate
an entropy-regularized exploratory control problem with stochastic policies to
capture the exploration--exploitation balance essential for RL. Unlike the pure
diffusion case initially studied by Wang et al. (2020), the derivation of the
exploratory dynamics under jump-diffusions calls for a careful formulation of
the jump part. Through a theoretical analysis, we find that one can simply use
the same policy evaluation and $q$-learning algorithms in Jia and Zhou (2022a,
2023), originally developed for controlled diffusions, without needing to check
a priori whether the underlying data come from a pure diffusion or a
jump-diffusion. However, we show that the presence of jumps ought to affect
parameterizations of actors and critics in general. We investigate as an
application the mean--variance portfolio selection problem with stock price
modelled as a jump-diffusion, and show that both RL algorithms and
parameterizations are invariant with respect to jumps. Finally, we present a
detailed study on applying the general theory to option hedging.",2024-05-26,"Xuefeng Gao, Lingfei Li, Xun Yu Zhou",http://arxiv.org/pdf/2405.16449v3,cs.LG
Fast Asymmetric Factorization for Large Scale Multiple Kernel Clustering,"Kernel methods are extensively employed for nonlinear data clustering, yet
their effectiveness heavily relies on selecting suitable kernels and associated
parameters, posing challenges in advance determination. In response, Multiple
Kernel Clustering (MKC) has emerged as a solution, allowing the fusion of
information from multiple base kernels for clustering. However, both early
fusion and late fusion methods for large-scale MKC encounter challenges in
memory and time constraints, necessitating simultaneous optimization of both
aspects. To address this issue, we propose Efficient Multiple Kernel Concept
Factorization (EMKCF), which constructs a new sparse kernel matrix inspired by
local regression to achieve memory efficiency. EMKCF learns consensus and
individual representations by extending orthogonal concept factorization to
handle multiple kernels for time efficiency. Experimental results demonstrate
the efficiency and effectiveness of EMKCF on benchmark datasets compared to
state-of-the-art methods. The proposed method offers a straightforward,
scalable, and effective solution for large-scale MKC tasks.",2024-05-26,"Yan Chen, Liang Du, Lei Duan",http://arxiv.org/pdf/2405.16447v1,cs.LG
CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion,"Large language models (LLMs) often incorporate multiple text chunks in their
inputs to provide the necessary contexts. To speed up the prefill of the long
LLM inputs, one can pre-compute the KV cache of a text and re-use the KV cache
when the context is reused as the prefix of another LLM input. However, the
reused text chunks are not always the input prefix, which makes precomputed KV
caches not directly usable since they ignore the text's cross-attention with
the preceding texts. Thus, the benefits of reusing KV caches remain largely
unrealized.
  This paper tackles just one challenge: when an LLM input contains multiple
text chunks, how to quickly combine their precomputed KV caches in order to
achieve the same generation quality as the expensive full prefill (i.e.,
without reusing KV cache)? This challenge naturally arises in
retrieval-augmented generation (RAG) where the input is supplemented with
multiple retrieved texts as the context. We present CacheBlend, a scheme that
reuses the precomputed KV caches, regardless prefix or not, and selectively
recomputes the KV values of a small subset of tokens to partially update each
reused KV cache. In the meantime, the small extra delay for recomputing some
tokens can be pipelined with the retrieval of KV caches within the same job,
allowing CacheBlend to store KV caches in slower devices with more storage
capacity while retrieving them without increasing the inference delay. By
comparing CacheBlend with the state-of-the-art KV cache reusing schemes on
three open-source LLMs of various sizes and four popular benchmark datasets of
different tasks, we show that CacheBlend reduces time-to-first-token (TTFT) by
2.2-3.3x and increases the inference throughput by 2.8-5x from full KV
recompute without compromising generation quality. The code is available at
https://github.com/LMCache/LMCache.",2024-05-26,"Jiayi Yao, Hanchen Li, Yuhan Liu, Siddhant Ray, Yihua Cheng, Qizheng Zhang, Kuntai Du, Shan Lu, Junchen Jiang",http://arxiv.org/pdf/2405.16444v3,cs.LG
Categorical Flow Matching on Statistical Manifolds,"We introduce Statistical Flow Matching (SFM), a novel and mathematically
rigorous flow-matching framework on the manifold of parameterized probability
measures inspired by the results from information geometry. We demonstrate the
effectiveness of our method on the discrete generation problem by instantiating
SFM on the manifold of categorical distributions whose geometric properties
remain unexplored in previous discrete generative models. Utilizing the Fisher
information metric, we equip the manifold with a Riemannian structure whose
intrinsic geometries are effectively leveraged by following the shortest paths
of geodesics. We develop an efficient training and sampling algorithm that
overcomes numerical stability issues with a diffeomorphism between manifolds.
Our distinctive geometric perspective of statistical manifolds allows us to
apply optimal transport during training and interpret SFM as following the
steepest direction of the natural gradient. Unlike previous models that rely on
variational bounds for likelihood estimation, SFM enjoys the exact likelihood
calculation for arbitrary probability measures. We manifest that SFM can learn
more complex patterns on the statistical manifold where existing models often
fail due to strong prior assumptions. Comprehensive experiments on real-world
generative tasks ranging from image, text to biological domains further
demonstrate that SFM achieves higher sampling quality and likelihood than other
discrete diffusion or flow-based models.",2024-05-26,"Chaoran Cheng, Jiahan Li, Jian Peng, Ge Liu",http://arxiv.org/pdf/2405.16441v3,cs.LG
MambaTS: Improved Selective State Space Models for Long-term Time Series Forecasting,"In recent years, Transformers have become the de-facto architecture for
long-term sequence forecasting (LTSF), but faces challenges such as quadratic
complexity and permutation invariant bias. A recent model, Mamba, based on
selective state space models (SSMs), has emerged as a competitive alternative
to Transformer, offering comparable performance with higher throughput and
linear complexity related to sequence length. In this study, we analyze the
limitations of current Mamba in LTSF and propose four targeted improvements,
leading to MambaTS. We first introduce variable scan along time to arrange the
historical information of all the variables together. We suggest that causal
convolution in Mamba is not necessary for LTSF and propose the Temporal Mamba
Block (TMB). We further incorporate a dropout mechanism for selective
parameters of TMB to mitigate model overfitting. Moreover, we tackle the issue
of variable scan order sensitivity by introducing variable permutation
training. We further propose variable-aware scan along time to dynamically
discover variable relationships during training and decode the optimal variable
scan order by solving the shortest path visiting all nodes problem during
inference. Extensive experiments conducted on eight public datasets demonstrate
that MambaTS achieves new state-of-the-art performance.",2024-05-26,"Xiuding Cai, Yaoyao Zhu, Xueyao Wang, Yu Yao",http://arxiv.org/pdf/2405.16440v1,cs.LG
Multi-Agent Inverse Reinforcement Learning in Real World Unstructured Pedestrian Crowds,"Social robot navigation in crowded public spaces such as university campuses,
restaurants, grocery stores, and hospitals, is an increasingly important area
of research. One of the core strategies for achieving this goal is to
understand humans' intent--underlying psychological factors that govern their
motion--by learning their reward functions, typically via inverse reinforcement
learning (IRL). Despite significant progress in IRL, learning reward functions
of multiple agents simultaneously in dense unstructured pedestrian crowds has
remained intractable due to the nature of the tightly coupled social
interactions that occur in these scenarios \textit{e.g.} passing,
intersections, swerving, weaving, etc. In this paper, we present a new
multi-agent maximum entropy inverse reinforcement learning algorithm for real
world unstructured pedestrian crowds. Key to our approach is a simple, but
effective, mathematical trick which we name the so-called
tractability-rationality trade-off trick that achieves tractability at the cost
of a slight reduction in accuracy. We compare our approach to the classical
single-agent MaxEnt IRL as well as state-of-the-art trajectory prediction
methods on several datasets including the ETH, UCY, SCAND, JRDB, and a new
dataset, called Speedway, collected at a busy intersection on a University
campus focusing on dense, complex agent interactions. Our key findings show
that, on the dense Speedway dataset, our approach ranks 1st among top 7
baselines with >2X improvement over single-agent IRL, and is competitive with
state-of-the-art large transformer-based encoder-decoder models on sparser
datasets such as ETH/UCY (ranks 3rd among top 7 baselines).",2024-05-26,"Rohan Chandra, Haresh Karnan, Negar Mehr, Peter Stone, Joydeep Biswas",http://arxiv.org/pdf/2405.16439v3,cs.LG
Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer,"Aligning generative models with human preference via RLHF typically suffers
from overoptimization, where an imperfectly learned reward model can misguide
the generative model to output undesired responses. We investigate this problem
in a principled manner by identifying the source of the misalignment as a form
of distributional shift and uncertainty in learning human preferences. To
mitigate overoptimization, we first propose a theoretical algorithm that
chooses the best policy for an adversarially chosen reward model; one that
simultaneously minimizes the maximum likelihood estimation of the loss and a
reward penalty term. Here, the reward penalty term is introduced to prevent the
policy from choosing actions with spurious high proxy rewards, resulting in
provable sample efficiency of the algorithm under a partial coverage style
condition. Moving from theory to practice, the proposed algorithm further
enjoys an equivalent but surprisingly easy-to-implement reformulation. Using
the equivalence between reward models and the corresponding optimal policy, the
algorithm features a simple objective that combines: (i) a preference
optimization loss that directly aligns the policy with human preference, and
(ii) a supervised learning loss that explicitly imitates the policy with a
(suitable) baseline distribution. In the context of aligning large language
models (LLM), this objective fuses the direct preference optimization (DPO)
loss with the supervised fine-tuning (SFT) loss to help mitigate the
overoptimization towards undesired responses, for which we name the algorithm
Regularized Preference Optimization (RPO). Experiments of aligning LLMs
demonstrate the improved performance of RPO compared with DPO baselines. Our
work sheds light on the interplay between preference optimization and SFT in
tuning LLMs with both theoretical guarantees and empirical evidence.",2024-05-26,"Zhihan Liu, Miao Lu, Shenao Zhang, Boyi Liu, Hongyi Guo, Yingxiang Yang, Jose Blanchet, Zhaoran Wang",http://arxiv.org/pdf/2405.16436v3,cs.LG
"Node Identifiers: Compact, Discrete Representations for Efficient Graph Learning","We present a novel end-to-end framework that generates highly compact
(typically 6-15 dimensions), discrete (int4 type), and interpretable node
representations, termed node identifiers (node IDs), to tackle inference
challenges on large-scale graphs. By employing vector quantization, we compress
continuous node embeddings from multiple layers of a Graph Neural Network (GNN)
into discrete codes, applicable under both self-supervised and supervised
learning paradigms. These node IDs capture high-level abstractions of graph
data and offer interpretability that traditional GNN embeddings lack. Extensive
experiments on 34 datasets, encompassing node classification, graph
classification, link prediction, and attributed graph clustering tasks,
demonstrate that the generated node IDs significantly enhance speed and memory
efficiency while achieving competitive performance compared to current
state-of-the-art methods.",2024-05-26,"Yuankai Luo, Hongkang Li, Qijiong Liu, Lei Shi, Xiao-Ming Wu",http://arxiv.org/pdf/2405.16435v2,cs.LG
Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making,"With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.",2024-05-26,"Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah",http://arxiv.org/pdf/2405.16424v1,cs.LG
AI-Generated Text Detection and Classification Based on BERT Deep Learning Algorithm,"AI-generated text detection plays an increasingly important role in various
fields. In this study, we developed an efficient AI-generated text detection
model based on the BERT algorithm, which provides new ideas and methods for
solving related problems. In the data preprocessing stage, a series of steps
were taken to process the text, including operations such as converting to
lowercase, word splitting, removing stop words, stemming extraction, removing
digits, and eliminating redundant spaces, to ensure data quality and accuracy.
By dividing the dataset into a training set and a test set in the ratio of 60%
and 40%, and observing the changes in the accuracy and loss values during the
training process, we found that the model performed well during the training
process. The accuracy increases steadily from the initial 94.78% to 99.72%,
while the loss value decreases from 0.261 to 0.021 and converges gradually,
which indicates that the BERT model is able to detect AI-generated text with
high accuracy and the prediction results are gradually approaching the real
classification results. Further analysis of the results of the training and
test sets reveals that in terms of loss value, the average loss of the training
set is 0.0565, while the average loss of the test set is 0.0917, showing a
slightly higher loss value. As for the accuracy, the average accuracy of the
training set reaches 98.1%, while the average accuracy of the test set is
97.71%, which is not much different from each other, indicating that the model
has good generalisation ability. In conclusion, the AI-generated text detection
model based on the BERT algorithm proposed in this study shows high accuracy
and stability in experiments, providing an effective solution for related
fields.",2024-05-26,"Hao Wang, Jianwei Li, Zhengyu Li",http://arxiv.org/pdf/2405.16422v1,cs.LG
Unraveling the Smoothness Properties of Diffusion Models: A Gaussian Mixture Perspective,"Diffusion models have made rapid progress in generating high-quality samples
across various domains. However, a theoretical understanding of the Lipschitz
continuity and second momentum properties of the diffusion process is still
lacking. In this paper, we bridge this gap by providing a detailed examination
of these smoothness properties for the case where the target data distribution
is a mixture of Gaussians, which serves as a universal approximator for smooth
densities such as image data. We prove that if the target distribution is a
$k$-mixture of Gaussians, the density of the entire diffusion process will also
be a $k$-mixture of Gaussians. We then derive tight upper bounds on the
Lipschitz constant and second momentum that are independent of the number of
mixture components $k$. Finally, we apply our analysis to various diffusion
solvers, both SDE and ODE based, to establish concrete error guarantees in
terms of the total variation distance and KL divergence between the target and
learned distributions. Our results provide deeper theoretical insights into the
dynamics of the diffusion process under common data distributions.",2024-05-26,"Yingyu Liang, Zhenmei Shi, Zhao Song, Yufa Zhou",http://arxiv.org/pdf/2405.16418v2,cs.LG
Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach,"This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.",2024-05-26,"Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao",http://arxiv.org/pdf/2405.17502v1,cs.LG
Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models,"Alzheimer's disease (AD) is the fifth-leading cause of death among Americans
aged 65 and older. Screening and early detection of AD and related dementias
(ADRD) are critical for timely intervention and for identifying clinical trial
participants. The widespread adoption of electronic health records (EHRs)
offers an important resource for developing ADRD screening tools such as
machine learning based predictive models. Recent advancements in large language
models (LLMs) demonstrate their unprecedented capability of encoding knowledge
and performing reasoning, which offers them strong potential for enhancing risk
prediction. This paper proposes a novel pipeline that augments risk prediction
by leveraging the few-shot inference power of LLMs to make predictions on cases
where traditional supervised learning methods (SLs) may not excel.
Specifically, we develop a collaborative pipeline that combines SLs and LLMs
via a confidence-driven decision-making mechanism, leveraging the strengths of
SLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this
pipeline using a real-world EHR data warehouse from Oregon Health \& Science
University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients
and more than 20 million patient encounters. Our results show that our proposed
approach effectively combines the power of SLs and LLMs, offering significant
improvements in predictive performance. This advancement holds promise for
revolutionizing ADRD screening and early detection practices, with potential
implications for better strategies of patient management and thus improving
healthcare.",2024-05-26,"Jiankun Wang, Sumyeong Ahn, Taykhoom Dalal, Xiaodan Zhang, Weishen Pan, Qiannan Zhang, Bin Chen, Hiroko H. Dodge, Fei Wang, Jiayu Zhou",http://arxiv.org/pdf/2405.16413v1,cs.LG
KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge,"Knowledge Graph Embedding (KGE) techniques are crucial in learning compact
representations of entities and relations within a knowledge graph,
facilitating efficient reasoning and knowledge discovery. While existing
methods typically focus either on training KGE models solely based on graph
structure or fine-tuning pre-trained language models with classification data
in KG, KG-FIT leverages LLM-guided refinement to construct a semantically
coherent hierarchical structure of entity clusters. By incorporating this
hierarchical knowledge along with textual information during the fine-tuning
process, KG-FIT effectively captures both global semantics from the LLM and
local semantics from the KG. Extensive experiments on the benchmark datasets
FB15K-237, YAGO3-10, and PrimeKG demonstrate the superiority of KG-FIT over
state-of-the-art pre-trained language model-based methods, achieving
improvements of 14.4%, 13.5%, and 11.9% in the Hits@10 metric for the link
prediction task, respectively. Furthermore, KG-FIT yields substantial
performance gains of 12.6%, 6.7%, and 17.7% compared to the structure-based
base models upon which it is built. These results highlight the effectiveness
of KG-FIT in incorporating open-world knowledge from LLMs to significantly
enhance the expressiveness and informativeness of KG embeddings.",2024-05-26,"Pengcheng Jiang, Lang Cao, Cao Xiao, Parminder Bhatia, Jimeng Sun, Jiawei Han",http://arxiv.org/pdf/2405.16412v3,cs.LG
Tensor Attention Training: Provably Efficient Learning of Higher-order Transformers,"Tensor Attention, a multi-view attention that is able to capture high-order
correlations among multiple modalities, can overcome the representational
limitations of classical matrix attention. However, the $O(n^3)$ time
complexity of tensor attention poses a significant obstacle to its utilization
in transformers, where $n$ is the input sequence length. In this work, we prove
that the backward gradient of tensor attention training can be computed in
almost linear time $n^{1+o(1)}$, the same complexity as its forward computation
under the bounded entries assumption. We provide a closed-form solution for the
gradient and propose a fast computation method utilizing polynomial
approximation methods and tensor algebraic techniques. Furthermore, we prove
the necessity and tightness of our assumption through hardness analysis,
showing that slightly weakening it renders the gradient problem unsolvable in
truly subcubic time. Our theoretical results establish the feasibility of
efficient higher-order transformer training and may facilitate practical
applications of tensor attention architectures.",2024-05-26,"Yingyu Liang, Zhenmei Shi, Zhao Song, Yufa Zhou",http://arxiv.org/pdf/2405.16411v2,cs.LG
Network Interdiction Goes Neural,"Network interdiction problems are combinatorial optimization problems
involving two players: one aims to solve an optimization problem on a network,
while the other seeks to modify the network to thwart the first player's
objectives. Such problems typically emerge in an attacker-defender context,
encompassing areas such as military operations, disease spread analysis, and
communication network management. The primary bottleneck in network
interdiction arises from the high time complexity of using conventional exact
solvers and the challenges associated with devising efficient heuristic
solvers. GNNs, recognized as a cutting-edge methodology, have shown significant
effectiveness in addressing single-level CO problems on graphs, such as the
traveling salesman problem, graph matching, and graph edit distance.
Nevertheless, network interdiction presents a bi-level optimization challenge,
which current GNNs find difficult to manage. To address this gap, we represent
network interdiction problems as Mixed-Integer Linear Programming (MILP)
instances, then apply a multipartite GNN with sufficient representational
capacity to learn these formulations. This approach ensures that our neural
network is more compatible with the mathematical algorithms designed to solve
network interdiction problems, resulting in improved generalization. Through
two distinct tasks, we demonstrate that our proposed method outperforms
theoretical baseline models and provides advantages over traditional exact
solvers.",2024-05-26,"Lei Zhang, Zhiqian Chen, Chang-Tien Lu, Liang Zhao",http://arxiv.org/pdf/2405.16409v1,cs.LG
Geometry of Critical Sets and Existence of Saddle Branches for Two-layer Neural Networks,"This paper presents a comprehensive analysis of critical point sets in
two-layer neural networks. To study such complex entities, we introduce the
critical embedding operator and critical reduction operator as our tools. Given
a critical point, we use these operators to uncover the whole underlying
critical set representing the same output function, which exhibits a
hierarchical structure. Furthermore, we prove existence of saddle branches for
any critical set whose output function can be represented by a narrower
network. Our results provide a solid foundation to the further study of
optimization and training behavior of neural networks.",2024-05-26,"Leyang Zhang, Yaoyu Zhang, Tao Luo",http://arxiv.org/pdf/2405.17501v1,cs.LG
SpinQuant: LLM quantization with learned rotations,"Post-training quantization (PTQ) techniques applied to weights, activations,
and the KV cache greatly reduce memory usage, latency, and power consumption of
Large Language Models (LLMs), but may lead to large quantization errors when
outliers are present. Rotating activation or weight matrices helps remove
outliers and benefits quantization. In this work, we identify a collection of
applicable rotation parameterizations that lead to identical outputs in
full-precision Transformer architectures while enhancing quantization accuracy.
In addition, we find that some random rotations lead to much better
quantization than others, with an up to 13 points difference in downstream
zero-shot reasoning performance. As a result, we propose SpinQuant, a novel
approach that incorporates learned rotation matrices for optimal quantized
network accuracy. With 4-bit quantization of weight, activation, and KV-cache,
SpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full
precision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by
19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also
outperforms concurrent work QuaRot, which applies random rotations to remove
outliers. In particular, for LLaMA-3 8B models that are hard to quantize,
SpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.
Code is available at https://github.com/facebookresearch/SpinQuant.",2024-05-26,"Zechun Liu, Changsheng Zhao, Igor Fedorov, Bilge Soran, Dhruv Choudhary, Raghuraman Krishnamoorthi, Vikas Chandra, Yuandong Tian, Tijmen Blankevoort",http://arxiv.org/pdf/2405.16406v4,cs.LG
Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level,"Graph Neural Networks (GNNs) excel across various applications but remain
vulnerable to adversarial attacks, particularly Graph Injection Attacks (GIAs),
which inject malicious nodes into the original graph and pose realistic
threats. Text-attributed graphs (TAGs), where nodes are associated with textual
features, are crucial due to their prevalence in real-world applications and
are commonly used to evaluate these vulnerabilities. However, existing research
only focuses on embedding-level GIAs, which inject node embeddings rather than
actual textual content, limiting their applicability and simplifying detection.
In this paper, we pioneer the exploration of GIAs at the text level, presenting
three novel attack designs that inject textual content into the graph. Through
theoretical and empirical analysis, we demonstrate that text interpretability,
a factor previously overlooked at the embedding level, plays a crucial role in
attack strength. Among the designs we investigate, the Word-frequency-based
Text-level GIA (WTGIA) is particularly notable for its balance between
performance and interpretability. Despite the success of WTGIA, we discover
that defenders can easily enhance their defenses with customized text embedding
methods or large language model (LLM)--based predictors. These insights
underscore the necessity for further research into the potential and practical
significance of text-level GIAs.",2024-05-26,"Runlin Lei, Yuwei Hu, Yuchen Ren, Zhewei Wei",http://arxiv.org/pdf/2405.16405v2,cs.LG
Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning,"Vision transformers have established a precedent of patchifying images into
uniformly-sized chunks before processing. We hypothesize that this design
choice may limit models in learning comprehensive and compositional
representations from visual data. This paper explores the notion of providing
semantically-meaningful visual tokens to transformer encoders within a
vision-language pre-training framework. Leveraging off-the-shelf segmentation
and scene-graph models, we extract representations of instance segmentation
masks (referred to as tangible tokens) and relationships and actions (referred
to as intangible tokens). Subsequently, we pre-train a vision-side transformer
by incorporating these newly extracted tokens and aligning the resultant
embeddings with caption embeddings from a text-side encoder. To capture the
structural and semantic relationships among visual tokens, we introduce
additive attention weights, which are used to compute self-attention scores.
Our experiments on COCO demonstrate notable improvements over ViTs in learned
representation quality across text-to-image (+47%) and image-to-text retrieval
(+44%) tasks. Furthermore, we showcase the advantages on compositionality
benchmarks such as ARO (+18%) and Winoground (+10%).",2024-05-26,"Neha Kalibhat, Priyatham Kattakinda, Sumit Nawathe, Arman Zarei, Nikita Seleznev, Samuel Sharpe, Senthil Kumar, Soheil Feizi",http://arxiv.org/pdf/2405.16401v2,cs.LG
AdaFisher: Adaptive Second Order Optimization via Fisher Information,"First-order optimization methods are currently the mainstream in training
deep neural networks (DNNs). Optimizers like Adam incorporate limited curvature
information by employing the diagonal matrix preconditioning of the stochastic
gradient during the training. Despite their widespread, second-order
optimization algorithms exhibit superior convergence properties compared to
their first-order counterparts e.g. Adam and SGD. However, their practicality
in training DNNs is still limited due to increased per-iteration computations
compared to the first-order methods. We present \emph{AdaFisher}--an adaptive
second-order optimizer that leverages a \emph{diagonal block-Kronecker}
approximation of the Fisher information matrix for adaptive gradient
preconditioning. AdaFisher aims to bridge the gap between enhanced
\emph{convergence/generalization} capabilities and computational efficiency in
second-order optimization framework for training DNNs. Despite the slow pace of
second-order optimizers, we showcase that AdaFisher can be reliably adopted for
image classification, language modeling and stands out for its stability and
robustness in hyper-parameter tuning. We demonstrate that AdaFisher
\textbf{outperforms the SOTA optimizers} in terms of both accuracy and
convergence speed. Code is available from
https://github.com/AtlasAnalyticsLab/AdaFisher.",2024-05-26,"Damien Martins Gomes, Yanlei Zhang, Eugene Belilovsky, Guy Wolf, Mahdi S. Hosseini",http://arxiv.org/pdf/2405.16397v3,cs.LG
Machine learning in business process management: A systematic literature review,"Machine learning (ML) provides algorithms to create computer programs based
on data without explicitly programming them. In business process management
(BPM), ML applications are used to analyse and improve processes efficiently.
Three frequent examples of using ML are providing decision support through
predictions, discovering accurate process models, and improving resource
allocation. This paper organises the body of knowledge on ML in BPM. We extract
BPM tasks from different literature streams, summarise them under the phases of
a process`s lifecycle, explain how ML helps perform these tasks and identify
technical commonalities in ML implementations across tasks. This study is the
first exhaustive review of how ML has been used in BPM. We hope that it can
open the door for a new era of cumulative research by helping researchers to
identify relevant preliminary work and then combine and further develop
existing approaches in a focused fashion. Our paper helps managers and
consultants to find ML applications that are relevant in the current project
phase of a BPM initiative, like redesigning a business process. We also offer -
as a synthesis of our review - a research agenda that spreads ten avenues for
future research, including applying novel ML concepts like federated learning,
addressing less regarded BPM lifecycle phases like process identification, and
delivering ML applications with a focus on end-users.",2024-05-26,"Sven Weinzierl, Sandra Zilker, Sebastian Dunzer, Martin Matzner",http://arxiv.org/pdf/2405.16396v1,cs.LG
Daily Physical Activity Monitoring -- Adaptive Learning from Multi-source Motion Sensor Data,"In healthcare applications, there is a growing need to develop machine
learning models that use data from a single source, such as that from a wrist
wearable device, to monitor physical activities, assess health risks, and
provide immediate health recommendations or interventions. However, the
limitation of using single-source data often compromises the model's accuracy,
as it fails to capture the full scope of human activities. While a more
comprehensive dataset can be gathered in a lab setting using multiple sensors
attached to various body parts, this approach is not practical for everyday use
due to the impracticality of wearing multiple sensors. To address this
challenge, we introduce a transfer learning framework that optimizes machine
learning models for everyday applications by leveraging multi-source data
collected in a laboratory setting. We introduce a novel metric to leverage the
inherent relationship between these multiple data sources, as they are all
paired to capture aspects of the same physical activity. Through numerical
experiments, our framework outperforms existing methods in classification
accuracy and robustness to noise, offering a promising avenue for the
enhancement of daily activity monitoring.",2024-05-26,"Haoting Zhang, Donglin Zhan, Yunduan Lin, Jinghai He, Qing Zhu, Zuo-Jun Max Shen, Zeyu Zheng",http://arxiv.org/pdf/2405.16395v1,cs.LG
When does compositional structure yield compositional generalization? A kernel theory,"Compositional generalization (the ability to respond correctly to novel
combinations of familiar components) is thought to be a cornerstone of
intelligent behavior. Compositionally structured (e.g. disentangled)
representations support this ability; however, the conditions under which they
are sufficient for the emergence of compositional generalization remain
unclear. To address this gap, we present a theory of compositional
generalization in kernel models with fixed, compositionally structured
representations. This provides a tractable framework for characterizing the
impact of training data statistics on generalization. We find that these models
are limited to functions that assign values to each combination of components
seen during training, and then sum up these values (""conjunction-wise
additivity""). This imposes fundamental restrictions on the set of tasks
compositionally structured kernel models can learn, in particular preventing
them from transitively generalizing equivalence relations. Even for
compositional tasks that they can learn in principle, we identify novel failure
modes in compositional generalization (memorization leak and shortcut bias)
that arise from biases in the training data. Finally, we empirically validate
our theory, showing that it captures the behavior of deep neural networks
(convolutional networks, residual networks, and Vision Transformers) trained on
a set of compositional tasks with similarly structured data. Ultimately, this
work examines how statistical structure in the training data can affect
compositional generalization, with implications for how to identify and remedy
failure modes in deep learning models.",2024-05-26,"Samuel Lippl, Kim Stachenfeld",http://arxiv.org/pdf/2405.16391v3,cs.LG
Safe and Balanced: A Framework for Constrained Multi-Objective Reinforcement Learning,"In numerous reinforcement learning (RL) problems involving safety-critical
systems, a key challenge lies in balancing multiple objectives while
simultaneously meeting all stringent safety constraints. To tackle this issue,
we propose a primal-based framework that orchestrates policy optimization
between multi-objective learning and constraint adherence. Our method employs a
novel natural policy gradient manipulation method to optimize multiple RL
objectives and overcome conflicting gradients between different tasks, since
the simple weighted average gradient direction may not be beneficial for
specific tasks' performance due to misaligned gradients of different task
objectives. When there is a violation of a hard constraint, our algorithm steps
in to rectify the policy to minimize this violation. We establish theoretical
convergence and constraint violation guarantees in a tabular setting.
Empirically, our proposed method also outperforms prior state-of-the-art
methods on challenging safe multi-objective reinforcement learning tasks.",2024-05-26,"Shangding Gu, Bilgehan Sel, Yuhao Ding, Lu Wang, Qingwei Lin, Alois Knoll, Ming Jin",http://arxiv.org/pdf/2405.16390v1,cs.LG
Multi-Reference Preference Optimization for Large Language Models,"How can Large Language Models (LLMs) be aligned with human intentions and
values? A typical solution is to gather human preference on model outputs and
finetune the LLMs accordingly while ensuring that updates do not deviate too
far from a reference model. Recent approaches, such as direct preference
optimization (DPO), have eliminated the need for unstable and sluggish
reinforcement learning optimization by introducing close-formed supervised
losses. However, a significant limitation of the current approach is its design
for a single reference model only, neglecting to leverage the collective power
of numerous pretrained LLMs. To overcome this limitation, we introduce a novel
closed-form formulation for direct preference optimization using multiple
reference models. The resulting algorithm, Multi-Reference Preference
Optimization (MRPO), leverages broader prior knowledge from diverse reference
models, substantially enhancing preference learning capabilities compared to
the single-reference DPO. Our experiments demonstrate that LLMs finetuned with
MRPO generalize better in various preference data, regardless of data scarcity
or abundance. Furthermore, MRPO effectively finetunes LLMs to exhibit superior
performance in several downstream natural language processing tasks such as
GSM8K and TruthfulQA.",2024-05-26,"Hung Le, Quan Tran, Dung Nguyen, Kien Do, Saloni Mittal, Kelechi Ogueji, Svetha Venkatesh",http://arxiv.org/pdf/2405.16388v1,cs.LG
Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference,"To generate data from trained diffusion models, most inference algorithms,
such as DDPM, DDIM, and other variants, rely on discretizing the reverse SDEs
or their equivalent ODEs. In this paper, we view such approaches as decomposing
the entire denoising diffusion process into several segments, each
corresponding to a reverse transition kernel (RTK) sampling subproblem.
Specifically, DDPM uses a Gaussian approximation for the RTK, resulting in low
per-subproblem complexity but requiring a large number of segments (i.e.,
subproblems), which is conjectured to be inefficient. To address this, we
develop a general RTK framework that enables a more balanced subproblem
decomposition, resulting in $\tilde O(1)$ subproblems, each with strongly
log-concave targets. We then propose leveraging two fast sampling algorithms,
the Metropolis-Adjusted Langevin Algorithm (MALA) and Underdamped Langevin
Dynamics (ULD), for solving these strongly log-concave subproblems. This gives
rise to the RTK-MALA and RTK-ULD algorithms for diffusion inference. In theory,
we further develop the convergence guarantees for RTK-MALA and RTK-ULD in total
variation (TV) distance: RTK-ULD can achieve $\epsilon$ target error within
$\tilde{\mathcal O}(d^{1/2}\epsilon^{-1})$ under mild conditions, and RTK-MALA
enjoys a $\mathcal{O}(d^{2}\log(d/\epsilon))$ convergence rate under slightly
stricter conditions. These theoretical results surpass the state-of-the-art
convergence rates for diffusion inference and are well supported by numerical
experiments.",2024-05-26,"Xunpeng Huang, Difan Zou, Hanze Dong, Yi Zhang, Yi-An Ma, Tong Zhang",http://arxiv.org/pdf/2405.16387v1,cs.LG
Variational Offline Multi-agent Skill Discovery,"Skills are effective temporal abstractions established for sequential
decision making, which enable efficient hierarchical learning for long-horizon
tasks and facilitate multi-task learning through their transferability. Despite
extensive research, research gaps remain in multi-agent scenarios, particularly
for automatically extracting subgroup coordination patterns in a multi-agent
task. In this case, we propose two novel auto-encoder schemes: VO-MASD-3D and
VO-MASD-Hier, to simultaneously capture subgroup- and temporal-level
abstractions and form multi-agent skills, which firstly solves the
aforementioned challenge. An essential algorithm component of these schemes is
a dynamic grouping function that can automatically detect latent subgroups
based on agent interactions in a task. Further, our method can be applied to
offline multi-task data, and the discovered subgroup skills can be transferred
across relevant tasks without retraining. Empirical evaluations on StarCraft
tasks indicate that our approach significantly outperforms existing
hierarchical multi-agent reinforcement learning (MARL) methods. Moreover,
skills discovered using our method can effectively reduce the learning
difficulty in MARL scenarios with delayed and sparse reward signals. The
codebase is available at https://github.com/LucasCJYSDL/VOMASD.",2024-05-26,"Jiayu Chen, Tian Lan, Vaneet Aggarwal",http://arxiv.org/pdf/2405.16386v3,cs.LG
Rewarded Region Replay (R3) for Policy Learning with Discrete Action Space,"We introduce a new on-policy algorithm called Rewarded Region Replay (R3),
which significantly improves on PPO in solving environments with discrete
action spaces. R3 improves sample efficiency by using a replay buffer which
contains past successful trajectories with reward above a certain threshold,
which are used to update a PPO agent with importance sampling. Crucially, we
discard the importance sampling factors which are above a certain ratio to
reduce variance and stabilize training. We found that R3 significantly
outperforms PPO in Minigrid environments with sparse rewards and discrete
action space, such as DoorKeyEnv and CrossingEnv, and moreover we found that
the improvement margin of our method versus baseline PPO increases with the
complexity of the environment. We also benchmarked the performance of R3
against DDQN (Double Deep Q-Network), which is a standard baseline in
off-policy methods for discrete actions, and found that R3 also outperforms
DDQN agent in DoorKeyEnv. Lastly, we adapt the idea of R3 to dense reward
setting to obtain the Dense R3 algorithm (or DR3) and benchmarked it against
PPO on Cartpole-V1 environment. We found that DR3 outperforms PPO significantly
on this dense reward environment. Our code can be found at
https://github.com/chry-santhemum/R3.",2024-05-26,"Bangzheng Li, Ningshan Ma, Zifan Wang",http://arxiv.org/pdf/2405.16383v1,cs.LG
Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups,"The generative modeling of data on manifolds is an important task, for which
diffusion models in flat spaces typically need nontrivial adaptations. This
article demonstrates how a technique called `trivialization' can transfer the
effectiveness of diffusion models in Euclidean spaces to Lie groups. In
particular, an auxiliary momentum variable was algorithmically introduced to
help transport the position variable between data distribution and a fixed,
easy-to-sample distribution. Normally, this would incur further difficulty for
manifold data because momentum lives in a space that changes with the position.
However, our trivialization technique creates a new momentum variable that
stays in a simple fixed vector space. This design, together with a manifold
preserving integrator, simplifies implementation and avoids inaccuracies
created by approximations such as projections to tangent space and manifold,
which were typically used in prior work, hence facilitating generation with
high-fidelity and efficiency. The resulting method achieves state-of-the-art
performance on protein and RNA torsion angle generation and sophisticated torus
datasets. We also, arguably for the first time, tackle the generation of data
on high-dimensional Special Orthogonal and Unitary groups, the latter essential
for quantum problems. Code is available at
https://github.com/yuchen-zhu-zyc/TDM.",2024-05-25,"Yuchen Zhu, Tianrong Chen, Lingkai Kong, Evangelos A. Theodorou, Molei Tao",http://arxiv.org/pdf/2405.16381v2,cs.LG
Dynamic Inhomogeneous Quantum Resource Scheduling with Reinforcement Learning,"A central challenge in quantum information science and technology is
achieving real-time estimation and feedforward control of quantum systems. This
challenge is compounded by the inherent inhomogeneity of quantum resources,
such as qubit properties and controls, and their intrinsically probabilistic
nature. This leads to stochastic challenges in error detection and
probabilistic outcomes in processes such as heralded remote entanglement. Given
these complexities, optimizing the construction of quantum resource states is
an NP-hard problem. In this paper, we address the quantum resource scheduling
issue by formulating the problem and simulating it within a digitized
environment, allowing the exploration and development of agent-based
optimization strategies. We employ reinforcement learning agents within this
probabilistic setting and introduce a new framework utilizing a Transformer
model that emphasizes self-attention mechanisms for pairs of qubits. This
approach facilitates dynamic scheduling by providing real-time, next-step
guidance. Our method significantly improves the performance of quantum systems,
achieving more than a 3$\times$ improvement over rule-based agents, and
establishes an innovative framework that improves the joint design of physical
and control systems for quantum applications in communication, networking, and
computing.",2024-05-25,"Linsen Li, Pratyush Anand, Kaiming He, Dirk Englund",http://arxiv.org/pdf/2405.16380v1,cs.LG
Qsco: A Quantum Scoring Module for Open-set Supervised Anomaly Detection,"Open set anomaly detection (OSAD) is a crucial task that aims to identify
abnormal patterns or behaviors in data sets, especially when the anomalies
observed during training do not represent all possible classes of anomalies.
The recent advances in quantum computing in handling complex data structures
and improving machine learning models herald a paradigm shift in anomaly
detection methodologies. This study proposes a Quantum Scoring Module (Qsco),
embedding quantum variational circuits into neural networks to enhance the
model's processing capabilities in handling uncertainty and unlabeled data.
Extensive experiments conducted across eight real-world anomaly detection
datasets demonstrate our model's superior performance in detecting anomalies
across varied settings and reveal that integrating quantum simulators does not
result in prohibitive time complexities. Our study validates the feasibility of
quantum-enhanced anomaly detection methods in practical applications.",2024-05-25,"Yifeng Peng, Xinyi Li, Zhiding Liang, Ying Wang",http://arxiv.org/pdf/2405.16368v2,cs.LG
Noisy Data Meets Privacy: Training Local Models with Post-Processed Remote Queries,"The adoption of large cloud-based models for inference in privacy-sensitive
domains, such as homeless care systems and medical imaging, raises concerns
about end-user data privacy. A common solution is adding locally differentially
private (LDP) noise to queries before transmission, but this often reduces
utility. LDPKiT, which stands for Local Differentially-Private and
Utility-Preserving Inference via Knowledge Transfer, addresses the concern by
generating a privacy-preserving inference dataset aligned with the private data
distribution. This dataset is used to train a reliable local model for
inference on sensitive inputs. LDPKiT employs a two-layer noise injection
framework that leverages LDP and its post-processing property to create a
privacy-protected inference dataset. The first layer ensures privacy, while the
second layer helps to recover utility by creating a sufficiently large dataset
for subsequent local model extraction using noisy labels returned from a cloud
model on privacy-protected noisy inputs. Our experiments on Fashion-MNIST, SVHN
and PathMNIST medical datasets demonstrate that LDPKiT effectively improves
utility while preserving privacy. Moreover, the benefits of using LDPKiT
increase at higher, more privacy-protective noise levels. For instance, on
SVHN, LDPKiT achieves similar inference accuracy with $\epsilon=1.25$ as it
does with $\epsilon=2.0$, providing stronger privacy guarantees with less than
a 2% drop in accuracy. Furthermore, we perform extensive sensitivity analyses
to evaluate the impact of dataset sizes on LDPKiT's effectiveness and
systematically analyze the latent space representations to offer a theoretical
explanation for its accuracy improvements. Lastly, we qualitatively and
quantitatively demonstrate that the type of knowledge distillation performed by
LDPKiT is ethical and fundamentally distinct from adversarial model extraction
attacks.",2024-05-25,"Kexin Li, Aastha Mehta, David Lie",http://arxiv.org/pdf/2405.16361v2,cs.LG
A Differential Equation Approach for Wasserstein GANs and Beyond,"This paper proposes a new theoretical lens to view Wasserstein generative
adversarial networks (WGANs). To minimize the Wasserstein-1 distance between
the true data distribution and our estimate of it, we derive a
distribution-dependent ordinary differential equation (ODE) which represents
the gradient flow of the Wasserstein-1 loss, and show that a forward Euler
discretization of the ODE converges. This inspires a new class of generative
models that naturally integrates persistent training (which we call W1-FE).
When persistent training is turned off, we prove that W1-FE reduces to WGAN.
When we intensify persistent training, W1-FE is shown to outperform WGAN in
training experiments from low to high dimensions, in terms of both convergence
speed and training results. Intriguingly, one can reap the benefits only when
persistent training is carefully integrated through our ODE perspective. As
demonstrated numerically, a naive inclusion of persistent training in WGAN
(without relying on our ODE framework) can significantly worsen training
results.",2024-05-25,"Zachariah Malik, Yu-Jui Huang",http://arxiv.org/pdf/2405.16351v2,cs.LG
A Second-Order Perspective on Model Compositionality and Incremental Learning,"The fine-tuning of deep pre-trained models has revealed compositional
properties, with multiple specialized modules that can be arbitrarily composed
into a single, multi-task model. However, identifying the conditions that
promote compositionality remains an open issue, with recent efforts
concentrating mainly on linearized networks. We conduct a theoretical study
that attempts to demystify compositionality in standard non-linear networks
through the second-order Taylor approximation of the loss function. The
proposed formulation highlights the importance of staying within the
pre-training basin to achieve composable modules. Moreover, it provides the
basis for two dual incremental training algorithms: the one from the
perspective of multiple models trained individually, while the other aims to
optimize the composed model as a whole. We probe their application in
incremental classification tasks and highlight some valuable skills. In fact,
the pool of incrementally learned modules not only supports the creation of an
effective multi-task model but also enables unlearning and specialization in
certain tasks. Code available at https://github.com/aimagelab/mammoth.",2024-05-25,"Angelo Porrello, Lorenzo Bonicelli, Pietro Buzzega, Monica Millunzi, Simone Calderara, Rita Cucchiara",http://arxiv.org/pdf/2405.16350v3,cs.LG
BOLD: Boolean Logic Deep Learning,"Deep learning is computationally intensive, with significant efforts focused
on reducing arithmetic complexity, particularly regarding energy consumption
dominated by data movement. While existing literature emphasizes inference,
training is considerably more resource-intensive. This paper proposes a novel
mathematical principle by introducing the notion of Boolean variation such that
neurons made of Boolean weights and inputs can be trained -- for the first time
-- efficiently in Boolean domain using Boolean logic instead of gradient
descent and real arithmetic. We explore its convergence, conduct extensively
experimental benchmarking, and provide consistent complexity evaluation by
considering chip architecture, memory hierarchy, dataflow, and arithmetic
precision. Our approach achieves baseline full-precision accuracy in ImageNet
classification and surpasses state-of-the-art results in semantic segmentation,
with notable performance in image super-resolution, and natural language
understanding with transformer-based models. Moreover, it significantly reduces
energy consumption during both training and inference.",2024-05-25,"Van Minh Nguyen, Cristian Ocampo, Aymen Askri, Louis Leconte, Ba-Hien Tran",http://arxiv.org/pdf/2405.16339v1,cs.LG
RoboArm-NMP: a Learning Environment for Neural Motion Planning,"We present RoboArm-NMP, a learning and evaluation environment that allows
simple and thorough evaluations of Neural Motion Planning (NMP) algorithms,
focused on robotic manipulators. Our Python-based environment provides baseline
implementations for learning control policies (either supervised or
reinforcement learning based), a simulator based on PyBullet, data of solved
instances using a classical motion planning solver, various representation
learning methods for encoding the obstacles, and a clean interface between the
learning and planning frameworks. Using RoboArm-NMP, we compare several
prominent NMP design points, and demonstrate that the best methods mostly
succeed in generalizing to unseen goals in a scene with fixed obstacles, but
have difficulty in generalizing to unseen obstacle configurations, suggesting
focus points for future research.",2024-05-25,"Tom Jurgenson, Matan Sudry, Gal Avineri, Aviv Tamar",http://arxiv.org/pdf/2405.16335v1,cs.LG
SLoPe: Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining of LLMs,"We propose SLoPe, a Double-Pruned Sparse Plus Lazy Low-rank Adapter
Pretraining method for LLMs that improves the accuracy of sparse LLMs while
accelerating their pretraining and inference and reducing their memory
footprint. Sparse pretraining of LLMs reduces the accuracy of the model, to
overcome this, prior work uses dense models during fine-tuning. SLoPe improves
the accuracy of sparsely pretrained models by adding low-rank adapters in the
final 1% iterations of pretraining without adding significant overheads to the
model pretraining and inference. In addition, SLoPe uses a double-pruned
backward pass formulation that prunes the transposed weight matrix using N:M
sparsity structures to enable an accelerated sparse backward pass. SLoPe
accelerates the training and inference of models with billions of parameters up
to $1.25\times$ and $1.54\times$ respectively (OPT-33B and OPT-66B) while
reducing their memory usage by up to $0.63\times$ and $0.61\times$ for training
and inference respectively.",2024-05-25,"Mohammad Mozaffari, Amir Yazdanbakhsh, Zhao Zhang, Maryam Mehri Dehnavi",http://arxiv.org/pdf/2405.16325v3,cs.LG
Secure Hierarchical Federated Learning in Vehicular Networks Using Dynamic Client Selection and Anomaly Detection,"Hierarchical Federated Learning (HFL) faces the significant challenge of
adversarial or unreliable vehicles in vehicular networks, which can compromise
the model's integrity through misleading updates. Addressing this, our study
introduces a novel framework that integrates dynamic vehicle selection and
robust anomaly detection mechanisms, aiming to optimize participant selection
and mitigate risks associated with malicious contributions. Our approach
involves a comprehensive vehicle reliability assessment, considering historical
accuracy, contribution frequency, and anomaly records. An anomaly detection
algorithm is utilized to identify anomalous behavior by analyzing the cosine
similarity of local or model parameters during the federated learning (FL)
process. These anomaly records are then registered and combined with past
performance for accuracy and contribution frequency to identify the most
suitable vehicles for each learning round. Dynamic client selection and anomaly
detection algorithms are deployed at different levels, including cluster heads
(CHs), cluster members (CMs), and the Evolving Packet Core (EPC), to detect and
filter out spurious updates. Through simulation-based performance evaluation,
our proposed algorithm demonstrates remarkable resilience even under intense
attack conditions. Even in the worst-case scenarios, it achieves convergence
times at $63$\% as effective as those in scenarios without any attacks.
Conversely, in scenarios without utilizing our proposed algorithm, there is a
high likelihood of non-convergence in the FL process.",2024-05-25,"M. Saeid HaghighiFard, Sinem Coleri",http://arxiv.org/pdf/2405.17497v1,cs.LG
Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting,"State Space Models (SSMs) have emerged as a potent tool in sequence modeling
tasks in recent years. These models approximate continuous systems using a set
of basis functions and discretize them to handle input data, making them
well-suited for modeling time series data collected at specific frequencies
from continuous systems. Despite its potential, the application of SSMs in time
series forecasting remains underexplored, with most existing models treating
SSMs as a black box for capturing temporal or channel dependencies. To address
this gap, this paper proposes a novel theoretical framework termed Dynamic
Spectral Operator, offering more intuitive and general guidance on applying
SSMs to time series data. Building upon our theory, we introduce Time-SSM, a
novel SSM-based foundation model with only one-seventh of the parameters
compared to Mamba. Various experiments validate both our theoretical framework
and the superior performance of Time-SSM.",2024-05-25,"Jiaxi Hu, Disen Lan, Ziyu Zhou, Qingsong Wen, Yuxuan Liang",http://arxiv.org/pdf/2405.16312v2,cs.LG
Efficiently Parameterized Neural Metriplectic Systems,"Metriplectic systems are learned from data in a way that scales quadratically
in both the size of the state and the rank of the metriplectic data. Besides
being provably energy conserving and entropy stable, the proposed approach
comes with approximation results demonstrating its ability to accurately learn
metriplectic dynamics from data as well as an error estimate indicating its
potential for generalization to unseen timescales when approximation error is
low. Examples are provided which illustrate performance in the presence of both
full state information as well as when entropic variables are unknown,
confirming that the proposed approach exhibits superior accuracy and
scalability without compromising on model expressivity.",2024-05-25,"Anthony Gruber, Kookjin Lee, Haksoo Lim, Noseong Park, Nathaniel Trask",http://arxiv.org/pdf/2405.16305v3,cs.LG
Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients,"We address the problem of federated domain generalization in an unsupervised
setting for the first time. We first theoretically establish a connection
between domain shift and alignment of gradients in unsupervised federated
learning and show that aligning the gradients at both client and server levels
can facilitate the generalization of the model to new (target) domains.
Building on this insight, we propose a novel method named FedGaLA, which
performs gradient alignment at the client level to encourage clients to learn
domain-invariant features, as well as global gradient alignment at the server
to obtain a more generalized aggregated model. To empirically evaluate our
method, we perform various experiments on four commonly used multi-domain
datasets, PACS, OfficeHome, DomainNet, and TerraInc. The results demonstrate
the effectiveness of our method which outperforms comparable baselines.
Ablation and sensitivity studies demonstrate the impact of different components
and parameters in our approach. The source code is available at:
https://github.com/MahdiyarMM/FedGaLA.",2024-05-25,"Farhad Pourpanah, Mahdiyar Molahasani, Milad Soltany, Michael Greenspan, Ali Etemad",http://arxiv.org/pdf/2405.16304v2,cs.LG
Active Learning for Finely-Categorized Image-Text Retrieval by Selecting Hard Negative Unpaired Samples,"Securing a sufficient amount of paired data is important to train an
image-text retrieval (ITR) model, but collecting paired data is very expensive.
To address this issue, in this paper, we propose an active learning algorithm
for ITR that can collect paired data cost-efficiently. Previous studies assume
that image-text pairs are given and their category labels are asked to the
annotator. However, in the recent ITR studies, the importance of category label
is decreased since a retrieval model can be trained with only image-text pairs.
For this reason, we set up an active learning scenario where unpaired images
(or texts) are given and the annotator provides corresponding texts (or images)
to make paired data. The key idea of the proposed AL algorithm is to select
unpaired images (or texts) that can be hard negative samples for existing texts
(or images). To this end, we introduce a novel scoring function to choose hard
negative samples. We validate the effectiveness of the proposed method on
Flickr30K and MS-COCO datasets.",2024-05-25,"Dae Ung Jo, Kyuewang Lee, JaeHo Chung, Jin Young Choi",http://arxiv.org/pdf/2405.16301v1,cs.LG
LUCIE: A Lightweight Uncoupled ClImate Emulator with long-term stability and physical consistency for O(1000)-member ensembles,"We present a lightweight, easy-to-train, low-resolution, fully data-driven
climate emulator, LUCIE, that can be trained on as low as $2$ years of
$6$-hourly ERA5 data. Unlike most state-of-the-art AI weather models, LUCIE
remains stable and physically consistent for $100$ years of autoregressive
simulation with $100$ ensemble members. Long-term mean climatology from LUCIE's
simulation of temperature, wind, precipitation, and humidity matches that of
ERA5 data, along with the variability. We further demonstrate how well extreme
weather events and their return periods can be estimated from a large ensemble
of long-term simulations. We further discuss an improved training strategy with
a hard-constrained first-order integrator to suppress autoregressive error
growth, a novel spectral regularization strategy to better capture fine-scale
dynamics, and finally an optimization algorithm that enables data-limited (as
low as $2$ years of $6$-hourly data) training of the emulator without losing
stability and physical consistency. Finally, we provide a scaling experiment to
compare the long-term bias of LUCIE with respect to the number of training
samples. Importantly, LUCIE is an easy to use model that can be trained in just
$2.4$h on a single A-100 GPU, allowing for multiple experiments that can
explore important scientific questions that could be answered with large
ensembles of long-term simulations, e.g., the impact of different variables on
the simulation, dynamic response to external forcing, and estimation of extreme
weather events, amongst others.",2024-05-25,"Haiwen Guan, Troy Arcomano, Ashesh Chattopadhyay, Romit Maulik",http://arxiv.org/pdf/2405.16297v3,cs.LG
Comparative Analysis of Open-Source Language Models in Summarizing Medical Text Data,"Unstructured text in medical notes and dialogues contains rich information.
Recent advancements in Large Language Models (LLMs) have demonstrated superior
performance in question answering and summarization tasks on unstructured text
data, outperforming traditional text analysis approaches. However, there is a
lack of scientific studies in the literature that methodically evaluate and
report on the performance of different LLMs, specifically for domain-specific
data such as medical chart notes. We propose an evaluation approach to analyze
the performance of open-source LLMs such as Llama2 and Mistral for medical
summarization tasks, using GPT-4 as an assessor. Our innovative approach to
quantitative evaluation of LLMs can enable quality control, support the
selection of effective LLMs for specific tasks, and advance knowledge discovery
in digital health.",2024-05-25,"Yuhao Chen, Zhimu Wang, Bo Wen, Farhana Zulkernine",http://arxiv.org/pdf/2405.16295v3,cs.LG
"Vertical Federated Learning for Effectiveness, Security, Applicability: A Survey","Vertical Federated Learning (VFL) is a privacy-preserving distributed
learning paradigm where different parties collaboratively learn models using
partitioned features of shared samples, without leaking private data. Recent
research has shown promising results addressing various challenges in VFL,
highlighting its potential for practical applications in cross-domain
collaboration. However, the corresponding research is scattered and lacks
organization. To advance VFL research, this survey offers a systematic overview
of recent developments. First, we provide a history and background
introduction, along with a summary of the general training protocol of VFL. We
then revisit the taxonomy in recent reviews and analyze limitations in-depth.
For a comprehensive and structured discussion, we synthesize recent research
from three fundamental perspectives: effectiveness, security, and
applicability. Finally, we discuss several critical future research directions
in VFL, which will facilitate the developments in this field. We provide a
collection of research lists and periodically update them at
https://github.com/shentt67/VFL_Survey.",2024-05-25,"Mang Ye, Wei Shen, Bo Du, Eduard Snezhko, Vassili Kovalev, Pong C. Yuen",http://arxiv.org/pdf/2405.17495v2,cs.LG
Generating configurations of increasing lattice size with machine learning and the inverse renormalization group,"We review recent developments of machine learning algorithms pertinent to the
inverse renormalization group, which was originally established as a generative
numerical method by Ron-Swendsen-Brandt via the implementation of compatible
Monte Carlo simulations. Inverse renormalization group methods enable the
iterative generation of configurations for increasing lattice size without the
critical slowing down effect. We discuss the construction of inverse
renormalization group transformations with the use of convolutional neural
networks and present applications in models of statistical mechanics, lattice
field theory, and disordered systems. We highlight the case of the
three-dimensional Edwards-Anderson spin glass, where the inverse
renormalization group can be employed to construct configurations for lattice
volumes that have not yet been accessed by dedicated supercomputers.",2024-05-25,Dimitrios Bachtis,http://arxiv.org/pdf/2405.16288v1,cs.LG
LoGAH: Predicting 774-Million-Parameter Transformers using Graph HyperNetworks with 1/100 Parameters,"A good initialization of deep learning models is essential since it can help
them converge better and faster. However, pretraining large models is
unaffordable for many researchers, which makes a desired prediction for initial
parameters more necessary nowadays. Graph HyperNetworks (GHNs), one approach to
predicting model parameters, have recently shown strong performance in
initializing large vision models. Unfortunately, predicting parameters of very
wide networks relies on copying small chunks of parameters multiple times and
requires an extremely large number of parameters to support full prediction,
which greatly hinders its adoption in practice. To address this limitation, we
propose LoGAH (Low-rank GrAph Hypernetworks), a GHN with a low-rank parameter
decoder that expands to significantly wider networks without requiring as
excessive increase of parameters as in previous attempts. LoGAH allows us to
predict the parameters of 774-million large neural networks in a
memory-efficient manner. We show that vision and language models (i.e., ViT and
GPT-2) initialized with LoGAH achieve better performance than those initialized
randomly or using existing hypernetworks. Furthermore, we show promising
transfer learning results w.r.t. training LoGAH on small datasets and using the
predicted parameters to initialize for larger tasks. We provide the codes in
https://github.com/Blackzxy/LoGAH .",2024-05-25,"Xinyu Zhou, Boris Knyazev, Alexia Jolicoeur-Martineau, Jie Fu",http://arxiv.org/pdf/2405.16287v1,cs.LG
Generation of synthetic data using breast cancer dataset and classification with resnet18,"Since technology is advancing so quickly in the modern era of information,
data is becoming an essential resource in many fields. Correct data collection,
organization, and analysis make it a potent tool for successful
decision-making, process improvement, and success across a wide range of
sectors. Synthetic data is required for a number of reasons, including the
constraints of real data, the expense of collecting labeled data, and privacy
and security problems in specific situations and domains. For a variety of
reasons, including security, ethics, legal restrictions, sensitivity and
privacy issues, and ethics, synthetic data is a valuable tool, particularly in
the health sector. A deep learning model called GAN (Generative Adversarial
Networks) has been developed with the intention of generating synthetic data.
In this study, the Breast Histopathology dataset was used to generate malignant
and negatively labeled synthetic patch images using MSG-GAN (Multi-Scale
Gradients for Generative Adversarial Networks), a form of GAN, to aid in cancer
identification. After that, the ResNet18 model was used to classify both
synthetic and real data via Transfer Learning. Following the investigation, an
attempt was made to ascertain whether the synthetic images behaved like the
real data or if they are comparable to the original data.",2024-05-25,"Dilsat Berin Aytar, Semra Gunduc",http://arxiv.org/pdf/2405.16286v1,cs.LG
ModelLock: Locking Your Model With a Spell,"This paper presents a novel model protection paradigm ModelLock that locks
(destroys) the performance of a model on normal clean data so as to make it
unusable or unextractable without the right key. Specifically, we proposed a
diffusion-based framework dubbed ModelLock that explores text-guided image
editing to transform the training data into unique styles or add new objects in
the background. A model finetuned on this edited dataset will be locked and can
only be unlocked by the key prompt, i.e., the text prompt used to transform the
data. We conduct extensive experiments on both image classification and
segmentation tasks, and show that 1) ModelLock can effectively lock the
finetuned models without significantly reducing the expected performance, and
more importantly, 2) the locked model cannot be easily unlocked without knowing
both the key prompt and the diffusion model. Our work opens up a new direction
for intellectual property protection of private models.",2024-05-25,"Yifeng Gao, Yuhua Sun, Xingjun Ma, Zuxuan Wu, Yu-Gang Jiang",http://arxiv.org/pdf/2405.16285v3,cs.LG
Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models,"As the use of Large Language Models (LLMs) becomes more widespread,
understanding their self-evaluation of confidence in generated responses
becomes increasingly important as it is integral to the reliability of the
output of these models. We introduce the concept of Confidence-Probability
Alignment, that connects an LLM's internal confidence, quantified by token
probabilities, to the confidence conveyed in the model's response when
explicitly asked about its certainty. Using various datasets and prompting
techniques that encourage model introspection, we probe the alignment between
models' internal and expressed confidence. These techniques encompass using
structured evaluation scales to rate confidence, including answer options when
prompting, and eliciting the model's confidence level for outputs it does not
recognize as its own. Notably, among the models analyzed, OpenAI's GPT-4 showed
the strongest confidence-probability alignment, with an average Spearman's
$\hat{\rho}$ of 0.42, across a wide range of tasks. Our work contributes to the
ongoing efforts to facilitate risk assessment in the application of LLMs and to
further our understanding of model trustworthiness.",2024-05-25,"Abhishek Kumar, Robert Morabito, Sanzhar Umbet, Jad Kabbara, Ali Emami",http://arxiv.org/pdf/2405.16282v5,cs.LG
Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge,"Large Language Models (LLMs) have demonstrated remarkable success in tasks
like the Winograd Schema Challenge (WSC), showcasing advanced textual
common-sense reasoning. However, applying this reasoning to multimodal domains,
where understanding text and images together is essential, remains a
substantial challenge. To address this, we introduce WinoVis, a novel dataset
specifically designed to probe text-to-image models on pronoun disambiguation
within multimodal contexts. Utilizing GPT-4 for prompt generation and Diffusion
Attentive Attribution Maps (DAAM) for heatmap analysis, we propose a novel
evaluation framework that isolates the models' ability in pronoun
disambiguation from other visual processing challenges. Evaluation of
successive model versions reveals that, despite incremental advancements,
Stable Diffusion 2.0 achieves a precision of 56.7% on WinoVis, only marginally
surpassing random guessing. Further error analysis identifies important areas
for future research aimed at advancing text-to-image models in their ability to
interpret and interact with the complex visual world.",2024-05-25,"Brendan Park, Madeline Janecek, Naser Ezzati-Jivan, Yifeng Li, Ali Emami",http://arxiv.org/pdf/2405.16277v3,cs.LG
A GPU-Accelerated Bi-linear ADMM Algorithm for Distributed Sparse Machine Learning,"This paper introduces the Bi-linear consensus Alternating Direction Method of
Multipliers (Bi-cADMM), aimed at solving large-scale regularized Sparse Machine
Learning (SML) problems defined over a network of computational nodes.
Mathematically, these are stated as minimization problems with convex local
loss functions over a global decision vector, subject to an explicit $\ell_0$
norm constraint to enforce the desired sparsity. The considered SML problem
generalizes different sparse regression and classification models, such as
sparse linear and logistic regression, sparse softmax regression, and sparse
support vector machines. Bi-cADMM leverages a bi-linear consensus reformulation
of the original non-convex SML problem and a hierarchical decomposition
strategy that divides the problem into smaller sub-problems amenable to
parallel computing. In Bi-cADMM, this decomposition strategy is based on a
two-phase approach. Initially, it performs a sample decomposition of the data
and distributes local datasets across computational nodes. Subsequently, a
delayed feature decomposition of the data is conducted on Graphics Processing
Units (GPUs) available to each node. This methodology allows Bi-cADMM to
undertake computationally intensive data-centric computations on GPUs, while
CPUs handle more cost-effective computations. The proposed algorithm is
implemented within an open-source Python package called Parallel Sparse Fitting
Toolbox (PsFiT), which is publicly available. Finally, computational
experiments demonstrate the efficiency and scalability of our algorithm through
numerical benchmarks across various SML problems featuring distributed
datasets.",2024-05-25,"Alireza Olama, Andreas Lundell, Jan Kronqvist, Elham Ahmadi, Eduardo Camponogara",http://arxiv.org/pdf/2405.16267v2,cs.LG
Deep Reinforcement Learning with Enhanced PPO for Safe Mobile Robot Navigation,"Collision-free motion is essential for mobile robots. Most approaches to
collision-free and efficient navigation with wheeled robots require parameter
tuning by experts to obtain good navigation behavior. This study investigates
the application of deep reinforcement learning to train a mobile robot for
autonomous navigation in a complex environment. The robot utilizes LiDAR sensor
data and a deep neural network to generate control signals guiding it toward a
specified target while avoiding obstacles. We employ two reinforcement learning
algorithms in the Gazebo simulation environment: Deep Deterministic Policy
Gradient and proximal policy optimization. The study introduces an enhanced
neural network structure in the Proximal Policy Optimization algorithm to boost
performance, accompanied by a well-designed reward function to improve
algorithm efficacy. Experimental results conducted in both obstacle and
obstacle-free environments underscore the effectiveness of the proposed
approach. This research significantly contributes to the advancement of
autonomous robotics in complex environments through the application of deep
reinforcement learning.",2024-05-25,"Hamid Taheri, Seyed Rasoul Hosseini, Mohammad Ali Nekoui",http://arxiv.org/pdf/2405.16266v2,cs.LG
MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time,"Although Large Language Models (LLMs) achieve remarkable performance across
various tasks, they often struggle with complex reasoning tasks, such as
answering mathematical questions. Recent efforts to address this issue have
primarily focused on leveraging mathematical datasets through supervised
fine-tuning or self-improvement techniques. However, these methods often depend
on high-quality datasets that are difficult to prepare, or they require
substantial computational resources for fine-tuning. Inspired by findings that
LLMs know how to produce the right answer but struggle to select the correct
reasoning path, we propose a purely inference-based searching method --
MindStar (M*). This method formulates reasoning tasks as searching problems and
proposes two search ideas to identify the optimal reasoning paths. We evaluate
the M* framework on both the GSM8K and MATH datasets, comparing its performance
with existing open and closed-source LLMs. Our results demonstrate that M*
significantly enhances the reasoning abilities of open-source models, such as
Llama-2-13B and Mistral-7B, and achieves comparable performance to GPT-3.5 and
Grok-1, but with substantially reduced model size and computational costs.",2024-05-25,"Jikun Kang, Xin Zhe Li, Xi Chen, Amirreza Kazemi, Qianyi Sun, Boxing Chen, Dong Li, Xu He, Quan He, Feng Wen, Jianye Hao, Jun Yao",http://arxiv.org/pdf/2405.16265v4,cs.LG
Layer-Aware Analysis of Catastrophic Overfitting: Revealing the Pseudo-Robust Shortcut Dependency,"Catastrophic overfitting (CO) presents a significant challenge in single-step
adversarial training (AT), manifesting as highly distorted deep neural networks
(DNNs) that are vulnerable to multi-step adversarial attacks. However, the
underlying factors that lead to the distortion of decision boundaries remain
unclear. In this work, we delve into the specific changes within different DNN
layers and discover that during CO, the former layers are more susceptible,
experiencing earlier and greater distortion, while the latter layers show
relative insensitivity. Our analysis further reveals that this increased
sensitivity in former layers stems from the formation of pseudo-robust
shortcuts, which alone can impeccably defend against single-step adversarial
attacks but bypass genuine-robust learning, resulting in distorted decision
boundaries. Eliminating these shortcuts can partially restore robustness in
DNNs from the CO state, thereby verifying that dependence on them triggers the
occurrence of CO. This understanding motivates us to implement adaptive weight
perturbations across different layers to hinder the generation of pseudo-robust
shortcuts, consequently mitigating CO. Extensive experiments demonstrate that
our proposed method, Layer-Aware Adversarial Weight Perturbation (LAP), can
effectively prevent CO and further enhance robustness.",2024-05-25,"Runqi Lin, Chaojian Yu, Bo Han, Hang Su, Tongliang Liu",http://arxiv.org/pdf/2405.16262v2,cs.LG
Enhancing Consistency-Based Image Generation via Adversarialy-Trained Classification and Energy-Based Discrimination,"The recently introduced Consistency models pose an efficient alternative to
diffusion algorithms, enabling rapid and good quality image synthesis. These
methods overcome the slowness of diffusion models by directly mapping noise to
data, while maintaining a (relatively) simpler training. Consistency models
enable a fast one- or few-step generation, but they typically fall somewhat
short in sample quality when compared to their diffusion origins. In this work
we propose a novel and highly effective technique for post-processing
Consistency-based generated images, enhancing their perceptual quality. Our
approach utilizes a joint classifier-discriminator model, in which both
portions are trained adversarially. While the classifier aims to grade an image
based on its assignment to a designated class, the discriminator portion of the
very same network leverages the softmax values to assess the proximity of the
input image to the targeted data manifold, thereby serving as an Energy-based
Model. By employing example-specific projected gradient iterations under the
guidance of this joint machine, we refine synthesized images and achieve an
improved FID scores on the ImageNet 64x64 dataset for both Consistency-Training
and Consistency-Distillation techniques.",2024-05-25,"Shelly Golan, Roy Ganz, Michael Elad",http://arxiv.org/pdf/2405.16260v2,cs.LG
Front-propagation Algorithm: Explainable AI Technique for Extracting Linear Function Approximations from Neural Networks,"This paper introduces the front-propagation algorithm, a novel eXplainable AI
(XAI) technique designed to elucidate the decision-making logic of deep neural
networks. Unlike other popular explainability algorithms such as Integrated
Gradients or Shapley Values, the proposed algorithm is able to extract an
accurate and consistent linear function explanation of the network in a single
forward pass of the trained model. This nuance sets apart the time complexity
of the front-propagation as it could be running real-time and in parallel with
deployed models. We packaged this algorithm in a software called
$\texttt{front-prop}$ and we demonstrate its efficacy in providing accurate
linear functions with three different neural network architectures trained on
publicly available benchmark datasets.",2024-05-25,Javier Viaña,http://arxiv.org/pdf/2405.16259v1,cs.LG
USD: Unsupervised Soft Contrastive Learning for Fault Detection in Multivariate Time Series,"Unsupervised fault detection in multivariate time series is critical for
maintaining the integrity and efficiency of complex systems, with current
methodologies largely focusing on statistical and machine learning techniques.
However, these approaches often rest on the assumption that data distributions
conform to Gaussian models, overlooking the diversity of patterns that can
manifest in both normal and abnormal states, thereby diminishing discriminative
performance. Our innovation addresses this limitation by introducing a
combination of data augmentation and soft contrastive learning, specifically
designed to capture the multifaceted nature of state behaviors more accurately.
The data augmentation process enriches the dataset with varied representations
of normal states, while soft contrastive learning fine-tunes the model's
sensitivity to the subtle differences between normal and abnormal patterns,
enabling it to recognize a broader spectrum of anomalies. This dual strategy
significantly boosts the model's ability to distinguish between normal and
abnormal states, leading to a marked improvement in fault detection performance
across multiple datasets and settings, thereby setting a new benchmark for
unsupervised fault detection in complex systems. The code of our method is
available at \url{https://github.com/zangzelin/code_USD.git}.",2024-05-25,"Hong Liu, Xiuxiu Qiu, Yiming Shi, Zelin Zang",http://arxiv.org/pdf/2405.16258v1,cs.LG
GeoAdaLer: Geometric Insights into Adaptive Stochastic Gradient Descent Algorithms,"The Adam optimization method has achieved remarkable success in addressing
contemporary challenges in stochastic optimization. This method falls within
the realm of adaptive sub-gradient techniques, yet the underlying geometric
principles guiding its performance have remained shrouded in mystery, and have
long confounded researchers. In this paper, we introduce GeoAdaLer (Geometric
Adaptive Learner), a novel adaptive learning method for stochastic gradient
descent optimization, which draws from the geometric properties of the
optimization landscape. Beyond emerging as a formidable contender, the proposed
method extends the concept of adaptive learning by introducing a geometrically
inclined approach that enhances the interpretability and effectiveness in
complex optimization scenarios",2024-05-25,"Chinedu Eleh, Masuzyo Mwanza, Ekene Aguegboh, Hans-Werner van Wyk",http://arxiv.org/pdf/2405.16255v1,cs.LG
Combining Radiomics and Machine Learning Approaches for Objective ASD Diagnosis: Verifying White Matter Associations with ASD,"Autism Spectrum Disorder is a condition characterized by a typical brain
development leading to impairments in social skills, communication abilities,
repetitive behaviors, and sensory processing. There have been many studies
combining brain MRI images with machine learning algorithms to achieve
objective diagnosis of autism, but the correlation between white matter and
autism has not been fully utilized. To address this gap, we develop a
computer-aided diagnostic model focusing on white matter regions in brain MRI
by employing radiomics and machine learning methods. This study introduced a
MultiUNet model for segmenting white matter, leveraging the UNet architecture
and utilizing manually segmented MRI images as the training data. Subsequently,
we extracted white matter features using the Pyradiomics toolkit and applied
different machine learning models such as Support Vector Machine, Random
Forest, Logistic Regression, and K-Nearest Neighbors to predict autism. The
prediction sets all exceeded 80% accuracy. Additionally, we employed
Convolutional Neural Network to analyze segmented white matter images,
achieving a prediction accuracy of 86.84%. Notably, Support Vector Machine
demonstrated the highest prediction accuracy at 89.47%. These findings not only
underscore the efficacy of the models but also establish a link between white
matter abnormalities and autism. Our study contributes to a comprehensive
evaluation of various diagnostic models for autism and introduces a
computer-aided diagnostic algorithm for early and objective autism diagnosis
based on MRI white matter regions.",2024-05-25,"Junlin Song, Yuzhuo Chen, Yuan Yao, Zetong Chen, Renhao Guo, Lida Yang, Xinyi Sui, Qihang Wang, Xijiao Li, Aihua Cao, Wei Li",http://arxiv.org/pdf/2405.16248v1,cs.LG
AFL: A Single-Round Analytic Approach for Federated Learning with Pre-trained Models,"In this paper, we introduce analytic federated learning (AFL), a new training
paradigm that brings analytical (i.e., closed-form) solutions to the federated
learning (FL) with pre-trained models. Our AFL draws inspiration from analytic
learning -- a gradient-free technique that trains neural networks with
analytical solutions in one epoch. In the local client training stage, the AFL
facilitates a one-epoch training, eliminating the necessity for multi-epoch
updates. In the aggregation stage, we derive an absolute aggregation (AA) law.
This AA law allows a single-round aggregation, reducing heavy communication
overhead and achieving fast convergence by removing the need for multiple
aggregation rounds. More importantly, the AFL exhibits a property that
$\textit{invariance to data partitioning}$, meaning that regardless of how the
full dataset is distributed among clients, the aggregated result remains
identical. This could spawn various potentials, such as data heterogeneity
invariance and client-number invariance. We conduct experiments across various
FL settings including extremely non-IID ones, and scenarios with a large number
of clients (e.g., $\ge 1000$). In all these settings, our AFL constantly
performs competitively while existing FL techniques encounter various
obstacles. Our codes are available at
https://github.com/ZHUANGHP/Analytic-federated-learning.",2024-05-25,"Run He, Kai Tong, Di Fang, Han Sun, Haoran Li, Tianyi Chen, Ziqian Zeng, Huiping Zhuang",http://arxiv.org/pdf/2405.16240v2,cs.LG
A transfer learning framework for weak-to-strong generalization,"Modern large language model (LLM) alignment techniques rely on human
feedback, but it is unclear whether these techniques fundamentally limit the
capabilities of aligned LLMs. In particular, it is unknown if it is possible to
align (stronger) LLMs with superhuman capabilities with (weaker) human feedback
without degrading their capabilities. This is an instance of the weak-to-strong
generalization problem: using feedback from a weaker (less capable) model to
train a stronger (more capable) model. We prove that weak-to-strong
generalization is possible by eliciting latent knowledge from pre-trained LLMs.
In particular, we cast the weak-to-strong generalization problem as a transfer
learning problem in which we wish to transfer a latent concept prior from a
weak model to a strong pre-trained model. We prove that a naive fine-tuning
approach suffers from fundamental limitations, but an alternative
refinement-based approach suggested by the problem structure provably overcomes
the limitations of fine-tuning. Finally, we demonstrate the practical
applicability of the refinement approach in multiple LLM alignment tasks.",2024-05-25,"Seamus Somerstep, Felipe Maia Polo, Moulinath Banerjee, Ya'acov Ritov, Mikhail Yurochkin, Yuekai Sun",http://arxiv.org/pdf/2405.16236v3,cs.LG
Client2Vec: Improving Federated Learning by Distribution Shifts Aware Client Indexing,"Federated Learning (FL) is a privacy-preserving distributed machine learning
paradigm. Nonetheless, the substantial distribution shifts among clients pose a
considerable challenge to the performance of current FL algorithms. To mitigate
this challenge, various methods have been proposed to enhance the FL training
process. This paper endeavors to tackle the issue of data heterogeneity from
another perspective -- by improving FL algorithms prior to the actual training
stage. Specifically, we introduce the Client2Vec mechanism, which generates a
unique client index for each client before the commencement of FL training.
Subsequently, we leverage the generated client index to enhance the subsequent
FL training process. To demonstrate the effectiveness of the proposed
Client2Vec method, we conduct three case studies that assess the impact of the
client index on the FL training process. These case studies encompass enhanced
client sampling, model aggregation, and local training. Extensive experiments
conducted on diverse datasets and model architectures show the efficacy of
Client2Vec across all three case studies. Our code is avaliable at
\url{https://github.com/LINs-lab/client2vec}.",2024-05-25,"Yongxin Guo, Lin Wang, Xiaoying Tang, Tao Lin",http://arxiv.org/pdf/2405.16233v1,cs.LG
Detecting Adversarial Data using Perturbation Forgery,"As a defense strategy against adversarial attacks, adversarial detection aims
to identify and filter out adversarial data from the data flow based on
discrepancies in distribution and noise patterns between natural and
adversarial data. Although previous detection methods achieve high performance
in detecting gradient-based adversarial attacks, new attacks based on
generative models with imbalanced and anisotropic noise patterns evade
detection. Even worse, the significant inference time overhead and limited
performance against unseen attacks make existing techniques impractical for
real-world use. In this paper, we explore the proximity relationship among
adversarial noise distributions and demonstrate the existence of an open
covering for these distributions. By training on the open covering of
adversarial noise distributions, a detector with strong generalization
performance against various types of unseen attacks can be developed. Based on
this insight, we heuristically propose Perturbation Forgery, which includes
noise distribution perturbation, sparse mask generation, and pseudo-adversarial
data production, to train an adversarial detector capable of detecting any
unseen gradient-based, generative-based, and physical adversarial attacks.
Comprehensive experiments conducted on multiple general and facial datasets,
with a wide spectrum of attacks, validate the strong generalization of our
method.",2024-05-25,"Qian Wang, Chen Li, Yuchen Luo, Hefei Ling, Shijuan Huang, Ruoxi Jia, Ning Yu",http://arxiv.org/pdf/2405.16226v4,cs.LG
Local Causal Structure Learning in the Presence of Latent Variables,"Discovering causal relationships from observational data, particularly in the
presence of latent variables, poses a challenging problem. While current local
structure learning methods have proven effective and efficient when the focus
lies solely on the local relationships of a target variable, they operate under
the assumption of causal sufficiency. This assumption implies that all the
common causes of the measured variables are observed, leaving no room for
latent variables. Such a premise can be easily violated in various real-world
applications, resulting in inaccurate structures that may adversely impact
downstream tasks. In light of this, our paper delves into the primary
investigation of locally identifying potential parents and children of a target
from observational data that may include latent variables. Specifically, we
harness the causal information from m-separation and V-structures to derive
theoretical consistency results, effectively bridging the gap between global
and local structure learning. Together with the newly developed stop rules, we
present a principled method for determining whether a variable is a direct
cause or effect of a target. Further, we theoretically demonstrate the
correctness of our approach under the standard causal Markov and faithfulness
conditions, with infinite samples. Experimental results on both synthetic and
real-world data validate the effectiveness and efficiency of our approach.",2024-05-25,"Feng Xie, Zheng Li, Peng Wu, Yan Zeng, Chunchen Liu, Zhi Geng",http://arxiv.org/pdf/2405.16225v2,cs.LG
Negative as Positive: Enhancing Out-of-distribution Generalization for Graph Contrastive Learning,"Graph contrastive learning (GCL), standing as the dominant paradigm in the
realm of graph pre-training, has yielded considerable progress. Nonetheless,
its capacity for out-of-distribution (OOD) generalization has been relatively
underexplored. In this work, we point out that the traditional optimization of
InfoNCE in GCL restricts the cross-domain pairs only to be negative samples,
which inevitably enlarges the distribution gap between different domains. This
violates the requirement of domain invariance under OOD scenario and
consequently impairs the model's OOD generalization performance. To address
this issue, we propose a novel strategy ""Negative as Positive"", where the most
semantically similar cross-domain negative pairs are treated as positive during
GCL. Our experimental results, spanning a wide array of datasets, confirm that
this method substantially improves the OOD generalization performance of GCL.",2024-05-25,"Zixu Wang, Bingbing Xu, Yige Yuan, Huawei Shen, Xueqi Cheng",http://arxiv.org/pdf/2405.16224v1,cs.LG
Deep Causal Generative Models with Property Control,"Generating data with properties of interest by external users while following
the right causation among its intrinsic factors is important yet has not been
well addressed jointly. This is due to the long-lasting challenge of jointly
identifying key latent variables, their causal relations, and their correlation
with properties of interest, as well as how to leverage their discoveries
toward causally controlled data generation. To address these challenges, we
propose a novel deep generative framework called the Correlation-aware Causal
Variational Auto-encoder (C2VAE). This framework simultaneously recovers the
correlation and causal relationships between properties using disentangled
latent vectors. Specifically, causality is captured by learning the causal
graph on latent variables through a structural causal model, while correlation
is learned via a novel correlation pooling algorithm. Extensive experiments
demonstrate C2VAE's ability to accurately recover true causality and
correlation, as well as its superiority in controllable data generation
compared to baseline models.",2024-05-25,"Qilong Zhao, Shiyu Wang, Guangji Bai, Bo Pan, Zhaohui Qin, Liang Zhao",http://arxiv.org/pdf/2405.16219v1,cs.LG
Transitional Uncertainty with Layered Intermediate Predictions,"In this paper, we discuss feature engineering for single-pass uncertainty
estimation. For accurate uncertainty estimates, neural networks must extract
differences in the feature space that quantify uncertainty. This could be
achieved by current single-pass approaches that maintain feature distances
between data points as they traverse the network. While initial results are
promising, maintaining feature distances within the network representations
frequently inhibits information compression and opposes the learning objective.
We study this effect theoretically and empirically to arrive at a simple
conclusion: preserving feature distances in the output is beneficial when the
preserved features contribute to learning the label distribution and act in
opposition otherwise. We then propose Transitional Uncertainty with Layered
Intermediate Predictions (TULIP) as a simple approach to address the
shortcomings of current single-pass estimators. Specifically, we implement
feature preservation by extracting features from intermediate representations
before information is collapsed by subsequent layers. We refer to the
underlying preservation mechanism as transitional feature preservation. We show
that TULIP matches or outperforms current single-pass methods on standard
benchmarks and in practical settings where these methods are less reliable
(imbalances, complex architectures, medical modalities).",2024-05-25,"Ryan Benkert, Mohit Prabhushankar, Ghassan AlRegib",http://arxiv.org/pdf/2405.17494v2,cs.LG
Learning Visual-Semantic Subspace Representations,"Learning image representations that capture rich semantic relationships
remains a significant challenge. Existing approaches are either contrastive,
lacking robust theoretical guarantees, or struggle to effectively represent the
partial orders inherent to structured visual-semantic data. In this paper, we
introduce a nuclear norm-based loss function, grounded in the same information
theoretic principles that have proved effective in self-supervised learning. We
present a theoretical characterization of this loss, demonstrating that, in
addition to promoting class orthogonality, it encodes the spectral geometry of
the data within a subspace lattice. This geometric representation allows us to
associate logical propositions with subspaces, ensuring that our learned
representations adhere to a predefined symbolic structure.",2024-05-25,"Gabriel Moreira, Manuel Marques, João Paulo Costeira, Alexander Hauptmann",http://arxiv.org/pdf/2405.16213v2,cs.LG
Towards Black-Box Membership Inference Attack for Diffusion Models,"Given the rising popularity of AI-generated art and the associated copyright
concerns, identifying whether an artwork was used to train a diffusion model is
an important research topic. The work approaches this problem from the
membership inference attack (MIA) perspective. We first identify the limitation
of applying existing MIA methods for proprietary diffusion models: the required
access of internal U-nets. To address the above problem, we introduce a novel
membership inference attack method that uses only the image-to-image variation
API and operates without access to the model's internal U-net. Our method is
based on the intuition that the model can more easily obtain an unbiased noise
prediction estimate for images from the training set. By applying the API
multiple times to the target image, averaging the outputs, and comparing the
result to the original image, our approach can classify whether a sample was
part of the training set. We validate our method using DDIM and Stable
Diffusion setups and further extend both our approach and existing algorithms
to the Diffusion Transformer architecture. Our experimental results
consistently outperform previous methods.",2024-05-25,"Jingwei Li, Jing Dong, Tianxing He, Jingzhao Zhang",http://arxiv.org/pdf/2405.20771v3,cs.LG
GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine Learning,"Glycans are basic biomolecules and perform essential functions within living
organisms. The rapid increase of functional glycan data provides a good
opportunity for machine learning solutions to glycan understanding. However,
there still lacks a standard machine learning benchmark for glycan property and
function prediction. In this work, we fill this blank by building a
comprehensive benchmark for Glycan Machine Learning (GlycanML). The GlycanML
benchmark consists of diverse types of tasks including glycan taxonomy
prediction, glycan immunogenicity prediction, glycosylation type prediction,
and protein-glycan interaction prediction. Glycans can be represented by both
sequences and graphs in GlycanML, which enables us to extensively evaluate
sequence-based models and graph neural networks (GNNs) on benchmark tasks.
Furthermore, by concurrently performing eight glycan taxonomy prediction tasks,
we introduce the GlycanML-MTL testbed for multi-task learning (MTL) algorithms.
Also, we evaluate how taxonomy prediction can boost other three function
prediction tasks by MTL. Experimental results show the superiority of modeling
glycans with multi-relational GNNs, and suitable MTL methods can further boost
model performance. We provide all datasets and source codes at
https://github.com/GlycanML/GlycanML and maintain a leaderboard at
https://GlycanML.github.io/project",2024-05-25,"Minghao Xu, Yunteng Geng, Yihang Zhang, Ling Yang, Jian Tang, Wentao Zhang",http://arxiv.org/pdf/2405.16206v3,cs.LG
Evolutionary Large Language Model for Automated Feature Transformation,"Feature transformation aims to reconstruct the feature space of raw features
to enhance the performance of downstream models. However, the exponential
growth in the combinations of features and operations poses a challenge, making
it difficult for existing methods to efficiently explore a wide space.
Additionally, their optimization is solely driven by the accuracy of downstream
models in specific domains, neglecting the acquisition of general feature
knowledge. To fill this research gap, we propose an evolutionary LLM framework
for automated feature transformation. This framework consists of two parts: 1)
constructing a multi-population database through an RL data collector while
utilizing evolutionary algorithm strategies for database maintenance, and 2)
utilizing the ability of Large Language Model (LLM) in sequence understanding,
we employ few-shot prompts to guide LLM in generating superior samples based on
feature transformation sequence distinction. Leveraging the multi-population
database initially provides a wide search scope to discover excellent
populations. Through culling and evolution, the high-quality populations are
afforded greater opportunities, thereby furthering the pursuit of optimal
individuals. Through the integration of LLMs with evolutionary algorithms, we
achieve efficient exploration within a vast space, while harnessing feature
knowledge to propel optimization, thus realizing a more adaptable search
paradigm. Finally, we empirically demonstrate the effectiveness and generality
of our proposed method.",2024-05-25,"Nanxu Gong, Chandan K. Reddy, Wangyang Ying, Haifeng Chen, Yanjie Fu",http://arxiv.org/pdf/2405.16203v2,cs.LG
Maintaining and Managing Road Quality:Using MLP and DNN,"Poor roads are a major issue for cars, drivers, and pedestrians since they
are a major cause of vehicle damage and can occasionally be quite dangerous for
both groups of people (pedestrians and drivers), this makes road surface
condition monitoring systems essential for traffic safety, reducing accident
rates ad also protecting vehicles from getting damaged. The primary objective
is to develop and evaluate machine learning models that can accurately classify
road conditions into four categories: good, satisfactory, poor, and very poor,
using a Kaggle dataset of road images. To address this, we implemented a
variety of machine learning approaches. Firstly, a baseline model was created
using a Multilayer Perceptron (MLP) implemented from scratch. Secondly, a more
sophisticated Deep Neural Network (DNN) was constructed using Keras.
Additionally, we developed a Logistic Regression model from scratch to compare
performance. Finally, a wide model incorporating extensive feature engineering
was built using the K-Nearest Neighbors (KNN) algorithm with sklearn.The study
compared different models for image-based road quality assessment. Deep
learning models, the DNN with Keras achieved the best accuracy, while the
baseline MLP provided a solid foundation. The Logistic Regression although it
is simpler, but it provided interpretability and insights into important
features. The KNN model, with the help of feature engineering, achieved the
best results. The research shows that machine learning can automate road
condition monitoring, saving time and money on maintenance. The next step is to
improve these models and test them in real cities, which will make our cities
better managed and safer.",2024-05-25,Makgotso Jacqueline Maotwana,http://arxiv.org/pdf/2405.16196v1,cs.LG
Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement Learning,"Deep Reinforcement Learning (RL) is well known for being highly sensitive to
hyperparameters, requiring practitioners substantial efforts to optimize them
for the problem at hand. This also limits the applicability of RL in real-world
scenarios. In recent years, the field of automated Reinforcement Learning
(AutoRL) has grown in popularity by trying to address this issue. However,
these approaches typically hinge on additional samples to select
well-performing hyperparameters, hindering sample-efficiency and practicality.
Furthermore, most AutoRL methods are heavily based on already existing AutoML
methods, which were originally developed neglecting the additional challenges
inherent to RL due to its non-stationarities. In this work, we propose a new
approach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to
RL to take into account the non-stationarity of the optimization procedure
without requiring additional samples. AdaQN learns several $Q$-functions, each
one trained with different hyperparameters, which are updated online using the
$Q$-function with the smallest approximation error as a shared target. Our
selection scheme simultaneously handles different hyperparameters while coping
with the non-stationarity induced by the RL optimization procedure and being
orthogonal to any critic-based RL algorithm. We demonstrate that AdaQN is
theoretically sound and empirically validate it in MuJoCo control problems and
Atari $2600$ games, showing benefits in sample-efficiency, overall performance,
robustness to stochasticity and training stability.",2024-05-25,"Théo Vincent, Fabian Wahren, Jan Peters, Boris Belousov, Carlo D'Eramo",http://arxiv.org/pdf/2405.16195v3,cs.LG
Diffusion-Reward Adversarial Imitation Learning,"Imitation learning aims to learn a policy from observing expert
demonstrations without access to reward signals from environments. Generative
adversarial imitation learning (GAIL) formulates imitation learning as
adversarial learning, employing a generator policy learning to imitate expert
behaviors and discriminator learning to distinguish the expert demonstrations
from agent trajectories. Despite its encouraging results, GAIL training is
often brittle and unstable. Inspired by the recent dominance of diffusion
models in generative modeling, we propose Diffusion-Reward Adversarial
Imitation Learning (DRAIL), which integrates a diffusion model into GAIL,
aiming to yield more robust and smoother rewards for policy learning.
Specifically, we propose a diffusion discriminative classifier to construct an
enhanced discriminator, and design diffusion rewards based on the classifier's
output for policy learning. Extensive experiments are conducted in navigation,
manipulation, and locomotion, verifying DRAIL's effectiveness compared to prior
imitation learning methods. Moreover, additional experimental results
demonstrate the generalizability and data efficiency of DRAIL. Visualized
learned reward functions of GAIL and DRAIL suggest that DRAIL can produce more
robust and smoother rewards. Project page:
https://nturobotlearninglab.github.io/DRAIL/",2024-05-25,"Chun-Mao Lai, Hsiang-Chun Wang, Ping-Chun Hsieh, Yu-Chiang Frank Wang, Min-Hung Chen, Shao-Hua Sun",http://arxiv.org/pdf/2405.16194v4,cs.LG
Differentiable Cluster Graph Neural Network,"Graph Neural Networks often struggle with long-range information propagation
and in the presence of heterophilous neighborhoods. We address both challenges
with a unified framework that incorporates a clustering inductive bias into the
message passing mechanism, using additional cluster-nodes. Central to our
approach is the formulation of an optimal transport based implicit clustering
objective function. However, the algorithm for solving the implicit objective
function needs to be differentiable to enable end-to-end learning of the GNN.
To facilitate this, we adopt an entropy regularized objective function and
propose an iterative optimization process, alternating between solving for the
cluster assignments and updating the node/cluster-node embeddings. Notably, our
derived closed-form optimization steps are themselves simple yet elegant
message passing steps operating seamlessly on a bipartite graph of nodes and
cluster-nodes. Our clustering-based approach can effectively capture both local
and global information, demonstrated by extensive experiments on both
heterophilous and homophilous datasets.",2024-05-25,"Yanfei Dong, Mohammed Haroon Dupty, Lambert Deng, Zhuanghua Liu, Yong Liang Goh, Wee Sun Lee",http://arxiv.org/pdf/2405.16185v1,cs.LG
Safe Deep Model-Based Reinforcement Learning with Lyapunov Functions,"Model-based Reinforcement Learning (MBRL) has shown many desirable properties
for intelligent control tasks. However, satisfying safety and stability
constraints during training and rollout remains an open question. We propose a
new Model-based RL framework to enable efficient policy learning with unknown
dynamics based on learning model predictive control (LMPC) framework with
mathematically provable guarantees of stability. We introduce and explore a
novel method for adding safety constraints for model-based RL during training
and policy learning. The new stability-augmented framework consists of a
neural-network-based learner that learns to construct a Lyapunov function, and
a model-based RL agent to consistently complete the tasks while satisfying
user-specified constraints given only sub-optimal demonstrations and
sparse-cost feedback. We demonstrate the capability of the proposed framework
through simulated experiments.",2024-05-25,Harry Zhang,http://arxiv.org/pdf/2405.16184v1,cs.LG
Graph Neural PDE Solvers with Conservation and Similarity-Equivariance,"Utilizing machine learning to address partial differential equations (PDEs)
presents significant challenges due to the diversity of spatial domains and
their corresponding state configurations, which complicates the task of
encompassing all potential scenarios through data-driven methodologies alone.
Moreover, there are legitimate concerns regarding the generalization and
reliability of such approaches, as they often overlook inherent physical
constraints. In response to these challenges, this study introduces a novel
machine-learning architecture that is highly generalizable and adheres to
conservation laws and physical symmetries, thereby ensuring greater
reliability. The foundation of this architecture is graph neural networks
(GNNs), which are adept at accommodating a variety of shapes and forms.
Additionally, we explore the parallels between GNNs and traditional numerical
solvers, facilitating a seamless integration of conservative principles and
symmetries into machine learning models. Our findings from experiments
demonstrate that the model's inclusion of physical laws significantly enhances
its generalizability, i.e., no significant accuracy degradation for unseen
spatial domains while other models degrade. The code is available at
https://github.com/yellowshippo/fluxgnn-icml2024.",2024-05-25,"Masanobu Horie, Naoto Mitsume",http://arxiv.org/pdf/2405.16183v1,cs.LG
Diffusion-based Reinforcement Learning via Q-weighted Variational Policy Optimization,"Diffusion models have garnered widespread attention in Reinforcement Learning
(RL) for their powerful expressiveness and multimodality. It has been verified
that utilizing diffusion policies can significantly improve the performance of
RL algorithms in continuous control tasks by overcoming the limitations of
unimodal policies, such as Gaussian policies, and providing the agent with
enhanced exploration capabilities. However, existing works mainly focus on the
application of diffusion policies in offline RL, while their incorporation into
online RL is less investigated. The training objective of the diffusion model,
known as the variational lower bound, cannot be optimized directly in online RL
due to the unavailability of 'good' actions. This leads to difficulties in
conducting diffusion policy improvement. To overcome this, we propose a novel
model-free diffusion-based online RL algorithm, Q-weighted Variational Policy
Optimization (QVPO). Specifically, we introduce the Q-weighted variational
loss, which can be proved to be a tight lower bound of the policy objective in
online RL under certain conditions. To fulfill these conditions, the Q-weight
transformation functions are introduced for general scenarios. Additionally, to
further enhance the exploration capability of the diffusion policy, we design a
special entropy regularization term. We also develop an efficient behavior
policy to enhance sample efficiency by reducing the variance of the diffusion
policy during online interactions. Consequently, the QVPO algorithm leverages
the exploration capabilities and multimodality of diffusion policies,
preventing the RL agent from converging to a sub-optimal policy. To verify the
effectiveness of QVPO, we conduct comprehensive experiments on MuJoCo
benchmarks. The final results demonstrate that QVPO achieves state-of-the-art
performance on both cumulative reward and sample efficiency.",2024-05-25,"Shutong Ding, Ke Hu, Zhenhao Zhang, Kan Ren, Weinan Zhang, Jingyi Yu, Jingya Wang, Ye Shi",http://arxiv.org/pdf/2405.16173v3,cs.LG
Multi-Player Approaches for Dueling Bandits,"Various approaches have emerged for multi-armed bandits in distributed
systems. The multiplayer dueling bandit problem, common in scenarios with only
preference-based information like human feedback, introduces challenges related
to controlling collaborative exploration of non-informative arm pairs, but has
received little attention. To fill this gap, we demonstrate that the direct use
of a Follow Your Leader black-box approach matches the lower bound for this
setting when utilizing known dueling bandit algorithms as a foundation.
Additionally, we analyze a message-passing fully distributed approach with a
novel Condorcet-winner recommendation protocol, resulting in expedited
exploration in many cases. Our experimental comparisons reveal that our
multiplayer algorithms surpass single-player benchmark algorithms, underscoring
their efficacy in addressing the nuanced challenges of the multiplayer dueling
bandit setting.",2024-05-25,"Or Raveh, Junya Honda, Masashi Sugiyama",http://arxiv.org/pdf/2405.16168v2,cs.LG
Acquiring Better Load Estimates by Combining Anomaly and Change Point Detection in Power Grid Time-series Measurements,"In this paper we present novel methodology for automatic anomaly and switch
event filtering to improve load estimation in power grid systems. By leveraging
unsupervised methods with supervised optimization, our approach prioritizes
interpretability while ensuring robust and generalizable performance on unseen
data. Through experimentation, a combination of binary segmentation for change
point detection and statistical process control for anomaly detection emerges
as the most effective strategy, specifically when ensembled in a novel
sequential manner. Results indicate the clear wasted potential when filtering
is not applied. The automatic load estimation is also fairly accurate, with
approximately 90% of estimates falling within a 10% error margin, with only a
single significant failure in both the minimum and maximum load estimates
across 60 measurements in the test set. Our methodology's interpretability
makes it particularly suitable for critical infrastructure planning, thereby
enhancing decision-making processes.",2024-05-25,"Roel Bouman, Linda Schmeitz, Luco Buise, Jacco Heres, Yuliya Shapovalova, Tom Heskes",http://arxiv.org/pdf/2405.16164v3,cs.LG
A Declarative Query Language for Scientific Machine Learning,"The popularity of data science as a discipline and its importance in the
emerging economy and industrial progress dictate that machine learning be
democratized for the masses. This also means that the current practice of
workforce training using machine learning tools, which requires low-level
statistical and algorithmic details, is a barrier that needs to be addressed.
Similar to data management languages such as SQL, machine learning needs to be
practiced at a conceptual level to help make it a staple tool for general
users. In particular, the technical sophistication demanded by existing machine
learning frameworks is prohibitive for many scientists who are not
computationally savvy or well versed in machine learning techniques. The
learning curve to use the needed machine learning tools is also too high for
them to take advantage of these powerful platforms to rapidly advance science.
In this paper, we introduce a new declarative machine learning query language,
called {\em MQL}, for naive users. We discuss its merit and possible ways of
implementing it over a traditional relational database system. We discuss two
materials science experiments implemented using MQL on a materials science
workflow system called MatFlow.",2024-05-25,Hasan M Jamil,http://arxiv.org/pdf/2405.16159v1,cs.LG
"Bigger, Regularized, Optimistic: scaling for compute and sample-efficient continuous control","Sample efficiency in Reinforcement Learning (RL) has traditionally been
driven by algorithmic enhancements. In this work, we demonstrate that scaling
can also lead to substantial improvements. We conduct a thorough investigation
into the interplay of scaling model capacity and domain-specific RL
enhancements. These empirical findings inform the design choices underlying our
proposed BRO (Bigger, Regularized, Optimistic) algorithm. The key innovation
behind BRO is that strong regularization allows for effective scaling of the
critic networks, which, paired with optimistic exploration, leads to superior
performance. BRO achieves state-of-the-art results, significantly outperforming
the leading model-based and model-free algorithms across 40 complex tasks from
the DeepMind Control, MetaWorld, and MyoSuite benchmarks. BRO is the first
model-free algorithm to achieve near-optimal policies in the notoriously
challenging Dog and Humanoid tasks.",2024-05-25,"Michal Nauman, Mateusz Ostaszewski, Krzysztof Jankowski, Piotr Miłoś, Marek Cygan",http://arxiv.org/pdf/2405.16158v3,cs.LG
Mixture of In-Context Prompters for Tabular PFNs,"Recent benchmarks found In-Context Learning (ICL) outperforms both deep
learning and tree-based algorithms on small tabular datasets. However, on
larger datasets, ICL for tabular learning cannot run without severely
compromising performance, due to its quadratic space and time complexity w.r.t.
dataset size. We propose MIXTUREPFN, which both extends nearest-neighbor
sampling to the state-of-the-art ICL for tabular learning model and uses
bootstrapping to finetune said model on the inference-time dataset. MIXTUREPFN
is the Condorcet winner across 36 diverse tabular datasets against 19 strong
deep learning and tree-based baselines, achieving the highest mean rank among
Top-10 aforementioned algorithms with statistical significance.",2024-05-25,"Derek Xu, Olcay Cirit, Reza Asadi, Yizhou Sun, Wei Wang",http://arxiv.org/pdf/2405.16156v1,cs.LG
DefSent+: Improving sentence embeddings of language models by projecting definition sentences into a quasi-isotropic or isotropic vector space of unlimited dictionary entries,"This paper presents a significant improvement on the previous conference
paper known as DefSent. The prior study seeks to improve sentence embeddings of
language models by projecting definition sentences into the vector space of
dictionary entries. We discover that this approach is not fully explored due to
the methodological limitation of using word embeddings of language models to
represent dictionary entries. This leads to two hindrances. First, dictionary
entries are constrained by the single-word vocabulary, and thus cannot be fully
exploited. Second, semantic representations of language models are known to be
anisotropic, but pre-processing word embeddings for DefSent is not allowed
because its weight is frozen during training and tied to the prediction layer.
In this paper, we propose a novel method to progressively build entry
embeddings not subject to the limitations. As a result, definition sentences
can be projected into a quasi-isotropic or isotropic vector space of unlimited
dictionary entries, so that sentence embeddings of noticeably better quality
are attainable. We abbreviate our approach as DefSent+ (a plus version of
DefSent), involving the following strengths: 1) the task performance on
measuring sentence similarities is significantly improved compared to DefSent;
2) when DefSent+ is used to further train data-augmented models like SIMCSE,
SNCSE, and SynCSE, state-of-the-art performance on measuring sentence
similarities can be achieved among the approaches without using manually
labeled datasets; 3) DefSent+ is also competitive in feature-based transfer for
NLP downstream tasks.",2024-05-25,Xiaodong Liu,http://arxiv.org/pdf/2405.16153v4,cs.LG
Accelerating Transformers with Spectrum-Preserving Token Merging,"Increasing the throughput of the Transformer architecture, a foundational
component used in numerous state-of-the-art models for vision and language
tasks (e.g., GPT, LLaVa), is an important problem in machine learning. One
recent and effective strategy is to merge token representations within
Transformer models, aiming to reduce computational and memory requirements
while maintaining accuracy. Prior works have proposed algorithms based on
Bipartite Soft Matching (BSM), which divides tokens into distinct sets and
merges the top k similar tokens. However, these methods have significant
drawbacks, such as sensitivity to token-splitting strategies and damage to
informative tokens in later layers. This paper presents a novel paradigm called
PiToMe, which prioritizes the preservation of informative tokens using an
additional metric termed the energy score. This score identifies large clusters
of similar tokens as high-energy, indicating potential candidates for merging,
while smaller (unique and isolated) clusters are considered as low-energy and
preserved. Experimental findings demonstrate that PiToMe saved from 40-60\%
FLOPs of the base models while exhibiting superior off-the-shelf performance on
image classification (0.5\% average performance drop of ViT-MAE-H compared to
2.6\% as baselines), image-text retrieval (0.3\% average performance drop of
CLIP on Flickr30k compared to 4.5\% as others), and analogously in visual
questions answering with LLaVa-7B. Furthermore, PiToMe is theoretically shown
to preserve intrinsic spectral properties of the original token space under
mild conditions",2024-05-25,"Hoai-Chau Tran, Duy M. H. Nguyen, Duy M. Nguyen, Trung-Tin Nguyen, Ngan Le, Pengtao Xie, Daniel Sonntag, James Y. Zou, Binh T. Nguyen, Mathias Niepert",http://arxiv.org/pdf/2405.16148v2,cs.LG
AIGB: Generative Auto-bidding via Conditional Diffusion Modeling,"Auto-bidding plays a crucial role in facilitating online advertising by
automatically providing bids for advertisers. Reinforcement learning (RL) has
gained popularity for auto-bidding. However, most current RL auto-bidding
methods are modeled through the Markovian Decision Process (MDP), which assumes
the Markovian state transition. This assumption restricts the ability to
perform in long horizon scenarios and makes the model unstable when dealing
with highly random online advertising environments. To tackle this issue, this
paper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding
through generative modeling. In this paradigm, we propose DiffBid, a
conditional diffusion modeling approach for bid generation. DiffBid directly
models the correlation between the return and the entire trajectory,
effectively avoiding error propagation across time steps in long horizons.
Additionally, DiffBid offers a versatile approach for generating trajectories
that maximize given targets while adhering to specific constraints. Extensive
experiments conducted on the real-world dataset and online A/B test on Alibaba
advertising platform demonstrate the effectiveness of DiffBid, achieving 2.81%
increase in GMV and 3.36% increase in ROI.",2024-05-25,"Jiayan Guo, Yusen Huo, Zhilin Zhang, Tianyu Wang, Chuan Yu, Jian Xu, Yan Zhang, Bo Zheng",http://arxiv.org/pdf/2405.16141v4,cs.LG
Expanded Gating Ranges Improve Activation Functions,"Activation functions are core components of all deep learning architectures.
Currently, the most popular activation functions are smooth ReLU variants like
GELU and SiLU. These are self-gated activation functions where the range of the
gating function is between zero and one. In this paper, we explore the
viability of using arctan as a gating mechanism. A self-gated activation
function that uses arctan as its gating function has a monotonically increasing
first derivative. To make this activation function competitive, it is necessary
to introduce a trainable parameter for every MLP block to expand the range of
the gating function beyond zero and one. We find that this technique also
improves existing self-gated activation functions. We conduct an empirical
evaluation of Expanded ArcTan Linear Unit (xATLU), Expanded GELU (xGELU), and
Expanded SiLU (xSiLU) and show that they outperform existing activation
functions within a transformer architecture. Additionally, expanded gating
ranges show promising results in improving first-order Gated Linear Units
(GLU).",2024-05-25,Allen Hao Huang,http://arxiv.org/pdf/2405.20768v1,cs.LG
C3LLM: Conditional Multimodal Content Generation Using Large Language Models,"We introduce C3LLM (Conditioned-on-Three-Modalities Large Language Models), a
novel framework combining three tasks of video-to-audio, audio-to-text, and
text-to-audio together. C3LLM adapts the Large Language Model (LLM) structure
as a bridge for aligning different modalities, synthesizing the given
conditional information, and making multimodal generation in a discrete manner.
Our contributions are as follows. First, we adapt a hierarchical structure for
audio generation tasks with pre-trained audio codebooks. Specifically, we train
the LLM to generate audio semantic tokens from the given conditions, and
further use a non-autoregressive transformer to generate different levels of
acoustic tokens in layers to better enhance the fidelity of the generated
audio. Second, based on the intuition that LLMs were originally designed for
discrete tasks with the next-word prediction method, we use the discrete
representation for audio generation and compress their semantic meanings into
acoustic tokens, similar to adding ""acoustic vocabulary"" to LLM. Third, our
method combines the previous tasks of audio understanding, video-to-audio
generation, and text-to-audio generation together into one unified model,
providing more versatility in an end-to-end fashion. Our C3LLM achieves
improved results through various automated evaluation metrics, providing better
semantic alignment compared to previous methods.",2024-05-25,"Zixuan Wang, Qinkai Duan, Yu-Wing Tai, Chi-Keung Tang",http://arxiv.org/pdf/2405.16136v1,cs.LG
Automating the Selection of Proxy Variables of Unmeasured Confounders,"Recently, interest has grown in the use of proxy variables of unobserved
confounding for inferring the causal effect in the presence of unmeasured
confounders from observational data. One difficulty inhibiting the practical
use is finding valid proxy variables of unobserved confounding to a target
causal effect of interest. These proxy variables are typically justified by
background knowledge. In this paper, we investigate the estimation of causal
effects among multiple treatments and a single outcome, all of which are
affected by unmeasured confounders, within a linear causal model, without prior
knowledge of the validity of proxy variables. To be more specific, we first
extend the existing proxy variable estimator, originally addressing a single
unmeasured confounder, to accommodate scenarios where multiple unmeasured
confounders exist between the treatments and the outcome. Subsequently, we
present two different sets of precise identifiability conditions for selecting
valid proxy variables of unmeasured confounders, based on the second-order
statistics and higher-order statistics of the data, respectively. Moreover, we
propose two data-driven methods for the selection of proxy variables and for
the unbiased estimation of causal effects. Theoretical analysis demonstrates
the correctness of our proposed algorithms. Experimental results on both
synthetic and real-world data show the effectiveness of the proposed approach.",2024-05-25,"Feng Xie, Zhengming Chen, Shanshan Luo, Wang Miao, Ruichu Cai, Zhi Geng",http://arxiv.org/pdf/2405.16130v1,cs.LG
Near-Optimal Distributed Minimax Optimization under the Second-Order Similarity,"This paper considers the distributed convex-concave minimax optimization
under the second-order similarity. We propose stochastic variance-reduced
optimistic gradient sliding (SVOGS) method, which takes the advantage of the
finite-sum structure in the objective by involving the mini-batch client
sampling and variance reduction. We prove SVOGS can achieve the
$\varepsilon$-duality gap within communication rounds of ${\mathcal O}(\delta
D^2/\varepsilon)$, communication complexity of ${\mathcal O}(n+\sqrt{n}\delta
D^2/\varepsilon)$, and local gradient calls of $\tilde{\mathcal
O}(n+(\sqrt{n}\delta+L)D^2/\varepsilon\log(1/\varepsilon))$, where $n$ is the
number of nodes, $\delta$ is the degree of the second-order similarity, $L$ is
the smoothness parameter and $D$ is the diameter of the constraint set. We can
verify that all of above complexity (nearly) matches the corresponding lower
bounds. For the specific $\mu$-strongly-convex-$\mu$-strongly-convex case, our
algorithm has the upper bounds on communication rounds, communication
complexity, and local gradient calls of $\mathcal
O(\delta/\mu\log(1/\varepsilon))$, ${\mathcal
O}((n+\sqrt{n}\delta/\mu)\log(1/\varepsilon))$, and $\tilde{\mathcal
O}(n+(\sqrt{n}\delta+L)/\mu)\log(1/\varepsilon))$ respectively, which are also
nearly tight. Furthermore, we conduct the numerical experiments to show the
empirical advantages of proposed method.",2024-05-25,"Qihao Zhou, Haishan Ye, Luo Luo",http://arxiv.org/pdf/2405.16126v1,cs.LG
Unsupervised Meta-Learning via In-Context Learning,"Unsupervised meta-learning aims to learn feature representations from
unsupervised datasets that can transfer to downstream tasks with limited
labeled data. In this paper, we propose a novel approach to unsupervised
meta-learning that leverages the generalization abilities of in-context
learning observed in transformer architectures. Our method reframes
meta-learning as a sequence modeling problem, enabling the transformer encoder
to learn task context from support images and utilize it to predict query
images. At the core of our approach lies the creation of diverse tasks
generated using a combination of data augmentations and a mixing strategy that
challenges the model during training while fostering generalization to unseen
tasks at test time. Experimental results on benchmark datasets showcase the
superiority of our approach over existing unsupervised meta-learning baselines,
establishing it as the new state-of-the-art. Remarkably, our method achieves
competitive results with supervised and self-supervised approaches,
underscoring its efficacy in leveraging generalization over memorization.",2024-05-25,"Anna Vettoruzzo, Lorenzo Braccaioli, Joaquin Vanschoren, Marlena Nowaczyk",http://arxiv.org/pdf/2405.16124v3,cs.LG
Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars,"Large language models (LLMs) have shown impressive capabilities in real-world
applications. The capability of in-context learning (ICL) allows us to adapt an
LLM to downstream tasks by including input-label exemplars in the prompt
without model fine-tuning. However, the quality of these exemplars in the
prompt greatly impacts performance, highlighting the need for an effective
automated exemplar selection method. Recent studies have explored
retrieval-based approaches to select exemplars tailored to individual test
queries, which can be undesirable due to extra test-time computation and an
increased risk of data exposure. Moreover, existing methods fail to adequately
account for the impact of exemplar ordering on the performance. On the other
hand, the impact of the instruction, another essential component in the prompt
given to the LLM, is often overlooked in existing exemplar selection methods.
To address these challenges, we propose a novel method named EASE, which
leverages the hidden embedding from a pre-trained language model to represent
ordered sets of exemplars and uses a neural bandit algorithm to optimize the
sets of exemplars while accounting for exemplar ordering. Our EASE can
efficiently find an ordered set of exemplars that performs well for all test
queries from a given task, thereby eliminating test-time computation.
Importantly, EASE can be readily extended to jointly optimize both the
exemplars and the instruction. Through extensive empirical evaluations
(including novel tasks), we demonstrate the superiority of EASE over existing
methods, and reveal practical insights about the impact of exemplar selection
on ICL, which may be of independent interest. Our code is available at
https://github.com/ZhaoxuanWu/EASE-Prompt-Optimization.",2024-05-25,"Zhaoxuan Wu, Xiaoqiang Lin, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2405.16122v2,cs.LG
Method and Software Tool for Generating Artificial Databases of Biomedical Images Based on Deep Neural Networks,"A wide variety of biomedical image data, as well as methods for generating
training images using basic deep neural networks, were analyzed. Additionally,
all platforms for creating images were analyzed, considering their
characteristics. The article develops a method for generating artificial
biomedical images based on GAN. GAN architecture has been developed for
biomedical image synthesis. The data foundation and module for generating
training images were designed and implemented in a software system. A
comparison of the generated image database with known databases was made.",2024-05-25,"Oleh Berezsky, Petro Liashchynskyi, Oleh Pitsun, Grygoriy Melnyk",http://arxiv.org/pdf/2405.16119v1,cs.LG
Beyond Primal-Dual Methods in Bandits with Stochastic and Adversarial Constraints,"We address a generalization of the bandit with knapsacks problem, where a
learner aims to maximize rewards while satisfying an arbitrary set of long-term
constraints. Our goal is to design best-of-both-worlds algorithms that perform
optimally under both stochastic and adversarial constraints. Previous works
address this problem via primal-dual methods, and require some stringent
assumptions, namely the Slater's condition, and in adversarial settings, they
either assume knowledge of a lower bound on the Slater's parameter, or impose
strong requirements on the primal and dual regret minimizers such as requiring
weak adaptivity. We propose an alternative and more natural approach based on
optimistic estimations of the constraints. Surprisingly, we show that
estimating the constraints with an UCB-like approach guarantees optimal
performances. Our algorithm consists of two main components: (i) a regret
minimizer working on \emph{moving strategy sets} and (ii) an estimate of the
feasible set as an optimistic weighted empirical mean of previous samples. The
key challenge in this approach is designing adaptive weights that meet the
different requirements for stochastic and adversarial constraints. Our
algorithm is significantly simpler than previous approaches, and has a cleaner
analysis. Moreover, ours is the first best-of-both-worlds algorithm providing
bounds logarithmic in the number of constraints. Additionally, in stochastic
settings, it provides $\widetilde O(\sqrt{T})$ regret \emph{without} Slater's
condition.",2024-05-25,"Martino Bernasconi, Matteo Castiglioni, Andrea Celli, Federico Fusco",http://arxiv.org/pdf/2405.16118v1,cs.LG
SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT clinical terminology,"The extraction and analysis of insights from medical data, primarily stored
in free-text formats by healthcare workers, presents significant challenges due
to its unstructured nature. Medical coding, a crucial process in healthcare,
remains minimally automated due to the complexity of medical ontologies and
restricted access to medical texts for training Natural Language Processing
models. In this paper, we proposed a method, ""SNOBERT,"" of linking text spans
in clinical notes to specific concepts in the SNOMED CT using BERT-based
models. The method consists of two stages: candidate selection and candidate
matching. The models were trained on one of the largest publicly available
dataset of labeled clinical notes. SNOBERT outperforms other classical methods
based on deep learning, as confirmed by the results of a challenge in which it
was applied.",2024-05-25,"Mikhail Kulyabin, Gleb Sokolov, Aleksandr Galaida, Andreas Maier, Tomas Arias-Vergara",http://arxiv.org/pdf/2405.16115v1,cs.LG
Multi-scale Quaternion CNN and BiGRU with Cross Self-attention Feature Fusion for Fault Diagnosis of Bearing,"In recent years, deep learning has led to significant advances in bearing
fault diagnosis (FD). Most techniques aim to achieve greater accuracy. However,
they are sensitive to noise and lack robustness, resulting in insufficient
domain adaptation and anti-noise ability. The comparison of studies reveals
that giving equal attention to all features does not differentiate their
significance. In this work, we propose a novel FD model by integrating
multi-scale quaternion convolutional neural network (MQCNN), bidirectional
gated recurrent unit (BiGRU), and cross self-attention feature fusion (CSAFF).
We have developed innovative designs in two modules, namely MQCNN and CSAFF.
Firstly, MQCNN applies quaternion convolution to multi-scale architecture for
the first time, aiming to extract the rich hidden features of the original
signal from multiple scales. Then, the extracted multi-scale information is
input into CSAFF for feature fusion, where CSAFF innovatively incorporates
cross self-attention mechanism to enhance discriminative interaction
representation within features. Finally, BiGRU captures temporal dependencies
while a softmax layer is employed for fault classification, achieving accurate
FD. To assess the efficacy of our approach, we experiment on three public
datasets (CWRU, MFPT, and Ottawa) and compare it with other excellent methods.
The results confirm its state-of-the-art, which the average accuracies can
achieve up to 99.99%, 100%, and 99.21% on CWRU, MFPT, and Ottawa datasets.
Moreover, we perform practical tests and ablation experiments to validate the
efficacy and robustness of the proposed approach. Code is available at
https://github.com/mubai011/MQCCAF.",2024-05-25,"Huanbai Liu, Fanlong Zhang, Yin Tan, Lian Huang, Yan Li, Guoheng Huang, Shenghong Luo, An Zeng",http://arxiv.org/pdf/2405.16114v1,cs.LG
Enabling On-Device Learning via Experience Replay with Efficient Dataset Condensation,"Upon deployment to edge devices, it is often desirable for a model to further
learn from streaming data to improve accuracy. However, extracting
representative features from such data is challenging because it is typically
unlabeled, non-independent and identically distributed (non-i.i.d), and is seen
only once. To mitigate this issue, a common strategy is to maintain a small
data buffer on the edge device to hold the most representative data for further
learning. As most data is either never stored or quickly discarded, identifying
the most representative data to avoid significant information loss becomes
critical. In this paper, we propose an on-device framework that addresses this
issue by condensing incoming data into more informative samples. Specifically,
to effectively handle unlabeled incoming data, we propose a pseudo-labeling
technique designed for unlabeled on-device learning environments. Additionally,
we develop a dataset condensation technique that only requires little
computation resources. To counteract the effects of noisy labels during the
condensation process, we further utilize a contrastive learning objective to
improve the purity of class data within the buffer. Our empirical results
indicate substantial improvements over existing methods, particularly when
buffer capacity is severely restricted. For instance, with a buffer capacity of
just one sample per class, our method achieves an accuracy that outperforms the
best existing baseline by 58.4% on the CIFAR-10 dataset.",2024-05-25,"Gelei Xu, Ningzhi Tang, Jun Xia, Wei Jin, Yiyu Shi",http://arxiv.org/pdf/2405.16113v1,cs.LG
Global Well-posedness and Convergence Analysis of Score-based Generative Models via Sharp Lipschitz Estimates,"We establish global well-posedness and convergence of the score-based
generative models (SGM) under minimal general assumptions of initial data for
score estimation. For the smooth case, we start from a Lipschitz bound of the
score function with optimal time length. The optimality is validated by an
example whose Lipschitz constant of scores is bounded at initial but blows up
in finite time. This necessitates the separation of time scales in conventional
bounds for non-log-concave distributions. In contrast, our follow up analysis
only relies on a local Lipschitz condition and is valid globally in time. This
leads to the convergence of numerical scheme without time separation. For the
non-smooth case, we show that the optimal Lipschitz bound is O(1/t) in the
point-wise sense for distributions supported on a compact, smooth and
low-dimensional manifold with boundary.",2024-05-25,"Connor Mooney, Zhongjian Wang, Jack Xin, Yifeng Yu",http://arxiv.org/pdf/2405.16104v1,cs.LG
Overcoming Negative Transfer by Online Selection: Distant Domain Adaptation for Fault Diagnosis,"Unsupervised domain adaptation (UDA) has achieved remarkable success in fault
diagnosis, bringing significant benefits to diverse industrial applications.
While most UDA methods focus on cross-working condition scenarios where the
source and target domains are notably similar, real-world applications often
grapple with severe domain shifts. We coin the term `distant domain adaptation
problem' to describe the challenge of adapting from a labeled source domain to
a significantly disparate unlabeled target domain. This problem exhibits the
risk of negative transfer, where extraneous knowledge from the source domain
adversely affects the target domain performance. Unfortunately, conventional
UDA methods often falter in mitigating this negative transfer, leading to
suboptimal performance. In response to this challenge, we propose a novel
Online Selective Adversarial Alignment (OSAA) approach. Central to OSAA is its
ability to dynamically identify and exclude distant source samples via an
online gradient masking approach, focusing primarily on source samples that
closely resemble the target samples. Furthermore, recognizing the inherent
complexities in bridging the source and target domains, we construct an
intermediate domain to act as a transitional domain and ease the adaptation
process. Lastly, we develop a class-conditional adversarial adaptation to
address the label distribution disparities while learning domain invariant
representation to account for potential label distribution disparities between
the domains. Through detailed experiments and ablation studies on two
real-world datasets, we validate the superior performance of the OSAA method
over state-of-the-art methods, underscoring its significant utility in
practical scenarios with severe domain shifts.",2024-05-25,"Ziyan Wang, Mohamed Ragab, Wenmian Yang, Min Wu, Sinno Jialin Pan, Jie Zhang, Zhenghua Chen",http://arxiv.org/pdf/2405.17493v1,cs.LG
Estimating the normal-inverse-Wishart distribution,"The normal-inverse-Wishart (NIW) distribution is commonly used as a prior
distribution for the mean and covariance parameters of a multivariate normal
distribution. The family of NIW distributions is also a minimal exponential
family. In this short note we describe a convergent procedure for converting
from mean parameters to natural parameters in the NIW family, or --
equivalently -- for performing maximum likelihood estimation of the natural
parameters given observed sufficient statistics. This is needed, for example,
when using a NIW base family in expectation propagation.",2024-05-25,Jonathan So,http://arxiv.org/pdf/2405.16088v2,cs.LG
From Orthogonality to Dependency: Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals,"Existing methods for multi-modal time series representation learning aim to
disentangle the modality-shared and modality-specific latent variables.
Although achieving notable performances on downstream tasks, they usually
assume an orthogonal latent space. However, the modality-specific and
modality-shared latent variables might be dependent on real-world scenarios.
Therefore, we propose a general generation process, where the modality-shared
and modality-specific latent variables are dependent, and further develop a
\textbf{M}ulti-mod\textbf{A}l \textbf{TE}mporal Disentanglement (\textbf{MATE})
model. Specifically, our \textbf{MATE} model is built on a temporally
variational inference architecture with the modality-shared and
modality-specific prior networks for the disentanglement of latent variables.
Furthermore, we establish identifiability results to show that the extracted
representation is disentangled. More specifically, we first achieve the
subspace identifiability for modality-shared and modality-specific latent
variables by leveraging the pairing of multi-modal data. Then we establish the
component-wise identifiability of modality-specific latent variables by
employing sufficient changes of historical latent variables. Extensive
experimental studies on multi-modal sensors, human activity recognition, and
healthcare datasets show a general improvement in different downstream tasks,
highlighting the effectiveness of our method in real-world scenarios.",2024-05-25,"Ruichu Cai, Zhifang Jiang, Zijian Li, Weilin Chen, Xuexin Chen, Zhifeng Hao, Yifan Shen, Guangyi Chen, Kun Zhang",http://arxiv.org/pdf/2405.16083v1,cs.LG
Theoretical Study of Conflict-Avoidant Multi-Objective Reinforcement Learning,"Multi-task reinforcement learning (MTRL) has shown great promise in many
real-world applications. Existing MTRL algorithms often aim to learn a policy
that optimizes individual objective functions simultaneously with a given prior
preference (or weights) on different tasks. However, these methods often suffer
from the issue of \textit{gradient conflict} such that the tasks with larger
gradients dominate the update direction, resulting in a performance
degeneration on other tasks. In this paper, we develop a novel dynamic
weighting multi-task actor-critic algorithm (MTAC) under two options of
sub-procedures named as CA and FC in task weight updates. MTAC-CA aims to find
a conflict-avoidant (CA) update direction that maximizes the minimum value
improvement among tasks, and MTAC-FC targets at a much faster convergence rate.
We provide a comprehensive finite-time convergence analysis for both
algorithms. We show that MTAC-CA can find a
$\epsilon+\epsilon_{\text{app}}$-accurate Pareto stationary policy using
$\mathcal{O}({\epsilon^{-5}})$ samples, while ensuring a small
$\epsilon+\sqrt{\epsilon_{\text{app}}}$-level CA distance (defined as the
distance to the CA direction), where $\epsilon_{\text{app}}$ is the function
approximation error. The analysis also shows that MTAC-FC improves the sample
complexity to $\mathcal{O}(\epsilon^{-3})$, but with a constant-level CA
distance. Our experiments on MT10 demonstrate the improved performance of our
algorithms over existing MTRL methods with fixed preference.",2024-05-25,"Yudan Wang, Peiyao Xiao, Hao Ban, Kaiyi Ji, Shaofeng Zou",http://arxiv.org/pdf/2405.16077v3,cs.LG
Continuous Temporal Domain Generalization,"Temporal Domain Generalization (TDG) addresses the challenge of training
predictive models under temporally varying data distributions. Traditional TDG
approaches typically focus on domain data collected at fixed, discrete time
intervals, which limits their capability to capture the inherent dynamics
within continuous-evolving and irregularly-observed temporal domains. To
overcome this, this work formalizes the concept of Continuous Temporal Domain
Generalization (CTDG), where domain data are derived from continuous times and
are collected at arbitrary times. CTDG tackles critical challenges including:
1) Characterizing the continuous dynamics of both data and models, 2) Learning
complex high-dimensional nonlinear dynamics, and 3) Optimizing and controlling
the generalization across continuous temporal domains. To address them, we
propose a Koopman operator-driven continuous temporal domain generalization
(Koodos) framework. We formulate the problem within a continuous dynamic system
and leverage the Koopman theory to learn the underlying dynamics; the framework
is further enhanced with a comprehensive optimization strategy equipped with
analysis and control driven by prior knowledge of the dynamics patterns.
Extensive experiments demonstrate the effectiveness and efficiency of our
approach. The code can be found at: https://github.com/Zekun-Cai/Koodos.",2024-05-25,"Zekun Cai, Guangji Bai, Renhe Jiang, Xuan Song, Liang Zhao",http://arxiv.org/pdf/2405.16075v2,cs.LG
IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark,"Evaluating observational estimators of causal effects demands information
that is rarely available: unconfounded interventions and outcomes from the
population of interest, created either by randomization or adjustment. As a
result, it is customary to fall back on simulators when creating benchmark
tasks. Simulators offer great control but are often too simplistic to make
challenging tasks, either because they are hand-designed and lack the nuances
of real-world data, or because they are fit to observational data without
structural constraints. In this work, we propose a general, repeatable strategy
for turning observational data into sequential structural causal models and
challenging estimation tasks by following two simple principles: 1) fitting
real-world data where possible, and 2) creating complexity by composing simple,
hand-designed mechanisms. We implement these ideas in a highly configurable
software package and apply it to the well-known Adult income data set to
construct the IncomeSCM simulator. From this, we devise multiple estimation
tasks and sample data sets to compare established estimators of causal effects.
The tasks present a suitable challenge, with effect estimates varying greatly
in quality between methods, despite similar performance in the modeling of
factual outcomes, highlighting the need for dedicated causal estimators and
model selection criteria.",2024-05-25,Fredrik D. Johansson,http://arxiv.org/pdf/2405.16069v3,cs.LG
SPP: Sparsity-Preserved Parameter-Efficient Fine-Tuning for Large Language Models,"Large Language Models (LLMs) have become pivotal in advancing the field of
artificial intelligence, yet their immense sizes pose significant challenges
for both fine-tuning and deployment. Current post-training pruning methods,
while reducing the sizes of LLMs, often fail to maintain their original
performance. To address these challenges, this paper introduces SPP, a
Sparsity-Preserved Parameter-efficient fine-tuning method. Different from
existing post-training pruning approaches that struggle with performance
retention, SPP proposes to employ lightweight learnable column and row matrices
to optimize sparse LLM weights, keeping the structure and sparsity of pruned
pre-trained models intact. By element-wise multiplication and residual
addition, SPP ensures the consistency of model sparsity pattern and ratio
during both training and weight-merging processes. We demonstrate the
effectiveness of SPP by applying it to the LLaMA and LLaMA-2 model families
with recent post-training pruning methods. Our results show that SPP
significantly enhances the performance of models with different sparsity
patterns (i.e. unstructured and N:M sparsity), especially for those with high
sparsity ratios (e.g. 75%), making it a promising solution for the efficient
fine-tuning of sparse LLMs. Code will be made available at
https://github.com/Lucky-Lance/SPP.",2024-05-25,"Xudong Lu, Aojun Zhou, Yuhui Xu, Renrui Zhang, Peng Gao, Hongsheng Li",http://arxiv.org/pdf/2405.16057v1,cs.LG
FedSheafHN: Personalized Federated Learning on Graph-structured Data,"Personalized subgraph Federated Learning (FL) is a task that customizes Graph
Neural Networks (GNNs) to individual client needs, accommodating diverse data
distributions. However, applying hypernetworks in FL, while aiming to
facilitate model personalization, often encounters challenges due to inadequate
representation of client-specific characteristics. To overcome these
limitations, we propose a model called FedSheafHN, using enhanced collaboration
graph embedding and efficient personalized model parameter generation.
Specifically, our model embeds each client's local subgraph into a
server-constructed collaboration graph. We utilize sheaf diffusion in the
collaboration graph to learn client representations. Our model improves the
integration and interpretation of complex client characteristics. Furthermore,
our model ensures the generation of personalized models through advanced
hypernetworks optimized for parallel operations across clients. Empirical
evaluations demonstrate that FedSheafHN outperforms existing methods in most
scenarios, in terms of client model performance on various graph-structured
datasets. It also has fast model convergence and effective new clients
generalization.",2024-05-25,"Wenfei Liang, Yanan Zhao, Rui She, Yiming Li, Wee Peng Tay",http://arxiv.org/pdf/2405.16056v3,cs.LG
Federated Learning for Non-factorizable Models using Deep Generative Prior Approximations,"Federated learning (FL) allows for collaborative model training across
decentralized clients while preserving privacy by avoiding data sharing.
However, current FL methods assume conditional independence between client
models, limiting the use of priors that capture dependence, such as Gaussian
processes (GPs). We introduce the Structured Independence via deep Generative
Model Approximation (SIGMA) prior which enables FL for non-factorizable models
across clients, expanding the applicability of FL to fields such as spatial
statistics, epidemiology, environmental science, and other domains where
modeling dependencies is crucial. The SIGMA prior is a pre-trained deep
generative model that approximates the desired prior and induces a specified
conditional independence structure in the latent variables, creating an
approximate model suitable for FL settings. We demonstrate the SIGMA prior's
effectiveness on synthetic data and showcase its utility in a real-world
example of FL for spatial data, using a conditional autoregressive prior to
model spatial dependence across Australia. Our work enables new FL applications
in domains where modeling dependent data is essential for accurate predictions
and decision-making.",2024-05-25,"Conor Hassan, Joshua J Bon, Elizaveta Semenova, Antonietta Mira, Kerrie Mengersen",http://arxiv.org/pdf/2405.16055v1,cs.LG
Pausing Policy Learning in Non-stationary Reinforcement Learning,"Real-time inference is a challenge of real-world reinforcement learning due
to temporal differences in time-varying environments: the system collects data
from the past, updates the decision model in the present, and deploys it in the
future. We tackle a common belief that continually updating the decision is
optimal to minimize the temporal gap. We propose forecasting an online
reinforcement learning framework and show that strategically pausing decision
updates yields better overall performance by effectively managing aleatoric
uncertainty. Theoretically, we compute an optimal ratio between policy update
and hold duration, and show that a non-zero policy hold duration provides a
sharper upper bound on the dynamic regret. Our experimental evaluations on
three different environments also reveal that a non-zero policy hold duration
yields higher rewards compared to continuous decision updates.",2024-05-25,"Hyunin Lee, Ming Jin, Javad Lavaei, Somayeh Sojoudi",http://arxiv.org/pdf/2405.16053v1,cs.LG
A Bi-Objective Approach to Last-Mile Delivery Routing Considering Driver Preferences,"The Multi-Objective Vehicle Routing Problem (MOVRP) is a complex optimization
problem in the transportation and logistics industry. This paper proposes a
novel approach to the MOVRP that aims to create routes that consider drivers'
and operators' decisions and preferences. We evaluate two approaches to address
this objective: visually attractive route planning and data mining of
historical driver behavior to plan similar routes. Using a real-world dataset
provided by Amazon, we demonstrate that data mining of historical patterns is
more effective than visual attractiveness metrics found in the literature.
Furthermore, we propose a bi-objective problem to balance the similarity of
routes to historical routes and minimize routing costs. We propose a two-stage
GRASP algorithm with heuristic box splitting to solve this problem. The
proposed algorithm aims to approximate the Pareto front and to present routes
that cover a wide range of the objective function space. The results
demonstrate that our approach can generate a small number of non-dominated
solutions per instance, which can help decision-makers to identify trade-offs
between routing costs and drivers' preferences. Our approach has the potential
to enhance the last-mile delivery operations of logistics companies by
balancing these conflicting objectives.",2024-05-25,"Juan Pablo Mesa, Alejandro Montoya, Raul Ramos-Pollán, Mauricio Toro",http://arxiv.org/pdf/2405.16051v1,cs.LG
Theoretical Analysis of Weak-to-Strong Generalization,"Strong student models can learn from weaker teachers: when trained on the
predictions of a weaker model, a strong pretrained student can learn to correct
the weak model's errors and generalize to examples where the teacher is not
confident, even when these examples are excluded from training. This enables
learning from cheap, incomplete, and possibly incorrect label information, such
as coarse logical rules or the generations of a language model. We show that
existing weak supervision theory fails to account for both of these effects,
which we call pseudolabel correction and coverage expansion, respectively. We
give a new bound based on expansion properties of the data distribution and
student hypothesis class that directly accounts for pseudolabel correction and
coverage expansion. Our bounds capture the intuition that weak-to-strong
generalization occurs when the strong model is unable to fit the mistakes of
the weak teacher without incurring additional error. We show that these
expansion properties can be checked from finite data and give empirical
evidence that they hold in practice.",2024-05-25,"Hunter Lang, David Sontag, Aravindan Vijayaraghavan",http://arxiv.org/pdf/2405.16043v1,cs.LG
"Revisit, Extend, and Enhance Hessian-Free Influence Functions","Influence functions serve as crucial tools for assessing sample influence in
model interpretation, subset training set selection, noisy label detection, and
more. By employing the first-order Taylor extension, influence functions can
estimate sample influence without the need for expensive model retraining.
However, applying influence functions directly to deep models presents
challenges, primarily due to the non-convex nature of the loss function and the
large size of model parameters. This difficulty not only makes computing the
inverse of the Hessian matrix costly but also renders it non-existent in some
cases. Various approaches, including matrix decomposition, have been explored
to expedite and approximate the inversion of the Hessian matrix, with the aim
of making influence functions applicable to deep models. In this paper, we
revisit a specific, albeit naive, yet effective approximation method known as
TracIn. This method substitutes the inverse of the Hessian matrix with an
identity matrix. We provide deeper insights into why this simple approximation
method performs well. Furthermore, we extend its applications beyond measuring
model utility to include considerations of fairness and robustness. Finally, we
enhance TracIn through an ensemble strategy. To validate its effectiveness, we
conduct experiments on synthetic data and extensive evaluations on noisy label
detection, sample selection for large language model fine-tuning, and defense
against adversarial attacks.",2024-05-25,"Ziao Yang, Han Yue, Jian Chen, Hongfu Liu",http://arxiv.org/pdf/2405.17490v2,cs.LG
Explainable Molecular Property Prediction: Aligning Chemical Concepts with Predictions via Language Models,"Providing explainable molecular property predictions is critical for many
scientific domains, such as drug discovery and material science. Though
transformer-based language models have shown great potential in accurate
molecular property prediction, they neither provide chemically meaningful
explanations nor faithfully reveal the molecular structure-property
relationships. In this work, we develop a framework for explainable molecular
property prediction based on language models, dubbed as Lamole, which can
provide chemical concepts-aligned explanations. We take a string-based
molecular representation -- Group SELFIES -- as input tokens to pretrain and
fine-tune our Lamole, as it provides chemically meaningful semantics. By
disentangling the information flows of Lamole, we propose combining
self-attention weights and gradients for better quantification of each
chemically meaningful substructure's impact on the model's output. To make the
explanations more faithfully respect the structure-property relationship, we
then carefully craft a marginal loss to explicitly optimize the explanations to
be able to align with the chemists' annotations. We bridge the manifold
hypothesis with the elaborated marginal loss to prove that the loss can align
the explanations with the tangent space of the data manifold, leading to
concept-aligned explanations. Experimental results over six mutagenicity
datasets and one hepatotoxicity dataset demonstrate Lamole can achieve
comparable classification accuracy and boost the explanation accuracy by up to
14.3%, being the state-of-the-art in explainable molecular property prediction.",2024-05-25,"Zhenzhong Wang, Zehui Lin, Wanyu Lin, Ming Yang, Minggang Zeng, Kay Chen Tan",http://arxiv.org/pdf/2405.16041v3,cs.LG
On the Inflation of KNN-Shapley Value,"Shapley value-based data valuation methods, originating from cooperative game
theory, quantify the usefulness of each individual sample by considering its
contribution to all possible training subsets. Despite their extensive
applications, these methods encounter the challenge of value inflation - while
samples with negative Shapley values are detrimental, some with positive values
can also be harmful. This challenge prompts two fundamental questions: the
suitability of zero as a threshold for distinguishing detrimental from
beneficial samples and the determination of an appropriate threshold. To
address these questions, we focus on KNN-Shapley and propose Calibrated
KNN-Shapley (CKNN-Shapley), which calibrates zero as the threshold to
distinguish detrimental samples from beneficial ones by mitigating the negative
effects of small-sized training subsets. Through extensive experiments, we
demonstrate the effectiveness of CKNN-Shapley in alleviating data valuation
inflation, detecting detrimental samples, and assessing data quality. We also
extend our approach beyond conventional classification settings, applying it to
diverse and practical scenarios such as learning with mislabeled data, online
learning with stream data, and active learning for label annotation.",2024-05-25,"Ziao Yang, Han Yue, Jian Chen, Hongfu Liu",http://arxiv.org/pdf/2405.17489v1,cs.LG
MoEUT: Mixture-of-Experts Universal Transformers,"Previous work on Universal Transformers (UTs) has demonstrated the importance
of parameter sharing across layers. By allowing recurrence in depth, UTs have
advantages over standard Transformers in learning compositional
generalizations, but layer-sharing comes with a practical limitation of
parameter-compute ratio: it drastically reduces the parameter count compared to
the non-shared model with the same dimensionality. Naively scaling up the layer
size to compensate for the loss of parameters makes its computational resource
requirements prohibitive. In practice, no previous work has succeeded in
proposing a shared-layer Transformer design that is competitive in parameter
count-dominated tasks such as language modeling. Here we propose MoEUT
(pronounced ""moot""), an effective mixture-of-experts (MoE)-based shared-layer
Transformer architecture, which combines several recent advances in MoEs for
both feedforward and attention layers of standard Transformers together with
novel layer-normalization and grouping schemes that are specific and crucial to
UTs. The resulting UT model, for the first time, slightly outperforms standard
Transformers on language modeling tasks such as BLiMP and PIQA, while using
significantly less compute and memory.",2024-05-25,"Róbert Csordás, Kazuki Irie, Jürgen Schmidhuber, Christopher Potts, Christopher D. Manning",http://arxiv.org/pdf/2405.16039v2,cs.LG
Certifying Adapters: Enabling and Enhancing the Certification of Classifier Adversarial Robustness,"Randomized smoothing has become a leading method for achieving certified
robustness in deep classifiers against l_{p}-norm adversarial perturbations.
Current approaches for achieving certified robustness, such as data
augmentation with Gaussian noise and adversarial training, require expensive
training procedures that tune large models for different Gaussian noise levels
and thus cannot leverage high-performance pre-trained neural networks. In this
work, we introduce a novel certifying adapters framework (CAF) that enables and
enhances the certification of classifier adversarial robustness. Our approach
makes few assumptions about the underlying training algorithm or feature
extractor and is thus broadly applicable to different feature extractor
architectures (e.g., convolutional neural networks or vision transformers) and
smoothing algorithms. We show that CAF (a) enables certification in uncertified
models pre-trained on clean datasets and (b) substantially improves the
performance of certified classifiers via randomized smoothing and SmoothAdv at
multiple radii in CIFAR-10 and ImageNet. We demonstrate that CAF achieves
improved certified accuracies when compared to methods based on random or
denoised smoothing, and that CAF is insensitive to certifying adapter
hyperparameters. Finally, we show that an ensemble of adapters enables a single
pre-trained feature extractor to defend against a range of noise perturbation
scales.",2024-05-25,"Jieren Deng, Hanbin Hong, Aaron Palmer, Xin Zhou, Jinbo Bi, Kaleel Mahmood, Yuan Hong, Derek Aguiar",http://arxiv.org/pdf/2405.16036v1,cs.LG
Constrained Ensemble Exploration for Unsupervised Skill Discovery,"Unsupervised Reinforcement Learning (RL) provides a promising paradigm for
learning useful behaviors via reward-free per-training. Existing methods for
unsupervised RL mainly conduct empowerment-driven skill discovery or
entropy-based exploration. However, empowerment often leads to static skills,
and pure exploration only maximizes the state coverage rather than learning
useful behaviors. In this paper, we propose a novel unsupervised RL framework
via an ensemble of skills, where each skill performs partition exploration
based on the state prototypes. Thus, each skill can explore the clustered area
locally, and the ensemble skills maximize the overall state coverage. We adopt
state-distribution constraints for the skill occupancy and the desired cluster
for learning distinguishable skills. Theoretical analysis is provided for the
state entropy and the resulting skill distributions. Based on extensive
experiments on several challenging tasks, we find our method learns
well-explored ensemble skills and achieves superior performance in various
downstream tasks compared to previous methods.",2024-05-25,"Chenjia Bai, Rushuai Yang, Qiaosheng Zhang, Kang Xu, Yi Chen, Ting Xiao, Xuelong Li",http://arxiv.org/pdf/2405.16030v1,cs.LG
Online Resource Allocation for Edge Intelligence with Colocated Model Retraining and Inference,"With edge intelligence, AI models are increasingly pushed to the edge to
serve ubiquitous users. However, due to the drift of model, data, and task, AI
model deployed at the edge suffers from degraded accuracy in the inference
serving phase. Model retraining handles such drifts by periodically retraining
the model with newly arrived data. When colocating model retraining and model
inference serving for the same model on resource-limited edge servers, a
fundamental challenge arises in balancing the resource allocation for model
retraining and inference, aiming to maximize long-term inference accuracy. This
problem is particularly difficult due to the underlying mathematical
formulation being time-coupled, non-convex, and NP-hard. To address these
challenges, we introduce a lightweight and explainable online approximation
algorithm, named ORRIC, designed to optimize resource allocation for adaptively
balancing the accuracy of model training and inference. The competitive ratio
of ORRIC outperforms that of the traditional Inference-Only paradigm,
especially when data drift persists for a sufficiently lengthy time. This
highlights the advantages and applicable scenarios of colocating model
retraining and inference. Notably, ORRIC can be translated into several
heuristic algorithms for different resource environments. Experiments conducted
in real scenarios validate the effectiveness of ORRIC.",2024-05-25,"Huaiguang Cai, Zhi Zhou, Qianyi Huang",http://arxiv.org/pdf/2405.16029v1,cs.LG
Feature Protection For Out-of-distribution Generalization,"With the availability of large pre-trained models, a modern workflow for
building real-world machine learning solutions is to fine-tune such models on a
downstream task with a relatively small domain-specific dataset. In such
applications, one major challenge is that the small fine-tuning dataset does
not have sufficient coverage of the distribution encountered when the model is
deployed. It is thus important to design fine-tuning methods that are robust to
out-of-distribution (OOD) data that are under-represented by the training data.
This paper compares common fine-tuning methods to investigate their OOD
performance and demonstrates that standard methods will result in a significant
change to the pre-trained model so that the fine-tuned features overfit the
fine-tuning dataset. However, this causes deteriorated OOD performance. To
overcome this issue, we show that protecting pre-trained features leads to a
fine-tuned model more robust to OOD generalization. We validate the feature
protection methods with extensive experiments of fine-tuning CLIP on ImageNet
and DomainNet.",2024-05-25,"Lu Tan, Huei Zhou, Yinxiang Huang, Zeming Zheng, Yujiu Yang",http://arxiv.org/pdf/2405.16027v1,cs.LG
Convergence Behavior of an Adversarial Weak Supervision Method,"Labeling data via rules-of-thumb and minimal label supervision is central to
Weak Supervision, a paradigm subsuming subareas of machine learning such as
crowdsourced learning and semi-supervised ensemble learning. By using this
labeled data to train modern machine learning methods, the cost of acquiring
large amounts of hand labeled data can be ameliorated. Approaches to combining
the rules-of-thumb falls into two camps, reflecting different ideologies of
statistical estimation. The most common approach, exemplified by the
Dawid-Skene model, is based on probabilistic modeling. The other, developed in
the work of Balsubramani-Freund and others, is adversarial and game-theoretic.
We provide a variety of statistical results for the adversarial approach under
log-loss: we characterize the form of the solution, relate it to logistic
regression, demonstrate consistency, and give rates of convergence. On the
other hand, we find that probabilistic approaches for the same model class can
fail to be consistent. Experimental results are provided to corroborate the
theoretical results.",2024-05-25,"Steven An, Sanjoy Dasgupta",http://arxiv.org/pdf/2405.16013v1,cs.LG
Pessimistic Backward Policy for GFlowNets,"This paper studies Generative Flow Networks (GFlowNets), which learn to
sample objects proportionally to a given reward function through the trajectory
of state transitions. In this work, we observe that GFlowNets tend to
under-exploit the high-reward objects due to training on insufficient number of
trajectories, which may lead to a large gap between the estimated flow and the
(known) reward value. In response to this challenge, we propose a pessimistic
backward policy for GFlowNets (PBP-GFN), which maximizes the observed flow to
align closely with the true reward for the object. We extensively evaluate
PBP-GFN across eight benchmarks, including hyper-grid environment, bag
generation, structured set generation, molecular generation, and four RNA
sequence generation tasks. In particular, PBP-GFN enhances the discovery of
high-reward objects, maintains the diversity of the objects, and consistently
outperforms existing methods.",2024-05-25,"Hyosoon Jang, Yunhui Jang, Minsu Kim, Jinkyoo Park, Sungsoo Ahn",http://arxiv.org/pdf/2405.16012v3,cs.LG
Disentangling Heterogeneous Knowledge Concept Embedding for Cognitive Diagnosis on Untested Knowledge,"Cognitive diagnosis is a fundamental and critical task in learning
assessment, which aims to infer students' proficiency on knowledge concepts
from their response logs. Current works assume each knowledge concept will
certainly be tested and covered by multiple exercises. However, whether online
or offline courses, it's hardly feasible to completely cover all knowledge
concepts in several exercises. Restricted tests lead to undiscovered knowledge
deficits, especially untested knowledge concepts(UKCs). In this paper, we
propose a novel framework for Cognitive Diagnosis called Disentangling
Heterogeneous Knowledge Cognitive Diagnosis(DisKCD) on untested knowledge.
Specifically, we leverage course grades, exercise questions, and learning
resources to learn the potential representations of students, exercises, and
knowledge concepts. In particular, knowledge concepts are disentangled into
tested and untested based on the limiting actual exercises. We construct a
heterogeneous relation graph network via students, exercises, tested knowledge
concepts(TKCs), and UKCs. Then, through a hierarchical heterogeneous
message-passing mechanism, the fine-grained relations are incorporated into the
embeddings of the entities. Finally, the embeddings will be applied to multiple
existing cognitive diagnosis models to infer students' proficiency on UKCs.
Experimental results on real-world datasets show that the proposed model can
effectively improve the performance of the task of diagnosing students'
proficiency on UKCs. Our code is available at
https://github.com/Hubuers/DisKCD.",2024-05-25,"Miao Zhang, Ziming Wang, Runtian Xing, Kui Xiao, Zhifei Li, Yan Zhang, Chang Tang",http://arxiv.org/pdf/2405.16003v2,cs.LG
Does SGD really happen in tiny subspaces?,"Understanding the training dynamics of deep neural networks is challenging
due to their high-dimensional nature and intricate loss landscapes. Recent
studies have revealed that, along the training trajectory, the gradient
approximately aligns with a low-rank top eigenspace of the training loss
Hessian, referred to as the dominant subspace. Given this alignment, this paper
explores whether neural networks can be trained within the dominant subspace,
which, if feasible, could lead to more efficient training methods. Our primary
observation is that when the SGD update is projected onto the dominant
subspace, the training loss does not decrease further. This suggests that the
observed alignment between the gradient and the dominant subspace is spurious.
Surprisingly, projecting out the dominant subspace proves to be just as
effective as the original update, despite removing the majority of the original
update component. We observe similar behavior across practical setups,
including the large learning rate regime (also known as Edge of Stability),
Sharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the
main causes and implications of this spurious alignment, shedding light on the
dynamics of neural network training.",2024-05-25,"Minhak Song, Kwangjun Ahn, Chulhee Yun",http://arxiv.org/pdf/2405.16002v3,cs.LG
Carnatic Raga Identification System using Rigorous Time-Delay Neural Network,"Large scale machine learning-based Raga identification continues to be a
nontrivial issue in the computational aspects behind Carnatic music. Each raga
consists of many unique and intrinsic melodic patterns that can be used to
easily identify them from others. These ragas can also then be used to cluster
songs within the same raga, as well as identify songs in other closely related
ragas. In this case, the input sound is analyzed using a combination of steps
including using a Discrete Fourier transformation and using Triangular
Filtering to create custom bins of possible notes, extracting features from the
presence of particular notes or lack thereof. Using a combination of Neural
Networks including 1D Convolutional Neural Networks conventionally known as
Time-Delay Neural Networks) and Long Short-Term Memory (LSTM), which are a form
of Recurrent Neural Networks, the backbone of the classification strategy to
build the model can be created. In addition, to help with variations in shruti,
a long-time attention-based mechanism will be implemented to determine the
relative changes in frequency rather than the absolute differences. This will
provide a much more meaningful data point when training audio clips in
different shrutis. To evaluate the accuracy of the classifier, a dataset of 676
recordings is used. The songs are distributed across the list of ragas. The
goal of this program is to be able to effectively and efficiently label a much
wider range of audio clips in more shrutis, ragas, and with more background
noise.",2024-05-25,"Sanjay Natesan, Homayoon Beigi",http://arxiv.org/pdf/2405.16000v1,cs.LG
Verified Safe Reinforcement Learning for Neural Network Dynamic Models,"Learning reliably safe autonomous control is one of the core problems in
trustworthy autonomy. However, training a controller that can be formally
verified to be safe remains a major challenge. We introduce a novel approach
for learning verified safe control policies in nonlinear neural dynamical
systems while maximizing overall performance. Our approach aims to achieve
safety in the sense of finite-horizon reachability proofs, and is comprised of
three key parts. The first is a novel curriculum learning scheme that
iteratively increases the verified safe horizon. The second leverages the
iterative nature of gradient-based learning to leverage incremental
verification, reusing information from prior verification runs. Finally, we
learn multiple verified initial-state-dependent controllers, an idea that is
especially valuable for more complex domains where learning a single universal
verified safe controller is extremely challenging. Our experiments on five safe
control problems demonstrate that our trained controllers can achieve verified
safety over horizons that are as much as an order of magnitude longer than
state-of-the-art baselines, while maintaining high reward, as well as a perfect
safety record over entire episodes. Our code is available at
https://github.com/jlwu002/VSRL.",2024-05-25,"Junlin Wu, Huan Zhang, Yevgeniy Vorobeychik",http://arxiv.org/pdf/2405.15994v2,cs.LG
Data Complexity Estimates for Operator Learning,"Operator learning has emerged as a new paradigm for the data-driven
approximation of nonlinear operators. Despite its empirical success, the
theoretical underpinnings governing the conditions for efficient operator
learning remain incomplete. The present work develops theory to study the data
complexity of operator learning, complementing existing research on the
parametric complexity. We investigate the fundamental question: How many
input/output samples are needed in operator learning to achieve a desired
accuracy $\epsilon$? This question is addressed from the point of view of
$n$-widths, and this work makes two key contributions. The first contribution
is to derive lower bounds on $n$-widths for general classes of Lipschitz and
Fr\'echet differentiable operators. These bounds rigorously demonstrate a
``curse of data-complexity'', revealing that learning on such general classes
requires a sample size exponential in the inverse of the desired accuracy
$\epsilon$. The second contribution of this work is to show that ``parametric
efficiency'' implies ``data efficiency''; using the Fourier neural operator
(FNO) as a case study, we show rigorously that on a narrower class of
operators, efficiently approximated by FNO in terms of the number of tunable
parameters, efficient operator learning is attainable in data complexity as
well. Specifically, we show that if only an algebraically increasing number of
tunable parameters is needed to reach a desired approximation accuracy, then an
algebraically bounded number of data samples is also sufficient to achieve the
same accuracy.",2024-05-25,"Nikola B. Kovachki, Samuel Lanthaler, Hrushikesh Mhaskar",http://arxiv.org/pdf/2405.15992v2,cs.LG
Rényi Neural Processes,"Neural Processes (NPs) are deep probabilistic models that represent
stochastic processes by conditioning their prior distributions on a set of
context points. Despite their obvious advantages in uncertainty estimation for
complex distributions, NPs enforce parameterization coupling between the
conditional prior model and the posterior model, thereby risking introducing a
misspecified prior distribution. We hereby revisit the NP objectives and
propose R\'enyi Neural Processes (RNP) to ameliorate the impacts of prior
misspecification by optimizing an alternative posterior that achieves better
marginal likelihood. More specifically, by replacing the standard KL divergence
with the R\'enyi divergence between the model posterior and the true posterior,
we scale the density ratio $\frac{p}{q}$ by the power of (1-$\alpha$) in the
divergence gradients with respect to the posterior. This hyper parameter
$\alpha$ allows us to dampen the effects of the misspecified prior for the
posterior update, which has been shown to effectively avoid oversmoothed
predictions and improve the expressiveness of the posterior model. Our
extensive experiments show consistent log-likelihood improvements over
state-of-the-art NP family models which adopt both the variational inference or
maximum likelihood estimation objectives. We validate the effectiveness of our
approach across multiple benchmarks including regression and image inpainting
tasks, and show significant performance improvements of RNPs in real-world
regression problems where the underlying prior model is misspecifed.",2024-05-25,"Xuesong Wang, He Zhao, Edwin V. Bonilla",http://arxiv.org/pdf/2405.15991v2,cs.LG
Transductive Confidence Machine and its application to Medical Data Sets,"The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and
a supporting, simple user interface was developed. Different settings of the
TCMNN algorithms' parameters were tested on medical data sets, in addition to
the use of different Minkowski metrics and polynomial kernels. The effect of
increasing the number of nearest neighbours and marking results with
significance was also investigated. SVM implementation of the Transductive
Confidence Machine was compared with Nearest Neighbours implementation. The
application of neural networks was investigated as a useful comparison to the
transductive algorithms.",2024-05-25,David Lindsay,http://arxiv.org/pdf/2405.15988v1,cs.LG
Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity,"Diffusion models have become a leading method for generative modeling of both
image and scientific data. As these models are costly to train and evaluate,
reducing the inference cost for diffusion models remains a major goal. Inspired
by the recent empirical success in accelerating diffusion models via the
parallel sampling technique~\cite{shih2024parallel}, we propose to divide the
sampling process into $\mathcal{O}(1)$ blocks with parallelizable Picard
iterations within each block. Rigorous theoretical analysis reveals that our
algorithm achieves $\widetilde{\mathcal{O}}(\mathrm{poly} \log d)$ overall time
complexity, marking the first implementation with provable sub-linear
complexity w.r.t. the data dimension $d$. Our analysis is based on a
generalized version of Girsanov's theorem and is compatible with both the SDE
and probability flow ODE implementations. Our results shed light on the
potential of fast and efficient sampling of high-dimensional data on
fast-evolving modern large-memory GPU clusters.",2024-05-24,"Haoxuan Chen, Yinuo Ren, Lexing Ying, Grant M. Rotskoff",http://arxiv.org/pdf/2405.15986v1,cs.LG
Hierarchical Clustering via Local Search,"In this paper, we introduce a local search algorithm for hierarchical
clustering. For the local step, we consider a tree re-arrangement operation,
known as the {\em interchange}, which involves swapping two closely positioned
sub-trees within a tree hierarchy. The interchange operation has been
previously used in the context of phylogenetic trees. As the objective function
for evaluating the resulting hierarchies, we utilize the revenue function
proposed by Moseley and Wang (NIPS 2017.)
  In our main result, we show that any locally optimal tree guarantees a
revenue of at least $\frac{n-2}{3}\sum_{i < j}w(i,j)$ where is $n$ the number
of objects and $w: [n] \times [n] \rightarrow \mathbb{R}^+$ is the associated
similarity function. This finding echoes the previously established bound for
the average link algorithm as analyzed by Moseley and Wang. We demonstrate that
this alignment is not coincidental, as the average link trees enjoy the
property of being locally optimal with respect to the interchange operation.
Consequently, our study provides an alternative insight into the average link
algorithm and reveals the existence of a broader range of hierarchies with
relatively high revenue achievable through a straightforward local search
algorithm.
  Furthermore, we present an implementation of the local search framework,
where each local step requires $O(n)$ computation time. Our empirical results
indicate that the proposed method, used as post-processing step, can
effectively generate a hierarchical clustering with substantial revenue.",2024-05-24,Hossein Jowhari,http://arxiv.org/pdf/2405.15983v1,cs.LG
BadGD: A unified data-centric framework to identify gradient descent vulnerabilities,"We present BadGD, a unified theoretical framework that exposes the
vulnerabilities of gradient descent algorithms through strategic backdoor
attacks. Backdoor attacks involve embedding malicious triggers into a training
dataset to disrupt the model's learning process. Our framework introduces three
novel constructs: Max RiskWarp Trigger, Max GradWarp Trigger, and Max
GradDistWarp Trigger, each designed to exploit specific aspects of gradient
descent by distorting empirical risk, deterministic gradients, and stochastic
gradients respectively. We rigorously define clean and backdoored datasets and
provide mathematical formulations for assessing the distortions caused by these
malicious backdoor triggers. By measuring the impact of these triggers on the
model training procedure, our framework bridges existing empirical findings
with theoretical insights, demonstrating how a malicious party can exploit
gradient descent hyperparameters to maximize attack effectiveness. In
particular, we show that these exploitations can significantly alter the loss
landscape and gradient calculations, leading to compromised model integrity and
performance. This research underscores the severe threats posed by such
data-centric attacks and highlights the urgent need for robust defenses in
machine learning. BadGD sets a new standard for understanding and mitigating
adversarial manipulations, ensuring the reliability and security of AI systems.",2024-05-24,"Chi-Hua Wang, Guang Cheng",http://arxiv.org/pdf/2405.15979v1,cs.LG
Inference of Utilities and Time Preference in Sequential Decision-Making,"This paper introduces a novel stochastic control framework to enhance the
capabilities of automated investment managers, or robo-advisors, by accurately
inferring clients' investment preferences from past activities. Our approach
leverages a continuous-time model that incorporates utility functions and a
generic discounting scheme of a time-varying rate, tailored to each client's
risk tolerance, valuation of daily consumption, and significant life goals. We
address the resulting time inconsistency issue through state augmentation and
the establishment of the dynamic programming principle and the verification
theorem. Additionally, we provide sufficient conditions for the identifiability
of client investment preferences. To complement our theoretical developments,
we propose a learning algorithm based on maximum likelihood estimation within a
discrete-time Markov Decision Process framework, augmented with entropy
regularization. We prove that the log-likelihood function is locally concave,
facilitating the fast convergence of our proposed algorithm. Practical
effectiveness and efficiency are showcased through two numerical examples,
including Merton's problem and an investment problem with unhedgeable risks.
  Our proposed framework not only advances financial technology by improving
personalized investment advice but also contributes broadly to other fields
such as healthcare, economics, and artificial intelligence, where understanding
individual preferences is crucial.",2024-05-24,"Haoyang Cao, Zhengqi Wu, Renyuan Xu",http://arxiv.org/pdf/2405.15975v2,cs.LG
Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement,"Large vision-language models (LVLMs) have achieved impressive results in
visual question-answering and reasoning tasks through vision instruction tuning
on specific datasets. However, there remains significant room for improvement
in aligning visual and language modalities. Existing methods often depend on
external models or data, leading to uncontrollable and unstable alignment
results. In this paper, we propose SIMA, a self-improvement framework that
enhances visual and language modality alignment without external dependencies.
SIMA leverages existing vision instruction tuning datasets to self-generate
responses, incorporating an in-context self-critic mechanism that constructs
preference pairs for tuning. Crucially, our approach allows LVLMs to act as
critics by designing effective critic prompts, eliminating the need for
additional fine-tuning with external instruction data. We introduce three novel
visual metrics within the self-critic process to guide judgment, significantly
improving the accuracy of self-critic. Through extensive experiments across 14
hallucination and comprehensive benchmarks, we demonstrate that SIMA
significantly improves LVLM's performance and outperforms previous approaches,
achieving superior modality alignment.",2024-05-24,"Xiyao Wang, Jiuhai Chen, Zhaoyang Wang, Yuhang Zhou, Yiyang Zhou, Huaxiu Yao, Tianyi Zhou, Tom Goldstein, Parminder Bhatia, Furong Huang, Cao Xiao",http://arxiv.org/pdf/2405.15973v4,cs.LG
Robust width: A lightweight and certifiable adversarial defense,"Deep neural networks are vulnerable to so-called adversarial examples: inputs
which are intentionally constructed to cause the model to make incorrect
predictions or classifications. Adversarial examples are often visually
indistinguishable from natural data samples, making them hard to detect. As
such, they pose significant threats to the reliability of deep learning
systems. In this work, we study an adversarial defense based on the robust
width property (RWP), which was recently introduced for compressed sensing. We
show that a specific input purification scheme based on the RWP gives
theoretical robustness guarantees for images that are approximately sparse. The
defense is easy to implement and can be applied to any existing model without
additional training or finetuning. We empirically validate the defense on
ImageNet against $L^\infty$ perturbations at perturbation budgets ranging from
$4/255$ to $32/255$. In the black-box setting, our method significantly
outperforms the state-of-the-art, especially for large perturbations. In the
white-box setting, depending on the choice of base classifier, we closely match
the state of the art in robust ImageNet classification while avoiding the need
for additional data, larger models or expensive adversarial training routines.
Our code is available at https://github.com/peck94/robust-width-defense.",2024-05-24,"Jonathan Peck, Bart Goossens",http://arxiv.org/pdf/2405.15971v1,cs.LG
CFGs: Causality Constrained Counterfactual Explanations using goal-directed ASP,"Machine learning models that automate decision-making are increasingly used
in consequential areas such as loan approvals, pretrial bail approval, and
hiring. Unfortunately, most of these models are black boxes, i.e., they are
unable to reveal how they reach these prediction decisions. A need for
transparency demands justification for such predictions. An affected individual
might also desire explanations to understand why a decision was made. Ethical
and legal considerations require informing the individual of changes in the
input attribute (s) that could be made to produce a desirable outcome. Our work
focuses on the latter problem of generating counterfactual explanations by
considering the causal dependencies between features. In this paper, we present
the framework CFGs, CounterFactual Generation with s(CASP), which utilizes the
goal-directed Answer Set Programming (ASP) system s(CASP) to automatically
generate counterfactual explanations from models generated by rule-based
machine learning algorithms in particular. We benchmark CFGs with the FOLD-SE
model. Reaching the counterfactual state from the initial state is planned and
achieved using a series of interventions. To validate our proposal, we show how
counterfactual explanations are computed and justified by imagining worlds
where some or all factual assumptions are altered/changed. More importantly, we
show how CFGs navigates between these worlds, namely, go from our initial state
where we obtain an undesired outcome to the imagined goal state where we obtain
the desired decision, taking into account the causal relationships among
features.",2024-05-24,"Sopam Dasgupta, Joaquín Arias, Elmer Salazar, Gopal Gupta",http://arxiv.org/pdf/2405.15956v1,cs.LG
A Systematic Bias of Machine Learning Regression Models and Its Correction: an Application to Imaging-based Brain Age Prediction,"Machine learning models for continuous outcomes often yield systematically
biased predictions, particularly for values that largely deviate from the mean.
Specifically, predictions for large-valued outcomes tend to be negatively
biased (underestimating actual values), while those for small-valued outcomes
are positively biased (overestimating actual values). We refer to this linear
central tendency warped bias as the ""systematic bias of machine learning
regression"". In this paper, we first demonstrate that this systematic
prediction bias persists across various machine learning regression models, and
then delve into its theoretical underpinnings. To address this issue, we
propose a general constrained optimization approach designed to correct this
bias and develop computationally efficient implementation algorithms.
Simulation results indicate that our correction method effectively eliminates
the bias from the predicted outcomes. We apply the proposed approach to the
prediction of brain age using neuroimaging data. In comparison to competing
machine learning regression models, our method effectively addresses the
longstanding issue of ""systematic bias of machine learning regression"" in
neuroimaging-based brain age calculation, yielding unbiased predictions of
brain age.",2024-05-24,"Hwiyoung Lee, Shuo Chen",http://arxiv.org/pdf/2405.15950v2,cs.LG
Transformers represent belief state geometry in their residual stream,"What computational structure are we building into large language models when
we train them on next-token prediction? Here, we present evidence that this
structure is given by the meta-dynamics of belief updating over hidden states
of the data-generating process. Leveraging the theory of optimal prediction, we
anticipate and then find that belief states are linearly represented in the
residual stream of transformers, even in cases where the predicted belief state
geometry has highly nontrivial fractal structure. We investigate cases where
the belief state geometry is represented in the final residual stream or
distributed across the residual streams of multiple layers, providing a
framework to explain these observations. Furthermore we demonstrate that the
inferred belief states contain information about the entire future, beyond the
local next-token prediction that the transformers are explicitly trained on.
Our work provides a general framework connecting the structure of training data
to the geometric structure of activations inside transformers.",2024-05-24,"Adam S. Shai, Sarah E. Marzen, Lucas Teixeira, Alexander Gietelink Oldenziel, Paul M. Riechers",http://arxiv.org/pdf/2405.15943v3,cs.LG
Can Implicit Bias Imply Adversarial Robustness?,"The implicit bias of gradient-based training algorithms has been considered
mostly beneficial as it leads to trained networks that often generalize well.
However, Frei et al. (2023) show that such implicit bias can harm adversarial
robustness. Specifically, they show that if the data consists of clusters with
small inter-cluster correlation, a shallow (two-layer) ReLU network trained by
gradient flow generalizes well, but it is not robust to adversarial attacks of
small radius. Moreover, this phenomenon occurs despite the existence of a much
more robust classifier that can be explicitly constructed from a shallow
network. In this paper, we extend recent analyses of neuron alignment to show
that a shallow network with a polynomial ReLU activation (pReLU) trained by
gradient flow not only generalizes well but is also robust to adversarial
attacks. Our results highlight the importance of the interplay between data
structure and architecture design in the implicit bias and robustness of
trained networks.",2024-05-24,"Hancheng Min, René Vidal",http://arxiv.org/pdf/2405.15942v2,cs.LG
A Unified Theory of Stochastic Proximal Point Methods without Smoothness,"This paper presents a comprehensive analysis of a broad range of variations
of the stochastic proximal point method (SPPM). Proximal point methods have
attracted considerable interest owing to their numerical stability and
robustness against imperfect tuning, a trait not shared by the dominant
stochastic gradient descent (SGD) algorithm. A framework of assumptions that we
introduce encompasses methods employing techniques such as variance reduction
and arbitrary sampling. A cornerstone of our general theoretical approach is a
parametric assumption on the iterates, correction and control vectors. We
establish a single theorem that ensures linear convergence under this
assumption and the $\mu$-strong convexity of the loss function, and without the
need to invoke smoothness. This integral theorem reinstates best known
complexity and convergence guarantees for several existing methods which
demonstrates the robustness of our approach. We expand our study by developing
three new variants of SPPM, and through numerical experiments we elucidate
various properties inherent to them.",2024-05-24,"Peter Richtárik, Abdurakhmon Sadiev, Yury Demidovich",http://arxiv.org/pdf/2405.15941v1,cs.LG
Clustering Survival Data using a Mixture of Non-parametric Experts,"Survival analysis aims to predict the timing of future events across various
fields, from medical outcomes to customer churn. However, the integration of
clustering into survival analysis, particularly for precision medicine, remains
underexplored. This study introduces SurvMixClust, a novel algorithm for
survival analysis that integrates clustering with survival function prediction
within a unified framework. SurvMixClust learns latent representations for
clustering while also predicting individual survival functions using a mixture
of non-parametric experts. Our evaluations on five public datasets show that
SurvMixClust creates balanced clusters with distinct survival curves,
outperforms clustering baselines, and competes with non-clustering survival
models in predictive accuracy, as measured by the time-dependent c-index and
log-rank metrics.",2024-05-24,"Gabriel Buginga, Edmundo de Souza e Silva",http://arxiv.org/pdf/2405.15934v1,cs.LG
PatchProt: Hydrophobic patch prediction using protein foundation models,"Hydrophobic patches on protein surfaces play important functional roles in
protein-protein and protein-ligand interactions. Large hydrophobic surfaces are
also involved in the progression of aggregation diseases. Predicting exposed
hydrophobic patches from a protein sequence has been shown to be a difficult
task. Fine-tuning foundation models allows for adapting a model to the specific
nuances of a new task using a much smaller dataset. Additionally, multi-task
deep learning offers a promising solution for addressing data gaps,
simultaneously outperforming single-task methods. In this study, we harnessed a
recently released leading large language model ESM-2. Efficient fine-tuning of
ESM-2 was achieved by leveraging a recently developed parameter-efficient
fine-tuning method. This approach enabled comprehensive training of model
layers without excessive parameters and without the need to include a
computationally expensive multiple sequence analysis. We explored several
related tasks, at local (residue) and global (protein) levels, to improve the
representation of the model. As a result, our fine-tuned ESM-2 model,
PatchProt, cannot only predict hydrophobic patch areas but also outperforms
existing methods at predicting primary tasks, including secondary structure and
surface accessibility predictions. Importantly, our analysis shows that
including related local tasks can improve predictions on more difficult global
tasks. This research sets a new standard for sequence-based protein property
prediction and highlights the remarkable potential of fine-tuning foundation
models enriching the model representation by training over related tasks.",2024-05-24,"Dea Gogishvili, Emmanuel Minois-Genin, Jan van Eck, Sanne Abeln",http://arxiv.org/pdf/2405.15928v1,cs.LG
Dissecting the Interplay of Attention Paths in a Statistical Mechanics Theory of Transformers,"Despite the remarkable empirical performance of Transformers, their
theoretical understanding remains elusive. Here, we consider a deep multi-head
self-attention network, that is closely related to Transformers yet
analytically tractable. We develop a statistical mechanics theory of Bayesian
learning in this model, deriving exact equations for the network's predictor
statistics under the finite-width thermodynamic limit, i.e.,
$N,P\rightarrow\infty$, $P/N=\mathcal{O}(1)$, where $N$ is the network width
and $P$ is the number of training examples. Our theory shows that the predictor
statistics are expressed as a sum of independent kernels, each one pairing
different 'attention paths', defined as information pathways through different
attention heads across layers. The kernels are weighted according to a
'task-relevant kernel combination' mechanism that aligns the total kernel with
the task labels. As a consequence, this interplay between attention paths
enhances generalization performance. Experiments confirm our findings on both
synthetic and real-world sequence classification tasks. Finally, our theory
explicitly relates the kernel combination mechanism to properties of the
learned weights, allowing for a qualitative transfer of its insights to models
trained via gradient descent. As an illustration, we demonstrate an efficient
size reduction of the network, by pruning those attention heads that are deemed
less relevant by our theory.",2024-05-24,"Lorenzo Tiberi, Francesca Mignacco, Kazuki Irie, Haim Sompolinsky",http://arxiv.org/pdf/2405.15926v2,cs.LG
MUCM-Net: A Mamba Powered UCM-Net for Skin Lesion Segmentation,"Skin lesion segmentation is key for early skin cancer detection. Challenges
in automatic segmentation from dermoscopic images include variations in color,
texture, and artifacts of indistinct lesion boundaries. Deep learning methods
like CNNs and U-Net have shown promise in addressing these issues. To further
aid early diagnosis, especially on mobile devices with limited computing power,
we present MUCM-Net. This efficient model combines Mamba State-Space Models
with our UCM-Net architecture for improved feature learning and segmentation.
MUCM-Net's Mamba-UCM Layer is optimized for mobile deployment, offering high
accuracy with low computational needs. Tested on ISIC datasets, it outperforms
other methods in accuracy and computational efficiency, making it a scalable
tool for early detection in settings with limited resources. Our MUCM-Net
source code is available for research and collaboration, supporting advances in
mobile health diagnostics and the fight against skin cancer. In order to
facilitate accessibility and further research in the field, the MUCM-Net source
code is https://github.com/chunyuyuan/MUCM-Net",2024-05-24,"Chunyu Yuan, Dongfang Zhao, Sos S. Agaian",http://arxiv.org/pdf/2405.15925v2,cs.LG
SF-DQN: Provable Knowledge Transfer using Successor Feature for Deep Reinforcement Learning,"This paper studies the transfer reinforcement learning (RL) problem where
multiple RL problems have different reward functions but share the same
underlying transition dynamics. In this setting, the Q-function of each RL
problem (task) can be decomposed into a successor feature (SF) and a reward
mapping: the former characterizes the transition dynamics, and the latter
characterizes the task-specific reward function. This Q-function decomposition,
coupled with a policy improvement operator known as generalized policy
improvement (GPI), reduces the sample complexity of finding the optimal
Q-function, and thus the SF \& GPI framework exhibits promising empirical
performance compared to traditional RL methods like Q-learning. However, its
theoretical foundations remain largely unestablished, especially when learning
the successor features using deep neural networks (SF-DQN). This paper studies
the provable knowledge transfer using SFs-DQN in transfer RL problems. We
establish the first convergence analysis with provable generalization
guarantees for SF-DQN with GPI. The theory reveals that SF-DQN with GPI
outperforms conventional RL approaches, such as deep Q-network, in terms of
both faster convergence rate and better generalization. Numerical experiments
on real and synthetic RL tasks support the superior performance of SF-DQN \&
GPI, aligning with our theoretical findings.",2024-05-24,"Shuai Zhang, Heshan Devaka Fernando, Miao Liu, Keerthiram Murugesan, Songtao Lu, Pin-Yu Chen, Tianyi Chen, Meng Wang",http://arxiv.org/pdf/2405.15920v2,cs.LG
Pattern-Based Time-Series Risk Scoring for Anomaly Detection and Alert Filtering -- A Predictive Maintenance Case Study,"Fault detection is a key challenge in the management of complex systems. In
the context of SparkCognition's efforts towards predictive maintenance in large
scale industrial systems, this problem is often framed in terms of anomaly
detection - identifying patterns of behavior in the data which deviate from
normal. Patterns of normal behavior aren't captured simply in the coarse
statistics of measured signals. Rather, the multivariate sequential pattern
itself can be indicative of normal vs. abnormal behavior. For this reason,
normal behavior modeling that relies on snapshots of the data without taking
into account temporal relationships as they evolve would be lacking. However,
common strategies for dealing with temporal dependence, such as Recurrent
Neural Networks or attention mechanisms are oftentimes computationally
expensive and difficult to train. In this paper, we propose a fast and
efficient approach to anomaly detection and alert filtering based on sequential
pattern similarities. In our empirical analysis section, we show how this
approach can be leveraged for a variety of purposes involving anomaly detection
on a large scale real-world industrial system. Subsequently, we test our
approach on a publicly-available dataset in order to establish its general
applicability and robustness compared to a state-of-the-art baseline. We also
demonstrate an efficient way of optimizing the framework based on an alert
recall objective function.",2024-05-24,Elad Liebman,http://arxiv.org/pdf/2405.17488v1,cs.LG
Scaling up the Banded Matrix Factorization Mechanism for Differentially Private ML,"Correlated noise mechanisms such as DP Matrix Factorization (DP-MF) have
proven to be effective alternatives to DP-SGD in large-epsilon few-epoch
training regimes. Significant work has been done to find the best correlated
noise strategies, and the current state-of-the-art approach is DP-BandMF, which
optimally balances the benefits of privacy amplification and noise correlation.
Despite it's utility advantages, severe scalability limitations prevent this
mechanism from handling large-scale training scenarios where the number of
training iterations may exceed $10^4$ and the number of model parameters may
exceed $10^7$. In this work, we present techniques to scale up DP-BandMF along
these two dimensions, significantly extending it's reach and enabling it to
handle settings with virtually any number of model parameters and training
iterations, with negligible utility degradation.",2024-05-24,Ryan McKenna,http://arxiv.org/pdf/2405.15913v4,cs.LG
Uncertainty Quantification for Neurosymbolic Programs via Compositional Conformal Prediction,"Machine learning has become an effective tool for automatically annotating
unstructured data (e.g., images) with structured labels (e.g., object
detections). As a result, a new programming paradigm called neurosymbolic
programming has emerged where users write queries against these predicted
annotations. However, due to the intrinsic fallibility of machine learning
models, these programs currently lack any notion of correctness. In many
domains, users may want some kind of conservative guarantee that the results of
their queries contain all possibly relevant instances. Conformal prediction has
emerged as a promising strategy for quantifying uncertainty in machine learning
by modifying models to predict sets of labels instead of individual labels; it
provides a probabilistic guarantee that the prediction set contains the true
label with high probability. We propose a novel framework for adapting
conformal prediction to neurosymbolic programs; our strategy is to represent
prediction sets as abstract values in some abstract domain, and then to use
abstract interpretation to propagate prediction sets through the program. Our
strategy satisfies three key desiderata: (i) correctness (i.e., the program
outputs a prediction set that contains the true output with high probability),
(ii) compositionality (i.e., we can quantify uncertainty separately for
different modules and then compose them together), and (iii) structured values
(i.e., we can provide uncertainty quantification for structured values such as
lists). When the full program is available ahead-of-time, we propose an
optimization that incorporates conformal prediction at intermediate program
points to reduce imprecision in abstract interpretation. We evaluate our
approach on programs that take MNIST and MS-COCO images as input, demonstrating
that it produces reasonably sized prediction sets while satisfying a coverage
guarantee.",2024-05-24,"Ramya Ramalingam, Sangdon Park, Osbert Bastani",http://arxiv.org/pdf/2405.15912v1,cs.LG
Learning accurate and interpretable tree-based models,"Decision trees and their ensembles are popular in machine learning as
easy-to-understand models. Several techniques have been proposed in the
literature for learning tree-based classifiers, with different techniques
working well for data from different domains. In this work, we develop
approaches to design tree-based learning algorithms given repeated access to
data from the same domain. We study multiple formulations covering different
aspects and popular techniques for learning decision tree based approaches. We
propose novel parameterized classes of node splitting criteria in top-down
algorithms, which interpolate between popularly used entropy and Gini impurity
based criteria, and provide theoretical bounds on the number of samples needed
to learn the splitting function appropriate for the data at hand. We also study
the sample complexity of tuning prior parameters in Bayesian decision tree
learning, and extend our results to decision tree regression. We further
consider the problem of tuning hyperparameters in pruning the decision tree for
classical pruning algorithms including min-cost complexity pruning. In
addition, our techniques can be used to optimize the explainability versus
accuracy trade-off when using decision trees. We extend our results to tuning
popular tree-based ensembles, including random forests and gradient-boosted
trees. We demonstrate the significance of our approach on real world datasets
by learning data-specific decision trees which are simultaneously more accurate
and interpretable.",2024-05-24,"Maria-Florina Balcan, Dravyansh Sharma",http://arxiv.org/pdf/2405.15911v2,cs.LG
Knowledge-Informed Auto-Penetration Testing Based on Reinforcement Learning with Reward Machine,"Automated penetration testing (AutoPT) based on reinforcement learning (RL)
has proven its ability to improve the efficiency of vulnerability
identification in information systems. However, RL-based PT encounters several
challenges, including poor sampling efficiency, intricate reward specification,
and limited interpretability. To address these issues, we propose a
knowledge-informed AutoPT framework called DRLRM-PT, which leverages reward
machines (RMs) to encode domain knowledge as guidelines for training a PT
policy. In our study, we specifically focus on lateral movement as a PT case
study and formulate it as a partially observable Markov decision process
(POMDP) guided by RMs. We design two RMs based on the MITRE ATT\&CK knowledge
base for lateral movement. To solve the POMDP and optimize the PT policy, we
employ the deep Q-learning algorithm with RM (DQRM). The experimental results
demonstrate that the DQRM agent exhibits higher training efficiency in PT
compared to agents without knowledge embedding. Moreover, RMs encoding more
detailed domain knowledge demonstrated better PT performance compared to RMs
with simpler knowledge.",2024-05-24,"Yuanliang Li, Hanzheng Dai, Jun Yan",http://arxiv.org/pdf/2405.15908v1,cs.LG
AMGPT: a Large Language Model for Contextual Querying in Additive Manufacturing,"Generalized large language models (LLMs) such as GPT-4 may not provide
specific answers to queries formulated by materials science researchers. These
models may produce a high-level outline but lack the capacity to return
detailed instructions on manufacturing and material properties of novel alloys.
Enhancing a smaller model with specialized domain knowledge may provide an
advantage over large language models which cannot be retrained quickly enough
to keep up with the rapid pace of research in metal additive manufacturing
(AM). We introduce ""AMGPT,"" a specialized LLM text generator designed for metal
AM queries. The goal of AMGPT is to assist researchers and users in navigating
the extensive corpus of literature in AM. Instead of training from scratch, we
employ a pre-trained Llama2-7B model from Hugging Face in a Retrieval-Augmented
Generation (RAG) setup, utilizing it to dynamically incorporate information
from $\sim$50 AM papers and textbooks in PDF format. Mathpix is used to convert
these PDF documents into TeX format, facilitating their integration into the
RAG pipeline managed by LlamaIndex. Expert evaluations of this project
highlight that specific embeddings from the RAG setup accelerate response times
and maintain coherence in the generated text.",2024-05-24,"Achuth Chandrasekhar, Jonathan Chan, Francis Ogoke, Olabode Ajenifujah, Amir Barati Farimani",http://arxiv.org/pdf/2406.00031v1,cs.LG
UnitNorm: Rethinking Normalization for Transformers in Time Series,"Normalization techniques are crucial for enhancing Transformer models'
performance and stability in time series analysis tasks, yet traditional
methods like batch and layer normalization often lead to issues such as token
shift, attention shift, and sparse attention. We propose UnitNorm, a novel
approach that scales input vectors by their norms and modulates attention
patterns, effectively circumventing these challenges. Grounded in existing
normalization frameworks, UnitNorm's effectiveness is demonstrated across
diverse time series analysis tasks, including forecasting, classification, and
anomaly detection, via a rigorous evaluation on 6 state-of-the-art models and
10 datasets. Notably, UnitNorm shows superior performance, especially in
scenarios requiring robust attention mechanisms and contextual comprehension,
evidenced by significant improvements by up to a 1.46 decrease in MSE for
forecasting, and a 4.89% increase in accuracy for classification. This work not
only calls for a reevaluation of normalization strategies in time series
Transformers but also sets a new direction for enhancing model performance and
stability. The source code is available at
https://anonymous.4open.science/r/UnitNorm-5B84.",2024-05-24,"Nan Huang, Christian Kümmerle, Xiang Zhang",http://arxiv.org/pdf/2405.15903v1,cs.LG
"Matchings, Predictions and Counterfactual Harm in Refugee Resettlement Processes","Resettlement agencies have started to adopt data-driven algorithmic matching
to match refugees to locations using employment rate as a measure of utility.
Given a pool of refugees, data-driven algorithmic matching utilizes a
classifier to predict the probability that each refugee would find employment
at any given location. Then, it uses the predicted probabilities to estimate
the expected utility of all possible placement decisions. Finally, it finds the
placement decisions that maximize the predicted utility by solving a maximum
weight bipartite matching problem. In this work, we argue that, using existing
solutions, there may be pools of refugees for which data-driven algorithmic
matching is (counterfactually) harmful -- it would have achieved lower utility
than a given default policy used in the past, had it been used. Then, we
develop a post-processing algorithm that, given placement decisions made by a
default policy on a pool of refugees and their employment outcomes, solves an
inverse~matching problem to minimally modify the predictions made by a given
classifier. Under these modified predictions, the optimal matching policy that
maximizes predicted utility on the pool is guaranteed to be not harmful.
Further, we introduce a Transformer model that, given placement decisions made
by a default policy on multiple pools of refugees and their employment
outcomes, learns to modify the predictions made by a classifier so that the
optimal matching policy that maximizes predicted utility under the modified
predictions on an unseen pool of refugees is less likely to be harmful than
under the original predictions. Experiments on simulated resettlement processes
using synthetic refugee data created from a variety of publicly available data
suggest that our methodology may be effective in making algorithmic placement
decisions that are less likely to be harmful than existing solutions.",2024-05-24,"Seungeon Lee, Nina Corvelo Benz, Suhas Thejaswi, Manuel Gomez-Rodriguez",http://arxiv.org/pdf/2407.13052v1,cs.LG
Predicting the Impact of Model Expansion through the Minima Manifold: A Loss Landscape Perspective,"The optimal model for a given task is often challenging to determine,
requiring training multiple models from scratch which becomes prohibitive as
dataset and model sizes grow. A more efficient alternative is to reuse smaller
pre-trained models by expanding them, however, this is not widely adopted as
how this impacts training dynamics remains poorly understood. While prior works
have introduced statistics to measure these effects, they remain flawed. To
rectify this, we offer a new approach for understanding and quantifying the
impact of expansion through the lens of the loss landscape, which has been
shown to contain a manifold of linearly connected minima. Building on this new
perspective, we propose a metric to study the impact of expansion by estimating
the size of the manifold. Experimental results show a clear relationship
between gains in performance and manifold size, enabling the comparison of
candidate models and presenting a first step towards expanding models more
reliably based on geometric properties of the loss landscape.",2024-05-24,"Pranshu Malviya, Jerry Huang, Quentin Fournier, Sarath Chandar",http://arxiv.org/pdf/2405.15895v1,cs.LG
Derivatives of Stochastic Gradient Descent in parametric optimization,"We consider stochastic optimization problems where the objective depends on
some parameter, as commonly found in hyperparameter optimization for instance.
We investigate the behavior of the derivatives of the iterates of Stochastic
Gradient Descent (SGD) with respect to that parameter and show that they are
driven by an inexact SGD recursion on a different objective function, perturbed
by the convergence of the original SGD. This enables us to establish that the
derivatives of SGD converge to the derivative of the solution mapping in terms
of mean squared error whenever the objective is strongly convex. Specifically,
we demonstrate that with constant step-sizes, these derivatives stabilize
within a noise ball centered at the solution derivative, and that with
vanishing step-sizes they exhibit $O(\log(k)^2 / k)$ convergence rates.
Additionally, we prove exponential convergence in the interpolation regime. Our
theoretical findings are illustrated by numerical experiments on synthetic
tasks.",2024-05-24,"Franck Iutzeler, Edouard Pauwels, Samuel Vaiter",http://arxiv.org/pdf/2405.15894v2,cs.LG
Score Distillation via Reparametrized DDIM,"While 2D diffusion models generate realistic, high-detail images, 3D shape
generation methods like Score Distillation Sampling (SDS) built on these 2D
diffusion models produce cartoon-like, over-smoothed shapes. To help explain
this discrepancy, we show that the image guidance used in Score Distillation
can be understood as the velocity field of a 2D denoising generative process,
up to the choice of a noise term. In particular, after a change of variables,
SDS resembles a high-variance version of Denoising Diffusion Implicit Models
(DDIM) with a differently-sampled noise term: SDS introduces noise i.i.d.
randomly at each step, while DDIM infers it from the previous noise
predictions. This excessive variance can lead to over-smoothing and unrealistic
outputs. We show that a better noise approximation can be recovered by
inverting DDIM in each SDS update step. This modification makes SDS's
generative process for 2D images almost identical to DDIM. In 3D, it removes
over-smoothing, preserves higher-frequency detail, and brings the generation
quality closer to that of 2D samplers. Experimentally, our method achieves
better or similar 3D generation quality compared to other state-of-the-art
Score Distillation methods, all without training additional neural networks or
multi-view supervision, and providing useful insights into relationship between
2D and 3D asset generation with diffusion models.",2024-05-24,"Artem Lukoianov, Haitz Sáez de Ocáriz Borde, Kristjan Greenewald, Vitor Campagnolo Guizilini, Timur Bagautdinov, Vincent Sitzmann, Justin Solomon",http://arxiv.org/pdf/2405.15891v3,cs.LG
Diffusion Bridge Implicit Models,"Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion
models for interpolating between two arbitrary paired distributions given as
endpoints. Despite their promising performance in tasks like image translation,
DDBMs require a computationally intensive sampling process that involves the
simulation of a (stochastic) differential equation through hundreds of network
evaluations. In this work, we take the first step in fast sampling of DDBMs
without extra training, motivated by the well-established recipes in diffusion
models. We generalize DDBMs via a class of non-Markovian diffusion bridges
defined on the discretized timesteps concerning sampling, which share the same
marginal distributions and training objectives, give rise to generative
processes ranging from stochastic to deterministic, and result in diffusion
bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than
the vanilla sampler of DDBMs but also induce a novel, simple, and insightful
form of ordinary differential equation (ODE) which inspires high-order
numerical solvers. Moreover, DBIMs maintain the generation diversity in a
distinguished way, by using a booting noise in the initial sampling step, which
enables faithful encoding, reconstruction, and semantic interpolation in image
translation tasks. Code is available at
https://github.com/thu-ml/DiffusionBridge.",2024-05-24,"Kaiwen Zheng, Guande He, Jianfei Chen, Fan Bao, Jun Zhu",http://arxiv.org/pdf/2405.15885v6,cs.LG
Risk Factor Identification In Osteoporosis Using Unsupervised Machine Learning Techniques,"In this study, the reliability of identified risk factors associated with
osteoporosis is investigated using a new clustering-based method on electronic
medical records. This study proposes utilizing a new CLustering Iterations
Framework (CLIF) that includes an iterative clustering framework that can adapt
any of the following three components: clustering, feature selection, and
principal feature identification. The study proposes using Wasserstein distance
to identify principal features, borrowing concepts from the optimal transport
theory. The study also suggests using a combination of ANOVA and ablation tests
to select influential features from a data set. Some risk factors presented in
existing works are endorsed by our identified significant clusters, while the
reliability of some other risk factors is weakened.",2024-05-24,Mikayla Calitis,http://arxiv.org/pdf/2405.15882v1,cs.LG
Scaling Diffusion Mamba with Bidirectional SSMs for Efficient Image and Video Generation,"In recent developments, the Mamba architecture, known for its selective state
space approach, has shown potential in the efficient modeling of long
sequences. However, its application in image generation remains underexplored.
Traditional diffusion transformers (DiT), which utilize self-attention blocks,
are effective but their computational complexity scales quadratically with the
input length, limiting their use for high-resolution images. To address this
challenge, we introduce a novel diffusion architecture, Diffusion Mamba (DiM),
which foregoes traditional attention mechanisms in favor of a scalable
alternative. By harnessing the inherent efficiency of the Mamba architecture,
DiM achieves rapid inference times and reduced computational load, maintaining
linear complexity with respect to sequence length. Our architecture not only
scales effectively but also outperforms existing diffusion transformers in both
image and video generation tasks. The results affirm the scalability and
efficiency of DiM, establishing a new benchmark for image and video generation
techniques. This work advances the field of generative models and paves the way
for further applications of scalable architectures.",2024-05-24,"Shentong Mo, Yapeng Tian",http://arxiv.org/pdf/2405.15881v1,cs.LG
eQMARL: Entangled Quantum Multi-Agent Reinforcement Learning for Distributed Cooperation over Quantum Channels,"Collaboration is a key challenge in distributed multi-agent reinforcement
learning (MARL) environments. Learning frameworks for these decentralized
systems must weigh the benefits of explicit player coordination against the
communication overhead and computational cost of sharing local observations and
environmental data. Quantum computing has sparked a potential synergy between
quantum entanglement and cooperation in multi-agent environments, which could
enable more efficient distributed collaboration with minimal information
sharing. This relationship is largely unexplored, however, as current
state-of-the-art quantum MARL (QMARL) implementations rely on classical
information sharing rather than entanglement over a quantum channel as a
coordination medium. In contrast, in this paper, a novel framework dubbed
entangled QMARL (eQMARL) is proposed. The proposed eQMARL is a distributed
actor-critic framework that facilitates cooperation over a quantum channel and
eliminates local observation sharing via a quantum entangled split critic.
Introducing a quantum critic uniquely spread across the agents allows coupling
of local observation encoders through entangled input qubits over a quantum
channel, which requires no explicit sharing of local observations and reduces
classical communication overhead. Further, agent policies are tuned through
joint observation-value function estimation via joint quantum measurements,
thereby reducing the centralized computational burden. Experimental results
show that eQMARL with ${\Psi}^{+}$ entanglement converges to a cooperative
strategy up to $17.8\%$ faster and with a higher overall score compared to
split classical and fully centralized classical and quantum baselines. The
results also show that eQMARL achieves this performance with a constant factor
of $25$-times fewer centralized parameters compared to the split classical
baseline.",2024-05-24,"Alexander DeRieux, Walid Saad",http://arxiv.org/pdf/2405.17486v2,cs.LG
Comet: A Communication-efficient and Performant Approximation for Private Transformer Inference,"The prevalent use of Transformer-like models, exemplified by ChatGPT in
modern language processing applications, underscores the critical need for
enabling private inference essential for many cloud-based services reliant on
such models. However, current privacy-preserving frameworks impose significant
communication burden, especially for non-linear computation in Transformer
model. In this paper, we introduce a novel plug-in method Comet to effectively
reduce the communication cost without compromising the inference performance.
We second introduce an efficient approximation method to eliminate the heavy
communication in finding good initial approximation. We evaluate our Comet on
Bert and RoBERTa models with GLUE benchmark datasets, showing up to 3.9$\times$
less communication and 3.5$\times$ speedups while keep competitive model
performance compared to the prior art.",2024-05-24,"Xiangrui Xu, Qiao Zhang, Rui Ning, Chunsheng Xin, Hongyi Wu",http://arxiv.org/pdf/2405.17485v2,cs.LG
Basis Selection: Low-Rank Decomposition of Pretrained Large Language Models for Target Applications,"Large language models (LLMs) significantly enhance the performance of various
applications, but they are computationally intensive and energy-demanding. This
makes it challenging to deploy them on devices with limited resources, such as
personal computers and mobile/wearable devices, and results in substantial
inference costs in resource-rich environments like cloud servers. To extend the
use of LLMs, we introduce a low-rank decomposition approach to effectively
compress these models, tailored to the requirements of specific applications.
We observe that LLMs pretrained on general datasets contain many redundant
components not needed for particular applications. Our method focuses on
identifying and removing these redundant parts, retaining only the necessary
elements for the target applications. Specifically, we represent the weight
matrices of LLMs as a linear combination of base components. We then prune the
irrelevant bases and enhance the model with new bases beneficial for specific
applications. Deep compression results on the Llama 2-7b and -13B models,
conducted on target applications including mathematical reasoning and code
generation, show that our method significantly reduces model size while
maintaining comparable accuracy to state-of-the-art low-rank compression
techniques.",2024-05-24,"Yang Li, Changsheng Zhao, Hyungtak Lee, Ernie Chang, Yangyang Shi, Vikas Chandra",http://arxiv.org/pdf/2405.15877v1,cs.LG
"MeMo: Meaningful, Modular Controllers via Noise Injection","Robots are often built from standardized assemblies, (e.g. arms, legs, or
fingers), but each robot must be trained from scratch to control all the
actuators of all the parts together. In this paper we demonstrate a new
approach that takes a single robot and its controller as input and produces a
set of modular controllers for each of these assemblies such that when a new
robot is built from the same parts, its control can be quickly learned by
reusing the modular controllers. We achieve this with a framework called MeMo
which learns (Me)aningful, (Mo)dular controllers. Specifically, we propose a
novel modularity objective to learn an appropriate division of labor among the
modules. We demonstrate that this objective can be optimized simultaneously
with standard behavior cloning loss via noise injection. We benchmark our
framework in locomotion and grasping environments on simple to complex robot
morphology transfer. We also show that the modules help in task transfer. On
both structure and task transfer, MeMo achieves improved training efficiency to
graph neural network and Transformer baselines.",2024-05-24,"Megan Tjandrasuwita, Jie Xu, Armando Solar-Lezama, Wojciech Matusik",http://arxiv.org/pdf/2407.01567v2,cs.LG
CausalConceptTS: Causal Attributions for Time Series Classification using High Fidelity Diffusion Models,"Despite the excelling performance of machine learning models, understanding
the decisions of machine learning models remains a long-standing goal. While
commonly used attribution methods in explainable AI attempt to address this
issue, they typically rely on associational rather than causal relationships.
In this study, within the context of time series classification, we introduce a
novel framework to assess the causal effect of concepts, i.e., predefined
segments within a time series, on specific classification outcomes. To achieve
this, we leverage state-of-the-art diffusion-based generative models to
estimate counterfactual outcomes. Our approach compares these causal
attributions with closely related associational attributions, both
theoretically and empirically. We demonstrate the insights gained by our
approach for a diverse set of qualitatively different time series
classification tasks. Although causal and associational attributions might
often share some similarities, in all cases they differ in important details,
underscoring the risks associated with drawing causal conclusions from
associational data alone. We believe that the proposed approach is widely
applicable also in other domains, particularly where predefined segmentations
are available, to shed some light on the limits of associational attributions.",2024-05-24,"Juan Miguel Lopez Alcaraz, Nils Strodthoff",http://arxiv.org/pdf/2405.15871v1,cs.LG
LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization,"Training deep neural networks (DNNs) using traditional backpropagation (BP)
presents challenges in terms of computational complexity and energy
consumption, particularly for on-device learning where computational resources
are limited. Various alternatives to BP, including random feedback alignment,
forward-forward, and local classifiers, have been explored to address these
challenges. These methods have their advantages, but they can encounter
difficulties when dealing with intricate visual tasks or demand considerable
computational resources. In this paper, we propose a novel Local Learning rule
inspired by neural activity Synchronization phenomena (LLS) observed in the
brain. LLS utilizes fixed periodic basis vectors to synchronize neuron activity
within each layer, enabling efficient training without the need for additional
trainable parameters. We demonstrate the effectiveness of LLS and its
variations, LLS-M and LLS-MxM, on multiple image classification datasets,
achieving accuracy comparable to BP with reduced computational complexity and
minimal additional parameters. Specifically, LLS achieves comparable
performance with up to $300 \times$ fewer multiply-accumulate (MAC) operations
and half the memory requirements of BP. Furthermore, the performance of LLS on
the Visual Wake Word (VWW) dataset highlights its suitability for on-device
learning tasks, making it a promising candidate for edge hardware
implementations.",2024-05-24,"Marco Paul E. Apolinario, Arani Roy, Kaushik Roy",http://arxiv.org/pdf/2405.15868v2,cs.LG
Large Language Model Pruning,"We surely enjoy the larger the better models for their superior performance
in the last couple of years when both the hardware and software support the
birth of such extremely huge models. The applied fields include text mining and
others. In particular, the success of LLMs on text understanding and text
generation draws attention from researchers who have worked on NLP and related
areas for years or even decades. On the side, LLMs may suffer from problems
like model overfitting, hallucination, and device limitation to name a few. In
this work, we suggest a model pruning technique specifically focused on LLMs.
The proposed methodology emphasizes the explainability of deep learning models.
By having the theoretical foundation, we obtain a trustworthy deep model so
that huge models with a massive number of model parameters become not quite
necessary. A mutual information-based estimation is adopted to find neurons
with redundancy to eliminate. Moreover, an estimator with well-tuned parameters
helps to find precise estimation to guide the pruning procedure. At the same
time, we also explore the difference between pruning on large-scale models vs.
pruning on small-scale models. The choice of pruning criteria is sensitive in
small models but not for large-scale models. It is a novel finding through this
work. Overall, we demonstrate the superiority of the proposed model to the
state-of-the-art models.",2024-05-24,"Hanjuan Huang, Hao-Jia Song, Hsing-Kuo Pao",http://arxiv.org/pdf/2406.00030v1,cs.LG
Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization,"Federated Learning (FL) offers a promising framework for collaborative and
privacy-preserving machine learning across distributed data sources. However,
the substantial communication costs associated with FL significantly challenge
its efficiency. Specifically, in each communication round, the communication
costs scale linearly with the model's dimension, which presents a formidable
obstacle, especially in large model scenarios. Despite various
communication-efficient strategies, the intrinsic dimension-dependent
communication cost remains a major bottleneck for current FL implementations.
This paper proposes a novel dimension-free communication algorithm - DeComFL,
which leverages the zeroth-order optimization techniques and reduces the
communication cost from $\mathscr{O}(d)$ to $\mathscr{O}(1)$ by transmitting
only a constant number of scalar values between clients and the server in each
round, regardless of the dimension $d$ of the model parameters. Theoretically,
in non-convex functions, we prove that our algorithm achieves state-of-the-art
rates, which show a linear speedup of the number of clients and local steps
under standard assumptions. With additional low effective rank assumption, we
can further show the convergence rate is independent of the model dimension $d$
as well. Empirical evaluations, encompassing both classic deep learning
training and large language model fine-tuning, demonstrate significant
reductions in communication overhead. Notably, DeComFL achieves this by
transmitting only around 1MB of data in total between the server and a client
to fine-tune a model with billions of parameters. Our code is available at
https://github.com/ZidongLiu/DeComFL.",2024-05-24,"Zhe Li, Bicheng Ying, Zidong Liu, Chaosheng Dong, Haibo Yang",http://arxiv.org/pdf/2405.15861v4,cs.LG
Canonical Variates in Wasserstein Metric Space,"In this paper, we address the classification of instances each characterized
not by a singular point, but by a distribution on a vector space. We employ the
Wasserstein metric to measure distances between distributions, which are then
used by distance-based classification algorithms such as k-nearest neighbors,
k-means, and pseudo-mixture modeling. Central to our investigation is dimension
reduction within the Wasserstein metric space to enhance classification
accuracy. We introduce a novel approach grounded in the principle of maximizing
Fisher's ratio, defined as the quotient of between-class variation to
within-class variation. The directions in which this ratio is maximized are
termed discriminant coordinates or canonical variates axes. In practice, we
define both between-class and within-class variations as the average squared
distances between pairs of instances, with the pairs either belonging to the
same class or to different classes. This ratio optimization is achieved through
an iterative algorithm, which alternates between optimal transport and
maximization steps within the vector space. We conduct empirical studies to
assess the algorithm's convergence and, through experimental validation,
demonstrate that our dimension reduction technique substantially enhances
classification performance. Moreover, our method outperforms well-established
algorithms that operate on vector representations derived from distributional
data. It also exhibits robustness against variations in the distributional
representations of data clouds.",2024-05-24,"Jia Li, Lin Lin",http://arxiv.org/pdf/2405.15768v1,cs.LG
Improved Particle Approximation Error for Mean Field Neural Networks,"Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized
nonlinear convex functional defined over the space of probability
distributions. MFLD has gained attention due to its connection with noisy
gradient descent for mean-field two-layer neural networks. Unlike standard
Langevin dynamics, the nonlinearity of the objective functional induces
particle interactions, necessitating multiple particles to approximate the
dynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzuki
et al., 2023b) have demonstrated the uniform-in-time propagation of chaos for
MFLD, showing that the gap between the particle system and its mean-field limit
uniformly shrinks over time as the number of particles increases. In this work,
we improve the dependence on logarithmic Sobolev inequality (LSI) constants in
their particle approximation errors, which can exponentially deteriorate with
the regularization coefficient. Specifically, we establish an LSI-constant-free
particle approximation error concerning the objective gap by leveraging the
problem structure in risk minimization. As the application, we demonstrate
improved convergence of MFLD, sampling guarantee for the mean-field stationary
distribution, and uniform-in-time Wasserstein propagation of chaos in terms of
particle complexity.",2024-05-24,Atsushi Nitanda,http://arxiv.org/pdf/2405.15767v3,cs.LG
Scaling Laws for Discriminative Classification in Large Language Models,"Modern large language models (LLMs) represent a paradigm shift in what can
plausibly be expected of machine learning models. The fact that LLMs can
effectively generate sensible answers to a diverse range of queries suggests
that they would be useful in customer support applications. While powerful,
LLMs have been observed to be prone to hallucination which unfortunately makes
their near term use in customer support applications challenging. To address
this issue we present a system that allows us to use an LLM to augment our
customer support advocates by re-framing the language modeling task as a
discriminative classification task. In this framing, we seek to present the
top-K best template responses for a customer support advocate to use when
responding to a customer. We present the result of both offline and online
experiments where we observed offline gains and statistically significant
online lifts for our experimental system. Along the way, we present observed
scaling curves for validation loss and top-K accuracy, resulted from model
parameter ablation studies. We close by discussing the space of trade-offs with
respect to model size, latency, and accuracy as well as and suggesting future
applications to explore.",2024-05-24,"Dean Wyatte, Fatemeh Tahmasbi, Ming Li, Thomas Markovich",http://arxiv.org/pdf/2405.15765v1,cs.LG
"Wasserstein Distances, Neuronal Entanglement, and Sparsity","Disentangling polysemantic neurons is at the core of many current approaches
to interpretability of large language models. Here we attempt to study how
disentanglement can be used to understand performance, particularly under
weight sparsity, a leading post-training optimization technique. We suggest a
novel measure for estimating neuronal entanglement: the Wasserstein distance of
a neuron's output distribution to a Gaussian. Moreover, we show the existence
of a small number of highly entangled ""Wasserstein Neurons"" in each linear
layer of an LLM, characterized by their highly non-Gaussian output
distributions, their role in mapping similar inputs to dissimilar outputs, and
their significant impact on model accuracy. To study these phenomena, we
propose a new experimental framework for disentangling polysemantic neurons.
Our framework separates each layer's inputs to create a mixture of experts
where each neuron's output is computed by a mixture of neurons of lower
Wasserstein distance, each better at maintaining accuracy when sparsified
without retraining. We provide strong evidence that this is because the mixture
of sparse experts is effectively disentangling the input-output relationship of
individual neurons, in particular the difficult Wasserstein neurons.",2024-05-24,"Shashata Sawmya, Linghao Kong, Ilia Markov, Dan Alistarh, Nir Shavit",http://arxiv.org/pdf/2405.15756v4,cs.LG
Score-based generative models are provably robust: an uncertainty quantification perspective,"Through an uncertainty quantification (UQ) perspective, we show that
score-based generative models (SGMs) are provably robust to the multiple
sources of error in practical implementation. Our primary tool is the
Wasserstein uncertainty propagation (WUP) theorem, a model-form UQ bound that
describes how the $L^2$ error from learning the score function propagates to a
Wasserstein-1 ($\mathbf{d}_1$) ball around the true data distribution under the
evolution of the Fokker-Planck equation. We show how errors due to (a) finite
sample approximation, (b) early stopping, (c) score-matching objective choice,
(d) score function parametrization expressiveness, and (e) reference
distribution choice, impact the quality of the generative model in terms of a
$\mathbf{d}_1$ bound of computable quantities. The WUP theorem relies on
Bernstein estimates for Hamilton-Jacobi-Bellman partial differential equations
(PDE) and the regularizing properties of diffusion processes. Specifically, PDE
regularity theory shows that stochasticity is the key mechanism ensuring SGM
algorithms are provably robust. The WUP theorem applies to integral probability
metrics beyond $\mathbf{d}_1$, such as the total variation distance and the
maximum mean discrepancy. Sample complexity and generalization bounds in
$\mathbf{d}_1$ follow directly from the WUP theorem. Our approach requires
minimal assumptions, is agnostic to the manifold hypothesis and avoids absolute
continuity assumptions for the target distribution. Additionally, our results
clarify the trade-offs among multiple error sources in SGMs.",2024-05-24,"Nikiforos Mimikos-Stamatopoulos, Benjamin J. Zhang, Markos A. Katsoulakis",http://arxiv.org/pdf/2405.15754v1,cs.LG
Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence,"This paper introduces Filtered Corpus Training, a method that trains language
models (LMs) on corpora with certain linguistic constructions filtered out from
the training data, and uses it to measure the ability of LMs to perform
linguistic generalization on the basis of indirect evidence. We apply the
method to both LSTM and Transformer LMs (of roughly comparable size),
developing filtered corpora that target a wide range of linguistic phenomena.
Our results show that while transformers are better qua LMs (as measured by
perplexity), both models perform equally and surprisingly well on linguistic
generalization measures, suggesting that they are capable of generalizing from
indirect evidence.",2024-05-24,"Abhinav Patil, Jaap Jumelet, Yu Ying Chiu, Andy Lapastora, Peter Shen, Lexie Wang, Clevis Willrich, Shane Steinert-Threlkeld",http://arxiv.org/pdf/2405.15750v2,cs.LG
CAFe: Cost and Age aware Federated Learning,"In many federated learning (FL) models, a common strategy employed to ensure
the progress in the training process, is to wait for at least $M$ clients out
of the total $N$ clients to send back their local gradients based on a
reporting deadline $T$, once the parameter server (PS) has broadcasted the
global model. If enough clients do not report back within the deadline, the
particular round is considered to be a failed round and the training round is
restarted from scratch. If enough clients have responded back, the round is
deemed successful and the local gradients of all the clients that responded
back are used to update the global model. In either case, the clients that
failed to report back an update within the deadline would have wasted their
computational resources. Having a tighter deadline (small $T$) and waiting for
a larger number of participating clients (large $M$) leads to a large number of
failed rounds and therefore greater communication cost and computation resource
wastage. However, having a larger $T$ leads to longer round durations whereas
smaller $M$ may lead to noisy gradients. Therefore, there is a need to optimize
the parameters $M$ and $T$ such that communication cost and the resource
wastage is minimized while having an acceptable convergence rate. In this
regard, we show that the average age of a client at the PS appears explicitly
in the theoretical convergence bound, and therefore, can be used as a metric to
quantify the convergence of the global model. We provide an analytical scheme
to select the parameters $M$ and $T$ in this setting.",2024-05-24,"Sahan Liyanaarachchi, Kanchana Thilakarathna, Sennur Ulukus",http://arxiv.org/pdf/2405.15744v1,cs.LG
Sparse maximal update parameterization: A holistic approach to sparse training dynamics,"Several challenges make it difficult for sparse neural networks to compete
with dense models. First, setting a large fraction of weights to zero impairs
forward and gradient signal propagation. Second, sparse studies often need to
test multiple sparsity levels, while also introducing new hyperparameters
(HPs), leading to prohibitive tuning costs. Indeed, the standard practice is to
re-use the learning HPs originally crafted for dense models. Unfortunately, we
show sparse and dense networks do not share the same optimal HPs. Without
stable dynamics and effective training recipes, it is costly to test sparsity
at scale, which is key to surpassing dense networks and making the business
case for sparsity acceleration in hardware.
  A holistic approach is needed to tackle these challenges and we propose
S$\mu$Par as one such approach. For random unstructured static sparsity,
S$\mu$Par ensures activations, gradients, and weight updates all scale
independently of sparsity level. Further, by reparameterizing the HPs,
S$\mu$Par enables the same HP values to be optimal as we vary both sparsity
level and model width. HPs can be tuned on small dense networks and transferred
to large sparse models, greatly reducing tuning costs. On large-scale language
modeling, S$\mu$Par shows increasing improvements over standard
parameterization as sparsity increases, leading up to 11.9% relative loss
improvement at 99.2% sparsity. A minimal implementation of S$\mu$Par is
available at https://github.com/EleutherAI/nanoGPT-mup/tree/supar.",2024-05-24,"Nolan Dey, Shane Bergsma, Joel Hestness",http://arxiv.org/pdf/2405.15743v2,cs.LG
Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias,"Citation practices are crucial in shaping the structure of scientific
knowledge, yet they are often influenced by contemporary norms and biases. The
emergence of Large Language Models (LLMs) introduces a new dynamic to these
practices. Interestingly, the characteristics and potential biases of
references recommended by LLMs that entirely rely on their parametric
knowledge, and not on search or retrieval-augmented generation, remain
unexplored. Here, we analyze these characteristics in an experiment using a
dataset from AAAI, NeurIPS, ICML, and ICLR, published after GPT-4's knowledge
cut-off date. In our experiment, LLMs are tasked with suggesting scholarly
references for the anonymized in-text citations within these papers. Our
findings reveal a remarkable similarity between human and LLM citation
patterns, but with a more pronounced high citation bias, which persists even
after controlling for publication year, title length, number of authors, and
venue. The results hold for both GPT-4, and the more capable models GPT-4o and
Claude 3.5 where the papers are part of the training data. Additionally, we
observe a large consistency between the characteristics of LLM's existing and
non-existent generated references, indicating the model's internalization of
citation patterns. By analyzing citation graphs, we show that the references
recommended are embedded in the relevant citation context, suggesting an even
deeper conceptual internalization of the citation networks. While LLMs can aid
in citation generation, they may also amplify existing biases, such as the
Matthew effect, and introduce new ones, potentially skewing scientific
knowledge dissemination.",2024-05-24,"Andres Algaba, Carmen Mazijn, Vincent Holst, Floriano Tori, Sylvia Wenmackers, Vincent Ginis",http://arxiv.org/pdf/2405.15739v3,cs.LG
Neural Persistence Dynamics,"We consider the problem of learning the dynamics in the topology of
time-evolving point clouds, the prevalent spatiotemporal model for systems
exhibiting collective behavior, such as swarms of insects and birds or
particles in physics. In such systems, patterns emerge from (local)
interactions among self-propelled entities. While several well-understood
governing equations for motion and interaction exist, they are notoriously
difficult to fit to data, as most prior work requires knowledge about
individual motion trajectories, i.e., a requirement that is challenging to
satisfy with an increasing number of entities. To evade such confounding
factors, we investigate collective behavior from a $\textit{topological
perspective}$, but instead of summarizing entire observation sequences (as done
previously), we propose learning a latent dynamical model from topological
features $\textit{per time point}$. The latter is then used to formulate a
downstream regression task to predict the parametrization of some a priori
specified governing equation. We implement this idea based on a latent ODE
learned from vectorized (static) persistence diagrams and show that a
combination of recent stability results for persistent homology justifies this
modeling choice. Various (ablation) experiments not only demonstrate the
relevance of each model component but provide compelling empirical evidence
that our proposed model - $\textit{Neural Persistence Dynamics}$ -
substantially outperforms the state-of-the-art across a diverse set of
parameter regression tasks.",2024-05-24,"Sebastian Zeng, Florian Graf, Martin Uray, Stefan Huber, Roland Kwitt",http://arxiv.org/pdf/2405.15732v2,cs.LG
"Understanding the differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks","Softmax attention is the principle backbone of foundation models for various
artificial intelligence applications, yet its quadratic complexity in sequence
length can limit its inference throughput in long-context settings. To address
this challenge, alternative architectures such as linear attention, State Space
Models (SSMs), and Recurrent Neural Networks (RNNs) have been considered as
more efficient alternatives. While connections between these approaches exist,
such models are commonly developed in isolation and there is a lack of
theoretical understanding of the shared principles underpinning these
architectures and their subtle differences, greatly influencing performance and
scalability. In this paper, we introduce the Dynamical Systems Framework (DSF),
which allows a principled investigation of all these architectures in a common
representation. Our framework facilitates rigorous comparisons, providing new
insights on the distinctive characteristics of each model class. For instance,
we compare linear attention and selective SSMs, detailing their differences and
conditions under which both are equivalent. We also provide principled
comparisons between softmax attention and other model classes, discussing the
theoretical conditions under which softmax attention can be approximated.
Additionally, we substantiate these new insights with empirical validations and
mathematical arguments. This shows the DSF's potential to guide the systematic
development of future more efficient and scalable foundation models.",2024-05-24,"Jerome Sieber, Carmen Amo Alonso, Alexandre Didier, Melanie N. Zeilinger, Antonio Orvieto",http://arxiv.org/pdf/2405.15731v3,cs.LG
Optimizing Large Language Models for OpenAPI Code Completion,"Recent advancements in Large Language Models (LLMs) and their utilization in
code generation tasks have significantly reshaped the field of software
development. Despite the remarkable efficacy of code completion solutions in
mainstream programming languages, their performance lags when applied to less
ubiquitous formats such as OpenAPI definitions. This study evaluates the
OpenAPI completion performance of GitHub Copilot, a prevalent commercial code
completion tool, and proposes a set of task-specific optimizations leveraging
Meta's open-source model Code Llama. A semantics-aware OpenAPI completion
benchmark proposed in this research is used to perform a series of experiments
through which the impact of various prompt-engineering and fine-tuning
techniques on the Code Llama model's performance is analyzed. The fine-tuned
Code Llama model reaches a peak correctness improvement of 55.2% over GitHub
Copilot despite utilizing 25 times fewer parameters than the commercial
solution's underlying Codex model. Additionally, this research proposes an
enhancement to a widely used code infilling training technique, addressing the
issue of underperformance when the model is prompted with context sizes smaller
than those used during training. The dataset, the benchmark, and the model
fine-tuning code are made publicly available.",2024-05-24,"Bohdan Petryshyn, Mantas Lukoševičius",http://arxiv.org/pdf/2405.15729v2,cs.LG
Anomalous Change Point Detection Using Probabilistic Predictive Coding,"Change point detection (CPD) and anomaly detection (AD) are essential
techniques in various fields to identify abrupt changes or abnormal data
instances. However, existing methods are often constrained to univariate data,
face scalability challenges with large datasets due to computational demands,
and experience reduced performance with high-dimensional or intricate data, as
well as hidden anomalies. Furthermore, they often lack interpretability and
adaptability to domain-specific knowledge, which limits their versatility
across different fields. In this work, we propose a deep learning-based CPD/AD
method called Probabilistic Predictive Coding (PPC) that jointly learns to
encode sequential data to low dimensional latent space representations and to
predict the subsequent data representations as well as the corresponding
prediction uncertainties. The model parameters are optimized with maximum
likelihood estimation by comparing these predictions with the true encodings.
At the time of application, the true and predicted encodings are used to
determine the probability of conformity, an interpretable and meaningful
anomaly score. Furthermore, our approach has linear time complexity,
scalability issues are prevented, and the method can easily be adjusted to a
wide range of data types and intricate applications. We demonstrate the
effectiveness and adaptability of our proposed method across synthetic time
series experiments, image data, and real-world magnetic resonance spectroscopic
imaging data.",2024-05-24,"Roelof G. Hup, Julian P. Merkofer, Alex A. Bhogal, Ruud J. G. van Sloun, Reinder Haakma, Rik Vullings",http://arxiv.org/pdf/2405.15727v1,cs.LG
Bisimulation Learning,"We introduce a data-driven approach to computing finite bisimulations for
state transition systems with very large, possibly infinite state space. Our
novel technique computes stutter-insensitive bisimulations of deterministic
systems, which we characterize as the problem of learning a state classifier
together with a ranking function for each class. Our procedure learns a
candidate state classifier and candidate ranking functions from a finite
dataset of sample states; then, it checks whether these generalise to the
entire state space using satisfiability modulo theory solving. Upon the
affirmative answer, the procedure concludes that the classifier constitutes a
valid stutter-insensitive bisimulation of the system. Upon a negative answer,
the solver produces a counterexample state for which the classifier violates
the claim, adds it to the dataset, and repeats learning and checking in a
counterexample-guided inductive synthesis loop until a valid bisimulation is
found. We demonstrate on a range of benchmarks from reactive verification and
software model checking that our method yields faster verification results than
alternative state-of-the-art tools in practice. Our method produces succinct
abstractions that enable an effective verification of linear temporal logic
without next operator, and are interpretable for system diagnostics.",2024-05-24,"Alessandro Abate, Mirco Giacobbe, Yannik Schnitzer",http://arxiv.org/pdf/2405.15723v1,cs.LG
Models That Prove Their Own Correctness,"How can we trust the correctness of a learned model on a particular input of
interest? Model accuracy is typically measured *on average* over a distribution
of inputs, giving no guarantee for any fixed input. This paper proposes a
theoretically-founded solution to this problem: to train *Self-Proving models*
that prove the correctness of their output to a verification algorithm $V$ via
an Interactive Proof. Self-Proving models satisfy that, with high probability
over a random input, the model generates a correct output *and* successfully
proves its correctness to $V\!$. The *soundness* property of $V$ guarantees
that, for *every* input, no model can convince $V$ of the correctness of an
incorrect output. Thus, a Self-Proving model proves correctness of most of its
outputs, while *all* incorrect outputs (of any model) are detected by $V$. We
devise a generic method for learning Self-Proving models, and we prove
convergence bounds under certain assumptions. The theoretical framework and
results are complemented by experiments on an arithmetic capability: computing
the greatest common divisor (GCD) of two integers. Our learning method is used
to train a Self-Proving transformer that computes the GCD *and* proves the
correctness of its answer.",2024-05-24,"Noga Amit, Shafi Goldwasser, Orr Paradise, Guy Rothblum",http://arxiv.org/pdf/2405.15722v3,cs.LG
Hierarchical Uncertainty Exploration via Feedforward Posterior Trees,"When solving ill-posed inverse problems, one often desires to explore the
space of potential solutions rather than be presented with a single plausible
reconstruction. Valuable insights into these feasible solutions and their
associated probabilities are embedded in the posterior distribution. However,
when confronted with data of high dimensionality (such as images), visualizing
this distribution becomes a formidable challenge, necessitating the application
of effective summarization techniques before user examination. In this work, we
introduce a new approach for visualizing posteriors across multiple levels of
granularity using tree-valued predictions. Our method predicts a tree-valued
hierarchical summarization of the posterior distribution for any input
measurement, in a single forward pass of a neural network. We showcase the
efficacy of our approach across diverse datasets and image restoration
challenges, highlighting its prowess in uncertainty quantification and
visualization. Our findings reveal that our method performs comparably to a
baseline that hierarchically clusters samples from a diffusion-based posterior
sampler, yet achieves this with orders of magnitude greater speed.",2024-05-24,"Elias Nehme, Rotem Mulayoff, Tomer Michaeli",http://arxiv.org/pdf/2405.15719v1,cs.LG
Infinite Limits of Multi-head Transformer Dynamics,"In this work, we analyze various scaling limits of the training dynamics of
transformer models in the feature learning regime. We identify the set of
parameterizations that admit well-defined infinite width and depth limits,
allowing the attention layers to update throughout training--a relevant notion
of feature learning in these models. We then use tools from dynamical mean
field theory (DMFT) to analyze various infinite limits (infinite key/query
dimension, infinite heads, and infinite depth) which have different statistical
descriptions depending on which infinite limit is taken and how attention
layers are scaled. We provide numerical evidence of convergence to the limits
and discuss how the parameterization qualitatively influences learned features.",2024-05-24,"Blake Bordelon, Hamza Tahir Chaudhry, Cengiz Pehlevan",http://arxiv.org/pdf/2405.15712v2,cs.LG
Information-theoretic Generalization Analysis for Expected Calibration Error,"While the expected calibration error (ECE), which employs binning, is widely
adopted to evaluate the calibration performance of machine learning models,
theoretical understanding of its estimation bias is limited. In this paper, we
present the first comprehensive analysis of the estimation bias in the two
common binning strategies, uniform mass and uniform width binning. Our analysis
establishes upper bounds on the bias, achieving an improved convergence rate.
Moreover, our bounds reveal, for the first time, the optimal number of bins to
minimize the estimation bias. We further extend our bias analysis to
generalization error analysis based on the information-theoretic approach,
deriving upper bounds that enable the numerical evaluation of how small the ECE
is for unknown data. Experiments using deep learning models show that our
bounds are nonvacuous thanks to this information-theoretic generalization
analysis approach.",2024-05-24,"Futoshi Futami, Masahiro Fujisawa",http://arxiv.org/pdf/2405.15709v2,cs.LG
The Impact of Geometric Complexity on Neural Collapse in Transfer Learning,"Many of the recent remarkable advances in computer vision and language models
can be attributed to the success of transfer learning via the pre-training of
large foundation models. However, a theoretical framework which explains this
empirical success is incomplete and remains an active area of research.
Flatness of the loss surface and neural collapse have recently emerged as
useful pre-training metrics which shed light on the implicit biases underlying
pre-training. In this paper, we explore the geometric complexity of a model's
learned representations as a fundamental mechanism that relates these two
concepts. We show through experiments and theory that mechanisms which affect
the geometric complexity of the pre-trained network also influence the neural
collapse. Furthermore, we show how this effect of the geometric complexity
generalizes to the neural collapse of new classes as well, thus encouraging
better performance on downstream tasks, particularly in the few-shot setting.",2024-05-24,"Michael Munn, Benoit Dherin, Javier Gonzalvo",http://arxiv.org/pdf/2405.15706v3,cs.LG
Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification,"Medical time series (MedTS) data, such as Electroencephalography (EEG) and
Electrocardiography (ECG), play a crucial role in healthcare, such as
diagnosing brain and heart diseases. Existing methods for MedTS classification
primarily rely on handcrafted biomarkers extraction and CNN-based models, with
limited exploration of transformer-based models. In this paper, we introduce
Medformer, a multi-granularity patching transformer tailored specifically for
MedTS classification. Our method incorporates three novel mechanisms to
leverage the unique characteristics of MedTS: cross-channel patching to
leverage inter-channel correlations, multi-granularity embedding for capturing
features at different scales, and two-stage (intra- and inter-granularity)
multi-granularity self-attention for learning features and correlations within
and among granularities. We conduct extensive experiments on five public
datasets under both subject-dependent and challenging subject-independent
setups. Results demonstrate Medformer's superiority over 10 baselines,
achieving top averaged ranking across five datasets on all six evaluation
metrics. These findings underscore the significant impact of our method on
healthcare applications, such as diagnosing Myocardial Infarction, Alzheimer's,
and Parkinson's disease. We release the source code at
https://github.com/DL4mHealth/Medformer.",2024-05-24,"Yihe Wang, Nan Huang, Taida Li, Yujun Yan, Xiang Zhang",http://arxiv.org/pdf/2405.19363v2,cs.LG
Dimension-free deterministic equivalents and scaling laws for random feature regression,"In this work we investigate the generalization performance of random feature
ridge regression (RFRR). Our main contribution is a general deterministic
equivalent for the test error of RFRR. Specifically, under a certain
concentration property, we show that the test error is well approximated by a
closed-form expression that only depends on the feature map eigenvalues.
Notably, our approximation guarantee is non-asymptotic, multiplicative, and
independent of the feature map dimension -- allowing for infinite-dimensional
features. We expect this deterministic equivalent to hold broadly beyond our
theoretical analysis, and we empirically validate its predictions on various
real and synthetic datasets. As an application, we derive sharp excess error
rates under standard power-law assumptions of the spectrum and target decay. In
particular, we provide a tight result for the smallest number of features
achieving optimal minimax error rate.",2024-05-24,"Leonardo Defilippis, Bruno Loureiro, Theodor Misiakiewicz",http://arxiv.org/pdf/2405.15699v3,cs.LG
Chain-of-Thought Prompting for Demographic Inference with Large Multimodal Models,"Conventional demographic inference methods have predominantly operated under
the supervision of accurately labeled data, yet struggle to adapt to shifting
social landscapes and diverse cultural contexts, leading to narrow
specialization and limited accuracy in applications. Recently, the emergence of
large multimodal models (LMMs) has shown transformative potential across
various research tasks, such as visual comprehension and description. In this
study, we explore the application of LMMs to demographic inference and
introduce a benchmark for both quantitative and qualitative evaluation. Our
findings indicate that LMMs possess advantages in zero-shot learning,
interpretability, and handling uncurated 'in-the-wild' inputs, albeit with a
propensity for off-target predictions. To enhance LMM performance and achieve
comparability with supervised learning baselines, we propose a Chain-of-Thought
augmented prompting approach, which effectively mitigates the off-target
prediction issue.",2024-05-24,"Yongsheng Yu, Jiebo Luo",http://arxiv.org/pdf/2405.15687v1,cs.LG
The Road Less Scheduled,"Existing learning rate schedules that do not require specification of the
optimization stopping step T are greatly out-performed by learning rate
schedules that depend on T. We propose an approach that avoids the need for
this stopping time by eschewing the use of schedules entirely, while exhibiting
state-of-the-art performance compared to schedules across a wide family of
problems ranging from convex problems to large-scale deep learning problems.
Our Schedule-Free approach introduces no additional hyper-parameters over
standard optimizers with momentum. Our method is a direct consequence of a new
theory we develop that unifies scheduling and iterate averaging. An open source
implementation of our method is available at
https://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the
core algorithm behind our winning entry to the MLCommons 2024 AlgoPerf
Algorithmic Efficiency Challenge Self-Tuning track.",2024-05-24,"Aaron Defazio, Xingyu Alice Yang, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, Ashok Cutkosky",http://arxiv.org/pdf/2405.15682v4,cs.LG
Model Cascading for Code: A Cascaded Black-Box Multi-Model Framework for Cost-Efficient Code Completion with Self-Testing,"The rapid advancement of large language models (LLMs) has significantly
improved code completion tasks, yet the trade-off between accuracy and
computational cost remains a critical challenge. While using larger models and
incorporating inference-time self-testing algorithms can significantly improve
output accuracy, they incur substantial computational expenses at the same
time. Furthermore, servers in real-world scenarios usually have a dynamic
preference on the cost-accuracy tradeoff, depending on the budget, bandwidth,
the concurrent user volume, and users' sensitivity to wrong answers. In this
work, we introduce a novel framework combining model cascading and
inference-time self-feedback algorithms to find multiple near-optimal
self-testing options on the cost-accuracy tradeoff in LLM-based code
generation. Our approach leverages self-generated tests to both enhance
accuracy and evaluate model cascading decisions. As a blackbox inference-time
method, it requires no access to internal model parameters. We further propose
a threshold-based algorithm to determine when to deploy larger models and a
heuristic to optimize the number of solutions, test cases, and test lines
generated per model, based on budget constraints. Experimental results show
that our cascading approach reduces costs by an average of 26%, and up to 70%
in the best case, across various model families and datasets, while maintaining
or improving accuracy in natural language generation tasks compared to both
random and optimal single-model self-testing schemes. To our knowledge, this is
the first work to provide a series of choices for optimizing the cost-accuracy
trade-off in LLM code generation with self-testing.",2024-05-24,"Boyuan Chen, Mingzhi Zhu, Brendan Dolan-Gavitt, Muhammad Shafique, Siddharth Garg",http://arxiv.org/pdf/2405.15842v2,cs.LG
Bridging The Gap between Low-rank and Orthogonal Adaptation via Householder Reflection Adaptation,"While following different technical routes, both low-rank and orthogonal
adaptation techniques can efficiently adapt large-scale pre-training models in
specific tasks or domains based on a small piece of trainable parameters. In
this study, we bridge the gap between these two techniques, proposing a simple
but effective adaptation method based on Householder reflections. Given a
pre-trained model, our method fine-tunes its layers by multiplying each frozen
weight matrix with an orthogonal matrix constructed by a chain of learnable
Householder reflections (HRs). This HR-based orthogonal fine-tuning is
equivalent to an adaptive low-rank adaptation. Moreover, we show that the
orthogonality of the reflection planes corresponding to the HRs impacts the
model capacity and regularity. The analysis motivates us to regularize the
orthogonality of the HRs, leading to different implementations of the proposed
Householder reflection adaptation (HRA) method. Compared with state-of-the-art
methods, HRA achieves superior performance with fewer learnable parameters when
adapting large language models and conditional image generators. The code of
the experiments is available at \url{https://github.com/DaShenZi721/HRA}, and
the method has been merged into the
\href{https://github.com/huggingface/peft}{PEFT} package.",2024-05-24,"Shen Yuan, Haotian Liu, Hongteng Xu",http://arxiv.org/pdf/2405.17484v3,cs.LG
Taming Score-Based Diffusion Priors for Infinite-Dimensional Nonlinear Inverse Problems,"This work introduces a sampling method capable of solving Bayesian inverse
problems in function space. It does not assume the log-concavity of the
likelihood, meaning that it is compatible with nonlinear inverse problems. The
method leverages the recently defined infinite-dimensional score-based
diffusion models as a learning-based prior, while enabling provable posterior
sampling through a Langevin-type MCMC algorithm defined on function spaces. A
novel convergence analysis is conducted, inspired by the fixed-point methods
established for traditional regularization-by-denoising algorithms and
compatible with weighted annealing. The obtained convergence bound explicitly
depends on the approximation error of the score; a well-approximated score is
essential to obtain a well-approximated posterior. Stylized and PDE-based
examples are provided, demonstrating the validity of our convergence analysis.
We conclude by presenting a discussion of the method's challenges related to
learning the score and computational complexity.",2024-05-24,"Lorenzo Baldassari, Ali Siahkoohi, Josselin Garnier, Knut Solna, Maarten V. de Hoop",http://arxiv.org/pdf/2405.15676v1,cs.LG
Consistency of Neural Causal Partial Identification,"Recent progress in Neural Causal Models (NCMs) showcased how identification
and partial identification of causal effects can be automatically carried out
via training of neural generative models that respect the constraints encoded
in a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,
formal consistency of these methods has only been proven for the case of
discrete variables or only for linear causal models. In this work, we prove the
consistency of partial identification via NCMs in a general setting with both
continuous and categorical variables. Further, our results highlight the impact
of the design of the underlying neural network architecture in terms of depth
and connectivity as well as the importance of applying Lipschitz regularization
in the training phase. In particular, we provide a counterexample showing that
without Lipschitz regularization this method may not be asymptotically
consistent. Our results are enabled by new results on the approximability of
Structural Causal Models (SCMs) via neural generative models, together with an
analysis of the sample complexity of the resulting architectures and how that
translates into an error in the constrained optimization problem that defines
the partial identification bounds.",2024-05-24,"Jiyuan Tan, Jose Blanchet, Vasilis Syrgkanis",http://arxiv.org/pdf/2405.15673v2,cs.LG
Learning the Language of Protein Structure,"Representation learning and \emph{de novo} generation of proteins are pivotal
computational biology tasks. Whilst natural language processing (NLP)
techniques have proven highly effective for protein sequence modelling,
structure modelling presents a complex challenge, primarily due to its
continuous and three-dimensional nature. Motivated by this discrepancy, we
introduce an approach using a vector-quantized autoencoder that effectively
tokenizes protein structures into discrete representations. This method
transforms the continuous, complex space of protein structures into a
manageable, discrete format with a codebook ranging from 4096 to 64000 tokens,
achieving high-fidelity reconstructions with backbone root mean square
deviations (RMSD) of approximately 1-5 \AA. To demonstrate the efficacy of our
learned representations, we show that a simple GPT model trained on our
codebooks can generate novel, diverse, and designable protein structures. Our
approach not only provides representations of protein structure, but also
mitigates the challenges of disparate modal representations and sets a
foundation for seamless, multi-modal integration, enhancing the capabilities of
computational methods in protein design.",2024-05-24,"Benoit Gaujac, Jérémie Donà, Liviu Copoiu, Timothy Atkinson, Thomas Pierrot, Thomas D. Barrett",http://arxiv.org/pdf/2405.15840v2,cs.LG
Class Machine Unlearning for Complex Data via Concepts Inference and Data Poisoning,"In current AI era, users may request AI companies to delete their data from
the training dataset due to the privacy concerns. As a model owner, retraining
a model will consume significant computational resources. Therefore, machine
unlearning is a new emerged technology to allow model owner to delete requested
training data or a class with little affecting on the model performance.
However, for large-scaling complex data, such as image or text data, unlearning
a class from a model leads to a inferior performance due to the difficulty to
identify the link between classes and model. An inaccurate class deleting may
lead to over or under unlearning. In this paper, to accurately defining the
unlearning class of complex data, we apply the definition of Concept, rather
than an image feature or a token of text data, to represent the semantic
information of unlearning class. This new representation can cut the link
between the model and the class, leading to a complete erasing of the impact of
a class. To analyze the impact of the concept of complex data, we adopt a
Post-hoc Concept Bottleneck Model, and Integrated Gradients to precisely
identify concepts across different classes. Next, we take advantage of data
poisoning with random and targeted labels to propose unlearning methods. We
test our methods on both image classification models and large language models
(LLMs). The results consistently show that the proposed methods can accurately
erase targeted information from models and can largely maintain the performance
of the models.",2024-05-24,"Wenhan Chang, Tianqing Zhu, Heng Xu, Wenjian Liu, Wanlei Zhou",http://arxiv.org/pdf/2405.15662v1,cs.LG
HiddenSpeaker: Generate Imperceptible Unlearnable Audios for Speaker Verification System,"In recent years, the remarkable advancements in deep neural networks have
brought tremendous convenience. However, the training process of a highly
effective model necessitates a substantial quantity of samples, which brings
huge potential threats, like unauthorized exploitation with privacy leakage. In
response, we propose a framework named HiddenSpeaker, embedding imperceptible
perturbations within the training speech samples and rendering them unlearnable
for deep-learning-based speaker verification systems that employ large-scale
speakers for efficient training. The HiddenSpeaker utilizes a simplified
error-minimizing method named Single-Level Error-Minimizing (SLEM) to generate
specific and effective perturbations. Additionally, a hybrid objective function
is employed for human perceptual optimization, ensuring the perturbation is
indistinguishable from human listeners. We conduct extensive experiments on
multiple state-of-the-art (SOTA) models in the speaker verification domain to
evaluate HiddenSpeaker. Our results demonstrate that HiddenSpeaker not only
deceives the model with unlearnable samples but also enhances the
imperceptibility of the perturbations, showcasing strong transferability across
different models.",2024-05-24,"Zhisheng Zhang, Pengyang Huang",http://arxiv.org/pdf/2405.15655v2,cs.LG
Planted: a dataset for planted forest identification from multi-satellite time series,"Protecting and restoring forest ecosystems is critical for biodiversity
conservation and carbon sequestration. Forest monitoring on a global scale is
essential for prioritizing and assessing conservation efforts. Satellite-based
remote sensing is the only viable solution for providing global coverage, but
to date, large-scale forest monitoring is limited to single modalities and
single time points. In this paper, we present a dataset consisting of data from
five public satellites for recognizing forest plantations and planted tree
species across the globe. Each satellite modality consists of a multi-year time
series. The dataset, named \PlantD, includes over 2M examples of 64 tree label
classes (46 genera and 40 species), distributed among 41 countries. This
dataset is released to foster research in forest monitoring using multimodal,
multi-scale, multi-temporal data sources. Additionally, we present initial
baseline results and evaluate modality fusion and data augmentation approaches
for this dataset.",2024-05-24,"Luis Miguel Pazos-Outón, Cristina Nader Vasconcelos, Anton Raichuk, Anurag Arnab, Dan Morris, Maxim Neumann",http://arxiv.org/pdf/2406.18554v1,cs.LG
Harnessing Increased Client Participation with Cohort-Parallel Federated Learning,"Federated learning (FL) is a machine learning approach where nodes
collaboratively train a global model. As more nodes participate in a round of
FL, the effectiveness of individual model updates by nodes also diminishes. In
this study, we increase the effectiveness of client updates by dividing the
network into smaller partitions, or cohorts. We introduce Cohort-Parallel
Federated Learning (CPFL): a novel learning approach where each cohort
independently trains a global model using FL, until convergence, and the
produced models by each cohort are then unified using knowledge distillation.
The insight behind CPFL is that smaller, isolated networks converge quicker
than in a one-network setting where all nodes participate. Through exhaustive
experiments involving realistic traces and non-IID data distributions on the
CIFAR-10 and FEMNIST image classification tasks, we investigate the balance
between the number of cohorts, model accuracy, training time, and compute
resources. Compared to traditional FL, CPFL with four cohorts, non-IID data
distribution, and CIFAR-10 yields a 1.9x reduction in train time and a 1.3x
reduction in resource usage, with a minimal drop in test accuracy.",2024-05-24,"Akash Dhasade, Anne-Marie Kermarrec, Tuan-Anh Nguyen, Rafael Pires, Martijn de Vos",http://arxiv.org/pdf/2405.15644v2,cs.LG
Scalable diffusion posterior sampling in infinite-dimensional inverse problems,"Score-based diffusion models (SDMs) have emerged as a powerful tool for
sampling from the posterior distribution in Bayesian inverse problems. However,
existing methods often require multiple evaluations of the forward mapping to
generate a single sample, resulting in significant computational costs for
large-scale inverse problems. To address this issue, we propose a scalable
diffusion posterior sampling (SDPS) method to bypass forward mapping
evaluations during sampling by shifting computational effort to an offline
training phase, where a task-dependent score is learned based on the forward
mapping. Crucially, the conditional posterior score is then derived from this
trained score using affine transformations, ensuring no conditional score
approximation is needed. The approach is shown to generalize to
infinite-dimensional diffusion models and is validated through rigorous
convergence analysis and high-dimensional CT imaging experiments.",2024-05-24,"Fabian Schneider, Duc-Lam Duong, Matti Lassas, Maarten V. de Hoop, Tapio Helin",http://arxiv.org/pdf/2405.15643v2,cs.LG
Effective Confidence Region Prediction Using Probability Forecasters,"Confidence region prediction is a practically useful extension to the
commonly studied pattern recognition problem. Instead of predicting a single
label, the constraint is relaxed to allow prediction of a subset of labels
given a desired confidence level 1-delta. Ideally, effective region predictions
should be (1) well calibrated - predictive regions at confidence level 1-delta
should err with relative frequency at most delta and (2) be as narrow (or
certain) as possible. We present a simple technique to generate confidence
region predictions from conditional probability estimates (probability
forecasts). We use this 'conversion' technique to generate confidence region
predictions from probability forecasts output by standard machine learning
algorithms when tested on 15 multi-class datasets. Our results show that
approximately 44% of experiments demonstrate well-calibrated confidence region
predictions, with the K-Nearest Neighbour algorithm tending to perform
consistently well across all data. Our results illustrate the practical
benefits of effective confidence region prediction with respect to medical
diagnostics, where guarantees of capturing the true disease label can be given.",2024-05-24,"David Lindsay, Sian Lindsay",http://arxiv.org/pdf/2405.15642v1,cs.LG
Personalized Adapter for Large Meteorology Model on Devices: Towards Weather Foundation Models,"This paper demonstrates that pre-trained language models (PLMs) are strong
foundation models for on-device meteorological variables modeling. We present
LM-Weather, a generic approach to taming PLMs, that have learned massive
sequential knowledge from the universe of natural language databases, to
acquire an immediate capability to obtain highly customized models for
heterogeneous meteorological data on devices while keeping high efficiency.
Concretely, we introduce a lightweight personalized adapter into PLMs and
endows it with weather pattern awareness. During communication between clients
and the server, low-rank-based transmission is performed to effectively fuse
the global knowledge among devices while maintaining high communication
efficiency and ensuring privacy. Experiments on real-wold dataset show that
LM-Weather outperforms the state-of-the-art results by a large margin across
various tasks (e.g., forecasting and imputation at different scales). We
provide extensive and in-depth analyses experiments, which verify that
LM-Weather can (1) indeed leverage sequential knowledge from natural language
to accurately handle meteorological sequence, (2) allows each devices obtain
highly customized models under significant heterogeneity, and (3) generalize
under data-limited and out-of-distribution (OOD) scenarios.",2024-05-24,"Shengchao Chen, Guodong Long, Jing Jiang, Chengqi Zhang",http://arxiv.org/pdf/2405.20348v1,cs.LG
Visualize and Paint GAN Activations,"We investigate how generated structures of GANs correlate with their
activations in hidden layers, with the purpose of better understanding the
inner workings of those models and being able to paint structures with
unconditionally trained GANs. This gives us more control over the generated
images, allowing to generate them from a semantic segmentation map while not
requiring such a segmentation in the training data. To this end we introduce
the concept of tileable features, allowing us to identify activations that work
well for painting.",2024-05-24,"Rudolf Herdt, Peter Maass",http://arxiv.org/pdf/2405.15636v3,cs.LG
Federated Behavioural Planes: Explaining the Evolution of Client Behaviour in Federated Learning,"Federated Learning (FL), a privacy-aware approach in distributed deep
learning environments, enables many clients to collaboratively train a model
without sharing sensitive data, thereby reducing privacy risks. However,
enabling human trust and control over FL systems requires understanding the
evolving behaviour of clients, whether beneficial or detrimental for the
training, which still represents a key challenge in the current literature. To
address this challenge, we introduce Federated Behavioural Planes (FBPs), a
novel method to analyse, visualise, and explain the dynamics of FL systems,
showing how clients behave under two different lenses: predictive performance
(error behavioural space) and decision-making processes (counterfactual
behavioural space). Our experiments demonstrate that FBPs provide informative
trajectories describing the evolving states of clients and their contributions
to the global model, thereby enabling the identification of clusters of clients
with similar behaviours. Leveraging the patterns identified by FBPs, we propose
a robust aggregation technique named Federated Behavioural Shields to detect
malicious or noisy client models, thereby enhancing security and surpassing the
efficacy of existing state-of-the-art FL defense mechanisms. Our code is
publicly available on GitHub.",2024-05-24,"Dario Fenoglio, Gabriele Dominici, Pietro Barbiero, Alberto Tonda, Martin Gjoreski, Marc Langheinrich",http://arxiv.org/pdf/2405.15632v2,cs.LG
Nonlinear denoising score matching for enhanced learning of structured distributions,"We present a novel method for training score-based generative models which
uses nonlinear noising dynamics to improve learning of structured
distributions. Generalizing to a nonlinear drift allows for additional
structure to be incorporated into the dynamics, thus making the training better
adapted to the data, e.g., in the case of multimodality or (approximate)
symmetries. Such structure can be obtained from the data by an inexpensive
preprocessing step. The nonlinear dynamics introduces new challenges into
training which we address in two ways: 1) we develop a new nonlinear denoising
score matching (NDSM) method, 2) we introduce neural control variates in order
to reduce the variance of the NDSM training objective. We demonstrate the
effectiveness of this method on several examples: a) a collection of
low-dimensional examples, motivated by clustering in latent space, b)
high-dimensional images, addressing issues with mode collapse, small training
sets, and approximate symmetries, the latter being a challenge for methods
based on equivariant neural networks, which require exact symmetries.",2024-05-24,"Jeremiah Birrell, Markos A. Katsoulakis, Luc Rey-Bellet, Benjamin Zhang, Wei Zhu",http://arxiv.org/pdf/2405.15625v1,cs.LG
Inverse-RLignment: Large Language Model Alignment from Demonstrations through Inverse Reinforcement Learning,"Aligning Large Language Models (LLMs) is crucial for enhancing their safety
and utility. However, existing methods, primarily based on preference datasets,
face challenges such as noisy labels, high annotation costs, and privacy
concerns. In this work, we introduce Alignment from Demonstrations (AfD), a
novel approach leveraging high-quality demonstration data to overcome these
challenges. We formalize AfD within a sequential decision-making framework,
highlighting its unique challenge of missing reward signals. Drawing insights
from forward and inverse reinforcement learning, we introduce divergence
minimization objectives for AfD. Analytically, we elucidate the mass-covering
and mode-seeking behaviors of various approaches, explaining when and why
certain methods are superior. Practically, we propose a computationally
efficient algorithm that extrapolates over a tailored reward model for AfD. We
validate our key insights through experiments on the Harmless and Helpful
tasks, demonstrating their strong empirical performance while maintaining
simplicity.",2024-05-24,"Hao Sun, Mihaela van der Schaar",http://arxiv.org/pdf/2405.15624v2,cs.LG
MLPs Learn In-Context on Regression and Classification Tasks,"In-context learning (ICL), the remarkable ability to solve a task from only
input exemplars, is often assumed to be a unique hallmark of Transformer
models. By examining commonly employed synthetic ICL tasks, we demonstrate that
multi-layer perceptrons (MLPs) can also learn in-context. Moreover, MLPs, and
the closely related MLP-Mixer models, learn in-context comparably with
Transformers under the same compute budget in this setting. We further show
that MLPs outperform Transformers on a series of classical tasks from
psychology designed to test relational reasoning, which are closely related to
in-context classification. These results underscore a need for studying
in-context learning beyond attention-based architectures, while also
challenging prior arguments against MLPs' ability to solve relational tasks.
Altogether, our results highlight the unexpected competence of MLPs in a
synthetic setting, and support the growing interest in all-MLP alternatives to
Transformer architectures. It remains unclear how MLPs perform against
Transformers at scale on real-world tasks, and where a performance gap may
originate. We encourage further exploration of these architectures in more
complex settings to better understand the potential comparative advantage of
attention-based schemes.",2024-05-24,"William L. Tong, Cengiz Pehlevan",http://arxiv.org/pdf/2405.15618v3,cs.LG
Neuromorphic dreaming: A pathway to efficient learning in artificial agents,"Achieving energy efficiency in learning is a key challenge for artificial
intelligence (AI) computing platforms. Biological systems demonstrate
remarkable abilities to learn complex skills quickly and efficiently. Inspired
by this, we present a hardware implementation of model-based reinforcement
learning (MBRL) using spiking neural networks (SNNs) on mixed-signal
analog/digital neuromorphic hardware. This approach leverages the energy
efficiency of mixed-signal neuromorphic chips while achieving high sample
efficiency through an alternation of online learning, referred to as the
""awake"" phase, and offline learning, known as the ""dreaming"" phase. The model
proposed includes two symbiotic networks: an agent network that learns by
combining real and simulated experiences, and a learned world model network
that generates the simulated experiences. We validate the model by training the
hardware implementation to play the Atari game Pong. We start from a baseline
consisting of an agent network learning without a world model and dreaming,
which successfully learns to play the game. By incorporating dreaming, the
number of required real game experiences are reduced significantly compared to
the baseline. The networks are implemented using a mixed-signal neuromorphic
processor, with the readout layers trained using a computer in-the-loop, while
the other layers remain fixed. These results pave the way toward
energy-efficient neuromorphic learning systems capable of rapid learning in
real world applications and use-cases.",2024-05-24,"Ingo Blakowski, Dmitrii Zendrikov, Cristiano Capone, Giacomo Indiveri",http://arxiv.org/pdf/2405.15616v1,cs.LG
Automatic Data Curation for Self-Supervised Learning: A Clustering-Based Approach,"Self-supervised features are the cornerstone of modern machine learning
systems. They are typically pre-trained on data collections whose construction
and curation typically require extensive human effort. This manual process has
some limitations similar to those encountered in supervised learning, e.g., the
crowd-sourced selection of data is costly and time-consuming, preventing
scaling the dataset size. In this work, we consider the problem of automatic
curation of high-quality datasets for self-supervised pre-training. We posit
that such datasets should be large, diverse and balanced, and propose a
clustering-based approach for building ones satisfying all these criteria. Our
method involves successive and hierarchical applications of $k$-means on a
large and diverse data repository to obtain clusters that distribute uniformly
among data concepts, followed by a hierarchical, balanced sampling step from
these clusters. Extensive experiments on three different data domains including
web-based images, satellite images and text show that features trained on our
automatically curated datasets outperform those trained on uncurated data while
being on par or better than ones trained on manually curated data. Code is
available at https://github.com/facebookresearch/ssl-data-curation.",2024-05-24,"Huy V. Vo, Vasil Khalidov, Timothée Darcet, Théo Moutakanni, Nikita Smetanin, Marc Szafraniec, Hugo Touvron, Camille Couprie, Maxime Oquab, Armand Joulin, Hervé Jégou, Patrick Labatut, Piotr Bojanowski",http://arxiv.org/pdf/2405.15613v2,cs.LG
Word Sense Disambiguation in Persian: Can AI Finally Get It Right?,"Homograph disambiguation, the task of distinguishing words with identical
spellings but different meanings, poses a substantial challenge in natural
language processing. In this study, we introduce a novel dataset tailored for
Persian homograph disambiguation. Our work encompasses a thorough exploration
of various embeddings, evaluated through the cosine similarity method and their
efficacy in downstream tasks like classification. Our investigation entails
training a diverse array of lightweight machine learning and deep learning
models for phonograph disambiguation. We scrutinize the models' performance in
terms of Accuracy, Recall, and F1 Score, thereby gaining insights into their
respective strengths and limitations. The outcomes of our research underscore
three key contributions. First, we present a newly curated Persian dataset,
providing a solid foundation for future research in homograph disambiguation.
Second, our comparative analysis of embeddings highlights their utility in
different contexts, enriching the understanding of their capabilities. Third,
by training and evaluating a spectrum of models, we extend valuable guidance
for practitioners in selecting suitable strategies for homograph disambiguation
tasks. In summary, our study unveils a new dataset, scrutinizes embeddings
through diverse perspectives, and benchmarks various models for homograph
disambiguation. These findings empower researchers and practitioners to
navigate the intricate landscape of homograph-related challenges effectively.",2024-05-24,"Seyed Moein Ayyoubzadeh, Kourosh Shahnazari",http://arxiv.org/pdf/2406.00028v3,cs.LG
Fast-PGM: Fast Probabilistic Graphical Model Learning and Inference,"Probabilistic graphical models (PGMs) serve as a powerful framework for
modeling complex systems with uncertainty and extracting valuable insights from
data. However, users face challenges when applying PGMs to their problems in
terms of efficiency and usability. This paper presents Fast-PGM, an efficient
and open-source library for PGM learning and inference. Fast-PGM supports
comprehensive tasks on PGMs, including structure and parameter learning, as
well as exact and approximate inference, and enhances efficiency of the tasks
through computational and memory optimizations and parallelization techniques.
Concurrently, Fast-PGM furnishes developers with flexible building blocks,
furnishes learners with detailed documentation, and affords non-experts
user-friendly interfaces, thereby ameliorating the usability of PGMs to users
across a spectrum of expertise levels. The source code of Fast-PGM is available
at https://github.com/jjiantong/FastPGM.",2024-05-24,"Jiantong Jiang, Zeyi Wen, Peiyu Yang, Atif Mansoor, Ajmal Mian",http://arxiv.org/pdf/2405.15605v2,cs.LG
Kronecker-Factored Approximate Curvature for Physics-Informed Neural Networks,"Physics-informed neural networks (PINNs) are infamous for being hard to
train. Recently, second-order methods based on natural gradient and
Gauss-Newton methods have shown promising performance, improving the accuracy
achieved by first-order methods by several orders of magnitude. While
promising, the proposed methods only scale to networks with a few thousand
parameters due to the high computational cost to evaluate, store, and invert
the curvature matrix. We propose Kronecker-factored approximate curvature
(KFAC) for PINN losses that greatly reduces the computational cost and allows
scaling to much larger networks. Our approach goes beyond the established KFAC
for traditional deep learning problems as it captures contributions from a
PDE's differential operator that are crucial for optimization. To establish
KFAC for such losses, we use Taylor-mode automatic differentiation to describe
the differential operator's computation graph as a forward network with shared
weights. This allows us to apply KFAC thanks to a recently-developed general
formulation for networks with weight sharing. Empirically, we find that our
KFAC-based optimizers are competitive with expensive second-order methods on
small problems, scale more favorably to higher-dimensional neural networks and
PDEs, and consistently outperform first-order methods and LBFGS.",2024-05-24,"Felix Dangel, Johannes Müller, Marius Zeinhofer",http://arxiv.org/pdf/2405.15603v3,cs.LG
On the Computational Landscape of Replicable Learning,"We study computational aspects of algorithmic replicability, a notion of
stability introduced by Impagliazzo, Lei, Pitassi, and Sorrell [2022].
Motivated by a recent line of work that established strong statistical
connections between replicability and other notions of learnability such as
online learning, private learning, and SQ learning, we aim to understand better
the computational connections between replicability and these learning
paradigms. Our first result shows that there is a concept class that is
efficiently replicably PAC learnable, but, under standard cryptographic
assumptions, no efficient online learner exists for this class. Subsequently,
we design an efficient replicable learner for PAC learning parities when the
marginal distribution is far from uniform, making progress on a question posed
by Impagliazzo et al. [2022]. To obtain this result, we design a replicable
lifting framework inspired by Blanc, Lange, Malik, and Tan [2023] that
transforms in a black-box manner efficient replicable PAC learners under the
uniform marginal distribution over the Boolean hypercube to replicable PAC
learners under any marginal distribution, with sample and time complexity that
depends on a certain measure of the complexity of the distribution. Finally, we
show that any pure DP learner can be transformed to a replicable one in time
polynomial in the accuracy, confidence parameters and exponential in the
representation dimension of the underlying hypothesis class.",2024-05-24,"Alkis Kalavasis, Amin Karbasi, Grigoris Velegkas, Felix Zhou",http://arxiv.org/pdf/2405.15599v2,cs.LG
MCDFN: Supply Chain Demand Forecasting via an Explainable Multi-Channel Data Fusion Network Model,"Accurate demand forecasting is crucial for optimizing supply chain
management. Traditional methods often fail to capture complex patterns from
seasonal variability and special events. Despite advancements in deep learning,
interpretable forecasting models remain a challenge. To address this, we
introduce the Multi-Channel Data Fusion Network (MCDFN), a hybrid architecture
that integrates Convolutional Neural Networks (CNN), Long Short-Term Memory
networks (LSTM), and Gated Recurrent Units (GRU) to enhance predictive
performance by extracting spatial and temporal features from time series data.
Our comparative benchmarking demonstrates that MCDFN outperforms seven other
deep-learning models, achieving superior metrics: MSE (23.5738), RMSE (4.8553),
MAE (3.9991), and MAPE (20.1575%). Theil's U statistic of 0.1181 (U<1) of MCDFN
indicates its superiority over the naive forecasting approach, and a 10-fold
cross-validated statistical paired t-test with a p-value of 5% indicated no
significant difference between MCDFN's predictions and actual values. We apply
explainable AI techniques like ShapTime and Permutation Feature Importance to
enhance interpretability. This research advances demand forecasting
methodologies and offers practical guidelines for integrating MCDFN into supply
chain systems, highlighting future research directions for scalability and
user-friendly deployment.",2024-05-24,"Md Abrar Jahin, Asef Shahriar, Md Al Amin",http://arxiv.org/pdf/2405.15598v5,cs.LG
MicroAdam: Accurate Adaptive Optimization with Low Space Overhead and Provable Convergence,"We propose a new variant of the Adam optimizer called MicroAdam that
specifically minimizes memory overheads, while maintaining theoretical
convergence guarantees. We achieve this by compressing the gradient information
before it is fed into the optimizer state, thereby reducing its memory
footprint significantly. We control the resulting compression error via a novel
instance of the classical \emph{error feedback} mechanism from distributed
optimization in which *the error correction information is itself compressed*
to allow for practical memory gains. We prove that the resulting approach
maintains theoretical convergence guarantees competitive to those of AMSGrad,
while providing good practical performance. Specifically, we show that
MicroAdam can be implemented efficiently on GPUs: on both million-scale (BERT)
and billion-scale (LLaMA) models, MicroAdam provides practical convergence
competitive to that of the uncompressed Adam baseline, with lower memory usage
and similar running time. Our code is available at
https://github.com/IST-DASLab/MicroAdam.",2024-05-24,"Ionut-Vlad Modoranu, Mher Safaryan, Grigory Malinovsky, Eldar Kurtic, Thomas Robert, Peter Richtarik, Dan Alistarh",http://arxiv.org/pdf/2405.15593v2,cs.LG
Efficient Adversarial Training in LLMs with Continuous Attacks,"Large language models (LLMs) are vulnerable to adversarial attacks that can
bypass their safety guardrails. In many domains, adversarial training has
proven to be one of the most promising methods to reliably improve robustness
against such attacks. Yet, in the context of LLMs, current methods for
adversarial training are hindered by the high computational costs required to
perform discrete adversarial attacks at each training iteration. We address
this problem by instead calculating adversarial attacks in the continuous
embedding space of the LLM, which is orders of magnitudes more efficient. We
propose a fast adversarial training algorithm (C-AdvUL) composed of two losses:
the first makes the model robust on continuous embedding attacks computed on an
adversarial behaviour dataset; the second ensures the usefulness of the final
model by fine-tuning on utility data. Moreover, we introduce C-AdvIPO, an
adversarial variant of IPO that does not require utility data for adversarially
robust alignment. Our empirical evaluation on five models from different
families (Gemma, Phi3, Mistral, Zephyr, Llama2) and at different scales (2B,
3.8B, 7B) shows that both algorithms substantially enhance LLM robustness
against discrete attacks (GCG, AutoDAN, PAIR), while maintaining utility. Our
results demonstrate that robustness to continuous perturbations can extrapolate
to discrete threat models. Thereby, we present a path toward scalable
adversarial training algorithms for robustly aligning LLMs.",2024-05-24,"Sophie Xhonneux, Alessandro Sordoni, Stephan Günnemann, Gauthier Gidel, Leo Schwinn",http://arxiv.org/pdf/2405.15589v3,cs.LG
DAGER: Exact Gradient Inversion for Large Language Models,"Federated learning works by aggregating locally computed gradients from
multiple clients, thus enabling collaborative training without sharing private
client data. However, prior work has shown that the data can actually be
recovered by the server using so-called gradient inversion attacks. While these
attacks perform well when applied on images, they are limited in the text
domain and only permit approximate reconstruction of small batches and short
input sequences. In this work, we propose DAGER, the first algorithm to recover
whole batches of input text exactly. DAGER leverages the low-rank structure of
self-attention layer gradients and the discrete nature of token embeddings to
efficiently check if a given token sequence is part of the client data. We use
this check to exactly recover full batches in the honest-but-curious setting
without any prior on the data for both encoder- and decoder-based architectures
using exhaustive heuristic search and a greedy approach, respectively. We
provide an efficient GPU implementation of DAGER and show experimentally that
it recovers full batches of size up to 128 on large language models (LLMs),
beating prior attacks in speed (20x at same batch size), scalability (10x
larger batches), and reconstruction quality (ROUGE-1/2 > 0.99).",2024-05-24,"Ivo Petrov, Dimitar I. Dimitrov, Maximilian Baader, Mark Niklas Müller, Martin Vechev",http://arxiv.org/pdf/2405.15586v2,cs.LG
Transfer Learning with Informative Priors: Simple Baselines Better than Previously Reported,"We pursue transfer learning to improve classifier accuracy on a target task
with few labeled examples available for training. Recent work suggests that
using a source task to learn a prior distribution over neural net weights, not
just an initialization, can boost target task performance. In this study, we
carefully compare transfer learning with and without source task informed
priors across 5 datasets. We find that standard transfer learning informed by
an initialization only performs far better than reported in previous
comparisons. The relative gains of methods using informative priors over
standard transfer learning vary in magnitude across datasets. For the scenario
of 5-300 examples per class, we find negative or negligible gains on 2
datasets, modest gains (between 1.5-3 points of accuracy) on 2 other datasets,
and substantial gains (>8 points) on one dataset. Among methods using
informative priors, we find that an isotropic covariance appears competitive
with learned low-rank covariance matrix while being substantially simpler to
understand and tune. Further analysis suggests that the mechanistic
justification for informed priors -- hypothesized improved alignment between
train and test loss landscapes -- is not consistently supported due to high
variability in empirical landscapes. We release code to allow independent
reproduction of all experiments.",2024-05-24,"Ethan Harvey, Mikhail Petrov, Michael C. Hughes",http://arxiv.org/pdf/2405.15583v1,cs.LG
"Discovering deposition process regimes: leveraging unsupervised learning for process insights, surrogate modeling, and sensitivity analysis","This work introduces a comprehensive approach utilizing data-driven methods
to elucidate the deposition process regimes in Chemical Vapor Deposition (CVD)
reactors and the interplay of physical mechanism that dominate in each one of
them. Through this work, we address three key objectives. Firstly, our
methodology relies on process outcomes, derived by a detailed CFD model, to
identify clusters of ""outcomes"" corresponding to distinct process regimes,
wherein the relative influence of input variables undergoes notable shifts.
This phenomenon is experimentally validated through Arrhenius plot analysis,
affirming the efficacy of our approach. Secondly, we demonstrate the
development of an efficient surrogate model, based on Polynomial Chaos
Expansion (PCE), that maintains accuracy, facilitating streamlined
computational analyses. Finally, as a result of PCE, sensitivity analysis is
made possible by means of Sobol' indices, that quantify the impact of process
inputs across identified regimes. The insights gained from our analysis
contribute to the formulation of hypotheses regarding phenomena occurring
beyond the transition regime. Notably, the significance of temperature even in
the diffusion-limited regime, as evidenced by the Arrhenius plot, suggests
activation of gas phase reactions at elevated temperatures. Importantly, our
proposed methods yield insights that align with experimental observations and
theoretical principles, aiding decision-making in process design and
optimization. By circumventing the need for costly and time-consuming
experiments, our approach offers a pragmatic pathway towards enhanced process
efficiency. Moreover, this study underscores the potential of data-driven
computational methods for innovating reactor design paradigms.",2024-05-24,"Geremy Loachamín Suntaxi, Paris Papavasileiou, Eleni D. Koronaki, Dimitrios G. Giovanis, Georgios Gakis, Ioannis G. Aviziotis, Martin Kathrein, Gabriele Pozzetti, Christoph Czettl, Stéphane P. A. Bordas, Andreas G. Boudouvis",http://arxiv.org/pdf/2405.18444v1,cs.LG
Generating density nowcasts for U.S. GDP growth with deep learning: Bayes by Backprop and Monte Carlo dropout,"Recent results in the literature indicate that artificial neural networks
(ANNs) can outperform the dynamic factor model (DFM) in terms of the accuracy
of GDP nowcasts. Compared to the DFM, the performance advantage of these highly
flexible, nonlinear estimators is particularly evident in periods of recessions
and structural breaks. From the perspective of policy-makers, however, nowcasts
are the most useful when they are conveyed with uncertainty attached to them.
While the DFM and other classical time series approaches analytically derive
the predictive (conditional) distribution for GDP growth, ANNs can only produce
point nowcasts based on their default training procedure (backpropagation). To
fill this gap, first in the literature, we adapt two different deep learning
algorithms that enable ANNs to generate density nowcasts for U.S. GDP growth:
Bayes by Backprop and Monte Carlo dropout. The accuracy of point nowcasts,
defined as the mean of the empirical predictive distribution, is evaluated
relative to a naive constant growth model for GDP and a benchmark DFM
specification. Using a 1D CNN as the underlying ANN architecture, both
algorithms outperform those benchmarks during the evaluation period (2012:Q1 --
2022:Q4). Furthermore, both algorithms are able to dynamically adjust the
location (mean), scale (variance), and shape (skew) of the empirical predictive
distribution. The results indicate that both Bayes by Backprop and Monte Carlo
dropout can effectively augment the scope and functionality of ANNs, rendering
them a fully compatible and competitive alternative for classical time series
approaches.",2024-05-24,"Kristóf Németh, Dániel Hadházi",http://arxiv.org/pdf/2405.15579v1,cs.LG
Rethinking Independent Cross-Entropy Loss For Graph-Structured Data,"Graph neural networks (GNNs) have exhibited prominent performance in learning
graph-structured data. Considering node classification task, based on the i.i.d
assumption among node labels, the traditional supervised learning simply sums
up cross-entropy losses of the independent training nodes and applies the
average loss to optimize GNNs' weights. But different from other data formats,
the nodes are naturally connected. It is found that the independent
distribution modeling of node labels restricts GNNs' capability to generalize
over the entire graph and defend adversarial attacks. In this work, we propose
a new framework, termed joint-cluster supervised learning, to model the joint
distribution of each node with its corresponding cluster. We learn the joint
distribution of node and cluster labels conditioned on their representations,
and train GNNs with the obtained joint loss. In this way, the data-label
reference signals extracted from the local cluster explicitly strengthen the
discrimination ability on the target node. The extensive experiments
demonstrate that our joint-cluster supervised learning can effectively bolster
GNNs' node classification accuracy. Furthermore, being benefited from the
reference signals which may be free from spiteful interference, our learning
paradigm significantly protects the node classification from being affected by
the adversarial attack.",2024-05-24,"Rui Miao, Kaixiong Zhou, Yili Wang, Ninghao Liu, Ying Wang, Xin Wang",http://arxiv.org/pdf/2405.15564v2,cs.LG
Learning from Linear Algebra: A Graph Neural Network Approach to Preconditioner Design for Conjugate Gradient Solvers,"Large linear systems are ubiquitous in modern computational science and
engineering. The main recipe for solving them is the use of Krylov subspace
iterative methods with well-designed preconditioners. Recently, GNNs have been
shown to be a promising tool for designing preconditioners to reduce the
overall computational cost of iterative methods by constructing them more
efficiently than with classical linear algebra techniques. Preconditioners
designed with these approaches cannot outperform those designed with classical
methods in terms of the number of iterations in CG. In our work, we recall
well-established preconditioners from linear algebra and use them as a starting
point for training the GNN to obtain preconditioners that reduce the condition
number of the system more significantly than classical preconditioners.
Numerical experiments show that our approach outperforms both classical and
neural network-based methods for an important class of parametric partial
differential equations. We also provide a heuristic justification for the loss
function used and show that preconditioners obtained by learning with this loss
function reduce the condition number in a more desirable way for CG.",2024-05-24,"Vladislav Trifonov, Alexander Rudikov, Oleg Iliev, Yuri M. Laevsky, Ivan Oseledets, Ekaterina Muravleva",http://arxiv.org/pdf/2405.15557v3,cs.LG
Certifiably Robust RAG against Retrieval Corruption,"Retrieval-augmented generation (RAG) has been shown vulnerable to retrieval
corruption attacks: an attacker can inject malicious passages into retrieval
results to induce inaccurate responses. In this paper, we propose RobustRAG as
the first defense framework against retrieval corruption attacks. The key
insight of RobustRAG is an isolate-then-aggregate strategy: we get LLM
responses from each passage in isolation and then securely aggregate these
isolated responses. To instantiate RobustRAG, we design keyword-based and
decoding-based algorithms for securely aggregating unstructured text responses.
Notably, RobustRAG can achieve certifiable robustness: we can formally prove
and certify that, for certain queries, RobustRAG can always return accurate
responses, even when the attacker has full knowledge of our defense and can
arbitrarily inject a small number of malicious passages. We evaluate RobustRAG
on open-domain QA and long-form text generation datasets and demonstrate its
effectiveness and generalizability across various tasks and datasets.",2024-05-24,"Chong Xiang, Tong Wu, Zexuan Zhong, David Wagner, Danqi Chen, Prateek Mittal",http://arxiv.org/pdf/2405.15556v1,cs.LG
Adapting PromptORE for Modern History: Information Extraction from Hispanic Monarchy Documents of the XVIth Century,"Semantic relations among entities are a widely accepted method for relation
extraction. PromptORE (Prompt-based Open Relation Extraction) was designed to
improve relation extraction with Large Language Models on generalistic
documents. However, it is less effective when applied to historical documents,
in languages other than English. In this study, we introduce an adaptation of
PromptORE to extract relations from specialized documents, namely digital
transcripts of trials from the Spanish Inquisition. Our approach involves
fine-tuning transformer models with their pretraining objective on the data
they will perform inference. We refer to this process as ""biasing"". Our Biased
PromptORE addresses complex entity placements and genderism that occur in
Spanish texts. We solve these issues by prompt engineering. We evaluate our
method using Encoder-like models, corroborating our findings with experts'
assessments. Additionally, we evaluate the performance using a binomial
classification benchmark. Our results show a substantial improvement in
accuracy -up to a 50% improvement with our Biased PromptORE models in
comparison to the baseline models using standard PromptORE.",2024-05-24,"Hèctor Loopez Hidalgo, Michel Boeglin, David Kahn, Josiane Mothe, Diego Ortiz, David Panzoli",http://arxiv.org/pdf/2406.00027v1,cs.LG
Thinking Forward: Memory-Efficient Federated Finetuning of Language Models,"Finetuning large language models (LLMs) in federated learning (FL) settings
has become increasingly important as it allows resource-constrained devices to
finetune a model using private data. However, finetuning LLMs using
backpropagation requires excessive memory (especially from intermediate
activations) for resource-constrained devices. While Forward-mode
Auto-Differentiation (AD) can significantly reduce memory footprint from
activations, we observe that directly applying it to LLM finetuning results in
slow convergence and poor accuracy. In this paper, we introduce Spry, an FL
algorithm that splits trainable weights of an LLM among participating clients,
such that each client computes gradients using forward-mode AD that are closer
estimations of the true gradients. Spry achieves a low memory footprint, high
accuracy, and fast convergence. We formally prove that the global gradients in
Spry are unbiased estimators of true global gradients for homogeneous data
distributions across clients, while heterogeneity increases bias of the
estimates. We also derive Spry's convergence rate, showing that the gradients
decrease inversely proportional to the number of FL rounds, indicating the
convergence up to the limits of heterogeneity. Empirically, Spry reduces the
memory footprint during training by 1.4-7.1x in contrast to backpropagation,
while reaching comparable accuracy, across a wide range of language tasks,
models, and FL settings. Spry reduces the convergence time by 1.2-20.3x and
achieves 5.2-13.5% higher accuracy against zero-order methods. When finetuning
Llama2-7B with LoRA, compared to the peak memory consumption of 33.9GB of
backpropagation, Spry only consumes 6.2GB of peak memory. For OPT13B, the
reduction is from 76.5GB to 10.8GB. Spry makes feasible previously impossible
FL deployments on commodity edge devices. Our source code is available at
https://github.com/Astuary/Spry.",2024-05-24,"Kunjal Panchal, Nisarg Parikh, Sunav Choudhary, Lijun Zhang, Yuriy Brun, Hui Guan",http://arxiv.org/pdf/2405.15551v2,cs.LG
Concept-based Explainable Malignancy Scoring on Pulmonary Nodules in CT Images,"To increase the transparency of modern computer-aided diagnosis (CAD) systems
for assessing the malignancy of lung nodules, an interpretable model based on
applying the generalized additive models and the concept-based learning is
proposed. The model detects a set of clinically significant attributes in
addition to the final malignancy regression score and learns the association
between the lung nodule attributes and a final diagnosis decision as well as
their contributions into the decision. The proposed concept-based learning
framework provides human-readable explanations in terms of different concepts
(numerical and categorical), their values, and their contribution to the final
prediction. Numerical experiments with the LIDC-IDRI dataset demonstrate that
the diagnosis results obtained using the proposed model, which explicitly
explores internal relationships, are in line with similar patterns observed in
clinical practice. Additionally, the proposed model shows the competitive
classification and the nodule attribute scoring performance, highlighting its
potential for effective decision-making in the lung nodule diagnosis.",2024-05-24,"Rinat I. Dumaev, Sergei A. Molodyakov, Lev V. Utkin",http://arxiv.org/pdf/2405.17483v1,cs.LG
Freya PAGE: First Optimal Time Complexity for Large-Scale Nonconvex Finite-Sum Optimization with Heterogeneous Asynchronous Computations,"In practical distributed systems, workers are typically not homogeneous, and
due to differences in hardware configurations and network conditions, can have
highly varying processing times. We consider smooth nonconvex finite-sum
(empirical risk minimization) problems in this setup and introduce a new
parallel method, Freya PAGE, designed to handle arbitrarily heterogeneous and
asynchronous computations. By being robust to ""stragglers"" and adaptively
ignoring slow computations, Freya PAGE offers significantly improved time
complexity guarantees compared to all previous methods, including Asynchronous
SGD, Rennala SGD, SPIDER, and PAGE, while requiring weaker assumptions. The
algorithm relies on novel generic stochastic gradient collection strategies
with theoretical guarantees that can be of interest on their own, and may be
used in the design of future optimization methods. Furthermore, we establish a
lower bound for smooth nonconvex finite-sum problems in the asynchronous setup,
providing a fundamental time complexity limit. This lower bound is tight and
demonstrates the optimality of Freya PAGE in the large-scale regime, i.e., when
$\sqrt{m} \geq n$, where $n$ is # of workers, and $m$ is # of data samples.",2024-05-24,"Alexander Tyurin, Kaja Gruntkowska, Peter Richtárik",http://arxiv.org/pdf/2405.15545v2,cs.LG
Bayesian WeakS-to-Strong from Text Classification to Generation,"Advances in large language models raise the question of how alignment
techniques will adapt as models become increasingly complex and humans will
only be able to supervise them weakly. Weak-to-Strong mimics such a scenario
where weak model supervision attempts to harness the full capabilities of a
much stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by
exploring an ensemble of weak models which simulate the variability in human
opinions. Confidence scores are estimated using a Bayesian approach to guide
the WeakS-to-Strong generalization. Furthermore, we extend the application of
WeakS-to-Strong from text classification tasks to text generation tasks where
more advanced strategies are investigated for supervision. Moreover, direct
preference optimization is applied to advance the student model's preference
learning, beyond the basic learning framework of teacher forcing. Results
demonstrate the effectiveness of the proposed approach for the reliability of a
strong student model, showing potential for superalignment.",2024-05-24,"Ziyun Cui, Ziyang Zhang, Guangzhi Sun, Wen Wu, Chao Zhang",http://arxiv.org/pdf/2406.03199v4,cs.LG
Knowledge-enhanced Relation Graph and Task Sampling for Few-shot Molecular Property Prediction,"Recently, few-shot molecular property prediction (FSMPP) has garnered
increasing attention. Despite impressive breakthroughs achieved by existing
methods, they often overlook the inherent many-to-many relationships between
molecules and properties, which limits their performance. For instance, similar
substructures of molecules can inspire the exploration of new compounds.
Additionally, the relationships between properties can be quantified, with
high-related properties providing more information in exploring the target
property than those low-related. To this end, this paper proposes a novel
meta-learning FSMPP framework (KRGTS), which comprises the Knowledge-enhanced
Relation Graph module and the Task Sampling module. The knowledge-enhanced
relation graph module constructs the molecule-property multi-relation graph
(MPMRG) to capture the many-to-many relationships between molecules and
properties. The task sampling module includes a meta-training task sampler and
an auxiliary task sampler, responsible for scheduling the meta-training process
and sampling high-related auxiliary tasks, respectively, thereby achieving
efficient meta-knowledge learning and reducing noise introduction. Empirically,
extensive experiments on five datasets demonstrate the superiority of KRGTS
over a variety of state-of-the-art methods. The code is available in
https://github.com/Vencent-Won/KRGTS-public.",2024-05-24,"Zeyu Wang, Tianyi Jiang, Yao Lu, Xiaoze Bao, Shanqing Yu, Bin Wei, Qi Xuan",http://arxiv.org/pdf/2405.15544v1,cs.LG
SATSense: Multi-Satellite Collaborative Framework for Spectrum Sensing,"Low Earth Orbit satellite Internet has recently been deployed, providing
worldwide service with non-terrestrial networks. With the large-scale
deployment of both non-terrestrial and terrestrial networks, limited spectrum
resources will not be allocated enough. Consequently, dynamic spectrum sharing
is crucial for their coexistence in the same spectrum, where accurate spectrum
sensing is essential. However, spectrum sensing in space is more challenging
than in terrestrial networks due to variable channel conditions, making
single-satellite sensing unstable. Therefore, we first attempt to design a
collaborative sensing scheme utilizing diverse data from multiple satellites.
However, it is non-trivial to achieve this collaboration due to heterogeneous
channel quality, considerable raw sampling data, and packet loss. To address
the above challenges, we first establish connections between the satellites by
modeling their sensing data as a graph and devising a graph neural
network-based algorithm to achieve effective spectrum sensing. Meanwhile, we
establish a joint sub-Nyquist sampling and autoencoder data compression
framework to reduce the amount of transmitted sensing data. Finally, we propose
a contrastive learning-based mechanism compensates for missing packets.
Extensive experiments demonstrate that our proposed strategy can achieve
efficient spectrum sensing performance and outperform the conventional deep
learning algorithm in spectrum sensing accuracy.",2024-05-24,"Haoxuan Yuan, Zhe Chen, Zheng Lin, Jinbo Peng, Zihan Fang, Yuhang Zhong, Zihang Song, Yue Gao",http://arxiv.org/pdf/2405.15542v1,cs.LG
Bundle Neural Networks for message diffusion on graphs,"The dominant paradigm for learning on graph-structured data is message
passing. Despite being a strong inductive bias, the local message passing
mechanism suffers from pathological issues such as over-smoothing,
over-squashing, and limited node-level expressivity. To address these
limitations we propose Bundle Neural Networks (BuNN), a new type of GNN that
operates via message diffusion over flat vector bundles - structures analogous
to connections on Riemannian manifolds that augment the graph by assigning to
each node a vector space and an orthogonal map. A BuNN layer evolves the
features according to a diffusion-type partial differential equation. When
discretized, BuNNs are a special case of Sheaf Neural Networks (SNNs), a
recently proposed MPNN capable of mitigating over-smoothing. The continuous
nature of message diffusion enables BuNNs to operate on larger scales of the
graph and, therefore, to mitigate over-squashing. Finally, we prove that BuNN
can approximate any feature transformation over nodes on any (potentially
infinite) family of graphs given injective positional encodings, resulting in
universal node-level expressivity. We support our theory via synthetic
experiments and showcase the strong empirical performance of BuNNs over a range
of real-world tasks, achieving state-of-the-art results on several standard
benchmarks in transductive and inductive settings.",2024-05-24,"Jacob Bamberger, Federico Barbero, Xiaowen Dong, Michael M. Bronstein",http://arxiv.org/pdf/2405.15540v2,cs.LG
A generalized neural tangent kernel for surrogate gradient learning,"State-of-the-art neural network training methods depend on the gradient of
the network function. Therefore, they cannot be applied to networks whose
activation functions do not have useful derivatives, such as binary and
discrete-time spiking neural networks. To overcome this problem, the activation
function's derivative is commonly substituted with a surrogate derivative,
giving rise to surrogate gradient learning (SGL). This method works well in
practice but lacks theoretical foundation. The neural tangent kernel (NTK) has
proven successful in the analysis of gradient descent. Here, we provide a
generalization of the NTK, which we call the surrogate gradient NTK, that
enables the analysis of SGL. First, we study a naive extension of the NTK to
activation functions with jumps, demonstrating that gradient descent for such
activation functions is also ill-posed in the infinite-width limit. To address
this problem, we generalize the NTK to gradient descent with surrogate
derivatives, i.e., SGL. We carefully define this generalization and expand the
existing key theorems on the NTK with mathematical rigor. Further, we
illustrate our findings with numerical experiments. Finally, we numerically
compare SGL in networks with sign activation function and finite width to
kernel regression with the surrogate gradient NTK; the results confirm that the
surrogate gradient NTK provides a good characterization of SGL.",2024-05-24,"Luke Eilers, Raoul-Martin Memmesheimer, Sven Goedeke",http://arxiv.org/pdf/2405.15539v1,cs.LG
Polyp Segmentation Generalisability of Pretrained Backbones,"It has recently been demonstrated that pretraining backbones in a
self-supervised manner generally provides better fine-tuned polyp segmentation
performance, and that models with ViT-B backbones typically perform better than
models with ResNet50 backbones. In this paper, we extend this recent work to
consider generalisability. I.e., we assess the performance of models on a
different dataset to that used for fine-tuning, accounting for variation in
network architecture and pretraining pipeline (algorithm and dataset). This
reveals how well models with different pretrained backbones generalise to data
of a somewhat different distribution to the training data, which will likely
arise in deployment due to different cameras and demographics of patients,
amongst other factors. We observe that the previous findings, regarding
pretraining pipelines for polyp segmentation, hold true when considering
generalisability. However, our results imply that models with ResNet50
backbones typically generalise better, despite being outperformed by models
with ViT-B backbones in evaluation on the test set from the same dataset used
for fine-tuning.",2024-05-24,"Edward Sanderson, Bogdan J. Matuszewski",http://arxiv.org/pdf/2405.15524v1,cs.LG
The Mosaic Memory of Large Language Models,"As Large Language Models (LLMs) become widely adopted, understanding how they
learn from, and memorize, training data becomes crucial. Memorization in LLMs
is widely assumed to only occur as a result of sequences being repeated in the
training data. Instead, we show that LLMs memorize by assembling information
from similar sequences, a phenomena we call mosaic memory. We show major LLMs
to exhibit mosaic memory, with fuzzy duplicates contributing to memorization as
much as 0.8 of an exact duplicate and even heavily modified sequences
contributing substantially to memorization. Despite models display reasoning
capabilities, we somewhat surprisingly show memorization to be predominantly
syntactic rather than semantic. We finally show fuzzy duplicates to be
ubiquitous in real-world data, untouched by deduplication techniques. Taken
together, our results challenge widely held beliefs and show memorization to be
a more complex, mosaic process, with real-world implications for privacy,
confidentiality, model utility and evaluation.",2024-05-24,"Igor Shilov, Matthieu Meeus, Yves-Alexandre de Montjoye",http://arxiv.org/pdf/2405.15523v2,cs.LG
Erase to Enhance: Data-Efficient Machine Unlearning in MRI Reconstruction,"Machine unlearning is a promising paradigm for removing unwanted data samples
from a trained model, towards ensuring compliance with privacy regulations and
limiting harmful biases. Although unlearning has been shown in, e.g.,
classification and recommendation systems, its potential in medical
image-to-image translation, specifically in image recon-struction, has not been
thoroughly investigated. This paper shows that machine unlearning is possible
in MRI tasks and has the potential to benefit for bias removal. We set up a
protocol to study how much shared knowledge exists between datasets of
different organs, allowing us to effectively quantify the effect of unlearning.
Our study reveals that combining training data can lead to hallucinations and
reduced image quality in the reconstructed data. We use unlearning to remove
hallucinations as a proxy exemplar of undesired data removal. Indeed, we show
that machine unlearning is possible without full retraining. Furthermore, our
observations indicate that maintaining high performance is feasible even when
using only a subset of retain data. We have made our code publicly accessible.",2024-05-24,"Yuyang Xue, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris",http://arxiv.org/pdf/2405.15517v2,cs.LG
On the Convexity and Reliability of the Bethe Free Energy Approximation,"The Bethe free energy approximation provides an effective way for relaxing
NP-hard problems of probabilistic inference. However, its accuracy depends on
the model parameters and particularly degrades if a phase transition in the
model occurs. In this work, we analyze when the Bethe approximation is reliable
and how this can be verified. We argue and show by experiment that it is mostly
accurate if it is convex on a submanifold of its domain, the 'Bethe box'. For
verifying its convexity, we derive two sufficient conditions that are based on
the definiteness properties of the Bethe Hessian matrix: the first uses the
concept of diagonal dominance, and the second decomposes the Bethe Hessian
matrix into a sum of sparse matrices and characterizes the definiteness
properties of the individual matrices in that sum. These theoretical results
provide a simple way to estimate the critical phase transition temperature of a
model. As a practical contribution we propose $\texttt{BETHE-MIN}$, a projected
quasi-Newton method to efficiently find a minimum of the Bethe free energy.",2024-05-24,"Harald Leisenberger, Christian Knoll, Franz Pernkopf",http://arxiv.org/pdf/2405.15514v1,cs.LG
ChatGPT Code Detection: Techniques for Uncovering the Source of Code,"In recent times, large language models (LLMs) have made significant strides
in generating computer code, blurring the lines between code created by humans
and code produced by artificial intelligence (AI). As these technologies evolve
rapidly, it is crucial to explore how they influence code generation,
especially given the risk of misuse in areas like higher education. This paper
explores this issue by using advanced classification techniques to
differentiate between code written by humans and that generated by ChatGPT, a
type of LLM. We employ a new approach that combines powerful embedding features
(black-box) with supervised learning algorithms - including Deep Neural
Networks, Random Forests, and Extreme Gradient Boosting - to achieve this
differentiation with an impressive accuracy of 98%. For the successful
combinations, we also examine their model calibration, showing that some of the
models are extremely well calibrated. Additionally, we present white-box
features and an interpretable Bayes classifier to elucidate critical
differences between the code sources, enhancing the explainability and
transparency of our approach. Both approaches work well but provide at most
85-88% accuracy. We also show that untrained humans solve the same task not
better than random guessing. This study is crucial in understanding and
mitigating the potential risks associated with using AI in code generation,
particularly in the context of higher education, software development, and
competitive programming.",2024-05-24,"Marc Oedingen, Raphael C. Engelhardt, Robin Denz, Maximilian Hammer, Wolfgang Konen",http://arxiv.org/pdf/2405.15512v2,cs.LG
Randomized algorithms and PAC bounds for inverse reinforcement learning in continuous spaces,"This work studies discrete-time discounted Markov decision processes with
continuous state and action spaces and addresses the inverse problem of
inferring a cost function from observed optimal behavior. We first consider the
case in which we have access to the entire expert policy and characterize the
set of solutions to the inverse problem by using occupation measures, linear
duality, and complementary slackness conditions. To avoid trivial solutions and
ill-posedness, we introduce a natural linear normalization constraint. This
results in an infinite-dimensional linear feasibility problem, prompting a
thorough analysis of its properties. Next, we use linear function approximators
and adopt a randomized approach, namely the scenario approach and related
probabilistic feasibility guarantees, to derive epsilon-optimal solutions for
the inverse problem. We further discuss the sample complexity for a desired
approximation accuracy. Finally, we deal with the more realistic case where we
only have access to a finite set of expert demonstrations and a generative
model and provide bounds on the error made when working with samples.",2024-05-24,"Angeliki Kamoutsi, Peter Schmitt-Förster, Tobias Sutter, Volkan Cevher, John Lygeros",http://arxiv.org/pdf/2405.15509v1,cs.LG
Human-in-the-loop Reinforcement Learning for Data Quality Monitoring in Particle Physics Experiments,"Data Quality Monitoring (DQM) is a crucial task in large particle physics
experiments, since detector malfunctioning can compromise the data. DQM is
currently performed by human shifters, which is costly and results in limited
accuracy. In this work, we provide a proof-of-concept for applying
human-in-the-loop Reinforcement Learning (RL) to automate the DQM process while
adapting to operating conditions that change over time. We implement a
prototype based on the Proximal Policy Optimization (PPO) algorithm and
validate it on a simplified synthetic dataset. We demonstrate how a multi-agent
system can be trained for continuous automated monitoring during data
collection, with human intervention actively requested only when relevant. We
show that random, unbiased noise in human classification can be reduced,
leading to an improved accuracy over the baseline. Additionally, we propose
data augmentation techniques to deal with scarce data and to accelerate the
learning process. Finally, we discuss further steps needed to implement the
approach in the real world, including protocols for periodic control of the
algorithm's outputs.",2024-05-24,"Olivia Jullian Parra, Julián García Pardiñas, Lorenzo Del Pianta Pérez, Maximilian Janisch, Suzanne Klaver, Thomas Lehéricy, Nicola Serra",http://arxiv.org/pdf/2405.15508v1,cs.LG
Learning to Discretize Denoising Diffusion ODEs,"Diffusion Probabilistic Models (DPMs) are generative models showing
competitive performance in various domains, including image synthesis and 3D
point cloud generation. Sampling from pre-trained DPMs involves multiple neural
function evaluations (NFEs) to transform Gaussian noise samples into images,
resulting in higher computational costs compared to single-step generative
models such as GANs or VAEs. Therefore, reducing the number of NFEs while
preserving generation quality is crucial. To address this, we propose LD3, a
lightweight framework designed to learn the optimal time discretization for
sampling. LD3 can be combined with various samplers and consistently improves
generation quality without having to retrain resource-intensive neural
networks. We demonstrate analytically and empirically that LD3 improves
sampling efficiency with much less computational overhead. We evaluate our
method with extensive experiments on 7 pre-trained models, covering
unconditional and conditional sampling in both pixel-space and latent-space
DPMs. We achieve FIDs of 2.38 (10 NFE), and 2.27 (10 NFE) on unconditional
CIFAR10 and AFHQv2 in 5-10 minutes of training. LD3 offers an efficient
approach to sampling from pre-trained diffusion models. Code is available at
https://github.com/vinhsuhi/LD3.",2024-05-24,"Vinh Tong, Hoang Trung-Dung, Anji Liu, Guy Van den Broeck, Mathias Niepert",http://arxiv.org/pdf/2405.15506v4,cs.LG
Revisiting Counterfactual Regression through the Lens of Gromov-Wasserstein Information Bottleneck,"As a promising individualized treatment effect (ITE) estimation method,
counterfactual regression (CFR) maps individuals' covariates to a latent space
and predicts their counterfactual outcomes. However, the selection bias between
control and treatment groups often imbalances the two groups' latent
distributions and negatively impacts this method's performance. In this study,
we revisit counterfactual regression through the lens of information bottleneck
and propose a novel learning paradigm called Gromov-Wasserstein information
bottleneck (GWIB). In this paradigm, we learn CFR by maximizing the mutual
information between covariates' latent representations and outcomes while
penalizing the kernelized mutual information between the latent representations
and the covariates. We demonstrate that the upper bound of the penalty term can
be implemented as a new regularizer consisting of $i)$ the fused
Gromov-Wasserstein distance between the latent representations of different
groups and $ii)$ the gap between the transport cost generated by the model and
the cross-group Gromov-Wasserstein distance between the latent representations
and the covariates. GWIB effectively learns the CFR model through alternating
optimization, suppressing selection bias while avoiding trivial latent
distributions. Experiments on ITE estimation tasks show that GWIB consistently
outperforms state-of-the-art CFR methods. To promote the research community, we
release our project at https://github.com/peteryang1031/Causal-GWIB.",2024-05-24,"Hao Yang, Zexu Sun, Hongteng Xu, Xu Chen",http://arxiv.org/pdf/2405.15505v1,cs.LG
Hierarchical Loss And Geometric Mask Refinement For Multilabel Ribs Segmentation,"Automatic ribs segmentation and numeration can increase computed tomography
assessment speed and reduce radiologists mistakes. We introduce a model for
multilabel ribs segmentation with hierarchical loss function, which enable to
improve multilabel segmentation quality. Also we propose postprocessing
technique to further increase labeling quality. Our model achieved new
state-of-the-art 98.2% label accuracy on public RibSeg v2 dataset, surpassing
previous result by 6.7%.",2024-05-24,"Aleksei Leonov, Aleksei Zakharov, Sergey Koshelev, Maxim Pisov, Anvar Kurmukov, Mikhail Belyaev",http://arxiv.org/pdf/2405.15500v1,cs.LG
Towards Natural Machine Unlearning,"Machine unlearning (MU) aims to eliminate information that has been learned
from specific training data, namely forgetting data, from a pre-trained model.
Currently, the mainstream of existing MU methods involves modifying the
forgetting data with incorrect labels and subsequently fine-tuning the model.
While learning such incorrect information can indeed remove knowledge, the
process is quite unnatural as the unlearning process undesirably reinforces the
incorrect information and leads to over-forgetting. Towards more
\textit{natural} machine unlearning, we inject correct information from the
remaining data to the forgetting samples when changing their labels. Through
pairing these adjusted samples with their labels, the model will tend to use
the injected correct information and naturally suppress the information meant
to be forgotten. Albeit straightforward, such a first step towards natural
machine unlearning can significantly outperform current state-of-the-art
approaches. In particular, our method substantially reduces the over-forgetting
and leads to strong robustness to hyperparameters, making it a promising
candidate for practical machine unlearning.",2024-05-24,"Zhengbao He, Tao Li, Xinwen Cheng, Zhehao Huang, Xiaolin Huang",http://arxiv.org/pdf/2405.15495v1,cs.LG
"Out of Many, One: Designing and Scaffolding Proteins at the Scale of the Structural Universe with Genie 2","Protein diffusion models have emerged as a promising approach for protein
design. One such pioneering model is Genie, a method that asymmetrically
represents protein structures during the forward and backward processes, using
simple Gaussian noising for the former and expressive SE(3)-equivariant
attention for the latter. In this work we introduce Genie 2, extending Genie to
capture a larger and more diverse protein structure space through architectural
innovations and massive data augmentation. Genie 2 adds motif scaffolding
capabilities via a novel multi-motif framework that designs co-occurring motifs
with unspecified inter-motif positions and orientations. This makes possible
complex protein designs that engage multiple interaction partners and perform
multiple functions. On both unconditional and conditional generation, Genie 2
achieves state-of-the-art performance, outperforming all known methods on key
design metrics including designability, diversity, and novelty. Genie 2 also
solves more motif scaffolding problems than other methods and does so with more
unique and varied solutions. Taken together, these advances set a new standard
for structure-based protein design. Genie 2 inference and training code, as
well as model weights, are freely available at:
https://github.com/aqlaboratory/genie2.",2024-05-24,"Yeqing Lin, Minji Lee, Zhao Zhang, Mohammed AlQuraishi",http://arxiv.org/pdf/2405.15489v1,cs.LG
Learning Beyond Pattern Matching? Assaying Mathematical Understanding in LLMs,"We are beginning to see progress in language model assisted scientific
discovery. Motivated by the use of LLMs as a general scientific assistant, this
paper assesses the domain knowledge of LLMs through its understanding of
different mathematical skills required to solve problems. In particular, we
look at not just what the pre-trained model already knows, but how it learned
to learn from information during in-context learning or instruction-tuning
through exploiting the complex knowledge structure within mathematics.
Motivated by the Neural Tangent Kernel (NTK), we propose \textit{NTKEval} to
assess changes in LLM's probability distribution via training on different
kinds of math data. Our systematic analysis finds evidence of domain
understanding during in-context learning. By contrast, certain
instruction-tuning leads to similar performance changes irrespective of
training on different data, suggesting a lack of domain understanding across
different skills.",2024-05-24,"Siyuan Guo, Aniket Didolkar, Nan Rosemary Ke, Anirudh Goyal, Ferenc Huszár, Bernhard Schölkopf",http://arxiv.org/pdf/2405.15485v1,cs.LG
Sparse Spectral Training and Inference on Euclidean and Hyperbolic Neural Networks,"The growing computational demands posed by increasingly number of neural
network's parameters necessitate low-memory-consumption training approaches.
Previous memory reduction techniques, such as Low-Rank Adaptation (LoRA) and
ReLoRA, suffer from the limitation of low rank and saddle point issues,
particularly during intensive tasks like pre-training. In this paper, we
propose Sparse Spectral Training (SST), an advanced training methodology that
updates all singular values and selectively updates singular vectors of network
weights, thereby optimizing resource usage while closely approximating
full-rank training. SST refines the training process by employing a targeted
updating strategy for singular vectors, which is determined by a multinomial
sampling method weighted by the significance of the singular values, ensuring
both high performance and memory reduction. Through comprehensive testing on
both Euclidean and hyperbolic neural networks across various tasks, including
natural language generation, machine translation, node classification and link
prediction, SST demonstrates its capability to outperform existing memory
reduction training methods and is comparable with full-rank training in some
cases. On OPT-125M, with rank equating to 8.3% of embedding dimension, SST
reduces the perplexity gap to full-rank training by 67.6%, demonstrating a
significant reduction of the performance loss with prevalent low-rank methods.
This approach offers a strong alternative to traditional training techniques,
paving the way for more efficient and scalable neural network training
solutions.",2024-05-24,"Jialin Zhao, Yingtao Zhang, Xinghang Li, Huaping Liu, Carlo Vittorio Cannistraci",http://arxiv.org/pdf/2405.15481v1,cs.LG
Fundamental computational limits of weak learnability in high-dimensional multi-index models,"Multi-index models - functions which only depend on the covariates through a
non-linear transformation of their projection on a subspace - are a useful
benchmark for investigating feature learning with neural nets. This paper
examines the theoretical boundaries of efficient learnability in this
hypothesis class, focusing on the minimum sample complexity required for weakly
recovering their low-dimensional structure with first-order iterative
algorithms, in the high-dimensional regime where the number of samples
$n\!=\!\alpha d$ is proportional to the covariate dimension $d$. Our findings
unfold in three parts: (i) we identify under which conditions a trivial
subspace can be learned with a single step of a first-order algorithm for any
$\alpha\!>\!0$; (ii) if the trivial subspace is empty, we provide necessary and
sufficient conditions for the existence of an easy subspace where directions
that can be learned only above a certain sample complexity
$\alpha\!>\!\alpha_c$, where $\alpha_{c}$ marks a computational phase
transition. In a limited but interesting set of really hard directions -- akin
to the parity problem -- $\alpha_c$ is found to diverge. Finally, (iii) we show
that interactions between different directions can result in an intricate
hierarchical learning phenomenon, where directions can be learned sequentially
when coupled to easier ones. We discuss in detail the grand staircase picture
associated to these functions (and contrast it with the original staircase
one). Our theory builds on the optimality of approximate message-passing among
first-order iterative methods, delineating the fundamental learnability limit
across a broad spectrum of algorithms, including neural networks trained with
gradient descent, which we discuss in this context.",2024-05-24,"Emanuele Troiani, Yatin Dandi, Leonardo Defilippis, Lenka Zdeborová, Bruno Loureiro, Florent Krzakala",http://arxiv.org/pdf/2405.15480v4,cs.LG
Editable Concept Bottleneck Models,"Concept Bottleneck Models (CBMs) have garnered much attention for their
ability to elucidate the prediction process through a humanunderstandable
concept layer. However, most previous studies focused on cases where the data,
including concepts, are clean. In many scenarios, we often need to
remove/insert some training data or new concepts from trained CBMs for reasons
such as privacy concerns, data mislabelling, spurious concepts, and concept
annotation errors. Thus, deriving efficient editable CBMs without retraining
from scratch remains a challenge, particularly in large-scale applications. To
address these challenges, we propose Editable Concept Bottleneck Models
(ECBMs). Specifically, ECBMs support three different levels of data removal:
concept-label-level, concept-level, and data-level. ECBMs enjoy mathematically
rigorous closed-form approximations derived from influence functions that
obviate the need for retraining. Experimental results demonstrate the
efficiency and adaptability of our ECBMs, affirming their practical value in
CBMs.",2024-05-24,"Lijie Hu, Chenyang Ren, Zhengyu Hu, Hongbin Lin, Cheng-Long Wang, Hui Xiong, Jingfeng Zhang, Di Wang",http://arxiv.org/pdf/2405.15476v3,cs.LG
Unlearning during Learning: An Efficient Federated Machine Unlearning Method,"In recent years, Federated Learning (FL) has garnered significant attention
as a distributed machine learning paradigm. To facilitate the implementation of
the right to be forgotten, the concept of federated machine unlearning (FMU)
has also emerged. However, current FMU approaches often involve additional
time-consuming steps and may not offer comprehensive unlearning capabilities,
which renders them less practical in real FL scenarios. In this paper, we
introduce FedAU, an innovative and efficient FMU framework aimed at overcoming
these limitations. Specifically, FedAU incorporates a lightweight auxiliary
unlearning module into the learning process and employs a straightforward
linear operation to facilitate unlearning. This approach eliminates the
requirement for extra time-consuming steps, rendering it well-suited for FL.
Furthermore, FedAU exhibits remarkable versatility. It not only enables
multiple clients to carry out unlearning tasks concurrently but also supports
unlearning at various levels of granularity, including individual data samples,
specific classes, and even at the client level. We conducted extensive
experiments on MNIST, CIFAR10, and CIFAR100 datasets to evaluate the
performance of FedAU. The results demonstrate that FedAU effectively achieves
the desired unlearning effect while maintaining model accuracy. Our code is
availiable at https://github.com/Liar-Mask/FedAU.",2024-05-24,"Hanlin Gu, Gongxi Zhu, Jie Zhang, Xinyuan Zhao, Yuxing Han, Lixin Fan, Qiang Yang",http://arxiv.org/pdf/2405.15474v2,cs.LG
Encoder Embedding for General Graph and Node Classification,"Graph encoder embedding, a recent technique for graph data, offers speed and
scalability in producing vertex-level representations from binary graphs. In
this paper, we extend the applicability of this method to a general graph
model, which includes weighted graphs, distance matrices, and kernel matrices.
We prove that the encoder embedding satisfies the law of large numbers and the
central limit theorem on a per-observation basis. Under certain condition, it
achieves asymptotic normality on a per-class basis, enabling optimal
classification through discriminant analysis. These theoretical findings are
validated through a series of experiments involving weighted graphs, as well as
text and image data transformed into general graph representations using
appropriate distance metrics.",2024-05-24,Cencheng Shen,http://arxiv.org/pdf/2405.15473v2,cs.LG
Repetita Iuvant: Data Repetition Allows SGD to Learn High-Dimensional Multi-Index Functions,"Neural networks can identify low-dimensional relevant structures within
high-dimensional noisy data, yet our mathematical understanding of how they do
so remains scarce. Here, we investigate the training dynamics of two-layer
shallow neural networks trained with gradient-based algorithms, and discuss how
they learn pertinent features in multi-index models, that is target functions
with low-dimensional relevant directions. In the high-dimensional regime, where
the input dimension $d$ diverges, we show that a simple modification of the
idealized single-pass gradient descent training scenario, where data can now be
repeated or iterated upon twice, drastically improves its computational
efficiency. In particular, it surpasses the limitations previously believed to
be dictated by the Information and Leap exponents associated with the target
function to be learned. Our results highlight the ability of networks to learn
relevant structures from data alone without any pre-processing. More precisely,
we show that (almost) all directions are learned with at most $O(d \log d)$
steps. Among the exceptions is a set of hard functions that includes sparse
parities. In the presence of coupling between directions, however, these can be
learned sequentially through a hierarchical mechanism that generalizes the
notion of staircase functions. Our results are proven by a rigorous study of
the evolution of the relevant statistics for high-dimensional dynamics.",2024-05-24,"Luca Arnaboldi, Yatin Dandi, Florent Krzakala, Luca Pesce, Ludovic Stephan",http://arxiv.org/pdf/2405.15459v2,cs.LG
FedCal: Achieving Local and Global Calibration in Federated Learning via Aggregated Parameterized Scaler,"Federated learning (FL) enables collaborative machine learning across
distributed data owners, but data heterogeneity poses a challenge for model
calibration. While prior work focused on improving accuracy for non-iid data,
calibration remains under-explored. This study reveals existing FL aggregation
approaches lead to sub-optimal calibration, and theoretical analysis shows
despite constraining variance in clients' label distributions, global
calibration error is still asymptotically lower bounded. To address this, we
propose a novel Federated Calibration (FedCal) approach, emphasizing both local
and global calibration. It leverages client-specific scalers for local
calibration to effectively correct output misalignment without sacrificing
prediction accuracy. These scalers are then aggregated via weight averaging to
generate a global scaler, minimizing the global calibration error. Extensive
experiments demonstrate FedCal significantly outperforms the best-performing
baseline, reducing global calibration error by 47.66% on average.",2024-05-24,"Hongyi Peng, Han Yu, Xiaoli Tang, Xiaoxiao Li",http://arxiv.org/pdf/2405.15458v2,cs.LG
Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top,"Multi-hop Question Answering (MQA) under knowledge editing (KE) is a key
challenge in Large Language Models (LLMs). While best-performing solutions in
this domain use a plan and solve paradigm to split a question into
sub-questions followed by response generation, we claim that this approach is
sub-optimal as it fails for hard to decompose questions, and it does not
explicitly cater to correlated knowledge updates resulting as a consequence of
knowledge edits. This has a detrimental impact on the overall consistency of
the updated knowledge. To address these issues, in this paper, we propose a
novel framework named RULE-KE, i.e., RULE based Knowledge Editing, which is a
cherry on the top for augmenting the performance of all existing MQA methods
under KE. Specifically, RULE-KE leverages rule discovery to discover a set of
logical rules. Then, it uses these discovered rules to update knowledge about
facts highly correlated with the edit. Experimental evaluation using existing
and newly curated datasets (i.e., RKE-EVAL) shows that RULE-KE helps augment
both performances of parameter-based and memory-based solutions up to 92% and
112.9%, respectively.",2024-05-24,"Keyuan Cheng, Muhammad Asif Ali, Shu Yang, Gang Lin, Yuxuan Zhai, Haoyang Fei, Ke Xu, Lu Yu, Lijie Hu, Di Wang",http://arxiv.org/pdf/2405.15452v2,cs.LG
Mind the Gap: A Causal Perspective on Bias Amplification in Prediction & Decision-Making,"Investigating fairness and equity of automated systems has become a critical
field of inquiry. Most of the literature in fair machine learning focuses on
defining and achieving fairness criteria in the context of prediction, while
not explicitly focusing on how these predictions may be used later on in the
pipeline. For instance, if commonly used criteria, such as independence or
sufficiency, are satisfied for a prediction score $S$ used for binary
classification, they need not be satisfied after an application of a simple
thresholding operation on $S$ (as commonly used in practice). In this paper, we
take an important step to address this issue in numerous statistical and causal
notions of fairness. We introduce the notion of a margin complement, which
measures how much a prediction score $S$ changes due to a thresholding
operation. We then demonstrate that the marginal difference in the optimal 0/1
predictor $\widehat Y$ between groups, written $P(\hat y \mid x_1) - P(\hat y
\mid x_0)$, can be causally decomposed into the influences of $X$ on the
$L_2$-optimal prediction score $S$ and the influences of $X$ on the margin
complement $M$, along different causal pathways (direct, indirect, spurious).
We then show that under suitable causal assumptions, the influences of $X$ on
the prediction score $S$ are equal to the influences of $X$ on the true outcome
$Y$. This yields a new decomposition of the disparity in the predictor
$\widehat Y$ that allows us to disentangle causal differences inherited from
the true outcome $Y$ that exists in the real world vs. those coming from the
optimization procedure itself. This observation highlights the need for more
regulatory oversight due to the potential for bias amplification, and to
address this issue we introduce new notions of weak and strong business
necessity, together with an algorithm for assessing whether these notions are
satisfied.",2024-05-24,"Drago Plecko, Elias Bareinboim",http://arxiv.org/pdf/2405.15446v1,cs.LG
HINT: Hypernetwork Approach to Training Weight Interval Regions in Continual Learning,"Recently, a new Continual Learning (CL) paradigm was presented to control
catastrophic forgetting, called Interval Continual Learning (InterContiNet),
which relies on enforcing interval constraints on the neural network parameter
space. Unfortunately, InterContiNet training is challenging due to the high
dimensionality of the weight space, making intervals difficult to manage. To
address this issue, we introduce HINT, a technique that employs interval
arithmetic within the embedding space and utilizes a hypernetwork to map these
intervals to the target network parameter space. We train interval embeddings
for consecutive tasks and train a hypernetwork to transform these embeddings
into weights of the target network. An embedding for a given task is trained
along with the hypernetwork, preserving the response of the target network for
the previous task embeddings. Interval arithmetic works with a more manageable,
lower-dimensional embedding space rather than directly preparing intervals in a
high-dimensional weight space. Our model allows faster and more efficient
training. Furthermore, HINT maintains the guarantee of not forgetting. At the
end of training, we can choose one universal embedding to produce a single
network dedicated to all tasks. In such a framework, hypernetwork is used only
for training and, finally, we can utilize one set of weights. HINT obtains
significantly better results than InterContiNet and gives SOTA results on
several benchmarks.",2024-05-24,"Patryk Krukowski, Anna Bielawska, Kamil Książek, Paweł Wawrzyński, Paweł Batorski, Przemysław Spurek",http://arxiv.org/pdf/2405.15444v4,cs.LG
Fairness-Accuracy Trade-Offs: A Causal Perspective,"Systems based on machine learning may exhibit discriminatory behavior based
on sensitive characteristics such as gender, sex, religion, or race. In light
of this, various notions of fairness and methods to quantify discrimination
were proposed, leading to the development of numerous approaches for
constructing fair predictors. At the same time, imposing fairness constraints
may decrease the utility of the decision-maker, highlighting a tension between
fairness and utility. This tension is also recognized in legal frameworks, for
instance in the disparate impact doctrine of Title VII of the Civil Rights Act
of 1964 -- in which specific attention is given to considerations of business
necessity -- possibly allowing the usage of proxy variables associated with the
sensitive attribute in case a high-enough utility cannot be achieved without
them. In this work, we analyze the tension between fairness and accuracy from a
causal lens for the first time. We introduce the notion of a path-specific
excess loss (PSEL) that captures how much the predictor's loss increases when a
causal fairness constraint is enforced. We then show that the total excess loss
(TEL), defined as the difference between the loss of predictor fair along all
causal pathways vs. an unconstrained predictor, can be decomposed into a sum of
more local PSELs. At the same time, enforcing a causal constraint often reduces
the disparity between demographic groups. Thus, we introduce a quantity that
summarizes the fairness-utility trade-off, called the causal fairness/utility
ratio, defined as the ratio of the reduction in discrimination vs. the excess
loss from constraining a causal pathway. This quantity is suitable for
comparing the fairness-utility trade-off across causal pathways. Finally, as
our approach requires causally-constrained fair predictors, we introduce a new
neural approach for causally-constrained fair learning.",2024-05-24,"Drago Plecko, Elias Bareinboim",http://arxiv.org/pdf/2405.15443v2,cs.LG
Towards Precision Healthcare: Robust Fusion of Time Series and Image Data,"With the increasing availability of diverse data types, particularly images
and time series data from medical experiments, there is a growing demand for
techniques designed to combine various modalities of data effectively. Our
motivation comes from the important areas of predicting mortality and
phenotyping where using different modalities of data could significantly
improve our ability to predict. To tackle this challenge, we introduce a new
method that uses two separate encoders, one for each type of data, allowing the
model to understand complex patterns in both visual and time-based information.
Apart from the technical challenges, our goal is to make the predictive model
more robust in noisy conditions and perform better than current methods. We
also deal with imbalanced datasets and use an uncertainty loss function,
yielding improved results while simultaneously providing a principled means of
modeling uncertainty. Additionally, we include attention mechanisms to fuse
different modalities, allowing the model to focus on what's important for each
task. We tested our approach using the comprehensive multimodal MIMIC dataset,
combining MIMIC-IV and MIMIC-CXR datasets. Our experiments show that our method
is effective in improving multimodal deep learning for clinical applications.
The code will be made available online.",2024-05-24,"Ali Rasekh, Reza Heidari, Amir Hosein Haji Mohammad Rezaie, Parsa Sharifi Sedeh, Zahra Ahmadi, Prasenjit Mitra, Wolfgang Nejdl",http://arxiv.org/pdf/2405.15442v1,cs.LG
Statistical and Computational Guarantees of Kernel Max-Sliced Wasserstein Distances,"Optimal transport has been very successful for various machine learning
tasks; however, it is known to suffer from the curse of dimensionality. Hence,
dimensionality reduction is desirable when applied to high-dimensional data
with low-dimensional structures. The kernel max-sliced (KMS) Wasserstein
distance is developed for this purpose by finding an optimal nonlinear mapping
that reduces data into $1$ dimension before computing the Wasserstein distance.
However, its theoretical properties have not yet been fully developed. In this
paper, we provide sharp finite-sample guarantees under milder technical
assumptions compared with state-of-the-art for the KMS $p$-Wasserstein distance
between two empirical distributions with $n$ samples for general
$p\in[1,\infty)$. Algorithm-wise, we show that computing the KMS
$2$-Wasserstein distance is NP-hard, and then we further propose a semidefinite
relaxation (SDR) formulation (which can be solved efficiently in polynomial
time) and provide a relaxation gap for the obtained solution. We provide
numerical examples to demonstrate the good performance of our scheme for
high-dimensional two-sample testing.",2024-05-24,"Jie Wang, March Boedihardjo, Yao Xie",http://arxiv.org/pdf/2405.15441v3,cs.LG
Comparing remote sensing-based forest biomass mapping approaches using new forest inventory plots in contrasting forests in northeastern and southwestern China,"Large-scale high spatial resolution aboveground biomass (AGB) maps play a
crucial role in determining forest carbon stocks and how they are changing,
which is instrumental in understanding the global carbon cycle, and
implementing policy to mitigate climate change. The advent of the new
space-borne LiDAR sensor, NASA's GEDI instrument, provides unparalleled
possibilities for the accurate and unbiased estimation of forest AGB at high
resolution, particularly in dense and tall forests, where Synthetic Aperture
Radar (SAR) and passive optical data exhibit saturation. However, GEDI is a
sampling instrument, collecting dispersed footprints, and its data must be
combined with that from other continuous cover satellites to create
high-resolution maps, using local machine learning methods. In this study, we
developed local models to estimate forest AGB from GEDI L2A data, as the models
used to create GEDI L4 AGB data incorporated minimal field data from China. We
then applied LightGBM and random forest regression to generate wall-to-wall AGB
maps at 25 m resolution, using extensive GEDI footprints as well as Sentinel-1
data, ALOS-2 PALSAR-2 and Sentinel-2 optical data. Through a 5-fold
cross-validation, LightGBM demonstrated a slightly better performance than
Random Forest across two contrasting regions. However, in both regions, the
computation speed of LightGBM is substantially faster than that of the random
forest model, requiring roughly one-third of the time to compute on the same
hardware. Through the validation against field data, the 25 m resolution AGB
maps generated using the local models developed in this study exhibited higher
accuracy compared to the GEDI L4B AGB data. We found in both regions an
increase in error as slope increased. The trained models were tested on nearby
but different regions and exhibited good performance.",2024-05-24,"Wenquan Dong, Edward T. A. Mitchard, Yuwei Chen, Man Chen, Congfeng Cao, Peilun Hu, Cong Xu, Steven Hancock",http://arxiv.org/pdf/2405.15438v1,cs.LG
Biometrics and Behavior Analysis for Detecting Distractions in e-Learning,"In this article, we explore computer vision approaches to detect abnormal
head pose during e-learning sessions and we introduce a study on the effects of
mobile phone usage during these sessions. We utilize behavioral data collected
from 120 learners monitored while participating in a MOOC learning sessions.
Our study focuses on the influence of phone-usage events on behavior and
physiological responses, specifically attention, heart rate, and meditation,
before, during, and after phone usage. Additionally, we propose an approach for
estimating head pose events using images taken by the webcam during the MOOC
learning sessions to detect phone-usage events. Our hypothesis suggests that
head posture undergoes significant changes when learners interact with a mobile
phone, contrasting with the typical behavior seen when learners face a computer
during e-learning sessions. We propose an approach designed to detect
deviations in head posture from the average observed during a learner's
session, operating as a semi-supervised method. This system flags events
indicating alterations in head posture for subsequent human review and
selection of mobile phone usage occurrences with a sensitivity over 90%.",2024-05-24,"Álvaro Becerra, Javier Irigoyen, Roberto Daza, Ruth Cobos, Aythami Morales, Julian Fierrez, Mutlu Cukurova",http://arxiv.org/pdf/2405.15434v3,cs.LG
Counterfactual Explanations for Linear Optimization,"The concept of counterfactual explanations (CE) has emerged as one of the
important concepts to understand the inner workings of complex AI systems. In
this paper, we translate the idea of CEs to linear optimization and propose,
motivate, and analyze three different types of CEs: strong, weak, and relative.
While deriving strong and weak CEs appears to be computationally intractable,
we show that calculating relative CEs can be done efficiently. By detecting and
exploiting the hidden convex structure of the optimization problem that arises
in the latter case, we show that obtaining relative CEs can be done in the same
magnitude of time as solving the original linear optimization problem. This is
confirmed by an extensive numerical experiment study on the NETLIB library.",2024-05-24,"Jannis Kurtz, Ş. İlker Birbil, Dick den Hertog",http://arxiv.org/pdf/2405.15431v1,cs.LG
Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics,"Naively trained Deep Reinforcement Learning agents may fail to satisfy vital
safety constraints. To avoid costly retraining, we may desire to repair a
previously trained reinforcement learning agent to obviate unsafe behaviour. We
devise a counterexample-guided repair algorithm for repairing reinforcement
learning systems leveraging safety critics. The algorithm jointly repairs a
reinforcement learning agent and a safety critic using gradient-based
constrained optimisation.",2024-05-24,"David Boetius, Stefan Leue",http://arxiv.org/pdf/2405.15430v1,cs.LG
E(n) Equivariant Topological Neural Networks,"Graph neural networks excel at modeling pairwise interactions, but they
cannot flexibly accommodate higher-order interactions and features. Topological
deep learning (TDL) has emerged recently as a promising tool for addressing
this issue. TDL enables the principled modeling of arbitrary multi-way,
hierarchical higher-order interactions by operating on combinatorial
topological spaces, such as simplicial or cell complexes, instead of graphs.
However, little is known about how to leverage geometric features such as
positions and velocities for TDL. This paper introduces E(n)-Equivariant
Topological Neural Networks (ETNNs), which are E(n)-equivariant message-passing
networks operating on combinatorial complexes, formal objects unifying graphs,
hypergraphs, simplicial, path, and cell complexes. ETNNs incorporate geometric
node features while respecting rotation, reflection, and translation
equivariance. Moreover, being TDL models, ETNNs are natively ready for settings
with heterogeneous interactions. We provide a theoretical analysis to show the
improved expressiveness of ETNNs over architectures for geometric graphs. We
also show how E(n)-equivariant variants of TDL models can be directly derived
from our framework. The broad applicability of ETNNs is demonstrated through
two tasks of vastly different scales: i) molecular property prediction on the
QM9 benchmark and ii) land-use regression for hyper-local estimation of air
pollution with multi-resolution irregular geospatial data. The results indicate
that ETNNs are an effective tool for learning from diverse types of richly
structured data, as they match or surpass SotA equivariant TDL models with a
significantly smaller computational burden, thus highlighting the benefits of a
principled geometric inductive bias. Our implementation of ETNNs can be found
at https://github.com/NSAPH-Projects/topological-equivariant-networks.",2024-05-24,"Claudio Battiloro, Ege Karaismailoğlu, Mauricio Tec, George Dasoulas, Michelle Audirac, Francesca Dominici",http://arxiv.org/pdf/2405.15429v5,cs.LG
Improving Simulation Regression Efficiency using a Machine Learning-based Method in Design Verification,"The verification throughput is becoming a major challenge bottleneck, since
the complexity and size of SoC designs are still ever increasing. Simply adding
more CPU cores and running more tests in parallel will not scale anymore. This
paper discusses various methods of improving verification throughput: ranking
and the new machine learning (ML) based technology introduced by Cadence i.e.
Xcelium ML. Both methods aim at getting comparable coverage in less CPU time by
applying more efficient stimulus. Ranking selects specific seeds that simply
turned out to come up with the largest coverage in previous simulations, while
Xcelium ML generates optimized patterns as a result of finding correlations
between randomization points and achieved coverage of previous regressions.
Quantified results as well as pros & cons of each approach are discussed in
this paper at the example of three actual industry projects. Both Xcelium ML
and Ranking methods gave comparable compression & speedup factors around 3
consistently. But the optimized ML based regressions simulated new random
scenarios occasionally producing a coverage regain of more than 100%. Finally,
a methodology is proposed to use Xcelium ML efficiently throughout the product
development.",2024-05-24,"Deepak Narayan Gadde, Sebastian Simon, Djones Lettnin, Thomas Ziller",http://arxiv.org/pdf/2405.17481v1,cs.LG
Enhancing Pollinator Conservation towards Agriculture 4.0: Monitoring of Bees through Object Recognition,"In an era of rapid climate change and its adverse effects on food production,
technological intervention to monitor pollinator conservation is of paramount
importance for environmental monitoring and conservation for global food
security. The survival of the human species depends on the conservation of
pollinators. This article explores the use of Computer Vision and Object
Recognition to autonomously track and report bee behaviour from images. A novel
dataset of 9664 images containing bees is extracted from video streams and
annotated with bounding boxes. With training, validation and testing sets
(6722, 1915, and 997 images, respectively), the results of the COCO-based YOLO
model fine-tuning approaches show that YOLOv5m is the most effective approach
in terms of recognition accuracy. However, YOLOv5s was shown to be the most
optimal for real-time bee detection with an average processing and inference
time of 5.1ms per video frame at the cost of slightly lower ability. The
trained model is then packaged within an explainable AI interface, which
converts detection events into timestamped reports and charts, with the aim of
facilitating use by non-technical users such as expert stakeholders from the
apiculture industry towards informing responsible consumption and production.",2024-05-24,"Ajay John Alex, Chloe M. Barnes, Pedro Machado, Isibor Ihianle, Gábor Markó, Martin Bencsik, Jordan J. Bird",http://arxiv.org/pdf/2405.15428v1,cs.LG
Smoothed Online Classification can be Harder than Batch Classification,"We study online classification under smoothed adversaries. In this setting,
at each time point, the adversary draws an example from a distribution that has
a bounded density with respect to a fixed base measure, which is known apriori
to the learner. For binary classification and scalar-valued regression,
previous works \citep{haghtalab2020smoothed, block2022smoothed} have shown that
smoothed online learning is as easy as learning in the iid batch setting under
PAC model. However, we show that smoothed online classification can be harder
than the iid batch classification when the label space is unbounded. In
particular, we construct a hypothesis class that is learnable in the iid batch
setting under the PAC model but is not learnable under the smoothed online
model. Finally, we identify a condition that ensures that the PAC learnability
of a hypothesis class is sufficient for its smoothed online learnability.",2024-05-24,"Vinod Raman, Unique Subedi, Ambuj Tewari",http://arxiv.org/pdf/2405.15424v1,cs.LG
Lost in the Averages: A New Specific Setup to Evaluate Membership Inference Attacks Against Machine Learning Models,"Membership Inference Attacks (MIAs) are widely used to evaluate the
propensity of a machine learning (ML) model to memorize an individual record
and the privacy risk releasing the model poses. MIAs are commonly evaluated
similarly to ML models: the MIA is performed on a test set of models trained on
datasets unseen during training, which are sampled from a larger pool,
$D_{eval}$. The MIA is evaluated across all datasets in this test set, and is
thus evaluated across the distribution of samples from $D_{eval}$. While this
was a natural extension of ML evaluation to MIAs, recent work has shown that a
record's risk heavily depends on its specific dataset. For example, outliers
are particularly vulnerable, yet an outlier in one dataset may not be one in
another. The sources of randomness currently used to evaluate MIAs may thus
lead to inaccurate individual privacy risk estimates. We propose a new,
specific evaluation setup for MIAs against ML models, using weight
initialization as the sole source of randomness. This allows us to accurately
evaluate the risk associated with the release of a model trained on a specific
dataset. Using SOTA MIAs, we empirically show that the risk estimates given by
the current setup lead to many records being misclassified as low risk. We
derive theoretical results which, combined with empirical evidence, suggest
that the risk calculated in the current setup is an average of the risks
specific to each sampled dataset, validating our use of weight initialization
as the only source of randomness. Finally, we consider an MIA with a stronger
adversary leveraging information about the target dataset to infer membership.
Taken together, our results show that current MIA evaluation is averaging the
risk across datasets leading to inaccurate risk estimates, and the risk posed
by attacks leveraging information about the target dataset to be potentially
underestimated.",2024-05-24,"Florent Guépin, Nataša Krčo, Matthieu Meeus, Yves-Alexandre de Montjoye",http://arxiv.org/pdf/2405.15423v1,cs.LG
Model-free reinforcement learning with noisy actions for automated experimental control in optics,"Setting up and controlling optical systems is often a challenging and tedious
task. The high number of degrees of freedom to control mirrors, lenses, or
phases of light makes automatic control challenging, especially when the
complexity of the system cannot be adequately modeled due to noise or
non-linearities. Here, we show that reinforcement learning (RL) can overcome
these challenges when coupling laser light into an optical fiber, using a
model-free RL approach that trains directly on the experiment without
pre-training. By utilizing the sample-efficient algorithms Soft Actor-Critic
(SAC) or Truncated Quantile Critics (TQC), our agent learns to couple with 90%
efficiency, comparable to the human expert. We demonstrate that direct training
on an experiment can replace extensive system modeling. Our result exemplifies
RL's potential to tackle problems in optics, paving the way for more complex
applications where full noise modeling is not feasible.",2024-05-24,"Lea Richtmann, Viktoria-S. Schmiesing, Dennis Wilken, Jan Heine, Aaron Tranter, Avishek Anand, Tobias J. Osborne, Michèle Heurs",http://arxiv.org/pdf/2405.15421v2,cs.LG
Data-driven Global Ocean Modeling for Seasonal to Decadal Prediction,"Accurate ocean dynamics modeling is crucial for enhancing understanding of
ocean circulation, predicting climate variability, and tackling challenges
posed by climate change. Despite improvements in traditional numerical models,
predicting global ocean variability over multi-year scales remains challenging.
Here, we propose ORCA-DL (Oceanic Reliable foreCAst via Deep Learning), the
first data-driven 3D ocean model for seasonal to decadal prediction of global
ocean circulation. ORCA-DL accurately simulates three-dimensional ocean
dynamics and outperforms state-of-the-art dynamical models in capturing extreme
events, including El Ni\~no-Southern Oscillation and upper ocean heatwaves.
This demonstrates the high potential of data-driven models for efficient and
accurate global ocean forecasting. Moreover, ORCA-DL stably emulates ocean
dynamics at decadal timescales, demonstrating its potential even for skillful
decadal predictions and climate projections.",2024-05-24,"Zijie Guo, Pumeng Lyu, Fenghua Ling, Lei Bai, Jing-Jia Luo, Niklas Boers, Toshio Yamagata, Takeshi Izumo, Sophie Cravatte, Antonietta Capotondi, Wanli Ouyang",http://arxiv.org/pdf/2405.15412v2,cs.LG
Towards Client Driven Federated Learning,"Conventional federated learning (FL) frameworks follow a server-driven model
where the server determines session initiation and client participation, which
faces challenges in accommodating clients' asynchronous needs for model
updates. We introduce Client-Driven Federated Learning (CDFL), a novel FL
framework that puts clients at the driving role. In CDFL, each client
independently and asynchronously updates its model by uploading the locally
trained model to the server and receiving a customized model tailored to its
local task. The server maintains a repository of cluster models, iteratively
refining them using received client models. Our framework accommodates complex
dynamics in clients' data distributions, characterized by time-varying mixtures
of cluster distributions, enabling rapid adaptation to new tasks with superior
performance. In contrast to traditional clustered FL protocols that send
multiple cluster models to a client to perform distribution estimation, we
propose a paradigm that offloads the estimation task to the server and only
sends a single model to a client, and novel strategies to improve estimation
accuracy. We provide a theoretical analysis of CDFL's convergence. Extensive
experiments across various datasets and system settings highlight CDFL's
substantial advantages in model performance and computation efficiency over
baselines.",2024-05-24,"Songze Li, Chenqing Zhu",http://arxiv.org/pdf/2405.15407v1,cs.LG
E2Vec: Feature Embedding with Temporal Information for Analyzing Student Actions in E-Book Systems,"Digital textbook (e-book) systems record student interactions with textbooks
as a sequence of events called EventStream data. In the past, researchers
extracted meaningful features from EventStream, and utilized them as inputs for
downstream tasks such as grade prediction and modeling of student behavior.
Previous research evaluated models that mainly used statistical-based features
derived from EventStream logs, such as the number of operation types or access
frequencies. While these features are useful for providing certain insights,
they lack temporal information that captures fine-grained differences in
learning behaviors among different students. This study proposes E2Vec, a novel
feature representation method based on word embeddings. The proposed method
regards operation logs and their time intervals for each student as a string
sequence of characters and generates a student vector of learning activity
features that incorporates time information. We applied fastText to generate an
embedding vector for each of 305 students in a dataset from two years of
computer science courses. Then, we investigated the effectiveness of E2Vec in
an at-risk detection task, demonstrating potential for generalizability and
performance.",2024-05-24,"Yuma Miyazaki, Valdemar Švábenský, Yuta Taniguchi, Fumiya Okubo, Tsubasa Minematsu, Atsushi Shimada",http://arxiv.org/pdf/2407.13053v1,cs.LG
A Misleading Gallery of Fluid Motion by Generative Artificial Intelligence,"In this technical report, we extensively investigate the accuracy of outputs
from well-known generative artificial intelligence (AI) applications in
response to prompts describing common fluid motion phenomena familiar to the
fluid mechanics community. We examine a range of applications, including
Midjourney, Dall-E, Runway ML, Microsoft Designer, Gemini, Meta AI, and
Leonardo AI, introduced by prominent companies such as Google, OpenAI, Meta,
and Microsoft. Our text prompts for generating images or videos include
examples such as ""Von Karman vortex street"", ""flow past an airfoil"",
""Kelvin-Helmholtz instability"", ""shock waves on a sharp-nosed supersonic body"",
etc. We compare the images generated by these applications with real images
from laboratory experiments and numerical software. Our findings indicate that
these generative AI models are not adequately trained in fluid dynamics
imagery, leading to potentially misleading outputs. Beyond text-to-image/video
generation, we further explore the transition from image/video to text
generation using these AI tools, aiming to investigate the accuracy of their
descriptions of fluid motion phenomena. This report serves as a cautionary note
for educators in academic institutions, highlighting the potential for these
tools to mislead students. It also aims to inform researchers at these renowned
companies, encouraging them to address this issue. We conjecture that a primary
reason for this shortcoming is the limited access to copyright-protected fluid
motion images from scientific journals.",2024-05-24,Ali Kashefi,http://arxiv.org/pdf/2405.15406v1,cs.LG
Fine-Grained Dynamic Framework for Bias-Variance Joint Optimization on Data Missing Not at Random,"In most practical applications such as recommendation systems, display
advertising, and so forth, the collected data often contains missing values and
those missing values are generally missing-not-at-random, which deteriorates
the prediction performance of models. Some existing estimators and regularizers
attempt to achieve unbiased estimation to improve the predictive performance.
However, variances and generalization bound of these methods are generally
unbounded when the propensity scores tend to zero, compromising their stability
and robustness. In this paper, we first theoretically reveal that limitations
of regularization techniques. Besides, we further illustrate that, for more
general estimators, unbiasedness will inevitably lead to unbounded variance.
These general laws inspire us that the estimator designs is not merely about
eliminating bias, reducing variance, or simply achieve a bias-variance
trade-off. Instead, it involves a quantitative joint optimization of bias and
variance. Then, we develop a systematic fine-grained dynamic learning framework
to jointly optimize bias and variance, which adaptively selects an appropriate
estimator for each user-item pair according to the predefined objective
function. With this operation, the generalization bounds and variances of
models are reduced and bounded with theoretical guarantees. Extensive
experiments are conducted to verify the theoretical results and the
effectiveness of the proposed dynamic learning framework.",2024-05-24,"Mingming Ha, Xuewen Tao, Wenfang Lin, Qionxu Ma, Wujiang Xu, Linxun Chen",http://arxiv.org/pdf/2405.15403v1,cs.LG
Reshuffling Resampling Splits Can Improve Generalization of Hyperparameter Optimization,"Hyperparameter optimization is crucial for obtaining peak performance of
machine learning models. The standard protocol evaluates various hyperparameter
configurations using a resampling estimate of the generalization error to guide
optimization and select a final hyperparameter configuration. Without much
evidence, paired resampling splits, i.e., either a fixed train-validation split
or a fixed cross-validation scheme, are often recommended. We show that,
surprisingly, reshuffling the splits for every configuration often improves the
final model's generalization performance on unseen data. Our theoretical
analysis explains how reshuffling affects the asymptotic behavior of the
validation loss surface and provides a bound on the expected regret in the
limiting regime. This bound connects the potential benefits of reshuffling to
the signal and noise characteristics of the underlying optimization problem. We
confirm our theoretical results in a controlled simulation study and
demonstrate the practical usefulness of reshuffling in a large-scale, realistic
hyperparameter optimization experiment. While reshuffling leads to test
performances that are competitive with using fixed splits, it drastically
improves results for a single train-validation holdout protocol and can often
make holdout become competitive with standard CV while being computationally
cheaper.",2024-05-24,"Thomas Nagler, Lennart Schneider, Bernd Bischl, Matthias Feurer",http://arxiv.org/pdf/2405.15393v2,cs.LG
Beyond Canonicalization: How Tensorial Messages Improve Equivariant Message Passing,"In numerous applications of geometric deep learning, the studied systems
exhibit spatial symmetries and it is desirable to enforce these. For the
symmetry of global rotations and reflections, this means that the model should
be equivariant with respect to the transformations that form the group of
$\mathrm O(d)$. While many approaches for equivariant message passing require
specialized architectures, including non-standard normalization layers or
non-linearities, we here present a framework based on local reference frames
(""local canonicalization"") which can be integrated with any architecture
without restrictions. We enhance equivariant message passing based on local
canonicalization by introducing tensorial messages to communicate geometric
information consistently between different local coordinate frames. Our
framework applies to message passing on geometric data in Euclidean spaces of
arbitrary dimension. We explicitly show how our approach can be adapted to make
a popular existing point cloud architecture equivariant. We demonstrate the
superiority of tensorial messages and achieve state-of-the-art results on
normal vector regression and competitive results on other standard 3D point
cloud tasks.",2024-05-24,"Peter Lippmann, Gerrit Gerhartz, Roman Remme, Fred A. Hamprecht",http://arxiv.org/pdf/2405.15389v3,cs.LG
Efficient Recurrent Off-Policy RL Requires a Context-Encoder-Specific Learning Rate,"Real-world decision-making tasks are usually partially observable Markov
decision processes (POMDPs), where the state is not fully observable. Recent
progress has demonstrated that recurrent reinforcement learning (RL), which
consists of a context encoder based on recurrent neural networks (RNNs) for
unobservable state prediction and a multilayer perceptron (MLP) policy for
decision making, can mitigate partial observability and serve as a robust
baseline for POMDP tasks. However, previous recurrent RL methods face training
stability issues due to the gradient instability of RNNs. In this paper, we
propose Recurrent Off-policy RL with Context-Encoder-Specific Learning Rate
(RESeL) to tackle this issue. Specifically, RESeL uses a lower learning rate
for context encoder than other MLP layers to ensure the stability of the former
while maintaining the training efficiency of the latter. We integrate this
technique into existing off-policy RL methods, resulting in the RESeL
algorithm. We evaluated RESeL in 18 POMDP tasks, including classic, meta-RL,
and credit assignment scenarios, as well as five MDP locomotion tasks. The
experiments demonstrate significant improvements in training stability with
RESeL. Comparative results show that RESeL achieves notable performance
improvements over previous recurrent RL baselines in POMDP tasks, and is
competitive with or even surpasses state-of-the-art methods in MDP tasks.
Further ablation studies highlight the necessity of applying a distinct
learning rate for the context encoder.",2024-05-24,"Fan-Ming Luo, Zuolin Tu, Zefang Huang, Yang Yu",http://arxiv.org/pdf/2405.15384v1,cs.LG
Randomized Midpoint Method for Log-Concave Sampling under Constraints,"In this paper, we study the problem of sampling from log-concave
distributions supported on convex, compact sets, with a particular focus on the
randomized midpoint discretization of both vanilla and kinetic Langevin
diffusions in this constrained setting. We propose a unified proximal framework
for handling constraints via a broad class of projection operators, including
Euclidean, Bregman, and Gauge projections. Within this framework, we establish
non-asymptotic bounds in both $\mathcal{W}_1$ and $\mathcal{W}_2$ distances,
providing precise complexity guarantees and performance comparisons. In
addition, our analysis leads to sharper convergence guarantees for both vanilla
and kinetic Langevin Monte Carlo under constraints, improving upon existing
theoretical results.",2024-05-24,"Yifeng Yu, Lu Yu",http://arxiv.org/pdf/2405.15379v2,cs.LG
Fast training and sampling of Restricted Boltzmann Machines,"Restricted Boltzmann Machines (RBMs) are effective tools for modeling complex
systems and deriving insights from data. However, training these models with
highly structured data presents significant challenges due to the slow mixing
characteristics of Markov Chain Monte Carlo processes. In this study, we build
upon recent theoretical advancements in RBM training, to significantly reduce
the computational cost of training (in very clustered datasets), evaluating and
sampling in RBMs in general. The learning process is analogous to thermodynamic
continuous phase transitions observed in ferromagnetic models, where new modes
in the probability measure emerge in a continuous manner. Such continuous
transitions are associated with the critical slowdown effect, which adversely
affects the accuracy of gradient estimates, particularly during the initial
stages of training with clustered data. To mitigate this issue, we propose a
pre-training phase that encodes the principal components into a low-rank RBM
through a convex optimization process. This approach enables efficient static
Monte Carlo sampling and accurate computation of the partition function. We
exploit the continuous and smooth nature of the parameter annealing trajectory
to achieve reliable and computationally efficient log-likelihood estimations,
enabling online assessment during the training, and propose a novel sampling
strategy named parallel trajectory tempering (PTT) which outperforms previously
optimized MCMC methods. Our results show that this training strategy enables
RBMs to effectively address highly structured datasets that conventional
methods struggle with. We also provide evidence that our log-likelihood
estimation is more accurate than traditional, more computationally intensive
approaches in controlled scenarios. The PTT algorithm significantly accelerates
MCMC processes compared to existing and conventional methods.",2024-05-24,"Nicolas Béreux, Aurélien Decelle, Cyril Furtlehner, Lorenzo Rosset, Beatriz Seoane",http://arxiv.org/pdf/2405.15376v2,cs.LG
A Fisher-Rao gradient flow for entropic mean-field min-max games,"Gradient flows play a substantial role in addressing many machine learning
problems. We examine the convergence in continuous-time of a
\textit{Fisher-Rao} (Mean-Field Birth-Death) gradient flow in the context of
solving convex-concave min-max games with entropy regularization. We propose
appropriate Lyapunov functions to demonstrate convergence with explicit rates
to the unique mixed Nash equilibrium.",2024-05-24,"Razvan-Andrei Lascu, Mateusz B. Majka, Łukasz Szpruch",http://arxiv.org/pdf/2405.15834v2,cs.LG
Cross-Domain Policy Adaptation by Capturing Representation Mismatch,"It is vital to learn effective policies that can be transferred to different
domains with dynamics discrepancies in reinforcement learning (RL). In this
paper, we consider dynamics adaptation settings where there exists dynamics
mismatch between the source domain and the target domain, and one can get
access to sufficient source domain data, while can only have limited
interactions with the target domain. Existing methods address this problem by
learning domain classifiers, performing data filtering from a value discrepancy
perspective, etc. Instead, we tackle this challenge from a decoupled
representation learning perspective. We perform representation learning only in
the target domain and measure the representation deviations on the transitions
from the source domain, which we show can be a signal of dynamics mismatch. We
also show that representation deviation upper bounds performance difference of
a given policy in the source domain and target domain, which motivates us to
adopt representation deviation as a reward penalty. The produced
representations are not involved in either policy or value function, but only
serve as a reward penalizer. We conduct extensive experiments on environments
with kinematic and morphology mismatch, and the results show that our method
exhibits strong performance on many tasks. Our code is publicly available at
https://github.com/dmksjfl/PAR.",2024-05-24,"Jiafei Lyu, Chenjia Bai, Jingwen Yang, Zongqing Lu, Xiu Li",http://arxiv.org/pdf/2405.15369v1,cs.LG
Pipeline Parallelism with Controllable Memory,"Pipeline parallelism has been widely explored, but most existing schedules
lack a systematic methodology. In this paper, we propose a framework to
decompose pipeline schedules as repeating a building block, and show that the
lifespan of the building block decides the peak activation memory of the
pipeline schedule. Guided by the observations, we find that almost all existing
pipeline schedules, to the best of our knowledge, are memory inefficient. To
address this, we introduce a family of memory efficient building blocks with
controllable activation memory, which can reduce the peak activation memory to
1/2 of 1F1B without sacrificing efficiency, and even to 1/3 with comparable
throughput. We can also achieve almost zero pipeline bubbles while maintaining
the same activation memory as 1F1B. Our evaluations demonstrate that in pure
pipeline parallelism settings, our methods outperform 1F1B by from 7% to 55% in
terms of throughput. When employing a grid search over hybrid parallelism
hyperparameters in practical scenarios, our methods demonstrate a 16%
throughput improvement over the 1F1B baseline for large language models. The
implementation is open-sourced at
https://github.com/sail-sg/zero-bubble-pipeline-parallelism.",2024-05-24,"Penghui Qi, Xinyi Wan, Nyamdavaa Amar, Min Lin",http://arxiv.org/pdf/2405.15362v4,cs.LG
Coordinated Multi-Neighborhood Learning on a Directed Acyclic Graph,"Learning the structure of causal directed acyclic graphs (DAGs) is useful in
many areas of machine learning and artificial intelligence, with wide
applications. However, in the high-dimensional setting, it is challenging to
obtain good empirical and theoretical results without strong and often
restrictive assumptions. Additionally, it is questionable whether all of the
variables purported to be included in the network are observable. It is of
interest then to restrict consideration to a subset of the variables for
relevant and reliable inferences. In fact, researchers in various disciplines
can usually select a set of target nodes in the network for causal discovery.
This paper develops a new constraint-based method for estimating the local
structure around multiple user-specified target nodes, enabling coordination in
structure learning between neighborhoods. Our method facilitates causal
discovery without learning the entire DAG structure. We establish consistency
results for our algorithm with respect to the local neighborhood structure of
the target nodes in the true graph. Experimental results on synthetic and
real-world data show that our algorithm is more accurate in learning the
neighborhood structures with much less computational cost than standard methods
that estimate the entire DAG. An R package implementing our methods may be
accessed at https://github.com/stephenvsmith/CML.",2024-05-24,"Stephen Smith, Qing Zhou",http://arxiv.org/pdf/2405.15358v1,cs.LG
Strong Screening Rules for Group-based SLOPE Models,"Tuning the regularization parameter in penalized regression models is an
expensive task, requiring multiple models to be fit along a path of parameters.
Strong screening rules drastically reduce computational costs by lowering the
dimensionality of the input prior to fitting. We develop strong screening rules
for group-based Sorted L-One Penalized Estimation (SLOPE) models: Group SLOPE
and Sparse-group SLOPE. The developed rules are applicable to the wider family
of group-based OWL models, including OSCAR. Our experiments on both synthetic
and real data show that the screening rules significantly accelerate the
fitting process. The screening rules make it accessible for group SLOPE and
sparse-group SLOPE to be applied to high-dimensional datasets, particularly
those encountered in genetics.",2024-05-24,"Fabio Feser, Marina Evangelou",http://arxiv.org/pdf/2405.15357v2,cs.LG
BiSup: Bidirectional Quantization Error Suppression for Large Language Models,"As the size and context length of Large Language Models (LLMs) grow,
weight-activation quantization has emerged as a crucial technique for efficient
deployment of LLMs. Compared to weight-only quantization, weight-activation
quantization presents greater challenges due to the presence of outliers in
activations. Existing methods have made significant progress by exploring
mixed-precision quantization and outlier suppression. However, these methods
primarily focus on optimizing the results of single matrix multiplication,
neglecting the bidirectional propagation of quantization errors in LLMs.
Specifically, errors accumulate vertically within the same token through
layers, and diffuse horizontally across different tokens due to self-attention
mechanisms. To address this issue, we introduce BiSup, a Bidirectional
quantization error Suppression method. By constructing appropriate optimizable
parameter spaces, BiSup utilizes a small amount of data for quantization-aware
parameter-efficient fine-tuning to suppress the error vertical accumulation.
Besides, BiSup employs prompt mixed-precision quantization strategy, which
preserves high precision for the key-value cache of system prompts, to mitigate
the error horizontal diffusion. Extensive experiments on Llama and Qwen
families demonstrate that BiSup can improve performance over two
state-of-the-art methods (the average WikiText2 perplexity decreases from 13.26
to 9.41 for Atom and from 14.33 to 7.85 for QuaRot under the W3A3-g128
configuration), further facilitating the practical applications of low-bit
weight-activation quantization.",2024-05-24,"Minghui Zou, Ronghui Guo, Sai Zhang, Xiaowang Zhang, Zhiyong Feng",http://arxiv.org/pdf/2405.15346v1,cs.LG
Transmission Interface Power Flow Adjustment: A Deep Reinforcement Learning Approach based on Multi-task Attribution Map,"Transmission interface power flow adjustment is a critical measure to ensure
the security and economy operation of power systems. However, conventional
model-based adjustment schemes are limited by the increasing variations and
uncertainties occur in power systems, where the adjustment problems of
different transmission interfaces are often treated as several independent
tasks, ignoring their coupling relationship and even leading to conflict
decisions. In this paper, we introduce a novel data-driven deep reinforcement
learning (DRL) approach, to handle multiple power flow adjustment tasks jointly
instead of learning each task from scratch. At the heart of the proposed method
is a multi-task attribution map (MAM), which enables the DRL agent to
explicitly attribute each transmission interface task to different power system
nodes with task-adaptive attention weights. Based on this MAM, the agent can
further provide effective strategies to solve the multi-task adjustment problem
with a near-optimal operation cost. Simulation results on the IEEE 118-bus
system, a realistic 300-bus system in China, and a very large European system
with 9241 buses demonstrate that the proposed method significantly improves the
performance compared with several baseline methods, and exhibits high
interpretability with the learnable MAM.",2024-05-24,"Shunyu Liu, Wei Luo, Yanzhen Zhou, Kaixuan Chen, Quan Zhang, Huating Xu, Qinglai Guo, Mingli Song",http://arxiv.org/pdf/2405.15831v1,cs.LG
Discriminative Estimation of Total Variation Distance: A Fidelity Auditor for Generative Data,"With the proliferation of generative AI and the increasing volume of
generative data (also called as synthetic data), assessing the fidelity of
generative data has become a critical concern. In this paper, we propose a
discriminative approach to estimate the total variation (TV) distance between
two distributions as an effective measure of generative data fidelity. Our
method quantitatively characterizes the relation between the Bayes risk in
classifying two distributions and their TV distance. Therefore, the estimation
of total variation distance reduces to that of the Bayes risk. In particular,
this paper establishes theoretical results regarding the convergence rate of
the estimation error of TV distance between two Gaussian distributions. We
demonstrate that, with a specific choice of hypothesis class in classification,
a fast convergence rate in estimating the TV distance can be achieved.
Specifically, the estimation accuracy of the TV distance is proven to
inherently depend on the separation of two Gaussian distributions: smaller
estimation errors are achieved when the two Gaussian distributions are farther
apart. This phenomenon is also validated empirically through extensive
simulations. In the end, we apply this discriminative estimation method to rank
fidelity of synthetic image data using the MNIST dataset.",2024-05-24,"Lan Tao, Shirong Xu, Chi-Hua Wang, Namjoon Suh, Guang Cheng",http://arxiv.org/pdf/2405.15337v1,cs.LG
Cross-Validated Off-Policy Evaluation,"We study estimator selection and hyper-parameter tuning in off-policy
evaluation. Although cross-validation is the most popular method for model
selection in supervised learning, off-policy evaluation relies mostly on
theory, which provides only limited guidance to practitioners. We show how to
use cross-validation for off-policy evaluation. This challenges a popular
belief that cross-validation in off-policy evaluation is not feasible. We
evaluate our method empirically and show that it addresses a variety of use
cases.",2024-05-24,"Matej Cief, Branislav Kveton, Michal Kompan",http://arxiv.org/pdf/2405.15332v4,cs.LG
Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model,"Recently, the strong latent Diffusion Probabilistic Model (DPM) has been
applied to high-quality Text-to-Image (T2I) generation (e.g., Stable
Diffusion), by injecting the encoded target text prompt into the gradually
denoised diffusion image generator. Despite the success of DPM in practice, the
mechanism behind it remains to be explored. To fill this blank, we begin by
examining the intermediate statuses during the gradual denoising generation
process in DPM. The empirical observations indicate, the shape of image is
reconstructed after the first few denoising steps, and then the image is filled
with details (e.g., texture). The phenomenon is because the low-frequency
signal (shape relevant) of the noisy image is not corrupted until the final
stage in the forward process (initial stage of generation) of adding noise in
DPM. Inspired by the observations, we proceed to explore the influence of each
token in the text prompt during the two stages. After a series of experiments
of T2I generations conditioned on a set of text prompts. We conclude that in
the earlier generation stage, the image is mostly decided by the special token
[\texttt{EOS}] in the text prompt, and the information in the text prompt is
already conveyed in this stage. After that, the diffusion model completes the
details of generated images by information from themselves. Finally, we propose
to apply this observation to accelerate the process of T2I generation by
properly removing text guidance, which finally accelerates the sampling up to
25\%+.",2024-05-24,"Mingyang Yi, Aoxue Li, Yi Xin, Zhenguo Li",http://arxiv.org/pdf/2405.15330v3,cs.LG
"Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality Constraints","User data spread across multiple modalities has popularized multi-modal
recommender systems (MMRS). They recommend diverse content such as products,
social media posts, TikTok reels, etc., based on a user-item interaction graph.
With rising data privacy demands, recent methods propose unlearning private
user data from uni-modal recommender systems (RS). However, methods for
unlearning item data related to outdated user preferences, revoked licenses,
and legally requested removals are still largely unexplored.
  Previous RS unlearning methods are unsuitable for MMRS due to the
incompatibility of their matrix-based representation with the multi-modal
user-item interaction graph. Moreover, their data partitioning step degrades
performance on each shard due to poor data heterogeneity and requires costly
performance aggregation across shards.
  This paper introduces MMRecUn, the first approach known to us for unlearning
in MMRS and unlearning item data. Given a trained RS model, MMRecUn employs a
novel Reverse Bayesian Personalized Ranking (BPR) objective to enable the model
to forget marked data. The reverse BPR attenuates the impact of user-item
interactions within the forget set, while the forward BPR reinforces the
significance of user-item interactions within the retain set. Our experiments
demonstrate that MMRecUn outperforms baseline methods across various unlearning
requests when evaluated on benchmark MMRS datasets. MMRecUn achieves recall
performance improvements of up to 49.85% compared to baseline methods and is up
to $\mathbf{1.3}\times$ faster than the Gold model, which is trained on retain
set from scratch. MMRecUn offers significant advantages, including superiority
in removing target interactions, preserving retained interactions, and zero
overhead costs compared to previous methods. The code will be released after
review.",2024-05-24,"Yash Sinha, Murari Mandal, Mohan Kankanhalli",http://arxiv.org/pdf/2405.15328v2,cs.LG
Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness,"The growing interest in fair AI development is evident. The ''Leave No One
Behind'' initiative urges us to address multiple and intersecting forms of
inequality in accessing services, resources, and opportunities, emphasising the
significance of fairness in AI. This is particularly relevant as an increasing
number of AI tools are applied to decision-making processes, such as resource
allocation and service scheme development, across various sectors such as
health, energy, and housing. Therefore, exploring joint inequalities in these
sectors is significant and valuable for thoroughly understanding overall
inequality and unfairness. This research introduces an innovative approach to
quantify cross-sectoral intersecting discrepancies among user-defined groups
using latent class analysis. These discrepancies can be used to approximate
inequality and provide valuable insights to fairness issues. We validate our
approach using both proprietary and public datasets, including both EVENS and
Census 2021 (England & Wales) datasets, to examine cross-sectoral intersecting
discrepancies among different ethnic groups. We also verify the reliability of
the quantified discrepancy by conducting a correlation analysis with a
government public metric. Our findings reveal significant discrepancies both
among minority ethnic groups and between minority ethnic groups and
non-minority ethnic groups, emphasising the need for targeted interventions in
policy-making processes. Furthermore, we demonstrate how the proposed approach
can provide valuable insights into ensuring fairness in machine learning
systems.",2024-05-24,"Yingfang Yuan, Kefan Chen, Mehdi Rizvi, Lynne Baillie, Wei Pang",http://arxiv.org/pdf/2407.03133v3,cs.LG
On the Identification of Temporally Causal Representation with Instantaneous Dependence,"Temporally causal representation learning aims to identify the latent causal
process from time series observations, but most methods require the assumption
that the latent causal processes do not have instantaneous relations. Although
some recent methods achieve identifiability in the instantaneous causality
case, they require either interventions on the latent variables or grouping of
the observations, which are in general difficult to obtain in real-world
scenarios. To fill this gap, we propose an \textbf{ID}entification framework
for instantane\textbf{O}us \textbf{L}atent dynamics (\textbf{IDOL}) by imposing
a sparse influence constraint that the latent causal processes have sparse
time-delayed and instantaneous relations. Specifically, we establish
identifiability results of the latent causal process based on sufficient
variability and the sparse influence constraint by employing contextual
information of time series data. Based on these theories, we incorporate a
temporally variational inference architecture to estimate the latent variables
and a gradient-based sparsity regularization to identify the latent causal
process. Experimental results on simulation datasets illustrate that our method
can identify the latent causal process. Furthermore, evaluations on multiple
human motion forecasting benchmarks with instantaneous dependencies indicate
the effectiveness of our method in real-world settings.",2024-05-24,"Zijian Li, Yifan Shen, Kaitao Zheng, Ruichu Cai, Xiangchen Song, Mingming Gong, Zhengmao Zhu, Guangyi Chen, Kun Zhang",http://arxiv.org/pdf/2405.15325v2,cs.LG
NuwaTS: a Foundation Model Mending Every Incomplete Time Series,"Time series imputation is critical for many real-world applications and has
been widely studied. However, existing models often require specialized designs
tailored to specific missing patterns, variables, or domains which limits their
generalizability. In addition, current evaluation frameworks primarily focus on
domain-specific tasks and often rely on time-wise train/validation/test data
splits, which fail to rigorously assess a model's ability to generalize across
unseen variables or domains. In this paper, we present \textbf{NuwaTS}, a novel
framework that repurposes Pre-trained Language Models (PLMs) for general time
series imputation. Once trained, NuwaTS can be applied to impute missing data
across any domain. We introduce specialized embeddings for each sub-series
patch, capturing information about the patch, its missing data patterns, and
its statistical characteristics. By combining contrastive learning with the
imputation task, we train PLMs to create a versatile, one-for-all imputation
model. Additionally, we employ a plug-and-play fine-tuning approach, enabling
efficient adaptation to domain-specific tasks with minimal adjustments. To
evaluate cross-variable and cross-domain generalization, we propose a new
benchmarking protocol that partitions the datasets along the variable
dimension. Experimental results on over seventeen million time series samples
from diverse domains demonstrate that NuwaTS outperforms state-of-the-art
domain-specific models across various datasets under the proposed benchmarking
protocol. Furthermore, we show that NuwaTS generalizes to other time series
tasks, such as forecasting. Our codes are available at
https://github.com/Chengyui/NuwaTS.",2024-05-24,"Jinguo Cheng, Chunwei Yang, Wanlin Cai, Yuxuan Liang, Qingsong Wen, Yuankai Wu",http://arxiv.org/pdf/2405.15317v3,cs.LG
Decaf: Data Distribution Decompose Attack against Federated Learning,"In contrast to prevalent Federated Learning (FL) privacy inference techniques
such as generative adversarial networks attacks, membership inference attacks,
property inference attacks, and model inversion attacks, we devise an
innovative privacy threat: the Data Distribution Decompose Attack on FL, termed
Decaf. This attack enables an honest-but-curious FL server to meticulously
profile the proportion of each class owned by the victim FL user, divulging
sensitive information like local market item distribution and business
competitiveness. The crux of Decaf lies in the profound observation that the
magnitude of local model gradient changes closely mirrors the underlying data
distribution, including the proportion of each class. Decaf addresses two
crucial challenges: accurately identify the missing/null class(es) given by any
victim user as a premise and then quantify the precise relationship between
gradient changes and each remaining non-null class. Notably, Decaf operates
stealthily, rendering it entirely passive and undetectable to victim users
regarding the infringement of their data distribution privacy. Experimental
validation on five benchmark datasets (MNIST, FASHION-MNIST, CIFAR-10,
FER-2013, and SkinCancer) employing diverse model architectures, including
customized convolutional networks, standardized VGG16, and ResNet18,
demonstrates Decaf's efficacy. Results indicate its ability to accurately
decompose local user data distribution, regardless of whether it is IID or
non-IID distributed. Specifically, the dissimilarity measured using
$L_{\infty}$ distance between the distribution decomposed by Decaf and ground
truth is consistently below 5\% when no null classes exist. Moreover, Decaf
achieves 100\% accuracy in determining any victim user's null classes,
validated through formal proof.",2024-05-24,"Zhiyang Dai, Chunyi Zhou, Anmin Fu",http://arxiv.org/pdf/2405.15316v1,cs.LG
Output-Constrained Decision Trees,"When there is a correlation between any pair of targets, one needs a
prediction method that can handle vector-valued output. In this setting,
multi-target learning is particularly important as it is widely used in various
applications. This paper introduces new variants of decision trees that can
handle not only multi-target output but also the constraints among the targets.
We focus on the customization of conventional decision trees by adjusting the
splitting criteria to handle the constraints and obtain feasible predictions.
We present both an optimization-based exact approach and several heuristics,
complete with a discussion on their respective advantages and disadvantages. To
support our findings, we conduct a computational study to demonstrate and
compare the results of the proposed approaches.",2024-05-24,"Doğanay Özese, Ş. İlker Birbil, Mustafa Baydoğan",http://arxiv.org/pdf/2405.15314v2,cs.LG
Multi-Feature Fusion and Compressed Bi-LSTM for Memory-Efficient Heartbeat Classification on Wearable Devices,"In this article, we present a resource-efficient approach for
electrocardiogram (ECG) based heartbeat classification using multi-feature
fusion and bidirectional long short-term memory (Bi-LSTM). The dataset
comprises five original classes from the MIT-BIH Arrhythmia Database: Normal
(N), Left Bundle Branch Block (LBBB), Right Bundle Branch Block (RBBB),
Premature Ventricular Contraction (PVC), and Paced Beat (PB). Preprocessing
methods including the discrete wavelet transform and dual moving average
windows are used to reduce noise and artifacts in the raw ECG signal, and
extract the main points (PQRST) of the ECG waveform. Multi-feature fusion is
achieved by utilizing time intervals and the proposed under-the-curve areas,
which are inherently robust against noise, as input features. Simulations
demonstrated that incorporating under-the-curve area features improved the
classification accuracy for the challenging RBBB and LBBB classes from 31.4\%
to 84.3\% for RBBB, and from 69.6\% to 87.0\% for LBBB. Using a Bi-LSTM
network, rather than a conventional LSTM network, resulted in higher accuracy
(33.8\% vs 21.8\%) with a 28\% reduction in required network parameters for the
RBBB class. Multiple neural network models with varying parameter sizes,
including tiny (84k), small (150k), medium (478k), and large (1.25M) models,
are developed to achieve high accuracy \textit{across all classes}, a more
crucial and challenging goal than overall classification accuracy.",2024-05-24,"Reza Nikandish, Jiayu He, Benyamin Haghi",http://arxiv.org/pdf/2405.15312v2,cs.LG
Spectraformer: A Unified Random Feature Framework for Transformer,"Linearization of attention using various kernel approximation and kernel
learning techniques has shown promise. Past methods use a subset of
combinations of component functions and weight matrices within the random
features paradigm. We identify the need for a systematic comparison of
different combinations of weight matrices and component functions for attention
learning in Transformer. In this work, we introduce Spectraformer, a unified
framework for approximating and learning the kernel function in linearized
attention of the Transformer. We experiment with broad classes of component
functions and weight matrices for three textual tasks in the LRA benchmark. Our
empirical findings indicate that different kernels are good at different tasks
and that kernel choice is fundamental to performant models. Our code is
available at: https://github.com/dukenguyenxyz/spectraformer .",2024-05-24,"Duke Nguyen, Aditya Joshi, Flora Salim",http://arxiv.org/pdf/2405.15310v3,cs.LG
Unlearning Concepts in Diffusion Model via Concept Domain Correction and Concept Preserving Gradient,"Text-to-image diffusion models have achieved remarkable success in generating
photorealistic images. However, the inclusion of sensitive information during
pre-training poses significant risks. Machine Unlearning (MU) offers a
promising solution to eliminate sensitive concepts from these models. Despite
its potential, existing MU methods face two main challenges: 1) limited
generalization, where concept erasure is effective only within the unlearned
set, failing to prevent sensitive concept generation from out-of-set prompts;
and 2) utility degradation, where removing target concepts significantly
impacts the model's overall performance. To address these issues, we propose a
novel concept domain correction framework named \textbf{DoCo} (\textbf{Do}main
\textbf{Co}rrection). By aligning the output domains of sensitive and anchor
concepts through adversarial training, our approach ensures comprehensive
unlearning of target concepts. Additionally, we introduce a concept-preserving
gradient surgery technique that mitigates conflicting gradient components,
thereby preserving the model's utility while unlearning specific concepts.
Extensive experiments across various instances, styles, and offensive concepts
demonstrate the effectiveness of our method in unlearning targeted concepts
with minimal impact on related concepts, outperforming previous approaches even
for out-of-distribution prompts.",2024-05-24,"Yongliang Wu, Shiji Zhou, Mingzhuo Yang, Lianzhe Wang, Heng Chang, Wenbo Zhu, Xinting Hu, Xiao Zhou, Xu Yang",http://arxiv.org/pdf/2405.15304v3,cs.LG
A Trajectory-Based Bayesian Approach to Multi-Objective Hyperparameter Optimization with Epoch-Aware Trade-Offs,"Training machine learning models inherently involves a resource-intensive and
noisy iterative learning procedure that allows epoch-wise monitoring of the
model performance. However, the insights gained from the iterative learning
procedure typically remain underutilized in multi-objective hyperparameter
optimization scenarios. Despite the limited research in this area, existing
methods commonly identify the trade-offs only at the end of model training,
overlooking the fact that trade-offs can emerge at earlier epochs in cases such
as overfitting. To bridge this gap, we propose an enhanced multi-objective
hyperparameter optimization problem that treats the number of training epochs
as a decision variable, rather than merely an auxiliary parameter, to account
for trade-offs at an earlier training stage. To solve this problem and
accommodate its iterative learning, we then present a trajectory-based
multi-objective Bayesian optimization algorithm characterized by two features:
1) a novel acquisition function that captures the improvement along the
predictive trajectory of model performances over epochs for any hyperparameter
setting and 2) a multi-objective early stopping mechanism that determines when
to terminate the training to maximize epoch efficiency. Experiments on
synthetic simulations and hyperparameter tuning benchmarks demonstrate that our
algorithm can effectively identify the desirable trade-offs while improving
tuning efficiency.",2024-05-24,"Wenyu Wang, Zheyi Fan, Szu Hui Ng",http://arxiv.org/pdf/2405.15303v2,cs.LG
Privacy-preserving recommender system using the data collaboration analysis for distributed datasets,"In order to provide high-quality recommendations for users, it is desirable
to share and integrate multiple datasets held by different parties. However,
when sharing such distributed datasets, we need to protect personal and
confidential information contained in the datasets. To this end, we establish a
framework for privacy-preserving recommender systems using the data
collaboration analysis of distributed datasets. Numerical experiments with two
public rating datasets demonstrate that our privacy-preserving method for
rating prediction can improve the prediction accuracy for distributed datasets.
This study opens up new possibilities for privacy-preserving techniques in
recommender systems.",2024-05-24,"Tomoya Yanagi, Shunnosuke Ikeda, Noriyoshi Sukegawa, Yuichi Takano",http://arxiv.org/pdf/2406.01603v1,cs.LG
The Buffer Mechanism for Multi-Step Information Reasoning in Language Models,"Large language models have consistently struggled with complex reasoning
tasks, such as mathematical problem-solving. Investigating the internal
reasoning mechanisms of these models can help us design better model
architectures and training strategies, ultimately enhancing their reasoning
capability. In this study, we constructed a symbolic dataset to investigate the
mechanisms by which Transformer models employ vertical thinking strategy based
on their inherent structure and horizontal thinking strategy based on Chain of
Thought to achieve multi-step reasoning. We introduced the concept of buffer
mechanism: the model stores various information in distinct buffers and
selectively extracts them through the query-key matrix. We proposed a random
matrix-based algorithm to enhance the model's reasoning ability, resulting in a
75% reduction in the training time required for the GPT-2 model to achieve
generalization capability on the PrOntoQA dataset. These findings provide new
insights into understanding the mechanisms of large language models.",2024-05-24,"Zhiwei Wang, Yunji Wang, Zhongwang Zhang, Zhangchen Zhou, Hui Jin, Tianyang Hu, Jiacheng Sun, Zhenguo Li, Yaoyu Zhang, Zhi-Qin John Xu",http://arxiv.org/pdf/2405.15302v2,cs.LG
Rankability-enhanced Revenue Uplift Modeling Framework for Online Marketing,"Uplift modeling has been widely employed in online marketing by predicting
the response difference between the treatment and control groups, so as to
identify the sensitive individuals toward interventions like coupons or
discounts. Compared with traditional \textit{conversion uplift modeling},
\textit{revenue uplift modeling} exhibits higher potential due to its direct
connection with the corporate income. However, previous works can hardly handle
the continuous long-tail response distribution in revenue uplift modeling.
Moreover, they have neglected to optimize the uplift ranking among different
individuals, which is actually the core of uplift modeling. To address such
issues, in this paper, we first utilize the zero-inflated lognormal (ZILN) loss
to regress the responses and customize the corresponding modeling network,
which can be adapted to different existing uplift models. Then, we study the
ranking-related uplift modeling error from the theoretical perspective and
propose two tighter error bounds as the additional loss terms to the
conventional response regression loss. Finally, we directly model the uplift
ranking error for the entire population with a listwise uplift ranking loss.
The experiment results on offline public and industrial datasets validate the
effectiveness of our method for revenue uplift modeling. Furthermore, we
conduct large-scale experiments on a prominent online fintech marketing
platform, Tencent FiT, which further demonstrates the superiority of our method
in real-world applications.",2024-05-24,"Bowei He, Yunpeng Weng, Xing Tang, Ziqiang Cui, Zexu Sun, Liang Chen, Xiuqiang He, Chen Ma",http://arxiv.org/pdf/2405.15301v2,cs.LG
Semi-Supervised Learning guided by the Generalized Bayes Rule under Soft Revision,"We provide a theoretical and computational investigation of the Gamma-Maximin
method with soft revision, which was recently proposed as a robust criterion
for pseudo-label selection (PLS) in semi-supervised learning. Opposed to
traditional methods for PLS we use credal sets of priors (""generalized Bayes"")
to represent the epistemic modeling uncertainty. These latter are then updated
by the Gamma-Maximin method with soft revision. We eventually select
pseudo-labeled data that are most likely in light of the least favorable
distribution from the so updated credal set. We formalize the task of finding
optimal pseudo-labeled data w.r.t. the Gamma-Maximin method with soft revision
as an optimization problem. A concrete implementation for the class of logistic
models then allows us to compare the predictive power of the method with
competing approaches. It is observed that the Gamma-Maximin method with soft
revision can achieve very promising results, especially when the proportion of
labeled data is low.",2024-05-24,"Stefan Dietrich, Julian Rodemann, Christoph Jansen",http://arxiv.org/pdf/2405.15294v2,cs.LG
Towards a Probabilistic Fusion Approach for Robust Battery Prognostics,"Batteries are a key enabling technology for the decarbonization of transport
and energy sectors. The safe and reliable operation of batteries is crucial for
battery-powered systems. In this direction, the development of accurate and
robust battery state-of-health prognostics models can unlock the potential of
autonomous systems for complex, remote and reliable operations. The combination
of Neural Networks, Bayesian modelling concepts and ensemble learning
strategies, form a valuable prognostics framework to combine uncertainty in a
robust and accurate manner. Accordingly, this paper introduces a Bayesian
ensemble learning approach to predict the capacity depletion of lithium-ion
batteries. The approach accurately predicts the capacity fade and quantifies
the uncertainty associated with battery design and degradation processes. The
proposed Bayesian ensemble methodology employs a stacking technique,
integrating multiple Bayesian neural networks (BNNs) as base learners, which
have been trained on data diversity. The proposed method has been validated
using a battery aging dataset collected by the NASA Ames Prognostics Center of
Excellence. Obtained results demonstrate the improved accuracy and robustness
of the proposed probabilistic fusion approach with respect to (i) a single BNN
model and (ii) a classical stacking strategy based on different BNNs.",2024-05-24,"Jokin Alcibar, Jose I. Aizpurua, Ekhi Zugasti",http://arxiv.org/pdf/2405.15292v1,cs.LG
Minimizing UCB: a Better Local Search Strategy in Local Bayesian Optimization,"Local Bayesian optimization is a promising practical approach to solve the
high dimensional black-box function optimization problem. Among them is the
approximated gradient class of methods, which implements a strategy similar to
gradient descent. These methods have achieved good experimental results and
theoretical guarantees. However, given the distributional properties of the
Gaussian processes applied on these methods, there may be potential to further
exploit the information of the Gaussian processes to facilitate the BO search.
In this work, we develop the relationship between the steps of the gradient
descent method and one that minimizes the Upper Confidence Bound (UCB), and
show that the latter can be a better strategy than direct gradient descent when
a Gaussian process is applied as a surrogate. Through this insight, we propose
a new local Bayesian optimization algorithm, MinUCB, which replaces the
gradient descent step with minimizing UCB in GIBO. We further show that MinUCB
maintains a similar convergence rate with GIBO. We then improve the acquisition
function of MinUCB further through a look ahead strategy, and obtain a more
efficient algorithm LA-MinUCB. We apply our algorithms on different synthetic
and real-world functions, and the results show the effectiveness of our method.
Our algorithms also illustrate improvements on local search strategies from an
upper bound perspective in Bayesian optimization, and provides a new direction
for future algorithm design.",2024-05-24,"Zheyi Fan, Wenyu Wang, Szu Hui Ng, Qingpei Hu",http://arxiv.org/pdf/2405.15285v1,cs.LG
Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation,"Parameter-Efficient Fine-Tuning (PEFT) has become the standard for
customising Foundation Models (FMs) to user-specific downstream tasks. However,
typical PEFT methods require storing multiple task-specific adapters, creating
scalability issues as these adapters must be housed and run at the FM server.
Traditional prompt tuning offers a potential solution by customising them
through task-specific input prefixes, but it under-performs compared to other
PEFT methods like LoRA. To address this gap, we propose Low-Rank Prompt
Adaptation (LoPA), a prompt-tuning-based approach that performs on par with
state-of-the-art PEFT methods and full fine-tuning while being more
parameter-efficient and not requiring a server-based adapter. LoPA generates
soft prompts by balancing between sharing task-specific information across
instances and customization for each instance. It uses a low-rank decomposition
of the soft-prompt component encoded for each instance to achieve parameter
efficiency. We provide a comprehensive evaluation on multiple natural language
understanding and code generation and understanding tasks across a wide range
of foundation models with varying sizes.",2024-05-24,"Abhinav Jain, Swarat Chaudhuri, Thomas Reps, Chris Jermaine",http://arxiv.org/pdf/2405.15282v2,cs.LG
DFGNN: Dual-frequency Graph Neural Network for Sign-aware Feedback,"The graph-based recommendation has achieved great success in recent years.
However, most existing graph-based recommendations focus on capturing user
preference based on positive edges/feedback, while ignoring negative
edges/feedback (e.g., dislike, low rating) that widely exist in real-world
recommender systems. How to utilize negative feedback in graph-based
recommendations still remains underexplored. In this study, we first conducted
a comprehensive experimental analysis and found that (1) existing graph neural
networks are not well-suited for modeling negative feedback, which acts as a
high-frequency signal in a user-item graph. (2) The graph-based recommendation
suffers from the representation degeneration problem. Based on the two
observations, we propose a novel model that models positive and negative
feedback from a frequency filter perspective called Dual-frequency Graph Neural
Network for Sign-aware Recommendation (DFGNN). Specifically, in DFGNN, the
designed dual-frequency graph filter (DGF) captures both low-frequency and
high-frequency signals that contain positive and negative feedback.
Furthermore, the proposed signed graph regularization is applied to maintain
the user/item embedding uniform in the embedding space to alleviate the
representation degeneration problem. Additionally, we conduct extensive
experiments on real-world datasets and demonstrate the effectiveness of the
proposed model. Codes of our model will be released upon acceptance.",2024-05-24,"Yiqing Wu, Ruobing Xie, Zhao Zhang, Xu Zhang, Fuzhen Zhuang, Leyu Lin, Zhanhui Kang, Yongjun Xu",http://arxiv.org/pdf/2405.15280v1,cs.LG
Towards a General Time Series Anomaly Detector with Adaptive Bottlenecks and Dual Adversarial Decoders,"Time series anomaly detection plays a vital role in a wide range of
applications. Existing methods require training one specific model for each
dataset, which exhibits limited generalization capability across different
target datasets, hindering anomaly detection performance in various scenarios
with scarce training data. Aiming at this problem, we propose constructing a
general time series anomaly detection model, which is pre-trained on extensive
multi-domain datasets and can subsequently apply to a multitude of downstream
scenarios. The significant divergence of time series data across different
domains presents two primary challenges in building such a general model: (1)
meeting the diverse requirements of appropriate information bottlenecks
tailored to different datasets in one unified model, and (2) enabling
distinguishment between multiple normal and abnormal patterns, both are crucial
for effective anomaly detection in various target scenarios. To tackle these
two challenges, we propose a General time series anomaly Detector with Adaptive
Bottlenecks and Dual Adversarial Decoders (DADA), which enables flexible
selection of bottlenecks based on different data and explicitly enhances clear
differentiation between normal and abnormal series. We conduct extensive
experiments on nine target datasets from different domains. After pre-training
on multi-domain data, DADA, serving as a zero-shot anomaly detector for these
datasets, still achieves competitive or even superior results compared to those
models tailored to each specific dataset. The code is made available at
https://github.com/decisionintelligence/DADA.",2024-05-24,"Qichao Shentu, Beibu Li, Kai Zhao, Yang Shu, Zhongwen Rao, Lujia Pan, Bin Yang, Chenjuan Guo",http://arxiv.org/pdf/2405.15273v4,cs.LG
A rationale from frequency perspective for grokking in training neural network,"Grokking is the phenomenon where neural networks NNs initially fit the
training data and later generalize to the test data during training. In this
paper, we empirically provide a frequency perspective to explain the emergence
of this phenomenon in NNs. The core insight is that the networks initially
learn the less salient frequency components present in the test data. We
observe this phenomenon across both synthetic and real datasets, offering a
novel viewpoint for elucidating the grokking phenomenon by characterizing it
through the lens of frequency dynamics during the training process. Our
empirical frequency-based analysis sheds new light on understanding the
grokking phenomenon and its underlying mechanisms.",2024-05-24,"Zhangchen Zhou, Yaoyu Zhang, Zhi-Qin John Xu",http://arxiv.org/pdf/2405.17479v1,cs.LG
BDetCLIP: Multimodal Prompting Contrastive Test-Time Backdoor Detection,"Multimodal contrastive learning methods (e.g., CLIP) have shown impressive
zero-shot classification performance due to their strong ability to joint
representation learning for visual and textual modalities. However, recent
research revealed that multimodal contrastive learning on poisoned pre-training
data with a small proportion of maliciously backdoored data can induce
backdoored CLIP that could be attacked by inserted triggers in downstream tasks
with a high success rate. To defend against backdoor attacks on CLIP, existing
defense methods focus on either the pre-training stage or the fine-tuning
stage, which would unfortunately cause high computational costs due to numerous
parameter updates. In this paper, we provide the first attempt at a
computationally efficient backdoor detection method to defend against
backdoored CLIP in the inference stage. We empirically find that the visual
representations of backdoored images are insensitive to both benign and
malignant changes in class description texts. Motivated by this observation, we
propose BDetCLIP, a novel test-time backdoor detection method based on
contrastive prompting. Specifically, we first prompt the language model (e.g.,
GPT-4) to produce class-related description texts (benign) and class-perturbed
random texts (malignant) by specially designed instructions. Then, the
distribution difference in cosine similarity between images and the two types
of class description texts can be used as the criterion to detect backdoor
samples. Extensive experiments validate that our proposed BDetCLIP is superior
to state-of-the-art backdoor detection methods, in terms of both effectiveness
and efficiency.",2024-05-24,"Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng",http://arxiv.org/pdf/2405.15269v2,cs.LG
ParamReL: Learning Parameter Space Representation via Progressively Encoding Bayesian Flow Networks,"The recently proposed Bayesian Flow Networks~(BFNs) show great potential in
modeling parameter spaces, offering a unified strategy for handling continuous,
discretized, and discrete data. However, BFNs cannot learn high-level semantic
representation from the parameter space since {common encoders, which encode
data into one static representation, cannot capture semantic changes in
parameters.} This motivates a new direction: learning semantic representations
hidden in the parameter spaces to characterize mixed-typed noisy data.
{Accordingly, we propose a representation learning framework named ParamReL,
which operates in the parameter space to obtain parameter-wise latent semantics
that exhibit progressive structures. Specifically, ParamReL proposes a
\emph{self-}encoder to learn latent semantics directly from parameters, rather
than from observations. The encoder is then integrated into BFNs, enabling
representation learning with various formats of observations. Mutual
information terms further promote the disentanglement of latent semantics and
capture meaningful semantics simultaneously.} We illustrate {conditional
generation and reconstruction} in ParamReL via expanding BFNs, and extensive
{quantitative} experimental results demonstrate the {superior effectiveness} of
ParamReL in learning parameter representation.",2024-05-24,"Zhangkai Wu, Xuhui Fan, Jin Li, Zhilin Zhao, Hui Chen, Longbing Cao",http://arxiv.org/pdf/2405.15268v3,cs.LG
FTMixer: Frequency and Time Domain Representations Fusion for Time Series Modeling,"Time series data can be represented in both the time and frequency domains,
with the time domain emphasizing local dependencies and the frequency domain
highlighting global dependencies. To harness the strengths of both domains in
capturing local and global dependencies, we propose the Frequency and Time
Domain Mixer (FTMixer). To exploit the global characteristics of the frequency
domain, we introduce the Frequency Channel Convolution (FCC) module, designed
to capture global inter-series dependencies. Inspired by the windowing concept
in frequency domain transformations, we present the Windowing Frequency
Convolution (WFC) module to capture local dependencies. The WFC module first
applies frequency transformation within each window, followed by convolution
across windows. Furthermore, to better capture these local dependencies, we
employ channel-independent scheme to mix the time domain and frequency domain
patches. Notably, FTMixer employs the Discrete Cosine Transformation (DCT) with
real numbers instead of the complex-number-based Discrete Fourier
Transformation (DFT), enabling direct utilization of modern deep learning
operators in the frequency domain. Extensive experimental results across seven
real-world long-term time series datasets demonstrate the superiority of
FTMixer, in terms of both forecasting performance and computational efficiency.",2024-05-24,"Zhengnan Li, Yunxiao Qin, Xilong Cheng, Yuting Tan",http://arxiv.org/pdf/2405.15256v2,cs.LG
Novel Kernel Models and Exact Representor Theory for Neural Networks Beyond the Over-Parameterized Regime,"This paper presents two models of neural-networks and their training
applicable to neural networks of arbitrary width, depth and topology, assuming
only finite-energy neural activations; and a novel representor theory for
neural networks in terms of a matrix-valued kernel. The first model is exact
(un-approximated) and global, casting the neural network as an elements in a
reproducing kernel Banach space (RKBS); we use this model to provide tight
bounds on Rademacher complexity. The second model is exact and local, casting
the change in neural network function resulting from a bounded change in
weights and biases (ie. a training step) in reproducing kernel Hilbert space
(RKHS) in terms of a local-intrinsic neural kernel (LiNK). This local model
provides insight into model adaptation through tight bounds on Rademacher
complexity of network adaptation. We also prove that the neural tangent kernel
(NTK) is a first-order approximation of the LiNK kernel. Finally, and noting
that the LiNK does not provide a representor theory for technical reasons, we
present an exact novel representor theory for layer-wise neural network
training with unregularized gradient descent in terms of a local-extrinsic
neural kernel (LeNK). This representor theory gives insight into the role of
higher-order statistics in neural network training and the effect of kernel
evolution in neural-network kernel models. Throughout the paper (a) feedforward
ReLU networks and (b) residual networks (ResNet) are used as illustrative
examples.",2024-05-24,"Alistair Shilton, Sunil Gupta, Santu Rana, Svetha Venkatesh",http://arxiv.org/pdf/2405.15254v1,cs.LG
Accelerating 3D Molecule Generation via Jointly Geometric Optimal Transport,"This paper proposes a new 3D molecule generation framework, called GOAT, for
fast and effective 3D molecule generation based on the flow-matching optimal
transport objective. Specifically, we formulate a geometric transport formula
for measuring the cost of mapping multi-modal features (e.g., continuous atom
coordinates and categorical atom types) between a base distribution and a
target data distribution. Our formula is solved within a joint, equivariant,
and smooth representation space. This is achieved by transforming the
multi-modal features into a continuous latent space with equivariant networks.
In addition, we find that identifying optimal distributional coupling is
necessary for fast and effective transport between any two distributions. We
further propose a mechanism for estimating and purifying optimal coupling to
train the flow model with optimal transport. By doing so, GOAT can turn
arbitrary distribution couplings into new deterministic couplings, leading to
an estimated optimal transport plan for fast 3D molecule generation. The
purification filters out the subpar molecules to ensure the ultimate generation
quality. We theoretically and empirically prove that the proposed optimal
coupling estimation and purification yield transport plan with non-increasing
cost. Finally, extensive experiments show that GOAT enjoys the efficiency of
solving geometric optimal transport, leading to a double speedup compared to
the sub-optimal method while achieving the best generation quality regarding
validity, uniqueness, and novelty. The code is available at
https://github.com/WanyuGroup/ICLR2025-GOAT.",2024-05-24,"Haokai Hong, Wanyu Lin, Kay Chen Tan",http://arxiv.org/pdf/2405.15252v2,cs.LG
Learning to optimize: A tutorial for continuous and mixed-integer optimization,"Learning to Optimize (L2O) stands at the intersection of traditional
optimization and machine learning, utilizing the capabilities of machine
learning to enhance conventional optimization techniques. As real-world
optimization problems frequently share common structures, L2O provides a tool
to exploit these structures for better or faster solutions. This tutorial dives
deep into L2O techniques, introducing how to accelerate optimization
algorithms, promptly estimate the solutions, or even reshape the optimization
problem itself, making it more adaptive to real-world applications. By
considering the prerequisites for successful applications of L2O and the
structure of the optimization problems at hand, this tutorial provides a
comprehensive guide for practitioners and researchers alike.",2024-05-24,"Xiaohan Chen, Jialin Liu, Wotao Yin",http://arxiv.org/pdf/2405.15251v1,cs.LG
Learning Antenna Pointing Correction in Operations: Efficient Calibration of a Black Box,"We propose an efficient offline pointing calibration method for operational
antenna systems which does not require any downtime. Our approach minimizes the
calibration effort and exploits technical signal information which is typically
used for monitoring and control purposes in ground station operations. Using a
standard antenna interface and data from an operational satellite contact, we
come up with a robust strategy for training data set generation. On top of
this, we learn the parameters of a suitable coordinate transform by means of
linear regression. In our experiments, we show the usefulness of the method in
a real-world setup.",2024-05-24,Leif Bergerhoff,http://arxiv.org/pdf/2405.15247v2,cs.LG
Cooperative Backdoor Attack in Decentralized Reinforcement Learning with Theoretical Guarantee,"The safety of decentralized reinforcement learning (RL) is a challenging
problem since malicious agents can share their poisoned policies with benign
agents. The paper investigates a cooperative backdoor attack in a decentralized
reinforcement learning scenario. Differing from the existing methods that hide
a whole backdoor attack behind their shared policies, our method decomposes the
backdoor behavior into multiple components according to the state space of RL.
Each malicious agent hides one component in its policy and shares its policy
with the benign agents. When a benign agent learns all the poisoned policies,
the backdoor attack is assembled in its policy. The theoretical proof is given
to show that our cooperative method can successfully inject the backdoor into
the RL policies of benign agents. Compared with the existing backdoor attacks,
our cooperative method is more covert since the policy from each attacker only
contains a component of the backdoor attack and is harder to detect. Extensive
simulations are conducted based on Atari environments to demonstrate the
efficiency and covertness of our method. To the best of our knowledge, this is
the first paper presenting a provable cooperative backdoor attack in
decentralized reinforcement learning.",2024-05-24,"Mengtong Gao, Yifei Zou, Zuyuan Zhang, Xiuzhen Cheng, Dongxiao Yu",http://arxiv.org/pdf/2405.15245v1,cs.LG
Adversarial Attacks on Hidden Tasks in Multi-Task Learning,"Deep learning models are susceptible to adversarial attacks, where slight
perturbations to input data lead to misclassification. Adversarial attacks
become increasingly effective with access to information about the targeted
classifier. In the context of multi-task learning, where a single model learns
multiple tasks simultaneously, attackers may aim to exploit vulnerabilities in
specific tasks with limited information. This paper investigates the
feasibility of attacking hidden tasks within multi-task classifiers, where
model access regarding the hidden target task and labeled data for the hidden
target task are not available, but model access regarding the non-target tasks
is available. We propose a novel adversarial attack method that leverages
knowledge from non-target tasks and the shared backbone network of the
multi-task model to force the model to forget knowledge related to the target
task. Experimental results on CelebA and DeepFashion datasets demonstrate the
effectiveness of our method in degrading the accuracy of hidden tasks while
preserving the performance of visible tasks, contributing to the understanding
of adversarial vulnerabilities in multi-task classifiers.",2024-05-24,"Yu Zhe, Rei Nagaike, Daiki Nishiyama, Kazuto Fukuchi, Jun Sakuma",http://arxiv.org/pdf/2405.15244v2,cs.LG
Embedding-Aligned Language Models,"We propose a novel approach for training large language models (LLMs) to
adhere to objectives defined within a latent embedding space. Our method
leverages reinforcement learning (RL), treating a pre-trained LLM as an
environment. Our embedding-aligned guided language (EAGLE) agent is trained to
iteratively steer the LLM's generation towards optimal regions of the latent
embedding space, w.r.t. some predefined criterion. We demonstrate the
effectiveness of the EAGLE agent using the MovieLens 25M and Amazon Review
datasets to surface content gaps that satisfy latent user demand. We also
demonstrate the benefit of using an optimal design of a state-dependent action
set to improve EAGLE's efficiency. Our work paves the way for controlled and
grounded text generation using LLMs, ensuring consistency with domain-specific
knowledge and data representations.",2024-05-24,"Guy Tennenholtz, Yinlam Chow, Chih-Wei Hsu, Lior Shani, Ethan Liang, Craig Boutilier",http://arxiv.org/pdf/2406.00024v2,cs.LG
"Towards Real-world Debiasing: Rethinking Evaluation, Challenge, and Solution","Spurious correlations in training data significantly hinder the
generalization capability of machine learning models when faced with
distribution shifts, leading to the proposition of numberous debiasing methods.
However, it remains to be asked: \textit{Do existing benchmarks for debiasing
really represent biases in the real world?} Recent works attempt to address
such concerns by sampling from real-world data (instead of synthesizing)
according to some predefined biased distributions to ensure the realism of
individual samples. However, the realism of the biased distribution is more
critical yet challenging and underexplored due to the complexity of real-world
bias distributions. To tackle the problem, we propose a fine-grained framework
for analyzing biased distributions, based on which we empirically and
theoretically identify key characteristics of biased distributions in the real
world that are poorly represented by existing benchmarks. Towards applicable
debiasing in the real world, we further introduce two novel real-world-inspired
biases to bridge this gap and build a systematic evaluation framework for
real-world debiasing, RDBench\footnote{RDBench: Code to be released.
Preliminary version in supplementary material for anonimized review.}.
Furthermore, focusing on the practical setting of debiasing w/o bias label, we
find real-world biases pose a novel \textit{Sparse bias capturing} challenge to
the existing paradigm. We propose a simple yet effective approach named Debias
in Destruction (DiD), to address the challenge, whose effectiveness is
validated with extensive experiments on 8 datasets of various biased
distributions.",2024-05-24,"Peng Kuang, Zhibo Wang, Zhixuan Chu, Jingyi Wang, Kui Ren",http://arxiv.org/pdf/2405.15240v4,cs.LG
Modally Reduced Representation Learning of Multi-Lead ECG Signals through Simultaneous Alignment and Reconstruction,"Electrocardiogram (ECG) signals, profiling the electrical activities of the
heart, are used for a plethora of diagnostic applications. However, ECG systems
require multiple leads or channels of signals to capture the complete view of
the cardiac system, which limits their application in smartwatches and
wearables. In this work, we propose a modally reduced representation learning
method for ECG signals that is capable of generating channel-agnostic, unified
representations for ECG signals. Through joint optimization of reconstruction
and alignment, we ensure that the embeddings of the different channels contain
an amalgamation of the overall information across channels while also retaining
their specific information. On an independent test dataset, we generated highly
correlated channel embeddings from different ECG channels, leading to a
moderate approximation of the 12-lead signals from a single-channel embedding.
Our generated embeddings can work as competent features for ECG signals for
downstream tasks.",2024-05-24,"Nabil Ibtehaz, Masood Mortazavi",http://arxiv.org/pdf/2405.19359v1,cs.LG
ROSE: Register Assisted General Time Series Forecasting with Decomposed Frequency Learning,"With the increasing collection of time series data from various domains,
there arises a strong demand for general time series forecasting models
pre-trained on a large number of time-series datasets to support a variety of
downstream prediction tasks. Enabling general time series forecasting faces two
challenges: how to obtain unified representations from multi-domian time series
data, and how to capture domain-specific features from time series data across
various domains for adaptive transfer in downstream tasks. To address these
challenges, we propose a Register Assisted General Time Series Forecasting
Model with Decomposed Frequency Learning (ROSE), a novel pre-trained model for
time series forecasting. ROSE employs Decomposed Frequency Learning for the
pre-training task, which decomposes coupled semantic and periodic information
in time series with frequency-based masking and reconstruction to obtain
unified representations across domains. We also equip ROSE with a Time Series
Register, which learns to generate a register codebook to capture
domain-specific representations during pre-training and enhances
domain-adaptive transfer by selecting related register tokens on downstream
tasks. After pre-training on large-scale time series data, ROSE achieves
state-of-the-art forecasting performance on 8 real-world benchmarks.
Remarkably, even in few-shot scenarios, it demonstrates competitive or superior
performance compared to existing methods trained with full data.",2024-05-24,"Yihang Wang, Yuying Qiu, Peng Chen, Kai Zhao, Yang Shu, Zhongwen Rao, Lujia Pan, Bin Yang, Chenjuan Guo",http://arxiv.org/pdf/2405.17478v2,cs.LG
Cardinality Estimation on Hyper-relational Knowledge Graphs,"Cardinality Estimation (CE) for query is to estimate the number of results
without execution, which is an effective index in query optimization. Recently,
CE for queries over knowlege graph (KGs) with triple facts has achieved great
success. To more precisely represent facts, current researchers propose
hyper-relational KGs (HKGs) to represent a triple fact with qualifiers
providing additional context to the fact. However, existing CE methods, such as
sampling and summary methods over KGs, perform unsatisfactorily on HKGs due to
the complexity of qualifiers. Learning-based CE methods do not utilize
qualifier information to learn query representation accurately, leading to poor
performance. Also, there is only one limited CE benchmark for HKG query, which
is not comprehensive and only covers limited patterns. The lack of querysets
over HKG also becomes a bottleneck to comprehensively investigate CE problems
on HKGs. In this work, we first construct diverse and unbiased hyper-relational
querysets over three popular HKGs for investigating CE. Besides, we also
propose a novel qualifier-aware graph neural network (GNN) model that
effectively incorporates qualifier information and adaptively combines outputs
from multiple GNN layers, to accurately predict the cardinality. Our
experiments demonstrate that our model outperforms all state-of-the-art CE
methods over three benchmarks on popular HKGs.",2024-05-24,"Fei Teng, Haoyang Li, Shimin Di, Lei Chen",http://arxiv.org/pdf/2405.15231v3,cs.LG
$i$REPO: $i$mplicit Reward Pairwise Difference based Empirical Preference Optimization,"While astonishingly capable, large Language Models (LLM) can sometimes
produce outputs that deviate from human expectations. Such deviations
necessitate an alignment phase to prevent disseminating untruthful, toxic, or
biased information. Traditional alignment methods based on reinforcement
learning often struggle with the identified instability, whereas preference
optimization methods are limited by their overfitting to pre-collected
hard-label datasets. In this paper, we propose a novel LLM alignment framework
named $i$REPO, which utilizes implicit Reward pairwise difference regression
for Empirical Preference Optimization. Particularly, $i$REPO employs
self-generated datasets labeled by empirical human (or AI annotator) preference
to iteratively refine the aligned policy through a novel regression-based loss
function. Furthermore, we introduce an innovative algorithm backed by
theoretical guarantees for achieving optimal results under ideal assumptions
and providing a practical performance-gap result without such assumptions.
Experimental results with Phi-2 and Mistral-7B demonstrate that $i$REPO
effectively achieves self-alignment using soft-label, self-generated responses
and the logit of empirical AI annotators. Furthermore, our approach surpasses
preference optimization baselines in evaluations using the Language Model
Evaluation Harness and Multi-turn benchmarks.",2024-05-24,"Long Tan Le, Han Shu, Tung-Anh Nguyen, Choong Seon Hong, Nguyen H. Tran",http://arxiv.org/pdf/2405.15230v2,cs.LG
Learning from True-False Labels via Multi-modal Prompt Retrieving,"Weakly supervised learning has recently achieved considerable success in
reducing annotation costs and label noise. Unfortunately, existing weakly
supervised learning methods are short of ability in generating reliable labels
via pre-trained vision-language models (VLMs). In this paper, we propose a
novel weakly supervised labeling setting, namely True-False Labels (TFLs) which
can achieve high accuracy when generated by VLMs. The TFL indicates whether an
instance belongs to the label, which is randomly and uniformly sampled from the
candidate label set. Specifically, we theoretically derive a risk-consistent
estimator to explore and utilize the conditional probability distribution
information of TFLs. Besides, we propose a convolutional-based Multi-modal
Prompt Retrieving (MRP) method to bridge the gap between the knowledge of VLMs
and target learning tasks. Experimental results demonstrate the effectiveness
of the proposed TFL setting and MRP learning method. The code to reproduce the
experiments is at https://github.com/Tranquilxu/TMP.",2024-05-24,"Zhongnian Li, Jinghao Xu, Peng Ying, Meng Wei, Tongfeng Sun, Xinzheng Xu",http://arxiv.org/pdf/2405.15228v1,cs.LG
iVideoGPT: Interactive VideoGPTs are Scalable World Models,"World models empower model-based agents to interactively explore, reason, and
plan within imagined environments for real-world decision-making. However, the
high demand for interactivity poses challenges in harnessing recent
advancements in video generative models for developing world models at scale.
This work introduces Interactive VideoGPT (iVideoGPT), a scalable
autoregressive transformer framework that integrates multimodal signals--visual
observations, actions, and rewards--into a sequence of tokens, facilitating an
interactive experience of agents via next-token prediction. iVideoGPT features
a novel compressive tokenization technique that efficiently discretizes
high-dimensional visual observations. Leveraging its scalable architecture, we
are able to pre-train iVideoGPT on millions of human and robotic manipulation
trajectories, establishing a versatile foundation that is adaptable to serve as
interactive world models for a wide range of downstream tasks. These include
action-conditioned video prediction, visual planning, and model-based
reinforcement learning, where iVideoGPT achieves competitive performance
compared with state-of-the-art methods. Our work advances the development of
interactive general world models, bridging the gap between generative video
models and practical model-based reinforcement learning applications. Code and
pre-trained models are available at https://thuml.github.io/iVideoGPT.",2024-05-24,"Jialong Wu, Shaofeng Yin, Ningya Feng, Xu He, Dong Li, Jianye Hao, Mingsheng Long",http://arxiv.org/pdf/2405.15223v3,cs.LG
AGS-GNN: Attribute-guided Sampling for Graph Neural Networks,"We propose AGS-GNN, a novel attribute-guided sampling algorithm for Graph
Neural Networks (GNNs) that exploits node features and connectivity structure
of a graph while simultaneously adapting for both homophily and heterophily in
graphs. (In homophilic graphs vertices of the same class are more likely to be
connected, and vertices of different classes tend to be linked in heterophilic
graphs.) While GNNs have been successfully applied to homophilic graphs, their
application to heterophilic graphs remains challenging. The best-performing
GNNs for heterophilic graphs do not fit the sampling paradigm, suffer high
computational costs, and are not inductive. We employ samplers based on
feature-similarity and feature-diversity to select subsets of neighbors for a
node, and adaptively capture information from homophilic and heterophilic
neighborhoods using dual channels. Currently, AGS-GNN is the only algorithm
that we know of that explicitly controls homophily in the sampled subgraph
through similar and diverse neighborhood samples. For diverse neighborhood
sampling, we employ submodularity, which was not used in this context prior to
our work. The sampling distribution is pre-computed and highly parallel,
achieving the desired scalability. Using an extensive dataset consisting of 35
small ($\le$ 100K nodes) and large (>100K nodes) homophilic and heterophilic
graphs, we demonstrate the superiority of AGS-GNN compare to the current
approaches in the literature. AGS-GNN achieves comparable test accuracy to the
best-performing heterophilic GNNs, even outperforming methods using the entire
graph for node classification. AGS-GNN also converges faster compared to
methods that sample neighborhoods randomly, and can be incorporated into
existing GNN models that employ node or graph sampling.",2024-05-24,"Siddhartha Shankar Das, S M Ferdous, Mahantesh M Halappanavar, Edoardo Serra, Alex Pothen",http://arxiv.org/pdf/2405.15218v1,cs.LG
Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition,"Language models (LMs) have long been used to improve results of automatic
speech recognition (ASR) systems, but they are unaware of the errors that ASR
systems make. Error correction models are designed to fix ASR errors, however,
they showed little improvement over traditional LMs mainly due to the lack of
supervised training data. In this paper, we present Denoising LM (DLM), which
is a $\textit{scaled}$ error correction model trained with vast amounts of
synthetic data, significantly exceeding prior attempts meanwhile achieving new
state-of-the-art ASR performance. We use text-to-speech (TTS) systems to
synthesize audio, which is fed into an ASR system to produce noisy hypotheses,
which are then paired with the original texts to train the DLM. DLM has several
$\textit{key ingredients}$: (i) up-scaled model and data; (ii) usage of
multi-speaker TTS systems; (iii) combination of multiple noise augmentation
strategies; and (iv) new decoding techniques. With a Transformer-CTC ASR, DLM
achieves 1.5% word error rate (WER) on $\textit{test-clean}$ and 3.3% WER on
$\textit{test-other}$ on Librispeech, which to our knowledge are the best
reported numbers in the setting where no external audio data are used and even
match self-supervised methods which use external audio data. Furthermore, a
single DLM is applicable to different ASRs, and greatly surpassing the
performance of conventional LM based beam-search rescoring. These results
indicate that properly investigated error correction models have the potential
to replace conventional LMs, holding the key to a new level of accuracy in ASR
systems.",2024-05-24,"Zijin Gu, Tatiana Likhomanenko, He Bai, Erik McDermott, Ronan Collobert, Navdeep Jaitly",http://arxiv.org/pdf/2405.15216v1,cs.LG
OLLIE: Imitation Learning from Offline Pretraining to Online Finetuning,"In this paper, we study offline-to-online Imitation Learning (IL) that
pretrains an imitation policy from static demonstration data, followed by fast
finetuning with minimal environmental interaction. We find the na\""ive
combination of existing offline IL and online IL methods tends to behave poorly
in this context, because the initial discriminator (often used in online IL)
operates randomly and discordantly against the policy initialization, leading
to misguided policy optimization and $\textit{unlearning}$ of pretraining
knowledge. To overcome this challenge, we propose a principled
offline-to-online IL method, named $\texttt{OLLIE}$, that simultaneously learns
a near-expert policy initialization along with an $\textit{aligned
discriminator initialization}$, which can be seamlessly integrated into online
IL, achieving smooth and fast finetuning. Empirically, $\texttt{OLLIE}$
consistently and significantly outperforms the baseline methods in
$\textbf{20}$ challenging tasks, from continuous control to vision-based
domains, in terms of performance, demonstration efficiency, and convergence
speed. This work may serve as a foundation for further exploration of
pretraining and finetuning in the context of IL.",2024-05-24,"Sheng Yue, Xingyuan Hua, Ju Ren, Sen Lin, Junshan Zhang, Yaoxue Zhang",http://arxiv.org/pdf/2405.17477v3,cs.LG
How to Leverage Diverse Demonstrations in Offline Imitation Learning,"Offline Imitation Learning (IL) with imperfect demonstrations has garnered
increasing attention owing to the scarcity of expert data in many real-world
domains. A fundamental problem in this scenario is how to extract positive
behaviors from noisy data. In general, current approaches to the problem select
data building on state-action similarity to given expert demonstrations,
neglecting precious information in (potentially abundant) $\textit{diverse}$
state-actions that deviate from expert ones. In this paper, we introduce a
simple yet effective data selection method that identifies positive behaviors
based on their resultant states -- a more informative criterion enabling
explicit utilization of dynamics information and effective extraction of both
expert and beneficial diverse behaviors. Further, we devise a lightweight
behavior cloning algorithm capable of leveraging the expert and selected data
correctly. In the experiments, we evaluate our method on a suite of complex and
high-dimensional offline IL benchmarks, including continuous-control and
vision-based tasks. The results demonstrate that our method achieves
state-of-the-art performance, outperforming existing methods on
$\textbf{20/21}$ benchmarks, typically by $\textbf{2-5x}$, while maintaining a
comparable runtime to Behavior Cloning ($\texttt{BC}$).",2024-05-24,"Sheng Yue, Jiani Liu, Xingyuan Hua, Ju Ren, Sen Lin, Junshan Zhang, Yaoxue Zhang",http://arxiv.org/pdf/2405.17476v3,cs.LG
How Culturally Aware are Vision-Language Models?,"An image is often considered worth a thousand words, and certain images can
tell rich and insightful stories. Can these stories be told via image
captioning? Images from folklore genres, such as mythology, folk dance,
cultural signs, and symbols, are vital to every culture. Our research compares
the performance of four popular vision-language models (GPT-4V, Gemini Pro
Vision, LLaVA, and OpenFlamingo) in identifying culturally specific information
in such images and creating accurate and culturally sensitive image captions.
We also propose a new evaluation metric, the Cultural Awareness Score (CAS),
which measures the degree of cultural awareness in image captions. We provide a
dataset MOSAIC-1.5k labeled with ground truth for images containing cultural
background and context and a labeled dataset with assigned Cultural Awareness
Scores that can be used with unseen data. Creating culturally appropriate image
captions is valuable for scientific research and can be beneficial for many
practical applications. We envision our work will promote a deeper integration
of cultural sensitivity in AI applications worldwide. By making the dataset and
Cultural Awareness Score available to the public, we aim to facilitate further
research in this area, encouraging the development of more culturally aware AI
systems that respect and celebrate global diversity.",2024-05-24,"Olena Burda-Lassen, Aman Chadha, Shashank Goswami, Vinija Jain",http://arxiv.org/pdf/2405.17475v2,cs.LG
Federated Offline Policy Optimization with Dual Regularization,"Federated Reinforcement Learning (FRL) has been deemed as a promising
solution for intelligent decision-making in the era of Artificial Internet of
Things. However, existing FRL approaches often entail repeated interactions
with the environment during local updating, which can be prohibitively
expensive or even infeasible in many real-world domains. To overcome this
challenge, this paper proposes a novel offline federated policy optimization
algorithm, named $\texttt{DRPO}$, which enables distributed agents to
collaboratively learn a decision policy only from private and static data
without further environmental interactions. $\texttt{DRPO}$ leverages dual
regularization, incorporating both the local behavioral policy and the global
aggregated policy, to judiciously cope with the intrinsic two-tier
distributional shifts in offline FRL. Theoretical analysis characterizes the
impact of the dual regularization on performance, demonstrating that by
achieving the right balance thereof, $\texttt{DRPO}$ can effectively counteract
distributional shifts and ensure strict policy improvement in each federative
learning round. Extensive experiments validate the significant performance
gains of $\texttt{DRPO}$ over baseline methods.",2024-05-24,"Sheng Yue, Zerui Qin, Xingyuan Hua, Yongheng Deng, Ju Ren",http://arxiv.org/pdf/2405.17474v2,cs.LG
Indexed Minimum Empirical Divergence-Based Algorithms for Linear Bandits,"The Indexed Minimum Empirical Divergence (IMED) algorithm is a highly
effective approach that offers a stronger theoretical guarantee of the
asymptotic optimality compared to the Kullback--Leibler Upper Confidence Bound
(KL-UCB) algorithm for the multi-armed bandit problem. Additionally, it has
been observed to empirically outperform UCB-based algorithms and Thompson
Sampling. Despite its effectiveness, the generalization of this algorithm to
contextual bandits with linear payoffs has remained elusive. In this paper, we
present novel linear versions of the IMED algorithm, which we call the family
of LinIMED algorithms. We demonstrate that LinIMED provides a
$\widetilde{O}(d\sqrt{T})$ upper regret bound where $d$ is the dimension of the
context and $T$ is the time horizon. Furthermore, extensive empirical studies
reveal that LinIMED and its variants outperform widely-used linear bandit
algorithms such as LinUCB and Linear Thompson Sampling in some regimes.",2024-05-24,"Jie Bian, Vincent Y. F. Tan",http://arxiv.org/pdf/2405.15200v1,cs.LG
Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning,"Reinforcement Learning (RL) suffers from sample inefficiency in sparse reward
domains, and the problem is further pronounced in case of stochastic
transitions. To improve the sample efficiency, reward shaping is a well-studied
approach to introduce intrinsic rewards that can help the RL agent converge to
an optimal policy faster. However, designing a useful reward shaping function
for all desirable states in the Markov Decision Process (MDP) is challenging,
even for domain experts. Given that Large Language Models (LLMs) have
demonstrated impressive performance across a magnitude of natural language
tasks, we aim to answer the following question: `Can we obtain heuristics using
LLMs for constructing a reward shaping function that can boost an RL agent's
sample efficiency?' To this end, we aim to leverage off-the-shelf LLMs to
generate a plan for an abstraction of the underlying MDP. We further use this
LLM-generated plan as a heuristic to construct the reward shaping signal for
the downstream RL agent. By characterizing the type of abstraction based on the
MDP horizon length, we analyze the quality of heuristics when generated using
an LLM, with and without a verifier in the loop. Our experiments across
multiple domains with varying horizon length and number of sub-goals from the
BabyAI environment suite, Household, Mario, and, Minecraft domain, show 1) the
advantages and limitations of querying LLMs with and without a verifier to
generate a reward shaping heuristic, and, 2) a significant improvement in the
sample efficiency of PPO, A2C, and Q-learning when guided by the LLM-generated
heuristics.",2024-05-24,"Siddhant Bhambri, Amrita Bhattacharjee, Durgesh Kalwar, Lin Guan, Huan Liu, Subbarao Kambhampati",http://arxiv.org/pdf/2405.15194v2,cs.LG
TrojanForge: Generating Adversarial Hardware Trojan Examples Using Reinforcement Learning,"The Hardware Trojan (HT) problem can be thought of as a continuous game
between attackers and defenders, each striving to outsmart the other by
leveraging any available means for an advantage. Machine Learning (ML) has
recently played a key role in advancing HT research. Various novel techniques,
such as Reinforcement Learning (RL) and Graph Neural Networks (GNNs), have
shown HT insertion and detection capabilities. HT insertion with ML techniques,
specifically, has seen a spike in research activity due to the shortcomings of
conventional HT benchmarks and the inherent human design bias that occurs when
we create them. This work continues this innovation by presenting a tool called
TrojanForge, capable of generating HT adversarial examples that defeat HT
detectors; demonstrating the capabilities of GAN-like adversarial tools for
automatic HT insertion. We introduce an RL environment where the RL insertion
agent interacts with HT detectors in an insertion-detection loop where the
agent collects rewards based on its success in bypassing HT detectors. Our
results show that this process helps inserted HTs evade various HT detectors,
achieving high attack success percentages. This tool provides insight into why
HT insertion fails in some instances and how we can leverage this knowledge in
defense.",2024-05-24,"Amin Sarihi, Peter Jamieson, Ahmad Patooghy, Abdel-Hameed A. Badawy",http://arxiv.org/pdf/2405.15184v3,cs.LG
Repeat-Aware Neighbor Sampling for Dynamic Graph Learning,"Dynamic graph learning equips the edges with time attributes and allows
multiple links between two nodes, which is a crucial technology for
understanding evolving data scenarios like traffic prediction and
recommendation systems. Existing works obtain the evolving patterns mainly
depending on the most recent neighbor sequences. However, we argue that whether
two nodes will have interaction with each other in the future is highly
correlated with the same interaction that happened in the past. Only
considering the recent neighbors overlooks the phenomenon of repeat behavior
and fails to accurately capture the temporal evolution of interactions. To fill
this gap, this paper presents RepeatMixer, which considers evolving patterns of
first and high-order repeat behavior in the neighbor sampling strategy and
temporal information learning. Firstly, we define the first-order repeat-aware
nodes of the source node as the destination nodes that have interacted
historically and extend this concept to high orders as nodes in the destination
node's high-order neighbors. Then, we extract neighbors of the source node that
interacted before the appearance of repeat-aware nodes with a slide window
strategy as its neighbor sequence. Next, we leverage both the first and
high-order neighbor sequences of source and destination nodes to learn temporal
patterns of interactions via an MLP-based encoder. Furthermore, considering the
varying temporal patterns on different orders, we introduce a time-aware
aggregation mechanism that adaptively aggregates the temporal representations
from different orders based on the significance of their interaction time
sequences. Experimental results demonstrate the superiority of RepeatMixer over
state-of-the-art models in link prediction tasks, underscoring the
effectiveness of the proposed repeat-aware neighbor sampling strategy.",2024-05-24,"Tao Zou, Yuhao Mao, Junchen Ye, Bowen Du",http://arxiv.org/pdf/2405.17473v2,cs.LG
FreezeAsGuard: Mitigating Illegal Adaptation of Diffusion Models via Selective Tensor Freezing,"Text-to-image diffusion models can be fine-tuned in custom domains to adapt
to specific user preferences, but such adaptability has also been utilized for
illegal purposes, such as forging public figures' portraits, duplicating
copyrighted artworks and generating explicit contents. Existing work focused on
detecting the illegally generated contents, but cannot prevent or mitigate
illegal adaptations of diffusion models. Other schemes of model unlearning and
reinitialization, similarly, cannot prevent users from relearning the knowledge
of illegal model adaptation with custom data. In this paper, we present
FreezeAsGuard, a new technique that addresses these limitations and enables
irreversible mitigation of illegal adaptations of diffusion models. Our
approach is that the model publisher selectively freezes tensors in pre-trained
diffusion models that are critical to illegal model adaptations, to mitigate
the fine-tuned model's representation power in illegal adaptations, but
minimize the impact on other legal adaptations. Experiment results in multiple
text-to-image application domains show that FreezeAsGuard provides 37% stronger
power in mitigating illegal model adaptations compared to competitive
baselines, while incurring less than 5% impact on legal model adaptations. The
source code is available at: https://github.com/pittisl/FreezeAsGuard.",2024-05-24,"Kai Huang, Haoming Wang, Wei Gao",http://arxiv.org/pdf/2405.17472v2,cs.LG
Momentum-Based Federated Reinforcement Learning with Interaction and Communication Efficiency,"Federated Reinforcement Learning (FRL) has garnered increasing attention
recently. However, due to the intrinsic spatio-temporal non-stationarity of
data distributions, the current approaches typically suffer from high
interaction and communication costs. In this paper, we introduce a new FRL
algorithm, named $\texttt{MFPO}$, that utilizes momentum, importance sampling,
and additional server-side adjustment to control the shift of stochastic policy
gradients and enhance the efficiency of data utilization. We prove that by
proper selection of momentum parameters and interaction frequency,
$\texttt{MFPO}$ can achieve $\tilde{\mathcal{O}}(H N^{-1}\epsilon^{-3/2})$ and
$\tilde{\mathcal{O}}(\epsilon^{-1})$ interaction and communication complexities
($N$ represents the number of agents), where the interaction complexity
achieves linear speedup with the number of agents, and the communication
complexity aligns the best achievable of existing first-order FL algorithms.
Extensive experiments corroborate the substantial performance gains of
$\texttt{MFPO}$ over existing methods on a suite of complex and
high-dimensional benchmarks.",2024-05-24,"Sheng Yue, Xingyuan Hua, Lili Chen, Ju Ren",http://arxiv.org/pdf/2405.17471v2,cs.LG
Diffusion Actor-Critic with Entropy Regulator,"Reinforcement learning (RL) has proven highly effective in addressing complex
decision-making and control tasks. However, in most traditional RL algorithms,
the policy is typically parameterized as a diagonal Gaussian distribution with
learned mean and variance, which constrains their capability to acquire complex
policies. In response to this problem, we propose an online RL algorithm termed
diffusion actor-critic with entropy regulator (DACER). This algorithm
conceptualizes the reverse process of the diffusion model as a novel policy
function and leverages the capability of the diffusion model to fit multimodal
distributions, thereby enhancing the representational capacity of the policy.
Since the distribution of the diffusion policy lacks an analytical expression,
its entropy cannot be determined analytically. To mitigate this, we propose a
method to estimate the entropy of the diffusion policy utilizing Gaussian
mixture model. Building on the estimated entropy, we can learn a parameter
$\alpha$ that modulates the degree of exploration and exploitation. Parameter
$\alpha$ will be employed to adaptively regulate the variance of the added
noise, which is applied to the action output by the diffusion model.
Experimental trials on MuJoCo benchmarks and a multimodal task demonstrate that
the DACER algorithm achieves state-of-the-art (SOTA) performance in most MuJoCo
control tasks while exhibiting a stronger representational capacity of the
diffusion policy.",2024-05-24,"Yinuo Wang, Likun Wang, Yuxuan Jiang, Wenjun Zou, Tong Liu, Xujie Song, Wenxuan Wang, Liming Xiao, Jiang Wu, Jingliang Duan, Shengbo Eben Li",http://arxiv.org/pdf/2405.15177v5,cs.LG
Athena: Efficient Block-Wise Post-Training Quantization for Large Language Models Using Second-Order Matrix Derivative Information,"Large Language Models (LLMs) have significantly advanced natural language
processing tasks such as machine translation, text generation, and sentiment
analysis. However, their large size, often consisting of billions of
parameters, poses challenges for storage, computation, and deployment,
particularly in resource-constrained environments like mobile devices and edge
computing platforms. Effective compression and quantization techniques are
crucial for addressing these issues, reducing memory footprint and
computational requirements without significantly compromising performance.
Traditional methods that uniformly map parameters to compressed spaces fail to
account for the uneven distribution of parameters, leading to substantial
accuracy loss. In this work, we propose Athena, a novel algorithm for efficient
block-wise post-training quantization of LLMs. Athena leverages Second-Order
Matrix Derivative Information to guide the quantization process using the
curvature information of the loss landscape. By grouping parameters by columns
or rows and iteratively optimizing the quantization process, Athena updates the
model parameters and Hessian matrix to achieve significant compression while
maintaining high accuracy. This makes Athena a practical solution for deploying
LLMs in various settings.",2024-05-24,"Yanshu Wang, Wenyang He, Tong Yang",http://arxiv.org/pdf/2405.17470v1,cs.LG
Learning the Distribution Map in Reverse Causal Performative Prediction,"In numerous predictive scenarios, the predictive model affects the sampling
distribution; for example, job applicants often meticulously craft their
resumes to navigate through a screening systems. Such shifts in distribution
are particularly prevalent in the realm of social computing, yet, the
strategies to learn these shifts from data remain remarkably limited. Inspired
by a microeconomic model that adeptly characterizes agents' behavior within
labor markets, we introduce a novel approach to learn the distribution shift.
Our method is predicated on a reverse causal model, wherein the predictive
model instigates a distribution shift exclusively through a finite set of
agents' actions. Within this framework, we employ a microfoundation model for
the agents' actions and develop a statistically justified methodology to learn
the distribution shift map, which we demonstrate to be effective in minimizing
the performative prediction risk.",2024-05-24,"Daniele Bracale, Subha Maity, Moulinath Banerjee, Yuekai Sun",http://arxiv.org/pdf/2405.15172v2,cs.LG
ProDAG: Projected Variational Inference for Directed Acyclic Graphs,"Directed acyclic graph (DAG) learning is a central task in structure
discovery and causal inference. Although the field has witnessed remarkable
advances over the past few years, it remains statistically and computationally
challenging to learn a single (point estimate) DAG from data, let alone provide
uncertainty quantification. We address the difficult task of quantifying graph
uncertainty by developing a Bayesian variational inference framework based on
novel, provably valid distributions that have support directly on the space of
sparse DAGs. These distributions, which we use to define our prior and
variational posterior, are induced by a projection operation that maps an
arbitrary continuous distribution onto the space of sparse weighted acyclic
adjacency matrices. While this projection is combinatorial, it can be solved
efficiently using recent continuous reformulations of acyclicity constraints.
We empirically demonstrate that our method, ProDAG, can outperform
state-of-the-art alternatives in both accuracy and uncertainty quantification.",2024-05-24,"Ryan Thompson, Edwin V. Bonilla, Robert Kohn",http://arxiv.org/pdf/2405.15167v5,cs.LG
A Dataset for Research on Water Sustainability,"Freshwater scarcity is a global problem that requires collective efforts
across all industry sectors. Nevertheless, a lack of access to operational
water footprint data bars many applications from exploring optimization
opportunities hidden within the temporal and spatial variations. To break this
barrier into research in water sustainability, we build a dataset for operation
direct water usage in the cooling systems and indirect water embedded in
electricity generation. Our dataset consists of the hourly water efficiency of
major U.S. cities and states from 2019 to 2023. We also offer cooling system
models that capture the impact of weather on water efficiency. We present a
preliminary analysis of our dataset and discuss three potential applications
that can benefit from it. Our dataset is publicly available at Open Science
Framework (OSF)",2024-05-24,"Pranjol Sen Gupta, Md Rajib Hossen, Pengfei Li, Shaolei Ren, Mohammad A. Islam",http://arxiv.org/pdf/2405.17469v1,cs.LG
"From Frege to chatGPT: Compositionality in language, cognition, and deep neural networks","Compositionality has long been considered a key explanatory property
underlying human intelligence: arbitrary concepts can be composed into novel
complex combinations, permitting the acquisition of an open ended, potentially
infinite expressive capacity from finite learning experiences. Influential
arguments have held that neural networks fail to explain this aspect of
behavior, leading many to dismiss them as viable models of human cognition.
Over the last decade, however, modern deep neural networks (DNNs), which share
the same fundamental design principles as their predecessors, have come to
dominate artificial intelligence, exhibiting the most advanced cognitive
behaviors ever demonstrated in machines. In particular, large language models
(LLMs), DNNs trained to predict the next word on a large corpus of text, have
proven capable of sophisticated behaviors such as writing syntactically complex
sentences without grammatical errors, producing cogent chains of reasoning, and
even writing original computer programs -- all behaviors thought to require
compositional processing. In this chapter, we survey recent empirical work from
machine learning for a broad audience in philosophy, cognitive science, and
neuroscience, situating recent breakthroughs within the broader context of
philosophical arguments about compositionality. In particular, our review
emphasizes two approaches to endowing neural networks with compositional
generalization capabilities: (1) architectural inductive biases, and (2)
metalearning, or learning to learn. We also present findings suggesting that
LLM pretraining can be understood as a kind of metalearning, and can thereby
equip DNNs with compositional generalization abilities in a similar way. We
conclude by discussing the implications that these findings may have for the
study of compositionality in human cognition and by suggesting avenues for
future research.",2024-05-24,"Jacob Russin, Sam Whitman McGrath, Danielle J. Williams, Lotem Elber-Dorozko",http://arxiv.org/pdf/2405.15164v1,cs.LG
ProtFAD: Introducing function-aware domains as implicit modality towards protein function prediction,"Protein function prediction is currently achieved by encoding its sequence or
structure, where the sequence-to-function transcendence and high-quality
structural data scarcity lead to obvious performance bottlenecks. Protein
domains are ""building blocks"" of proteins that are functionally independent,
and their combinations determine the diverse biological functions. However,
most existing studies have yet to thoroughly explore the intricate functional
information contained in the protein domains. To fill this gap, we propose a
synergistic integration approach for a function-aware domain representation,
and a domain-joint contrastive learning strategy to distinguish different
protein functions while aligning the modalities. Specifically, we align the
domain semantics with GO terms and text description to pre-train domain
embeddings. Furthermore, we partition proteins into multiple sub-views based on
continuous joint domains for contrastive training under the supervision of a
novel triplet InfoNCE loss. Our approach significantly and comprehensively
outperforms the state-of-the-art methods on various benchmarks, and clearly
differentiates proteins carrying distinct functions compared to the competitor.
Our implementation is available at
https://github.com/AI-HPC-Research-Team/ProtFAD.",2024-05-24,"Mingqing Wang, Zhiwei Nie, Yonghong He, Athanasios V. Vasilakos, Zhixiang Ren",http://arxiv.org/pdf/2405.15158v2,cs.LG
Spatio-temporal Value Semantics-based Abstraction for Dense Deep Reinforcement Learning,"Intelligent Cyber-Physical Systems (ICPS) represent a specialized form of
Cyber-Physical System (CPS) that incorporates intelligent components, notably
Convolutional Neural Networks (CNNs) and Deep Reinforcement Learning (DRL), to
undertake multifaceted tasks encompassing perception, decision-making, and
control. The utilization of DRL for decision-making facilitates dynamic
interaction with the environment, generating control actions aimed at
maximizing cumulative rewards. Nevertheless, the inherent uncertainty of the
operational environment and the intricate nature of ICPS necessitate
exploration within complex and dynamic state spaces during the learning phase.
DRL confronts challenges in terms of efficiency, generalization capabilities,
and data scarcity during decision-making process. In response to these
challenges, we propose an innovative abstract modeling approach grounded in
spatial-temporal value semantics, capturing the evolution in the distribution
of semantic value across time and space. A semantics-based abstraction is
introduced to construct an abstract Markov Decision Process (MDP) for the DRL
learning process. Furthermore, optimization techniques for abstraction are
delineated, aiming to refine the abstract model and mitigate semantic gaps
between abstract and concrete states. The efficacy of the abstract modeling is
assessed through the evaluation and analysis of the abstract MDP model using
PRISM. A series of experiments are conducted, involving diverse scenarios such
as lane-keeping, adaptive cruise control, and intersection crossroad
assistance, to demonstrate the effectiveness of our abstracting approach.",2024-05-24,"Jihui Nie, Dehui Du, Jiangnan Zhao",http://arxiv.org/pdf/2405.15829v1,cs.LG
Online Prompt Pricing based on Combinatorial Multi-Armed Bandit and Hierarchical Stackelberg Game,"Generation models have shown promising performance in various tasks, making
trading around machine learning models possible. In this paper, we aim at a
novel prompt trading scenario, prompt bundle trading (PBT) system, and propose
an online pricing mechanism. Based on the combinatorial multi-armed bandit
(CMAB) and three-stage hierarchical Stackelburg (HS) game, our pricing
mechanism considers the profits of the consumer, platform, and seller,
simultaneously achieving the profit satisfaction of these three participants.
We break down the pricing issue into two steps, namely unknown category
selection and incentive strategy optimization. The former step is to select a
set of categories with the highest qualities, and the latter is to derive the
optimal strategy for each participant based on the chosen categories. Unlike
the existing fixed pricing mode, the PBT pricing mechanism we propose is more
flexible and diverse, which is more in accord with the transaction needs of
real-world scenarios. We test our method on a simulated text-to-image dataset.
The experimental results demonstrate the effectiveness of our algorithm, which
provides a feasible price-setting standard for the prompt marketplaces.",2024-05-24,"Meiling Li, Hongrun Ren, Haixu Xiong, Zhenxing Qian, Xinpeng Zhang",http://arxiv.org/pdf/2405.15154v2,cs.LG
Enhancing Learning with Label Differential Privacy by Vector Approximation,"Label differential privacy (DP) is a framework that protects the privacy of
labels in training datasets, while the feature vectors are public. Existing
approaches protect the privacy of labels by flipping them randomly, and then
train a model to make the output approximate the privatized label. However, as
the number of classes $K$ increases, stronger randomization is needed, thus the
performances of these methods become significantly worse. In this paper, we
propose a vector approximation approach, which is easy to implement and
introduces little additional computational overhead. Instead of flipping each
label into a single scalar, our method converts each label into a random vector
with $K$ components, whose expectations reflect class conditional
probabilities. Intuitively, vector approximation retains more information than
scalar labels. A brief theoretical analysis shows that the performance of our
method only decays slightly with $K$. Finally, we conduct experiments on both
synthesized and real datasets, which validate our theoretical analysis as well
as the practical performance of our method.",2024-05-24,"Puning Zhao, Rongfei Fan, Huiwen Wu, Qingming Li, Jiafei Wu, Zhe Liu",http://arxiv.org/pdf/2405.15150v1,cs.LG
Deep Activity Model: A Generative Approach for Human Mobility Pattern Synthesis,"Human mobility plays a crucial role in transportation, urban planning, and
public health. Advances in deep learning and the availability of diverse
mobility data have transformed mobility modeling. However, existing deep
learning models often focus on spatio-temporal patterns and struggle to capture
the semantic interdependencies among activities, while also being limited by
specific data sources. These challenges reduce their realism and adaptability.
Traditional activity-based models (ABMs) face issues as well, relying on rigid
assumptions and requiring extensive data, making them costly and difficult to
adapt to new regions, especially those with limited conventional travel data.
To address these limitations, we develop a novel generative deep learning
approach for human mobility modeling and synthesis that incorporates both
activity patterns and location trajectories using open-source data. The model
can be fine-tuned with local data, allowing it to adapt to and accurately
represent mobility patterns across diverse regions. The model is evaluated on a
nationwide dataset of the United States, where it demonstrates superior
performance in generating activity-location chains that closely follow ground
truth distributions. Further tests using state- or city-specific datasets from
California, Washington, and Mexico City confirm its transferability. This
innovative approach offers substantial potential to advance mobility modeling
research, particularly in generating synthetic human mobility data. This can
provide urban planners and policymakers with enhanced tools for simulating
mobility in diverse regions and better informing decisions related to
transportation, urban development, and public health.",2024-05-24,"Xishun Liao, Qinhua Jiang, Brian Yueshuai He, Yifan Liu, Chenchen Kuai, Jiaqi Ma",http://arxiv.org/pdf/2405.17468v2,cs.LG
Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models,"Go-Explore is a powerful family of algorithms designed to solve
hard-exploration problems built on the principle of archiving discovered
states, and iteratively returning to and exploring from the most promising
states. This approach has led to superhuman performance across a wide variety
of challenging problems including Atari games and robotic control, but requires
manually designing heuristics to guide exploration (i.e., determine which
states to save and explore from, and what actions to consider next), which is
time-consuming and infeasible in general. To resolve this, we propose
Intelligent Go-Explore (IGE) which greatly extends the scope of the original
Go-Explore by replacing these handcrafted heuristics with the intelligence and
internalized human notions of interestingness captured by giant pretrained
foundation models (FMs). This provides IGE with a human-like ability to
instinctively identify how interesting or promising any new state is (e.g.,
discovering new objects, locations, or behaviors), even in complex environments
where heuristics are hard to define. Moreover, IGE offers the exciting
opportunity to recognize and capitalize on serendipitous discoveries -- states
encountered during exploration that are valuable in terms of exploration, yet
where what makes them interesting was not anticipated by the human user. We
evaluate our algorithm on a diverse range of language and vision-based tasks
that require search and exploration. Across these tasks, IGE strongly exceeds
classic reinforcement learning and graph search baselines, and also succeeds
where prior state-of-the-art FM agents like Reflexion completely fail. Overall,
Intelligent Go-Explore combines the tremendous strengths of FMs and the
powerful Go-Explore algorithm, opening up a new frontier of research into
creating more generally capable agents with impressive exploration
capabilities.",2024-05-24,"Cong Lu, Shengran Hu, Jeff Clune",http://arxiv.org/pdf/2405.15143v4,cs.LG
Better Membership Inference Privacy Measurement through Discrepancy,"Membership Inference Attacks have emerged as a dominant method for
empirically measuring privacy leakage from machine learning models. Here,
privacy is measured by the {\em{advantage}} or gap between a score or a
function computed on the training and the test data. A major barrier to the
practical deployment of these attacks is that they do not scale to large
well-generalized models -- either the advantage is relatively low, or the
attack involves training multiple models which is highly compute-intensive. In
this work, inspired by discrepancy theory, we propose a new empirical privacy
metric that is an upper bound on the advantage of a family of membership
inference attacks. We show that this metric does not involve training multiple
models, can be applied to large Imagenet classification models in-the-wild, and
has higher advantage than existing metrics on models trained with more recent
and sophisticated training recipes. Motivated by our empirical results, we also
propose new membership inference attacks tailored to these training losses.",2024-05-24,"Ruihan Wu, Pengrun Huang, Kamalika Chaudhuri",http://arxiv.org/pdf/2405.15140v1,cs.LG
Exploring the Evolution of Hidden Activations with Live-Update Visualization,"Monitoring the training of neural networks is essential for identifying
potential data anomalies, enabling timely interventions and conserving
significant computational resources. Apart from the commonly used metrics such
as losses and validation accuracies, the hidden representation could give more
insight into the model progression. To this end, we introduce SentryCam, an
automated, real-time visualization tool that reveals the progression of hidden
representations during training. Our results show that this visualization
offers a more comprehensive view of the learning dynamics compared to basic
metrics such as loss and accuracy over various datasets. Furthermore, we show
that SentryCam could facilitate detailed analysis such as task transfer and
catastrophic forgetting to a continual learning setting. The code is available
at https://github.com/xianglinyang/SentryCam.",2024-05-24,"Xianglin Yang, Jin Song Dong",http://arxiv.org/pdf/2405.15135v1,cs.LG
Beyond the noise: intrinsic dimension estimation with optimal neighbourhood identification,"The Intrinsic Dimension (ID) is a key concept in unsupervised learning and
feature selection, as it is a lower bound to the number of variables which are
necessary to describe a system. However, in almost any real-world dataset the
ID depends on the scale at which the data are analysed. Quite typically at a
small scale, the ID is very large, as the data are affected by measurement
errors. At large scale, the ID can also be erroneously large, due to the
curvature and the topology of the manifold containing the data. In this work,
we introduce an automatic protocol to select the sweet spot, namely the correct
range of scales in which the ID is meaningful and useful. This protocol is
based on imposing that for distances smaller than the correct scale the density
of the data is constant. In the presented framework, to estimate the density it
is necessary to know the ID, therefore, this condition is imposed
self-consistently. We derive theoretical guarantees and illustrate the
usefulness and robustness of this procedure by benchmarks on artificial and
real-world datasets.",2024-05-24,"Antonio Di Noia, Iuri Macocco, Aldo Glielmo, Alessandro Laio, Antonietta Mira",http://arxiv.org/pdf/2405.15132v2,cs.LG
OptLLM: Optimal Assignment of Queries to Large Language Models,"Large Language Models (LLMs) have garnered considerable attention owing to
their remarkable capabilities, leading to an increasing number of companies
offering LLMs as services. Different LLMs achieve different performance at
different costs. A challenge for users lies in choosing the LLMs that best fit
their needs, balancing cost and performance. In this paper, we propose a
framework for addressing the cost-effective query allocation problem for LLMs.
Given a set of input queries and candidate LLMs, our framework, named OptLLM,
provides users with a range of optimal solutions to choose from, aligning with
their budget constraints and performance preferences, including options for
maximizing accuracy and minimizing cost. OptLLM predicts the performance of
candidate LLMs on each query using a multi-label classification model with
uncertainty estimation and then iteratively generates a set of non-dominated
solutions by destructing and reconstructing the current solution. To evaluate
the effectiveness of OptLLM, we conduct extensive experiments on various types
of tasks, including text classification, question answering, sentiment
analysis, reasoning, and log parsing. Our experimental results demonstrate that
OptLLM substantially reduces costs by 2.40% to 49.18% while achieving the same
accuracy as the best LLM. Compared to other multi-objective optimization
algorithms, OptLLM improves accuracy by 2.94% to 69.05% at the same cost or
saves costs by 8.79% and 95.87% while maintaining the highest attainable
accuracy.",2024-05-24,"Yueyue Liu, Hongyu Zhang, Yuantian Miao, Van-Hoang Le, Zhiqiang Li",http://arxiv.org/pdf/2405.15130v1,cs.LG
Scaling Law for Time Series Forecasting,"Scaling law that rewards large datasets, complex models and enhanced data
granularity has been observed in various fields of deep learning. Yet, studies
on time series forecasting have cast doubt on scaling behaviors of deep
learning methods for time series forecasting: while more training data improves
performance, more capable models do not always outperform less capable models,
and longer input horizons may hurt performance for some models. We propose a
theory for scaling law for time series forecasting that can explain these
seemingly abnormal behaviors. We take into account the impact of dataset size
and model complexity, as well as time series data granularity, particularly
focusing on the look-back horizon, an aspect that has been unexplored in
previous theories. Furthermore, we empirically evaluate various models using a
diverse set of time series forecasting datasets, which (1) verifies the
validity of scaling law on dataset size and model complexity within the realm
of time series forecasting, and (2) validates our theoretical framework,
particularly regarding the influence of look back horizon. We hope our findings
may inspire new models targeting time series forecasting datasets of limited
size, as well as large foundational datasets and models for time series
forecasting in future work. Code for our experiments has been made public at
https://github.com/JingzheShi/ScalingLawForTimeSeriesForecasting.",2024-05-24,"Jingzhe Shi, Qinwei Ma, Huan Ma, Lei Li",http://arxiv.org/pdf/2405.15124v4,cs.LG
A Counterfactual Analysis of the Dishonest Casino,"The dishonest casino is a well-known hidden Markov model (HMM) used in
educational settings to introduce HMMs and graphical models. Here, a sequence
of die rolls is observed, with the casino switching between a fair and a loaded
die. Typically, the goal is to use the observed rolls to infer the pattern of
fair and loaded dice, leading to filtering, smoothing, and Viterbi algorithms.
This paper, however, explores how much of the winnings is attributable to the
casino's cheating, a counterfactual question beyond the scope of HMM
primitives. To address this, we introduce a structural causal model (SCM)
consistent with the HMM and show the expected winnings attributable to cheating
(EWAC) (which is only partially identifiable) can be bounded using linear
programs (LPs). Through numerical experiments, we compute these bounds and
develop intuition using benchmark SCMs based on independence, comonotonic, and
counter-monotonic copulas. We show that tighter bounds are obtained with a
time-homogeneity condition on the SCM, while looser bounds allow for an almost
explicit LP solution. Domain-specific knowledge such as pathwise monotonicity
or counterfactual stability can be incorporated via linear constraints. We also
show the time-average EWAC is fully identifiable in the limit as the number of
time periods goes to infinity. Our work contributes to bounding counterfactuals
in causal inference and is the first to develop LP bounds in a dynamic HMM
setting, benefiting educational contexts where counterfactual inference is
taught.",2024-05-24,"Martin Haugh, Raghav Singal",http://arxiv.org/pdf/2405.15120v2,cs.LG
Bayesian Optimization of Functions over Node Subsets in Graphs,"We address the problem of optimizing over functions defined on node subsets
in a graph. The optimization of such functions is often a non-trivial task
given their combinatorial, black-box and expensive-to-evaluate nature. Although
various algorithms have been introduced in the literature, most are either
task-specific or computationally inefficient and only utilize information about
the graph structure without considering the characteristics of the function. To
address these limitations, we utilize Bayesian Optimization (BO), a
sample-efficient black-box solver, and propose a novel framework for
combinatorial optimization on graphs. More specifically, we map each $k$-node
subset in the original graph to a node in a new combinatorial graph and adopt a
local modeling approach to efficiently traverse the latter graph by
progressively sampling its subgraphs using a recursive algorithm. Extensive
experiments under both synthetic and real-world setups demonstrate the
effectiveness of the proposed BO framework on various types of graphs and
optimization tasks, where its behavior is analyzed in detail with ablation
studies.",2024-05-24,"Huidong Liang, Xingchen Wan, Xiaowen Dong",http://arxiv.org/pdf/2405.15119v2,cs.LG
Quantifying the Gain in Weak-to-Strong Generalization,"Recent advances in large language models have shown capabilities that are
extraordinary and near-superhuman. These models operate with such complexity
that reliably evaluating and aligning them proves challenging for humans. This
leads to the natural question: can guidance from weak models (like humans)
adequately direct the capabilities of strong models? In a recent and somewhat
surprising work, Burns et al. (2023) empirically demonstrated that when strong
models (like GPT-4) are finetuned using labels generated by weak supervisors
(like GPT-2), the strong models outperform their weaker counterparts -- a
phenomenon they term weak-to-strong generalization.
  In this work, we present a theoretical framework for understanding
weak-to-strong generalization. Specifically, we show that the improvement in
performance achieved by strong models over their weaker counterparts is
quantified by the misfit error incurred by the strong model on labels generated
by the weaker model. Our theory reveals several curious algorithmic insights.
For instance, we can predict the amount by which the strong model will improve
over the weak model, and also choose among different weak models to train the
strong model, based on its misfit error. We validate our theoretical findings
through various empirical assessments.",2024-05-24,"Moses Charikar, Chirag Pabbaraju, Kirankumar Shiragur",http://arxiv.org/pdf/2405.15116v2,cs.LG
Towards Better Understanding of In-Context Learning Ability from In-Context Uncertainty Quantification,"Predicting simple function classes has been widely used as a testbed for
developing theory and understanding of the trained Transformer's in-context
learning (ICL) ability. In this paper, we revisit the training of Transformers
on linear regression tasks, and different from all the existing literature, we
consider a bi-objective prediction task of predicting both the conditional
expectation $\mathbb{E}[Y|X]$ and the conditional variance Var$(Y|X)$. This
additional uncertainty quantification objective provides a handle to (i) better
design out-of-distribution experiments to distinguish ICL from in-weight
learning (IWL) and (ii) make a better separation between the algorithms with
and without using the prior information of the training distribution.
Theoretically, we show that the trained Transformer reaches near Bayes-optimum,
suggesting the usage of the information of the training distribution. Our
method can be extended to other cases. Specifically, with the Transformer's
context window $S$, we prove a generalization bound of
$\tilde{\mathcal{O}}(\sqrt{\min\{S, T\}/(n T)})$ on $n$ tasks with sequences of
length $T$, providing sharper analysis compared to previous results of
$\tilde{\mathcal{O}}(\sqrt{1/n})$. Empirically, we illustrate that while the
trained Transformer behaves as the Bayes-optimal solution as a natural
consequence of supervised training in distribution, it does not necessarily
perform a Bayesian inference when facing task shifts, in contrast to the
\textit{equivalence} between these two proposed in many existing literature. We
also demonstrate the trained Transformer's ICL ability over covariates shift
and prompt-length shift and interpret them as a generalization over a meta
distribution.",2024-05-24,"Shang Liu, Zhongze Cai, Guanting Chen, Xiaocheng Li",http://arxiv.org/pdf/2405.15115v1,cs.LG
Is Algorithmic Stability Testable? A Unified Framework under Computational Constraints,"Algorithmic stability is a central notion in learning theory that quantifies
the sensitivity of an algorithm to small changes in the training data. If a
learning algorithm satisfies certain stability properties, this leads to many
important downstream implications, such as generalization, robustness, and
reliable predictive inference. Verifying that stability holds for a particular
algorithm is therefore an important and practical question. However, recent
results establish that testing the stability of a black-box algorithm is
impossible, given limited data from an unknown distribution, in settings where
the data lies in an uncountably infinite space (such as real-valued data). In
this work, we extend this question to examine a far broader range of settings,
where the data may lie in any space -- for example, categorical data. We
develop a unified framework for quantifying the hardness of testing algorithmic
stability, which establishes that across all settings, if the available data is
limited then exhaustive search is essentially the only universally valid
mechanism for certifying algorithmic stability. Since in practice, any test of
stability would naturally be subject to computational constraints, exhaustive
search is impossible and so this implies fundamental limits on our ability to
test the stability property for a black-box algorithm.",2024-05-23,"Yuetian Luo, Rina Foygel Barber",http://arxiv.org/pdf/2405.15107v2,cs.LG
Conformal Classification with Equalized Coverage for Adaptively Selected Groups,"This paper introduces a conformal inference method to evaluate uncertainty in
classification by generating prediction sets with valid coverage conditional on
adaptively chosen features. These features are carefully selected to reflect
potential model limitations or biases. This can be useful to find a practical
compromise between efficiency -- by providing informative predictions -- and
algorithmic fairness -- by ensuring equalized coverage for the most sensitive
groups. We demonstrate the validity and effectiveness of this method on
simulated and real data sets.",2024-05-23,"Yanfei Zhou, Matteo Sesia",http://arxiv.org/pdf/2405.15106v2,cs.LG
Certified Inventory Control of Critical Resources,"Inventory control is subject to service-level requirements, in which
sufficient stock levels must be maintained despite an unknown demand. We
propose a data-driven order policy that certifies any prescribed service level
under minimal assumptions on the unknown demand process. The policy achieves
this using any online learning method along with integral action. We further
propose an inference method that is valid in finite samples. The properties and
theoretical guarantees of the method are illustrated using both synthetic and
real-world data.",2024-05-23,"Ludvig Hult, Dave Zachariah, Petre Stoica",http://arxiv.org/pdf/2405.15105v1,cs.LG
The Rarity of Musical Audio Signals Within the Space of Possible Audio Generation,"A white noise signal can access any possible configuration of values, though
statistically over many samples tends to a uniform spectral distribution, and
is highly unlikely to produce intelligible sound. But how unlikely? The
probability that white noise generates a music-like signal over different
durations is analyzed, based on some necessary features observed in real music
audio signals such as mostly proximate movement and zero crossing rate. Given
the mathematical results, the rarity of music as a signal is considered
overall. The applicability of this study is not just to show that music has a
precious rarity value, but that examination of the size of music relative to
the overall size of audio signal space provides information to inform new
generations of algorithmic music system (which are now often founded on audio
signal generation directly, and may relate to white noise via such machine
learning processes as diffusion). Estimated upper bounds on the rarity of music
to the size of various physical and musical spaces are compared, to better
understand the magnitude of the results (pun intended). Underlying the research
are the questions `how much music is still out there?' and `how much music
could a machine learning process actually reach?'.",2024-05-23,Nick Collins,http://arxiv.org/pdf/2405.15103v1,cs.LG
Magnetic Resonance Image Processing Transformer for General Accelerated Image Reconstruction,"Recent advancements in deep learning have enabled the development of
generalizable models that achieve state-of-the-art performance across various
imaging tasks. Vision Transformer (ViT)-based architectures, in particular,
have demonstrated strong feature extraction capabilities when pre-trained on
large-scale datasets. In this work, we introduce the Magnetic Resonance Image
Processing Transformer (MR-IPT), a ViT-based framework designed to enhance the
generalizability and robustness of accelerated MRI reconstruction. Unlike
conventional deep learning models that require separate training for different
acceleration factors, MR-IPT is pre-trained on a large-scale dataset
encompassing multiple undersampling patterns and acceleration settings,
enabling a unified reconstruction framework. By leveraging a shared transformer
backbone, MR-IPT effectively learns universal feature representations, allowing
it to generalize across diverse reconstruction tasks. Extensive experiments
demonstrate that MR-IPT outperforms both CNN-based and existing
transformer-based methods, achieving superior reconstruction quality across
varying acceleration factors and sampling masks. Moreover, MR-IPT exhibits
strong robustness, maintaining high performance even under unseen acquisition
setups, highlighting its potential as a scalable and efficient solution for
accelerated MRI. Our findings suggest that transformer-based general models can
significantly advance MRI reconstruction, offering improved adaptability and
stability compared to traditional deep learning approaches.",2024-05-23,"Guoyao Shen, Mengyu Li, Stephan Anderson, Chad W. Farris, Xin Zhang",http://arxiv.org/pdf/2405.15098v2,cs.LG
Music Genre Classification: Training an AI model,"Music genre classification is an area that utilizes machine learning models
and techniques for the processing of audio signals, in which applications range
from content recommendation systems to music recommendation systems. In this
research I explore various machine learning algorithms for the purpose of music
genre classification, using features extracted from audio signals.The systems
are namely, a Multilayer Perceptron (built from scratch), a k-Nearest
Neighbours (also built from scratch), a Convolutional Neural Network and lastly
a Random Forest wide model. In order to process the audio signals, feature
extraction methods such as Short-Time Fourier Transform, and the extraction of
Mel Cepstral Coefficients (MFCCs), is performed. Through this extensive
research, I aim to asses the robustness of machine learning models for genre
classification, and to compare their results.",2024-05-23,Keoikantse Mogonediwa,http://arxiv.org/pdf/2405.15096v1,cs.LG
ULTRA-MC: A Unified Approach to Learning Mixtures of Markov Chains via Hitting Times,"This study introduces a novel approach for learning mixtures of Markov
chains, a critical process applicable to various fields, including healthcare
and the analysis of web users. Existing research has identified a clear divide
in methodologies for learning mixtures of discrete and continuous-time Markov
chains, while the latter presents additional complexities for recovery accuracy
and efficiency.
  We introduce a unifying strategy for learning mixtures of discrete and
continuous-time Markov chains, focusing on hitting times, which are well
defined for both types. Specifically, we design a reconstruction algorithm that
outputs a mixture which accurately reflects the estimated hitting times and
demonstrates resilience to noise. We introduce an efficient gradient-descent
approach, specifically tailored to manage the computational complexity and
non-symmetric characteristics inherent in the calculation of hitting time
derivatives. Our approach is also of significant interest when applied to a
single Markov chain, thus extending the methodologies previously established by
Hoskins et al. and Wittmann et al. We complement our theoretical work with
experiments conducted on synthetic and real-world datasets, providing a
comprehensive evaluation of our methodology.",2024-05-23,"Fabian Spaeh, Konstantinos Sotiropoulos, Charalampos E. Tsourakakis",http://arxiv.org/pdf/2405.15094v1,cs.LG
Pure Exploration for Constrained Best Mixed Arm Identification with a Fixed Budget,"In this paper, we introduce the constrained best mixed arm identification
(CBMAI) problem with a fixed budget. This is a pure exploration problem in a
stochastic finite armed bandit model. Each arm is associated with a reward and
multiple types of costs from unknown distributions. Unlike the unconstrained
best arm identification problem, the optimal solution for the CBMAI problem may
be a randomized mixture of multiple arms. The goal thus is to find the best
mixed arm that maximizes the expected reward subject to constraints on the
expected costs with a given learning budget $N$. We propose a novel,
parameter-free algorithm, called the Score Function-based Successive Reject
(SFSR) algorithm, that combines the classical successive reject framework with
a novel score-function-based rejection criteria based on linear programming
theory to identify the optimal support. We provide a theoretical upper bound on
the mis-identification (of the the support of the best mixed arm) probability
and show that it decays exponentially in the budget $N$ and some constants that
characterize the hardness of the problem instance. We also develop an
information theoretic lower bound on the error probability that shows that
these constants appropriately characterize the problem difficulty. We validate
this empirically on a number of average and hard instances.",2024-05-23,"Dengwang Tang, Rahul Jain, Ashutosh Nayyar, Pierluigi Nuzzo",http://arxiv.org/pdf/2405.15090v1,cs.LG
Efficient Certificates of Anti-Concentration Beyond Gaussians,"A set of high dimensional points $X=\{x_1, x_2,\ldots, x_n\} \subset R^d$ in
isotropic position is said to be $\delta$-anti concentrated if for every
direction $v$, the fraction of points in $X$ satisfying $|\langle x_i,v \rangle
|\leq \delta$ is at most $O(\delta)$. Motivated by applications to
list-decodable learning and clustering, recent works have considered the
problem of constructing efficient certificates of anti-concentration in the
average case, when the set of points $X$ corresponds to samples from a Gaussian
distribution. Their certificates played a crucial role in several subsequent
works in algorithmic robust statistics on list-decodable learning and settling
the robust learnability of arbitrary Gaussian mixtures, yet remain limited to
rotationally invariant distributions.
  This work presents a new (and arguably the most natural) formulation for
anti-concentration. Using this formulation, we give quasi-polynomial time
verifiable sum-of-squares certificates of anti-concentration that hold for a
wide class of non-Gaussian distributions including anti-concentrated bounded
product distributions and uniform distributions over $L_p$ balls (and their
affine transformations). Consequently, our method upgrades and extends results
in algorithmic robust statistics e.g., list-decodable learning and clustering,
to such distributions. Our approach constructs a canonical integer program for
anti-concentration and analysis a sum-of-squares relaxation of it, independent
of the intended application. We rely on duality and analyze a
pseudo-expectation on large subsets of the input points that take a small value
in some direction. Our analysis uses the method of polynomial reweightings to
reduce the problem to analyzing only analytically dense or sparse directions.",2024-05-23,"Ainesh Bakshi, Pravesh Kothari, Goutham Rajendran, Madhur Tulsiani, Aravindan Vijayaraghavan",http://arxiv.org/pdf/2405.15084v2,cs.LG
Distributed Harmonization: Federated Clustered Batch Effect Adjustment and Generalization,"Independent and identically distributed (i.i.d.) data is essential to many
data analysis and modeling techniques. In the medical domain, collecting data
from multiple sites or institutions is a common strategy that guarantees
sufficient clinical diversity, determined by the decentralized nature of
medical data. However, data from various sites are easily biased by the local
environment or facilities, thereby violating the i.i.d. rule. A common strategy
is to harmonize the site bias while retaining important biological information.
The ComBat is among the most popular harmonization approaches and has recently
been extended to handle distributed sites. However, when faced with situations
involving newly joined sites in training or evaluating data from unknown/unseen
sites, ComBat lacks compatibility and requires retraining with data from all
the sites. The retraining leads to significant computational and logistic
overhead that is usually prohibitive. In this work, we develop a novel Cluster
ComBat harmonization algorithm, which leverages cluster patterns of the data in
different sites and greatly advances the usability of ComBat harmonization. We
use extensive simulation and real medical imaging data from ADNI to demonstrate
the superiority of the proposed approach. Our codes are provided in
https://github.com/illidanlab/distributed-cluster-harmonization.",2024-05-23,"Bao Hoang, Yijiang Pang, Siqi Liang, Liang Zhan, Paul Thompson, Jiayu Zhou",http://arxiv.org/pdf/2405.15081v3,cs.LG
Sports center customer segmentation: a case study,"Customer segmentation is a fundamental process to develop effective marketing
strategies, personalize customer experience and boost their retention and
loyalty. This problem has been widely addressed in the scientific literature,
yet no definitive solution for every case is available. A specific case study
characterized by several individualizing features is thoroughly analyzed and
discussed in this paper. Because of the case properties a robust and innovative
approach to both data handling and analytical processes is required. The study
led to a sound proposal for customer segmentation. The highlights of the
proposal include a convenient data partition to decompose the problem, an
adaptive distance function definition and its optimization through genetic
algorithms. These comprehensive data handling strategies not only enhance the
dataset reliability for segmentation analysis but also support the operational
efficiency and marketing strategies of sports centers, ultimately improving the
customer experience.",2024-05-23,"Juan Soto, Ramón Carmenaty, Miguel Lastra, Juan M. Fernández-Luna, José M. Benítez",http://arxiv.org/pdf/2405.17467v1,cs.LG
"A Survey of Distributed Learning in Cloud, Mobile, and Edge Settings","In the era of deep learning (DL), convolutional neural networks (CNNs), and
large language models (LLMs), machine learning (ML) models are becoming
increasingly complex, demanding significant computational resources for both
inference and training stages. To address this challenge, distributed learning
has emerged as a crucial approach, employing parallelization across various
devices and environments. This survey explores the landscape of distributed
learning, encompassing cloud and edge settings. We delve into the core concepts
of data and model parallelism, examining how models are partitioned across
different dimensions and layers to optimize resource utilization and
performance. We analyze various partitioning schemes for different layer types,
including fully connected, convolutional, and recurrent layers, highlighting
the trade-offs between computational efficiency, communication overhead, and
memory constraints. This survey provides valuable insights for future research
and development in this rapidly evolving field by comparing and contrasting
distributed learning approaches across diverse contexts.",2024-05-23,"Madison Threadgill, Andreas Gerstlauer",http://arxiv.org/pdf/2405.15079v1,cs.LG
4+3 Phases of Compute-Optimal Neural Scaling Laws,"We consider the solvable neural scaling model with three parameters: data
complexity, target complexity, and model-parameter-count. We use this neural
scaling model to derive new predictions about the compute-limited,
infinite-data scaling law regime. To train the neural scaling model, we run
one-pass stochastic gradient descent on a mean-squared loss. We derive a
representation of the loss curves which holds over all iteration counts and
improves in accuracy as the model parameter count grows. We then analyze the
compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in
the data-complexity/target-complexity phase-plane. The phase boundaries are
determined by the relative importance of model capacity, optimizer noise, and
embedding of the features. We furthermore derive, with mathematical proof and
extensive numerical evidence, the scaling-law exponents in all of these phases,
in particular computing the optimal model-parameter-count as a function of
floating point operation budget.",2024-05-23,"Elliot Paquette, Courtney Paquette, Lechao Xiao, Jeffrey Pennington",http://arxiv.org/pdf/2405.15074v3,cs.LG
An LSTM Feature Imitation Network for Hand Movement Recognition from sEMG Signals,"Surface Electromyography (sEMG) is a non-invasive signal that is used in the
recognition of hand movement patterns, the diagnosis of diseases, and the
robust control of prostheses. Despite the remarkable success of recent
end-to-end Deep Learning approaches, they are still limited by the need for
large amounts of labeled data. To alleviate the requirement for big data, we
propose utilizing a feature-imitating network (FIN) for closed-form temporal
feature learning over a 300ms signal window on Ninapro DB2, and applying it to
the task of 17 hand movement recognition. We implement a lightweight LSTM-FIN
network to imitate four standard temporal features (entropy, root mean square,
variance, simple square integral). We observed that the LSTM-FIN network can
achieve up to 99\% R2 accuracy in feature reconstruction and 80\% accuracy in
hand movement recognition. Our results also showed that the model can be
robustly applied for both within- and cross-subject movement recognition, as
well as simulated low-latency environments. Overall, our work demonstrates the
potential of the FIN modeling paradigm in data-scarce scenarios for sEMG signal
processing.",2024-05-23,"Chuheng Wu, S. Farokh Atashzar, Mohammad M. Ghassemi, Tuka Alhanai",http://arxiv.org/pdf/2405.19356v2,cs.LG
Direct Preference Optimization With Unobserved Preference Heterogeneity,"RLHF has emerged as a pivotal step in aligning language models with human
objectives and values. It typically involves learning a reward model from human
preference data and then using reinforcement learning to update the generative
model accordingly. Conversely, Direct Preference Optimization (DPO) directly
optimizes the generative model with preference data, skipping reinforcement
learning. However, both RLHF and DPO assume uniform preferences, overlooking
the reality of diverse human annotators. This paper presents a new method to
align generative models with varied human preferences. We propose an
Expectation-Maximization adaptation to DPO, generating a mixture of models
based on latent preference types of the annotators. We then introduce a min-max
regret ensemble learning model to produce a single generative method to
minimize worst-case regret among annotator subgroups with similar latent
factors. Our algorithms leverage the simplicity of DPO while accommodating
diverse preferences. Experimental results validate the effectiveness of our
approach in producing equitable generative policies.",2024-05-23,"Keertana Chidambaram, Karthik Vinay Seetharaman, Vasilis Syrgkanis",http://arxiv.org/pdf/2405.15065v1,cs.LG
Distributed Continual Learning,"This work studies the intersection of continual and federated learning, in
which independent agents face unique tasks in their environments and
incrementally develop and share knowledge. We introduce a mathematical
framework capturing the essential aspects of distributed continual learning,
including agent model and statistical heterogeneity, continual distribution
shift, network topology, and communication constraints. Operating on the thesis
that distributed continual learning enhances individual agent performance over
single-agent learning, we identify three modes of information exchange: data
instances, full model parameters, and modular (partial) model parameters. We
develop algorithms for each sharing mode and conduct extensive empirical
investigations across various datasets, topology structures, and communication
limits. Our findings reveal three key insights: sharing parameters is more
efficient than sharing data as tasks become more complex; modular parameter
sharing yields the best performance while minimizing communication costs; and
combining sharing modes can cumulatively improve performance.",2024-05-23,"Long Le, Marcel Hussing, Eric Eaton",http://arxiv.org/pdf/2405.17466v2,cs.LG
A classification model based on a population of hypergraphs,"This paper introduces a novel hypergraph classification algorithm. The use of
hypergraphs in this framework has been widely studied. In previous work,
hypergraph models are typically constructed using distance or attribute based
methods. That is, hyperedges are generated by connecting a set of samples which
are within a certain distance or have a common attribute. These methods
however, do not often focus on multi-way interactions directly. The algorithm
provided in this paper looks to address this problem by constructing
hypergraphs which explore multi-way interactions of any order. We also increase
the performance and robustness of the algorithm by using a population of
hypergraphs. The algorithm is evaluated on two datasets, demonstrating
promising performance compared to a generic random forest classification
algorithm.",2024-05-23,"Samuel Barton, Adelle Coster, Diane Donovan, James Lefevre",http://arxiv.org/pdf/2405.15063v1,cs.LG
Model-Agnostic Utility-Preserving Biometric Information Anonymization,"The recent rapid advancements in both sensing and machine learning
technologies have given rise to the universal collection and utilization of
people's biometrics, such as fingerprints, voices, retina/facial scans, or
gait/motion/gestures data, enabling a wide range of applications including
authentication, health monitoring, or much more sophisticated analytics. While
providing better user experiences and deeper business insights, the use of
biometrics has raised serious privacy concerns due to their intrinsic sensitive
nature and the accompanying high risk of leaking sensitive information such as
identity or medical conditions.
  In this paper, we propose a novel modality-agnostic data transformation
framework that is capable of anonymizing biometric data by suppressing its
sensitive attributes and retaining features relevant to downstream machine
learning-based analyses that are of research and business values. We carried
out a thorough experimental evaluation using publicly available facial, voice,
and motion datasets. Results show that our proposed framework can achieve a
\highlight{high suppression level for sensitive information}, while at the same
time retain underlying data utility such that subsequent analyses on the
anonymized biometric data could still be carried out to yield satisfactory
accuracy.",2024-05-23,"Chun-Fu Chen, Bill Moriarty, Shaohan Hu, Sean Moran, Marco Pistoia, Vincenzo Piuri, Pierangela Samarati",http://arxiv.org/pdf/2405.15062v1,cs.LG
Message-Passing Monte Carlo: Generating low-discrepancy point sets via Graph Neural Networks,"Discrepancy is a well-known measure for the irregularity of the distribution
of a point set. Point sets with small discrepancy are called low-discrepancy
and are known to efficiently fill the space in a uniform manner.
Low-discrepancy points play a central role in many problems in science and
engineering, including numerical integration, computer vision, machine
perception, computer graphics, machine learning, and simulation. In this work,
we present the first machine learning approach to generate a new class of
low-discrepancy point sets named Message-Passing Monte Carlo (MPMC) points.
Motivated by the geometric nature of generating low-discrepancy point sets, we
leverage tools from Geometric Deep Learning and base our model on Graph Neural
Networks. We further provide an extension of our framework to higher
dimensions, which flexibly allows the generation of custom-made points that
emphasize the uniformity in specific dimensions that are primarily important
for the particular problem at hand. Finally, we demonstrate that our proposed
model achieves state-of-the-art performance superior to previous methods by a
significant margin. In fact, MPMC points are empirically shown to be either
optimal or near-optimal with respect to the discrepancy for low dimension and
small number of points, i.e., for which the optimal discrepancy can be
determined. Code for generating MPMC points can be found at
https://github.com/tk-rusch/MPMC.",2024-05-23,"T. Konstantin Rusch, Nathan Kirk, Michael M. Bronstein, Christiane Lemieux, Daniela Rus",http://arxiv.org/pdf/2405.15059v2,cs.LG
ElastoGen: 4D Generative Elastodynamics,"We present ElastoGen, a knowledge-driven AI model that generates physically
accurate 4D elastodynamics. Unlike deep models that learn from video- or
image-based observations, ElastoGen leverages the principles of physics and
learns from established mathematical and optimization procedures. The core idea
of ElastoGen is converting the differential equation, corresponding to the
nonlinear force equilibrium, into a series of iterative local convolution-like
operations, which naturally fit deep architectures. We carefully build our
network module following this overarching design philosophy. ElastoGen is much
more lightweight in terms of both training requirements and network scale than
deep generative models. Because of its alignment with actual physical
procedures, ElastoGen efficiently generates accurate dynamics for a wide range
of hyperelastic materials and can be easily integrated with upstream and
downstream deep modules to enable end-to-end 4D generation.",2024-05-23,"Yutao Feng, Yintong Shang, Xiang Feng, Lei Lan, Shandian Zhe, Tianjia Shao, Hongzhi Wu, Kun Zhou, Hao Su, Chenfanfu Jiang, Yin Yang",http://arxiv.org/pdf/2405.15056v2,cs.LG
CCBNet: Confidential Collaborative Bayesian Networks Inference,"Effective large-scale process optimization in manufacturing industries
requires close cooperation between different human expert parties who encode
their knowledge of related domains as Bayesian network models. For instance,
Bayesian networks for domains such as lithography equipment, processes, and
auxiliary tools must be conjointly used to effectively identify process
optimizations in the semiconductor industry. However, business confidentiality
across domains hinders such collaboration, and encourages alternatives to
centralized inference. We propose CCBNet, the first Confidentiality-preserving
Collaborative Bayesian Network inference framework. CCBNet leverages secret
sharing to securely perform analysis on the combined knowledge of party models
by joining two novel subprotocols: (i) CABN, which augments probability
distributions for features across parties by modeling them into secret shares
of their normalized combination; and (ii) SAVE, which aggregates party
inference result shares through distributed variable elimination. We
extensively evaluate CCBNet via 9 public Bayesian networks. Our results show
that CCBNet achieves predictive quality that is similar to the ones of
centralized methods while preserving model confidentiality. We further
demonstrate that CCBNet scales to challenging manufacturing use cases that
involve 16-128 parties in large networks of 223-1003 features, and decreases,
on average, computational overhead by 23%, while communicating 71k values per
request. Finally, we showcase possible attacks and mitigations for partially
reconstructing party networks in the two subprotocols.",2024-05-23,"Abele Mălan, Jérémie Decouchant, Thiago Guzella, Lydia Chen",http://arxiv.org/pdf/2405.15055v1,cs.LG
Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning,"The study of behavioral diversity in Multi-Agent Reinforcement Learning
(MARL) is a nascent yet promising field. In this context, the present work
deals with the question of how to control the diversity of a multi-agent
system. With no existing approaches to control diversity to a set value,
current solutions focus on blindly promoting it via intrinsic rewards or
additional loss functions, effectively changing the learning objective and
lacking a principled measure for it. To address this, we introduce Diversity
Control (DiCo), a method able to control diversity to an exact value of a given
metric by representing policies as the sum of a parameter-shared component and
dynamically scaled per-agent components. By applying constraints directly to
the policy architecture, DiCo leaves the learning objective unchanged, enabling
its applicability to any actor-critic MARL algorithm. We theoretically prove
that DiCo achieves the desired diversity, and we provide several experiments,
both in cooperative and competitive tasks, that show how DiCo can be employed
as a novel paradigm to increase performance and sample efficiency in MARL.
Multimedia results are available on the paper's website:
https://sites.google.com/view/dico-marl.",2024-05-23,"Matteo Bettini, Ryan Kortvelesy, Amanda Prorok",http://arxiv.org/pdf/2405.15054v1,cs.LG
Revisiting MoE and Dense Speed-Accuracy Comparisons for LLM Training,"Mixture-of-Experts (MoE) enjoys performance gain by increasing model capacity
while keeping computation cost constant. When comparing MoE to dense models,
prior work typically adopt the following setting: 1) use FLOPs or activated
parameters as a measure of model complexity; 2) train all models to the same
number of tokens. We argue that this setting favors MoE as FLOPs and activated
parameters do not accurately measure the communication overhead in sparse
layers, leading to a larger actual training budget for MoE. In this work, we
revisit the settings by adopting step time as a more accurate measure of model
complexity, and by determining the total compute budget under the Chinchilla
compute-optimal settings. To efficiently run MoE on modern accelerators, we
adopt a 3D sharding method that keeps the dense-to-MoE step time increase
within a healthy range. We evaluate MoE and dense LLMs on a set of nine 0-shot
and two 1-shot English tasks, as well as MMLU 5-shot and GSM8K 8-shot across
three model scales at 6.4B, 12.6B, and 29.6B. Experimental results show that
even under these settings, MoE consistently outperform dense LLMs on the
speed-accuracy trade-off curve with meaningful gaps. Our full model
implementation and sharding strategy has been released
at~\url{https://github.com/apple/axlearn}",2024-05-23,"Xianzhi Du, Tom Gunter, Xiang Kong, Mark Lee, Zirui Wang, Aonan Zhang, Nan Du, Ruoming Pang",http://arxiv.org/pdf/2405.15052v2,cs.LG
Reinforcement Learning for Infinite-Horizon Average-Reward Linear MDPs via Approximation by Discounted-Reward MDPs,"We study the problem of infinite-horizon average-reward reinforcement
learning with linear Markov decision processes (MDPs). The associated Bellman
operator of the problem not being a contraction makes the algorithm design
challenging. Previous approaches either suffer from computational inefficiency
or require strong assumptions on dynamics, such as ergodicity, for achieving a
regret bound of $\widetilde{O}(\sqrt{T})$. In this paper, we propose the first
algorithm that achieves $\widetilde{O}(\sqrt{T})$ regret with computational
complexity polynomial in the problem parameters, without making strong
assumptions on dynamics. Our approach approximates the average-reward setting
by a discounted MDP with a carefully chosen discounting factor, and then
applies an optimistic value iteration. We propose an algorithmic structure that
plans for a nonstationary policy through optimistic value iteration and follows
that policy until a specified information metric in the collected data doubles.
Additionally, we introduce a value function clipping procedure for limiting the
span of the value function for sample efficiency.",2024-05-23,"Kihyuk Hong, Woojin Chae, Yufan Zhang, Dabeen Lee, Ambuj Tewari",http://arxiv.org/pdf/2405.15050v3,cs.LG
Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification,"This paper presents an innovative approach, called credal wrapper, to
formulating a credal set representation of model averaging for Bayesian neural
networks (BNNs) and deep ensembles (DEs), capable of improving uncertainty
estimation in classification tasks. Given a finite collection of single
predictive distributions derived from BNNs or DEs, the proposed credal wrapper
approach extracts an upper and a lower probability bound per class,
acknowledging the epistemic uncertainty due to the availability of a limited
amount of distributions. Such probability intervals over classes can be mapped
on a convex set of probabilities (a credal set) from which, in turn, a unique
prediction can be obtained using a transformation called intersection
probability transformation. In this article, we conduct extensive experiments
on several out-of-distribution (OOD) detection benchmarks, encompassing various
dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C,
CIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network
architectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base).
Compared to the BNN and DE baselines, the proposed credal wrapper method
exhibits superior performance in uncertainty estimation and achieves a lower
expected calibration error on corrupted data.",2024-05-23,"Kaizheng Wang, Fabio Cuzzolin, Keivan Shariatmadar, David Moens, Hans Hallez",http://arxiv.org/pdf/2405.15047v2,cs.LG
Feature Fusion for Improved Classification: Combining Dempster-Shafer Theory and Multiple CNN Architectures,"Addressing uncertainty in Deep Learning (DL) is essential, as it enables the
development of models that can make reliable predictions and informed decisions
in complex, real-world environments where data may be incomplete or ambiguous.
This paper introduces a novel algorithm leveraging Dempster-Shafer Theory (DST)
to integrate multiple pre-trained models to form an ensemble capable of
providing more reliable and enhanced classifications. The main steps of the
proposed method include feature extraction, mass function calculation, fusion,
and expected utility calculation. Several experiments have been conducted on
CIFAR-10 and CIFAR-100 datasets, demonstrating superior classification accuracy
of the proposed DST-based method, achieving improvements of 5.4% and 8.4%,
respectively, compared to the best individual pre-trained models. Results
highlight the potential of DST as a robust framework for managing uncertainties
related to data when applying DL in real-world scenarios.",2024-05-23,"Ayyub Alzahem, Wadii Boulila, Maha Driss, Anis Koubaa",http://arxiv.org/pdf/2405.20230v1,cs.LG
CEEBERT: Cross-Domain Inference in Early Exit BERT,"Pre-trained Language Models (PLMs), like BERT, with self-supervision
objectives exhibit remarkable performance and generalization across various
tasks. However, they suffer in inference latency due to their large size. To
address this issue, side branches are attached at intermediate layers, enabling
early inference of samples without requiring them to pass through all layers.
However, the challenge is to decide which layer to infer and exit each sample
so that the accuracy and latency are balanced. Moreover, the distribution of
the samples to be inferred may differ from that used for training necessitating
cross-domain adaptation. We propose an online learning algorithm named
Cross-Domain Inference in Early Exit BERT (CeeBERT) that dynamically determines
early exits of samples based on the level of confidence at each exit point.
CeeBERT learns optimal thresholds from domain-specific confidence observed at
intermediate layers on the fly, eliminating the need for labeled data.
Experimental results on five distinct datasets with BERT and ALBERT models
demonstrate CeeBERT's ability to improve latency by reducing unnecessary
computations with minimal drop in performance. By adapting to the threshold
values, CeeBERT can speed up the BERT/ALBERT models by $2\times$ - $3.5\times$
with minimal drop in accuracy.",2024-05-23,"Divya Jyoti Bajpai, Manjesh Kumar Hanawal",http://arxiv.org/pdf/2405.15039v1,cs.LG
Input-driven circuit reconfiguration in critical recurrent neural networks,"Changing a circuit dynamically, without actually changing the hardware
itself, is called reconfiguration, and is of great importance due to its
manifold technological applications. Circuit reconfiguration appears to be a
feature of the cerebral cortex, and hence understanding the neuroarchitectural
and dynamical features underlying self-reconfiguration may prove key to
elucidate brain function. We present a very simple single-layer recurrent
network, whose signal pathways can be reconfigured ""on the fly"" using only its
inputs, with no changes to its synaptic weights. We use the low spatio-temporal
frequencies of the input to landscape the ongoing activity, which in turn
permits or denies the propagation of traveling waves. This mechanism uses the
inherent properties of dynamically-critical systems, which we guarantee through
unitary convolution kernels. We show this network solves the classical
connectedness problem, by allowing signal propagation only along the regions to
be evaluated for connectedness and forbidding it elsewhere.",2024-05-23,Marcelo O. Magnasco,http://arxiv.org/pdf/2405.15036v1,cs.LG
Amortized nonmyopic active search via deep imitation learning,"Active search formalizes a specialized active learning setting where the goal
is to collect members of a rare, valuable class. The state-of-the-art algorithm
approximates the optimal Bayesian policy in a budget-aware manner, and has been
shown to achieve impressive empirical performance in previous work. However,
even this approximate policy has a superlinear computational complexity with
respect to the size of the search problem, rendering its application
impractical in large spaces or in real-time systems where decisions must be
made quickly. We study the amortization of this policy by training a neural
network to learn to search. To circumvent the difficulty of learning from
scratch, we appeal to imitation learning techniques to mimic the behavior of
the expert, expensive-to-compute policy. Our policy network, trained on
synthetic data, learns a beneficial search strategy that yields nonmyopic
decisions carefully balancing exploration and exploitation. Extensive
experiments demonstrate our policy achieves competitive performance at
real-world tasks that closely approximates the expert's at a fraction of the
cost, while outperforming cheaper baselines.",2024-05-23,"Quan Nguyen, Anindya Sarkar, Roman Garnett",http://arxiv.org/pdf/2405.15031v1,cs.LG
OAC: Output-adaptive Calibration for Accurate Post-training Quantization,"Deployment of Large Language Models (LLMs) has major computational costs, due
to their rapidly expanding size. Compression of LLMs reduces the memory
footprint, latency, and energy required for their inference. Post-training
Quantization (PTQ) techniques have been developed to compress LLMs while
avoiding expensive re-training. Most PTQ approaches formulate the quantization
error based on a layer-wise Euclidean loss, ignoring the model output. Then,
each layer is calibrated using its layer-wise Hessian to update the weights
towards minimizing the quantization error. The Hessian is also used for
detecting the most salient weights to quantization. Such PTQ approaches are
prone to accuracy drop in low-precision quantization. We propose
Output-adaptive Calibration (OAC) to incorporate the model output in the
calibration process. We formulate the quantization error based on the
distortion of the output cross-entropy loss. OAC approximates the
output-adaptive Hessian for each layer under reasonable assumptions to reduce
the computational complexity. The output-adaptive Hessians are used to update
the weight matrices and detect the salient weights towards maintaining the
model output. Our proposed method outperforms the state-of-the-art baselines
such as SpQR and BiLLM, especially, at extreme low-precision (2-bit and binary)
quantization.",2024-05-23,"Ali Edalati, Alireza Ghaffari, Mahsa Ghazvini Nejad, Lu Hou, Boxing Chen, Masoud Asgharian, Vahid Partovi Nia",http://arxiv.org/pdf/2405.15025v2,cs.LG
AdjointDEIS: Efficient Gradients for Diffusion Models,"The optimization of the latents and parameters of diffusion models with
respect to some differentiable metric defined on the output of the model is a
challenging and complex problem. The sampling for diffusion models is done by
solving either the probability flow ODE or diffusion SDE wherein a neural
network approximates the score function allowing a numerical ODE/SDE solver to
be used. However, naive backpropagation techniques are memory intensive,
requiring the storage of all intermediate states, and face additional
complexity in handling the injected noise from the diffusion term of the
diffusion SDE. We propose a novel family of bespoke ODE solvers to the
continuous adjoint equations for diffusion models, which we call AdjointDEIS.
We exploit the unique construction of diffusion SDEs to further simplify the
formulation of the continuous adjoint equations using exponential integrators.
Moreover, we provide convergence order guarantees for our bespoke solvers.
Significantly, we show that continuous adjoint equations for diffusion SDEs
actually simplify to a simple ODE. Lastly, we demonstrate the effectiveness of
AdjointDEIS for guided generation with an adversarial attack in the form of the
face morphing problem. Our code will be released at https:
//github.com/zblasingame/AdjointDEIS.",2024-05-23,"Zander W. Blasingame, Chen Liu",http://arxiv.org/pdf/2405.15020v3,cs.LG
Agentic Skill Discovery,"Language-conditioned robotic skills make it possible to apply the high-level
reasoning of Large Language Models (LLMs) to low-level robotic control. A
remaining challenge is to acquire a diverse set of fundamental skills. Existing
approaches either manually decompose a complex task into atomic robotic actions
in a top-down fashion, or bootstrap as many combinations as possible in a
bottom-up fashion to cover a wider range of task possibilities. These
decompositions or combinations, however, require an initial skill library. For
example, a ``grasping'' capability can never emerge from a skill library
containing only diverse ``pushing'' skills. Existing skill discovery techniques
with reinforcement learning acquire skills by an exhaustive exploration but
often yield non-meaningful behaviors. In this study, we introduce a novel
framework for skill discovery that is entirely driven by LLMs. The framework
begins with an LLM generating task proposals based on the provided scene
description and the robot's configurations, aiming to incrementally acquire new
skills upon task completion. For each proposed task, a series of reinforcement
learning processes are initiated, utilizing reward and success determination
functions sampled by the LLM to develop the corresponding policy. The
reliability and trustworthiness of learned behaviors are further ensured by an
independent vision-language model. We show that starting with zero skill, the
skill library emerges and expands to more and more meaningful and reliable
skills, enabling the robot to efficiently further propose and complete advanced
tasks. Project page: \url{https://agentic-skill-discovery.github.io}.",2024-05-23,"Xufeng Zhao, Cornelius Weber, Stefan Wermter",http://arxiv.org/pdf/2405.15019v2,cs.LG
What Variables Affect Out-of-Distribution Generalization in Pretrained Models?,"Embeddings produced by pre-trained deep neural networks (DNNs) are widely
used; however, their efficacy for downstream tasks can vary widely. We study
the factors influencing transferability and out-of-distribution (OOD)
generalization of pre-trained DNN embeddings through the lens of the tunnel
effect hypothesis, which is closely related to intermediate neural collapse.
This hypothesis suggests that deeper DNN layers compress representations and
hinder OOD generalization. Contrary to earlier work, our experiments show this
is not a universal phenomenon. We comprehensively investigate the impact of DNN
architecture, training data, image resolution, and augmentations on
transferability. We identify that training with high-resolution datasets
containing many classes greatly reduces representation compression and improves
transferability. Our results emphasize the danger of generalizing findings from
toy datasets to broader contexts.",2024-05-23,"Md Yousuf Harun, Kyungbok Lee, Jhair Gallardo, Giri Krishnan, Christopher Kanan",http://arxiv.org/pdf/2405.15018v3,cs.LG
Fast inference with Kronecker-sparse matrices,"This paper benchmarks and improves existing GPU matrix multiplication
algorithms specialized for Kronecker-sparse matrices, whose sparsity patterns
are described by Kronecker products. These matrices have recently gained
popularity as replacements for dense matrices in neural networks because they
preserve accuracy while using fewer parameters. We present the first energy and
time benchmarks for the multiplication with such matrices, helping users
identify scenarios where Kronecker-sparse matrices are more time- and
energy-efficient than their dense counterparts. Our benchmark also reveals that
specialized implementations spend up to 50% of their total runtime on memory
rewriting operations. To address the challenge of reducing memory transfers, we
introduce a new so-called tiling strategy adapted to the Kronecker-sparsity
structure, which reduces reads and writes between levels of GPU memory. We
implement this tiling strategy in a new CUDA kernel that achieves a median
speed-up of x1.4, while also cutting energy consumption by 15%. We further
demonstrate the broader impact of our results by applying the new kernel to
accelerate transformer inference.",2024-05-23,"Antoine Gonon, Léon Zheng, Pascal Carrivain, Quoc-Tung Le",http://arxiv.org/pdf/2405.15013v2,cs.LG
Extracting Prompts by Inverting LLM Outputs,"We consider the problem of language model inversion: given outputs of a
language model, we seek to extract the prompt that generated these outputs. We
develop a new black-box method, output2prompt, that learns to extract prompts
without access to the model's logits and without adversarial or jailbreaking
queries. In contrast to previous work, output2prompt only needs outputs of
normal user queries. To improve memory efficiency, output2prompt employs a new
sparse encoding techique. We measure the efficacy of output2prompt on a variety
of user and system prompts and demonstrate zero-shot transferability across
different LLMs.",2024-05-23,"Collin Zhang, John X. Morris, Vitaly Shmatikov",http://arxiv.org/pdf/2405.15012v2,cs.LG
Parameter-free Clipped Gradient Descent Meets Polyak,"Gradient descent and its variants are de facto standard algorithms for
training machine learning models. As gradient descent is sensitive to its
hyperparameters, we need to tune the hyperparameters carefully using a grid
search. However, the method is time-consuming, particularly when multiple
hyperparameters exist. Therefore, recent studies have analyzed parameter-free
methods that adjust the hyperparameters on the fly. However, the existing work
is limited to investigations of parameter-free methods for the stepsize, and
parameter-free methods for other hyperparameters have not been explored. For
instance, although the gradient clipping threshold is a crucial hyperparameter
in addition to the stepsize for preventing gradient explosion issues, none of
the existing studies have investigated parameter-free methods for clipped
gradient descent. Therefore, in this study, we investigate the parameter-free
methods for clipped gradient descent. Specifically, we propose Inexact Polyak
Stepsize, which converges to the optimal solution without any hyperparameters
tuning, and its convergence rate is asymptotically independent of $L$ under
$L$-smooth and $(L_0, L_1)$-smooth assumptions of the loss function, similar to
that of clipped gradient descent with well-tuned hyperparameters. We
numerically validated our convergence results using a synthetic function and
demonstrated the effectiveness of our proposed methods using LSTM, Nano-GPT,
and T5.",2024-05-23,"Yuki Takezawa, Han Bao, Ryoma Sato, Kenta Niwa, Makoto Yamada",http://arxiv.org/pdf/2405.15010v2,cs.LG
RE-Adapt: Reverse Engineered Adaptation of Large Language Models,"We introduce RE-Adapt, an approach to fine-tuning large language models on
new domains without degrading any pre-existing instruction-tuning. We reverse
engineer an adapter which isolates what an instruction-tuned model has learned
beyond its corresponding pretrained base model. Importantly, this requires no
additional data or training. We can then fine-tune the base model on a new
domain and readapt it to instruction following with the reverse engineered
adapter. RE-Adapt and our low-rank variant LoRE-Adapt both outperform other
methods of fine-tuning, across multiple popular LLMs and datasets, even when
the models are used in conjunction with retrieval-augmented generation.",2024-05-23,"William Fleshman, Benjamin Van Durme",http://arxiv.org/pdf/2405.15007v1,cs.LG
A rescaling-invariant Lipschitz bound based on path-metrics for modern ReLU network parameterizations,"Lipschitz bounds on neural network parameterizations are important to
establish generalization, quantization or pruning guarantees, as they control
the robustness of the network with respect to parameter changes. Yet, there are
few Lipschitz bounds with respect to parameters in the literature, and existing
ones only apply to simple feedforward architectures, while also failing to
capture the intrinsic rescaling-symmetries of ReLU networks. This paper proves
a new Lipschitz bound in terms of the so-called path-metrics of the parameters.
Since this bound is intrinsically invariant with respect to the rescaling
symmetries of the networks, it sharpens previously known Lipschitz bounds. It
is also, to the best of our knowledge, the first bound of its kind that is
broadly applicable to modern networks such as ResNets, VGGs, U-nets, and many
more.",2024-05-23,"Antoine Gonon, Nicolas Brisebarre, Elisa Riccietti, Rémi Gribonval",http://arxiv.org/pdf/2405.15006v2,cs.LG
Private Regression via Data-Dependent Sufficient Statistic Perturbation,"Sufficient statistic perturbation (SSP) is a widely used method for
differentially private linear regression. SSP adopts a data-independent
approach where privacy noise from a simple distribution is added to sufficient
statistics. However, sufficient statistics can often be expressed as linear
queries and better approximated by data-dependent mechanisms. In this paper we
introduce data-dependent SSP for linear regression based on post-processing
privately released marginals, and find that it outperforms state-of-the-art
data-independent SSP. We extend this result to logistic regression by
developing an approximate objective that can be expressed in terms of
sufficient statistics, resulting in a novel and highly competitive SSP approach
for logistic regression. We also make a connection to synthetic data for
machine learning: for models with sufficient statistics, training on synthetic
data corresponds to data-dependent SSP, with the overall utility determined by
how well the mechanism answers these linear queries.",2024-05-23,"Cecilia Ferrando, Daniel Sheldon",http://arxiv.org/pdf/2405.15002v1,cs.LG
Lower Bound on the Greedy Approximation Ratio for Adaptive Submodular Cover,"We show that the greedy algorithm for adaptive-submodular cover has
approximation ratio at least 1.3*(1+ln Q). Moreover, the instance demonstrating
this gap has Q=1. So, it invalidates a prior result in the paper ``Adaptive
Submodularity: A New Approach to Active Learning and Stochastic Optimization''
by Golovin-Krause, that claimed a (1+ln Q)^2 approximation ratio for the same
algorithm.",2024-05-23,"Blake Harris, Viswanath Nagarajan",http://arxiv.org/pdf/2405.14995v1,cs.LG
Linking In-context Learning in Transformers to Human Episodic Memory,"Understanding connections between artificial and biological intelligent
systems can reveal fundamental principles of general intelligence. While many
artificial intelligence models have a neuroscience counterpart, such
connections are largely missing in Transformer models and the self-attention
mechanism. Here, we examine the relationship between interacting attention
heads and human episodic memory. We focus on induction heads, which contribute
to in-context learning in Transformer-based large language models (LLMs). We
demonstrate that induction heads are behaviorally, functionally, and
mechanistically similar to the contextual maintenance and retrieval (CMR) model
of human episodic memory. Our analyses of LLMs pre-trained on extensive text
data show that CMR-like heads often emerge in the intermediate and late layers,
qualitatively mirroring human memory biases. The ablation of CMR-like heads
suggests their causal role in in-context learning. Our findings uncover a
parallel between the computational mechanisms of LLMs and human memory,
offering valuable insights into both research fields.",2024-05-23,"Li Ji-An, Corey Y. Zhou, Marcus K. Benna, Marcelo G. Mattar",http://arxiv.org/pdf/2405.14992v2,cs.LG
Hand bone age estimation using divide and conquer strategy and lightweight convolutional neural networks,"Estimating the Bone Age of children is very important for diagnosing growth
defects, and related diseases, and estimating the final height that children
reach after maturity. For this reason, it is widely used in different
countries. Traditional methods for estimating bone age are performed by
comparing atlas images and radiographic images of the left hand, which is
time-consuming and error-prone. To estimate bone age using deep neural network
models, a lot of research has been done, our effort has been to improve the
accuracy and speed of this process by using the introduced approach. After
creating and analyzing our initial model, we focused on preprocessing and made
the inputs smaller, and increased their quality. we selected small regions of
hand radiographs and estimated the age of the bone only according to these
regions. by doing this we improved bone age estimation accuracy even further
than what was achieved in related works, without increasing the required
computational resource. We reached a Mean Absolute Error (MAE) of 3.90 months
in the range of 0-20 years and an MAE of 3.84 months in the range of 1-18 years
on the RSNA test set.",2024-05-23,"Amin Ahmadi Kasani, Hedieh Sajedi",http://arxiv.org/pdf/2405.14986v1,cs.LG
In-context Time Series Predictor,"Recent Transformer-based large language models (LLMs) demonstrate in-context
learning ability to perform various functions based solely on the provided
context, without updating model parameters. To fully utilize the in-context
capabilities in time series forecasting (TSF) problems, unlike previous
Transformer-based or LLM-based time series forecasting methods, we reformulate
""time series forecasting tasks"" as input tokens by constructing a series of
(lookback, future) pairs within the tokens. This method aligns more closely
with the inherent in-context mechanisms, and is more parameter-efficient
without the need of using pre-trained LLM parameters. Furthermore, it addresses
issues such as overfitting in existing Transformer-based TSF models,
consistently achieving better performance across full-data, few-shot, and
zero-shot settings compared to previous architectures.",2024-05-23,"Jiecheng Lu, Yan Sun, Shihao Yang",http://arxiv.org/pdf/2405.14982v1,cs.LG
MaSS: Multi-attribute Selective Suppression for Utility-preserving Data Transformation from an Information-theoretic Perspective,"The growing richness of large-scale datasets has been crucial in driving the
rapid advancement and wide adoption of machine learning technologies. The
massive collection and usage of data, however, pose an increasing risk for
people's private and sensitive information due to either inadvertent
mishandling or malicious exploitation. Besides legislative solutions, many
technical approaches have been proposed towards data privacy protection.
However, they bear various limitations such as leading to degraded data
availability and utility, or relying on heuristics and lacking solid
theoretical bases. To overcome these limitations, we propose a formal
information-theoretic definition for this utility-preserving privacy protection
problem, and design a data-driven learnable data transformation framework that
is capable of selectively suppressing sensitive attributes from target datasets
while preserving the other useful attributes, regardless of whether or not they
are known in advance or explicitly annotated for preservation. We provide
rigorous theoretical analyses on the operational bounds for our framework, and
carry out comprehensive experimental evaluations using datasets of a variety of
modalities, including facial images, voice audio clips, and human activity
motion sensor signals. Results demonstrate the effectiveness and
generalizability of our method under various configurations on a multitude of
tasks. Our code is available at https://github.com/jpmorganchase/MaSS.",2024-05-23,"Yizhuo Chen, Chun-Fu Chen, Hsiang Hsu, Shaohan Hu, Marco Pistoia, Tarek Abdelzaher",http://arxiv.org/pdf/2405.14981v2,cs.LG
Efficient Mitigation of Bus Bunching through Setter-Based Curriculum Learning,"Curriculum learning has been growing in the domain of reinforcement learning
as a method of improving training efficiency for various tasks. It involves
modifying the difficulty (lessons) of the environment as the agent learns, in
order to encourage more optimal agent behavior and higher reward states.
However, most curriculum learning methods currently involve discrete
transitions of the curriculum or predefined steps by the programmer or using
automatic curriculum learning on only a small subset training such as only on
an adversary. In this paper, we propose a novel approach to curriculum learning
that uses a Setter Model to automatically generate an action space, adversary
strength, initialization, and bunching strength. Transportation and traffic
optimization is a well known area of study, especially for reinforcement
learning based solutions. We specifically look at the bus bunching problem for
the context of this study. The main idea of the problem is to minimize the
delays caused by inefficient bus timings for passengers arriving and departing
from a system of buses. While the heavy exploration in the area makes
innovation and improvement with regards to performance marginal, it
simultaneously provides an effective baseline for developing new generalized
techniques. Our group is particularly interested in examining curriculum
learning and its effect on training efficiency and overall performance. We
decide to try a lesser known approach to curriculum learning, in which the
curriculum is not fixed or discretely thresholded. Our method for automated
curriculum learning involves a curriculum that is dynamically chosen and
learned by an adversary network made to increase the difficulty of the agent's
training, and defined by multiple forms of input. Our results are shown in the
following sections of this paper.",2024-05-23,"Avidan Shah, Danny Tran, Yuhan Tang",http://arxiv.org/pdf/2405.15824v1,cs.LG
Efficiently Training Deep-Learning Parametric Policies using Lagrangian Duality,"Constrained Markov Decision Processes (CMDPs) are critical in many
high-stakes applications, where decisions must optimize cumulative rewards
while strictly adhering to complex nonlinear constraints. In domains such as
power systems, finance, supply chains, and precision robotics, violating these
constraints can result in significant financial or societal costs. Existing
Reinforcement Learning (RL) methods often struggle with sample efficiency and
effectiveness in finding feasible policies for highly and strictly constrained
CMDPs, limiting their applicability in these environments. Stochastic dual
dynamic programming is often used in practice on convex relaxations of the
original problem, but they also encounter computational challenges and loss of
optimality. This paper introduces a novel approach, Two-Stage Deep Decision
Rules (TS-DDR), to efficiently train parametric actor policies using Lagrangian
Duality. TS-DDR is a self-supervised learning algorithm that trains general
decision rules (parametric policies) using stochastic gradient descent (SGD);
its forward passes solve {\em deterministic} optimization problems to find
feasible policies, and its backward passes leverage duality theory to train the
parametric policy with closed-form gradients. TS-DDR inherits the flexibility
and computational performance of deep learning methodologies to solve CMDP
problems. Applied to the Long-Term Hydrothermal Dispatch (LTHD) problem using
actual power system data from Bolivia, TS-DDR is shown to enhance solution
quality and to reduce computation times by several orders of magnitude when
compared to current state-of-the-art methods.",2024-05-23,"Andrew Rosemberg, Alexandre Street, Davi M. Valladão, Pascal Van Hentenryck",http://arxiv.org/pdf/2405.14973v2,cs.LG
SFDDM: Single-fold Distillation for Diffusion models,"While diffusion models effectively generate remarkable synthetic images, a
key limitation is the inference inefficiency, requiring numerous sampling
steps. To accelerate inference and maintain high-quality synthesis,
teacher-student distillation is applied to compress the diffusion models in a
progressive and binary manner by retraining, e.g., reducing the 1024-step model
to a 128-step model in 3 folds. In this paper, we propose a single-fold
distillation algorithm, SFDDM, which can flexibly compress the teacher
diffusion model into a student model of any desired step, based on
reparameterization of the intermediate inputs from the teacher model. To train
the student diffusion, we minimize not only the output distance but also the
distribution of the hidden variables between the teacher and student model.
Extensive experiments on four datasets demonstrate that our student model
trained by the proposed SFDDM is able to sample high-quality data with steps
reduced to as little as approximately 1%, thus, trading off inference time. Our
remarkable performance highlights that SFDDM effectively transfers knowledge in
single-fold distillation, achieving semantic consistency and meaningful image
interpolation.",2024-05-23,"Chi Hong, Jiyue Huang, Robert Birke, Dick Epema, Stefanie Roos, Lydia Y. Chen",http://arxiv.org/pdf/2405.14961v1,cs.LG
Understanding the dynamics of the frequency bias in neural networks,"Recent works have shown that traditional Neural Network (NN) architectures
display a marked frequency bias in the learning process. Namely, the NN first
learns the low-frequency features before learning the high-frequency ones. In
this study, we rigorously develop a partial differential equation (PDE) that
unravels the frequency dynamics of the error for a 2-layer NN in the Neural
Tangent Kernel regime. Furthermore, using this insight, we explicitly
demonstrate how an appropriate choice of distributions for the initialization
weights can eliminate or control the frequency bias. We focus our study on the
Fourier Features model, an NN where the first layer has sine and cosine
activation functions, with frequencies sampled from a prescribed distribution.
In this setup, we experimentally validate our theoretical results and compare
the NN dynamics to the solution of the PDE using the finite element method.
Finally, we empirically show that the same principle extends to multi-layer
NNs.",2024-05-23,"Juan Molina, Mircea Petrache, Francisco Sahli Costabal, Matías Courdurier",http://arxiv.org/pdf/2405.14957v1,cs.LG
Interpretable and Editable Programmatic Tree Policies for Reinforcement Learning,"Deep reinforcement learning agents are prone to goal misalignments. The
black-box nature of their policies hinders the detection and correction of such
misalignments, and the trust necessary for real-world deployment. So far,
solutions learning interpretable policies are inefficient or require many human
priors. We propose INTERPRETER, a fast distillation method producing
INTerpretable Editable tRee Programs for ReinforcEmenT lEaRning. We empirically
demonstrate that INTERPRETER compact tree programs match oracles across a
diverse set of sequential decision tasks and evaluate the impact of our design
choices on interpretability and performances. We show that our policies can be
interpreted and edited to correct misalignments on Atari games and to explain
real farming strategies.",2024-05-23,"Hector Kohler, Quentin Delfosse, Riad Akrour, Kristian Kersting, Philippe Preux",http://arxiv.org/pdf/2405.14956v1,cs.LG
MallowsPO: Fine-Tune Your LLM with Preference Dispersions,"Direct Preference Optimization (DPO) has recently emerged as a popular
approach to improve reinforcement learning with human feedback (RLHF), leading
to better techniques to fine-tune large language models (LLM). A weakness of
DPO, however, lies in its lack of capability to characterize the diversity of
human preferences. Inspired by Mallows' theory of preference ranking, we
develop in this paper a new approach, the MallowsPO. A distinct feature of this
approach is a dispersion index, which reflects the dispersion of human
preference to prompts. We show that existing DPO models can be reduced to
special cases of this dispersion index, thus unified with MallowsPO. More
importantly, we demonstrate (empirically) how to use this dispersion index to
enhance the performance of DPO in a broad array of benchmark tasks, from
synthetic bandit selection to controllable generations and dialogues, while
maintaining great generalization capabilities. MallowsPO is also compatible
with other SOTA offline preference optimization methods, boosting nearly 2\%
extra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.",2024-05-23,"Haoxian Chen, Hanyang Zhao, Henry Lam, David Yao, Wenpin Tang",http://arxiv.org/pdf/2405.14953v5,cs.LG
AstroPT: Scaling Large Observation Models for Astronomy,"This work presents AstroPT, an autoregressive pretrained transformer
developed with astronomical use-cases in mind. The AstroPT models presented
here have been pretrained on 8.6 million $512 \times 512$ pixel $grz$-band
galaxy postage stamp observations from the DESI Legacy Survey DR8. We train a
selection of foundation models of increasing size from 1 million to 2.1 billion
parameters, and find that AstroPT follows a similar saturating log-log scaling
law to textual models. We also find that the models' performances on downstream
tasks as measured by linear probing improves with model size up to the model
parameter saturation point. We believe that collaborative community development
paves the best route towards realising an open source `Large Observation Model'
-- a model trained on data taken from the observational sciences at the scale
seen in natural language processing. To this end, we release the source code,
weights, and dataset for AstroPT under the MIT license, and invite potential
collaborators to join us in collectively building and researching these models.",2024-05-23,"Michael J. Smith, Ryan J. Roberts, Eirini Angeloudi, Marc Huertas-Company",http://arxiv.org/pdf/2405.14930v1,cs.LG
Fast Bayesian Inference for Neutrino Non-Standard Interactions at Dark Matter Direct Detection Experiments,"Multi-dimensional parameter spaces are commonly encountered in physics
theories that go beyond the Standard Model. However, they often possess
complicated posterior geometries that are expensive to traverse using
techniques traditional to astroparticle physics. Several recent innovations,
which are only beginning to make their way into this field, have made
navigating such complex posteriors possible. These include GPU acceleration,
automatic differentiation, and neural-network-guided reparameterization. We
apply these advancements to dark matter direct detection experiments in the
context of non-standard neutrino interactions and benchmark their performances
against traditional nested sampling techniques when conducting Bayesian
inference. Compared to nested sampling alone, we find that these techniques
increase performance for both nested sampling and Hamiltonian Monte Carlo,
accelerating inference by factors of $\sim 100$ and $\sim 60$, respectively. As
nested sampling also evaluates the Bayesian evidence, these advancements can be
exploited to improve model comparison performance while retaining compatibility
with existing implementations that are widely used in the natural sciences.
Using these techniques, we perform the first scan in the neutrino non-standard
interactions parameter space for direct detection experiments whereby all
parameters are allowed to vary simultaneously. We expect that these
advancements are broadly applicable to other areas of astroparticle physics
featuring multi-dimensional parameter spaces.",2024-05-23,"Dorian W. P. Amaral, Shixiao Liang, Juehang Qin, Christopher Tunnell",http://arxiv.org/pdf/2405.14932v2,cs.LG
Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis,"Accurate reconstruction of complex dynamic scenes from just a single
viewpoint continues to be a challenging task in computer vision. Current
dynamic novel view synthesis methods typically require videos from many
different camera viewpoints, necessitating careful recording setups, and
significantly restricting their utility in the wild as well as in terms of
embodied AI applications. In this paper, we propose $\textbf{GCD}$, a
controllable monocular dynamic view synthesis pipeline that leverages
large-scale diffusion priors to, given a video of any scene, generate a
synchronous video from any other chosen perspective, conditioned on a set of
relative camera pose parameters. Our model does not require depth as input, and
does not explicitly model 3D scene geometry, instead performing end-to-end
video-to-video translation in order to achieve its goal efficiently. Despite
being trained on synthetic multi-view video data only, zero-shot real-world
generalization experiments show promising results in multiple domains,
including robotics, object permanence, and driving environments. We believe our
framework can potentially unlock powerful applications in rich dynamic scene
understanding, perception for robotics, and interactive 3D video viewing
experiences for virtual reality.",2024-05-23,"Basile Van Hoorick, Rundi Wu, Ege Ozguroglu, Kyle Sargent, Ruoshi Liu, Pavel Tokmakov, Achal Dave, Changxi Zheng, Carl Vondrick",http://arxiv.org/pdf/2405.14868v2,cs.LG
A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns,"Cross-domain alignment refers to the task of mapping a concept from one
domain to another. For example, ``If a \textit{doctor} were a \textit{color},
what color would it be?''. This seemingly peculiar task is designed to
investigate how people represent concrete and abstract concepts through their
mappings between categories and their reasoning processes over those mappings.
In this paper, we adapt this task from cognitive science to evaluate the
conceptualization and reasoning abilities of large language models (LLMs)
through a behavioral study. We examine several LLMs by prompting them with a
cross-domain mapping task and analyzing their responses at both the population
and individual levels. Additionally, we assess the models' ability to reason
about their predictions by analyzing and categorizing their explanations for
these mappings. The results reveal several similarities between humans' and
models' mappings and explanations, suggesting that models represent concepts
similarly to humans. This similarity is evident not only in the model
representation but also in their behavior. Furthermore, the models mostly
provide valid explanations and deploy reasoning paths that are similar to those
of humans.",2024-05-23,"Asaf Yehudai, Taelin Karidi, Gabriel Stanovsky, Ariel Goldstein, Omri Abend",http://arxiv.org/pdf/2405.14863v1,cs.LG
Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models,"This paper investigates score-based diffusion models when the underlying
target distribution is concentrated on or near low-dimensional manifolds within
the higher-dimensional space in which they formally reside, a common
characteristic of natural image distributions. Despite previous efforts to
understand the data generation process of diffusion models, existing
theoretical support remains highly suboptimal in the presence of
low-dimensional structure, which we strengthen in this paper. For the popular
Denoising Diffusion Probabilistic Model (DDPM), we find that the dependency of
the error incurred within each denoising step on the ambient dimension $d$ is
in general unavoidable. We further identify a unique design of coefficients
that yields a converges rate at the order of $O(k^{2}/\sqrt{T})$ (up to log
factors), where $k$ is the intrinsic dimension of the target distribution and
$T$ is the number of steps. This represents the first theoretical demonstration
that the DDPM sampler can adapt to unknown low-dimensional structures in the
target distribution, highlighting the critical importance of coefficient
design. All of this is achieved by a novel set of analysis tools that
characterize the algorithmic dynamics in a more deterministic manner.",2024-05-23,"Gen Li, Yuling Yan",http://arxiv.org/pdf/2405.14861v2,cs.LG
Not All Language Model Features Are One-Dimensionally Linear,"Recent work has proposed that language models perform computation by
manipulating one-dimensional representations of concepts (""features"") in
activation space. In contrast, we explore whether some language model
representations may be inherently multi-dimensional. We begin by developing a
rigorous definition of irreducible multi-dimensional features based on whether
they can be decomposed into either independent or non-co-occurring
lower-dimensional features. Motivated by these definitions, we design a
scalable method that uses sparse autoencoders to automatically find
multi-dimensional features in GPT-2 and Mistral 7B. These auto-discovered
features include strikingly interpretable examples, e.g. circular features
representing days of the week and months of the year. We identify tasks where
these exact circles are used to solve computational problems involving modular
arithmetic in days of the week and months of the year. Next, we provide
evidence that these circular features are indeed the fundamental unit of
computation in these tasks with intervention experiments on Mistral 7B and
Llama 3 8B, and we examine the continuity of the days of the week feature in
Mistral 7B. Overall, our work argues that understanding multi-dimensional
features is necessary to mechanistically decompose some model behaviors.",2024-05-23,"Joshua Engels, Eric J. Michaud, Isaac Liao, Wes Gurnee, Max Tegmark",http://arxiv.org/pdf/2405.14860v3,cs.LG
PILOT: Equivariant diffusion for pocket conditioned de novo ligand generation with multi-objective guidance via importance sampling,"The generation of ligands that both are tailored to a given protein pocket
and exhibit a range of desired chemical properties is a major challenge in
structure-based drug design. Here, we propose an in-silico approach for the
$\textit{de novo}$ generation of 3D ligand structures using the equivariant
diffusion model PILOT, combining pocket conditioning with a large-scale
pre-training and property guidance. Its multi-objective trajectory-based
importance sampling strategy is designed to direct the model towards molecules
that not only exhibit desired characteristics such as increased binding
affinity for a given protein pocket but also maintains high synthetic
accessibility. This ensures the practicality of sampled molecules, thus
maximizing their potential for the drug discovery pipeline. PILOT significantly
outperforms existing methods across various metrics on the common benchmark
dataset CrossDocked2020. Moreover, we employ PILOT to generate novel ligands
for unseen protein pockets from the Kinodata-3D dataset, which encompasses a
substantial portion of the human kinome. The generated structures exhibit
predicted $IC_{50}$ values indicative of potent biological activity, which
highlights the potential of PILOT as a powerful tool for structure-based drug
design.",2024-05-23,"Julian Cremer, Tuan Le, Frank Noé, Djork-Arné Clevert, Kristof T. Schütt",http://arxiv.org/pdf/2405.14925v1,cs.LG
Conditional Diffusion on Web-Scale Image Pairs leads to Diverse Image Variations,"Generating image variations, where a model produces variations of an input
image while preserving the semantic context has gained increasing attention.
Current image variation techniques involve adapting a text-to-image model to
reconstruct an input image conditioned on the same image. We first demonstrate
that a diffusion model trained to reconstruct an input image from frozen
embeddings, can reconstruct the image with minor variations. Second, inspired
by how text-to-image models learn from web-scale text-image pairs, we explore a
new pretraining strategy to generate image variations using a large collection
of image pairs. Our diffusion model \textit{Semantica} receives a random
(encoded) image from a webpage as conditional input and denoises another noisy
random image from the same webpage. We carefully examine various design choices
for the image encoder, given its crucial role in extracting relevant context
from the input image. Once trained, \textit{Semantica} can adaptively generate
new images from a dataset by simply using images from that dataset as input.
Finally, we identify limitations in standard image consistency metrics for
evaluating image variations and propose alternative metrics based on few-shot
generation.",2024-05-23,"Manoj Kumar, Neil Houlsby, Emiel Hoogeboom",http://arxiv.org/pdf/2405.14857v3,cs.LG
TerDiT: Ternary Diffusion Models with Transformers,"Recent developments in large-scale pre-trained text-to-image diffusion models
have significantly improved the generation of high-fidelity images,
particularly with the emergence of diffusion transformer models (DiTs). Among
diffusion models, diffusion transformers have demonstrated superior
image-generation capabilities, boosting lower FID scores and higher
scalability. However, deploying large-scale DiT models can be expensive due to
their excessive parameter numbers. Although existing research has explored
efficient deployment techniques for diffusion models, such as model
quantization, there is still little work concerning DiT-based models. To tackle
this research gap, we propose TerDiT, the first quantization-aware training
(QAT) and efficient deployment scheme for extremely low-bit diffusion
transformer models. We focus on the ternarization of DiT networks, with model
sizes ranging from 600M to 4.2B, and image resolution from 256$\times$256 to
512$\times$512. Our work contributes to the exploration of efficient deployment
of large-scale DiT models, demonstrating the feasibility of training extremely
low-bit DiT models from scratch while maintaining competitive image generation
capacities compared to full-precision models. Our code and pre-trained TerDiT
checkpoints have been released at https://github.com/Lucky-Lance/TerDiT.",2024-05-23,"Xudong Lu, Aojun Zhou, Ziyi Lin, Qi Liu, Yuhui Xu, Renrui Zhang, Xue Yang, Junchi Yan, Peng Gao, Hongsheng Li",http://arxiv.org/pdf/2405.14854v2,cs.LG
Privileged Sensing Scaffolds Reinforcement Learning,"We need to look at our shoelaces as we first learn to tie them but having
mastered this skill, can do it from touch alone. We call this phenomenon
""sensory scaffolding"": observation streams that are not needed by a master
might yet aid a novice learner. We consider such sensory scaffolding setups for
training artificial agents. For example, a robot arm may need to be deployed
with just a low-cost, robust, general-purpose camera; yet its performance may
improve by having privileged training-time-only access to informative albeit
expensive and unwieldy motion capture rigs or fragile tactile sensors. For
these settings, we propose ""Scaffolder"", a reinforcement learning approach
which effectively exploits privileged sensing in critics, world models, reward
estimators, and other such auxiliary components that are only used at training
time, to improve the target policy. For evaluating sensory scaffolding agents,
we design a new ""S3"" suite of ten diverse simulated robotic tasks that explore
a wide range of practical sensor setups. Agents must use privileged camera
sensing to train blind hurdlers, privileged active visual perception to help
robot arms overcome visual occlusions, privileged touch sensors to train robot
hands, and more. Scaffolder easily outperforms relevant prior baselines and
frequently performs comparably even to policies that have test-time access to
the privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/",2024-05-23,"Edward S. Hu, James Springer, Oleh Rybkin, Dinesh Jayaraman",http://arxiv.org/pdf/2405.14853v1,cs.LG
PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression,"There has been significant interest in ""extreme"" compression of large
language models (LLMs), i.e., to 1-2 bits per parameter, which allows such
models to be executed efficiently on resource-constrained devices. Existing
work focused on improved one-shot quantization techniques and weight
representations; yet, purely post-training approaches are reaching diminishing
returns in terms of the accuracy-vs-bit-width trade-off. State-of-the-art
quantization methods such as QuIP# and AQLM include fine-tuning (part of) the
compressed parameters over a limited amount of calibration data; however, such
fine-tuning techniques over compressed weights often make exclusive use of
straight-through estimators (STE), whose performance is not well-understood in
this setting. In this work, we question the use of STE for extreme LLM
compression, showing that it can be sub-optimal, and perform a systematic study
of quantization-aware fine-tuning strategies for LLMs. We propose PV-Tuning - a
representation-agnostic framework that generalizes and improves upon existing
fine-tuning strategies, and provides convergence guarantees in restricted
cases. On the practical side, when used for 1-2 bit vector quantization,
PV-Tuning outperforms prior techniques for highly-performant models such as
Llama and Mistral. Using PV-Tuning, we achieve the first Pareto-optimal
quantization for Llama 2 family models at 2 bits per parameter.",2024-05-23,"Vladimir Malinovskii, Denis Mazur, Ivan Ilin, Denis Kuznedelev, Konstantin Burlachenko, Kai Yi, Dan Alistarh, Peter Richtarik",http://arxiv.org/pdf/2405.14852v2,cs.LG
Local Causal Discovery for Structural Evidence of Direct Discrimination,"Identifying the causal pathways of unfairness is a critical objective for
improving policy design and algorithmic decision-making. Prior work in causal
fairness analysis often requires knowledge of the causal graph, hindering
practical applications in complex or low-knowledge domains. Moreover, global
discovery methods that learn causal structure from data can display unstable
performance on finite samples, preventing robust fairness conclusions. To
mitigate these challenges, we introduce local discovery for direct
discrimination (LD3): a method that uncovers structural evidence of direct
unfairness by identifying the causal parents of an outcome variable. LD3
performs a linear number of conditional independence tests relative to variable
set size, and allows for latent confounding under the sufficient condition that
all parents of the outcome are observed. We show that LD3 returns a valid
adjustment set (VAS) under a new graphical criterion for the weighted
controlled direct effect, a qualitative indicator of direct discrimination. LD3
limits unnecessary adjustment, providing interpretable VAS for assessing
unfairness. We use LD3 to analyze causal fairness in two complex decision
systems: criminal recidivism prediction and liver transplant allocation. LD3
was more time-efficient and returned more plausible results on real-world data
than baselines, which took 46$\times$ to 5870$\times$ longer to execute.",2024-05-23,"Jacqueline Maasch, Kyra Gan, Violet Chen, Agni Orfanoudaki, Nil-Jana Akpinar, Fei Wang",http://arxiv.org/pdf/2405.14848v3,cs.LG
Differentiable Annealed Importance Sampling Minimizes The Symmetrized Kullback-Leibler Divergence Between Initial and Target Distribution,"Differentiable annealed importance sampling (DAIS), proposed by Geffner &
Domke (2021) and Zhang et al. (2021), allows optimizing over the initial
distribution of AIS. In this paper, we show that, in the limit of many
transitions, DAIS minimizes the symmetrized Kullback-Leibler divergence between
the initial and target distribution. Thus, DAIS can be seen as a form of
variational inference (VI) as its initial distribution is a parametric fit to
an intractable target distribution. We empirically evaluate the usefulness of
the initial distribution as a variational distribution on synthetic and
real-world data, observing that it often provides more accurate uncertainty
estimates than VI (optimizing the reverse KL divergence), importance weighted
VI, and Markovian score climbing (optimizing the forward KL divergence).",2024-05-23,"Johannes Zenn, Robert Bamler",http://arxiv.org/pdf/2405.14840v2,cs.LG
From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step,"When leveraging language models for reasoning tasks, generating explicit
chain-of-thought (CoT) steps often proves essential for achieving high accuracy
in final outputs. In this paper, we investigate if models can be taught to
internalize these CoT steps. To this end, we propose a simple yet effective
method for internalizing CoT steps: starting with a model trained for explicit
CoT reasoning, we gradually remove the intermediate steps and finetune the
model. This process allows the model to internalize the intermediate reasoning
steps, thus simplifying the reasoning process while maintaining high
performance. Our approach enables a GPT-2 Small model to solve 9-by-9
multiplication with up to 99% accuracy, whereas standard training cannot solve
beyond 4-by-4 multiplication. Furthermore, our method proves effective on
larger language models, such as Mistral 7B, achieving over 50% accuracy on
GSM8K without producing any intermediate steps.",2024-05-23,"Yuntian Deng, Yejin Choi, Stuart Shieber",http://arxiv.org/pdf/2405.14838v1,cs.LG
Information Fusion in Smart Agriculture: Machine Learning Applications and Future Research Directions,"Machine learning (ML) is a rapidly evolving technology with expanding
applications across various fields. This paper presents a comprehensive survey
of recent ML applications in agriculture for sustainability and efficiency.
Existing reviews mainly focus on narrow subdomains or lack a fusion-driven
perspectives. This study provides a combined analysis of ML applications in
agriculture, structured around five key objectives: (i) Analyzing ML techniques
across pre-harvesting, harvesting, and post-harvesting phases. (ii)
Demonstrating how ML can be used with agricultural data and data fusion. (iii)
Conducting a bibliometric and statistical analysis to reveal research trends
and activity. (iv) Investigating real-world case studies of leading artificial
intelligence (AI)-driven agricultural companies that use different types of
multisensors and multisource data. (v) Compiling publicly available datasets to
support ML model training. Going beyond existing previous reviews, this review
focuses on how machine learning (ML) techniques, combined with multi-source
data fusion (integrating remote sensing, IoT, and climate analytics), enhance
precision agriculture by improving predictive accuracy and decision-making.
Case studies and statistical insights illustrate the evolving landscape of AI
driven smart farming, while future research directions also discusses
challenges associated with data fusion for heterogeneous datasets. This review
bridges the gap between AI research and agricultural applications, offering a
roadmap for researchers, industry professionals, and policymakers to harness
information fusion and ML for advancing precision agriculture.",2024-05-23,"Aashu Katharria, Kanchan Rajwar, Millie Pant, Juan D. Velásquez, Václav Snášel, Kusum Deep",http://arxiv.org/pdf/2405.17465v2,cs.LG
How Does Bayes Error Limit Probabilistic Robust Accuracy,"Adversarial examples pose a security threat to many critical systems built on
neural networks. Given that deterministic robustness often comes with
significantly reduced accuracy, probabilistic robustness (i.e., the probability
of having the same label with a vicinity is $\ge 1-\kappa$) has been proposed
as a promising way of achieving robustness whilst maintaining accuracy.
However, existing training methods for probabilistic robustness still
experience non-trivial accuracy loss. It is unclear whether there is an upper
bound on the accuracy when optimising towards probabilistic robustness, and
whether there is a certain relationship between $\kappa$ and this bound. This
work studies these problems from a Bayes error perspective. We find that while
Bayes uncertainty does affect probabilistic robustness, its impact is smaller
than that on deterministic robustness. This reduced Bayes uncertainty allows a
higher upper bound on probabilistic robust accuracy than that on deterministic
robust accuracy. Further, we prove that with optimal probabilistic robustness,
each probabilistically robust input is also deterministically robust in a
smaller vicinity. We also show that voting within the vicinity always improves
probabilistic robust accuracy and the upper bound of probabilistic robust
accuracy monotonically increases as $\kappa$ grows. Our empirical findings also
align with our results.",2024-05-23,"Ruihan Zhang, Jun Sun",http://arxiv.org/pdf/2405.14923v1,cs.LG
Analysis of Atom-level pretraining with Quantum Mechanics (QM) data for Graph Neural Networks Molecular property models,"Despite the rapid and significant advancements in deep learning for
Quantitative Structure-Activity Relationship (QSAR) models, the challenge of
learning robust molecular representations that effectively generalize in
real-world scenarios to novel compounds remains an elusive and unresolved task.
This study examines how atom-level pretraining with quantum mechanics (QM) data
can mitigate violations of assumptions regarding the distributional similarity
between training and test data and therefore improve performance and
generalization in downstream tasks. In the public dataset Therapeutics Data
Commons (TDC), we show how pretraining on atom-level QM improves performance
overall and makes the activation of the features distributes more Gaussian-like
which results in a representation that is more robust to distribution shifts.
To the best of our knowledge, this is the first time that hidden state
molecular representations are analyzed to compare the effects of molecule-level
and atom-level pretraining on QM data.",2024-05-23,"Jose Arjona-Medina, Ramil Nugmanov",http://arxiv.org/pdf/2405.14837v2,cs.LG
Deep learning lattice gauge theories,"Monte Carlo methods have led to profound insights into the strong-coupling
behaviour of lattice gauge theories and produced remarkable results such as
first-principles computations of hadron masses. Despite tremendous progress
over the last four decades, fundamental challenges such as the sign problem and
the inability to simulate real-time dynamics remain. Neural network quantum
states have emerged as an alternative method that seeks to overcome these
challenges. In this work, we use gauge-invariant neural network quantum states
to accurately compute the ground state of $\mathbb{Z}_N$ lattice gauge theories
in $2+1$ dimensions. Using transfer learning, we study the distinct topological
phases and the confinement phase transition of these theories. For
$\mathbb{Z}_2$, we identify a continuous transition and compute critical
exponents, finding excellent agreement with existing numerics for the expected
Ising universality class. In the $\mathbb{Z}_3$ case, we observe a weakly
first-order transition and identify the critical coupling. Our findings suggest
that neural network quantum states are a promising method for precise studies
of lattice gauge theory.",2024-05-23,"Anuj Apte, Anthony Ashmore, Clay Cordova, Tzu-Chen Huang",http://arxiv.org/pdf/2405.14830v1,cs.LG
PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher,"The diffusion model performs remarkable in generating high-dimensional
content but is computationally intensive, especially during training. We
propose Progressive Growing of Diffusion Autoencoder (PaGoDA), a novel pipeline
that reduces the training costs through three stages: training diffusion on
downsampled data, distilling the pretrained diffusion, and progressive
super-resolution. With the proposed pipeline, PaGoDA achieves a $64\times$
reduced cost in training its diffusion model on 8x downsampled data; while at
the inference, with the single-step, it performs state-of-the-art on ImageNet
across all resolutions from 64x64 to 512x512, and text-to-image. PaGoDA's
pipeline can be applied directly in the latent space, adding compression
alongside the pre-trained autoencoder in Latent Diffusion Models (e.g., Stable
Diffusion). The code is available at https://github.com/sony/pagoda.",2024-05-23,"Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon",http://arxiv.org/pdf/2405.14822v2,cs.LG
Small Language Models for Application Interactions: A Case Study,"We study the efficacy of Small Language Models (SLMs) in facilitating
application usage through natural language interactions. Our focus here is on a
particular internal application used in Microsoft for cloud supply chain
fulfilment. Our experiments show that small models can outperform much larger
ones in terms of both accuracy and running time, even when fine-tuned on small
datasets. Alongside these results, we also highlight SLM-based system design
considerations.",2024-05-23,"Beibin Li, Yi Zhang, Sébastien Bubeck, Jeevan Pathuri, Ishai Menache",http://arxiv.org/pdf/2405.20347v1,cs.LG
Scalable Optimization in the Modular Norm,"To improve performance in contemporary deep learning, one is interested in
scaling up the neural network in terms of both the number and the size of the
layers. When ramping up the width of a single layer, graceful scaling of
training has been linked to the need to normalize the weights and their updates
in the ""natural norm"" particular to that layer. In this paper, we significantly
generalize this idea by defining the modular norm, which is the natural norm on
the full weight space of any neural network architecture. The modular norm is
defined recursively in tandem with the network architecture itself. We show
that the modular norm has several promising applications. On the practical
side, the modular norm can be used to normalize the updates of any base
optimizer so that the learning rate becomes transferable across width and
depth. This means that the user does not need to compute optimizer-specific
scale factors in order to scale training. On the theoretical side, we show that
for any neural network built from ""well-behaved"" atomic modules, the gradient
of the network is Lipschitz-continuous in the modular norm, with the Lipschitz
constant admitting a simple recursive formula. This characterization opens the
door to porting standard ideas in optimization theory over to deep learning. We
have created a Python package called Modula that automatically normalizes
weight updates in the modular norm of the architecture. The package is
available via ""pip install modula"" with source code at
https://github.com/jxbz/modula.",2024-05-23,"Tim Large, Yang Liu, Minyoung Huh, Hyojin Bahng, Phillip Isola, Jeremy Bernstein",http://arxiv.org/pdf/2405.14813v1,cs.LG
Implicit Personalization in Language Models: A Systematic Study,"Implicit Personalization (IP) is a phenomenon of language models inferring a
user's background from the implicit cues in the input prompts and tailoring the
response based on this inference. While previous work has touched upon various
instances of this problem, there lacks a unified framework to study this
behavior. This work systematically studies IP through a rigorous mathematical
formulation, a multi-perspective moral reasoning framework, and a set of case
studies. Our theoretical foundation for IP relies on a structural causal model
and introduces a novel method, indirect intervention, to estimate the causal
effect of a mediator variable that cannot be directly intervened upon. Beyond
the technical approach, we also introduce a set of moral reasoning principles
based on three schools of moral philosophy to study when IP may or may not be
ethically appropriate. Equipped with both mathematical and ethical insights, we
present three diverse case studies illustrating the varied nature of the IP
problem and offer recommendations for future research. Our code is at
https://github.com/jiarui-liu/IP, and our data is at
https://huggingface.co/datasets/Jerry999/ImplicitPersonalizationData.",2024-05-23,"Zhijing Jin, Nils Heil, Jiarui Liu, Shehzaad Dhuliawala, Yahang Qi, Bernhard Schölkopf, Rada Mihalcea, Mrinmaya Sachan",http://arxiv.org/pdf/2405.14808v2,cs.LG
Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics,"Extracting scientific understanding from particle-physics experiments
requires solving diverse learning problems with high precision and good data
efficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a
new multi-purpose architecture for high-energy physics. L-GATr represents
high-energy data in a geometric algebra over four-dimensional space-time and is
equivariant under Lorentz transformations, the symmetry group of relativistic
kinematics. At the same time, the architecture is a Transformer, which makes it
versatile and scalable to large systems. L-GATr is first demonstrated on
regression and classification tasks from particle physics. We then construct
the first Lorentz-equivariant generative model: a continuous normalizing flow
based on an L-GATr network, trained with Riemannian flow matching. Across our
experiments, L-GATr is on par with or outperforms strong domain-specific
baselines.",2024-05-23,"Jonas Spinner, Victor Bresó, Pim de Haan, Tilman Plehn, Jesse Thaler, Johann Brehmer",http://arxiv.org/pdf/2405.14806v3,cs.LG
AnalogCoder: Analog Circuit Design via Training-Free Code Generation,"Analog circuit design is a significant task in modern chip technology,
focusing on the selection of component types, connectivity, and parameters to
ensure proper circuit functionality. Despite advances made by Large Language
Models (LLMs) in digital circuit design, the complexity and scarcity of data in
analog circuitry pose significant challenges. To mitigate these issues, we
introduce AnalogCoder, the first training-free LLM agent for designing analog
circuits through Python code generation. Firstly, AnalogCoder incorporates a
feedback-enhanced flow with tailored domain-specific prompts, enabling the
automated and self-correcting design of analog circuits with a high success
rate. Secondly, it proposes a circuit tool library to archive successful
designs as reusable modular sub-circuits, simplifying composite circuit
creation. Thirdly, extensive experiments on a benchmark designed to cover a
wide range of analog circuit tasks show that AnalogCoder outperforms other
LLM-based methods. It has successfully designed 20 circuits, 5 more than
standard GPT-4o. We believe AnalogCoder can significantly improve the
labor-intensive chip design process, enabling non-experts to design analog
circuits efficiently.",2024-05-23,"Yao Lai, Sungyoung Lee, Guojin Chen, Souradip Poddar, Mengkang Hu, David Z. Pan, Ping Luo",http://arxiv.org/pdf/2405.14918v2,cs.LG
Recurrent Early Exits for Federated Learning with Heterogeneous Clients,"Federated learning (FL) has enabled distributed learning of a model across
multiple clients in a privacy-preserving manner. One of the main challenges of
FL is to accommodate clients with varying hardware capacities; clients have
differing compute and memory requirements. To tackle this challenge, recent
state-of-the-art approaches leverage the use of early exits. Nonetheless, these
approaches fall short of mitigating the challenges of joint learning multiple
exit classifiers, often relying on hand-picked heuristic solutions for
knowledge distillation among classifiers and/or utilizing additional layers for
weaker classifiers. In this work, instead of utilizing multiple classifiers, we
propose a recurrent early exit approach named ReeFL that fuses features from
different sub-models into a single shared classifier. Specifically, we use a
transformer-based early-exit module shared among sub-models to i) better
exploit multi-layer feature representations for task-specific prediction and
ii) modulate the feature representation of the backbone model for subsequent
predictions. We additionally present a per-client self-distillation approach
where the best sub-model is automatically selected as the teacher of the other
sub-models at each client. Our experiments on standard image and speech
classification benchmarks across various emerging federated fine-tuning
baselines demonstrate ReeFL's effectiveness over previous works.",2024-05-23,"Royson Lee, Javier Fernandez-Marques, Shell Xu Hu, Da Li, Stefanos Laskaridis, Łukasz Dudziak, Timothy Hospedales, Ferenc Huszár, Nicholas D. Lane",http://arxiv.org/pdf/2405.14791v2,cs.LG
DIDI: Diffusion-Guided Diversity for Offline Behavioral Generation,"In this paper, we propose a novel approach called DIffusion-guided DIversity
(DIDI) for offline behavioral generation. The goal of DIDI is to learn a
diverse set of skills from a mixture of label-free offline data. We achieve
this by leveraging diffusion probabilistic models as priors to guide the
learning process and regularize the policy. By optimizing a joint objective
that incorporates diversity and diffusion-guided regularization, we encourage
the emergence of diverse behaviors while maintaining the similarity to the
offline data. Experimental results in four decision-making domains (Push,
Kitchen, Humanoid, and D4RL tasks) show that DIDI is effective in discovering
diverse and discriminative skills. We also introduce skill stitching and skill
interpolation, which highlight the generalist nature of the learned skill
space. Further, by incorporating an extrinsic reward function, DIDI enables
reward-guided behavior generation, facilitating the learning of diverse and
optimal behaviors from sub-optimal data.",2024-05-23,"Jinxin Liu, Xinghong Guo, Zifeng Zhuang, Donglin Wang",http://arxiv.org/pdf/2405.14790v1,cs.LG
EditWorld: Simulating World Dynamics for Instruction-Following Image Editing,"Diffusion models have significantly improved the performance of image
editing. Existing methods realize various approaches to achieve high-quality
image editing, including but not limited to text control, dragging operation,
and mask-and-inpainting. Among these, instruction-based editing stands out for
its convenience and effectiveness in following human instructions across
diverse scenarios. However, it still focuses on simple editing operations like
adding, replacing, or deleting, and falls short of understanding aspects of
world dynamics that convey the realistic dynamic nature in the physical world.
Therefore, this work, EditWorld, introduces a new editing task, namely
world-instructed image editing, which defines and categorizes the instructions
grounded by various world scenarios. We curate a new image editing dataset with
world instructions using a set of large pretrained models (e.g., GPT-3.5,
Video-LLava and SDXL). To enable sufficient simulation of world dynamics for
image editing, our EditWorld trains model in the curated dataset, and improves
instruction-following ability with designed post-edit strategy. Extensive
experiments demonstrate our method significantly outperforms existing editing
methods in this new task. Our dataset and code will be available at
https://github.com/YangLing0818/EditWorld",2024-05-23,"Ling Yang, Bohan Zeng, Jiaming Liu, Hong Li, Minghao Xu, Wentao Zhang, Shuicheng Yan",http://arxiv.org/pdf/2405.14785v1,cs.LG
Metric Flow Matching for Smooth Interpolations on the Data Manifold,"Matching objectives underpin the success of modern generative models and rely
on constructing conditional paths that transform a source distribution into a
target distribution. Despite being a fundamental building block, conditional
paths have been designed principally under the assumption of Euclidean
geometry, resulting in straight interpolations. However, this can be
particularly restrictive for tasks such as trajectory inference, where straight
paths might lie outside the data manifold, thus failing to capture the
underlying dynamics giving rise to the observed marginals. In this paper, we
propose Metric Flow Matching (MFM), a novel simulation-free framework for
conditional flow matching where interpolants are approximate geodesics learned
by minimizing the kinetic energy of a data-induced Riemannian metric. This way,
the generative model matches vector fields on the data manifold, which
corresponds to lower uncertainty and more meaningful interpolations. We
prescribe general metrics to instantiate MFM, independent of the task, and test
it on a suite of challenging problems including LiDAR navigation, unpaired
image translation, and modeling cellular dynamics. We observe that MFM
outperforms the Euclidean baselines, particularly achieving SOTA on single-cell
trajectory prediction.",2024-05-23,"Kacper Kapuśniak, Peter Potaptchik, Teodora Reu, Leo Zhang, Alexander Tong, Michael Bronstein, Avishek Joey Bose, Francesco Di Giovanni",http://arxiv.org/pdf/2405.14780v2,cs.LG
Smart Bilingual Focused Crawling of Parallel Documents,"Crawling parallel texts $\unicode{x2014}$texts that are mutual
translations$\unicode{x2014}$ from the Internet is usually done following a
brute-force approach: documents are massively downloaded in an unguided
process, and only a fraction of them end up leading to actual parallel content.
In this work we propose a smart crawling method that guides the crawl towards
finding parallel content more rapidly. Our approach builds on two different
models: one that infers the language of a document from its URL, and another
that infers whether a pair of URLs link to parallel documents. We evaluate both
models in isolation and their integration into a crawling tool. The results
demonstrate the individual effectiveness of both models and highlight that
their combination enables the early discovery of parallel content during
crawling, leading to a reduction in the amount of downloaded documents deemed
useless, and yielding a greater quantity of parallel documents compared to
conventional crawling approaches.",2024-05-23,"Cristian García-Romero, Miquel Esplà-Gomis, Felipe Sánchez-Martínez",http://arxiv.org/pdf/2405.14779v1,cs.LG
Optimal Rates for Vector-Valued Spectral Regularization Learning Algorithms,"We study theoretical properties of a broad class of regularized algorithms
with vector-valued output. These spectral algorithms include kernel ridge
regression, kernel principal component regression, various implementations of
gradient descent and many more. Our contributions are twofold. First, we
rigorously confirm the so-called saturation effect for ridge regression with
vector-valued output by deriving a novel lower bound on learning rates; this
bound is shown to be suboptimal when the smoothness of the regression function
exceeds a certain level. Second, we present the upper bound for the finite
sample risk general vector-valued spectral algorithms, applicable to both
well-specified and misspecified scenarios (where the true regression function
lies outside of the hypothesis space) which is minimax optimal in various
regimes. All of our results explicitly allow the case of infinite-dimensional
output variables, proving consistency of recent practical applications.",2024-05-23,"Dimitri Meunier, Zikai Shen, Mattes Mollenhauer, Arthur Gretton, Zhu Li",http://arxiv.org/pdf/2405.14778v1,cs.LG
Kinetics of orbital ordering in cooperative Jahn-Teller models: Machine-learning enabled large-scale simulations,"We present a scalable machine learning (ML) force-field model for the
adiabatic dynamics of cooperative Jahn-Teller (JT) systems. Large scale
dynamical simulations of the JT model also shed light on the orbital ordering
dynamics in colossal magnetoresistance manganites. The JT effect in these
materials describes the distortion of local oxygen octahedra driven by a
coupling to the orbital degrees of freedom of $e_g$ electrons. An effective
electron-mediated interaction between the local JT modes leads to a structural
transition and the emergence of long-range orbital order at low temperatures.
Assuming the principle of locality, a deep-learning neural-network model is
developed to accurately and efficiently predict the electron-induced forces
that drive the dynamical evolution of JT phonons. A group-theoretical method is
utilized to develop a descriptor that incorporates the combined orbital and
lattice symmetry into the ML model. Large-scale Langevin dynamics simulations,
enabled by the ML force-field models, are performed to investigate the
coarsening dynamics of the composite JT distortion and orbital order after a
thermal quench. The late-stage coarsening of orbital domains exhibits
pronounced freezing behaviors which are likely related to the unusual
morphology of the domain structures. Our work highlights a promising avenue for
multi-scale dynamical modeling of correlated electron systems.",2024-05-23,"Supriyo Ghosh, Sheng Zhang, Chen Cheng, Gia-Wei Chern",http://arxiv.org/pdf/2405.14776v1,cs.LG
Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from Human Input,"Humans use social context to specify preferences over behaviors, i.e. their
reward functions. Yet, algorithms for inferring reward models from preference
data do not take this social learning view into account. Inspired by pragmatic
human communication, we study how to extract fine-grained data regarding why an
example is preferred that is useful for learning more accurate reward models.
We propose to enrich binary preference queries to ask both (1) which features
of a given example are preferable in addition to (2) comparisons between
examples themselves. We derive an approach for learning from these
feature-level preferences, both for cases where users specify which features
are reward-relevant, and when users do not. We evaluate our approach on linear
bandit settings in both vision- and language-based domains. Results support the
efficiency of our approach in quickly converging to accurate rewards with fewer
comparisons vs. example-only labels. Finally, we validate the real-world
applicability with a behavioral experiment on a mushroom foraging task. Our
findings suggest that incorporating pragmatic feature preferences is a
promising approach for more efficient user-aligned reward learning.",2024-05-23,"Andi Peng, Yuying Sun, Tianmin Shu, David Abel",http://arxiv.org/pdf/2405.14769v1,cs.LG
WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models,"Large language models (LLMs) need knowledge updates to meet the ever-growing
world facts and correct the hallucinated responses, facilitating the methods of
lifelong model editing. Where the updated knowledge resides in memories is a
fundamental question for model editing. In this paper, we find that editing
either long-term memory (direct model parameters) or working memory
(non-parametric knowledge of neural network activations/representations by
retrieval) will result in an impossible triangle -- reliability,
generalization, and locality can not be realized together in the lifelong
editing settings. For long-term memory, directly editing the parameters will
cause conflicts with irrelevant pretrained knowledge or previous edits (poor
reliability and locality). For working memory, retrieval-based activations can
hardly make the model understand the edits and generalize (poor
generalization). Therefore, we propose WISE to bridge the gap between memories.
In WISE, we design a dual parametric memory scheme, which consists of the main
memory for the pretrained knowledge and a side memory for the edited knowledge.
We only edit the knowledge in the side memory and train a router to decide
which memory to go through when given a query. For continual editing, we devise
a knowledge-sharding mechanism where different sets of edits reside in distinct
subspaces of parameters, and are subsequently merged into a shared memory
without conflicts. Extensive experiments show that WISE can outperform previous
model editing methods and overcome the impossible triangle under lifelong model
editing of question answering, hallucination, and out-of-distribution settings
across trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is
available at https://github.com/zjunlp/EasyEdit.",2024-05-23,"Peng Wang, Zexi Li, Ningyu Zhang, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",http://arxiv.org/pdf/2405.14768v3,cs.LG
FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models,"As financial institutions and professionals increasingly incorporate Large
Language Models (LLMs) into their workflows, substantial barriers, including
proprietary data and specialized knowledge, persist between the finance sector
and the AI community. These challenges impede the AI community's ability to
enhance financial tasks effectively. Acknowledging financial analysis's
critical role, we aim to devise financial-specialized LLM-based toolchains and
democratize access to them through open-source initiatives, promoting wider AI
adoption in financial decision-making. In this paper, we introduce FinRobot, a
novel open-source AI agent platform supporting multiple financially specialized
AI agents, each powered by LLM. Specifically, the platform consists of four
major layers: 1) the Financial AI Agents layer that formulates Financial
Chain-of-Thought (CoT) by breaking sophisticated financial problems down into
logical sequences; 2) the Financial LLM Algorithms layer dynamically configures
appropriate model application strategies for specific tasks; 3) the LLMOps and
DataOps layer produces accurate models by applying training/fine-tuning
techniques and using task-relevant data; 4) the Multi-source LLM Foundation
Models layer that integrates various LLMs and enables the above layers to
access them directly. Finally, FinRobot provides hands-on for both
professional-grade analysts and laypersons to utilize powerful AI techniques
for advanced financial analysis. We open-source FinRobot at
\url{https://github.com/AI4Finance-Foundation/FinRobot}.",2024-05-23,"Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, Christina Dan Wang",http://arxiv.org/pdf/2405.14767v2,cs.LG
Evaluating Large Language Models for Public Health Classification and Extraction Tasks,"Advances in Large Language Models (LLMs) have led to significant interest in
their potential to support human experts across a range of domains, including
public health. In this work we present automated evaluations of LLMs for public
health tasks involving the classification and extraction of free text. We
combine six externally annotated datasets with seven new internally annotated
datasets to evaluate LLMs for processing text related to: health burden,
epidemiological risk factors, and public health interventions. We evaluate
eleven open-weight LLMs (7-123 billion parameters) across all tasks using
zero-shot in-context learning. We find that Llama-3.3-70B-Instruct is the
highest performing model, achieving the best results on 8/16 tasks (using
micro-F1 scores). We see significant variation across tasks with all
open-weight LLMs scoring below 60% micro-F1 on some challenging tasks, such as
Contact Classification, while all LLMs achieve greater than 80% micro-F1 on
others, such as GI Illness Classification. For a subset of 11 tasks, we also
evaluate three GPT-4 and GPT-4o series models and find comparable results to
Llama-3.3-70B-Instruct. Overall, based on these initial results we find
promising signs that LLMs may be useful tools for public health experts to
extract information from a wide variety of free text sources, and support
public health surveillance, research, and interventions.",2024-05-23,"Joshua Harris, Timothy Laurence, Leo Loman, Fan Grayson, Toby Nonnenmacher, Harry Long, Loes WalsGriffith, Amy Douglas, Holly Fountain, Stelios Georgiou, Jo Hardstaff, Kathryn Hopkins, Y-Ling Chi, Galena Kuyumdzhieva, Lesley Larkin, Samuel Collins, Hamish Mohammed, Thomas Finnie, Luke Hounsome, Michael Borowitz, Steven Riley",http://arxiv.org/pdf/2405.14766v2,cs.LG
Neural Pfaffians: Solving Many Many-Electron Schrödinger Equations,"Neural wave functions accomplished unprecedented accuracies in approximating
the ground state of many-electron systems, though at a high computational cost.
Recent works proposed amortizing the cost by learning generalized wave
functions across different structures and compounds instead of solving each
problem independently. Enforcing the permutation antisymmetry of electrons in
such generalized neural wave functions remained challenging as existing methods
require discrete orbital selection via non-learnable hand-crafted algorithms.
This work tackles the problem by defining overparametrized, fully learnable
neural wave functions suitable for generalization across molecules. We achieve
this by relying on Pfaffians rather than Slater determinants. The Pfaffian
allows us to enforce the antisymmetry on arbitrary electronic systems without
any constraint on electronic spin configurations or molecular structure. Our
empirical evaluation finds that a single neural Pfaffian calculates the ground
state and ionization energies with chemical accuracy across various systems. On
the TinyMol dataset, we outperform the `gold-standard' CCSD(T) CBS reference
energies by 1.9m$E_h$ and reduce energy errors compared to previous generalized
neural wave functions by up to an order of magnitude.",2024-05-23,"Nicholas Gao, Stephan Günnemann",http://arxiv.org/pdf/2405.14762v3,cs.LG
Fault Tolerant ML: Efficient Meta-Aggregation and Synchronous Training,"In this paper, we investigate the challenging framework of Byzantine-robust
training in distributed machine learning (ML) systems, focusing on enhancing
both efficiency and practicality. As distributed ML systems become integral for
complex ML tasks, ensuring resilience against Byzantine failures-where workers
may contribute incorrect updates due to malice or error-gains paramount
importance. Our first contribution is the introduction of the Centered Trimmed
Meta Aggregator (CTMA), an efficient meta-aggregator that upgrades baseline
aggregators to optimal performance levels, while requiring low computational
demands. Additionally, we propose harnessing a recently developed gradient
estimation technique based on a double-momentum strategy within the Byzantine
context. Our paper highlights its theoretical and practical advantages for
Byzantine-robust training, especially in simplifying the tuning process and
reducing the reliance on numerous hyperparameters. The effectiveness of this
technique is supported by theoretical insights within the stochastic convex
optimization (SCO) framework and corroborated by empirical evidence.",2024-05-23,"Tehila Dahan, Kfir Y. Levy",http://arxiv.org/pdf/2405.14759v3,cs.LG
Axioms for AI Alignment from Human Feedback,"In the context of reinforcement learning from human feedback (RLHF), the
reward function is generally derived from maximum likelihood estimation of a
random utility model based on pairwise comparisons made by humans. The problem
of learning a reward function is one of preference aggregation that, we argue,
largely falls within the scope of social choice theory. From this perspective,
we can evaluate different aggregation methods via established axioms, examining
whether these methods meet or fail well-known standards. We demonstrate that
both the Bradley-Terry-Luce Model and its broad generalizations fail to meet
basic axioms. In response, we develop novel rules for learning reward functions
with strong axiomatic guarantees. A key innovation from the standpoint of
social choice is that our problem has a linear structure, which greatly
restricts the space of feasible rules and leads to a new paradigm that we call
linear social choice.",2024-05-23,"Luise Ge, Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira, Yevgeniy Vorobeychik, Junlin Wu",http://arxiv.org/pdf/2405.14758v2,cs.LG
Large language models can be zero-shot anomaly detectors for time series?,"Recent studies have shown the ability of large language models to perform a
variety of tasks, including time series forecasting. The flexible nature of
these models allows them to be used for many applications. In this paper, we
present a novel study of large language models used for the challenging task of
time series anomaly detection. This problem entails two aspects novel for LLMs:
the need for the model to identify part of the input sequence (or multiple
parts) as anomalous; and the need for it to work with time series data rather
than the traditional text input. We introduce sigllm, a framework for time
series anomaly detection using large language models. Our framework includes a
time-series-to-text conversion module, as well as end-to-end pipelines that
prompt language models to perform time series anomaly detection. We investigate
two paradigms for testing the abilities of large language models to perform the
detection task. First, we present a prompt-based detection method that directly
asks a language model to indicate which elements of the input are anomalies.
Second, we leverage the forecasting capability of a large language model to
guide the anomaly detection process. We evaluated our framework on 11 datasets
spanning various sources and 10 pipelines. We show that the forecasting method
significantly outperformed the prompting method in all 11 datasets with respect
to the F1 score. Moreover, while large language models are capable of finding
anomalies, state-of-the-art deep learning models are still superior in
performance, achieving results 30% better than large language models.",2024-05-23,"Sarah Alnegheimish, Linh Nguyen, Laure Berti-Equille, Kalyan Veeramachaneni",http://arxiv.org/pdf/2405.14755v3,cs.LG
Applied Machine Learning to Anomaly Detection in Enterprise Purchase Processes,"In a context of a continuous digitalisation of processes, organisations must
deal with the challenge of detecting anomalies that can reveal suspicious
activities upon an increasing volume of data. To pursue this goal, audit
engagements are carried out regularly, and internal auditors and purchase
specialists are constantly looking for new methods to automate these processes.
This work proposes a methodology to prioritise the investigation of the cases
detected in two large purchase datasets from real data. The goal is to
contribute to the effectiveness of the companies' control efforts and to
increase the performance of carrying out such tasks. A comprehensive
Exploratory Data Analysis is carried out before using unsupervised Machine
Learning techniques addressed to detect anomalies. A univariate approach has
been applied through the z-Score index and the DBSCAN algorithm, while a
multivariate analysis is implemented with the k-Means and Isolation Forest
algorithms, and the Silhouette index, resulting in each method having a
transaction candidates' proposal to be reviewed. An ensemble prioritisation of
the candidates is provided jointly with a proposal of explicability methods
(LIME, Shapley, SHAP) to help the company specialists in their understanding.",2024-05-23,"A. Herreros-Martínez, R. Magdalena-Benedicto, J. Vila-Francés, A. J. Serrano-López, S. Pérez-Díaz",http://arxiv.org/pdf/2405.14754v1,cs.LG
SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large Language Models,"Post-training quantization (PTQ) is an effective technique for compressing
large language models (LLMs). However, while uniform-precision quantization is
computationally efficient, it often compromises model performance. To address
this, we propose SliM-LLM, a salience-driven mixed-precision quantization
framework that allocates bit-widths at the group-wise. Our approach leverages
the observation that important weights follow a structured distribution and
introduces two key components: \textbf{1)} \textit{Salience-Determined Bit
Allocation} adaptively assigns bit-widths to groups within each layer based on
their salience; and \textbf{2)} \textit{Salience-Weighted Quantizer
Calibration} optimizes quantizer parameters by incorporating element-level
salience. With its structured partitioning, SliM-LLM provides a
hardware-friendly solution that matches the efficiency of uniform quantization
methods while improving accuracy. Experiments show that SliM-LLM achieves
superior performance across various LLMs at low bit-widths. For example, a
2-bit quantized LLaMA-7B model reduces memory usage by nearly 6x compared to
the floating-point baseline, decreases perplexity by 48\% compared to
state-of-the-art gradient-free PTQ methods, and maintains GPU inference speed.
Additionally, the extended version, SliM-LLM$^+$, which incorporates
gradient-based quantization, further reduces perplexity by 35.1\%. Our code is
available at https://github.com/Aaronhuang-778/SliM-LLM",2024-05-23,"Wei Huang, Haotong Qin, Yangdong Liu, Yawei Li, Qinshuo Liu, Xianglong Liu, Luca Benini, Michele Magno, Shiming Zhang, Xiaojuan Qi",http://arxiv.org/pdf/2405.14917v2,cs.LG
A Transformer-Based Approach for Smart Invocation of Automatic Code Completion,"Transformer-based language models are highly effective for code completion,
with much research dedicated to enhancing the content of these completions.
Despite their effectiveness, these models come with high operational costs and
can be intrusive, especially when they suggest too often and interrupt
developers who are concentrating on their work. Current research largely
overlooks how these models interact with developers in practice and neglects to
address when a developer should receive completion suggestions. To tackle this
issue, we developed a machine learning model that can accurately predict when
to invoke a code completion tool given the code context and available telemetry
data.
  To do so, we collect a dataset of 200k developer interactions with our
cross-IDE code completion plugin and train several invocation filtering models.
Our results indicate that our small-scale transformer model significantly
outperforms the baseline while maintaining low enough latency. We further
explore the search space for integrating additional telemetry data into a
pre-trained transformer directly and obtain promising results. To further
demonstrate our approach's practical potential, we deployed the model in an
online environment with 34 developers and provided real-world insights based on
74k actual invocations.",2024-05-23,"Aral de Moor, Arie van Deursen, Maliheh Izadi",http://arxiv.org/pdf/2405.14753v1,cs.LG
AGILE: A Novel Reinforcement Learning Framework of LLM Agents,"We introduce a novel reinforcement learning framework of LLM agents named
AGILE (AGent that Interacts and Learns from Environments) designed to perform
complex conversational tasks with users, leveraging LLMs, memory, tools, and
interactions with experts. The agent possesses capabilities beyond
conversation, including reflection, tool usage, and expert consultation. We
formulate the construction of such an LLM agent as a reinforcement learning
(RL) problem, in which the LLM serves as the policy model. We fine-tune the LLM
using labeled data of actions and the PPO algorithm. We focus on question
answering and release a dataset for agents called ProductQA, comprising
challenging questions in online shopping. Our extensive experiments on
ProductQA, MedMCQA and HotPotQA show that AGILE agents based on 7B and 13B LLMs
trained with PPO can outperform GPT-4 agents. Our ablation study highlights the
indispensability of memory, tools, consultation, reflection, and reinforcement
learning in achieving the agent's strong performance. Datasets and code are
available at https://github.com/bytarnish/AGILE.",2024-05-23,"Peiyuan Feng, Yichen He, Guanhua Huang, Yuan Lin, Hanchong Zhang, Yuchen Zhang, Hang Li",http://arxiv.org/pdf/2405.14751v2,cs.LG
Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams,"Solar flares, especially C, M, and X class, pose significant risks to
satellite operations, communication systems, and power grids. We present a
novel approach for predicting extreme solar flares using HMI intensitygrams and
magnetograms. By detecting sunspots from intensitygrams and extracting magnetic
field patches from magnetograms, we train a Residual Network (ResNet) to
classify extreme class flares. Our model demonstrates high accuracy, offering a
robust tool for predicting extreme solar flares and improving space weather
forecasting. Additionally, we show that HMI magnetograms provide more useful
data for deep learning compared to other SDO AIA images by better capturing
features critical for predicting flare magnitudes. This study underscores the
importance of identifying magnetic fields in solar flare prediction, marking a
significant advancement in solar activity prediction with practical
implications for mitigating space weather impacts.",2024-05-23,"Juyoung Yun, Jungmin Shin",http://arxiv.org/pdf/2405.14750v2,cs.LG
Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence,"Risk-sensitive reinforcement learning (RL) is crucial for maintaining
reliable performance in high-stakes applications. While traditional RL methods
aim to learn a point estimate of the random cumulative cost, distributional RL
(DRL) seeks to estimate the entire distribution of it, which leads to a unified
framework for handling different risk measures. However, developing policy
gradient methods for risk-sensitive DRL is inherently more complex as it
involves finding the gradient of a probability measure. This paper introduces a
new policy gradient method for risk-sensitive DRL with general coherent risk
measures, where we provide an analytical form of the probability measure's
gradient for any distribution. For practical use, we design a categorical
distributional policy gradient algorithm (CDPG) that approximates any
distribution by a categorical family supported on some fixed points. We further
provide a finite-support optimality guarantee and a finite-iteration
convergence guarantee under inexact policy evaluation and gradient estimation.
Through experiments on stochastic Cliffwalk and CartPole environments, we
illustrate the benefits of considering a risk-sensitive setting in DRL.",2024-05-23,"Minheng Xiao, Xian Yu, Lei Ying",http://arxiv.org/pdf/2405.14749v2,cs.LG
MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs,"Predicting future values in multivariate time series is vital across various
domains. This work explores the use of large language models (LLMs) for this
task. However, LLMs typically handle one-dimensional data. We introduce
MultiCast, a zero-shot LLM-based approach for multivariate time series
forecasting. It allows LLMs to receive multivariate time series as input,
through three novel token multiplexing solutions that effectively reduce
dimensionality while preserving key repetitive patterns. Additionally, a
quantization scheme helps LLMs to better learn these patterns, while
significantly reducing token use for practical applications. We showcase the
performance of our approach in terms of RMSE and execution time against
state-of-the-art approaches on three real-world datasets.",2024-05-23,"Georgios Chatzigeorgakidis, Konstantinos Lentzos, Dimitrios Skoutas",http://arxiv.org/pdf/2405.14748v1,cs.LG
AnyLoss: Transforming Classification Metrics into Loss Functions,"Many evaluation metrics can be used to assess the performance of models in
binary classification tasks. However, most of them are derived from a confusion
matrix in a non-differentiable form, making it very difficult to generate a
differentiable loss function that could directly optimize them. The lack of
solutions to bridge this challenge not only hinders our ability to solve
difficult tasks, such as imbalanced learning, but also requires the deployment
of computationally expensive hyperparameter search processes in model
selection. In this paper, we propose a general-purpose approach that transforms
any confusion matrix-based metric into a loss function, \textit{AnyLoss}, that
is available in optimization processes. To this end, we use an approximation
function to make a confusion matrix represented in a differentiable form, and
this approach enables any confusion matrix-based metric to be directly used as
a loss function. The mechanism of the approximation function is provided to
ensure its operability and the differentiability of our loss functions is
proved by suggesting their derivatives. We conduct extensive experiments under
diverse neural networks with many datasets, and we demonstrate their general
availability to target any confusion matrix-based metrics. Our method,
especially, shows outstanding achievements in dealing with imbalanced datasets,
and its competitive learning speed, compared to multiple baseline models,
underscores its efficiency.",2024-05-23,"Doheon Han, Nuno Moniz, Nitesh V Chawla",http://arxiv.org/pdf/2405.14745v1,cs.LG
Iterative Causal Segmentation: Filling the Gap between Market Segmentation and Marketing Strategy,"The field of causal Machine Learning (ML) has made significant strides in
recent years. Notable breakthroughs include methods such as meta learners
(arXiv:1706.03461v6) and heterogeneous doubly robust estimators
(arXiv:2004.14497) introduced in the last five years. Despite these
advancements, the field still faces challenges, particularly in managing
tightly coupled systems where both the causal treatment variable and a
confounding covariate must serve as key decision-making indicators. This
scenario is common in applications of causal ML for marketing, such as
marketing segmentation and incremental marketing uplift. In this work, we
present our formally proven algorithm, iterative causal segmentation, to
address this issue.",2024-05-23,"Kaihua Ding, Jingsong Cui, Mohammad Soltani, Jing Jin",http://arxiv.org/pdf/2405.14743v1,cs.LG
HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph Representation Learning,"Graph Auto-Encoders (GAEs) are powerful tools for graph representation
learning. In this paper, we develop a novel Hierarchical Cluster-based GAE
(HC-GAE), that can learn effective structural characteristics for graph data
analysis. To this end, during the encoding process, we commence by utilizing
the hard node assignment to decompose a sample graph into a family of separated
subgraphs. We compress each subgraph into a coarsened node, transforming the
original graph into a coarsened graph. On the other hand, during the decoding
process, we adopt the soft node assignment to reconstruct the original graph
structure by expanding the coarsened nodes. By hierarchically performing the
above compressing procedure during the decoding process as well as the
expanding procedure during the decoding process, the proposed HC-GAE can
effectively extract bidirectionally hierarchical structural features of the
original sample graph. Furthermore, we re-design the loss function that can
integrate the information from either the encoder or the decoder. Since the
associated graph convolution operation of the proposed HC-GAE is restricted in
each individual separated subgraph and cannot propagate the node information
between different subgraphs, the proposed HC-GAE can significantly reduce the
over-smoothing problem arising in the classical convolution-based GAEs. The
proposed HC-GAE can generate effective representations for either node
classification or graph classification, and the experiments demonstrate the
effectiveness on real-world datasets.",2024-05-23,"Zhuo Xu, Lu Bai, Lixin Cui, Ming Li, Yue Wang, Edwin R. Hancock",http://arxiv.org/pdf/2405.14742v1,cs.LG
Subsampled Ensemble Can Improve Generalization Tail Exponentially,"Ensemble learning is a popular technique to improve the accuracy of machine
learning models. It traditionally hinges on the rationale that aggregating
multiple weak models can lead to better models with lower variance and hence
higher stability, especially for discontinuous base learners. In this paper, we
provide a new perspective on ensembling. By selecting the best model trained on
subsamples via majority voting, we can attain exponentially decaying tails for
the excess risk, even if the base learner suffers from slow (i.e., polynomial)
decay rates. This tail enhancement power of ensembling is agnostic to the
underlying base learner and is stronger than variance reduction in the sense of
exhibiting rate improvement. We demonstrate how our ensemble methods can
substantially improve out-of-sample performances in a range of numerical
examples involving heavy-tailed data or intrinsically slow rates. Code for the
proposed methods is available at https://github.com/mickeyhqian/VoteEnsemble.",2024-05-23,"Huajie Qian, Donghao Ying, Henry Lam, Wotao Yin",http://arxiv.org/pdf/2405.14741v4,cs.LG
GIFT: Unlocking Full Potential of Labels in Distilled Dataset at Near-zero Cost,"Recent advancements in dataset distillation have demonstrated the significant
benefits of employing soft labels generated by pre-trained teacher models. In
this paper, we introduce a novel perspective by emphasizing the full
utilization of labels. We first conduct a comprehensive comparison of various
loss functions for soft label utilization in dataset distillation, revealing
that the model trained on the synthetic dataset exhibits high sensitivity to
the choice of loss function for soft label utilization. This finding highlights
the necessity of a universal loss function for training models on synthetic
datasets. Building on these insights, we introduce an extremely simple yet
surprisingly effective plug-and-play approach, GIFT, which encompasses soft
label refinement and a cosine similarity-based loss function to efficiently
leverage full label information. Extensive experiments indicate that GIFT
consistently enhances state-of-the-art dataset distillation methods across
various dataset scales, without incurring additional computational costs.
Importantly, GIFT significantly enhances cross-optimizer generalization, an
area previously overlooked. For instance, on ImageNet-1K with IPC = 10, GIFT
enhances the state-of-the-art method RDED by 30.8% in cross-optimizer
generalization. Our code is available at https://github.com/LINs-lab/GIFT.",2024-05-23,"Xinyi Shang, Peng Sun, Tao Lin",http://arxiv.org/pdf/2405.14736v2,cs.LG
SimPO: Simple Preference Optimization with a Reference-Free Reward,"Direct Preference Optimization (DPO) is a widely used offline preference
optimization algorithm that reparameterizes reward functions in reinforcement
learning from human feedback (RLHF) to enhance simplicity and training
stability. In this work, we propose SimPO, a simpler yet more effective
approach. The effectiveness of SimPO is attributed to a key design: using the
average log probability of a sequence as the implicit reward. This reward
formulation better aligns with model generation and eliminates the need for a
reference model, making it more compute and memory efficient. Additionally, we
introduce a target reward margin to the Bradley-Terry objective to encourage a
larger margin between the winning and losing responses, further improving the
algorithm's performance. We compare SimPO to DPO and its latest variants across
various state-of-the-art training setups, including both base and
instruction-tuned models such as Mistral, Llama 3, and Gemma 2. We evaluate on
extensive chat-based evaluation benchmarks, including AlpacaEval 2, MT-Bench,
and Arena-Hard. Our results demonstrate that SimPO consistently and
significantly outperforms existing approaches without substantially increasing
response length. Specifically, SimPO outperforms DPO by up to 6.4 points on
AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our top-performing model,
built on Gemma-2-9B-it, achieves a 72.4% length-controlled win rate on
AlpacaEval 2, a 59.1% win rate on Arena-Hard, and ranks 1st on Chatbot Arena
among <10B models with real user votes.",2024-05-23,"Yu Meng, Mengzhou Xia, Danqi Chen",http://arxiv.org/pdf/2405.14734v3,cs.LG
Embedding Compression for Efficient Re-Identification,"Real world re-identfication (ReID) algorithms aim to map new observations of
an object to previously recorded instances. These systems are often constrained
by quantity and size of the stored embeddings. To combat this scaling problem,
we attempt to shrink the size of these vectors by using a variety of
compression techniques. In this paper, we benchmark quantization-aware-training
along with three different dimension reduction methods: iterative structured
pruning, slicing the embeddings at initialize, and using low rank embeddings.
We find that ReID embeddings can be compressed by up to 96x with minimal drop
in performance. This implies that modern re-identification paradigms do not
fully leverage the high dimensional latent space, opening up further research
to increase the capabilities of these systems.",2024-05-23,Luke McDermott,http://arxiv.org/pdf/2405.14730v1,cs.LG
Intervention and Conditioning in Causal Bayesian Networks,"Causal models are crucial for understanding complex systems and identifying
causal relationships among variables. Even though causal models are extremely
popular, conditional probability calculation of formulas involving
interventions pose significant challenges. In case of Causal Bayesian Networks
(CBNs), Pearl assumes autonomy of mechanisms that determine interventions to
calculate a range of probabilities. We show that by making simple yet often
realistic independence assumptions, it is possible to uniquely estimate the
probability of an interventional formula (including the well-studied notions of
probability of sufficiency and necessity). We discuss when these assumptions
are appropriate. Importantly, in many cases of interest, when the assumptions
are appropriate, these probability estimates can be evaluated using
observational data, which carries immense significance in scenarios where
conducting experiments is impractical or unfeasible.",2024-05-23,"Sainyam Galhotra, Joseph Y. Halpern",http://arxiv.org/pdf/2405.14728v1,cs.LG
A Systematic and Formal Study of the Impact of Local Differential Privacy on Fairness: Preliminary Results,"Machine learning (ML) algorithms rely primarily on the availability of
training data, and, depending on the domain, these data may include sensitive
information about the data providers, thus leading to significant privacy
issues. Differential privacy (DP) is the predominant solution for
privacy-preserving ML, and the local model of DP is the preferred choice when
the server or the data collector are not trusted. Recent experimental studies
have shown that local DP can impact ML prediction for different subgroups of
individuals, thus affecting fair decision-making. However, the results are
conflicting in the sense that some studies show a positive impact of privacy on
fairness while others show a negative one. In this work, we conduct a
systematic and formal study of the effect of local DP on fairness.
Specifically, we perform a quantitative study of how the fairness of the
decisions made by the ML model changes under local DP for different levels of
privacy and data distributions. In particular, we provide bounds in terms of
the joint distributions and the privacy level, delimiting the extent to which
local DP can impact the fairness of the model. We characterize the cases in
which privacy reduces discrimination and those with the opposite effect. We
validate our theoretical findings on synthetic and real-world datasets. Our
results are preliminary in the sense that, for now, we study only the case of
one sensitive attribute, and only statistical disparity, conditional
statistical disparity, and equal opportunity difference.",2024-05-23,"Karima Makhlouf, Tamara Stefanovic, Heber H. Arcolezi, Catuscia Palamidessi",http://arxiv.org/pdf/2405.14725v1,cs.LG
Decision-Focused Forecasting: Decision Losses for Multistage Optimisation,"Decision-focused learning has emerged as a promising approach for decision
making under uncertainty by training the upstream predictive aspect of the
pipeline with respect to the quality of the downstream decisions. Most existing
work has focused on single stage problems. Many real-world decision problems
are more appropriately modelled using multistage optimisation as contextual
information such as prices or demand is revealed over time and decisions now
have a bearing on future decisions. We propose decision-focused forecasting, a
multiple-implicitlayer model which in its training accounts for the
intertemporal decision effects of forecasts using differentiable optimisation.
The recursive model reflects a fully differentiable multistage optimisation
approach. We present an analysis of the gradients produced by this model
showing the adjustments made to account for the state-path caused by
forecasting. We demonstrate an application of the model to an energy storage
arbitrage task and report that our model outperforms existing approaches.",2024-05-23,"Egon Peršak, Miguel F. Anjos",http://arxiv.org/pdf/2405.14719v1,cs.LG
Defining error accumulation in ML atmospheric simulators,"Machine learning (ML) has recently shown significant promise in modelling
atmospheric systems, such as the weather. Many of these ML models are
autoregressive, and error accumulation in their forecasts is a key problem.
However, there is no clear definition of what `error accumulation' actually
entails. In this paper, we propose a definition and an associated metric to
measure it. Our definition distinguishes between errors which are due to model
deficiencies, which we may hope to fix, and those due to the intrinsic
properties of atmospheric systems (chaos, unobserved variables), which are not
fixable. We illustrate the usefulness of this definition by proposing a simple
regularization loss penalty inspired by it. This approach shows performance
improvements (according to RMSE and spread/skill) in a selection of atmospheric
systems, including the real-world weather prediction task.",2024-05-23,"Raghul Parthipan, Mohit Anand, Hannah M. Christensen, J. Scott Hosking, Damon J. Wischik",http://arxiv.org/pdf/2405.14714v1,cs.LG
Cascade of phase transitions in the training of Energy-based models,"In this paper, we investigate the feature encoding process in a prototypical
energy-based generative model, the Restricted Boltzmann Machine (RBM). We start
with an analytical investigation using simplified architectures and data
structures, and end with numerical analysis of real trainings on real datasets.
Our study tracks the evolution of the model's weight matrix through its
singular value decomposition, revealing a series of phase transitions
associated to a progressive learning of the principal modes of the empirical
probability distribution. The model first learns the center of mass of the
modes and then progressively resolve all modes through a cascade of phase
transitions. We first describe this process analytically in a controlled setup
that allows us to study analytically the training dynamics. We then validate
our theoretical results by training the Bernoulli-Bernoulli RBM on real data
sets. By using data sets of increasing dimension, we show that learning indeed
leads to sharp phase transitions in the high-dimensional limit. Moreover, we
propose and test a mean-field finite-size scaling hypothesis. This shows that
the first phase transition is in the same universality class of the one we
studied analytically, and which is reminiscent of the mean-field
paramagnetic-to-ferromagnetic phase transition.",2024-05-23,"Dimitrios Bachtis, Giulio Biroli, Aurélien Decelle, Beatriz Seoane",http://arxiv.org/pdf/2405.14689v4,cs.LG
Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss,"PAC-Bayesian analysis is a frequentist framework for incorporating prior
knowledge into learning. It was inspired by Bayesian learning, which allows
sequential data processing and naturally turns posteriors from one processing
step into priors for the next. However, despite two and a half decades of
research, the ability to update priors sequentially without losing confidence
information along the way remained elusive for PAC-Bayes. While PAC-Bayes
allows construction of data-informed priors, the final confidence intervals
depend only on the number of points that were not used for the construction of
the prior, whereas confidence information in the prior, which is related to the
number of points used to construct the prior, is lost. This limits the
possibility and benefit of sequential prior updates, because the final bounds
depend only on the size of the final batch.
  We present a novel and, in retrospect, surprisingly simple and powerful
PAC-Bayesian procedure that allows sequential prior updates with no information
loss. The procedure is based on a novel decomposition of the expected loss of
randomized classifiers. The decomposition rewrites the loss of the posterior as
an excess loss relative to a downscaled loss of the prior plus the downscaled
loss of the prior, which is bounded recursively. As a side result, we also
present a generalization of the split-kl and PAC-Bayes-split-kl inequalities to
discrete random variables, which we use for bounding the excess losses, and
which can be of independent interest. In empirical evaluation the new procedure
significantly outperforms state-of-the-art.",2024-05-23,"Yi-Shan Wu, Yijie Zhang, Badr-Eddine Chérief-Abdellatif, Yevgeny Seldin",http://arxiv.org/pdf/2405.14681v3,cs.LG
RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance,"Customizing diffusion models to generate identity-preserving images from
user-provided reference images is an intriguing new problem. The prevalent
approaches typically require training on extensive domain-specific images to
achieve identity preservation, which lacks flexibility across different use
cases. To address this issue, we exploit classifier guidance, a training-free
technique that steers diffusion models using an existing classifier, for
personalized image generation. Our study shows that based on a recent rectified
flow framework, the major limitation of vanilla classifier guidance in
requiring a special classifier can be resolved with a simple fixed-point
solution, allowing flexible personalization with off-the-shelf image
discriminators. Moreover, its solving procedure proves to be stable when
anchored to a reference flow trajectory, with a convergence guarantee. The
derived method is implemented on rectified flow with different off-the-shelf
image discriminators, delivering advantageous personalization results for human
faces, live subjects, and certain objects. Code is available at
https://github.com/feifeiobama/RectifID.",2024-05-23,"Zhicheng Sun, Zhenhao Yang, Yang Jin, Haozhe Chi, Kun Xu, Kun Xu, Liwei Chen, Hao Jiang, Yang Song, Kun Gai, Yadong Mu",http://arxiv.org/pdf/2405.14677v4,cs.LG
Overcoming the Challenges of Batch Normalization in Federated Learning,"Batch normalization has proven to be a very beneficial mechanism to
accelerate the training and improve the accuracy of deep neural networks in
centralized environments. Yet, the scheme faces significant challenges in
federated learning, especially under high data heterogeneity. Essentially, the
main challenges arise from external covariate shifts and inconsistent
statistics across clients. We introduce in this paper Federated BatchNorm
(FBN), a novel scheme that restores the benefits of batch normalization in
federated learning. Essentially, FBN ensures that the batch normalization
during training is consistent with what would be achieved in a centralized
execution, hence preserving the distribution of the data, and providing running
statistics that accurately approximate the global statistics. FBN thereby
reduces the external covariate shift and matches the evaluation performance of
the centralized setting. We also show that, with a slight increase in
complexity, we can robustify FBN to mitigate erroneous statistics and
potentially adversarial attacks.",2024-05-23,"Rachid Guerraoui, Rafael Pinot, Geovani Rizk, John Stephan, François Taiani",http://arxiv.org/pdf/2405.14670v1,cs.LG
Efficiency for Free: Ideal Data Are Transportable Representations,"Data, the seminal opportunity and challenge in modern machine learning,
currently constrains the scalability of representation learning and impedes the
pace of model evolution. In this work, we investigate the efficiency properties
of data from both optimization and generalization perspectives. Our theoretical
and empirical analysis reveals an unexpected finding: for a given task,
utilizing a publicly available, task- and architecture-agnostic model (referred
to as the `prior model' in this paper) can effectively produce efficient data.
Building on this insight, we propose the Representation Learning Accelerator
(\algopt), which promotes the formation and utilization of efficient data,
thereby accelerating representation learning. Utilizing a ResNet-18 pre-trained
on CIFAR-10 as a prior model to inform ResNet-50 training on ImageNet-1K
reduces computational costs by 50% while maintaining the same accuracy as the
model trained with the original BYOL, which requires 100% cost. Our code is
available at: \url{https://github.com/LINs-lab/ReLA}.",2024-05-23,"Peng Sun, Yi Jiang, Tao Lin",http://arxiv.org/pdf/2405.14669v2,cs.LG
Fisher Flow Matching for Generative Modeling over Discrete Data,"Generative modeling over discrete data has recently seen numerous success
stories, with applications spanning language modeling, biological sequence
design, and graph-structured molecular data. The predominant generative
modeling paradigm for discrete data is still autoregressive, with more recent
alternatives based on diffusion or flow-matching falling short of their
impressive performance in continuous data settings, such as image or video
generation. In this work, we introduce Fisher-Flow, a novel flow-matching model
for discrete data. Fisher-Flow takes a manifestly geometric perspective by
considering categorical distributions over discrete data as points residing on
a statistical manifold equipped with its natural Riemannian metric: the
$\textit{Fisher-Rao metric}$. As a result, we demonstrate discrete data itself
can be continuously reparameterised to points on the positive orthant of the
$d$-hypersphere $\mathbb{S}^d_+$, which allows us to define flows that map any
source distribution to target in a principled manner by transporting mass along
(closed-form) geodesics of $\mathbb{S}^d_+$. Furthermore, the learned flows in
Fisher-Flow can be further bootstrapped by leveraging Riemannian optimal
transport leading to improved training dynamics. We prove that the gradient
flow induced by Fisher-Flow is optimal in reducing the forward KL divergence.
We evaluate Fisher-Flow on an array of synthetic and diverse real-world
benchmarks, including designing DNA Promoter, and DNA Enhancer sequences.
Empirically, we find that Fisher-Flow improves over prior diffusion and
flow-matching models on these benchmarks.",2024-05-23,"Oscar Davis, Samuel Kessler, Mircea Petrache, İsmail İlkan Ceylan, Michael Bronstein, Avishek Joey Bose",http://arxiv.org/pdf/2405.14664v4,cs.LG
Implicit In-context Learning,"In-context Learning (ICL) empowers large language models (LLMs) to swiftly
adapt to unseen tasks at inference-time by prefixing a few demonstration
examples before queries. Despite its versatility, ICL incurs substantial
computational and memory overheads compared to zero-shot learning and is
sensitive to the selection and order of demonstration examples. In this work,
we introduce Implicit In-context Learning (I2CL), an innovative paradigm that
reduces the inference cost of ICL to that of zero-shot learning with minimal
information loss. I2CL operates by first generating a condensed vector
representation, namely a context vector, extracted from the demonstration
examples. It then conducts an inference-time intervention through injecting a
linear combination of the context vector and query activations back into the
model's residual streams. Empirical evaluation on nine real-world tasks across
three model architectures demonstrates that I2CL achieves few-shot level
performance at zero-shot inference cost, and it exhibits robustness against
variations in demonstration examples. Furthermore, I2CL facilitates a novel
representation of task-ids, enhancing task similarity detection and fostering
effective transfer learning. We also perform a comprehensive analysis and
ablation study on I2CL, offering deeper insights into its internal mechanisms.
Code is available at https://github.com/LzVv123456/I2CL.",2024-05-23,"Zhuowei Li, Zihao Xu, Ligong Han, Yunhe Gao, Song Wen, Di Liu, Hao Wang, Dimitris N. Metaxas",http://arxiv.org/pdf/2405.14660v2,cs.LG
Heteroscedastic Preferential Bayesian Optimization with Informative Noise Distributions,"Preferential Bayesian optimization (PBO) is a sample-efficient framework for
learning human preferences between candidate designs. PBO classically relies on
homoscedastic noise models to represent human aleatoric uncertainty. Yet, such
noise fails to accurately capture the varying levels of human aleatoric
uncertainty, particularly when the user possesses partial knowledge among
different pairs of candidates. For instance, a chemist with solid expertise in
glucose-related molecules may easily compare two compounds from that family
while struggling to compare alcohol-related molecules. Currently, PBO overlooks
this uncertainty during the search for a new candidate through the maximization
of the acquisition function, consequently underestimating the risk associated
with human uncertainty. To address this issue, we propose a heteroscedastic
noise model to capture human aleatoric uncertainty. This model adaptively
assigns noise levels based on the distance of a specific input to a predefined
set of reliable inputs known as anchors provided by the human. Anchors
encapsulate partial knowledge and offer insight into the comparative difficulty
of evaluating different candidate pairs. Such a model can be seamlessly
integrated into the acquisition function, thus leading to candidate design
pairs that elegantly trade informativeness and ease of comparison for the human
expert. We perform an extensive empirical evaluation of the proposed approach,
demonstrating a consistent improvement over homoscedastic PBO.",2024-05-23,"Marshal Arijona Sinaga, Julien Martinelli, Vikas Garg, Samuel Kaski",http://arxiv.org/pdf/2405.14657v1,cs.LG
Multi-turn Reinforcement Learning from Preference Human Feedback,"Reinforcement Learning from Human Feedback (RLHF) has become the standard
approach for aligning Large Language Models (LLMs) with human preferences,
allowing LLMs to demonstrate remarkable abilities in various tasks. Existing
methods work by emulating the preferences at the single decision (turn) level,
limiting their capabilities in settings that require planning or multi-turn
interactions to achieve a long-term goal. In this paper, we address this issue
by developing novel methods for Reinforcement Learning (RL) from preference
feedback between two full multi-turn conversations. In the tabular setting, we
present a novel mirror-descent-based policy optimization algorithm for the
general multi-turn preference-based RL problem, and prove its convergence to
Nash equilibrium. To evaluate performance, we create a new environment,
Education Dialogue, where a teacher agent guides a student in learning a random
topic, and show that a deep RL variant of our algorithm outperforms RLHF
baselines. Finally, we show that in an environment with explicit rewards, our
algorithm recovers the same performance as a reward-based RL baseline, despite
relying solely on a weaker preference signal.",2024-05-23,"Lior Shani, Aviv Rosenberg, Asaf Cassel, Oran Lang, Daniele Calandriello, Avital Zipori, Hila Noga, Orgad Keller, Bilal Piot, Idan Szpektor, Avinatan Hassidim, Yossi Matias, Rémi Munos",http://arxiv.org/pdf/2405.14655v2,cs.LG
PhiNets: Brain-inspired Non-contrastive Learning Based on Temporal Prediction Hypothesis,"Predictive coding is a theory which hypothesises that cortex predicts sensory
inputs at various levels of abstraction to minimise prediction errors. Inspired
by predictive coding, Chen et al. (2024) proposed another theory, temporal
prediction hypothesis, to claim that sequence memory residing in hippocampus
has emerged through predicting input signals from the past sensory inputs.
Specifically, they supposed that the CA3 predictor in hippocampus creates
synaptic delay between input signals, which is compensated by the following CA1
predictor. Though recorded neural activities were replicated based on the
temporal prediction hypothesis, its validity has not been fully explored. In
this work, we aim to explore the temporal prediction hypothesis from the
perspective of self-supervised learning. Specifically, we focus on
non-contrastive learning, which generates two augmented views of an input image
and predicts one from another. Non-contrastive learning is intimately related
to the temporal prediction hypothesis because the synaptic delay is implicitly
created by StopGradient. Building upon a popular non-contrastive learner,
SimSiam, we propose PhiNet, an extension of SimSiam to have two predictors
explicitly corresponding to the CA3 and CA1, respectively. Through studying the
PhiNet model, we discover two findings. First, meaningful data representations
emerge in PhiNet more stably than in SimSiam. This is initially supported by
our learning dynamics analysis: PhiNet is more robust to the representational
collapse. Second, PhiNet adapts more quickly to newly incoming patterns in
online and continual learning scenarios. For practitioners, we additionally
propose an extension called X-PhiNet integrated with a momentum encoder,
excelling in continual learning. All in all, our work reveals that the temporal
prediction hypothesis is a reasonable model in terms of the robustness and
adaptivity.",2024-05-23,"Satoki Ishikawa, Makoto Yamada, Han Bao, Yuki Takezawa",http://arxiv.org/pdf/2405.14650v2,cs.LG
Lagrangian Neural Networks for Reversible Dissipative Evolution,"There is a growing attention given to utilizing Lagrangian and Hamiltonian
mechanics with network training in order to incorporate physics into the
network. Most commonly, conservative systems are modeled, in which there are no
frictional losses, so the system may be run forward and backward in time
without requiring regularization. This work addresses systems in which the
reverse direction is ill-posed because of the dissipation that occurs in
forward evolution. The novelty is the use of Morse-Feshbach Lagrangian, which
models dissipative dynamics by doubling the number of dimensions of the system
in order to create a mirror latent representation that would counterbalance the
dissipation of the observable system, making it a conservative system, albeit
embedded in a larger space. We start with their formal approach by redefining a
new Dissipative Lagrangian, such that the unknown matrices in the
Euler-Lagrange's equations arise as partial derivatives of the Lagrangian with
respect to only the observables. We then train a network from simulated
training data for dissipative systems such as Fickian diffusion that arise in
materials sciences. It is shown by experiments that the systems can be evolved
in both forward and reverse directions without regularization beyond that
provided by the Morse-Feshbach Lagrangian. Experiments of dissipative systems,
such as Fickian diffusion, demonstrate the degree to which dynamics can be
reversed.",2024-05-23,"Veera Sundararaghavan, Megna N. Shah, Jeff P. Simmons",http://arxiv.org/pdf/2405.14645v2,cs.LG
DLPO: Diffusion Model Loss-Guided Reinforcement Learning for Fine-Tuning Text-to-Speech Diffusion Models,"Recent advancements in generative models have sparked a significant interest
within the machine learning community. Particularly, diffusion models have
demonstrated remarkable capabilities in synthesizing images and speech. Studies
such as those by Lee et al. (2023), Black et al. (2023), Wang et al. (2023),
and Fan et al. (2024) illustrate that Reinforcement Learning with Human
Feedback (RLHF) can enhance diffusion models for image synthesis. However, due
to architectural differences between these models and those employed in speech
synthesis, it remains uncertain whether RLHF could similarly benefit speech
synthesis models. In this paper, we explore the practical application of RLHF
to diffusion-based text-to-speech synthesis, leveraging the mean opinion score
(MOS) as predicted by UTokyo-SaruLab MOS prediction system (Saeki et al., 2022)
as a proxy loss. We introduce diffusion model loss-guided RL policy
optimization (DLPO) and compare it against other RLHF approaches, employing the
NISQA speech quality and naturalness assessment model (Mittag et al., 2021) and
human preference experiments for further evaluation. Our results show that RLHF
can enhance diffusion-based text-to-speech synthesis models, and, moreover,
DLPO can better improve diffusion models in generating natural and high quality
speech audios.",2024-05-23,"Jingyi Chen, Ju-Seung Byun, Micha Elsner, Andrew Perrault",http://arxiv.org/pdf/2405.14632v2,cs.LG
Bounds for the smallest eigenvalue of the NTK for arbitrary spherical data of arbitrary dimension,"Bounds on the smallest eigenvalue of the neural tangent kernel (NTK) are a
key ingredient in the analysis of neural network optimization and memorization.
However, existing results require distributional assumptions on the data and
are limited to a high-dimensional setting, where the input dimension $d_0$
scales at least logarithmically in the number of samples $n$. In this work we
remove both of these requirements and instead provide bounds in terms of a
measure of the collinearity of the data: notably these bounds hold with high
probability even when $d_0$ is held constant versus $n$. We prove our results
through a novel application of the hemisphere transform.",2024-05-23,"Kedar Karhadkar, Michael Murray, Guido Montúfar",http://arxiv.org/pdf/2405.14630v1,cs.LG
Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences,"In reinforcement learning (RL) with experience replay, experiences stored in
a replay buffer influence the RL agent's performance. Information about how
these experiences influence the agent's performance is valuable for various
purposes, such as identifying experiences that negatively influence
underperforming agents. One method for estimating the influence of experiences
is the leave-one-out (LOO) method. However, this method is usually
computationally prohibitive. In this paper, we present Policy Iteration with
Turn-over Dropout (PIToD), which efficiently estimates the influence of
experiences. We evaluate how accurately PIToD estimates the influence of
experiences and its efficiency compared to LOO. We then apply PIToD to amend
underperforming RL agents, i.e., we use PIToD to estimate negatively
influential experiences for the RL agents and to delete the influence of these
experiences. We show that RL agents' performance is significantly improved via
amendments with PIToD.",2024-05-23,"Takuya Hiraoka, Guanquan Wang, Takashi Onishi, Yoshimasa Tsuruoka",http://arxiv.org/pdf/2405.14629v2,cs.LG
U-TELL: Unsupervised Task Expert Lifelong Learning,"Continual learning (CL) models are designed to learn new tasks arriving
sequentially without re-training the network. However, real-world ML
applications have very limited label information and these models suffer from
catastrophic forgetting. To address these issues, we propose an unsupervised CL
model with task experts called Unsupervised Task Expert Lifelong Learning
(U-TELL) to continually learn the data arriving in a sequence addressing
catastrophic forgetting. During training of U-TELL, we introduce a new expert
on arrival of a new task. Our proposed architecture has task experts, a
structured data generator and a task assigner. Each task expert is composed of
3 blocks; i) a variational autoencoder to capture the task distribution and
perform data abstraction, ii) a k-means clustering module, and iii) a structure
extractor to preserve latent task data signature. During testing, task assigner
selects a suitable expert to perform clustering. U-TELL does not store or
replay task samples, instead, we use generated structured samples to train the
task assigner. We compared U-TELL with five SOTA unsupervised CL methods.
U-TELL outperformed all baselines on seven benchmarks and one industry dataset
for various CL scenarios with a training time over 6 times faster than the best
performing baseline.",2024-05-23,"Indu Solomon, Aye Phyu Phyu Aung, Uttam Kumar, Senthilnath Jayavelu",http://arxiv.org/pdf/2405.14623v2,cs.LG
Calibrated Self-Rewarding Vision Language Models,"Large Vision-Language Models (LVLMs) have made substantial progress by
integrating pre-trained large language models (LLMs) and vision models through
instruction tuning. Despite these advancements, LVLMs often exhibit the
hallucination phenomenon, where generated text responses appear linguistically
plausible but contradict the input image, indicating a misalignment between
image and text pairs. This misalignment arises because the model tends to
prioritize textual information over visual input, even when both the language
model and visual representations are of high quality. Existing methods leverage
additional models or human annotations to curate preference data and enhance
modality alignment through preference optimization. These approaches may not
effectively reflect the target LVLM's preferences, making the curated
preferences easily distinguishable. Our work addresses these challenges by
proposing the Calibrated Self-Rewarding (CSR) approach, which enables the model
to self-improve by iteratively generating candidate responses, evaluating the
reward for each response, and curating preference data for fine-tuning. In the
reward modeling, we employ a step-wise strategy and incorporate visual
constraints into the self-rewarding process to place greater emphasis on visual
input. Empirical results demonstrate that CSR enhances performance and reduces
hallucinations across ten benchmarks and tasks, achieving substantial
improvements over existing methods by 7.62%. Our empirical results are further
supported by rigorous theoretical analysis, under mild assumptions, verifying
the effectiveness of introducing visual constraints into the self-rewarding
paradigm. Additionally, CSR shows compatibility with different vision-language
models and the ability to incrementally improve performance through iterative
fine-tuning. Our data and code are available at
https://github.com/YiyangZhou/CSR.",2024-05-23,"Yiyang Zhou, Zhiyuan Fan, Dongjie Cheng, Sihan Yang, Zhaorun Chen, Chenhang Cui, Xiyao Wang, Yun Li, Linjun Zhang, Huaxiu Yao",http://arxiv.org/pdf/2405.14622v4,cs.LG
Closed-form Solutions: A New Perspective on Solving Differential Equations,"The pursuit of analytical solutions for differential equations has
historically been limited by the need for extensive prior knowledge and
mathematical prowess; however, machine learning methods like genetic algorithms
have recently been applied to this end, albeit with issues of significant time
consumption and complexity. This paper presents a novel machine learning-based
solver, SSDE (Symbolic Solver for Differential Equations), which employs
reinforcement learning to derive symbolic closed-form solutions for various
differential equations. Our evaluations on a range of ordinary and partial
differential equations demonstrate that SSDE provides superior performance in
achieving analytical solutions compared to other machine learning approaches.",2024-05-23,"Shu Wei, Yanjie Li, Lina Yu, Weijun Li, Min Wu, Linjun Sun, Jufeng Han, Yan Pang",http://arxiv.org/pdf/2405.14620v2,cs.LG
TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting,"Time series forecasting is widely used in extensive applications, such as
traffic planning and weather forecasting. However, real-world time series
usually present intricate temporal variations, making forecasting extremely
challenging. Going beyond the mainstream paradigms of plain decomposition and
multiperiodicity analysis, we analyze temporal variations in a novel view of
multiscale-mixing, which is based on an intuitive but important observation
that time series present distinct patterns in different sampling scales. The
microscopic and the macroscopic information are reflected in fine and coarse
scales respectively, and thereby complex variations can be inherently
disentangled. Based on this observation, we propose TimeMixer as a fully
MLP-based architecture with Past-Decomposable-Mixing (PDM) and
Future-Multipredictor-Mixing (FMM) blocks to take full advantage of
disentangled multiscale series in both past extraction and future prediction
phases. Concretely, PDM applies the decomposition to multiscale series and
further mixes the decomposed seasonal and trend components in fine-to-coarse
and coarse-to-fine directions separately, which successively aggregates the
microscopic seasonal and macroscopic trend information. FMM further ensembles
multiple predictors to utilize complementary forecasting capabilities in
multiscale observations. Consequently, TimeMixer is able to achieve consistent
state-of-the-art performances in both long-term and short-term forecasting
tasks with favorable run-time efficiency.",2024-05-23,"Shiyu Wang, Haixu Wu, Xiaoming Shi, Tengge Hu, Huakun Luo, Lintao Ma, James Y. Zhang, Jun Zhou",http://arxiv.org/pdf/2405.14616v1,cs.LG
ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification,"Multivariate time series classification (MTSC) has attracted significant
research attention due to its diverse real-world applications. Recently,
exploiting transformers for MTSC has achieved state-of-the-art performance.
However, existing methods focus on generic features, providing a comprehensive
understanding of data, but they ignore class-specific features crucial for
learning the representative characteristics of each class. This leads to poor
performance in the case of imbalanced datasets or datasets with similar overall
patterns but differing in minor class-specific details. In this paper, we
propose a novel Shapelet Transformer (ShapeFormer), which comprises
class-specific and generic transformer modules to capture both of these
features. In the class-specific module, we introduce the discovery method to
extract the discriminative subsequences of each class (i.e. shapelets) from the
training set. We then propose a Shapelet Filter to learn the difference
features between these shapelets and the input time series. We found that the
difference feature for each shapelet contains important class-specific
features, as it shows a significant distinction between its class and others.
In the generic module, convolution filters are used to extract generic features
that contain information to distinguish among all classes. For each module, we
employ the transformer encoder to capture the correlation between their
features. As a result, the combination of two transformer modules allows our
model to exploit the power of both types of features, thereby enhancing the
classification performance. Our experiments on 30 UEA MTSC datasets demonstrate
that ShapeFormer has achieved the highest accuracy ranking compared to
state-of-the-art methods. The code is available at
https://github.com/xuanmay2701/shapeformer.",2024-05-23,"Xuan-May Le, Ling Luo, Uwe Aickelin, Minh-Tuan Tran",http://arxiv.org/pdf/2405.14608v1,cs.LG
Controllable Continual Test-Time Adaptation,"Continual Test-Time Adaptation (CTTA) is an emerging and challenging task
where a model trained in a source domain must adapt to continuously changing
conditions during testing, without access to the original source data. CTTA is
prone to error accumulation due to uncontrollable domain shifts, leading to
blurred decision boundaries between categories. Existing CTTA methods primarily
focus on suppressing domain shifts, which proves inadequate during the
unsupervised test phase. In contrast, we introduce a novel approach that guides
rather than suppresses these shifts. Specifically, we propose
$\textbf{C}$ontrollable $\textbf{Co}$ntinual $\textbf{T}$est-$\textbf{T}$ime
$\textbf{A}$daptation (C-CoTTA), which explicitly prevents any single category
from encroaching on others, thereby mitigating the mutual influence between
categories caused by uncontrollable shifts. Moreover, our method reduces the
sensitivity of model to domain transformations, thereby minimizing the
magnitude of category shifts. Extensive quantitative experiments demonstrate
the effectiveness of our method, while qualitative analyses, such as t-SNE
plots, confirm the theoretical validity of our approach.",2024-05-23,"Ziqi Shi, Fan Lyu, Ye Liu, Fanhua Shang, Fuyuan Hu, Wei Feng, Zhang Zhang, Liang Wang",http://arxiv.org/pdf/2405.14602v3,cs.LG
Discretization of continuous input spaces in the hippocampal autoencoder,"The hippocampus has been associated with both spatial cognition and episodic
memory formation, but integrating these functions into a unified framework
remains challenging. Here, we demonstrate that forming discrete memories of
visual events in sparse autoencoder neurons can produce spatial tuning similar
to hippocampal place cells. We then show that the resulting very
high-dimensional code enables neurons to discretize and tile the underlying
image space with minimal overlap. Additionally, we extend our results to the
auditory domain, showing that neurons similarly tile the frequency space in an
experience-dependent manner. Lastly, we show that reinforcement learning agents
can effectively perform various visuo-spatial cognitive tasks using these
sparse, very high-dimensional representations.",2024-05-23,"Adrian F. Amil, Ismael T. Freire, Paul F. M. J. Verschure",http://arxiv.org/pdf/2405.14600v1,cs.LG
Neuroexplicit Diffusion Models for Inpainting of Optical Flow Fields,"Deep learning has revolutionized the field of computer vision by introducing
large scale neural networks with millions of parameters. Training these
networks requires massive datasets and leads to intransparent models that can
fail to generalize. At the other extreme, models designed from partial
differential equations (PDEs) embed specialized domain knowledge into
mathematical equations and usually rely on few manually chosen hyperparameters.
This makes them transparent by construction and if designed and calibrated
carefully, they can generalize well to unseen scenarios. In this paper, we show
how to bring model- and data-driven approaches together by combining the
explicit PDE-based approaches with convolutional neural networks to obtain the
best of both worlds. We illustrate a joint architecture for the task of
inpainting optical flow fields and show that the combination of model- and
data-driven modeling leads to an effective architecture. Our model outperforms
both fully explicit and fully data-driven baselines in terms of reconstruction
quality, robustness and amount of required training data. Averaging the
endpoint error across different mask densities, our method outperforms the
explicit baselines by 11-27%, the GAN baseline by 47% and the Probabilisitic
Diffusion baseline by 42%. With that, our method sets a new state of the art
for inpainting of optical flow fields from random masks.",2024-05-23,"Tom Fischer, Pascal Peter, Joachim Weickert, Eddy Ilg",http://arxiv.org/pdf/2405.14599v1,cs.LG
Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation,"In recent years, with the realistic generation results and a wide range of
personalized applications, diffusion-based generative models gain huge
attention in both visual and audio generation areas. Compared to the
considerable advancements of text2image or text2audio generation, research in
audio2visual or visual2audio generation has been relatively slow. The recent
audio-visual generation methods usually resort to huge large language model or
composable diffusion models. Instead of designing another giant model for
audio-visual generation, in this paper we take a step back showing a simple and
lightweight generative transformer, which is not fully investigated in
multi-modal generation, can achieve excellent results on image2audio
generation. The transformer operates in the discrete audio and visual
Vector-Quantized GAN space, and is trained in the mask denoising manner. After
training, the classifier-free guidance could be deployed off-the-shelf
achieving better performance, without any extra training or modification. Since
the transformer model is modality symmetrical, it could also be directly
deployed for audio2image generation and co-generation. In the experiments, we
show that our simple method surpasses recent image2audio generation methods.
Generated audio samples can be found at
https://docs.google.com/presentation/d/1ZtC0SeblKkut4XJcRaDsSTuCRIXB3ypxmSi7HTY3IyQ/",2024-05-23,"Shiqi Yang, Zhi Zhong, Mengjie Zhao, Shusuke Takahashi, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji",http://arxiv.org/pdf/2405.14598v2,cs.LG
Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs,"We introduce Integer Scale, a novel post-training quantization scheme for
large language models that effectively resolves the inference bottleneck in
current fine-grained quantization approaches while maintaining similar
accuracies. Integer Scale is a free lunch as it requires no extra calibration
or fine-tuning which will otherwise incur additional costs. It can be used
plug-and-play for most fine-grained quantization methods. Its integration
results in at most 1.85x end-to-end speed boost over the original counterpart
with comparable accuracy. Additionally, due to the orchestration of the
proposed Integer Scale and fine-grained quantization, we resolved the
quantization difficulty for Mixtral-8x7B and LLaMA-3 models with negligible
performance degradation, and it comes with an end-to-end speed boost of 2.13x,
and 2.31x compared with their FP16 versions respectively.",2024-05-23,"Qingyuan Li, Ran Meng, Yiduo Li, Bo Zhang, Yifan Lu, Yerui Sun, Lin Ma, Yuchen Xie",http://arxiv.org/pdf/2405.14597v2,cs.LG
Linear Mode Connectivity in Differentiable Tree Ensembles,"Linear Mode Connectivity (LMC) refers to the phenomenon that performance
remains consistent for linearly interpolated models in the parameter space. For
independently optimized model pairs from different random initializations,
achieving LMC is considered crucial for understanding the stable success of the
non-convex optimization in modern machine learning models and for facilitating
practical parameter-based operations such as model merging. While LMC has been
achieved for neural networks by considering the permutation invariance of
neurons in each hidden layer, its attainment for other models remains an open
question. In this paper, we first achieve LMC for soft tree ensembles, which
are tree-based differentiable models extensively used in practice. We show the
necessity of incorporating two invariances: subtree flip invariance and
splitting order invariance, which do not exist in neural networks but are
inherent to tree architectures, in addition to permutation invariance of trees.
Moreover, we demonstrate that it is even possible to exclude such additional
invariances while keeping LMC by designing decision list-based tree
architectures, where such invariances do not exist by definition. Our findings
indicate the significance of accounting for architecture-specific invariances
in achieving LMC.",2024-05-23,"Ryuichi Kanoh, Mahito Sugiyama",http://arxiv.org/pdf/2405.14596v2,cs.LG
Reinforcing Language Agents via Policy Optimization with Action Decomposition,"Language models as intelligent agents push the boundaries of sequential
decision-making agents but struggle with limited knowledge of environmental
dynamics and exponentially huge action space. Recent efforts like GLAM and
TWOSOME manually constrain the action space to a restricted subset and employ
reinforcement learning to align agents' knowledge with specific environments.
However, they overlook fine-grained credit assignments for intra-action tokens,
which is essential for efficient language agent optimization, and rely on
human's prior knowledge to restrict action space. This paper proposes
decomposing language agent optimization from the action level to the token
level, offering finer supervision for each intra-action token and manageable
optimization complexity in environments with unrestricted action spaces.
Beginning with the simplification of flattening all actions, we theoretically
explore the discrepancies between action-level optimization and this naive
token-level optimization. We then derive the Bellman backup with Action
Decomposition (BAD) to integrate credit assignments for both intra-action and
inter-action tokens, effectively eliminating the discrepancies. Implementing
BAD within the PPO algorithm, we introduce Policy Optimization with Action
Decomposition (POAD). POAD benefits from a finer-grained credit assignment
process and lower optimization complexity, leading to enhanced learning
efficiency and generalization abilities in aligning language agents with
interactive environments. We validate POAD across diverse testbeds, with
results affirming the advantages of our approach and the correctness of our
theoretical analysis.",2024-05-23,"Muning Wen, Ziyu Wan, Weinan Zhang, Jun Wang, Ying Wen",http://arxiv.org/pdf/2405.15821v1,cs.LG
Surge Phenomenon in Optimal Learning Rate and Batch Size Scaling,"In current deep learning tasks, Adam style optimizers such as Adam, Adagrad,
RMSProp, Adafactor, and Lion have been widely used as alternatives to SGD style
optimizers. These optimizers typically update model parameters using the sign
of gradients, resulting in more stable convergence curves. The learning rate
and the batch size are the most critical hyperparameters for optimizers, which
require careful tuning to enable effective convergence. Previous research has
shown that the optimal learning rate increases linearly or follows similar
rules with batch size for SGD style optimizers. However, this conclusion is not
applicable to Adam style optimizers. In this paper, we elucidate the connection
between optimal learning rates and batch sizes for Adam style optimizers
through both theoretical analysis and extensive experiments. First, we raise
the scaling law between batch sizes and optimal learning rates in the sign of
gradient case, in which we prove that the optimal learning rate first rises and
then falls as the batch size increases. Moreover, the peak value of the surge
will gradually move toward the larger batch size as training progresses.
Second, we conducted experiments on various CV and NLP tasks and verified the
correctness of the scaling law.",2024-05-23,"Shuaipeng Li, Penghao Zhao, Hailin Zhang, Xingwu Sun, Hao Wu, Dian Jiao, Weiyan Wang, Chengjun Liu, Zheng Fang, Jinbao Xue, Yangyu Tao, Bin Cui, Di Wang",http://arxiv.org/pdf/2405.14578v5,cs.LG
Representation Noising: A Defence Mechanism Against Harmful Finetuning,"Releasing open-source large language models (LLMs) presents a dual-use risk
since bad actors can easily fine-tune these models for harmful purposes. Even
without the open release of weights, weight stealing and fine-tuning APIs make
closed models vulnerable to harmful fine-tuning attacks (HFAs). While safety
measures like preventing jailbreaks and improving safety guardrails are
important, such measures can easily be reversed through fine-tuning. In this
work, we propose Representation Noising (RepNoise), a defence mechanism that
operates even when attackers have access to the weights. RepNoise works by
removing information about harmful representations such that it is difficult to
recover them during fine-tuning. Importantly, our defence is also able to
generalize across different subsets of harm that have not been seen during the
defence process as long as they are drawn from the same distribution of the
attack set. Our method does not degrade the general capability of LLMs and
retains the ability to train the model on harmless tasks. We provide empirical
evidence that the efficacy of our defence lies in its ``depth'': the degree to
which information about harmful representations is removed across all layers of
the LLM. We also find areas where RepNoise still remains ineffective and
highlight how those limitations can inform future research.",2024-05-23,"Domenic Rosati, Jan Wehner, Kai Williams, Łukasz Bartoszcze, David Atanasov, Robie Gonzales, Subhabrata Majumdar, Carsten Maple, Hassan Sajjad, Frank Rudzicz",http://arxiv.org/pdf/2405.14577v4,cs.LG
Learning with Fitzpatrick Losses,"Fenchel-Young losses are a family of convex loss functions, encompassing the
squared, logistic and sparsemax losses, among others. Each Fenchel-Young loss
is implicitly associated with a link function, for mapping model outputs to
predictions. For instance, the logistic loss is associated with the soft argmax
link function. Can we build new loss functions associated with the same link
function as Fenchel-Young losses? In this paper, we introduce Fitzpatrick
losses, a new family of convex loss functions based on the Fitzpatrick
function. A well-known theoretical tool in maximal monotone operator theory,
the Fitzpatrick function naturally leads to a refined Fenchel-Young inequality,
making Fitzpatrick losses tighter than Fenchel-Young losses, while maintaining
the same link function for prediction. As an example, we introduce the
Fitzpatrick logistic loss and the Fitzpatrick sparsemax loss, counterparts of
the logistic and the sparsemax losses. This yields two new tighter losses
associated with the soft argmax and the sparse argmax, two of the most
ubiquitous output layers used in machine learning. We study in details the
properties of Fitzpatrick losses and in particular, we show that they can be
seen as Fenchel-Young losses using a modified, target-dependent generating
function. We demonstrate the effectiveness of Fitzpatrick losses for label
proportion estimation.",2024-05-23,"Seta Rakotomandimby, Jean-Philippe Chancelier, Michel de Lara, Mathieu Blondel",http://arxiv.org/pdf/2405.14574v1,cs.LG
AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents,"Autonomous agents that execute human tasks by controlling computers can
enhance human productivity and application accessibility. However, progress in
this field will be driven by realistic and reproducible benchmarks. We present
AndroidWorld, a fully functional Android environment that provides reward
signals for 116 programmatic tasks across 20 real-world Android apps. Unlike
existing interactive environments, which provide a static test set,
AndroidWorld dynamically constructs tasks that are parameterized and expressed
in natural language in unlimited ways, thus enabling testing on a much larger
and more realistic suite of tasks. To ensure reproducibility, each task
includes dedicated initialization, success-checking, and tear-down logic, which
modifies and inspects the device's system state. We experiment with baseline
agents to test AndroidWorld and provide initial results on the benchmark. Our
best agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for
future work. Furthermore, we adapt a popular desktop web agent to work on
Android, which we find to be less effective on mobile, suggesting future
research is needed to achieve universal, cross-platform agents. Finally, we
also conduct a robustness analysis, showing that task variations can
significantly affect agent performance, demonstrating that without such
testing, agent performance metrics may not fully reflect practical challenges.
AndroidWorld and the experiments in this paper are available at
github.com/google-research/android_world.",2024-05-23,"Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyamagundlu, Timothy Lillicrap, Oriana Riva",http://arxiv.org/pdf/2405.14573v5,cs.LG
EHRMamba: Towards Generalizable and Scalable Foundation Models for Electronic Health Records,"Transformers have significantly advanced the modeling of Electronic Health
Records (EHR), yet their deployment in real-world healthcare is limited by
several key challenges. Firstly, the quadratic computational cost and
insufficient context length of these models hinder hospitals' ability in
processing the extensive medical histories typical in EHR data. Additionally,
existing models employ separate finetuning for each clinical task, complicating
maintenance in healthcare environments. Moreover, these models focus
exclusively on either clinical prediction or EHR forecasting, lacking
proficiency in both tasks. To overcome these limitations, we introduce
EHRMamba, a robust foundation model built on the Mamba architecture. EHRMamba
can process sequences up to 300% longer than previous models due to its linear
computational cost. We also introduce a novel approach to Multitask Prompted
Finetuning (MPF) for EHR data, which enables EHRMamba to simultaneously learn
multiple clinical tasks in a single finetuning phase, significantly enhancing
deployment and cross-task generalization. Furthermore, our model leverages the
HL7 FHIR data standard to simplify integration into existing hospital systems.
Alongside EHRMamba, we open-source Odyssey, a toolkit designed to support the
development and deployment of EHR foundation models, with an emphasis on data
standardization and interpretability. Our evaluations on the MIMIC-IV dataset
demonstrate that EHRMamba advances state-of-the-art performance across 6 major
clinical tasks and excels in EHR forecasting, marking a significant leap
forward in the field.",2024-05-23,"Adibvafa Fallahpour, Mahshid Alinoori, Wenqian Ye, Xu Cao, Arash Afkanpour, Amrit Krishnan",http://arxiv.org/pdf/2405.14567v3,cs.LG
FUSE: Fast Unified Simulation and Estimation for PDEs,"The joint prediction of continuous fields and statistical estimation of the
underlying discrete parameters is a common problem for many physical systems,
governed by PDEs. Hitherto, it has been separately addressed by employing
operator learning surrogates for field prediction while using simulation-based
inference (and its variants) for statistical parameter determination. Here, we
argue that solving both problems within the same framework can lead to
consistent gains in accuracy and robustness. To this end, We propose a novel
and flexible formulation of the operator learning problem that allows jointly
predicting continuous quantities and inferring distributions of discrete
parameters, and thus amortizing the cost of both the inverse and the surrogate
models to a joint pre-training step. We present the capabilities of the
proposed methodology for predicting continuous and discrete biomarkers in
full-body haemodynamics simulations under different levels of missing
information. We also consider a test case for atmospheric large-eddy simulation
of a two-dimensional dry cold bubble, where we infer both continuous
time-series and information about the systems conditions. We present
comparisons against different baselines to showcase significantly increased
accuracy in both the inverse and the surrogate tasks.",2024-05-23,"Levi E. Lingsch, Dana Grund, Siddhartha Mishra, Georgios Kissas",http://arxiv.org/pdf/2405.14558v2,cs.LG
Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models,"Research on Large Language Models (LLMs) has often neglected subtle biases
that, although less apparent, can significantly influence the models' outputs
toward particular social narratives. This study addresses two such biases
within LLMs: representative bias, which denotes a tendency of LLMs to generate
outputs that mirror the experiences of certain identity groups, and affinity
bias, reflecting the models' evaluative preferences for specific narratives or
viewpoints. We introduce two novel metrics to measure these biases: the
Representative Bias Score (RBS) and the Affinity Bias Score (ABS), and present
the Creativity-Oriented Generation Suite (CoGS), a collection of open-ended
tasks such as short story writing and poetry composition, designed with
customized rubrics to detect these subtle biases. Our analysis uncovers marked
representative biases in prominent LLMs, with a preference for identities
associated with being white, straight, and men. Furthermore, our investigation
of affinity bias reveals distinctive evaluative patterns within each model,
akin to `bias fingerprints'. This trend is also seen in human evaluators,
highlighting a complex interplay between human and machine bias perceptions.",2024-05-23,"Abhishek Kumar, Sarfaroz Yunusov, Ali Emami",http://arxiv.org/pdf/2405.14555v4,cs.LG
Causal Effect Identification in a Sub-Population with Latent Variables,"The s-ID problem seeks to compute a causal effect in a specific
sub-population from the observational data pertaining to the same sub
population (Abouei et al., 2023). This problem has been addressed when all the
variables in the system are observable. In this paper, we consider an extension
of the s-ID problem that allows for the presence of latent variables. To tackle
the challenges induced by the presence of latent variables in a sub-population,
we first extend the classical relevant graphical definitions, such as
c-components and Hedges, initially defined for the so-called ID problem (Pearl,
1995; Tian & Pearl, 2002), to their new counterparts. Subsequently, we propose
a sound algorithm for the s-ID problem with latent variables.",2024-05-23,"Amir Mohammad Abouei, Ehsan Mokhtarian, Negar Kiyavash, Matthias Grossglauser",http://arxiv.org/pdf/2405.14547v2,cs.LG
A Cross-Field Fusion Strategy for Drug-Target Interaction Prediction,"Drug-target interaction (DTI) prediction is a critical component of the drug
discovery process. In the drug development engineering field, predicting novel
drug-target interactions is extremely crucial.However, although existing
methods have achieved high accuracy levels in predicting known drugs and drug
targets, they fail to utilize global protein information during DTI prediction.
This leads to an inability to effectively predict interaction the interactions
between novel drugs and their targets. As a result, the cross-field information
fusion strategy is employed to acquire local and global protein information.
Thus, we propose the siamese drug-target interaction SiamDTI prediction method,
which utilizes a double channel network structure for cross-field supervised
learning.Experimental results on three benchmark datasets demonstrate that
SiamDTI achieves higher accuracy levels than other state-of-the-art (SOTA)
methods on novel drugs and targets.Additionally, SiamDTI's performance with
known drugs and targets is comparable to that of SOTA approachs. The code is
available at https://anonymous.4open.science/r/DDDTI-434D.",2024-05-23,"Hongzhi Zhang, Xiuwen Gong, Shirui Pan, Jia Wu, Bo Du, Wenbin Hu",http://arxiv.org/pdf/2405.14545v1,cs.LG
Nuclear Norm Regularization for Deep Learning,"Penalizing the nuclear norm of a function's Jacobian encourages it to locally
behave like a low-rank linear map. Such functions vary locally along only a
handful of directions, making the Jacobian nuclear norm a natural regularizer
for machine learning problems. However, this regularizer is intractable for
high-dimensional problems, as it requires computing a large Jacobian matrix and
taking its singular value decomposition. We show how to efficiently penalize
the Jacobian nuclear norm using techniques tailor-made for deep learning. We
prove that for functions parametrized as compositions $f = g \circ h$, one may
equivalently penalize the average squared Frobenius norm of $Jg$ and $Jh$. We
then propose a denoising-style approximation that avoids the Jacobian
computations altogether. Our method is simple, efficient, and accurate,
enabling Jacobian nuclear norm regularization to scale to high-dimensional deep
learning problems. We complement our theory with an empirical study of our
regularizer's performance and investigate applications to denoising and
representation learning.",2024-05-23,"Christopher Scarvelis, Justin Solomon",http://arxiv.org/pdf/2405.14544v2,cs.LG
This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian Optimization,"Bayesian Optimization (BO) has proven to be very successful at optimizing a
static, noisy, costly-to-evaluate black-box function $f : \mathcal{S} \to
\mathbb{R}$. However, optimizing a black-box which is also a function of time
(i.e., a dynamic function) $f : \mathcal{S} \times \mathcal{T} \to \mathbb{R}$
remains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has
to keep track of the optimum over time. This changes the nature of the
optimization problem in at least three aspects: (i) querying an arbitrary point
in $\mathcal{S} \times \mathcal{T}$ is impossible, (ii) past observations
become less and less relevant for keeping track of the optimum as time goes by
and (iii) the DBO algorithm must have a high sampling frequency so it can
collect enough relevant observations to keep track of the optimum through time.
In this paper, we design a Wasserstein distance-based criterion able to
quantify the relevancy of an observation with respect to future predictions.
Then, we leverage this criterion to build W-DBO, a DBO algorithm able to remove
irrelevant observations from its dataset on the fly, thus maintaining
simultaneously a good predictive performance and a high sampling frequency,
even in continuous-time optimization tasks with unknown horizon. Numerical
experiments establish the superiority of W-DBO, which outperforms
state-of-the-art methods by a comfortable margin.",2024-05-23,"Anthony Bardou, Patrick Thiran, Giovanni Ranieri",http://arxiv.org/pdf/2405.14540v2,cs.LG
Regressor-free Molecule Generation to Support Drug Response Prediction,"Drug response prediction (DRP) is a crucial phase in drug discovery, and the
most important metric for its evaluation is the IC50 score. DRP results are
heavily dependent on the quality of the generated molecules. Existing molecule
generation methods typically employ classifier-based guidance, enabling
sampling within the IC50 classification range. However, these methods fail to
ensure the sampling space range's effectiveness, generating numerous
ineffective molecules. Through experimental and theoretical study, we
hypothesize that conditional generation based on the target IC50 score can
obtain a more effective sampling space. As a result, we introduce
regressor-free guidance molecule generation to ensure sampling within a more
effective space and support DRP. Regressor-free guidance combines a diffusion
model's score estimation with a regression controller model's gradient based on
number labels. To effectively map regression labels between drugs and cell
lines, we design a common-sense numerical knowledge graph that constrains the
order of text representations. Experimental results on the real-world dataset
for the DRP task demonstrate our method's effectiveness in drug discovery. The
code is available at:https://anonymous.4open.science/r/RMCD-DBD1.",2024-05-23,"Kun Li, Xiuwen Gong, Shirui Pan, Jia Wu, Bo Du, Wenbin Hu",http://arxiv.org/pdf/2405.14536v1,cs.LG
High Rank Path Development: an approach of learning the filtration of stochastic processes,"Since the weak convergence for stochastic processes does not account for the
growth of information over time which is represented by the underlying
filtration, a slightly erroneous stochastic model in weak topology may cause
huge loss in multi-periods decision making problems. To address such
discontinuities Aldous introduced the extended weak convergence, which can
fully characterise all essential properties, including the filtration, of
stochastic processes; however was considered to be hard to find efficient
numerical implementations. In this paper, we introduce a novel metric called
High Rank PCF Distance (HRPCFD) for extended weak convergence based on the high
rank path development method from rough path theory, which also defines the
characteristic function for measure-valued processes. We then show that such
HRPCFD admits many favourable analytic properties which allows us to design an
efficient algorithm for training HRPCFD from data and construct the HRPCF-GAN
by using HRPCFD as the discriminator for conditional time series generation.
Our numerical experiments on both hypothesis testing and generative modelling
validate the out-performance of our approach compared with several
state-of-the-art methods, highlighting its potential in broad applications of
synthetic time series generation and in addressing classic financial and
economic challenges, such as optimal stopping or utility maximisation problems.",2024-05-23,"Jiajie Tao, Hao Ni, Chong Liu",http://arxiv.org/pdf/2405.14913v1,cs.LG
Aligning Embeddings and Geometric Random Graphs: Informational Results and Computational Approaches for the Procrustes-Wasserstein Problem,"The Procrustes-Wasserstein problem consists in matching two high-dimensional
point clouds in an unsupervised setting, and has many applications in natural
language processing and computer vision. We consider a planted model with two
datasets $X,Y$ that consist of $n$ datapoints in $\mathbb{R}^d$, where $Y$ is a
noisy version of $X$, up to an orthogonal transformation and a relabeling of
the data points. This setting is related to the graph alignment problem in
geometric models. In this work, we focus on the euclidean transport cost
between the point clouds as a measure of performance for the alignment. We
first establish information-theoretic results, in the high ($d \gg \log n$) and
low ($d \ll \log n$) dimensional regimes. We then study computational aspects
and propose the Ping-Pong algorithm, alternatively estimating the orthogonal
transformation and the relabeling, initialized via a Franke-Wolfe convex
relaxation. We give sufficient conditions for the method to retrieve the
planted signal after one single step. We provide experimental results to
compare the proposed approach with the state-of-the-art method of Grave et al.
(2019).",2024-05-23,"Mathieu Even, Luca Ganassali, Jakob Maier, Laurent Massoulié",http://arxiv.org/pdf/2405.14532v1,cs.LG
Towards Privacy-Aware and Personalised Assistive Robots: A User-Centred Approach,"The global increase in the elderly population necessitates innovative
long-term care solutions to improve the quality of life for vulnerable
individuals while reducing caregiver burdens. Assistive robots, leveraging
advancements in Machine Learning, offer promising personalised support.
However, their integration into daily life raises significant privacy concerns.
Widely used frameworks like the Robot Operating System (ROS) historically lack
inherent privacy mechanisms, complicating data-driven approaches in robotics.
This research pioneers user-centric, privacy-aware technologies such as
Federated Learning (FL) to advance assistive robotics. FL enables collaborative
learning without sharing sensitive data, addressing privacy and scalability
issues. This work includes developing solutions for smart wheelchair
assistance, enhancing user independence and well-being. By tackling challenges
related to non-stationary data and heterogeneous environments, the research
aims to improve personalisation and user experience. Ultimately, it seeks to
lead the responsible integration of assistive robots into society, enhancing
the quality of life for elderly and care-dependent individuals.",2024-05-23,Fernando E. Casado,http://arxiv.org/pdf/2405.14528v1,cs.LG
ArchesWeather: An efficient AI weather forecasting model at 1.5° resolution,"One of the guiding principles for designing AI-based weather forecasting
systems is to embed physical constraints as inductive priors in the neural
network architecture. A popular prior is locality, where the atmospheric data
is processed with local neural interactions, like 3D convolutions or 3D local
attention windows as in Pangu-Weather. On the other hand, some works have shown
great success in weather forecasting without this locality principle, at the
cost of a much higher parameter count. In this paper, we show that the 3D local
processing in Pangu-Weather is computationally sub-optimal. We design
ArchesWeather, a transformer model that combines 2D attention with a
column-wise attention-based feature interaction module, and demonstrate that
this design improves forecasting skill.
  ArchesWeather is trained at 1.5{\deg} resolution and 24h lead time, with a
training budget of a few GPU-days and a lower inference cost than competing
methods. An ensemble of four of our models shows better RMSE scores than the
IFS HRES and is competitive with the 1.4{\deg} 50-members NeuralGCM ensemble
for one to three days ahead forecasting. Our code and models are publicly
available at https://github.com/gcouairon/ArchesWeather.",2024-05-23,"Guillaume Couairon, Christian Lessig, Anastase Charantonis, Claire Monteleoni",http://arxiv.org/pdf/2405.14527v2,cs.LG
Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property,"Techniques that explain the predictions of black-box machine learning models
are crucial to make the models transparent, thereby increasing trust in AI
systems. The input features to the models often have a nested structure that
consists of high- and low-level features, and each high-level feature is
decomposed into multiple low-level features. For such inputs, both high-level
feature attributions (HiFAs) and low-level feature attributions (LoFAs) are
important for better understanding the model's decision. In this paper, we
propose a model-agnostic local explanation method that effectively exploits the
nested structure of the input to estimate the two-level feature attributions
simultaneously. A key idea of the proposed method is to introduce the
consistency property that should exist between the HiFAs and LoFAs, thereby
bridging the separate optimization problems for estimating them. Thanks to this
consistency property, the proposed method can produce HiFAs and LoFAs that are
both faithful to the black-box models and consistent with each other, using a
smaller number of queries to the models. In experiments on image classification
in multiple instance learning and text classification using language models, we
demonstrate that the HiFAs and LoFAs estimated by the proposed method are
accurate, faithful to the behaviors of the black-box models, and provide
consistent explanations.",2024-05-23,"Yuya Yoshikawa, Masanari Kimura, Ryotaro Shimizu, Yuki Saito",http://arxiv.org/pdf/2405.14522v2,cs.LG
Synthetic Data Generation for Intersectional Fairness by Leveraging Hierarchical Group Structure,"In this paper, we introduce a data augmentation approach specifically
tailored to enhance intersectional fairness in classification tasks. Our method
capitalizes on the hierarchical structure inherent to intersectionality, by
viewing groups as intersections of their parent categories. This perspective
allows us to augment data for smaller groups by learning a transformation
function that combines data from these parent groups. Our empirical analysis,
conducted on four diverse datasets including both text and images, reveals that
classifiers trained with this data augmentation approach achieve superior
intersectional fairness and are more robust to ``leveling down'' when compared
to methods optimizing traditional group fairness metrics.",2024-05-23,"Gaurav Maheshwari, Aurélien Bellet, Pascal Denis, Mikaela Keller",http://arxiv.org/pdf/2405.14521v1,cs.LG
A New Formulation for Zeroth-Order Optimization of Adversarial EXEmples in Malware Detection,"Machine learning malware detectors are vulnerable to adversarial EXEmples,
i.e. carefully-crafted Windows programs tailored to evade detection. Unlike
other adversarial problems, attacks in this context must be
functionality-preserving, a constraint which is challenging to address. As a
consequence heuristic algorithms are typically used, that inject new content,
either randomly-picked or harvested from legitimate programs. In this paper, we
show how learning malware detectors can be cast within a zeroth-order
optimization framework which allows to incorporate functionality-preserving
manipulations. This permits the deployment of sound and efficient gradient-free
optimization algorithms, which come with theoretical guarantees and allow for
minimal hyper-parameters tuning. As a by-product, we propose and study ZEXE, a
novel zero-order attack against Windows malware detection. Compared to
state-of-the-art techniques, ZEXE provides drastic improvement in the evasion
rate, while reducing to less than one third the size of the injected content.",2024-05-23,"Marco Rando, Luca Demetrio, Lorenzo Rosasco, Fabio Roli",http://arxiv.org/pdf/2405.14519v1,cs.LG
TUNI: A Textual Unimodal Detector for Identity Inference in CLIP Models,"The widespread usage of large-scale multimodal models like CLIP has
heightened concerns about the leakage of PII. Existing methods for identity
inference in CLIP models require querying the model with full PII, including
textual descriptions of the person and corresponding images (e.g., the name and
the face photo of the person). However, applying images may risk exposing
personal information to target models, as the image might not have been
previously encountered by the target model. Additionally, previous MIAs train
shadow models to mimic the behaviors of the target model, which incurs high
computational costs, especially for large CLIP models. To address these
challenges, we propose a textual unimodal detector (TUNI) in CLIP models, a
novel technique for identity inference that: 1) only utilizes text data to
query the target model; and 2) eliminates the need for training shadow models.
Extensive experiments of TUNI across various CLIP model architectures and
datasets demonstrate its superior performance over baselines, albeit with only
text data.",2024-05-23,"Songze Li, Ruoxi Cheng, Xiaojun Jia",http://arxiv.org/pdf/2405.14517v2,cs.LG
Unchosen Experts Can Contribute Too: Unleashing MoE Models' Power by Self-Contrast,"Mixture-of-Experts (MoE) has emerged as a prominent architecture for scaling
model size while maintaining computational efficiency. In MoE, each token in
the input sequence activates a different subset of experts determined by a
routing mechanism. However, the unchosen experts in MoE models do not
contribute to the output, potentially leading to underutilization of the
model's capacity. In this work, we first conduct exploratory studies to
demonstrate that increasing the number of activated experts does not
necessarily improve and can even degrade the output quality. Then, we show that
output distributions from an MoE model using different routing strategies
substantially differ, indicating that different experts do not always act
synergistically. Motivated by these findings, we propose Self-Contrast
Mixture-of-Experts (SCMoE), a training-free strategy that utilizes unchosen
experts in a self-contrast manner during inference. In SCMoE, the next-token
probabilities are determined by contrasting the outputs from strong and weak
activation using the same MoE model. Our method is conceptually simple and
computationally lightweight, as it incurs minimal latency compared to greedy
decoding. Experiments on several benchmarks (GSM8K, StrategyQA, MBPP and
HumanEval) demonstrate that SCMoE can consistently enhance Mixtral 8x7B's
reasoning capability across various domains. For example, it improves the
accuracy on GSM8K from 61.79 to 66.94. Moreover, combining SCMoE with
self-consistency yields additional gains, increasing major@20 accuracy from
75.59 to 78.31.",2024-05-23,"Chufan Shi, Cheng Yang, Xinyu Zhu, Jiahao Wang, Taiqiang Wu, Siheng Li, Deng Cai, Yujiu Yang, Yu Meng",http://arxiv.org/pdf/2405.14507v2,cs.LG
Explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing,"Concerns about the effect of greenhouse gases have motivated the development
of certification protocols to quantify the industrial carbon footprint (CF).
These protocols are manual, work-intensive, and expensive. All of the above
have led to a shift towards automatic data-driven approaches to estimate the
CF, including Machine Learning (ML) solutions. Unfortunately, the
decision-making processes involved in these solutions lack transparency from
the end user's point of view, who must blindly trust their outcomes compared to
intelligible traditional manual approaches. In this research, manual and
automatic methodologies for CF estimation were reviewed, taking into account
their transparency limitations. This analysis led to the proposal of a new
explainable ML solution for automatic CF calculations through bank transaction
classification. Consideration should be given to the fact that no previous
research has considered the explainability of bank transaction classification
for this purpose. For classification, different ML models have been employed
based on their promising performance in the literature, such as Support Vector
Machine, Random Forest, and Recursive Neural Networks. The results obtained
were in the 90 % range for accuracy, precision, and recall evaluation metrics.
From their decision paths, the proposed solution estimates the CO2 emissions
associated with bank transactions. The explainability methodology is based on
an agnostic evaluation of the influence of the input terms extracted from the
descriptions of transactions using locally interpretable models. The
explainability terms were automatically validated using a similarity metric
over the descriptions of the target categories. Conclusively, the explanation
performance is satisfactory in terms of the proximity of the explanations to
the associated activity sector descriptions.",2024-05-23,"Jaime González-González, Silvia García-Méndez, Francisco de Arriba-Pérez, Francisco J. González-Castaño, Óscar Barba-Seara",http://arxiv.org/pdf/2405.14505v1,cs.LG
Hybrid Top-Down Global Causal Discovery with Local Search for Linear and Nonlinear Additive Noise Models,"Learning the unique directed acyclic graph corresponding to an unknown causal
model is a challenging task. Methods based on functional causal models can
identify a unique graph, but either suffer from the curse of dimensionality or
impose strong parametric assumptions. To address these challenges, we propose a
novel hybrid approach for global causal discovery in observational data that
leverages local causal substructures. We first present a topological sorting
algorithm that leverages ancestral relationships in linear structural causal
models to establish a compact top-down hierarchical ordering, encoding more
causal information than linear orderings produced by existing methods. We
demonstrate that this approach generalizes to nonlinear settings with arbitrary
noise. We then introduce a nonparametric constraint-based algorithm that prunes
spurious edges by searching for local conditioning sets, achieving greater
accuracy than current methods. We provide theoretical guarantees for
correctness and worst-case polynomial time complexities, with empirical
validation on synthetic data.",2024-05-23,"Sujai Hiremath, Jacqueline R. M. A. Maasch, Mengxiao Gao, Promit Ghosal, Kyra Gan",http://arxiv.org/pdf/2405.14496v5,cs.LG
Entrywise error bounds for low-rank approximations of kernel matrices,"In this paper, we derive entrywise error bounds for low-rank approximations
of kernel matrices obtained using the truncated eigen-decomposition (or
singular value decomposition). While this approximation is well-known to be
optimal with respect to the spectral and Frobenius norm error, little is known
about the statistical behaviour of individual entries. Our error bounds fill
this gap. A key technical innovation is a delocalisation result for the
eigenvectors of the kernel matrix corresponding to small eigenvalues, which
takes inspiration from the field of Random Matrix Theory. Finally, we validate
our theory with an empirical study of a collection of synthetic and real-world
datasets.",2024-05-23,Alexander Modell,http://arxiv.org/pdf/2405.14494v2,cs.LG
Iterative Methods for Full-Scale Gaussian Process Approximations for Large Spatial Data,"Gaussian processes are flexible probabilistic regression models which are
widely used in statistics and machine learning. However, a drawback is their
limited scalability to large data sets. To alleviate this, we consider
full-scale approximations (FSAs) that combine predictive process methods and
covariance tapering, thus approximating both global and local structures. We
show how iterative methods can be used to reduce the computational costs for
calculating likelihoods, gradients, and predictive distributions with FSAs. We
introduce a novel preconditioner and show that it accelerates the conjugate
gradient method's convergence speed and mitigates its sensitivity with respect
to the FSA parameters and the eigenvalue structure of the original covariance
matrix, and we demonstrate empirically that it outperforms a state-of-the-art
pivoted Cholesky preconditioner. Further, we present a novel, accurate, and
fast way to calculate predictive variances relying on stochastic estimations
and iterative methods. In both simulated and real-world data experiments, we
find that our proposed methodology achieves the same accuracy as Cholesky-based
computations with a substantial reduction in computational time. Finally, we
also compare different approaches for determining inducing points in predictive
process and FSA models. All methods are implemented in a free C++ software
library with high-level Python and R packages.",2024-05-23,"Tim Gyger, Reinhard Furrer, Fabio Sigrist",http://arxiv.org/pdf/2405.14492v2,cs.LG
LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models,"Advances in latent diffusion models (LDMs) have revolutionized
high-resolution image generation, but the design space of the autoencoder that
is central to these systems remains underexplored. In this paper, we introduce
LiteVAE, a new autoencoder design for LDMs, which leverages the 2D discrete
wavelet transform to enhance scalability and computational efficiency over
standard variational autoencoders (VAEs) with no sacrifice in output quality.
We investigate the training methodologies and the decoder architecture of
LiteVAE and propose several enhancements that improve the training dynamics and
reconstruction quality. Our base LiteVAE model matches the quality of the
established VAEs in current LDMs with a six-fold reduction in encoder
parameters, leading to faster training and lower GPU memory requirements, while
our larger model outperforms VAEs of comparable complexity across all evaluated
metrics (rFID, LPIPS, PSNR, and SSIM).",2024-05-23,"Seyedmorteza Sadat, Jakob Buhmann, Derek Bradley, Otmar Hilliges, Romann M. Weber",http://arxiv.org/pdf/2405.14477v2,cs.LG
Poisson Variational Autoencoder,"Variational autoencoders (VAEs) employ Bayesian inference to interpret
sensory inputs, mirroring processes that occur in primate vision across both
ventral (Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways.
Despite their success, traditional VAEs rely on continuous latent variables,
which deviates sharply from the discrete nature of biological neurons. Here, we
developed the Poisson VAE (P-VAE), a novel architecture that combines
principles of predictive coding with a VAE that encodes inputs into discrete
spike counts. Combining Poisson-distributed latent variables with predictive
coding introduces a metabolic cost term in the model loss function, suggesting
a relationship with sparse coding which we verify empirically. Additionally, we
analyze the geometry of learned representations, contrasting the P-VAE to
alternative VAE models. We find that the P-VAE encodes its inputs in relatively
higher dimensions, facilitating linear separability of categories in a
downstream classification task with a much better (5x) sample efficiency. Our
work provides an interpretable computational framework to study brain-like
sensory processing and paves the way for a deeper understanding of perception
as an inferential process.",2024-05-23,"Hadi Vafaii, Dekel Galor, Jacob L. Yates",http://arxiv.org/pdf/2405.14473v2,cs.LG
SolNet: Open-source deep learning models for photovoltaic power forecasting across the globe,"Deep learning models have gained increasing prominence in recent years in the
field of solar pho-tovoltaic (PV) forecasting. One drawback of these models is
that they require a lot of high-quality data to perform well. This is often
infeasible in practice, due to poor measurement infrastructure in legacy
systems and the rapid build-up of new solar systems across the world. This
paper proposes SolNet: a novel, general-purpose, multivariate solar power
forecaster, which addresses these challenges by using a two-step forecasting
pipeline which incorporates transfer learning from abundant synthetic data
generated from PVGIS, before fine-tuning on observational data. Using actual
production data from hundreds of sites in the Netherlands, Australia and
Belgium, we show that SolNet improves forecasting performance over data-scarce
settings as well as baseline models. We find transfer learning benefits to be
the strongest when only limited observational data is available. At the same
time we provide several guidelines and considerations for transfer learning
practitioners, as our results show that weather data, seasonal patterns, amount
of synthetic data and possible mis-specification in source location, can have a
major impact on the results. The SolNet models created in this way are
applicable for any land-based solar photovoltaic system across the planet where
simulated and observed data can be combined to obtain improved forecasting
capabilities.",2024-05-23,"Joris Depoortere, Johan Driesen, Johan Suykens, Hussain Syed Kazmi",http://arxiv.org/pdf/2405.14472v2,cs.LG
Generalization of Hamiltonian algorithms,"The paper proves generalization results for a class of stochastic learning
algorithms. The method applies whenever the algorithm generates an absolutely
continuous distribution relative to some a-priori measure and the Radon Nikodym
derivative has subgaussian concentration. Applications are bounds for the Gibbs
algorithm and randomizations of stable deterministic algorithms as well as
PAC-Bayesian bounds with data-dependent priors.",2024-05-23,Andreas Maurer,http://arxiv.org/pdf/2405.14469v2,cs.LG
Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really Optimal?,"Deep neural networks (DNNs) exhibit a surprising structure in their final
layer known as neural collapse (NC), and a growing body of works has currently
investigated the propagation of neural collapse to earlier layers of DNNs -- a
phenomenon called deep neural collapse (DNC). However, existing theoretical
results are restricted to special cases: linear models, only two layers or
binary classification. In contrast, we focus on non-linear models of arbitrary
depth in multi-class classification and reveal a surprising qualitative shift.
As soon as we go beyond two layers or two classes, DNC stops being optimal for
the deep unconstrained features model (DUFM) -- the standard theoretical
framework for the analysis of collapse. The main culprit is a low-rank bias of
multi-layer regularization schemes: this bias leads to optimal solutions of
even lower rank than the neural collapse. We support our theoretical findings
with experiments on both DUFM and real data, which show the emergence of the
low-rank structure in the solution found by gradient descent.",2024-05-23,"Peter Súkeník, Marco Mondelli, Christoph Lampert",http://arxiv.org/pdf/2405.14468v2,cs.LG
Segformer++: Efficient Token-Merging Strategies for High-Resolution Semantic Segmentation,"Utilizing transformer architectures for semantic segmentation of
high-resolution images is hindered by the attention's quadratic computational
complexity in the number of tokens. A solution to this challenge involves
decreasing the number of tokens through token merging, which has exhibited
remarkable enhancements in inference speed, training efficiency, and memory
utilization for image classification tasks. In this paper, we explore various
token merging strategies within the framework of the Segformer architecture and
perform experiments on multiple semantic segmentation and human pose estimation
datasets. Notably, without model re-training, we, for example, achieve an
inference acceleration of 61% on the Cityscapes dataset while maintaining the
mIoU performance. Consequently, this paper facilitates the deployment of
transformer-based architectures on resource-constrained devices and in
real-time applications.",2024-05-23,"Daniel Kienzle, Marco Kantonis, Robin Schön, Rainer Lienhart",http://arxiv.org/pdf/2405.14467v1,cs.LG
Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model,"Machine learning models can be trained with formal privacy guarantees via
differentially private optimizers such as DP-SGD. In this work, we focus on a
threat model where the adversary has access only to the final model, with no
visibility into intermediate updates. In the literature, this hidden state
threat model exhibits a significant gap between the lower bound from empirical
privacy auditing and the theoretical upper bound provided by privacy
accounting. To challenge this gap, we propose to audit this threat model with
adversaries that \emph{craft a gradient sequence} designed to maximize the
privacy loss of the final model without relying on intermediate updates. Our
experiments show that this approach consistently outperforms previous attempts
at auditing the hidden state model. Furthermore, our results advance the
understanding of achievable privacy guarantees within this threat model.
Specifically, when the crafted gradient is inserted at every optimization step,
we show that concealing the intermediate model updates in DP-SGD does not
amplify privacy. The situation is more complex when the crafted gradient is not
inserted at every step: our auditing lower bound matches the privacy upper
bound only for an adversarially-chosen loss landscape and a sufficiently large
batch size. This suggests that existing privacy upper bounds can be improved in
certain regimes.",2024-05-23,"Tudor Cebere, Aurélien Bellet, Nicolas Papernot",http://arxiv.org/pdf/2405.14457v2,cs.LG
Domain-specific augmentations with resolution agnostic self-attention mechanism improves choroid segmentation in optical coherence tomography images,"The choroid is a key vascular layer of the eye, supplying oxygen to the
retinal photoreceptors. Non-invasive enhanced depth imaging optical coherence
tomography (EDI-OCT) has recently improved access and visualisation of the
choroid, making it an exciting frontier for discovering novel vascular
biomarkers in ophthalmology and wider systemic health. However, current methods
to measure the choroid often require use of multiple, independent
semi-automatic and deep learning-based algorithms which are not made
open-source. Previously, Choroidalyzer -- an open-source, fully automatic deep
learning method trained on 5,600 OCT B-scans from 385 eyes -- was developed to
fully segment and quantify the choroid in EDI-OCT images, thus addressing these
issues. Using the same dataset, we propose a Robust, Resolution-agnostic and
Efficient Attention-based network for CHoroid segmentation (REACH). REACHNet
leverages multi-resolution training with domain-specific data augmentation to
promote generalisation, and uses a lightweight architecture with
resolution-agnostic self-attention which is not only faster than
Choroidalyzer's previous network (4 images/s vs. 2.75 images/s on a standard
laptop CPU), but has greater performance for segmenting the choroid region,
vessels and fovea (Dice coefficient for region 0.9769 vs. 0.9749, vessels
0.8612 vs. 0.8192 and fovea 0.8243 vs. 0.3783) due to its improved
hyperparameter configuration and model training pipeline. REACHNet can be used
with Choroidalyzer as a drop-in replacement for the original model and will be
made available upon publication.",2024-05-23,"Jamie Burke, Justin Engelmann, Charlene Hamid, Diana Moukaddem, Dan Pugh, Neeraj Dhaun, Amos Storkey, Niall Strang, Stuart King, Tom MacGillivray, Miguel O. Bernabeu, Ian J. C. MacCormick",http://arxiv.org/pdf/2405.14453v1,cs.LG
Adversarial Schrödinger Bridge Matching,"The Schr\""odinger Bridge (SB) problem offers a powerful framework for
combining optimal transport and diffusion models. A promising recent approach
to solve the SB problem is the Iterative Markovian Fitting (IMF) procedure,
which alternates between Markovian and reciprocal projections of
continuous-time stochastic processes. However, the model built by the IMF
procedure has a long inference time due to using many steps of numerical
solvers for stochastic differential equations.
  To address this limitation, we propose a novel Discrete-time IMF (D-IMF)
procedure in which learning of stochastic processes is replaced by learning
just a few transition probabilities in discrete time. Its great advantage is
that in practice it can be naturally implemented using the Denoising Diffusion
GAN (DD-GAN), an already well-established adversarial generative modeling
technique. We show that our D-IMF procedure can provide the same quality of
unpaired domain translation as the IMF, using only several generation steps
instead of hundreds. We provide the code at
https://github.com/Daniil-Selikhanovych/ASBM.",2024-05-23,"Nikita Gushchin, Daniil Selikhanovych, Sergei Kholkin, Evgeny Burnaev, Alexander Korotin",http://arxiv.org/pdf/2405.14449v2,cs.LG
Worldwide Federated Training of Language Models,"The reliance of language model training on massive amounts of computation and
vast datasets scraped from potentially low-quality, copyrighted, or sensitive
data has come into question practically, legally, and ethically. Federated
learning provides a plausible alternative by enabling previously untapped data
to be voluntarily gathered from collaborating organizations. However, when
scaled globally, federated learning requires collaboration across heterogeneous
legal, security, and privacy regimes while accounting for the inherent locality
of language data; this further exacerbates the established challenge of
federated statistical heterogeneity. We propose a Worldwide Federated Language
Model Training~(WorldLM) system based on federations of federations, where each
federation has the autonomy to account for factors such as its industry,
operating jurisdiction, or competitive environment. WorldLM enables such
autonomy in the presence of statistical heterogeneity via partial model
localization by allowing sub-federations to attentively aggregate key layers
from their constituents. Furthermore, it can adaptively share information
across federations via residual layer embeddings. Evaluations of language
modeling on naturally heterogeneous datasets show that WorldLM outperforms
standard federations by up to $1.91\times$, approaches the personalized
performance of fully local models, and maintains these advantages under
privacy-enhancing techniques.",2024-05-23,"Alex Iacob, Lorenzo Sani, Bill Marino, Preslav Aleksandrov, William F. Shen, Nicholas Donald Lane",http://arxiv.org/pdf/2405.14446v2,cs.LG
Bayesian Adaptive Calibration and Optimal Design,"The process of calibrating computer models of natural phenomena is essential
for applications in the physical sciences, where plenty of domain knowledge can
be embedded into simulations and then calibrated against real observations.
Current machine learning approaches, however, mostly rely on rerunning
simulations over a fixed set of designs available in the observed data,
potentially neglecting informative correlations across the design space and
requiring a large amount of simulations. Instead, we consider the calibration
process from the perspective of Bayesian adaptive experimental design and
propose a data-efficient algorithm to run maximally informative simulations
within a batch-sequential process. At each round, the algorithm jointly
estimates the parameters of the posterior distribution and optimal designs by
maximising a variational lower bound of the expected information gain. The
simulator is modelled as a sample from a Gaussian process, which allows us to
correlate simulations and observed data with the unknown calibration
parameters. We show the benefits of our method when compared to related
approaches across synthetic and real-data problems.",2024-05-23,"Rafael Oliveira, Dino Sejdinovic, David Howard, Edwin V. Bonilla",http://arxiv.org/pdf/2405.14440v3,cs.LG
LoRA-Ensemble: Efficient Uncertainty Modelling for Self-Attention Networks,"Numerous real-world decisions rely on machine learning algorithms and require
calibrated uncertainty estimates. However, modern methods often yield
overconfident, uncalibrated predictions. The dominant approach to quantifying
the uncertainty inherent in the model is to train an ensemble of separate
predictors and measure their empirical variance. In an explicit implementation,
the ensemble has high computational cost and memory footprint, especially if
the base model itself is already large, like modern transformers. This
motivates efforts to develop implicit ensemble methods that emulate the
ensemble without explicitly instantiating all its members. We introduce
LoRA-Ensemble, a parameter-efficient ensembling method for self-attention
networks. It is based on Low-Rank Adaptation (LoRA), originally developed for
efficient LLM fine-tuning, and extends it into an implicit ensembling scheme,
where all ensemble members share the same, pre-trained self-attention network,
but have individual low-rank matrices for the attention projections. The
resulting method not only outperforms state-of-the-art implicit techniques like
BatchEnsemble, but even matches or exceeds the accuracy of an Explicit
Ensemble, while at the same time achieving superior calibration.",2024-05-23,"Dominik J. Mühlematter, Michelle Halbheer, Alexander Becker, Dominik Narnhofer, Helge Aasen, Konrad Schindler, Mehmet Ozgur Turkoglu",http://arxiv.org/pdf/2405.14438v4,cs.LG
LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract Rules,"Human cognition excels at symbolic reasoning, deducing abstract rules from
limited samples. This has been explained using symbolic and connectionist
approaches, inspiring the development of a neuro-symbolic architecture that
combines both paradigms. In parallel, recent studies have proposed the use of a
""relational bottleneck"" that separates object-level features from abstract
rules, allowing learning from limited amounts of data . While powerful, it is
vulnerable to the curse of compositionality meaning that object representations
with similar features tend to interfere with each other. In this paper, we
leverage hyperdimensional computing, which is inherently robust to such
interference to build a compositional architecture. We adapt the ""relational
bottleneck"" strategy to a high-dimensional space, incorporating explicit vector
binding operations between symbols and relational representations.
Additionally, we design a novel high-dimensional attention mechanism that
leverages this relational representation. Our system benefits from the low
overhead of operations in hyperdimensional space, making it significantly more
efficient than the state of the art when evaluated on a variety of test
datasets, while maintaining higher or equal accuracy.",2024-05-23,"Mohamed Mejri, Chandramouli Amarnath, Abhijit Chatterjee",http://arxiv.org/pdf/2405.14436v1,cs.LG
Adaptive Gradient Clipping for Robust Federated Learning,"Robust federated learning aims to maintain reliable performance despite the
presence of adversarial or misbehaving workers. While state-of-the-art (SOTA)
robust distributed gradient descent (Robust-DGD) methods were proven
theoretically optimal, their empirical success has often relied on
pre-aggregation gradient clipping. However, existing static clipping strategies
yield inconsistent results: enhancing robustness against some attacks while
being ineffective or even detrimental against others. To address this
limitation, we propose a principled adaptive clipping strategy, Adaptive Robust
Clipping (ARC), which dynamically adjusts clipping thresholds based on the
input gradients. We prove that ARC not only preserves the theoretical
robustness guarantees of SOTA Robust-DGD methods but also provably improves
asymptotic convergence when the model is well-initialized. Extensive
experiments on benchmark image classification tasks confirm these theoretical
insights, demonstrating that ARC significantly enhances robustness,
particularly in highly heterogeneous and adversarial settings.",2024-05-23,"Youssef Allouah, Rachid Guerraoui, Nirupam Gupta, Ahmed Jellouli, Geovani Rizk, John Stephan",http://arxiv.org/pdf/2405.14432v5,cs.LG
Mitigating Quantization Errors Due to Activation Spikes in GLU-Based LLMs,"Modern large language models (LLMs) have established state-of-the-art
performance through architectural improvements, but still require significant
computational cost for inference. In an effort to reduce the inference cost,
post-training quantization (PTQ) has become a popular approach, quantizing
weights and activations to lower precision, such as INT8. In this paper, we
reveal the challenges of activation quantization in GLU variants, which are
widely used in feed-forward network (FFN) of modern LLMs, such as LLaMA family.
The problem is that severe local quantization errors, caused by excessive
magnitudes of activation in GLU variants, significantly degrade the performance
of the quantized LLM. We denote these activations as activation spikes. Our
further observations provide a systematic pattern of activation spikes: 1) The
activation spikes occur in the FFN of specific layers, particularly in the
early and late layers, 2) The activation spikes are dedicated to a couple of
tokens, rather than being shared across a sequence. Based on our observations,
we propose two empirical methods, Quantization-free Module (QFeM) and
Quantization-free Prefix (QFeP), to isolate the activation spikes during
quantization. Our extensive experiments validate the effectiveness of the
proposed methods for the activation quantization, especially with
coarse-grained scheme, of latest LLMs with GLU variants, including LLaMA-2/3,
Mistral, Mixtral, SOLAR, and Gemma. In particular, our methods enhance the
current alleviation techniques (e.g., SmoothQuant) that fail to control the
activation spikes. Code is available at
https://github.com/onnoo/activation-spikes.",2024-05-23,"Jaewoo Yang, Hayun Kim, Younghoon Kim",http://arxiv.org/pdf/2405.14428v1,cs.LG
When predict can also explain: few-shot prediction to select better neural latents,"Latent variable models serve as powerful tools to infer underlying dynamics
from observed neural activity. Ideally, the inferred dynamics should align with
true ones. However, due to the absence of ground truth data, prediction
benchmarks are often employed as proxies. One widely-used method,
*co-smoothing*, involves jointly estimating latent variables and predicting
observations along held-out channels to assess model performance. In this
study, we reveal the limitations of the co-smoothing prediction framework and
propose a remedy. In a student-teacher setup with Hidden Markov Models, we
demonstrate that the high co-smoothing model space encompasses models with
arbitrary extraneous dynamics in their latent representations. To address this,
we introduce a secondary metric -- *few-shot co-smoothing*, performing
regression from the latent variables to held-out channels in the data using
fewer trials. Our results indicate that among models with near-optimal
co-smoothing, those with extraneous dynamics underperform in the few-shot
co-smoothing compared to 'minimal' models that are devoid of such dynamics. We
provide analytical insights into the origin of this phenomenon and further
validate our findings on real neural data using two state-of-the-art methods:
LFADS and STNDT. In the absence of ground truth, we suggest a novel measure to
validate our approach. By cross-decoding the latent variables of all model
pairs with high co-smoothing, we identify models with minimal extraneous
dynamics. We find a correlation between few-shot co-smoothing performance and
this new measure. In summary, we present a novel prediction metric designed to
yield latent variables that more accurately reflect the ground truth, offering
a significant improvement for latent dynamics inference.",2024-05-23,"Kabir Dabholkar, Omri Barak",http://arxiv.org/pdf/2405.14425v3,cs.LG
Unraveling overoptimism and publication bias in ML-driven science,"Machine Learning (ML) is increasingly used across many disciplines with
impressive reported results. However, recent studies suggest published
performance of ML models are often overoptimistic. Validity concerns are
underscored by findings of an inverse relationship between sample size and
reported accuracy in published ML models, contrasting with the theory of
learning curves where accuracy should improve or remain stable with increasing
sample size. This paper investigates factors contributing to overoptimism in
ML-driven science, focusing on overfitting and publication bias. We introduce a
novel stochastic model for observed accuracy, integrating parametric learning
curves and the aforementioned biases. We construct an estimator that corrects
for these biases in observed data. Theoretical and empirical results show that
our framework can estimate the underlying learning curve, providing realistic
performance assessments from published results. Applying the model to
meta-analyses of classifications of neurological conditions, we estimate the
inherent limits of ML-based prediction in each domain.",2024-05-23,"Pouria Saidi, Gautam Dasarathy, Visar Berisha",http://arxiv.org/pdf/2405.14422v3,cs.LG
Dynamic Graph Unlearning: A General and Efficient Post-Processing Method via Gradient Transformation,"Dynamic graph neural networks (DGNNs) have emerged and been widely deployed
in various web applications (e.g., Reddit) to serve users (e.g., personalized
content delivery) due to their remarkable ability to learn from complex and
dynamic user interaction data. Despite benefiting from high-quality services,
users have raised privacy concerns, such as misuse of personal data (e.g.,
dynamic user-user/item interaction) for model training, requiring DGNNs to
``forget'' their data to meet AI governance laws (e.g., the ``right to be
forgotten'' in GDPR). However, current static graph unlearning studies cannot
\textit{unlearn dynamic graph elements} and exhibit limitations such as the
model-specific design or reliance on pre-processing, which disenable their
practicability in dynamic graph unlearning. To this end, we study the dynamic
graph unlearning for the first time and propose an effective, efficient,
general, and post-processing method to implement DGNN unlearning. Specifically,
we first formulate dynamic graph unlearning in the context of continuous-time
dynamic graphs, and then propose a method called Gradient Transformation that
directly maps the unlearning request to the desired parameter update.
Comprehensive evaluations on six real-world datasets and state-of-the-art DGNN
backbones demonstrate its effectiveness (e.g., limited drop or obvious
improvement in utility) and efficiency (e.g., 7.23$\times$ speed-up)
advantages. Additionally, our method has the potential to handle future
unlearning requests with significant performance gains (e.g., 32.59$\times$
speed-up).",2024-05-23,"He Zhang, Bang Wu, Xiangwen Yang, Xingliang Yuan, Xiaoning Liu, Xun Yi",http://arxiv.org/pdf/2405.14407v2,cs.LG
Exact Gauss-Newton Optimization for Training Deep Neural Networks,"We present EGN, a stochastic second-order optimization algorithm that
combines the generalized Gauss-Newton (GN) Hessian approximation with low-rank
linear algebra to compute the descent direction. Leveraging the Duncan-Guttman
matrix identity, the parameter update is obtained by factorizing a matrix which
has the size of the mini-batch. This is particularly advantageous for
large-scale machine learning problems where the dimension of the neural network
parameter vector is several orders of magnitude larger than the batch size.
Additionally, we show how improvements such as line search, adaptive
regularization, and momentum can be seamlessly added to EGN to further
accelerate the algorithm. Moreover, under mild assumptions, we prove that our
algorithm converges to an $\epsilon$-stationary point at a linear rate.
Finally, our numerical experiments demonstrate that EGN consistently exceeds,
or at most matches the generalization performance of well-tuned SGD, Adam, and
SGN optimizers across various supervised and reinforcement learning tasks.",2024-05-23,"Mikalai Korbit, Adeyemi D. Adeoye, Alberto Bemporad, Mario Zanon",http://arxiv.org/pdf/2405.14402v1,cs.LG
Endowing Interpretability for Neural Cognitive Diagnosis by Efficient Kolmogorov-Arnold Networks,"In the realm of intelligent education, cognitive diagnosis plays a crucial
role in subsequent recommendation tasks attributed to the revealed students'
proficiency in knowledge concepts. Although neural network-based neural
cognitive diagnosis models (CDMs) have exhibited significantly better
performance than traditional models, neural cognitive diagnosis is criticized
for the poor model interpretability due to the multi-layer perception (MLP)
employed, even with the monotonicity assumption. Therefore, this paper proposes
to empower the interpretability of neural cognitive diagnosis models through
efficient kolmogorov-arnold networks (KANs), named KAN2CD, where KANs are
designed to enhance interpretability in two manners. Specifically, in the first
manner, KANs are directly used to replace the used MLPs in existing neural
CDMs; while in the second manner, the student embedding, exercise embedding,
and concept embedding are directly processed by several KANs, and then their
outputs are further combined and learned in a unified KAN to get final
predictions. To overcome the problem of training KANs slowly, we modify the
implementation of original KANs to accelerate the training. Experiments on four
real-world datasets show that the proposed KA2NCD exhibits better performance
than traditional CDMs, and the proposed KA2NCD still has a bit of performance
leading even over the existing neural CDMs. More importantly, the learned
structures of KANs enable the proposed KA2NCD to hold as good interpretability
as traditional CDMs, which is superior to existing neural CDMs. Besides, the
training cost of the proposed KA2NCD is competitive to existing models.",2024-05-23,"Shangshang Yang, Linrui Qin, Xiaoshan Yu",http://arxiv.org/pdf/2405.14399v1,cs.LG
Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows,"Continuous normalizing flows (CNFs) learn the probability path between a
reference distribution and a target distribution by modeling the vector field
generating said path using neural networks. Recently, Lipman et al. (2022)
introduced a simple and inexpensive method for training CNFs in generative
modeling, termed flow matching (FM). In this paper, we repurpose this method
for probabilistic inference by incorporating Markovian sampling methods in
evaluating the FM objective, and using the learned CNF to improve Monte Carlo
sampling. Specifically, we propose an adaptive Markov chain Monte Carlo (MCMC)
algorithm, which combines a local Markov transition kernel with a non-local,
flow-informed transition kernel, defined using a CNF. This CNF is adapted
on-the-fly using samples from the Markov chain, which are used to specify the
probability path for the FM objective. Our method also includes an adaptive
tempering mechanism that allows the discovery of multiple modes in the target
distribution. Under mild assumptions, we establish convergence of our method to
a local optimum of the FM objective. We then benchmark our approach on several
synthetic and real-world examples, achieving similar performance to other
state-of-the-art methods, but often at a significantly lower computational
cost.",2024-05-23,"Alberto Cabezas, Louis Sharrock, Christopher Nemeth",http://arxiv.org/pdf/2405.14392v2,cs.LG
Reliable Trajectory Prediction and Uncertainty Quantification with Conditioned Diffusion Models,"This work introduces the conditioned Vehicle Motion Diffusion (cVMD) model, a
novel network architecture for highway trajectory prediction using diffusion
models. The proposed model ensures the drivability of the predicted trajectory
by integrating non-holonomic motion constraints and physical constraints into
the generative prediction module. Central to the architecture of cVMD is its
capacity to perform uncertainty quantification, a feature that is crucial in
safety-critical applications. By integrating the quantified uncertainty into
the prediction process, the cVMD's trajectory prediction performance is
improved considerably. The model's performance was evaluated using the publicly
available highD dataset. Experiments show that the proposed architecture
achieves competitive trajectory prediction accuracy compared to
state-of-the-art models, while providing guaranteed drivable trajectories and
uncertainty quantification.",2024-05-23,"Marion Neumeier, Sebastian Dorn, Michael Botsch, Wolfgang Utschick",http://arxiv.org/pdf/2405.14384v1,cs.LG
CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization,"Training large AI models such as LLMs and DLRMs costs massive GPUs and
computing time. The high training cost has become only affordable to big tech
companies, meanwhile also causing increasing concerns about the environmental
impact. This paper presents CoMERA, a Computing- and Memory-Efficient training
method via Rank-Adaptive tensor optimization. CoMERA achieves rank-adaptive
tensor-compressed (pre)-training via a multi-objective optimization formulation
and improves the training to provide both a high compression ratio and
excellent accuracy in the training process. Our optimized numerical computation
(e.g., optimized tensorized embedding and tensor-network contractions) and GPU
implementation eliminate part of the run-time overhead in the tensorized
training on GPU. This leads to, for the first time, $2-3\times$ speedup per
training epoch compared with standard training. CoMERA also outperforms the
recent GaLore in terms of both memory and computing efficiency. Specifically,
CoMERA is $2\times$ faster per training epoch and $9\times$ more
memory-efficient than GaLore on a tested six-encoder transformer with
single-batch training. Our method also shows $\sim 2\times$ speedup than
standard pre-training on a BERT-like code-generation LLM while achieving
$4.23\times$ compression ratio in pre-training. With further HPC optimization,
CoMERA may reduce the pre-training cost of many other LLMs. An implementation
of CoMERA is available at https://github.com/ziyangjoy/CoMERA.",2024-05-23,"Zi Yang, Ziyue Liu, Samridhi Choudhary, Xinfeng Xie, Cao Gao, Siegfried Kunzmann, Zheng Zhang",http://arxiv.org/pdf/2405.14377v2,cs.LG
State-Constrained Offline Reinforcement Learning,"Traditional offline reinforcement learning methods predominantly operate in a
batch-constrained setting. This confines the algorithms to a specific
state-action distribution present in the dataset, reducing the effects of
distributional shift but restricting the algorithm greatly. In this paper, we
alleviate this limitation by introducing a novel framework named
\emph{state-constrained} offline reinforcement learning. By exclusively
focusing on the dataset's state distribution, our framework significantly
enhances learning potential and reduces previous limitations. The proposed
setting not only broadens the learning horizon but also improves the ability to
combine different trajectories from the dataset effectively, a desirable
property inherent in offline reinforcement learning. Our research is
underpinned by solid theoretical findings that pave the way for subsequent
advancements in this domain. Additionally, we introduce StaCQ, a deep learning
algorithm that is both performance-driven on the D4RL benchmark datasets and
closely aligned with our theoretical propositions. StaCQ establishes a strong
baseline for forthcoming explorations in state-constrained offline
reinforcement learning.",2024-05-23,"Charles A. Hepburn, Yue Jin, Giovanni Montana",http://arxiv.org/pdf/2405.14374v1,cs.LG
Learning Constrained Markov Decision Processes With Non-stationary Rewards and Constraints,"In constrained Markov decision processes (CMDPs) with adversarial rewards and
constraints, a well-known impossibility result prevents any algorithm from
attaining both sublinear regret and sublinear constraint violation, when
competing against a best-in-hindsight policy that satisfies constraints on
average. In this paper, we show that this negative result can be eased in CMDPs
with non-stationary rewards and constraints, by providing algorithms whose
performances smoothly degrade as non-stationarity increases. Specifically, we
propose algorithms attaining $\tilde{\mathcal{O}} (\sqrt{T} + C)$ regret and
positive constraint violation under bandit feedback, where $C$ is a corruption
value measuring the environment non-stationarity. This can be $\Theta(T)$ in
the worst case, coherently with the impossibility result for adversarial CMDPs.
First, we design an algorithm with the desired guarantees when $C$ is known.
Then, in the case $C$ is unknown, we show how to obtain the same results by
embedding such an algorithm in a general meta-procedure. This is of independent
interest, as it can be applied to any non-stationary constrained online
learning setting.",2024-05-23,"Francesco Emanuele Stradi, Anna Lunghi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti",http://arxiv.org/pdf/2405.14372v2,cs.LG
RoPINN: Region Optimized Physics-Informed Neural Networks,"Physics-informed neural networks (PINNs) have been widely applied to solve
partial differential equations (PDEs) by enforcing outputs and gradients of
deep models to satisfy target equations. Due to the limitation of numerical
computation, PINNs are conventionally optimized on finite selected points.
However, since PDEs are usually defined on continuous domains, solely
optimizing models on scattered points may be insufficient to obtain an accurate
solution for the whole domain. To mitigate this inherent deficiency of the
default scatter-point optimization, this paper proposes and theoretically
studies a new training paradigm as region optimization. Concretely, we propose
to extend the optimization process of PINNs from isolated points to their
continuous neighborhood regions, which can theoretically decrease the
generalization error, especially for hidden high-order constraints of PDEs. A
practical training algorithm, Region Optimized PINN (RoPINN), is seamlessly
derived from this new paradigm, which is implemented by a straightforward but
effective Monte Carlo sampling method. By calibrating the sampling process into
trust regions, RoPINN finely balances optimization and generalization error.
Experimentally, RoPINN consistently boosts the performance of diverse PINNs on
a wide range of PDEs without extra backpropagation or gradient calculation.
Code is available at this repository: https://github.com/thuml/RoPINN.",2024-05-23,"Haixu Wu, Huakun Luo, Yuezhou Ma, Jianmin Wang, Mingsheng Long",http://arxiv.org/pdf/2405.14369v3,cs.LG
BiMix: A Bivariate Data Mixing Law for Language Model Pretraining,"Large language models have demonstrated remarkable capabilities across
various tasks, primarily attributed to the utilization of diversely sourced
data. However, the impact of pretraining data composition on model performance
remains poorly understood. This paper introduces $\textbf{BiMix}$, a novel
bivariate data mixing law that models the joint scaling behavior of domain
proportions and data volume in LLM pretraining. $\textbf{BiMix}$ provides a
systematic framework for understanding and optimizing data mixtures across
diverse domains. Through extensive experiments on two large-scale datasets, we
demonstrate $\textbf{BiMix}$'s high accuracy in loss extrapolation (mean
relative error < 0.2%) and its generalization to unseen mixtures (R${}^{2}$ >
0.97). Optimization of domain proportions yields superior model performance
compared to existing methods. Furthermore, we establish entropy-based measures
as efficient proxies for data mixing, offering a computationally lightweight
strategy. Our work contributes both theoretical insights into data mixing
dynamics and practical tools for enhancing LLM training efficiency, paving the
way for more effective scaling strategies in language model development.",2024-05-23,"Ce Ge, Zhijian Ma, Daoyuan Chen, Yaliang Li, Bolin Ding",http://arxiv.org/pdf/2405.14908v4,cs.LG
MiniCache: KV Cache Compression in Depth Dimension for Large Language Models,"A critical approach for efficiently deploying computationally demanding large
language models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value
states of previously generated tokens, significantly reducing the need for
repetitive computations and thereby lowering latency in autoregressive
generation. However, the size of the KV cache grows linearly with sequence
length, posing challenges for applications requiring long context input and
extensive sequence generation. In this paper, we present a simple yet effective
approach, called MiniCache, to compress the KV cache across layers from a novel
depth perspective, significantly reducing the memory footprint for LLM
inference. Our approach is based on the observation that KV cache states
exhibit high similarity between the adjacent layers in the middle-to-deep
portion of LLMs. To facilitate merging, we propose disentangling the states
into the magnitude and direction components, interpolating the directions of
the state vectors while preserving their lengths unchanged. Furthermore, we
introduce a token retention strategy to keep highly distinct state pairs
unmerged, thus preserving the information with minimal additional storage
overhead. Our MiniCache is training-free and general, complementing existing KV
cache compression strategies, such as quantization and sparsity. We conduct a
comprehensive evaluation of MiniCache utilizing various models including
LLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks,
demonstrating its exceptional performance in achieving superior compression
ratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit
MiniCache achieves a remarkable compression ratio of up to 5.02x, enhances
inference throughput by approximately 5x, and reduces the memory footprint by
41% compared to the FP16 full cache baseline, all while maintaining
near-lossless performance.",2024-05-23,"Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, Bohan Zhuang",http://arxiv.org/pdf/2405.14366v2,cs.LG
Retrieval-Augmented Mining of Temporal Logic Specifications from Data,"The integration of cyber-physical systems (CPS) into everyday life raises the
critical necessity of ensuring their safety and reliability. An important step
in this direction is requirement mining, i.e. inferring formally specified
system properties from observed behaviors, in order to discover knowledge about
the system. Signal Temporal Logic (STL) offers a concise yet expressive
language for specifying requirements, particularly suited for CPS, where
behaviors are typically represented as time series data. This work addresses
the task of learning STL requirements from observed behaviors in a data-driven
manner, focusing on binary classification, i.e. on inferring properties of the
system which are able to discriminate between regular and anomalous behaviour,
and that can be used both as classifiers and as monitors of the compliance of
the CPS to desirable specifications. We present a novel framework that combines
Bayesian Optimization (BO) and Information Retrieval (IR) techniques to
simultaneously learn both the structure and the parameters of STL formulae,
without restrictions on the STL grammar. Specifically, we propose a framework
that leverages a dense vector database containing semantic-preserving
continuous representations of millions of formulae, queried for facilitating
the mining of requirements inside a BO loop. We demonstrate the effectiveness
of our approach in several signal classification applications, showing its
ability to extract interpretable insights from system executions and advance
the state-of-the-art in requirement mining for CPS.",2024-05-23,"Gaia Saveri, Luca Bortolussi",http://arxiv.org/pdf/2405.14355v1,cs.LG
Explaining Graph Neural Networks via Structure-aware Interaction Index,"The Shapley value is a prominent tool for interpreting black-box machine
learning models thanks to its strong theoretical foundation. However, for
models with structured inputs, such as graph neural networks, existing
Shapley-based explainability approaches either focus solely on node-wise
importance or neglect the graph structure when perturbing the input instance.
This paper introduces the Myerson-Taylor interaction index that internalizes
the graph structure into attributing the node values and the interaction values
among nodes. Unlike the Shapley-based methods, the Myerson-Taylor index
decomposes coalitions into components satisfying a pre-chosen connectivity
criterion. We prove that the Myerson-Taylor index is the unique one that
satisfies a system of five natural axioms accounting for graph structure and
high-order interaction among nodes. Leveraging these properties, we propose
Myerson-Taylor Structure-Aware Graph Explainer (MAGE), a novel explainer that
uses the second-order Myerson-Taylor index to identify the most important
motifs influencing the model prediction, both positively and negatively.
Extensive experiments on various graph datasets and models demonstrate that our
method consistently provides superior subgraph explanations compared to
state-of-the-art methods.",2024-05-23,"Ngoc Bui, Hieu Trung Nguyen, Viet Anh Nguyen, Rex Ying",http://arxiv.org/pdf/2405.14352v1,cs.LG
"Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning","This work investigates the offline formulation of the contextual bandit
problem, where the goal is to leverage past interactions collected under a
behavior policy to evaluate, select, and learn new, potentially
better-performing, policies. Motivated by critical applications, we move beyond
point estimators. Instead, we adopt the principle of pessimism where we
construct upper bounds that assess a policy's worst-case performance, enabling
us to confidently select and learn improved policies. Precisely, we introduce
novel, fully empirical concentration bounds for a broad class of importance
weighting risk estimators. These bounds are general enough to cover most
existing estimators and pave the way for the development of new ones. In
particular, our pursuit of the tightest bound within this class motivates a
novel estimator (LS), that logarithmically smooths large importance weights.
The bound for LS is provably tighter than its competitors, and naturally
results in improved policy selection and learning strategies. Extensive policy
evaluation, selection, and learning experiments highlight the versatility and
favorable performance of LS.",2024-05-23,"Otmane Sakhi, Imad Aouali, Pierre Alquier, Nicolas Chopin",http://arxiv.org/pdf/2405.14335v2,cs.LG
LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision,"Prototypical parts networks combine the power of deep learning with the
explainability of case-based reasoning to make accurate, interpretable
decisions. They follow the this looks like that reasoning, representing each
prototypical part with patches from training images. However, a single image
patch comprises multiple visual features, such as color, shape, and texture,
making it difficult for users to identify which feature is important to the
model.
  To reduce this ambiguity, we introduce the Lucid Prototypical Parts Network
(LucidPPN), a novel prototypical parts network that separates color prototypes
from other visual features. Our method employs two reasoning branches: one for
non-color visual features, processing grayscale images, and another focusing
solely on color information. This separation allows us to clarify whether the
model's decisions are based on color, shape, or texture. Additionally, LucidPPN
identifies prototypical parts corresponding to semantic parts of classified
objects, making comparisons between data classes more intuitive, e.g., when two
bird species might differ primarily in belly color.
  Our experiments demonstrate that the two branches are complementary and
together achieve results comparable to baseline methods. More importantly,
LucidPPN generates less ambiguous prototypical parts, enhancing user
understanding.",2024-05-23,"Mateusz Pach, Dawid Rymarczyk, Koryna Lewandowska, Jacek Tabor, Bartosz Zieliński",http://arxiv.org/pdf/2405.14331v1,cs.LG
Data Valuation by Leveraging Global and Local Statistical Information,"Data valuation has garnered increasing attention in recent years, given the
critical role of high-quality data in various applications, particularly in
machine learning tasks. There are diverse technical avenues to quantify the
value of data within a corpus. While Shapley value-based methods are among the
most widely used techniques in the literature due to their solid theoretical
foundation, the accurate calculation of Shapley values is often intractable,
leading to the proposal of numerous approximated calculation methods. Despite
significant progress, nearly all existing methods overlook the utilization of
distribution information of values within a data corpus. In this paper, we
demonstrate that both global and local statistical information of value
distributions hold significant potential for data valuation within the context
of machine learning. Firstly, we explore the characteristics of both global and
local value distributions across several simulated and real data corpora.
Useful observations and clues are obtained. Secondly, we propose a new data
valuation method that estimates Shapley values by incorporating the explored
distribution characteristics into an existing method, AME. Thirdly, we present
a new path to address the dynamic data valuation problem by formulating an
optimization problem that integrates information of both global and local value
distributions. Extensive experiments are conducted on Shapley value estimation,
value-based data removal/adding, mislabeled data detection, and
incremental/decremental data valuation. The results showcase the effectiveness
and efficiency of our proposed methodologies, affirming the significant
potential of global and local value distributions in data valuation.",2024-05-23,"Xiaoling Zhou, Ou Wu, Michael K. Ng, Hao Jiang",http://arxiv.org/pdf/2405.17464v1,cs.LG
Adaptive Retention & Correction: Test-Time Training for Continual Learning,"Continual learning, also known as lifelong learning or incremental learning,
refers to the process by which a model learns from a stream of incoming data
over time. A common problem in continual learning is the classification layer's
bias towards the most recent task. Traditionally, methods have relied on
incorporating data from past tasks during training to mitigate this issue.
However, the recent shift in continual learning to memory-free environments has
rendered these approaches infeasible. In this study, we propose a solution
focused on the testing phase. We first introduce a simple Out-of-Task Detection
method, OTD, designed to accurately identify samples from past tasks during
testing. Leveraging OTD, we then propose: (1) an Adaptive Retention mechanism
for dynamically tuning the classifier layer on past task data; (2) an Adaptive
Correction mechanism for revising predictions when the model classifies data
from previous tasks into classes from the current task. We name our approach
Adaptive Retention & Correction (ARC). While designed for memory-free
environments, ARC also proves effective in memory-based settings. Extensive
experiments show that our proposed method can be plugged in to virtually any
existing continual learning approach without requiring any modifications to its
training procedure. Specifically, when integrated with state-of-the-art
approaches, ARC achieves an average performance increase of 2.7% and 2.6% on
the CIFAR-100 and Imagenet-R datasets, respectively.",2024-05-23,"Haoran Chen, Micah Goldblum, Zuxuan Wu, Yu-Gang Jiang",http://arxiv.org/pdf/2405.14318v4,cs.LG
Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration,"Grounding the reasoning ability of large language models (LLMs) for embodied
tasks is challenging due to the complexity of the physical world. Especially,
LLM planning for multi-agent collaboration requires communication of agents or
credit assignment as the feedback to re-adjust the proposed plans and achieve
effective coordination. However, existing methods that overly rely on physical
verification or self-reflection suffer from excessive and inefficient querying
of LLMs. In this paper, we propose a novel framework for multi-agent
collaboration that introduces Reinforced Advantage feedback (ReAd) for
efficient self-refinement of plans. Specifically, we perform critic regression
to learn a sequential advantage function from LLM-planned data, and then treat
the LLM planner as an optimizer to generate actions that maximize the advantage
function. It endows the LLM with the foresight to discern whether the action
contributes to accomplishing the final task. We provide theoretical analysis by
extending advantage-weighted regression in reinforcement learning to
multi-agent systems. Experiments on Overcooked-AI and a difficult variant of
RoCoBench show that ReAd surpasses baselines in success rate, and also
significantly decreases the interaction steps of agents and query rounds of
LLMs, demonstrating its high efficiency for grounding LLMs. More results are
given at https://read-llm.github.io/.",2024-05-23,"Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Zhen Wang, Xuelong Li",http://arxiv.org/pdf/2405.14314v2,cs.LG
Smooth Pseudo-Labeling,"Semi-Supervised Learning (SSL) seeks to leverage large amounts of
non-annotated data along with the smallest amount possible of annotated data in
order to achieve the same level of performance as if all data were annotated. A
fruitful method in SSL is Pseudo-Labeling (PL), which, however, suffers from
the important drawback that the associated loss function has discontinuities in
its derivatives, which cause instabilities in performance when labels are very
scarce. In the present work, we address this drawback with the introduction of
a Smooth Pseudo-Labeling (SP L) loss function. It consists in adding a
multiplicative factor in the loss function that smooths out the discontinuities
in the derivative due to thresholding. In our experiments, we test our
improvements on FixMatch and show that it significantly improves the
performance in the regime of scarce labels, without addition of any modules,
hyperparameters, or computational overhead. In the more stable regime of
abundant labels, performance remains at the same level. Robustness with respect
to variation of hyperparameters and training parameters is also significantly
improved. Moreover, we introduce a new benchmark, where labeled images are
selected randomly from the whole dataset, without imposing representation of
each class proportional to its frequency in the dataset. We see that the smooth
version of FixMatch does appear to perform better than the original, non-smooth
implementation. However, more importantly, we notice that both implementations
do not necessarily see their performance improve when labeled images are added,
an important issue in the design of SSL algorithms that should be addressed so
that Active Learning algorithms become more reliable and explainable.",2024-05-23,"Nikolaos Karaliolios, Hervé Le Borgne, Florian Chabot",http://arxiv.org/pdf/2405.14313v1,cs.LG
AdaGMLP: AdaBoosting GNN-to-MLP Knowledge Distillation,"Graph Neural Networks (GNNs) have revolutionized graph-based machine
learning, but their heavy computational demands pose challenges for
latency-sensitive edge devices in practical industrial applications. In
response, a new wave of methods, collectively known as GNN-to-MLP Knowledge
Distillation, has emerged. They aim to transfer GNN-learned knowledge to a more
efficient MLP student, which offers faster, resource-efficient inference while
maintaining competitive performance compared to GNNs. However, these methods
face significant challenges in situations with insufficient training data and
incomplete test data, limiting their applicability in real-world applications.
To address these challenges, we propose AdaGMLP, an AdaBoosting GNN-to-MLP
Knowledge Distillation framework. It leverages an ensemble of diverse MLP
students trained on different subsets of labeled nodes, addressing the issue of
insufficient training data. Additionally, it incorporates a Node Alignment
technique for robust predictions on test data with missing or incomplete
features. Our experiments on seven benchmark datasets with different settings
demonstrate that AdaGMLP outperforms existing G2M methods, making it suitable
for a wide range of latency-sensitive real-world applications. We have
submitted our code to the GitHub repository
(https://github.com/WeigangLu/AdaGMLP-KDD24).",2024-05-23,"Weigang Lu, Ziyu Guan, Wei Zhao, Yaming Yang",http://arxiv.org/pdf/2405.14307v1,cs.LG
Similarity-Navigated Conformal Prediction for Graph Neural Networks,"Graph Neural Networks have achieved remarkable accuracy in semi-supervised
node classification tasks. However, these results lack reliable uncertainty
estimates. Conformal prediction methods provide a theoretical guarantee for
node classification tasks, ensuring that the conformal prediction set contains
the ground-truth label with a desired probability (e.g., 95%). In this paper,
we empirically show that for each node, aggregating the non-conformity scores
of nodes with the same label can improve the efficiency of conformal prediction
sets while maintaining valid marginal coverage. This observation motivates us
to propose a novel algorithm named Similarity-Navigated Adaptive Prediction
Sets (SNAPS), which aggregates the non-conformity scores based on feature
similarity and structural neighborhood. The key idea behind SNAPS is that nodes
with high feature similarity or direct connections tend to have the same label.
By incorporating adaptive similar nodes information, SNAPS can generate compact
prediction sets and increase the singleton hit ratio (correct prediction sets
of size one). Moreover, we theoretically provide a finite-sample coverage
guarantee of SNAPS. Extensive experiments demonstrate the superiority of SNAPS,
improving the efficiency of prediction sets and singleton hit ratio while
maintaining valid coverage.",2024-05-23,"Jianqing Song, Jianguo Huang, Wenyu Jiang, Baoming Zhang, Shuangjie Li, Chongjun Wang",http://arxiv.org/pdf/2405.14303v2,cs.LG
Graphcode: Learning from multiparameter persistent homology using graph neural networks,"We introduce graphcodes, a novel multi-scale summary of the topological
properties of a dataset that is based on the well-established theory of
persistent homology. Graphcodes handle datasets that are filtered along two
real-valued scale parameters. Such multi-parameter topological summaries are
usually based on complicated theoretical foundations and difficult to compute;
in contrast, graphcodes yield an informative and interpretable summary and can
be computed as efficient as one-parameter summaries. Moreover, a graphcode is
simply an embedded graph and can therefore be readily integrated in machine
learning pipelines using graph neural networks. We describe such a pipeline and
demonstrate that graphcodes achieve better classification accuracy than
state-of-the-art approaches on various datasets.",2024-05-23,"Michael Kerber, Florian Russold",http://arxiv.org/pdf/2405.14302v1,cs.LG
No Algorithmic Collusion in Two-Player Blindfolded Game with Thompson Sampling,"When two players are engaged in a repeated game with unknown payoff matrices,
they may be completely unaware of the existence of each other and use
multi-armed bandit algorithms to choose the actions, which is referred to as
the ``blindfolded game'' in this paper. We show that when the players use
Thompson sampling, the game dynamics converges to the Nash equilibrium under a
mild assumption on the payoff matrices. Therefore, algorithmic collusion
doesn't arise in this case despite the fact that the players do not
intentionally deploy competitive strategies. To prove the convergence result,
we find that the framework developed in stochastic approximation doesn't apply,
because of the sporadic and infrequent updates of the inferior actions and the
lack of Lipschitz continuity. We develop a novel sample-path-wise approach to
show the convergence.",2024-05-23,"Ningyuan Chen, Xuefeng Gao, Yi Xiong",http://arxiv.org/pdf/2405.17463v1,cs.LG
Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient Transformer Models,"The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the
efficiency of training and inference for Transformer-based foundational models,
yielding promising results.However, the performance of SMoE heavily depends on
the choice of hyper-parameters, such as the number of experts and the number of
experts to be activated (referred to as top-k), resulting in significant
computational overhead due to the extensive model training by searching over
various hyper-parameter configurations. As a remedy, we introduce the Dynamic
Mixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating
method that enables each token to automatically determine the number of experts
to activate. (2) An adaptive process automatically adjusts the number of
experts during training. Extensive numerical results across Vision, Language,
and Vision-Language tasks demonstrate the effectiveness of our approach to
achieve competitive performance compared to GMoE for vision and language tasks,
and MoE-LLaVA for vision-language tasks, while maintaining efficiency by
activating fewer parameters. Our code is available at
https://github.com/LINs-lab/DynMoE.",2024-05-23,"Yongxin Guo, Zhenglin Cheng, Xiaoying Tang, Zhaopeng Tu, Tao Lin",http://arxiv.org/pdf/2405.14297v4,cs.LG
Variational Bayes for Federated Continual Learning,"Federated continual learning (FCL) has received increasing attention due to
its potential in handling real-world streaming data, characterized by evolving
data distributions and varying client classes over time. The constraints of
storage limitations and privacy concerns confine local models to exclusively
access the present data within each learning cycle. Consequently, this
restriction induces performance degradation in model training on previous data,
termed ""catastrophic forgetting"". However, existing FCL approaches need to
identify or know changes in data distribution, which is difficult in the real
world. To release these limitations, this paper directs attention to a broader
continuous framework. Within this framework, we introduce Federated Bayesian
Neural Network (FedBNN), a versatile and efficacious framework employing a
variational Bayesian neural network across all clients. Our method continually
integrates knowledge from local and historical data distributions into a single
model, adeptly learning from new data distributions while retaining performance
on historical distributions. We rigorously evaluate FedBNN's performance
against prevalent methods in federated learning and continual learning using
various metrics. Experimental analyses across diverse datasets demonstrate that
FedBNN achieves state-of-the-art results in mitigating forgetting.",2024-05-23,"Dezhong Yao, Sanmu Li, Yutong Dai, Zhiqiang Xu, Shengshan Hu, Peilin Zhao, Lichao Sun",http://arxiv.org/pdf/2405.14291v1,cs.LG
Co-Representation Neural Hypergraph Diffusion for Edge-Dependent Node Classification,"Hypergraphs are widely employed to represent complex higher-order relations
in real-world applications. Most hypergraph learning research focuses on
node-level or edge-level tasks. A practically relevant but more challenging
task, edge-dependent node classification (ENC), is only recently proposed. In
ENC, a node can have different labels across different hyperedges, which
requires the modeling of node-edge pairs instead of single nodes or hyperedges.
Existing solutions for this task are based on message passing and model
interactions in within-edge and within-node structures as multi-input
single-output functions. This brings three limitations: (1) non-adaptive
representation size, (2) non-adaptive messages, and (3) insufficient direct
interactions among nodes or edges. To tackle these limitations, we propose
CoNHD, a new ENC solution that models both within-edge and within-node
interactions as multi-input multi-output functions. Specifically, we represent
these interactions as a hypergraph diffusion process on node-edge
co-representations. We further develop a neural implementation for this
diffusion process, which can adapt to a specific ENC dataset. Extensive
experiments demonstrate the effectiveness and efficiency of the proposed CoNHD
method.",2024-05-23,"Yijia Zheng, Marcel Worring",http://arxiv.org/pdf/2405.14286v2,cs.LG
Computing the Bias of Constant-step Stochastic Approximation with Markovian Noise,"We study stochastic approximation algorithms with Markovian noise and
constant step-size $\alpha$. We develop a method based on infinitesimal
generator comparisons to study the bias of the algorithm, which is the expected
difference between $\theta_n$ -- the value at iteration $n$ -- and $\theta^*$
-- the unique equilibrium of the corresponding ODE. We show that, under some
smoothness conditions, this bias is of order $O(\alpha)$. Furthermore, we show
that the time-averaged bias is equal to $\alpha V + O(\alpha^2)$, where $V$ is
a constant characterized by a Lyapunov equation, showing that
$\mathbb{E}[\bar{\theta}_n] \approx \theta^*+V\alpha + O(\alpha^2)$, where
$\bar{\theta}_n=(1/n)\sum_{k=1}^n\theta_k$ is the Polyak-Ruppert average. We
also show that $\bar{\theta}_n$ converges with high probability around
$\theta^*+\alpha V$. We illustrate how to combine this with Richardson-Romberg
extrapolation to derive an iterative scheme with a bias of order $O(\alpha^2)$.",2024-05-23,"Sebastian Allmeier, Nicolas Gast",http://arxiv.org/pdf/2405.14285v2,cs.LG
A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP,"We consider the inverse optimization problem of estimating the weights of the
objective function such that the given solution is an optimal solution for a
mixed integer linear program (MILP). In this inverse optimization problem, the
known methods exhibit inefficient convergence. Specifically, if $d$ denotes the
dimension of the weights and $k$ the number of iterations, then the error of
the weights is bounded by $O(k^{-1/(d-1)})$, leading to slow convergence as $d$
increases. We propose a projected subgradient method with a step size of
$k^{-1/2}$ based on suboptimality loss. We theoretically show and demonstrate
that the proposed method efficiently learns the weights. In particular, we show
that there exists a constant $\gamma > 0$ such that the distance between the
learned and true weights is bounded by $ O\left(k^{-1/(1+\gamma)}
\exp\left(-\frac{\gamma k^{1/2}}{2+\gamma}\right)\right), $ or the optimal
solution is exactly recovered. Furthermore, experiments demonstrate that the
proposed method solves the inverse optimization problems of MILP using fewer
than $1/7$ the number of MILP calls required by known methods, and converges
within a finite number of iterations.",2024-05-23,Akira Kitaoka,http://arxiv.org/pdf/2405.14273v3,cs.LG
Sparse $L^1$-Autoencoders for Scientific Data Compression,"Scientific datasets present unique challenges for machine learning-driven
compression methods, including more stringent requirements on accuracy and
mitigation of potential invalidating artifacts. Drawing on results from
compressed sensing and rate-distortion theory, we introduce effective data
compression methods by developing autoencoders using high dimensional latent
spaces that are $L^1$-regularized to obtain sparse low dimensional
representations. We show how these information-rich latent spaces can be used
to mitigate blurring and other artifacts to obtain highly effective data
compression methods for scientific data. We demonstrate our methods for short
angle scattering (SAS) datasets showing they can achieve compression ratios
around two orders of magnitude and in some cases better. Our compression
methods show promise for use in addressing current bottlenecks in transmission,
storage, and analysis in high-performance distributed computing environments.
This is central to processing the large volume of SAS data being generated at
shared experimental facilities around the world to support scientific
investigations. Our approaches provide general ways for obtaining specialized
compression methods for targeted scientific datasets.",2024-05-23,"Matthias Chung, Rick Archibald, Paul Atzberger, Jack Michael Solomon",http://arxiv.org/pdf/2405.14270v1,cs.LG
A Gap in Time: The Challenge of Processing Heterogeneous IoT Data in Digitalized Buildings,"The increasing demand for sustainable energy solutions has driven the
integration of digitalized buildings into the power grid, leveraging
Internet-of-Things (IoT) technologies to enhance energy efficiency and
operational performance. Despite their potential, effectively utilizing IoT
point data within deep-learning frameworks presents significant challenges,
primarily due to its inherent heterogeneity. This study investigates the
diverse dimensions of IoT data heterogeneity in both intra-building and
inter-building contexts, examining their implications for predictive modeling.
A benchmarking analysis of state-of-the-art time series models highlights their
performance on this complex dataset. The results emphasize the critical need
for multi-modal data integration, domain-informed modeling, and automated data
engineering pipelines. Additionally, the study advocates for collaborative
efforts to establish high-quality public datasets, which are essential for
advancing intelligent and sustainable energy management systems in digitalized
buildings.",2024-05-23,"Xiachong Lin, Arian Prabowo, Imran Razzak, Hao Xue, Matthew Amos, Sam Behrens, Flora D. Salim",http://arxiv.org/pdf/2405.14267v2,cs.LG
Reassessing Evaluation Functions in Algorithmic Recourse: An Empirical Study from a Human-Centered Perspective,"In this study, we critically examine the foundational premise of algorithmic
recourse - a process of generating counterfactual action plans (i.e.,
recourses) assisting individuals to reverse adverse decisions made by AI
systems. The assumption underlying algorithmic recourse is that individuals
accept and act on recourses that minimize the gap between their current and
desired states. This assumption, however, remains empirically unverified. To
address this issue, we conducted a user study with 362 participants and
assessed whether minimizing the distance function, a metric of the gap between
the current and desired states, indeed prompts them to accept and act upon
suggested recourses. Our findings reveal a nuanced landscape: participants'
acceptance of recourses did not correlate with the recourse distance. Moreover,
participants' willingness to act upon recourses peaked at the minimal recourse
distance but was otherwise constant. These findings cast doubt on the
prevailing assumption of algorithmic recourse research and signal the need to
rethink the evaluation functions to pave the way for human-centered recourse
generation.",2024-05-23,"Tomu Tominaga, Naomi Yamashita, Takeshi Kurashima",http://arxiv.org/pdf/2405.14264v2,cs.LG
Graph Sparsification via Mixture of Graphs,"Graph Neural Networks (GNNs) have demonstrated superior performance across
various graph learning tasks but face significant computational challenges when
applied to large-scale graphs. One effective approach to mitigate these
challenges is graph sparsification, which involves removing non-essential edges
to reduce computational overhead. However, previous graph sparsification
methods often rely on a single global sparsity setting and uniform pruning
criteria, failing to provide customized sparsification schemes for each node's
complex local context. In this paper, we introduce Mixture-of-Graphs (MoG),
leveraging the concept of Mixture-of-Experts (MoE), to dynamically select
tailored pruning solutions for each node. Specifically, MoG incorporates
multiple sparsifier experts, each characterized by unique sparsity levels and
pruning criteria, and selects the appropriate experts for each node.
Subsequently, MoG performs a mixture of the sparse graphs produced by different
experts on the Grassmann manifold to derive an optimal sparse graph. One
notable property of MoG is its entirely local nature, as it depends on the
specific circumstances of each individual node. Extensive experiments on four
large-scale OGB datasets and two superpixel datasets, equipped with five GNN
backbones, demonstrate that MoG (I) identifies subgraphs at higher sparsity
levels ($8.67\%\sim 50.85\%$), with performance equal to or better than the
dense graph, (II) achieves $1.47-2.62\times$ speedup in GNN inference with
negligible performance drop, and (III) boosts ``top-student'' GNN performance
($1.02\%\uparrow$ on RevGNN+\textsc{ogbn-proteins} and $1.74\%\uparrow$ on
DeeperGCN+\textsc{ogbg-ppa}).",2024-05-23,"Guibin Zhang, Xiangguo Sun, Yanwei Yue, Chonghe Jiang, Kun Wang, Tianlong Chen, Shirui Pan",http://arxiv.org/pdf/2405.14260v2,cs.LG
Deep Learning Methods for Adjusting Global MFD Speed Estimations to Local Link Configurations,"In large-scale traffic optimization, models based on Macroscopic Fundamental
Diagram (MFD) are recognized for their efficiency in broad network analyses.
However, they fail to reflect variations in the individual traffic status of
each road link, leading to a gap in detailed traffic optimization and analysis.
To address the limitation, this study introduces a Local Correction Factor
(LCF) that represents local speed deviations between the actual link speed and
the MFD average speed based on the link configuration. The LCF is calculated
using a deep learning function that takes as inputs the average speed from the
MFD and the road network configuration. Our framework integrates Graph
Attention Networks (GATs) with Gated Recurrent Units (GRUs) to capture both the
spatial configurations and temporal correlations within the network. Coupled
with a strategic network partitioning method, our model enhances the precision
of link-level traffic speed estimations while preserving the computational
advantages of aggregate models. In our experiments, we evaluate the proposed
LCF across various urban traffic scenarios, including different levels of
origin-destination trip demand and distribution, as well as diverse road
configurations. The results demonstrate the robust adaptability and
effectiveness of the proposed model. Furthermore, we validate the practicality
of our model by calculating the travel time of each randomly generated path,
achieving an average error reduction of approximately 84% relative to MFD-based
results.",2024-05-23,"Zhixiong Jin, Dimitrios Tsitsokas, Nikolas Geroliminis, Ludovic Leclercq",http://arxiv.org/pdf/2405.14257v2,cs.LG
ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification,"KV cache stores key and value states from previous tokens to avoid
re-computation, yet it demands substantial storage space, especially for long
sequences. Adaptive KV cache compression seeks to discern the saliency of
tokens, preserving vital information while aggressively compressing those of
less importance. However, previous methods of this approach exhibit significant
performance degradation at high compression ratios due to inaccuracies in
identifying salient tokens. In this paper, we present ZipCache, an accurate and
efficient KV cache quantization method for LLMs. First, we construct a strong
baseline for quantizing KV cache. Through the proposed channel-separable
tokenwise quantization scheme, the memory overhead of quantization parameters
are substantially reduced compared to fine-grained groupwise quantization. To
enhance the compression ratio, we propose normalized attention score as an
effective metric for identifying salient tokens by considering the lower
triangle characteristics of the attention matrix. Moreover, we develop an
efficient approximation method that decouples the saliency metric from full
attention scores, enabling compatibility with fast attention implementations
like FlashAttention. Extensive experiments demonstrate that ZipCache achieves
superior compression ratios, fast generation speed and minimal performance
losses compared with previous KV cache compression methods. For instance, when
evaluating Mistral-7B model on GSM8k dataset, ZipCache is capable of
compressing the KV cache by $4.98\times$, with only a $0.38\%$ drop in
accuracy. In terms of efficiency, ZipCache also showcases a $37.3\%$ reduction
in prefill-phase latency, a $56.9\%$ reduction in decoding-phase latency, and a
$19.8\%$ reduction in GPU memory usage when evaluating LLaMA3-8B model with a
input length of $4096$.",2024-05-23,"Yefei He, Luoming Zhang, Weijia Wu, Jing Liu, Hong Zhou, Bohan Zhuang",http://arxiv.org/pdf/2405.14256v1,cs.LG
Higher-Rank Irreducible Cartesian Tensors for Equivariant Message Passing,"The ability to perform fast and accurate atomistic simulations is crucial for
advancing the chemical sciences. By learning from high-quality data,
machine-learned interatomic potentials achieve accuracy on par with ab initio
and first-principles methods at a fraction of their computational cost. The
success of machine-learned interatomic potentials arises from integrating
inductive biases such as equivariance to group actions on an atomic system,
e.g., equivariance to rotations and reflections. In particular, the field has
notably advanced with the emergence of equivariant message passing. Most of
these models represent an atomic system using spherical tensors, tensor
products of which require complicated numerical coefficients and can be
computationally demanding. Cartesian tensors offer a promising alternative,
though state-of-the-art methods lack flexibility in message-passing mechanisms,
restricting their architectures and expressive power. This work explores
higher-rank irreducible Cartesian tensors to address these limitations. We
integrate irreducible Cartesian tensor products into message-passing neural
networks and prove the equivariance and traceless property of the resulting
layers. Through empirical evaluations on various benchmark data sets, we
consistently observe on-par or better performance than that of state-of-the-art
spherical and Cartesian models.",2024-05-23,"Viktor Zaverkin, Francesco Alesiani, Takashi Maruyama, Federico Errica, Henrik Christiansen, Makoto Takamoto, Nicolas Weber, Mathias Niepert",http://arxiv.org/pdf/2405.14253v2,cs.LG
Time-FFM: Towards LM-Empowered Federated Foundation Model for Time Series Forecasting,"Unlike natural language processing and computer vision, the development of
Foundation Models (FMs) for time series forecasting is blocked due to data
scarcity. While recent efforts are focused on building such FMs by unlocking
the potential of language models (LMs) for time series analysis, dedicated
parameters for various downstream forecasting tasks need training, which
hinders the common knowledge sharing across domains. Moreover, data owners may
hesitate to share the access to local data due to privacy concerns and
copyright protection, which makes it impossible to simply construct a FM on
cross-domain training instances. To address these issues, we propose Time-FFM,
a Federated Foundation Model for Time series forecasting by leveraging
pretrained LMs. Specifically, we begin by transforming time series into the
modality of text tokens. To bootstrap LMs for time series reasoning, we propose
a prompt adaption module to determine domain-customized prompts dynamically
instead of artificially. Given the data heterogeneity across domains, we design
a personalized federated training strategy by learning global encoders and
local prediction heads. Our comprehensive experiments indicate that Time-FFM
outperforms state-of-the-arts and promises effective few-shot and zero-shot
forecaster.",2024-05-23,"Qingxiang Liu, Xu Liu, Chenghao Liu, Qingsong Wen, Yuxuan Liang",http://arxiv.org/pdf/2405.14252v4,cs.LG
Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors,"Diffusion or score-based models recently showed high performance in image
generation. They rely on a forward and a backward stochastic differential
equations (SDE). The sampling of a data distribution is achieved by solving
numerically the backward SDE or its associated flow ODE. Studying the
convergence of these models necessitates to control four different types of
error: the initialization error, the truncation error, the discretization and
the score approximation. In this paper, we study theoretically the behavior of
diffusion models and their numerical implementation when the data distribution
is Gaussian. In this restricted framework where the score function is a linear
operator, we derive the analytical solutions of the backward SDE and the
probability flow ODE. We prove that these solutions and their discretizations
are all Gaussian processes, which allows us to compute exact Wasserstein errors
induced by each error type for any sampling scheme. Monitoring convergence
directly in the data space instead of relying on Inception features, our
experiments show that the recommended numerical schemes from the diffusion
models literature are also the best sampling schemes for Gaussian
distributions.",2024-05-23,"Emile Pierret, Bruno Galerne",http://arxiv.org/pdf/2405.14250v4,cs.LG
GCondenser: Benchmarking Graph Condensation,"Large-scale graphs are valuable for graph representation learning, yet the
abundant data in these graphs hinders the efficiency of the training process.
Graph condensation (GC) alleviates this issue by compressing the large graph
into a significantly smaller one that still supports effective model training.
Although recent research has introduced various approaches to improve the
effectiveness of the condensed graph, comprehensive and practical evaluations
across different GC methods are neglected. This paper proposes the first
large-scale graph condensation benchmark, GCondenser, to holistically evaluate
and compare mainstream GC methods. GCondenser includes a standardised GC
paradigm, consisting of condensation, validation, and evaluation procedures, as
well as enabling extensions to new GC methods and datasets. With GCondenser, a
comprehensive performance study is conducted, presenting the effectiveness of
existing methods. GCondenser is open-sourced and available at
https://github.com/superallen13/GCondenser.",2024-05-23,"Yilun Liu, Ruihong Qiu, Zi Huang",http://arxiv.org/pdf/2405.14246v3,cs.LG
Tell me why: Training preferences-based RL with human preferences and step-level explanations,"Human-in-the-loop reinforcement learning allows the training of agents
through various interfaces, even for non-expert humans. Recently,
preference-based methods (PbRL), where the human has to give his preference
over two trajectories, increased in popularity since they allow training in
domains where more direct feedback is hard to formulate. However, the current
PBRL methods have limitations and do not provide humans with an expressive
interface for giving feedback. With this work, we propose a new
preference-based learning method that provides humans with a more expressive
interface to provide their preference over trajectories and a factual
explanation (or annotation of why they have this preference). These
explanations allow the human to explain what parts of the trajectory are most
relevant for the preference. We allow the expression of the explanations over
individual trajectory steps. We evaluate our method in various simulations
using a simulated human oracle (with realistic restrictions), and our results
show that our extended feedback can improve the speed of learning.",2024-05-23,Jakob Karalus,http://arxiv.org/pdf/2405.14244v2,cs.LG
Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity,"The advent of Federated Learning (FL) highlights the practical necessity for
the right to be forgotten for all clients, allowing them to request data
deletion from the machine learning models service provider. This necessity has
spurred a growing demand for Federated Unlearning (FU). Feature unlearning has
gained considerable attention due to its applications in unlearning sensitive,
backdoor, and biased features. Existing methods employ the influence function
to achieve feature unlearning, which is impractical for FL as it necessitates
the participation of other clients, if not all, in the unlearning process.
Furthermore, current research lacks an evaluation of the effectiveness of
feature unlearning. To address these limitations, we define feature sensitivity
in evaluating feature unlearning according to Lipschitz continuity. This metric
characterizes the model outputs rate of change or sensitivity to perturbations
in the input feature. We then propose an effective federated feature unlearning
framework called Ferrari, which minimizes feature sensitivity. Extensive
experimental results and theoretical analysis demonstrate the effectiveness of
Ferrari across various feature unlearning scenarios, including sensitive,
backdoor, and biased features. The code is publicly available at
https://github.com/OngWinKent/Federated-Feature-Unlearning",2024-05-23,"Hanlin Gu, Win Kent Ong, Chee Seng Chan, Lixin Fan",http://arxiv.org/pdf/2405.17462v4,cs.LG
Harmony: A Joint Self-Supervised and Weakly-Supervised Framework for Learning General Purpose Visual Representations,"Vision-language contrastive learning frameworks like CLIP enable learning
representations from natural language supervision, and provide strong zero-shot
classification capabilities. However, due to the nature of the supervisory
signal in these paradigms, they lack the ability to learn localized features,
leading to degraded performance on dense prediction tasks like segmentation and
detection. On the other hand, self-supervised learning methods have shown the
ability to learn granular representations, complementing the high-level
features in vision-language training. In this work, we present Harmony, a
framework that combines vision-language training with discriminative and
generative self-supervision to learn visual features that can be generalized
across different vision downstream tasks. Our framework is specifically
designed to work on web-scraped data by not relying on negative examples and
addressing the one-to-one correspondence issue using soft CLIP targets
generated by an EMA model. We comprehensively evaluate Harmony across various
vision downstream tasks and find that it significantly outperforms the baseline
CLIP and the previously leading joint self and weakly-supervised methods,
MaskCLIP and SLIP. Specifically, when comparing against these methods, Harmony
shows superior performance in fine-tuning and zero-shot classification on
ImageNet-1k, semantic segmentation on ADE20K, and both object detection and
instance segmentation on MS-COCO, when pre-training a ViT-B on CC3M. We also
show that Harmony outperforms other self-supervised learning methods like iBOT
and MAE across all tasks evaluated. Our code is publicly at
https://github.com/MohammedSB/Harmony}{https://github.com/MohammedSB/Harmony
available.",2024-05-23,"Mohammed Baharoon, Jonathan Klein, Dominik L. Michels",http://arxiv.org/pdf/2405.14239v2,cs.LG
Language processing in humans and computers,"Machine-learned language models have transformed everyday life: they steer us
when we study, drive, manage money. They have the potential to transform our
civilization. But they hallucinate. Their realities are virtual. This note
provides a high-level overview of language models and outlines a low-level
model of learning machines. It turns out that, after they become capable of
recognizing hallucinations and dreaming safely, as humans tend to be, the
language-learning machines proceed to generate broader systems of false beliefs
and self-confirming theories, as humans tend to do.",2024-05-23,Dusko Pavlovic,http://arxiv.org/pdf/2405.14233v1,cs.LG
FloodDamageCast: Building Flood Damage Nowcasting with Machine Learning and Data Augmentation,"Near-real time estimation of damage to buildings and infrastructure, referred
to as damage nowcasting in this study, is crucial for empowering emergency
responders to make informed decisions regarding evacuation orders and
infrastructure repair priorities during disaster response and recovery. Here,
we introduce FloodDamageCast, a machine learning framework tailored for
property flood damage nowcasting. The framework leverages heterogeneous data to
predict residential flood damage at a resolution of 500 meters by 500 meters
within Harris County, Texas, during the 2017 Hurricane Harvey. To deal with
data imbalance, FloodDamageCast incorporates a generative adversarial
networks-based data augmentation coupled with an efficient machine learning
model. The results demonstrate the model's ability to identify high-damage
spatial areas that would be overlooked by baseline models. Insights gleaned
from flood damage nowcasting can assist emergency responders to more
efficiently identify repair needs, allocate resources, and streamline
on-the-ground inspections, thereby saving both time and effort.",2024-05-23,"Chia-Fu Liu, Lipai Huang, Kai Yin, Sam Brody, Ali Mostafavi",http://arxiv.org/pdf/2405.14232v2,cs.LG
Variational Delayed Policy Optimization,"In environments with delayed observation, state augmentation by including
actions within the delay window is adopted to retrieve Markovian property to
enable reinforcement learning (RL). However, state-of-the-art (SOTA) RL
techniques with Temporal-Difference (TD) learning frameworks often suffer from
learning inefficiency, due to the significant expansion of the augmented state
space with the delay. To improve learning efficiency without sacrificing
performance, this work introduces a novel framework called Variational Delayed
Policy Optimization (VDPO), which reformulates delayed RL as a variational
inference problem. This problem is further modelled as a two-step iterative
optimization problem, where the first step is TD learning in the delay-free
environment with a small state space, and the second step is behaviour cloning
which can be addressed much more efficiently than TD learning. We not only
provide a theoretical analysis of VDPO in terms of sample complexity and
performance, but also empirically demonstrate that VDPO can achieve consistent
performance with SOTA methods, with a significant enhancement of sample
efficiency (approximately 50\% less amount of samples) in the MuJoCo benchmark.",2024-05-23,"Qingyuan Wu, Simon Sinong Zhan, Yixuan Wang, Yuhui Wang, Chung-Wei Lin, Chen Lv, Qi Zhu, Chao Huang",http://arxiv.org/pdf/2405.14226v2,cs.LG
Rate-Adaptive Quantization: A Multi-Rate Codebook Adaptation for Vector Quantization-based Generative Models,"Learning discrete representations with vector quantization (VQ) has emerged
as a powerful approach in various generative models. However, most VQ-based
models rely on a single, fixed-rate codebook, requiring extensive retraining
for new bitrates or efficiency requirements. We introduce Rate-Adaptive
Quantization (RAQ), a multi-rate codebook adaptation framework for VQ-based
generative models. RAQ applies a data-driven approach to generate variable-rate
codebooks from a single baseline VQ model, enabling flexible tradeoffs between
compression and reconstruction fidelity. Additionally, we provide a simple
clustering-based procedure for pre-trained VQ models, offering an alternative
when retraining is infeasible. Our experiments show that RAQ performs
effectively across multiple rates, often outperforming conventional fixed-rate
VQ baselines. By enabling a single system to seamlessly handle diverse bitrate
requirements, RAQ extends the adaptability of VQ-based generative models and
broadens their applicability to data compression, reconstruction, and
generation tasks.",2024-05-23,"Jiwan Seo, Joonhyuk Kang",http://arxiv.org/pdf/2405.14222v2,cs.LG
Understanding the Training and Generalization of Pretrained Transformer for Sequential Decision Making,"In this paper, we consider the supervised pre-trained transformer for a class
of sequential decision-making problems. The class of considered problems is a
subset of the general formulation of reinforcement learning in that there is no
transition probability matrix; though seemingly restrictive, the subset class
of problems covers bandits, dynamic pricing, and newsvendor problems as special
cases. Such a structure enables the use of optimal actions/decisions in the
pre-training phase, and the usage also provides new insights for the training
and generalization of the pre-trained transformer. We first note the training
of the transformer model can be viewed as a performative prediction problem,
and the existing methods and theories largely ignore or cannot resolve an
out-of-distribution issue. We propose a natural solution that includes the
transformer-generated action sequences in the training procedure, and it enjoys
better properties both numerically and theoretically. The availability of the
optimal actions in the considered tasks also allows us to analyze the
properties of the pre-trained transformer as an algorithm and explains why it
may lack exploration and how this can be automatically resolved. Numerically,
we categorize the advantages of pre-trained transformers over the structured
algorithms such as UCB and Thompson sampling into three cases: (i) it better
utilizes the prior knowledge in the pre-training data; (ii) it can elegantly
handle the misspecification issue suffered by the structured algorithms; (iii)
for short time horizon such as $T\le50$, it behaves more greedy and enjoys much
better regret than the structured algorithms designed for asymptotic
optimality.",2024-05-23,"Hanzhao Wang, Yu Pan, Fupeng Sun, Shang Liu, Kalyan Talluri, Guanting Chen, Xiaocheng Li",http://arxiv.org/pdf/2405.14219v2,cs.LG
A Behavior-Aware Approach for Deep Reinforcement Learning in Non-stationary Environments without Known Change Points,"Deep reinforcement learning is used in various domains, but usually under the
assumption that the environment has stationary conditions like transitions and
state distributions. When this assumption is not met, performance suffers. For
this reason, tracking continuous environmental changes and adapting to
unpredictable conditions is challenging yet crucial because it ensures that
systems remain reliable and flexible in practical scenarios. Our research
introduces Behavior-Aware Detection and Adaptation (BADA), an innovative
framework that merges environmental change detection with behavior adaptation.
The key inspiration behind our method is that policies exhibit different global
behaviors in changing environments. Specifically, environmental changes are
identified by analyzing variations between behaviors using Wasserstein
distances without manually set thresholds. The model adapts to the new
environment through behavior regularization based on the extent of changes. The
results of a series of experiments demonstrate better performance relative to
several current algorithms. This research also indicates significant potential
for tackling this long-standing challenge.",2024-05-23,"Zihe Liu, Jie Lu, Guangquan Zhang, Junyu Xuan",http://arxiv.org/pdf/2405.14214v1,cs.LG
Agent Planning with World Knowledge Model,"Recent endeavors towards directly using large language models (LLMs) as agent
models to execute interactive planning tasks have shown commendable results.
Despite their achievements, however, they still struggle with brainless
trial-and-error in global planning and generating hallucinatory actions in
local planning due to their poor understanding of the ``real'' physical world.
Imitating humans' mental world knowledge model which provides global prior
knowledge before the task and maintains local dynamic knowledge during the
task, in this paper, we introduce parametric World Knowledge Model (WKM) to
facilitate agent planning. Concretely, we steer the agent model to
self-synthesize knowledge from both expert and sampled trajectories. Then we
develop WKM, providing prior task knowledge to guide the global planning and
dynamic state knowledge to assist the local planning. Experimental results on
three complex real-world simulated datasets with three state-of-the-art
open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our
method can achieve superior performance compared to various strong baselines.
Besides, we analyze to illustrate that our WKM can effectively alleviate the
blind trial-and-error and hallucinatory action issues, providing strong support
for the agent's understanding of the world. Other interesting findings include:
1) our instance-level task knowledge can generalize better to unseen tasks, 2)
weak WKM can guide strong agent model planning, and 3) unified WKM training has
promising potential for further development. The code is available at
https://github.com/zjunlp/WKM.",2024-05-23,"Shuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu, Xiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",http://arxiv.org/pdf/2405.14205v4,cs.LG
GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices,"This paper presents a novel approach for predicting Power Conversion
Efficiency (PCE) of Organic Photovoltaic (OPV) devices, called GLaD:
synergizing molecular Graphs and Language Descriptors for enhanced PCE
prediction. Due to the lack of high-quality experimental data, we collect a
dataset consisting of 500 pairs of OPV donor and acceptor molecules along with
their corresponding PCE values, which we utilize as the training data for our
predictive model. In this low-data regime, GLaD leverages properties learned
from large language models (LLMs) pretrained on extensive scientific literature
to enrich molecular structural representations, allowing for a multimodal
representation of molecules. GLaD achieves precise predictions of PCE, thereby
facilitating the synthesis of new OPV molecules with improved efficiency.
Furthermore, GLaD showcases versatility, as it applies to a range of molecular
property prediction tasks (BBBP, BACE, ClinTox, and SIDER), not limited to
those concerning OPV materials. Especially, GLaD proves valuable for tasks in
low-data regimes within the chemical space, as it enriches molecular
representations by incorporating molecular property descriptions learned from
large-scale pretraining. This capability is significant in real-world
scientific endeavors like drug and material discovery, where access to
comprehensive data is crucial for informed decision-making and efficient
exploration of the chemical space.",2024-05-23,"Thao Nguyen, Tiara Torres-Flores, Changhyun Hwang, Carl Edwards, Ying Diao, Heng Ji",http://arxiv.org/pdf/2405.14203v1,cs.LG
Adaptive Teaching in Heterogeneous Agents: Balancing Surprise in Sparse Reward Scenarios,"Learning from Demonstration (LfD) can be an efficient way to train systems
with analogous agents by enabling ``Student'' agents to learn from the
demonstrations of the most experienced ``Teacher'' agent, instead of training
their policy in parallel. However, when there are discrepancies in agent
capabilities, such as divergent actuator power or joint angle constraints,
naively replicating demonstrations that are out of bounds for the Student's
capability can limit efficient learning. We present a Teacher-Student learning
framework specifically tailored to address the challenge of heterogeneity
between the Teacher and Student agents. Our framework is based on the concept
of ``surprise'', inspired by its application in exploration incentivization in
sparse-reward environments. Surprise is repurposed to enable the Teacher to
detect and adapt to differences between itself and the Student. By focusing on
maximizing its surprise in response to the environment while concurrently
minimizing the Student's surprise in response to the demonstrations, the
Teacher agent can effectively tailor its demonstrations to the Student's
specific capabilities and constraints. We validate our method by demonstrating
improvements in the Student's learning in control tasks within sparse-reward
environments.",2024-05-23,"Emma Clark, Kanghyun Ryu, Negar Mehr",http://arxiv.org/pdf/2405.14199v1,cs.LG
Graphlets correct for the topological information missed by random walks,"Random walks are widely used for mining networks due to the computational
efficiency of computing them. For instance, graph representation learning
learns a d-dimensional embedding space, so that the nodes that tend to co-occur
on random walks (a proxy of being in the same network neighborhood) are close
in the embedding space. Specific local network topology (i.e., structure)
influences the co-occurrence of nodes on random walks, so random walks of
limited length capture only partial topological information, hence diminishing
the performance of downstream methods. We explicitly capture all topological
neighborhood information and improve performance by introducing orbit
adjacencies that quantify the adjacencies of two nodes as co-occurring on a
given pair of graphlet orbits, which are symmetric positions on graphlets
(small, connected, non-isomorphic, induced subgraphs of a large network).
Importantly, we mathematically prove that random walks on up to k nodes capture
only a subset of all the possible orbit adjacencies for up to k-node graphlets.
Furthermore, we enable orbit adjacency-based analysis of networks by developing
an efficient GRaphlet-orbit ADjacency COunter (GRADCO), which exhaustively
computes all 28 orbit adjacency matrices for up to four-node graphlets. Note
that four-node graphlets suffice, because real networks are usually
small-world. In large networks on around 20,000 nodes,
GRADCOcomputesthe28matricesinminutes. Onsixrealnetworksfromvarious domains, we
compare the performance of node-label predictors obtained by using the network
embeddings based on our orbit adjacencies to those based on random walks. We
find that orbit adjacencies, which include those unseen by random walks,
outperform random walk-based adjacencies, demonstrating the importance of the
inclusion of the topological neighborhood information that is unseen by random
walks.",2024-05-23,"Sam F. L. Windels, Noel Malod-Dognin, Natasa Przulj",http://arxiv.org/pdf/2405.14194v1,cs.LG
Fairness Hub Technical Briefs: Definition and Detection of Distribution Shift,"Distribution shift is a common situation in machine learning tasks, where the
data used for training a model is different from the data the model is applied
to in the real world. This issue arises across multiple technical settings:
from standard prediction tasks, to time-series forecasting, and to more recent
applications of large language models (LLMs). This mismatch can lead to
performance reductions, and can be related to a multiplicity of factors:
sampling issues and non-representative data, changes in the environment or
policies, or the emergence of previously unseen scenarios. This brief focuses
on the definition and detection of distribution shifts in educational settings.
We focus on standard prediction problems, where the task is to learn a model
that takes in a series of input (predictors) $X=(x_1,x_2,...,x_m)$ and produces
an output $Y=f(X)$.",2024-05-23,"Nicolas Acevedo, Carmen Cortez, Chris Brooks, Rene Kizilcec, Renzhe Yu",http://arxiv.org/pdf/2405.14186v1,cs.LG
A Structure-Aware Framework for Learning Device Placements on Computation Graphs,"Computation graphs are Directed Acyclic Graphs (DAGs) where the nodes
correspond to mathematical operations and are used widely as abstractions in
optimizations of neural networks. The device placement problem aims to identify
optimal allocations of those nodes to a set of (potentially heterogeneous)
devices. Existing approaches rely on two types of architectures known as
grouper-placer and encoder-placer, respectively. In this work, we bridge the
gap between encoder-placer and grouper-placer techniques and propose a novel
framework for the task of device placement, relying on smaller computation
graphs extracted from the OpenVINO toolkit. The framework consists of five
steps, including graph coarsening, node representation learning and policy
optimization. It facilitates end-to-end training and takes into account the DAG
nature of the computation graphs. We also propose a model variant, inspired by
graph parsing networks and complex network analysis, enabling graph
representation learning and jointed, personalized graph partitioning, using an
unspecified number of groups. To train the entire framework, we use
reinforcement learning using the execution time of the placement as a reward.
We demonstrate the flexibility and effectiveness of our approach through
multiple experiments with three benchmark models, namely Inception-V3, ResNet,
and BERT. The robustness of the proposed framework is also highlighted through
an ablation study. The suggested placements improve the inference speed for the
benchmark models by up to 58.2% over CPU execution and by up to 60.24% compared
to other commonly used baselines.",2024-05-23,"Shukai Duan, Heng Ping, Nikos Kanakaris, Xiongye Xiao, Panagiotis Kyriakis, Nesreen K. Ahmed, Peiyu Zhang, Guixiang Ma, Mihai Capota, Shahin Nazarian, Theodore L. Willke, Paul Bogdan",http://arxiv.org/pdf/2405.14185v2,cs.LG
Deterministic Policies for Constrained Reinforcement Learning in Polynomial Time,"We present a novel algorithm that efficiently computes near-optimal
deterministic policies for constrained reinforcement learning (CRL) problems.
Our approach combines three key ideas: (1) value-demand augmentation, (2)
action-space approximate dynamic programming, and (3) time-space rounding. Our
algorithm constitutes a fully polynomial-time approximation scheme (FPTAS) for
any time-space recursive (TSR) cost criteria. A TSR criteria requires the cost
of a policy to be computable recursively over both time and (state) space,
which includes classical expectation, almost sure, and anytime constraints. Our
work answers three open questions spanning two long-standing lines of research:
polynomial-time approximability is possible for 1) anytime-constrained
policies, 2) almost-sure-constrained policies, and 3) deterministic
expectation-constrained policies.",2024-05-23,Jeremy McMahan,http://arxiv.org/pdf/2405.14183v2,cs.LG
EMR-Merging: Tuning-Free High-Performance Model Merging,"The success of pretrain-finetune paradigm brings about the release of
numerous model weights. In this case, merging models finetuned on different
tasks to enable a single model with multi-task capabilities is gaining
increasing attention for its practicability. Existing model merging methods
usually suffer from (1) significant performance degradation or (2) requiring
tuning by additional data or training. In this paper, we rethink and analyze
the existing model merging paradigm. We discover that using a single model's
weights can hardly simulate all the models' performance. To tackle this issue,
we propose Elect, Mask & Rescale-Merging (EMR-Merging). We first (a) elect a
unified model from all the model weights and then (b) generate extremely
lightweight task-specific modulators, including masks and rescalers, to align
the direction and magnitude between the unified model and each specific model,
respectively. EMR-Merging is tuning-free, thus requiring no data availability
or any additional training while showing impressive performance. We find that
EMR-Merging shows outstanding performance compared to existing merging methods
under different classical and newly-established settings, including merging
different numbers of vision models (up to 30), NLP models, PEFT models, and
multi-modal models.",2024-05-23,"Chenyu Huang, Peng Ye, Tao Chen, Tong He, Xiangyu Yue, Wanli Ouyang",http://arxiv.org/pdf/2405.17461v2,cs.LG
Certified Robustness against Sparse Adversarial Perturbations via Data Localization,"Recent work in adversarial robustness suggests that natural data
distributions are localized, i.e., they place high probability in small volume
regions of the input space, and that this property can be utilized for
designing classifiers with improved robustness guarantees for $\ell_2$-bounded
perturbations. Yet, it is still unclear if this observation holds true for more
general metrics. In this work, we extend this theory to $\ell_0$-bounded
adversarial perturbations, where the attacker can modify a few pixels of the
image but is unrestricted in the magnitude of perturbation, and we show
necessary and sufficient conditions for the existence of $\ell_0$-robust
classifiers. Theoretical certification approaches in this regime essentially
employ voting over a large ensemble of classifiers. Such procedures are
combinatorial and expensive or require complicated certification techniques. In
contrast, a simple classifier emerges from our theory, dubbed Box-NN, which
naturally incorporates the geometry of the problem and improves upon the
current state-of-the-art in certified robustness against sparse attacks for the
MNIST and Fashion-MNIST datasets.",2024-05-23,"Ambar Pal, René Vidal, Jeremias Sulam",http://arxiv.org/pdf/2405.14176v1,cs.LG
Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks,"Aiming at the limitations of traditional medical decision system in
processing large-scale heterogeneous medical data and realizing highly
personalized recommendation, this paper introduces a personalized medical
decision algorithm utilizing graph neural network (GNN). This research
innovatively integrates graph neural network technology into the medical and
health field, aiming to build a high-precision representation model of patient
health status by mining the complex association between patients' clinical
characteristics, genetic information, living habits. In this study, medical
data is preprocessed to transform it into a graph structure, where nodes
represent different data entities (such as patients, diseases, genes, etc.) and
edges represent interactions or relationships between entities. The core of the
algorithm is to design a novel multi-scale fusion mechanism, combining the
historical medical records, physiological indicators and genetic
characteristics of patients, to dynamically adjust the attention allocation
strategy of the graph neural network, so as to achieve highly customized
analysis of individual cases. In the experimental part, this study selected
several publicly available medical data sets for validation, and the results
showed that compared with traditional machine learning methods and a single
graph neural network model, the proposed personalized medical decision
algorithm showed significantly superior performance in terms of disease
prediction accuracy, treatment effect evaluation and patient risk
stratification.",2024-05-23,"Yafeng Yan, Shuyao He, Zhou Yu, Jiajie Yuan, Ziang Liu, Yan Chen",http://arxiv.org/pdf/2405.17460v1,cs.LG
Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models,"We propose an unsupervised adaptation framework, Self-TAught Recognizer
(STAR), which leverages unlabeled data to enhance the robustness of automatic
speech recognition (ASR) systems in diverse target domains, such as noise and
accents. STAR is developed for prevalent speech foundation models based on
Transformer-related architecture with auto-regressive decoding (e.g., Whisper,
Canary). Specifically, we propose a novel indicator that empirically integrates
step-wise information during decoding to assess the token-level quality of
pseudo labels without ground truth, thereby guiding model updates for effective
unsupervised adaptation. Experimental results show that STAR achieves an
average of 13.5% relative reduction in word error rate across 14 target
domains, and it sometimes even approaches the upper-bound performance of
supervised adaptation. Surprisingly, we also observe that STAR prevents the
adapted model from the common catastrophic forgetting problem without recalling
source-domain data. Furthermore, STAR exhibits high data efficiency that only
requires less than one-hour unlabeled data, and seamless generality to
alternative large speech models and speech translation tasks. Our code aims to
open source to the research communities.",2024-05-23,"Yuchen Hu, Chen Chen, Chao-Han Huck Yang, Chengwei Qin, Pin-Yu Chen, Eng Siong Chng, Chao Zhang",http://arxiv.org/pdf/2405.14161v1,cs.LG
A Neighbor-Searching Discrepancy-based Drift Detection Scheme for Learning Evolving Data,"Uncertain changes in data streams present challenges for machine learning
models to dynamically adapt and uphold performance in real-time. Particularly,
classification boundary change, also known as real concept drift, is the major
cause of classification performance deterioration. However, accurately
detecting real concept drift remains challenging because the theoretical
foundations of existing drift detection methods - two-sample distribution tests
and monitoring classification error rate, both suffer from inherent limitations
such as the inability to distinguish virtual drift (changes not affecting the
classification boundary, will introduce unnecessary model maintenance), limited
statistical power, or high computational cost. Furthermore, no existing
detection method can provide information on the trend of the drift, which could
be invaluable for model maintenance. This work presents a novel real concept
drift detection method based on Neighbor-Searching Discrepancy, a new statistic
that measures the classification boundary difference between two samples. The
proposed method is able to detect real concept drift with high accuracy while
ignoring virtual drift. It can also indicate the direction of the
classification boundary change by identifying the invasion or retreat of a
certain class, which is also an indicator of separability change between
classes. A comprehensive evaluation of 11 experiments is conducted, including
empirical verification of the proposed theory using artificial datasets, and
experimental comparisons with commonly used drift handling methods on
real-world datasets. The results show that the proposed theory is robust
against a range of distributions and dimensions, and the drift detection method
outperforms state-of-the-art alternative methods.",2024-05-23,"Feng Gu, Jie Lu, Zhen Fang, Kun Wang, Guangquan Zhang",http://arxiv.org/pdf/2405.14153v1,cs.LG
Minimum number of neurons in fully connected layers of a given neural network (the first approximation),"This paper presents an algorithm for searching for the minimum number of
neurons in fully connected layers of an arbitrary network solving given
problem, which does not require multiple training of the network with different
number of neurons. The algorithm is based at training the initial wide network
using the cross-validation method over at least two folds. Then by using
truncated singular value decomposition autoencoder inserted after the studied
layer of trained network we search the minimum number of neurons in inference
only mode of the network.
  It is shown that the minimum number of neurons in a fully connected layer
could be interpreted not as network hyperparameter associated with the other
hyperparameters of the network, but as internal (latent) property of the
solution, determined by the network architecture, the training dataset, layer
position, and the quality metric used. So the minimum number of neurons can be
estimated for each hidden fully connected layer independently. The proposed
algorithm is the first approximation for estimating the minimum number of
neurons in the layer, since, on the one hand, the algorithm does not guarantee
that a neural network with the found number of neurons can be trained to the
required quality, and on the other hand, it searches for the minimum number of
neurons in a limited class of possible solutions.
  The solution was tested on several datasets in classification and regression
problems.",2024-05-23,Oleg I. Berngardt,http://arxiv.org/pdf/2405.14147v1,cs.LG
"Contribute to balance, wire in accordance: Emergence of backpropagation from a simple, bio-plausible neuroplasticity rule","Backpropagation (BP) has been pivotal in advancing machine learning and
remains essential in computational applications and comparative studies of
biological and artificial neural networks. Despite its widespread use, the
implementation of BP in the brain remains elusive, and its biological
plausibility is often questioned due to inherent issues such as the need for
symmetry of weights between forward and backward connections, and the
requirement of distinct forward and backward phases of computation. Here, we
introduce a novel neuroplasticity rule that offers a potential mechanism for
implementing BP in the brain. Similar in general form to the classical Hebbian
rule, this rule is based on the core principles of maintaining the balance of
excitatory and inhibitory inputs as well as on retrograde signaling, and
operates over three progressively slower timescales: neural firing, retrograde
signaling, and neural plasticity. We hypothesize that each neuron possesses an
internal state, termed credit, in addition to its firing rate. After achieving
equilibrium in firing rates, neurons receive credits based on their
contribution to the E-I balance of postsynaptic neurons through retrograde
signaling. As the network's credit distribution stabilizes, connections from
those presynaptic neurons are strengthened that significantly contribute to the
balance of postsynaptic neurons. We demonstrate mathematically that our
learning rule precisely replicates BP in layered neural networks without any
approximations. Simulations on artificial neural networks reveal that this rule
induces varying community structures in networks, depending on the learning
rate. This simple theoretical framework presents a biologically plausible
implementation of BP, with testable assumptions and predictions that may be
evaluated through biological experiments.",2024-05-23,"Xinhao Fan, Shreesh P Mysore",http://arxiv.org/pdf/2405.14139v2,cs.LG
Space-aware Socioeconomic Indicator Inference with Heterogeneous Graphs,"Regional socioeconomic indicators are critical across various domains, yet
their acquisition can be costly. Inferring global socioeconomic indicators from
a limited number of regional samples is essential for enhancing management and
sustainability in urban areas and human settlements. Current inference methods
typically rely on spatial interpolation based on the assumption of spatial
continuity, which does not adequately address the complex variations present
within regional spaces. In this paper, we present GeoHG, the first space-aware
socioeconomic indicator inference method that utilizes a heterogeneous
graph-based structure to represent geospace for non-continuous inference.
Extensive experiments demonstrate the effectiveness of GeoHG in comparison to
existing methods, achieving an $R^2$ score exceeding 0.8 under extreme data
scarcity with a masked ratio of 95\%.",2024-05-23,"Xingchen Zou, Jiani Huang, Xixuan Hao, Yuhao Yang, Haomin Wen, Yibo Yan, Chao Huang, Chao Chen, Yuxuan Liang",http://arxiv.org/pdf/2405.14135v3,cs.LG
Automated Loss function Search for Class-imbalanced Node Classification,"Class-imbalanced node classification tasks are prevalent in real-world
scenarios. Due to the uneven distribution of nodes across different classes,
learning high-quality node representations remains a challenging endeavor. The
engineering of loss functions has shown promising potential in addressing this
issue. It involves the meticulous design of loss functions, utilizing
information about the quantities of nodes in different categories and the
network's topology to learn unbiased node representations. However, the design
of these loss functions heavily relies on human expert knowledge and exhibits
limited adaptability to specific target tasks. In this paper, we introduce a
high-performance, flexible, and generalizable automated loss function search
framework to tackle this challenge. Across 15 combinations of graph neural
networks and datasets, our framework achieves a significant improvement in
performance compared to state-of-the-art methods. Additionally, we observe that
homophily in graph-structured data significantly contributes to the
transferability of the proposed framework.",2024-05-23,"Xinyu Guo, Kai Wu, Xiaoyu Zhang, Jing Liu",http://arxiv.org/pdf/2405.14133v1,cs.LG
Text-to-Model: Text-Conditioned Neural Network Diffusion for Train-Once-for-All Personalization,"Generative artificial intelligence (GenAI) has made significant progress in
understanding world knowledge and generating content from human languages
across various modalities, like text-to-text large language models,
text-to-image stable diffusion, and text-to-video Sora. While in this paper, we
investigate the capability of GenAI for text-to-model generation, to see
whether GenAI can comprehend hyper-level knowledge embedded within AI itself
parameters. Specifically, we study a practical scenario termed
train-once-for-all personalization, aiming to generate personalized models for
diverse end-users and tasks using text prompts. Inspired by the recent
emergence of neural network diffusion, we present Tina, a text-conditioned
neural network diffusion for train-once-for-all personalization. Tina leverages
a diffusion transformer model conditioned on task descriptions embedded using a
CLIP model. Despite the astronomical number of potential personalized tasks
(e.g., $1.73\times10^{13}$), by our design, Tina demonstrates remarkable
in-distribution and out-of-distribution generalization even trained on small
datasets ($\sim 1000$). We further verify whether and how \Tina understands
world knowledge by analyzing its capabilities under zero-shot/few-shot image
prompts, different numbers of personalized classes, prompts of natural language
descriptions, and predicting unseen entities.",2024-05-23,"Zexi Li, Lingzhi Gao, Chao Wu",http://arxiv.org/pdf/2405.14132v2,cs.LG
Statistical Advantages of Perturbing Cosine Router in Mixture of Experts,"The cosine router in Mixture of Experts (MoE) has recently emerged as an
attractive alternative to the conventional linear router. Indeed, the cosine
router demonstrates favorable performance in image and language tasks and
exhibits better ability to mitigate the representation collapse issue, which
often leads to parameter redundancy and limited representation potentials.
Despite its empirical success, a comprehensive analysis of the cosine router in
MoE has been lacking. Considering the least square estimation of the cosine
routing MoE, we demonstrate that due to the intrinsic interaction of the model
parameters in the cosine router via some partial differential equations,
regardless of the structures of the experts, the estimation rates of experts
and model parameters can be as slow as $\mathcal{O}(1/\log^{\tau}(n))$ where
$\tau > 0$ is some constant and $n$ is the sample size. Surprisingly, these
pessimistic non-polynomial convergence rates can be circumvented by the widely
used technique in practice to stabilize the cosine router -- simply adding
noises to the $\ell^2$-norms in the cosine router, which we refer to as
\textit{perturbed cosine router}. Under the strongly identifiable settings of
the expert functions, we prove that the estimation rates for both the experts
and model parameters under the perturbed cosine routing MoE are significantly
improved to polynomial rates. Finally, we conduct extensive simulation studies
in both synthetic and real data settings to empirically validate our
theoretical results.",2024-05-23,"Huy Nguyen, Pedram Akbarian, Trang Pham, Trang Nguyen, Shujian Zhang, Nhat Ho",http://arxiv.org/pdf/2405.14131v3,cs.LG
Transformers for Image-Goal Navigation,"Visual perception and navigation have emerged as major focus areas in the
field of embodied artificial intelligence. We consider the task of image-goal
navigation, where an agent is tasked to navigate to a goal specified by an
image, relying only on images from an onboard camera. This task is particularly
challenging since it demands robust scene understanding, goal-oriented planning
and long-horizon navigation. Most existing approaches typically learn
navigation policies reliant on recurrent neural networks trained via online
reinforcement learning. However, training such policies requires substantial
computational resources and time, and performance of these models is not
reliable on long-horizon navigation. In this work, we present a generative
Transformer based model that jointly models image goals, camera observations
and the robot's past actions to predict future actions. We use state-of-the-art
perception models and navigation policies to learn robust goal conditioned
policies without the need for real-time interaction with the environment. Our
model demonstrates capability in capturing and associating visual information
across long time horizons, helping in effective navigation.
  NOTE: This work was submitted as part of a Master's Capstone Project and must
be treated as such. This is still an early work in progress and not the final
version.",2024-05-23,Nikhilanj Pelluri,http://arxiv.org/pdf/2405.14128v2,cs.LG
The Disappearance of Timestep Embedding in Modern Time-Dependent Neural Networks,"Dynamical systems are often time-varying, whose modeling requires a function
that evolves with respect to time. Recent studies such as the neural ordinary
differential equation proposed a time-dependent neural network, which provides
a neural network varying with respect to time. However, we claim that the
architectural choice to build a time-dependent neural network significantly
affects its time-awareness but still lacks sufficient validation in its current
states. In this study, we conduct an in-depth analysis of the architecture of
modern time-dependent neural networks. Here, we report a vulnerability of
vanishing timestep embedding, which disables the time-awareness of a
time-dependent neural network. Furthermore, we find that this vulnerability can
also be observed in diffusion models because they employ a similar architecture
that incorporates timestep embedding to discriminate between different
timesteps during a diffusion process. Our analysis provides a detailed
description of this phenomenon as well as several solutions to address the root
cause. Through experiments on neural ordinary differential equations and
diffusion models, we observed that ensuring alive time-awareness via proposed
solutions boosted their performance, which implies that their current
implementations lack sufficient time-dependency.",2024-05-23,"Bum Jun Kim, Yoshinobu Kawahara, Sang Woo Kim",http://arxiv.org/pdf/2405.14126v1,cs.LG
Mixture of Experts Meets Prompt-Based Continual Learning,"Exploiting the power of pre-trained models, prompt-based approaches stand out
compared to other continual learning solutions in effectively preventing
catastrophic forgetting, even with very few learnable parameters and without
the need for a memory buffer. While existing prompt-based continual learning
methods excel in leveraging prompts for state-of-the-art performance, they
often lack a theoretical explanation for the effectiveness of prompting. This
paper conducts a theoretical analysis to unravel how prompts bestow such
advantages in continual learning, thus offering a new perspective on prompt
design. We first show that the attention block of pre-trained models like
Vision Transformers inherently encodes a special mixture of experts
architecture, characterized by linear experts and quadratic gating score
functions. This realization drives us to provide a novel view on prefix tuning,
reframing it as the addition of new task-specific experts, thereby inspiring
the design of a novel gating mechanism termed Non-linear Residual Gates
(NoRGa). Through the incorporation of non-linear activation and residual
connection, NoRGa enhances continual learning performance while preserving
parameter efficiency. The effectiveness of NoRGa is substantiated both
theoretically and empirically across diverse benchmarks and pretraining
paradigms. Our code is publicly available at
https://github.com/Minhchuyentoancbn/MoE_PromptCL",2024-05-23,"Minh Le, An Nguyen, Huy Nguyen, Trang Nguyen, Trang Pham, Linh Van Ngo, Nhat Ho",http://arxiv.org/pdf/2405.14124v4,cs.LG
One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models,"Active learning (AL) for multiple target models aims to reduce labeled data
querying while effectively training multiple models concurrently. Existing AL
algorithms often rely on iterative model training, which can be computationally
expensive, particularly for deep models. In this paper, we propose a one-shot
AL method to address this challenge, which performs all label queries without
repeated model training.
  Specifically, we extract different representations of the same dataset using
distinct network backbones, and actively learn the linear prediction layer on
each representation via an $\ell_p$-regression formulation. The regression
problems are solved approximately by sampling and reweighting the unlabeled
instances based on their maximum Lewis weights across the representations. An
upper bound on the number of samples needed is provided with a rigorous
analysis for $p\in [1, +\infty)$.
  Experimental results on 11 benchmarks show that our one-shot approach
achieves competitive performances with the state-of-the-art AL methods for
multiple target models.",2024-05-23,"Sheng-Jun Huang, Yi Li, Yiming Sun, Ying-Peng Tang",http://arxiv.org/pdf/2405.14121v2,cs.LG
Learning Multimodal Confidence for Intention Recognition in Human-Robot Interaction,"The rapid development of collaborative robotics has provided a new
possibility of helping the elderly who has difficulties in daily life, allowing
robots to operate according to specific intentions. However, efficient
human-robot cooperation requires natural, accurate and reliable intention
recognition in shared environments. The current paramount challenge for this is
reducing the uncertainty of multimodal fused intention to be recognized and
reasoning adaptively a more reliable result despite current interactive
condition. In this work we propose a novel learning-based multimodal fusion
framework Batch Multimodal Confidence Learning for Opinion Pool (BMCLOP). Our
approach combines Bayesian multimodal fusion method and batch confidence
learning algorithm to improve accuracy, uncertainty reduction and success rate
given the interactive condition. In particular, the generic and practical
multimodal intention recognition framework can be easily extended further. Our
desired assistive scenarios consider three modalities gestures, speech and
gaze, all of which produce categorical distributions over all the finite
intentions. The proposed method is validated with a six-DoF robot through
extensive experiments and exhibits high performance compared to baselines.",2024-05-23,"Xiyuan Zhao, Huijun Li, Tianyuan Miao, Xianyi Zhu, Zhikai Wei, Aiguo Song",http://arxiv.org/pdf/2405.14116v1,cs.LG
Configuring Data Augmentations to Reduce Variance Shift in Positional Embedding of Vision Transformers,"Vision transformers (ViTs) have demonstrated remarkable performance in a
variety of vision tasks. Despite their promising capabilities, training a ViT
requires a large amount of diverse data. Several studies empirically found that
using rich data augmentations, such as Mixup, Cutmix, and random erasing, is
critical to the successful training of ViTs. Now, the use of rich data
augmentations has become a standard practice in the current state. However, we
report a vulnerability to this practice: Certain data augmentations such as
Mixup cause a variance shift in the positional embedding of ViT, which has been
a hidden factor that degrades the performance of ViT during the test phase. We
claim that achieving a stable effect from positional embedding requires a
specific condition on the image, which is often broken for the current data
augmentation methods. We provide a detailed analysis of this problem as well as
the correct configuration for these data augmentations to remove the side
effects of variance shift. Experiments showed that adopting our guidelines
improves the performance of ViTs compared with the current configuration of
data augmentations.",2024-05-23,"Bum Jun Kim, Sang Woo Kim",http://arxiv.org/pdf/2405.14115v1,cs.LG
Offline Reinforcement Learning from Datasets with Structured Non-Stationarity,"Current Reinforcement Learning (RL) is often limited by the large amount of
data needed to learn a successful policy. Offline RL aims to solve this issue
by using transitions collected by a different behavior policy. We address a
novel Offline RL problem setting in which, while collecting the dataset, the
transition and reward functions gradually change between episodes but stay
constant within each episode. We propose a method based on Contrastive
Predictive Coding that identifies this non-stationarity in the offline dataset,
accounts for it when training a policy, and predicts it during evaluation. We
analyze our proposed method and show that it performs well in simple continuous
control tasks and challenging, high-dimensional locomotion tasks. We show that
our method often achieves the oracle performance and performs better than
baselines.",2024-05-23,"Johannes Ackermann, Takayuki Osa, Masashi Sugiyama",http://arxiv.org/pdf/2405.14114v2,cs.LG
Improving Generalization of Deep Neural Networks by Optimum Shifting,"Recent studies showed that the generalization of neural networks is
correlated with the sharpness of the loss landscape, and flat minima suggests a
better generalization ability than sharp minima. In this paper, we propose a
novel method called \emph{optimum shifting}, which changes the parameters of a
neural network from a sharp minimum to a flatter one while maintaining the same
training loss value. Our method is based on the observation that when the input
and output of a neural network are fixed, the matrix multiplications within the
network can be treated as systems of under-determined linear equations,
enabling adjustment of parameters in the solution space, which can be simply
accomplished by solving a constrained optimization problem. Furthermore, we
introduce a practical stochastic optimum shifting technique utilizing the
Neural Collapse theory to reduce computational costs and provide more degrees
of freedom for optimum shifting. Extensive experiments (including
classification and detection) with various deep neural network architectures on
benchmark datasets demonstrate the effectiveness of our method.",2024-05-23,"Yuyan Zhou, Ye Li, Lei Feng, Sheng-Jun Huang",http://arxiv.org/pdf/2405.14111v1,cs.LG
Deep Learning for Protein-Ligand Docking: Are We There Yet?,"The effects of ligand binding on protein structures and their in vivo
functions carry numerous implications for modern biomedical research and
biotechnology development efforts such as drug discovery. Although several deep
learning (DL) methods and benchmarks designed for protein-ligand docking have
recently been introduced, to date no prior works have systematically studied
the behavior of the latest docking and structure prediction methods within the
broadly applicable context of (1) using predicted (apo) protein structures for
docking (e.g., for applicability to new proteins); (2) binding multiple
(cofactor) ligands concurrently to a given target protein (e.g., for enzyme
design); and (3) having no prior knowledge of binding pockets (e.g., for
generalization to unknown pockets). To enable a deeper understanding of docking
methods' real-world utility, we introduce PoseBench, the first comprehensive
benchmark for broadly applicable protein-ligand docking. PoseBench enables
researchers to rigorously and systematically evaluate DL methods for
apo-to-holo protein-ligand docking and protein-ligand structure prediction
using both primary ligand and multi-ligand benchmark datasets, the latter of
which we introduce for the first time to the DL community. Empirically, using
PoseBench, we find that (1) DL co-folding methods generally outperform
comparable conventional and DL docking baselines, yet popular methods such as
AlphaFold 3 are still challenged by prediction targets with novel protein
sequences; (2) certain DL co-folding methods are highly sensitive to their
input multiple sequence alignments, while others are not; and (3) DL methods
struggle to strike a balance between structural accuracy and chemical
specificity when predicting novel or multi-ligand protein targets. Code, data,
tutorials, and benchmark results are available at
https://github.com/BioinfoMachineLearning/PoseBench.",2024-05-23,"Alex Morehead, Nabin Giri, Jian Liu, Pawan Neupane, Jianlin Cheng",http://arxiv.org/pdf/2405.14108v5,cs.LG
Nearly Tight Black-Box Auditing of Differentially Private Machine Learning,"This paper presents an auditing procedure for the Differentially Private
Stochastic Gradient Descent (DP-SGD) algorithm in the black-box threat model
that is substantially tighter than prior work. The main intuition is to craft
worst-case initial model parameters, as DP-SGD's privacy analysis is agnostic
to the choice of the initial model parameters. For models trained on MNIST and
CIFAR-10 at theoretical $\varepsilon=10.0$, our auditing procedure yields
empirical estimates of $\varepsilon_{emp} = 7.21$ and $6.95$, respectively, on
a 1,000-record sample and $\varepsilon_{emp}= 6.48$ and $4.96$ on the full
datasets. By contrast, previous audits were only (relatively) tight in stronger
white-box models, where the adversary can access the model's inner parameters
and insert arbitrary gradients. Overall, our auditing procedure can offer
valuable insight into how the privacy analysis of DP-SGD could be improved and
detect bugs and DP violations in real-world implementations. The source code
needed to reproduce our experiments is available at
https://github.com/spalabucr/bb-audit-dpsgd.",2024-05-23,"Meenatchi Sundaram Muthu Selva Annamalai, Emiliano De Cristofaro",http://arxiv.org/pdf/2405.14106v4,cs.LG
Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis,"In this paper, an innovative multi-modal deep learning model is proposed to
deeply integrate heterogeneous information from medical images and clinical
reports. First, for medical images, convolutional neural networks were used to
extract high-dimensional features and capture key visual information such as
focal details, texture and spatial distribution. Secondly, for clinical report
text, a two-way long and short-term memory network combined with an attention
mechanism is used for deep semantic understanding, and key statements related
to the disease are accurately captured. The two features interact and integrate
effectively through the designed multi-modal fusion layer to realize the joint
representation learning of image and text. In the empirical study, we selected
a large medical image database covering a variety of diseases, combined with
corresponding clinical reports for model training and validation. The proposed
multimodal deep learning model demonstrated substantial superiority in the
realms of disease classification, lesion localization, and clinical description
generation, as evidenced by the experimental results.",2024-05-23,"Ziyan Yao, Fei Lin, Sheng Chai, Weijie He, Lu Dai, Xinghui Fei",http://arxiv.org/pdf/2405.17459v1,cs.LG
Distributed Speculative Inference (DSI): Speculation Parallelism for Provably Faster Lossless Language Model Inference,"This paper introduces distributed speculative inference (DSI), a novel
inference algorithm that is provably faster than speculative inference (SI)
[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard
autoregressive inference (non-SI). Like other SI algorithms, DSI operates on
frozen language models (LMs), requiring no training or architectural
modifications, and it preserves the target distribution. Prior studies on SI
have demonstrated empirical speedups over non-SI--but rely on sufficiently fast
and accurate drafters, which are often unavailable in practice. We identify a
gap where SI can be slower than non-SI if drafters are too slow or inaccurate.
We close this gap by proving that DSI is faster than both SI and non-SI--given
any drafters. DSI is therefore not only faster than SI, but also unlocks the
acceleration of LMs for which SI fails. DSI leverages speculation parallelism
(SP), a novel type of task parallelism, to orchestrate target and drafter
instances that overlap in time, establishing a new foundational tradeoff
between computational resources and latency. Our simulations show that DSI is
1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs
and tasks. We open-source all our code.",2024-05-23,"Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Moshe Wasserblat, Tomer Galanti, Michal Gordon, David Harel",http://arxiv.org/pdf/2405.14105v5,cs.LG
Online Self-Preferring Language Models,"Aligning with human preference datasets has been critical to the success of
large language models (LLMs). Reinforcement learning from human feedback (RLHF)
employs a costly reward model to provide feedback for on-policy sampling
responses. Recently, offline methods that directly fit responses with binary
preferences in the dataset have emerged as alternatives. However, existing
methods do not explicitly model preference strength information, which is
crucial for distinguishing different response pairs. To overcome this
limitation, we propose Online Self-Preferring (OSP) language models to learn
from self-generated response pairs and self-judged preference strengths. For
each prompt and corresponding self-generated responses, we introduce a ranked
pairing method to construct multiple response pairs with preference strength
information. We then propose the soft-preference cross-entropy loss to leverage
such information. Empirically, we demonstrate that leveraging preference
strength is crucial for avoiding overfitting and enhancing alignment
performance. OSP achieves state-of-the-art alignment performance across various
metrics in two widely used human preference datasets. OSP is
parameter-efficient and more robust than the dominant online method, RLHF when
limited offline data are available and generalizing to out-of-domain tasks.
Moreover, OSP language models established by LLMs with proficiency in
self-preferring can efficiently self-improve without external supervision.",2024-05-23,"Yuanzhao Zhai, Zhuo Zhang, Kele Xu, Hanyang Peng, Yue Yu, Dawei Feng, Cheng Yang, Bo Ding, Huaimin Wang",http://arxiv.org/pdf/2405.14103v1,cs.LG
Enhancing Image Layout Control with Loss-Guided Diffusion Models,"Diffusion models are a powerful class of generative models capable of
producing high-quality images from pure noise using a simple text prompt. While
most methods which introduce additional spatial constraints into the generated
images (e.g., bounding boxes) require fine-tuning, a smaller and more recent
subset of these methods take advantage of the models' attention mechanism, and
are training-free. These methods generally fall into one of two categories. The
first entails modifying the cross-attention maps of specific tokens directly to
enhance the signal in certain regions of the image. The second works by
defining a loss function over the cross-attention maps, and using the gradient
of this loss to guide the latent. While previous work explores these as
alternative strategies, we provide an interpretation for these methods which
highlights their complimentary features, and demonstrate that it is possible to
obtain superior performance when both methods are used in concert.",2024-05-23,"Zakaria Patel, Kirill Serkh",http://arxiv.org/pdf/2405.14101v2,cs.LG
Automatic Differentiation is Essential in Training Neural Networks for Solving Differential Equations,"Neural network-based approaches have recently shown significant promise in
solving partial differential equations (PDEs) in science and engineering,
especially in scenarios featuring complex domains or incorporation of empirical
data. One advantage of the neural network methods for PDEs lies in its
automatic differentiation (AD), which necessitates only the sample points
themselves, unlike traditional finite difference (FD) approximations that
require nearby local points to compute derivatives. In this paper, we
quantitatively demonstrate the advantage of AD in training neural networks. The
concept of truncated entropy is introduced to characterize the training
property. Specifically, through comprehensive experimental and theoretical
analyses conducted on random feature models and two-layer neural networks, we
discover that the defined truncated entropy serves as a reliable metric for
quantifying the residual loss of random feature models and the training speed
of neural networks for both AD and FD methods. Our experimental and theoretical
analyses demonstrate that, from a training perspective, AD outperforms FD in
solving PDEs.",2024-05-23,"Chuqi Chen, Yahong Yang, Yang Xiang, Wenrui Hao",http://arxiv.org/pdf/2405.14099v4,cs.LG
Newton Informed Neural Operator for Computing Multiple Solutions of Nonlinear Partials Differential Equations,"Solving nonlinear partial differential equations (PDEs) with multiple
solutions using neural networks has found widespread applications in various
fields such as physics, biology, and engineering. However, classical neural
network methods for solving nonlinear PDEs, such as Physics-Informed Neural
Networks (PINN), Deep Ritz methods, and DeepONet, often encounter challenges
when confronted with the presence of multiple solutions inherent in the
nonlinear problem. These methods may encounter ill-posedness issues. In this
paper, we propose a novel approach called the Newton Informed Neural Operator,
which builds upon existing neural network techniques to tackle nonlinearities.
Our method combines classical Newton methods, addressing well-posed problems,
and efficiently learns multiple solutions in a single learning process while
requiring fewer supervised data points compared to existing neural network
methods.",2024-05-23,"Wenrui Hao, Xinliang Liu, Yahong Yang",http://arxiv.org/pdf/2405.14096v1,cs.LG
Attending to Topological Spaces: The Cellular Transformer,"Topological Deep Learning seeks to enhance the predictive performance of
neural network models by harnessing topological structures in input data.
Topological neural networks operate on spaces such as cell complexes and
hypergraphs, that can be seen as generalizations of graphs. In this work, we
introduce the Cellular Transformer (CT), a novel architecture that generalizes
graph-based transformers to cell complexes. First, we propose a new formulation
of the usual self- and cross-attention mechanisms, tailored to leverage
incidence relations in cell complexes, e.g., edge-face and node-edge relations.
Additionally, we propose a set of topological positional encodings specifically
designed for cell complexes. By transforming three graph datasets into cell
complex datasets, our experiments reveal that CT not only achieves
state-of-the-art performance, but it does so without the need for more complex
enhancements such as virtual nodes, in-domain structural encodings, or graph
rewiring.",2024-05-23,"Rubén Ballester, Pablo Hernández-García, Mathilde Papillon, Claudio Battiloro, Nina Miolane, Tolga Birdal, Carles Casacuberta, Sergio Escalera, Mustafa Hajij",http://arxiv.org/pdf/2405.14094v2,cs.LG
Blood Glucose Control Via Pre-trained Counterfactual Invertible Neural Networks,"Type 1 diabetes mellitus (T1D) is characterized by insulin deficiency and
blood glucose (BG) control issues. The state-of-the-art solution for continuous
BG control is reinforcement learning (RL), where an agent can dynamically
adjust exogenous insulin doses in time to maintain BG levels within the target
range. However, due to the lack of action guidance, the agent often needs to
learn from randomized trials to understand misleading correlations between
exogenous insulin doses and BG levels, which can lead to instability and
unsafety. To address these challenges, we propose an introspective RL based on
Counterfactual Invertible Neural Networks (CINN). We use the pre-trained CINN
as a frozen introspective block of the RL agent, which integrates forward
prediction and counterfactual inference to guide the policy updates, promoting
more stable and safer BG control. Constructed based on interpretable causal
order, CINN employs bidirectional encoders with affine coupling layers to
ensure invertibility while using orthogonal weight normalization to enhance the
trainability, thereby ensuring the bidirectional differentiability of network
parameters. We experimentally validate the accuracy and generalization ability
of the pre-trained CINN in BG prediction and counterfactual inference for
action. Furthermore, our experimental results highlight the effectiveness of
pre-trained CINN in guiding RL policy updates for more accurate and safer BG
control.",2024-05-23,"Jingchi Jiang, Rujia Shen, Boran Wang, Yi Guan",http://arxiv.org/pdf/2405.17458v2,cs.LG
Actively Learning Combinatorial Optimization Using a Membership Oracle,"We consider solving a combinatorial optimization problem with an unknown
linear constraint using a membership oracle that, given a solution, determines
whether it is feasible or infeasible with absolute certainty. The goal of the
decision maker is to find the best possible solution subject to a budget on the
number of oracle calls. Inspired by active learning based on Support Vector
Machines (SVMs), we adapt a classical framework in order to solve the problem
by learning and exploiting a surrogate linear constraint. The resulting new
framework includes training a linear separator on the labeled points and
selecting new points to be labeled, which is achieved by applying a sampling
strategy and solving a 0-1 integer linear program. Following the active
learning literature, one can consider using SVM as a linear classifier and the
information-based sampling strategy known as simple margin. We improve on both
sides: we propose an alternative sampling strategy based on mixed-integer
quadratic programming and a linear separation method inspired by an algorithm
for convex optimization in the oracle model. We conduct experiments on the pure
knapsack problem and on a college study plan problem from the literature to
show how different linear separation methods and sampling strategies influence
the quality of the results in terms of objective value.",2024-05-23,"Rosario Messana, Rui Chen, Andrea Lodi",http://arxiv.org/pdf/2405.14090v3,cs.LG
Improved Canonicalization for Model Agnostic Equivariance,"This work introduces a novel approach to achieving architecture-agnostic
equivariance in deep learning, particularly addressing the limitations of
traditional layerwise equivariant architectures and the inefficiencies of the
existing architecture-agnostic methods. Building equivariant models using
traditional methods requires designing equivariant versions of existing models
and training them from scratch, a process that is both impractical and
resource-intensive. Canonicalization has emerged as a promising alternative for
inducing equivariance without altering model architecture, but it suffers from
the need for highly expressive and expensive equivariant networks to learn
canonical orientations accurately. We propose a new optimization-based method
that employs any non-equivariant network for canonicalization. Our method uses
contrastive learning to efficiently learn a canonical orientation and offers
more flexibility for the choice of canonicalization network. We empirically
demonstrate that this approach outperforms existing methods in achieving
equivariance for large pretrained models and significantly speeds up the
canonicalization process, making it up to 2 times faster.",2024-05-23,"Siba Smarak Panigrahi, Arnab Kumar Mondal",http://arxiv.org/pdf/2405.14089v2,cs.LG
High-dimensional Learning with Noisy Labels,"This paper provides theoretical insights into high-dimensional binary
classification with class-conditional noisy labels. Specifically, we study the
behavior of a linear classifier with a label noisiness aware loss function,
when both the dimension of data $p$ and the sample size $n$ are large and
comparable. Relying on random matrix theory by supposing a Gaussian mixture
data model, the performance of the linear classifier when $p,n\to \infty$ is
shown to converge towards a limit, involving scalar statistics of the data.
Importantly, our findings show that the low-dimensional intuitions to handle
label noise do not hold in high-dimension, in the sense that the optimal
classifier in low-dimension dramatically fails in high-dimension. Based on our
derivations, we design an optimized method that is shown to be provably more
efficient in handling noisy labels in high dimensions. Our theoretical
conclusions are further confirmed by experiments on real datasets, where we
show that our optimized approach outperforms the considered baselines.",2024-05-23,"Aymane El Firdoussi, Mohamed El Amine Seddik",http://arxiv.org/pdf/2405.14088v1,cs.LG
"How Do Transformers ""Do"" Physics? Investigating the Simple Harmonic Oscillator","How do transformers model physics? Do transformers model systems with
interpretable analytical solutions, or do they create ""alien physics"" that are
difficult for humans to decipher? We take a step in demystifying this larger
puzzle by investigating the simple harmonic oscillator (SHO), $\ddot{x}+2\gamma
\dot{x}+\omega_0^2x=0$, one of the most fundamental systems in physics. Our
goal is to identify the methods transformers use to model the SHO, and to do so
we hypothesize and evaluate possible methods by analyzing the encoding of these
methods' intermediates. We develop four criteria for the use of a method within
the simple testbed of linear regression, where our method is $y = wx$ and our
intermediate is $w$: (1) Can the intermediate be predicted from hidden states?
(2) Is the intermediate's encoding quality correlated with model performance?
(3) Can the majority of variance in hidden states be explained by the
intermediate? (4) Can we intervene on hidden states to produce predictable
outcomes? Armed with these two correlational (1,2), weak causal (3) and strong
causal (4) criteria, we determine that transformers use known numerical methods
to model trajectories of the simple harmonic oscillator, specifically the
matrix exponential method. Our analysis framework can conveniently extend to
high-dimensional linear systems and nonlinear systems, which we hope will help
reveal the ""world model"" hidden in transformers.",2024-05-23,"Subhash Kantamneni, Ziming Liu, Max Tegmark",http://arxiv.org/pdf/2405.17209v1,cs.LG
Exclusively Penalized Q-learning for Offline Reinforcement Learning,"Constraint-based offline reinforcement learning (RL) involves policy
constraints or imposing penalties on the value function to mitigate
overestimation errors caused by distributional shift. This paper focuses on a
limitation in existing offline RL methods with penalized value function,
indicating the potential for underestimation bias due to unnecessary bias
introduced in the value function. To address this concern, we propose
Exclusively Penalized Q-learning (EPQ), which reduces estimation bias in the
value function by selectively penalizing states that are prone to inducing
estimation errors. Numerical results show that our method significantly reduces
underestimation bias and improves performance in various offline control tasks
compared to other offline RL methods",2024-05-23,"Junghyuk Yeom, Yonghyeon Jo, Jungmo Kim, Sanghyeon Lee, Seungyul Han",http://arxiv.org/pdf/2405.14082v2,cs.LG
Advancing Transportation Mode Share Analysis with Built Environment: Deep Hybrid Models with Urban Road Network,"Transportation mode share analysis is important to various real-world
transportation tasks as it helps researchers understand the travel behaviors
and choices of passengers. A typical example is the prediction of communities'
travel mode share by accounting for their sociodemographics like age, income,
etc., and travel modes' attributes (e.g. travel cost and time). However, there
exist only limited efforts in integrating the structure of the urban built
environment, e.g., road networks, into the mode share models to capture the
impacts of the built environment. This task usually requires manual feature
engineering or prior knowledge of the urban design features. In this study, we
propose deep hybrid models (DHM), which directly combine road networks and
sociodemographic features as inputs for travel mode share analysis. Using graph
embedding (GE) techniques, we enhance travel demand models with a more powerful
representation of urban structures. In experiments of mode share prediction in
Chicago, results demonstrate that DHM can provide valuable spatial insights
into the sociodemographic structure, improving the performance of travel demand
models in estimating different mode shares at the city level. Specifically, DHM
improves the results by more than 20\% while retaining the interpretation power
of the choice models, demonstrating its superiority in interpretability,
prediction accuracy, and geographical insights.",2024-05-23,"Dingyi Zhuang, Qingyi Wang, Yunhan Zheng, Xiaotong Guo, Shenhao Wang, Haris N Koutsopoulos, Jinhua Zhao",http://arxiv.org/pdf/2405.14079v1,cs.LG
A finite time analysis of distributed Q-learning,"Multi-agent reinforcement learning (MARL) has witnessed a remarkable surge in
interest, fueled by the empirical success achieved in applications of
single-agent reinforcement learning (RL). In this study, we consider a
distributed Q-learning scenario, wherein a number of agents cooperatively solve
a sequential decision making problem without access to the central reward
function which is an average of the local rewards. In particular, we study
finite-time analysis of a distributed Q-learning algorithm, and provide a new
sample complexity result of $\tilde{\mathcal{O}}\left(
\min\left\{\frac{1}{\epsilon^2}\frac{t_{\text{mix}}}{(1-\gamma)^6 d_{\min}^4 }
,\frac{1}{\epsilon}\frac{\sqrt{|\gS||\gA|}}{(1-\sigma_2(\boldsymbol{W}))(1-\gamma)^4
d_{\min}^3} \right\}\right)$ under tabular lookup",2024-05-23,"Han-Dong Lim, Donghwan Lee",http://arxiv.org/pdf/2405.14078v1,cs.LG
$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language Models,"Large Language Models (LLMs) have emerged as powerful tools in artificial
intelligence, especially in complex decision-making scenarios, but their static
problem-solving strategies often limit their adaptability to dynamic
environments. We explore the enhancement of reasoning capabilities in LLMs
through Temperature Tree ($T^2$) prompting via a heuristic algorithm, termed as
$T^2$ of Thoughts ($T^2oT$). The primary focus is on enhancing decision-making
processes by dynamically adjusting search parameters, especially temperature,
to improve accuracy without increasing computational demands. We empirically
validate that our hybrid $T^2oT$ approach yields enhancements in,
single-solution accuracy, multi-solution generation and text generation
quality. Our findings suggest that while dynamic search depth adjustments based
on temperature can yield mixed results, a fixed search depth, when coupled with
adaptive capabilities of $T^2oT$, provides a more reliable and versatile
problem-solving strategy. This work highlights the potential for future
explorations in optimizing algorithmic interactions with foundational language
models, particularly illustrated by our development for the Game of 24 and
Creative Writing tasks.",2024-05-23,"Chengkun Cai, Xu Zhao, Yucheng Du, Haoliang Liu, Lei Li",http://arxiv.org/pdf/2405.14075v2,cs.LG
PEAC: Unsupervised Pre-training for Cross-Embodiment Reinforcement Learning,"Designing generalizable agents capable of adapting to diverse embodiments has
achieved significant attention in Reinforcement Learning (RL), which is
critical for deploying RL agents in various real-world applications. Previous
Cross-Embodiment RL approaches have focused on transferring knowledge across
embodiments within specific tasks. These methods often result in knowledge
tightly coupled with those tasks and fail to adequately capture the distinct
characteristics of different embodiments. To address this limitation, we
introduce the notion of Cross-Embodiment Unsupervised RL (CEURL), which
leverages unsupervised learning to enable agents to acquire embodiment-aware
and task-agnostic knowledge through online interactions within reward-free
environments. We formulate CEURL as a novel Controlled Embodiment Markov
Decision Process (CE-MDP) and systematically analyze CEURL's pre-training
objectives under CE-MDP. Based on these analyses, we develop a novel algorithm
Pre-trained Embodiment-Aware Control (PEAC) for handling CEURL, incorporating
an intrinsic reward function specifically designed for cross-embodiment
pre-training. PEAC not only provides an intuitive optimization strategy for
cross-embodiment pre-training but also can integrate flexibly with existing
unsupervised RL methods, facilitating cross-embodiment exploration and skill
discovery. Extensive experiments in both simulated (e.g., DMC and Robosuite)
and real-world environments (e.g., legged locomotion) demonstrate that PEAC
significantly improves adaptation performance and cross-embodiment
generalization, demonstrating its effectiveness in overcoming the unique
challenges of CEURL. The project page and code are in
https://yingchengyang.github.io/ceurl.",2024-05-23,"Chengyang Ying, Zhongkai Hao, Xinning Zhou, Xuezhou Xu, Hang Su, Xingxing Zhang, Jun Zhu",http://arxiv.org/pdf/2405.14073v2,cs.LG
Online Classification with Predictions,"We study online classification when the learner has access to predictions
about future examples. We design an online learner whose expected regret is
never worse than the worst-case regret, gracefully improves with the quality of
the predictions, and can be significantly better than the worst-case regret
when the predictions of future examples are accurate. As a corollary, we show
that if the learner is always guaranteed to observe data where future examples
are easily predictable, then online learning can be as easy as transductive
online learning. Our results complement recent work in online algorithms with
predictions and smoothed online classification, which go beyond a worse-case
analysis by using machine-learned predictions and distributional assumptions
respectively.",2024-05-22,"Vinod Raman, Ambuj Tewari",http://arxiv.org/pdf/2405.14066v1,cs.LG
Building a stable classifier with the inflated argmax,"We propose a new framework for algorithmic stability in the context of
multiclass classification. In practice, classification algorithms often operate
by first assigning a continuous score (for instance, an estimated probability)
to each possible label, then taking the maximizer -- i.e., selecting the class
that has the highest score. A drawback of this type of approach is that it is
inherently unstable, meaning that it is very sensitive to slight perturbations
of the training data, since taking the maximizer is discontinuous. Motivated by
this challenge, we propose a pipeline for constructing stable classifiers from
data, using bagging (i.e., resampling and averaging) to produce stable
continuous scores, and then using a stable relaxation of argmax, which we call
the ""inflated argmax,"" to convert these scores to a set of candidate labels.
The resulting stability guarantee places no distributional assumptions on the
data, does not depend on the number of classes or dimensionality of the
covariates, and holds for any base classifier. Using a common benchmark data
set, we demonstrate that the inflated argmax provides necessary protection
against unstable classifiers, without loss of accuracy.",2024-05-22,"Jake A. Soloff, Rina Foygel Barber, Rebecca Willett",http://arxiv.org/pdf/2405.14064v2,cs.LG
ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles,"We present ChatScene, a Large Language Model (LLM)-based agent that leverages
the capabilities of LLMs to generate safety-critical scenarios for autonomous
vehicles. Given unstructured language instructions, the agent first generates
textually described traffic scenarios using LLMs. These scenario descriptions
are subsequently broken down into several sub-descriptions for specified
details such as behaviors and locations of vehicles. The agent then
distinctively transforms the textually described sub-scenarios into
domain-specific languages, which then generate actual code for prediction and
control in simulators, facilitating the creation of diverse and complex
scenarios within the CARLA simulation environment. A key part of our agent is a
comprehensive knowledge retrieval component, which efficiently translates
specific textual descriptions into corresponding domain-specific code snippets
by training a knowledge database containing the scenario description and code
pairs. Extensive experimental results underscore the efficacy of ChatScene in
improving the safety of autonomous vehicles. For instance, the scenarios
generated by ChatScene show a 15% increase in collision rates compared to
state-of-the-art baselines when tested against different reinforcement
learning-based ego vehicles. Furthermore, we show that by using our generated
safety-critical scenarios to fine-tune different RL-based autonomous driving
models, they can achieve a 9% reduction in collision rates, surpassing current
SOTA methods. ChatScene effectively bridges the gap between textual
descriptions of traffic scenarios and practical CARLA simulations, providing a
unified way to conveniently generate safety-critical scenarios for safety
testing and improvement for AVs.",2024-05-22,"Jiawei Zhang, Chejian Xu, Bo Li",http://arxiv.org/pdf/2405.14062v1,cs.LG
Meanings and Feelings of Large Language Models: Observability of Latent States in Generative AI,"We tackle the question of whether Large Language Models (LLMs), viewed as
dynamical systems with state evolving in the embedding space of symbolic
tokens, are observable. That is, whether there exist multiple 'mental' state
trajectories that yield the same sequence of generated tokens, or sequences
that belong to the same Nerode equivalence class ('meaning'). If not
observable, mental state trajectories ('experiences') evoked by an input
('perception') or by feedback from the model's own state ('thoughts') could
remain self-contained and evolve unbeknown to the user while being potentially
accessible to the model provider. Such ""self-contained experiences evoked by
perception or thought"" are akin to what the American Psychological Association
(APA) defines as 'feelings'. Beyond the lexical curiosity, we show that current
LLMs implemented by autoregressive Transformers cannot have 'feelings'
according to this definition: The set of state trajectories indistinguishable
from the tokenized output is a singleton. But if there are 'system prompts' not
visible to the user, then the set of indistinguishable trajectories becomes
non-trivial, and there can be multiple state trajectories that yield the same
verbalized output. We prove these claims analytically, and show examples of
modifications to standard LLMs that engender such 'feelings.' Our analysis
sheds light on possible designs that would enable a model to perform
non-trivial computation that is not visible to the user, as well as on controls
that the provider of services using the model could take to prevent unintended
behavior.",2024-05-22,"Tian Yu Liu, Stefano Soatto, Matteo Marchi, Pratik Chaudhari, Paulo Tabuada",http://arxiv.org/pdf/2405.14061v1,cs.LG
Probabilistic Inference in the Era of Tensor Networks and Differential Programming,"Probabilistic inference is a fundamental task in modern machine learning.
Recent advances in tensor network (TN) contraction algorithms have enabled the
development of better exact inference methods. However, many common inference
tasks in probabilistic graphical models (PGMs) still lack corresponding
TN-based adaptations. In this work, we advance the connection between PGMs and
TNs by formulating and implementing tensor-based solutions for the following
inference tasks: (i) computing the partition function, (ii) computing the
marginal probability of sets of variables in the model, (iii) determining the
most likely assignment to a set of variables, and (iv) the same as (iii) but
after having marginalized a different set of variables. We also present a
generalized method for generating samples from a learned probability
distribution. Our work is motivated by recent technical advances in the fields
of quantum circuit simulation, quantum many-body physics, and statistical
physics. Through an experimental evaluation, we demonstrate that the
integration of these quantum technologies with a series of algorithms
introduced in this study significantly improves the effectiveness of existing
methods for solving probabilistic inference tasks.",2024-05-22,"Martin Roa-Villescas, Xuanzhao Gao, Sander Stuijk, Henk Corporaal, Jin-Guo Liu",http://arxiv.org/pdf/2405.14060v1,cs.LG
Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov Barrier Certificates,"Deep reinforcement learning (DRL) is a powerful machine learning paradigm for
generating agents that control autonomous systems. However, the ``black box''
nature of DRL agents limits their deployment in real-world safety-critical
applications. A promising approach for providing strong guarantees on an
agent's behavior is to use Neural Lyapunov Barrier (NLB) certificates, which
are learned functions over the system whose properties indirectly imply that an
agent behaves as desired. However, NLB-based certificates are typically
difficult to learn and even more difficult to verify, especially for complex
systems. In this work, we present a novel method for training and verifying
NLB-based certificates for discrete-time systems. Specifically, we introduce a
technique for certificate composition, which simplifies the verification of
highly-complex systems by strategically designing a sequence of certificates.
When jointly verified with neural network verification engines, these
certificates provide a formal guarantee that a DRL agent both achieves its
goals and avoids unsafe behavior. Furthermore, we introduce a technique for
certificate filtering, which significantly simplifies the process of producing
formally verified certificates. We demonstrate the merits of our approach with
a case study on providing safety and liveness guarantees for a DRL-controlled
spacecraft.",2024-05-22,"Udayan Mandal, Guy Amir, Haoze Wu, Ieva Daukantas, Fletcher Lee Newell, Umberto J. Ravaioli, Baoluo Meng, Michael Durling, Milan Ganai, Tobey Shim, Guy Katz, Clark Barrett",http://arxiv.org/pdf/2405.14058v2,cs.LG
A Uniform Concentration Inequality for Kernel-Based Two-Sample Statistics,"In many contemporary statistical and machine learning methods, one needs to
optimize an objective function that depends on the discrepancy between two
probability distributions. The discrepancy can be referred to as a metric for
distributions. Widely adopted examples of such a metric include Energy Distance
(ED), distance Covariance (dCov), Maximum Mean Discrepancy (MMD), and the
Hilbert-Schmidt Independence Criterion (HSIC). We show that these metrics can
be unified under a general framework of kernel-based two-sample statistics.
  This paper establishes a novel uniform concentration inequality for the
aforementioned kernel-based statistics. Our results provide upper bounds for
estimation errors in the associated optimization problems, thereby offering
both finite-sample and asymptotic performance guarantees. As illustrative
applications, we demonstrate how these bounds facilitate the derivation of
error bounds for procedures such as distance covariance-based dimension
reduction, distance covariance-based independent component analysis, MMD-based
fairness-constrained inference, MMD-based generative model search, and
MMD-based generative adversarial networks.",2024-05-22,"Yijin Ni, Xiaoming Huo",http://arxiv.org/pdf/2405.14051v3,cs.LG
Particle physics DL-simulation with control over generated data properties,"The research of innovative methods aimed at reducing costs and shortening the
time needed for simulation, going beyond conventional approaches based on Monte
Carlo methods, has been sparked by the development of collision simulations at
the Large Hadron Collider at CERN. Deep learning generative methods including
VAE, GANs and diffusion models have been used for this purpose. Although they
are much faster and simpler than standard approaches, they do not always keep
high fidelity of the simulated data. This work aims to mitigate this issue, by
providing an alternative solution to currently employed algorithms by
introducing the mechanism of control over the generated data properties. To
achieve this, we extend the recently introduced CorrVAE, which enables
user-defined parameter manipulation of the generated output. We adapt the model
to the problem of particle physics simulation. The proposed solution achieved
promising results, demonstrating control over the parameters of the generated
output and constituting an alternative for simulating the ZDC calorimeter in
the ALICE experiment at CERN.",2024-05-22,"Karol Rogoziński, Jan Dubiński, Przemysław Rokita, Kamil Deja",http://arxiv.org/pdf/2405.14049v1,cs.LG
Learning rigid-body simulators over implicit shapes for large-scale scenes and vision,"Simulating large scenes with many rigid objects is crucial for a variety of
applications, such as robotics, engineering, film and video games. Rigid
interactions are notoriously hard to model: small changes to the initial state
or the simulation parameters can lead to large changes in the final state.
Recently, learned simulators based on graph networks (GNNs) were developed as
an alternative to hand-designed simulators like MuJoCo and PyBullet. They are
able to accurately capture dynamics of real objects directly from real-world
observations. However, current state-of-the-art learned simulators operate on
meshes and scale poorly to scenes with many objects or detailed shapes. Here we
present SDF-Sim, the first learned rigid-body simulator designed for scale. We
use learned signed-distance functions (SDFs) to represent the object shapes and
to speed up distance computation. We design the simulator to leverage SDFs and
avoid the fundamental bottleneck of the previous simulators associated with
collision detection. For the first time in literature, we demonstrate that we
can scale the GNN-based simulators to scenes with hundreds of objects and up to
1.1 million nodes, where mesh-based approaches run out of memory. Finally, we
show that SDF-Sim can be applied to real world scenes by extracting SDFs from
multi-view images.",2024-05-22,"Yulia Rubanova, Tatiana Lopez-Guevara, Kelsey R. Allen, William F. Whitney, Kimberly Stachenfeld, Tobias Pfaff",http://arxiv.org/pdf/2405.14045v1,cs.LG
Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning,"Real-world data deviating from the independent and identically distributed
(i.i.d.) assumption of in-distribution training data poses security threats to
deep networks, thus advancing out-of-distribution (OOD) detection algorithms.
Detection methods in generative language models (GLMs) mainly focus on
uncertainty estimation and embedding distance measurement, with the latter
proven to be most effective in traditional linguistic tasks like summarization
and translation. However, another complex generative scenario mathematical
reasoning poses significant challenges to embedding-based methods due to its
high-density feature of output spaces, but this feature causes larger
discrepancies in the embedding shift trajectory between different samples in
latent spaces. Hence, we propose a trajectory-based method TV score, which uses
trajectory volatility for OOD detection in mathematical reasoning. Experiments
show that our method outperforms all traditional algorithms on GLMs under
mathematical reasoning scenarios and can be extended to more applications with
high-density features in output spaces, such as multiple-choice questions.",2024-05-22,"Yiming Wang, Pei Zhang, Baosong Yang, Derek F. Wong, Zhuosheng Zhang, Rui Wang",http://arxiv.org/pdf/2405.14039v2,cs.LG
FLIPHAT: Joint Differential Privacy for High Dimensional Sparse Linear Bandits,"High dimensional sparse linear bandits serve as an efficient model for
sequential decision-making problems (e.g. personalized medicine), where high
dimensional features (e.g. genomic data) on the users are available, but only a
small subset of them are relevant. Motivated by data privacy concerns in these
applications, we study the joint differentially private high dimensional sparse
linear bandits, where both rewards and contexts are considered as private data.
First, to quantify the cost of privacy, we derive a lower bound on the regret
achievable in this setting. To further address the problem, we design a
computationally efficient bandit algorithm, \textbf{F}orgetfu\textbf{L}
\textbf{I}terative \textbf{P}rivate \textbf{HA}rd \textbf{T}hresholding
(FLIPHAT). Along with doubling of episodes and episodic forgetting, FLIPHAT
deploys a variant of Noisy Iterative Hard Thresholding (N-IHT) algorithm as a
sparse linear regression oracle to ensure both privacy and regret-optimality.
We show that FLIPHAT achieves optimal regret in terms of privacy parameters
$\epsilon, \delta$, context dimension $d$, and time horizon $T$ up to a linear
factor in model sparsity and logarithmic factor in $d$. We analyze the regret
by providing a novel refined analysis of the estimation error of N-IHT, which
is of parallel interest.",2024-05-22,"Sunrit Chakraborty, Saptarshi Roy, Debabrota Basu",http://arxiv.org/pdf/2405.14038v3,cs.LG
Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization,"Training neural networks which are robust to adversarial attacks remains an
important problem in deep learning, especially as heavily overparameterized
models are adopted in safety-critical settings. Drawing from recent work which
reformulates the training problems for two-layer ReLU and polynomial activation
networks as convex programs, we devise a convex semidefinite program (SDP) for
adversarial training of two-layer polynomial activation networks and prove that
the convex SDP achieves the same globally optimal solution as its nonconvex
counterpart. The convex SDP is observed to improve robust test accuracy against
$\ell_\infty$ attacks relative to the original convex training formulation on
multiple datasets. Additionally, we present scalable implementations of
adversarial training for two-layer polynomial and ReLU networks which are
compatible with standard machine learning libraries and GPU acceleration.
Leveraging these implementations, we retrain the final two fully connected
layers of a Pre-Activation ResNet-18 model on the CIFAR-10 dataset with both
polynomial and ReLU activations. The two `robustified' models achieve
significantly higher robust test accuracies against $\ell_\infty$ attacks than
a Pre-Activation ResNet-18 model trained with sharpness-aware minimization,
demonstrating the practical utility of convex adversarial training on
large-scale problems.",2024-05-22,"Daniel Kuelbs, Sanjay Lall, Mert Pilanci",http://arxiv.org/pdf/2405.14033v2,cs.LG
WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response,"The recent breakthrough in large language models (LLMs) such as ChatGPT has
revolutionized production processes at an unprecedented pace. Alongside this
progress also comes mounting concerns about LLMs' susceptibility to
jailbreaking attacks, which leads to the generation of harmful or unsafe
content. While safety alignment measures have been implemented in LLMs to
mitigate existing jailbreak attempts and force them to become increasingly
complicated, it is still far from perfect. In this paper, we analyze the common
pattern of the current safety alignment and show that it is possible to exploit
such patterns for jailbreaking attacks by simultaneous obfuscation in queries
and responses. Specifically, we propose WordGame attack, which replaces
malicious words with word games to break down the adversarial intent of a query
and encourage benign content regarding the games to precede the anticipated
harmful content in the response, creating a context that is hardly covered by
any corpus used for safety alignment. Extensive experiments demonstrate that
WordGame attack can break the guardrails of the current leading proprietary and
open-source LLMs, including the latest Claude-3, GPT-4, and Llama-3 models.
Further ablation studies on such simultaneous obfuscation in query and response
provide evidence of the merits of the attack strategy beyond an individual
attack.",2024-05-22,"Tianrong Zhang, Bochuan Cao, Yuanpu Cao, Lu Lin, Prasenjit Mitra, Jinghui Chen",http://arxiv.org/pdf/2405.14023v1,cs.LG
A Study of Posterior Stability for Time-Series Latent Diffusion,"Latent diffusion has demonstrated promising results in image generation and
permits efficient sampling. However, this framework might suffer from the
problem of posterior collapse when applied to time series. In this paper, we
first show that posterior collapse will reduce latent diffusion to a
variational autoencoder (VAE), making it less expressive. This highlights the
importance of addressing this issue. We then introduce a principled method:
dependency measure, that quantifies the sensitivity of a recurrent decoder to
input variables. Using this tool, we confirm that posterior collapse
significantly affects time-series latent diffusion on real datasets, and a
phenomenon termed dependency illusion is also discovered in the case of
shuffled time series. Finally, building on our theoretical and empirical
studies, we introduce a new framework that extends latent diffusion and has a
stable posterior. Extensive experiments on multiple real time-series datasets
show that our new framework is free from posterior collapse and significantly
outperforms previous baselines in time series synthesis.",2024-05-22,"Yangming Li, Yixin Cheng, Mihaela van der Schaar",http://arxiv.org/pdf/2405.14021v2,cs.LG
Unlearning Information Bottleneck: Machine Unlearning of Systematic Patterns and Biases,"Effective adaptation to distribution shifts in training data is pivotal for
sustaining robustness in neural networks, especially when removing specific
biases or outdated information, a process known as machine unlearning.
Traditional approaches typically assume that data variations are random, which
makes it difficult to adjust the model parameters accurately to remove patterns
and characteristics from unlearned data. In this work, we present Unlearning
Information Bottleneck (UIB), a novel information-theoretic framework designed
to enhance the process of machine unlearning that effectively leverages the
influence of systematic patterns and biases for parameter adjustment. By
proposing a variational upper bound, we recalibrate the model parameters
through a dynamic prior that integrates changes in data distribution with an
affordable computational cost, allowing efficient and accurate removal of
outdated or unwanted data patterns and biases. Our experiments across various
datasets, models, and unlearning methods demonstrate that our approach
effectively removes systematic patterns and biases while maintaining the
performance of models post-unlearning.",2024-05-22,"Ling Han, Hao Huang, Dustin Scheinost, Mary-Anne Hartley, María Rodríguez Martínez",http://arxiv.org/pdf/2405.14020v1,cs.LG
Watermarking Generative Tabular Data,"In this paper, we introduce a simple yet effective tabular data watermarking
mechanism with statistical guarantees. We show theoretically that the proposed
watermark can be effectively detected, while faithfully preserving the data
fidelity, and also demonstrates appealing robustness against additive noise
attack. The general idea is to achieve the watermarking through a strategic
embedding based on simple data binning. Specifically, it divides the feature's
value range into finely segmented intervals and embeds watermarks into selected
``green list"" intervals. To detect the watermarks, we develop a principled
statistical hypothesis-testing framework with minimal assumptions: it remains
valid as long as the underlying data distribution has a continuous density
function. The watermarking efficacy is demonstrated through rigorous
theoretical analysis and empirical validation, highlighting its utility in
enhancing the security of synthetic and real-world datasets.",2024-05-22,"Hengzhi He, Peiyu Yu, Junpeng Ren, Ying Nian Wu, Guang Cheng",http://arxiv.org/pdf/2405.14018v1,cs.LG
Towards a Unified Framework for Evaluating Explanations,"The challenge of creating interpretable models has been taken up by two main
research communities: ML researchers primarily focused on lower-level
explainability methods that suit the needs of engineers, and HCI researchers
who have more heavily emphasized user-centered approaches often based on
participatory design methods. This paper reviews how these communities have
evaluated interpretability, identifying overlaps and semantic misalignments. We
propose moving towards a unified framework of evaluation criteria and lay the
groundwork for such a framework by articulating the relationships between
existing criteria. We argue that explanations serve as mediators between models
and stakeholders, whether for intrinsically interpretable models or opaque
black-box models analyzed via post-hoc techniques. We further argue that useful
explanations require both faithfulness and intelligibility. Explanation
plausibility is a prerequisite for intelligibility, while stability is a
prerequisite for explanation faithfulness. We illustrate these criteria, as
well as specific evaluation methods, using examples from an ongoing study of an
interpretable neural network for predicting a particular learner behavior.",2024-05-22,"Juan D. Pinto, Luc Paquette",http://arxiv.org/pdf/2405.14016v2,cs.LG
RadarOcc: Robust 3D Occupancy Prediction with 4D Imaging Radar,"3D occupancy-based perception pipeline has significantly advanced autonomous
driving by capturing detailed scene descriptions and demonstrating strong
generalizability across various object categories and shapes. Current methods
predominantly rely on LiDAR or camera inputs for 3D occupancy prediction. These
methods are susceptible to adverse weather conditions, limiting the all-weather
deployment of self-driving cars. To improve perception robustness, we leverage
the recent advances in automotive radars and introduce a novel approach that
utilizes 4D imaging radar sensors for 3D occupancy prediction. Our method,
RadarOcc, circumvents the limitations of sparse radar point clouds by directly
processing the 4D radar tensor, thus preserving essential scene details.
RadarOcc innovatively addresses the challenges associated with the voluminous
and noisy 4D radar data by employing Doppler bins descriptors, sidelobe-aware
spatial sparsification, and range-wise self-attention mechanisms. To minimize
the interpolation errors associated with direct coordinate transformations, we
also devise a spherical-based feature encoding followed by
spherical-to-Cartesian feature aggregation. We benchmark various baseline
methods based on distinct modalities on the public K-Radar dataset. The results
demonstrate RadarOcc's state-of-the-art performance in radar-based 3D occupancy
prediction and promising results even when compared with LiDAR- or camera-based
methods. Additionally, we present qualitative evidence of the superior
performance of 4D radar in adverse weather conditions and explore the impact of
key pipeline components through ablation studies.",2024-05-22,"Fangqiang Ding, Xiangyu Wen, Yunzhou Zhu, Yiming Li, Chris Xiaoxuan Lu",http://arxiv.org/pdf/2405.14014v4,cs.LG
ReCycle: Resilient Training of Large DNNs using Pipeline Adaptation,"Training large Deep Neural Network (DNN) models requires thousands of GPUs
over the course of several days or weeks. At this scale, failures are frequent
and can have a big impact on training throughput. Utilizing spare GPU servers
to mitigate performance loss becomes increasingly costly as model sizes grow.
ReCycle is a system designed for efficient DNN training in the presence of
failures, without relying on spare servers. It exploits the inherent functional
redundancy in distributed training systems -- where servers across
data-parallel groups store the same model parameters -- and pipeline schedule
bubbles within each data-parallel group. When servers fails, ReCycle
dynamically re-routes micro-batches to data-parallel peers, allowing for
uninterrupted training despite multiple failures. However, this re-routing can
create imbalances across pipeline stages, leading to reduced training
throughput. To address this, ReCycle introduces two key optimizations that
ensure re-routed micro-batches are processed within the original pipeline
schedule's bubbles. First, it decouples the backward pass into two phases: one
for computing gradients for the input and another for calculating gradients for
the parameters. Second, it avoids synchronization across pipeline stages by
staggering the optimizer step. Together, these optimizations enable adaptive
pipeline schedules that minimize or even eliminate training throughput
degradation during failures. We describe a prototype for ReCycle and show that
it achieves high training throughput under multiple failures, outperforming
recent proposals for fault-tolerant training such as Oobleck and Bamboo by up
to $1.46\times$ and $1.64\times$, respectively.",2024-05-22,"Swapnil Gandhi, Mark Zhao, Athinagoras Skiadopoulos, Christos Kozyrakis",http://arxiv.org/pdf/2405.14009v2,cs.LG
Bayesian Inverse Problems with Conditional Sinkhorn Generative Adversarial Networks in Least Volume Latent Spaces,"Solving inverse problems in scientific and engineering fields has long been
intriguing and holds great potential for many applications, yet most techniques
still struggle to address issues such as high dimensionality, nonlinearity and
model uncertainty inherent in these problems. Recently, generative models such
as Generative Adversarial Networks (GANs) have shown great potential in
approximating complex high dimensional conditional distributions and have paved
the way for characterizing posterior densities in Bayesian inverse problems,
yet the problems' high dimensionality and high nonlinearity often impedes the
model's training. In this paper we show how to tackle these issues with Least
Volume--a novel unsupervised nonlinear dimension reduction method--that can
learn to represent the given datasets with the minimum number of latent
variables while estimating their intrinsic dimensions. Once the low dimensional
latent spaces are identified, efficient and accurate training of conditional
generative models becomes feasible, resulting in a latent conditional GAN
framework for posterior inference. We demonstrate the power of the proposed
methodology on a variety of applications including inversion of parameters in
systems of ODEs and high dimensional hydraulic conductivities in subsurface
flow problems, and reveal the impact of the observables' and unobservables'
intrinsic dimensions on inverse problems.",2024-05-22,"Qiuyi Chen, Panagiotis Tsilifis, Mark Fuge",http://arxiv.org/pdf/2405.14008v1,cs.LG
A Practice in Enrollment Prediction with Markov Chain Models,"Enrollment projection is a critical aspect of university management, guiding
decisions related to resource allocation and revenue forecasting. However,
despite its importance, there remains a lack of transparency regarding the
methodologies utilized by many institutions. This paper presents an innovative
approach to enrollment projection using Markov Chain modeling, drawing upon a
case study conducted at Eastern Michigan University (EMU). Markov Chain
modeling emerges as a promising approach for enrollment projection, offering
precise predictions based on historical trends. This paper outlines the
implementation of Enhanced Markov Chain modeling at EMU, detailing the
methodology used to compute transition probabilities and evaluate model
performance. Despite challenges posed by external uncertainties such as the
COVID-19 pandemic, Markov Chain modeling has demonstrated impressive accuracy,
with an average difference of less than 1 percent between predicted and actual
enrollments. The paper concludes with a discussion of future directions and
opportunities for collaboration among institutions.",2024-05-22,"Yan Zhao, Amy Otteson",http://arxiv.org/pdf/2405.14007v1,cs.LG
Animal Behavior Analysis Methods Using Deep Learning: A Survey,"Animal behavior serves as a reliable indicator of the adaptation of organisms
to their environment and their overall well-being. Through rigorous observation
of animal actions and interactions, researchers and observers can glean
valuable insights into diverse facets of their lives, encompassing health,
social dynamics, ecological relationships, and neuroethological dimensions.
Although state-of-the-art deep learning models have demonstrated remarkable
accuracy in classifying various forms of animal data, their adoption in animal
behavior studies remains limited. This survey article endeavors to
comprehensively explore deep learning architectures and strategies applied to
the identification of animal behavior, spanning auditory, visual, and
audiovisual methodologies. Furthermore, the manuscript scrutinizes extant
animal behavior datasets, offering a detailed examination of the principal
challenges confronting this research domain. The article culminates in a
comprehensive discussion of key research directions within deep learning that
hold potential for advancing the field of animal behavior studies.",2024-05-22,"Edoardo Fazzari, Donato Romano, Fabrizio Falchi, Cesare Stefanini",http://arxiv.org/pdf/2405.14002v1,cs.LG
CViT: Continuous Vision Transformer for Operator Learning,"Operator learning, which aims to approximate maps between
infinite-dimensional function spaces, is an important area in scientific
machine learning with applications across various physical domains. Here we
introduce the Continuous Vision Transformer (CViT), a novel neural operator
architecture that leverages advances in computer vision to address challenges
in learning complex physical systems. CViT combines a vision transformer
encoder, a novel grid-based coordinate embedding, and a query-wise
cross-attention mechanism to effectively capture multi-scale dependencies. This
design allows for flexible output representations and consistent evaluation at
arbitrary resolutions. We demonstrate CViT's effectiveness across a diverse
range of partial differential equation (PDE) systems, including fluid dynamics,
climate modeling, and reaction-diffusion processes. Our comprehensive
experiments show that CViT achieves state-of-the-art performance on multiple
benchmarks, often surpassing larger foundation models, even without extensive
pretraining and roll-out fine-tuning. Taken together, CViT exhibits robust
handling of discontinuous solutions, multi-scale features, and intricate
spatio-temporal dynamics. Our contributions can be viewed as a significant step
towards adapting advanced computer vision architectures for building more
flexible and accurate machine learning models in the physical sciences.",2024-05-22,"Sifan Wang, Jacob H Seidman, Shyam Sankaran, Hanwen Wang, George J. Pappas, Paris Perdikaris",http://arxiv.org/pdf/2405.13998v3,cs.LG
Sigmoid Gating is More Sample Efficient than Softmax Gating in Mixture of Experts,"The softmax gating function is arguably the most popular choice in mixture of
experts modeling. Despite its widespread use in practice, the softmax gating
may lead to unnecessary competition among experts, potentially causing the
undesirable phenomenon of representation collapse due to its inherent
structure. In response, the sigmoid gating function has been recently proposed
as an alternative and has been demonstrated empirically to achieve superior
performance. However, a rigorous examination of the sigmoid gating function is
lacking in current literature. In this paper, we verify theoretically that the
sigmoid gating, in fact, enjoys a higher sample efficiency than the softmax
gating for the statistical task of expert estimation. Towards that goal, we
consider a regression framework in which the unknown regression function is
modeled as a mixture of experts, and study the rates of convergence of the
least squares estimator under the over-specified case in which the number of
fitted experts is larger than the true value. We show that two gating regimes
naturally arise and, in each of them, we formulate an identifiability condition
for the expert functions and derive the corresponding convergence rates. In
both cases, we find that experts formulated as feed-forward networks with
commonly used activation such as ReLU and GELU enjoy faster convergence rates
under the sigmoid gating than those under softmax gating. Furthermore, given
the same choice of experts, we demonstrate that the sigmoid gating function
requires a smaller sample size than its softmax counterpart to attain the same
error of expert estimation and, therefore, is more sample efficient.",2024-05-22,"Huy Nguyen, Nhat Ho, Alessandro Rinaldo",http://arxiv.org/pdf/2405.13997v3,cs.LG
Leveraging World Events to Predict E-Commerce Consumer Demand under Anomaly,"Consumer demand forecasting is of high importance for many e-commerce
applications, including supply chain optimization, advertisement placement, and
delivery speed optimization. However, reliable time series sales forecasting
for e-commerce is difficult, especially during periods with many anomalies, as
can often happen during pandemics, abnormal weather, or sports events. Although
many time series algorithms have been applied to the task, prediction during
anomalies still remains a challenge. In this work, we hypothesize that
leveraging external knowledge found in world events can help overcome the
challenge of prediction under anomalies. We mine a large repository of 40 years
of world events and their textual representations. Further, we present a novel
methodology based on transformers to construct an embedding of a day based on
the relations of the day's events. Those embeddings are then used to forecast
future consumer behavior. We empirically evaluate the methods over a large
e-commerce products sales dataset, extracted from eBay, one of the world's
largest online marketplaces. We show over numerous categories that our method
outperforms state-of-the-art baselines during anomalies.",2024-05-22,"Dan Kalifa, Uriel Singer, Ido Guy, Guy D. Rosin, Kira Radinsky",http://arxiv.org/pdf/2405.13995v1,cs.LG
Data-Free Federated Class Incremental Learning with Diffusion-Based Generative Memory,"Federated Class Incremental Learning (FCIL) is a critical yet largely
underexplored issue that deals with the dynamic incorporation of new classes
within federated learning (FL). Existing methods often employ generative
adversarial networks (GANs) to produce synthetic images to address privacy
concerns in FL. However, GANs exhibit inherent instability and high
sensitivity, compromising the effectiveness of these methods. In this paper, we
introduce a novel data-free federated class incremental learning framework with
diffusion-based generative memory (DFedDGM) to mitigate catastrophic forgetting
by generating stable, high-quality images through diffusion models. We design a
new balanced sampler to help train the diffusion models to alleviate the common
non-IID problem in FL, and introduce an entropy-based sample filtering
technique from an information theory perspective to enhance the quality of
generative samples. Finally, we integrate knowledge distillation with a
feature-based regularization term for better knowledge transfer. Our framework
does not incur additional communication costs compared to the baseline FedAvg
method. Extensive experiments across multiple datasets demonstrate that our
method significantly outperforms existing baselines, e.g., over a 4%
improvement in average accuracy on the Tiny-ImageNet dataset.",2024-05-22,"Naibo Wang, Yuchen Deng, Wenjie Feng, Jianwei Yin, See-Kiong Ng",http://arxiv.org/pdf/2405.17457v1,cs.LG
Practical $0.385$-Approximation for Submodular Maximization Subject to a Cardinality Constraint,"Non-monotone constrained submodular maximization plays a crucial role in
various machine learning applications. However, existing algorithms often
struggle with a trade-off between approximation guarantees and practical
efficiency. The current state-of-the-art is a recent $0.401$-approximation
algorithm, but its computational complexity makes it highly impractical. The
best practical algorithms for the problem only guarantee $1/e$-approximation.
In this work, we present a novel algorithm for submodular maximization subject
to a cardinality constraint that combines a guarantee of $0.385$-approximation
with a low and practical query complexity of $O(n+k^2)$. Furthermore, we
evaluate the empirical performance of our algorithm in experiments based on
various machine learning applications, including Movie Recommendation, Image
Summarization, and more. These experiments demonstrate the efficacy of our
approach.",2024-05-22,"Murad Tukan, Loay Mualem, Moran Feldman",http://arxiv.org/pdf/2405.13994v1,cs.LG
AutoLCZ: Towards Automatized Local Climate Zone Mapping from Rule-Based Remote Sensing,"Local climate zones (LCZs) established a standard classification system to
categorize the landscape universe for improved urban climate studies. Existing
LCZ mapping is guided by human interaction with geographic information systems
(GIS) or modelled from remote sensing (RS) data. GIS-based methods do not scale
to large areas. However, RS-based methods leverage machine learning techniques
to automatize LCZ classification from RS. Yet, RS-based methods require huge
amounts of manual labels for training.
  We propose a novel LCZ mapping framework, termed AutoLCZ, to extract the LCZ
classification features from high-resolution RS modalities. We study the
definition of numerical rules designed to mimic the LCZ definitions. Those
rules model geometric and surface cover properties from LiDAR data.
Correspondingly, we enable LCZ classification from RS data in a GIS-based
scheme. The proposed AutoLCZ method has potential to reduce the human labor to
acquire accurate metadata. At the same time, AutoLCZ sheds light on the
physical interpretability of RS-based methods. In a proof-of-concept for New
York City (NYC) we leverage airborne LiDAR surveys to model 4 LCZ features to
distinguish 10 LCZ types. The results indicate the potential of AutoLCZ as
promising avenue for large-scale LCZ mapping from RS data.",2024-05-22,"Chenying Liu, Hunsoo Song, Anamika Shreevastava, Conrad M Albrecht",http://arxiv.org/pdf/2405.13993v1,cs.LG
Learning Cut Generating Functions for Integer Programming,"The branch-and-cut algorithm is the method of choice to solve large scale
integer programming problems in practice. A key ingredient of branch-and-cut is
the use of cutting planes which are derived constraints that reduce the search
space for an optimal solution. Selecting effective cutting planes to produce
small branch-and-cut trees is a critical challenge in the branch-and-cut
algorithm. Recent advances have employed a data-driven approach to select
optimal cutting planes from a parameterized family, aimed at reducing the
branch-and-bound tree size (in expectation) for a given distribution of integer
programming instances. We extend this idea to the selection of the best cut
generating function (CGF), which is a tool in the integer programming
literature for generating a wide variety of cutting planes that generalize the
well-known Gomory Mixed-Integer (GMI) cutting planes. We provide rigorous
sample complexity bounds for the selection of an effective CGF from certain
parameterized families that provably performs well for any specified
distribution on the problem instances. Our empirical results show that the
selected CGF can outperform the GMI cuts for certain distributions.
Additionally, we explore the sample complexity of using neural networks for
instance-dependent CGF selection.",2024-05-22,"Hongyu Cheng, Amitabh Basu",http://arxiv.org/pdf/2405.13992v1,cs.LG
Analysis of Corrected Graph Convolutions,"Machine learning for node classification on graphs is a prominent area driven
by applications such as recommendation systems. State-of-the-art models often
use multiple graph convolutions on the data, as empirical evidence suggests
they can enhance performance. However, it has been shown empirically and
theoretically, that too many graph convolutions can degrade performance
significantly, a phenomenon known as oversmoothing. In this paper, we provide a
rigorous theoretical analysis, based on the two-class contextual stochastic
block model (CSBM), of the performance of vanilla graph convolution from which
we remove the principal eigenvector to avoid oversmoothing. We perform a
spectral analysis for $k$ rounds of corrected graph convolutions, and we
provide results for partial and exact classification. For partial
classification, we show that each round of convolution can reduce the
misclassification error exponentially up to a saturation level, after which
performance does not worsen. We also extend this analysis to the multi-class
setting with features distributed according to a Gaussian mixture model. For
exact classification, we show that the separability threshold can be improved
exponentially up to $O({\log{n}}/{\log\log{n}})$ corrected convolutions.",2024-05-22,"Robert Wang, Aseem Baranwal, Kimon Fountoulakis",http://arxiv.org/pdf/2405.13987v2,cs.LG
Riemannian Bilevel Optimization,"We develop new algorithms for Riemannian bilevel optimization. We focus in
particular on batch and stochastic gradient-based methods, with the explicit
goal of avoiding second-order information such as Riemannian hyper-gradients.
We propose and analyze $\mathrm{RF^2SA}$, a method that leverages first-order
gradient information to navigate the complex geometry of Riemannian manifolds
efficiently. Notably, $\mathrm{RF^2SA}$ is a single-loop algorithm, and thus
easier to implement and use. Under various setups, including stochastic
optimization, we provide explicit convergence rates for reaching
$\epsilon$-stationary points. We also address the challenge of optimizing over
Riemannian manifolds with constraints by adjusting the multiplier in the
Lagrangian, ensuring convergence to the desired solution without requiring
access to second-order derivatives.",2024-05-22,"Sanchayan Dutta, Xiang Cheng, Suvrit Sra",http://arxiv.org/pdf/2405.15816v1,cs.LG
DirectMultiStep: Direct Route Generation for Multistep Retrosynthesis,"Traditional computer-aided synthesis planning (CASP) methods rely on
iterative single-step predictions, leading to exponential search space growth
that limits efficiency and scalability. We introduce a series of
transformer-based models, that leverage a mixture of experts approach to
directly generate multistep synthetic routes as a single string, conditionally
predicting each transformation based on all preceding ones. Our DMS Explorer XL
model, which requires only target compounds as input, outperforms
state-of-the-art methods on the PaRoutes dataset with 1.9x and 3.1x
improvements in Top-1 accuracy on the n$_1$ and n$_5$ test sets, respectively.
Providing additional information, such as the desired number of steps and
starting materials, enables both a reduction in model size and an increase in
accuracy, highlighting the benefits of incorporating more constraints into the
prediction process. The top-performing DMS-Flex (Duo) model scores 25-50%
higher on Top-1 and Top-10 accuracies for both n$_1$ and n$_5$ sets.
Additionally, our models successfully predict routes for FDA-approved drugs not
included in the training data, demonstrating strong generalization
capabilities. While the limited diversity of the training set may affect
performance on less common reaction types, our multistep-first approach
presents a promising direction towards fully automated retrosynthetic planning.",2024-05-22,"Yu Shee, Anton Morgunov, Haote Li, Victor S. Batista",http://arxiv.org/pdf/2405.13983v3,cs.LG
Generalized Compressed Sensing for Image Reconstruction with Diffusion Probabilistic Models,"We examine the problem of selecting a small set of linear measurements for
reconstructing high-dimensional signals. Well-established methods for
optimizing such measurements include principal component analysis (PCA),
independent component analysis (ICA) and compressed sensing (CS) based on
random projections, all of which rely on axis- or subspace-aligned statistical
characterization of the signal source. However, many naturally occurring
signals, including photographic images, contain richer statistical structure.
To exploit such structure, we introduce a general method for obtaining an
optimized set of linear measurements for efficient image reconstruction, where
the signal statistics are expressed by the prior implicit in a neural network
trained to perform denoising (known as a ``diffusion model''). We demonstrate
that the optimal measurements derived for two natural image datasets differ
from those of PCA, ICA, or CS, and result in substantially lower mean squared
reconstruction error. Interestingly, the marginal distributions of the
measurement values are asymmetrical (skewed), substantially more so than those
of previous methods. We also find that optimizing with respect to perceptual
loss, as quantified by structural similarity (SSIM), leads to measurements
different from those obtained when optimizing for MSE. Our results highlight
the importance of incorporating the specific statistical regularities of
natural signals when designing effective linear measurements.",2024-05-22,"Ling-Qi Zhang, Zahra Kadkhodaie, Eero P. Simoncelli, David H. Brainard",http://arxiv.org/pdf/2405.17456v3,cs.LG
Rank Reduction Autoencoders,"The choice of an appropriate bottleneck dimension and the application of
effective regularization are both essential for Autoencoders to learn
meaningful representations from unlabeled data. In this paper, we introduce a
new class of deterministic autoencoders, Rank Reduction Autoencoders (RRAEs),
which regularize their latent spaces by employing a truncated singular value
decomposition (SVD) during training. In RRAEs, the bottleneck is defined by the
rank of the latent matrix, thereby alleviating the dependence of the
encoder/decoder architecture on the bottleneck size. This approach enabled us
to propose an adaptive algorithm (aRRAEs) that efficiently determines the
optimal bottleneck size during training. We empirically demonstrate that both
RRAEs and aRRAEs are stable, scalable, and reliable, as they do not introduce
any additional training hyperparameters. We evaluate our proposed architecture
on a synthetic data set, as well as on MNIST, Fashion MNIST, and CelebA. Our
results show that RRAEs offer several advantages over Vanilla AEs with both
large and small latent spaces, and outperform other regularizing AE
architectures.",2024-05-22,"Jad Mounayer, Sebastian Rodriguez, Chady Ghnatios, Charbel Farhat, Francisco Chinesta",http://arxiv.org/pdf/2405.13980v3,cs.LG
Mitigating Interference in the Knowledge Continuum through Attention-Guided Incremental Learning,"Continual learning (CL) remains a significant challenge for deep neural
networks, as it is prone to forgetting previously acquired knowledge. Several
approaches have been proposed in the literature, such as experience rehearsal,
regularization, and parameter isolation, to address this problem. Although
almost zero forgetting can be achieved in task-incremental learning,
class-incremental learning remains highly challenging due to the problem of
inter-task class separation. Limited access to previous task data makes it
difficult to discriminate between classes of current and previous tasks. To
address this issue, we propose `Attention-Guided Incremental Learning' (AGILE),
a novel rehearsal-based CL approach that incorporates compact task attention to
effectively reduce interference between tasks. AGILE utilizes lightweight,
learnable task projection vectors to transform the latent representations of a
shared task attention module toward task distribution. Through extensive
empirical evaluation, we show that AGILE significantly improves generalization
performance by mitigating task interference and outperforming rehearsal-based
approaches in several CL scenarios. Furthermore, AGILE can scale well to a
large number of tasks with minimal overhead while remaining well-calibrated
with reduced task-recency bias.",2024-05-22,"Prashant Bhat, Bharath Renjith, Elahe Arani, Bahram Zonooz",http://arxiv.org/pdf/2405.13978v1,cs.LG
Improving Fairness and Mitigating MADness in Generative Models,"Generative models unfairly penalize data belonging to minority classes,
suffer from model autophagy disorder (MADness), and learn biased estimates of
the underlying distribution parameters. Our theoretical and empirical results
show that training generative models with intentionally designed hypernetworks
leads to models that 1) are more fair when generating datapoints belonging to
minority classes 2) are more stable in a self-consumed (i.e., MAD) setting, and
3) learn parameters that are less statistically biased. To further mitigate
unfairness, MADness, and bias, we introduce a regularization term that
penalizes discrepancies between a generative model's estimated weights when
trained on real data versus its own synthetic data. To facilitate training
existing deep generative models within our framework, we offer a scalable
implementation of hypernetworks that automatically generates a hypernetwork
architecture for any given generative model.",2024-05-22,"Paul Mayer, Lorenzo Luzi, Ali Siahkoohi, Don H. Johnson, Richard G. Baraniuk",http://arxiv.org/pdf/2405.13977v3,cs.LG
EchoSpike Predictive Plasticity: An Online Local Learning Rule for Spiking Neural Networks,"The drive to develop artificial neural networks that efficiently utilize
resources has generated significant interest in bio-inspired Spiking Neural
Networks (SNNs). These networks are particularly attractive due to their
potential in applications requiring low power and memory. This potential is
further enhanced by the ability to perform online local learning, enabling them
to adapt to dynamic environments. This requires the model to be adaptive in a
self-supervised manner. While self-supervised learning has seen great success
in many deep learning domains, its application for online local learning in
multi-layer SNNs remains underexplored. In this paper, we introduce the
""EchoSpike Predictive Plasticity"" (ESPP) learning rule, a pioneering online
local learning rule designed to leverage hierarchical temporal dynamics in SNNs
through predictive and contrastive coding. We validate the effectiveness of
this approach using benchmark datasets, demonstrating that it performs on par
with current state-of-the-art supervised learning rules. The temporal and
spatial locality of ESPP makes it particularly well-suited for low-cost
neuromorphic processors, representing a significant advancement in developing
biologically plausible self-supervised learning models for neuromorphic
computing at the edge.",2024-05-22,"Lars Graf, Zhe Su, Giacomo Indiveri",http://arxiv.org/pdf/2405.13976v2,cs.LG
HOPE for a Robust Parameterization of Long-memory State Space Models,"State-space models (SSMs) that utilize linear, time-invariant (LTI) systems
are known for their effectiveness in learning long sequences. To achieve
state-of-the-art performance, an SSM often needs a specifically designed
initialization, and the training of state matrices is on a logarithmic scale
with a very small learning rate. To understand these choices from a unified
perspective, we view SSMs through the lens of Hankel operator theory. Building
upon it, we develop a new parameterization scheme, called HOPE, for LTI systems
that utilizes Markov parameters within Hankel operators. Our approach helps
improve the initialization and training stability, leading to a more robust
parameterization. We efficiently implement these innovations by nonuniformly
sampling the transfer functions of LTI systems, and they require fewer
parameters compared to canonical SSMs. When benchmarked against
HiPPO-initialized models such as S4 and S4D, an SSM parameterized by Hankel
operators demonstrates improved performance on Long-Range Arena (LRA) tasks.
Moreover, our new parameterization endows the SSM with non-decaying memory
within a fixed time window, which is empirically corroborated by a sequential
CIFAR-10 task with padded noise.",2024-05-22,"Annan Yu, Michael W. Mahoney, N. Benjamin Erichson",http://arxiv.org/pdf/2405.13975v2,cs.LG
Infinite-Dimensional Feature Interaction,"The past neural network design has largely focused on feature representation
space dimension and its capacity scaling (e.g., width, depth), but overlooked
the feature interaction space scaling.
  Recent advancements have shown shifted focus towards element-wise
multiplication to facilitate higher-dimensional feature interaction space for
better information transformation. Despite this progress, multiplications
predominantly capture low-order interactions, thus remaining confined to a
finite-dimensional interaction space. To transcend this limitation, classic
kernel methods emerge as a promising solution to engage features in an
infinite-dimensional space. We introduce InfiNet, a model architecture that
enables feature interaction within an infinite-dimensional space created by RBF
kernel. Our experiments reveal that InfiNet achieves new state-of-the-art,
owing to its capability to leverage infinite-dimensional interactions,
significantly enhancing model performance.",2024-05-22,"Chenhui Xu, Fuxun Yu, Maoliang Li, Zihao Zheng, Zirui Xu, Jinjun Xiong, Xiang Chen",http://arxiv.org/pdf/2405.13972v4,cs.LG
Uncertainty-Aware DRL for Autonomous Vehicle Crowd Navigation in Shared Space,"Safe, socially compliant, and efficient navigation of low-speed autonomous
vehicles (AVs) in pedestrian-rich environments necessitates considering
pedestrians' future positions and interactions with the vehicle and others.
Despite the inevitable uncertainties associated with pedestrians' predicted
trajectories due to their unobserved states (e.g., intent), existing deep
reinforcement learning (DRL) algorithms for crowd navigation often neglect
these uncertainties when using predicted trajectories to guide policy learning.
This omission limits the usability of predictions when diverging from ground
truth. This work introduces an integrated prediction and planning approach that
incorporates the uncertainties of predicted pedestrian states in the training
of a model-free DRL algorithm. A novel reward function encourages the AV to
respect pedestrians' personal space, decrease speed during close approaches,
and minimize the collision probability with their predicted paths. Unlike
previous DRL methods, our model, designed for AV operation in crowded spaces,
is trained in a novel simulation environment that reflects realistic pedestrian
behaviour in a shared space with vehicles. Results show a 40% decrease in
collision rate and a 15% increase in minimum distance to pedestrians compared
to the state of the art model that does not account for prediction uncertainty.
Additionally, the approach outperforms model predictive control methods that
incorporate the same prediction uncertainties in terms of both performance and
computational time, while producing trajectories closer to human drivers in
similar scenarios.",2024-05-22,"Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad",http://arxiv.org/pdf/2405.13969v1,cs.LG
Unleashing the Power of Unlabeled Data: A Self-supervised Learning Framework for Cyber Attack Detection in Smart Grids,"Modern power grids are undergoing significant changes driven by information
and communication technologies (ICTs), and evolving into smart grids with
higher efficiency and lower operation cost. Using ICTs, however, comes with an
inevitable side effect that makes the power system more vulnerable to cyber
attacks. In this paper, we propose a self-supervised learning-based framework
to detect and identify various types of cyber attacks. Different from existing
approaches, the proposed framework does not rely on large amounts of
well-curated labeled data but makes use of the massive unlabeled data in the
wild which are easily accessible. Specifically, the proposed framework adopts
the BERT model from the natural language processing domain and learns
generalizable and effective representations from the unlabeled sensing data,
which capture the distinctive patterns of different attacks. Using the learned
representations, together with a very small amount of labeled data, we can
train a task-specific classifier to detect various types of cyber attacks.
Meanwhile, real-world training datasets are usually imbalanced, i.e., there are
only a limited number of data samples containing attacks. In order to cope with
such data imbalance, we propose a new loss function, separate mean error (SME),
which pays equal attention to the large and small categories to better train
the model. Experiment results in a 5-area power grid system with 37 buses
demonstrate the superior performance of our framework over existing approaches,
especially when a very limited portion of labeled data are available, e.g., as
low as 0.002\%. We believe such a framework can be easily adopted to detect a
variety of cyber attacks in other power grid scenarios.",2024-05-22,"Hanyu Zeng, Pengfei Zhou, Xin Lou, Zhen Wei Ng, David K. Y. Yau, Marianne Winslett",http://arxiv.org/pdf/2405.13965v1,cs.LG
Visual Analysis of Prediction Uncertainty in Neural Networks for Deep Image Synthesis,"Ubiquitous applications of Deep neural networks (DNNs) in different
artificial intelligence systems have led to their adoption in solving
challenging visualization problems in recent years. While sophisticated DNNs
offer an impressive generalization, it is imperative to comprehend the quality,
confidence, robustness, and uncertainty associated with their prediction. A
thorough understanding of these quantities produces actionable insights that
help application scientists make informed decisions. Unfortunately, the
intrinsic design principles of the DNNs cannot beget prediction uncertainty,
necessitating separate formulations for robust uncertainty-aware models for
diverse visualization applications. To that end, this contribution demonstrates
how the prediction uncertainty and sensitivity of DNNs can be estimated
efficiently using various methods and then interactively compared and
contrasted for deep image synthesis tasks. Our inspection suggests that
uncertainty-aware deep visualization models generate illustrations of
informative and superior quality and diversity. Furthermore, prediction
uncertainty improves the robustness and interpretability of deep visualization
models, making them practical and convenient for various scientific domains
that thrive on visual analyses.",2024-05-22,"Soumya Dutta, Faheem Nizar, Ahmad Amaan, Ayan Acharya",http://arxiv.org/pdf/2406.18545v1,cs.LG
Design Editing for Offline Model-based Optimization,"Offline model-based optimization (MBO) aims to maximize a black-box objective
function using only an offline dataset of designs and scores. These tasks span
various domains, such as robotics, material design, and protein and molecular
engineering. A common approach involves training a surrogate model using
existing designs and their corresponding scores, and then generating new
designs through gradient-based updates with respect to the surrogate model.
This method suffers from the out-of-distribution issue, where the surrogate
model may erroneously predict high scores for unseen designs. To address this
challenge, we introduce a novel method, Design Editing for Offline Model-based
Optimization (DEMO), which leverages a diffusion prior to calibrate overly
optimized designs. DEMO first generates pseudo design candidates by performing
gradient ascent with respect to a surrogate model. While these pseudo design
candidates contain information beyond the offline dataset, they might be
invalid or have erroneously high predicted scores. Therefore, to address this
challenge while utilizing the information provided by pseudo design candidates,
we propose an editing process to refine these pseudo design candidates. We
introduce noise to the pseudo design candidates and subsequently denoise them
with a diffusion prior trained on the offline dataset, ensuring they align with
the distribution of valid designs. Empirical evaluations on seven offline MBO
tasks show that, with properly tuned hyperparameters, DEMOs score is
competitive with the best previously reported scores in the literature.",2024-05-22,"Ye Yuan, Youyuan Zhang, Can Chen, Haolun Wu, Zixuan Li, Jianmo Li, James J. Clark, Xue Liu",http://arxiv.org/pdf/2405.13964v4,cs.LG
Robust Generative Learning with Lipschitz-Regularized $α$-Divergences Allows Minimal Assumptions on Target Distributions,"This paper demonstrates the robustness of Lipschitz-regularized
$\alpha$-divergences as objective functionals in generative modeling, showing
they enable stable learning across a wide range of target distributions with
minimal assumptions. We establish that these divergences remain finite under a
mild condition-that the source distribution has a finite first
moment-regardless of the properties of the target distribution, making them
adaptable to the structure of target distributions. Furthermore, we prove the
existence and finiteness of their variational derivatives, which are essential
for stable training of generative models such as GANs and gradient flows. For
heavy-tailed targets, we derive necessary and sufficient conditions that
connect data dimension, $\alpha$, and tail behavior to divergence finiteness,
that also provide insights into the selection of suitable $\alpha$'s. We also
provide the first sample complexity bounds for empirical estimations of these
divergences on unbounded domains. As a byproduct, we obtain the first sample
complexity bounds for empirical estimations of these divergences and the
Wasserstein-1 metric with group symmetry on unbounded domains. Numerical
experiments confirm that generative models leveraging Lipschitz-regularized
$\alpha$-divergences can stably learn distributions in various challenging
scenarios, including those with heavy tails or complex, low-dimensional, or
fractal support, all without any prior knowledge of the structure of target
distributions.",2024-05-22,"Ziyu Chen, Hyemin Gu, Markos A. Katsoulakis, Luc Rey-Bellet, Wei Zhu",http://arxiv.org/pdf/2405.13962v2,cs.LG
SADDLe: Sharpness-Aware Decentralized Deep Learning with Heterogeneous Data,"Decentralized training enables learning with distributed datasets generated
at different locations without relying on a central server. In realistic
scenarios, the data distribution across these sparsely connected learning
agents can be significantly heterogeneous, leading to local model over-fitting
and poor global model generalization. Another challenge is the high
communication cost of training models in such a peer-to-peer fashion without
any central coordination. In this paper, we jointly tackle these two-fold
practical challenges by proposing SADDLe, a set of sharpness-aware
decentralized deep learning algorithms. SADDLe leverages Sharpness-Aware
Minimization (SAM) to seek a flatter loss landscape during training, resulting
in better model generalization as well as enhanced robustness to communication
compression. We present two versions of our approach and conduct extensive
experiments to show that SADDLe leads to 1-20% improvement in test accuracy
compared to other existing techniques. Additionally, our proposed approach is
robust to communication compression, with an average drop of only 1% in the
presence of up to 4x compression.",2024-05-22,"Sakshi Choudhary, Sai Aparna Aketi, Kaushik Roy",http://arxiv.org/pdf/2405.13961v2,cs.LG
Learning To Play Atari Games Using Dueling Q-Learning and Hebbian Plasticity,"In this work, an advanced deep reinforcement learning architecture is used to
train neural network agents playing atari games. Given only the raw game
pixels, action space, and reward information, the system can train agents to
play any Atari game. At first, this system uses advanced techniques like deep
Q-networks and dueling Q-networks to train efficient agents, the same
techniques used by DeepMind to train agents that beat human players in Atari
games. As an extension, plastic neural networks are used as agents, and their
feasibility is analyzed in this scenario. The plasticity implementation was
based on backpropagation and the Hebbian update rule. Plastic neural networks
have excellent features like lifelong learning after the initial training,
which makes them highly suitable in adaptive learning environments. As a new
analysis of plasticity in this context, this work might provide valuable
insights and direction for future works.",2024-05-22,Md Ashfaq Salehin,http://arxiv.org/pdf/2405.13960v1,cs.LG
Fair Evaluation of Federated Learning Algorithms for Automated Breast Density Classification: The Results of the 2022 ACR-NCI-NVIDIA Federated Learning Challenge,"The correct interpretation of breast density is important in the assessment
of breast cancer risk. AI has been shown capable of accurately predicting
breast density, however, due to the differences in imaging characteristics
across mammography systems, models built using data from one system do not
generalize well to other systems. Though federated learning (FL) has emerged as
a way to improve the generalizability of AI without the need to share data, the
best way to preserve features from all training data during FL is an active
area of research. To explore FL methodology, the breast density classification
FL challenge was hosted in partnership with the American College of Radiology,
Harvard Medical School's Mass General Brigham, University of Colorado, NVIDIA,
and the National Institutes of Health National Cancer Institute. Challenge
participants were able to submit docker containers capable of implementing FL
on three simulated medical facilities, each containing a unique large
mammography dataset. The breast density FL challenge ran from June 15 to
September 5, 2022, attracting seven finalists from around the world. The
winning FL submission reached a linear kappa score of 0.653 on the challenge
test data and 0.413 on an external testing dataset, scoring comparably to a
model trained on the same data in a central location.",2024-05-22,"Kendall Schmidt, Benjamin Bearce, Ken Chang, Laura Coombs, Keyvan Farahani, Marawan Elbatele, Kaouther Mouhebe, Robert Marti, Ruipeng Zhang, Yao Zhang, Yanfeng Wang, Yaojun Hu, Haochao Ying, Yuyang Xu, Conrad Testagrose, Mutlu Demirer, Vikash Gupta, Ünal Akünal, Markus Bujotzek, Klaus H. Maier-Hein, Yi Qin, Xiaomeng Li, Jayashree Kalpathy-Cramer, Holger R. Roth",http://arxiv.org/pdf/2405.14900v1,cs.LG
Exploring the Relationship Between Feature Attribution Methods and Model Performance,"Machine learning and deep learning models are pivotal in educational
contexts, particularly in predicting student success. Despite their widespread
application, a significant gap persists in comprehending the factors
influencing these models' predictions, especially in explainability within
education. This work addresses this gap by employing nine distinct explanation
methods and conducting a comprehensive analysis to explore the correlation
between the agreement among these methods in generating explanations and the
predictive model's performance. Applying Spearman's correlation, our findings
reveal a very strong correlation between the model's performance and the
agreement level observed among the explanation methods.",2024-05-22,"Priscylla Silva, Claudio T. Silva, Luis Gustavo Nonato",http://arxiv.org/pdf/2405.13957v1,cs.LG
Attention as an RNN,"The advent of Transformers marked a significant breakthrough in sequence
modelling, providing a highly performant architecture capable of leveraging GPU
parallelism. However, Transformers are computationally expensive at inference
time, limiting their applications, particularly in low-resource settings (e.g.,
mobile and embedded devices). Addressing this, we (1) begin by showing that
attention can be viewed as a special Recurrent Neural Network (RNN) with the
ability to compute its \textit{many-to-one} RNN output efficiently. We then (2)
show that popular attention-based models such as Transformers can be viewed as
RNN variants. However, unlike traditional RNNs (e.g., LSTMs), these models
cannot be updated efficiently with new tokens, an important property in
sequence modelling. Tackling this, we (3) introduce a new efficient method of
computing attention's \textit{many-to-many} RNN output based on the parallel
prefix scan algorithm. Building on the new attention formulation, we (4)
introduce \textbf{Aaren}, an attention-based module that can not only (i) be
trained in parallel (like Transformers) but also (ii) be updated efficiently
with new tokens, requiring only constant memory for inferences (like
traditional RNNs). Empirically, we show Aarens achieve comparable performance
to Transformers on $38$ datasets spread across four popular sequential problem
settings: reinforcement learning, event forecasting, time series
classification, and time series forecasting tasks while being more time and
memory-efficient.",2024-05-22,"Leo Feng, Frederick Tung, Hossein Hajimirsadeghi, Mohamed Osama Ahmed, Yoshua Bengio, Greg Mori",http://arxiv.org/pdf/2405.13956v2,cs.LG
What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions,"Large language models (LLMs) are trained on a vast amount of human-written
data, but data providers often remain uncredited. In response to this issue,
data valuation (or data attribution), which quantifies the contribution or
value of each data to the model output, has been discussed as a potential
solution. Nevertheless, applying existing data valuation methods to recent LLMs
and their vast training datasets has been largely limited by prohibitive
compute and memory costs. In this work, we focus on influence functions, a
popular gradient-based data valuation method, and significantly improve its
scalability with an efficient gradient projection strategy called LoGra that
leverages the gradient structure in backpropagation. We then provide a
theoretical motivation of gradient projection approaches to influence functions
to promote trust in the data valuation process. Lastly, we lower the barrier to
implementing data valuation systems by introducing LogIX, a software package
that can transform existing training code into data valuation code with minimal
effort. In our data valuation experiments, LoGra achieves competitive accuracy
against more expensive baselines while showing up to 6,500x improvement in
throughput and 5x reduction in GPU memory usage when applied to
Llama3-8B-Instruct and the 1B-token dataset.",2024-05-22,"Sang Keun Choe, Hwijeen Ahn, Juhan Bae, Kewen Zhao, Minsoo Kang, Youngseog Chung, Adithya Pratapa, Willie Neiswanger, Emma Strubell, Teruko Mitamura, Jeff Schneider, Eduard Hovy, Roger Grosse, Eric Xing",http://arxiv.org/pdf/2405.13954v1,cs.LG
Spectral Adapter: Fine-Tuning in Spectral Space,"Recent developments in Parameter-Efficient Fine-Tuning (PEFT) methods for
pretrained deep neural networks have captured widespread interest. In this
work, we study the enhancement of current PEFT methods by incorporating the
spectral information of pretrained weight matrices into the fine-tuning
procedure. We investigate two spectral adaptation mechanisms, namely additive
tuning and orthogonal rotation of the top singular vectors, both are done via
first carrying out Singular Value Decomposition (SVD) of pretrained weights and
then fine-tuning the top spectral space. We provide a theoretical analysis of
spectral fine-tuning and show that our approach improves the rank capacity of
low-rank adapters given a fixed trainable parameter budget. We show through
extensive experiments that the proposed fine-tuning model enables better
parameter efficiency and tuning performance as well as benefits multi-adapter
fusion.",2024-05-22,"Fangzhao Zhang, Mert Pilanci",http://arxiv.org/pdf/2405.13952v2,cs.LG
Learning to sample fibers for goodness-of-fit testing,"We consider the problem of constructing exact goodness-of-fit tests for
discrete exponential family models. This classical problem remains practically
unsolved for many types of structured or sparse data, as it rests on a
computationally difficult core task: to produce a reliable sample from lattice
points in a high-dimensional polytope. We translate the problem into a Markov
decision process and demonstrate a reinforcement learning approach for learning
`good moves' for sampling. We illustrate the approach on data sets and models
for which traditional MCMC samplers converge too slowly due to problem size,
sparsity structure, and the requirement to use prohibitive non-linear algebra
computations in the process. The differentiating factor is the use of scalable
tools from \emph{linear} algebra in the context of theoretical guarantees
provided by \emph{non-linear} algebra. Our algorithm is based on an
actor-critic sampling scheme, with provable convergence.
  The discovered moves can be used to efficiently obtain an exchangeable
sample, significantly cutting computational times with regards to statistical
testing.",2024-05-22,"Ivan Gvozdanović, Sonja Petrović",http://arxiv.org/pdf/2405.13950v3,cs.LG
Leader Reward for POMO-Based Neural Combinatorial Optimization,"Deep neural networks based on reinforcement learning (RL) for solving
combinatorial optimization (CO) problems are developing rapidly and have shown
a tendency to approach or even outperform traditional solvers. However,
existing methods overlook an important distinction: CO problems differ from
other traditional problems in that they focus solely on the optimal solution
provided by the model within a specific length of time, rather than considering
the overall quality of all solutions generated by the model. In this paper, we
propose Leader Reward and apply it during two different training phases of the
Policy Optimization with Multiple Optima (POMO) model to enhance the model's
ability to generate optimal solutions. This approach is applicable to a variety
of CO problems, such as the Traveling Salesman Problem (TSP), the Capacitated
Vehicle Routing Problem (CVRP), and the Flexible Flow Shop Problem (FFSP), but
also works well with other POMO-based models or inference phase's strategies.
We demonstrate that Leader Reward greatly improves the quality of the optimal
solutions generated by the model. Specifically, we reduce the POMO's gap to the
optimum by more than 100 times on TSP100 with almost no additional
computational overhead.",2024-05-22,"Chaoyang Wang, Pengzhi Cheng, Jingze Li, Weiwei Sun",http://arxiv.org/pdf/2405.13947v1,cs.LG
A Survey on Design-space Dimensionality Reduction Methods for Shape Optimization,"The rapidly evolving field of engineering design of functional surfaces
necessitates sophisticated tools to manage the inherent complexity of
high-dimensional design spaces. This survey paper offers a scoping review,
i.e., a literature mapping synthesis borrowed from clinical medicine, delving
into the field of design-space dimensionality reduction techniques tailored for
shape optimization, bridging traditional methods and cutting-edge technologies.
Dissecting the spectrum of these techniques, from classical linear approaches
like principal component analysis to more nuanced nonlinear methods such as
autoencoders, the discussion extends to innovative physics-informed methods
that integrate physical data into the dimensionality reduction process,
enhancing the physical relevance and effectiveness of reduced design spaces. By
integrating these methods into optimization frameworks, it is shown how they
significantly mitigate the curse of dimensionality, streamline computational
processes, and refine the design exploration and optimization of complex
functional surfaces. The survey provides a classification of methods and
highlights the transformative impact of these techniques in simplifying design
challenges, thereby fostering more efficient and effective engineering
solutions.",2024-05-22,"Andrea Serani, Matteo Diez",http://arxiv.org/pdf/2405.13944v2,cs.LG
Principal eigenstate classical shadows,"Given many copies of an unknown quantum state $\rho$, we consider the task of
learning a classical description of its principal eigenstate. Namely, assuming
that $\rho$ has an eigenstate $|\phi\rangle$ with (unknown) eigenvalue $\lambda
> 1/2$, the goal is to learn a (classical shadows style) classical description
of $|\phi\rangle$ which can later be used to estimate expectation values
$\langle \phi |O| \phi \rangle$ for any $O$ in some class of observables. We
consider the sample-complexity setting in which generating a copy of $\rho$ is
expensive, but joint measurements on many copies of the state are possible. We
present a protocol for this task scaling with the principal eigenvalue
$\lambda$ and show that it is optimal within a space of natural approaches,
e.g., applying quantum state purification followed by a single-copy classical
shadows scheme. Furthermore, when $\lambda$ is sufficiently close to $1$, the
performance of our algorithm is optimal--matching the sample complexity for
pure state classical shadows.",2024-05-22,"Daniel Grier, Hakop Pashayan, Luke Schaeffer",http://arxiv.org/pdf/2405.13939v1,cs.LG
eXmY: A Data Type and Technique for Arbitrary Bit Precision Quantization,"eXmY is a novel data type for quantization of ML models. It supports both
arbitrary bit widths and arbitrary integer and floating point formats. For
example, it seamlessly supports 3, 5, 6, 7, 9 bit formats. For a specific bit
width, say 7, it defines all possible formats e.g. e0m6, e1m5, e2m4, e3m3,
e4m2, e5m1 and e6m0. For non-power of two bit widths e.g. 5, 6, 7, we created a
novel encoding and decoding scheme which achieves perfect compression, byte
addressability and is amenable to sharding and vector processing. We
implemented libraries for emulation, encoding and decoding tensors and
checkpoints in C++, TensorFlow, JAX and PAX. For optimal performance, the
codecs use SIMD instructions on CPUs and vector instructions on TPUs and GPUs.
eXmY is also a technique and exploits the statistical distribution of exponents
in tensors. It can be used to quantize weights, static and dynamic activations,
gradients, master weights and optimizer state. It can reduce memory (CPU DRAM
and accelerator HBM), network and disk storage and transfers. It can increase
multi tenancy and accelerate compute. eXmY has been deployed in production for
almost 2 years.",2024-05-22,"Aditya Agrawal, Matthew Hedlund, Blake Hechtman",http://arxiv.org/pdf/2405.13938v1,cs.LG
Node-Time Conditional Prompt Learning In Dynamic Graphs,"Dynamic graphs capture evolving interactions between entities, such as in
social networks, online learning platforms, and crowdsourcing projects. For
dynamic graph modeling, dynamic graph neural networks (DGNNs) have emerged as a
mainstream technique. However, they are generally pre-trained on the link
prediction task, leaving a significant gap from the objectives of downstream
tasks such as node classification. To bridge the gap, prompt-based learning has
gained traction on graphs, but most existing efforts focus on static graphs,
neglecting the evolution of dynamic graphs. In this paper, we propose
DYGPROMPT, a novel pre-training and prompt learning framework for dynamic graph
modeling. First, we design dual prompts to address the gap in both task
objectives and temporal variations across pre-training and downstream tasks.
Second, we recognize that node and time features mutually characterize each
other, and propose dual condition-nets to model the evolving node-time patterns
in downstream tasks. Finally, we thoroughly evaluate and analyze DYGPROMPT
through extensive experiments on four public datasets.",2024-05-22,"Xingtong Yu, Zhenghao Liu, Xinming Zhang, Yuan Fang",http://arxiv.org/pdf/2405.13937v8,cs.LG
Text-Free Multi-domain Graph Pre-training: Toward Graph Foundation Models,"Given the ubiquity of graph data, it is intriguing to ask: Is it possible to
train a graph foundation model on a broad range of graph data across diverse
domains? A major hurdle toward this goal lies in the fact that graphs from
different domains often exhibit profoundly divergent characteristics. Although
there have been some initial efforts in integrating multi-domain graphs for
pre-training, they primarily rely on textual descriptions to align the graphs,
limiting their application to text-attributed graphs. Moreover, different
source domains may conflict or interfere with each other, and their relevance
to the target domain can vary significantly. To address these issues, we
propose MDGPT, a text free Multi-Domain Graph Pre-Training and adaptation
framework designed to exploit multi-domain knowledge for graph learning. First,
we propose a set of domain tokens to to align features across source domains
for synergistic pre-training. Second, we propose a dual prompts, consisting of
a unifying prompt and a mixing prompt, to further adapt the target domain with
unified multi-domain knowledge and a tailored mixture of domain-specific
knowledge. Finally, we conduct extensive experiments involving six public
datasets to evaluate and analyze MDGPT, which outperforms prior art by up to
37.9%.",2024-05-22,"Xingtong Yu, Chang Zhou, Yuan Fang, Xinming Zhang",http://arxiv.org/pdf/2405.13934v4,cs.LG
A Methodology to Identify Physical or Computational Experiment Conditions for Uncertainty Mitigation,"Complex engineering systems require integration of simulation of sub-systems
and calculation of metrics to drive design decisions. This paper introduces a
methodology for designing computational or physical experiments for
system-level uncertainty mitigation purposes. The methodology follows a
previously determined problem ontology, where physical, functional and modeling
architectures are decided upon. By carrying out sensitivity analysis techniques
utilizing system-level tools, critical epistemic uncertainties can be
identified. Afterwards, a framework is introduced to design specific
computational and physical experimentation for generating new knowledge about
parameters, and for uncertainty mitigation. The methodology is demonstrated
through a case study on an early-stage design Blended-Wing-Body (BWB) aircraft
concept, showcasing how aerostructures analyses can be leveraged for mitigating
system-level uncertainty, by computer experiments or guiding physical
experimentation. The proposed methodology is versatile enough to tackle
uncertainty management across various design challenges, highlighting the
potential for more risk-informed design processes.",2024-05-22,"Efe Y. Yarbasi, Dimitri N. Mavris",http://arxiv.org/pdf/2405.13931v1,cs.LG
Towards Certification of Uncertainty Calibration under Adversarial Attacks,"Since neural classifiers are known to be sensitive to adversarial
perturbations that alter their accuracy, \textit{certification methods} have
been developed to provide provable guarantees on the insensitivity of their
predictions to such perturbations. Furthermore, in safety-critical
applications, the frequentist interpretation of the confidence of a classifier
(also known as model calibration) can be of utmost importance. This property
can be measured via the Brier score or the expected calibration error. We show
that attacks can significantly harm calibration, and thus propose certified
calibration as worst-case bounds on calibration under adversarial
perturbations. Specifically, we produce analytic bounds for the Brier score and
approximate bounds via the solution of a mixed-integer program on the expected
calibration error. Finally, we propose novel calibration attacks and
demonstrate how they can improve model calibration through \textit{adversarial
calibration training}.",2024-05-22,"Cornelius Emde, Francesco Pinto, Thomas Lukasiewicz, Philip H. S. Torr, Adel Bibi",http://arxiv.org/pdf/2405.13922v3,cs.LG
Fair Online Bilateral Trade,"In online bilateral trade, a platform posts prices to incoming pairs of
buyers and sellers that have private valuations for a certain good. If the
price is lower than the buyers' valuation and higher than the sellers'
valuation, then a trade takes place. Previous work focused on the platform
perspective, with the goal of setting prices maximizing the gain from trade
(the sum of sellers' and buyers' utilities). Gain from trade is, however,
potentially unfair to traders, as they may receive highly uneven shares of the
total utility. In this work we enforce fairness by rewarding the platform with
the fair gain from trade, defined as the minimum between sellers' and buyers'
utilities. After showing that any no-regret learning algorithm designed to
maximize the sum of the utilities may fail badly with fair gain from trade, we
present our main contribution: a complete characterization of the regret
regimes for fair gain from trade when, after each interaction, the platform
only learns whether each trader accepted the current price. Specifically, we
prove the following regret bounds: $\Theta(\ln T)$ in the deterministic
setting, $\Omega(T)$ in the stochastic setting, and $\tilde{\Theta}(T^{2/3})$
in the stochastic setting when sellers' and buyers' valuations are independent
of each other. We conclude by providing tight regret bounds when, after each
interaction, the platform is allowed to observe the true traders' valuations.",2024-05-22,"François Bachoc, Nicolò Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni",http://arxiv.org/pdf/2405.13919v1,cs.LG
HeteGraph-Mamba: Heterogeneous Graph Learning via Selective State Space Model,"We propose a heterogeneous graph mamba network (HGMN) as the first
exploration in leveraging the selective state space models (SSSMs) for
heterogeneous graph learning. Compared with the literature, our HGMN overcomes
two major challenges: (i) capturing long-range dependencies among heterogeneous
nodes and (ii) adapting SSSMs to heterogeneous graph data. Our key contribution
is a general graph architecture that can solve heterogeneous nodes in
real-world scenarios, followed an efficient flow. Methodologically, we
introduce a two-level efficient tokenization approach that first captures
long-range dependencies within identical node types, and subsequently across
all node types. Empirically, we conduct comparisons between our framework and
19 state-of-the-art methods on the heterogeneous benchmarks. The extensive
comparisons demonstrate that our framework outperforms other methods in both
the accuracy and efficiency dimensions.",2024-05-22,"Zhenyu Pan, Yoonsung Jeong, Xiaoda Liu, Han Liu",http://arxiv.org/pdf/2405.13915v1,cs.LG
Matrix Denoising with Doubly Heteroscedastic Noise: Fundamental Limits and Optimal Spectral Methods,"We study the matrix denoising problem of estimating the singular vectors of a
rank-$1$ signal corrupted by noise with both column and row correlations.
Existing works are either unable to pinpoint the exact asymptotic estimation
error or, when they do so, the resulting approaches (e.g., based on whitening
or singular value shrinkage) remain vastly suboptimal. On top of this, most of
the literature has focused on the special case of estimating the left singular
vector of the signal when the noise only possesses row correlation (one-sided
heteroscedasticity). In contrast, our work establishes the
information-theoretic and algorithmic limits of matrix denoising with doubly
heteroscedastic noise. We characterize the exact asymptotic minimum mean square
error, and design a novel spectral estimator with rigorous optimality
guarantees: under a technical condition, it attains positive correlation with
the signals whenever information-theoretically possible and, for one-sided
heteroscedasticity, it also achieves the Bayes-optimal error. Numerical
experiments demonstrate the significant advantage of our theoretically
principled method with the state of the art. The proofs draw connections with
statistical physics and approximate message passing, departing drastically from
standard random matrix theory techniques.",2024-05-22,"Yihan Zhang, Marco Mondelli",http://arxiv.org/pdf/2405.13912v2,cs.LG
A Contextual Online Learning Theory of Brokerage,"We study the role of contextual information in the online learning problem of
brokerage between traders. At each round, two traders arrive with secret
valuations about an asset they wish to trade. The broker suggests a trading
price based on contextual data about the asset. Then, the traders decide to buy
or sell depending on whether their valuations are higher or lower than the
brokerage price.
  We assume the market value of traded assets is an unknown linear function of
a $d$-dimensional vector representing the contextual information available to
the broker. Additionally, we model traders' valuations as independent bounded
zero-mean perturbations of the asset's market value, allowing for potentially
different unknown distributions across traders and time steps. Consistently
with the existing online learning literature, we evaluate the performance of a
learning algorithm with the regret with respect to the gain from trade. If the
noise distributions admit densities bounded by some constant $L$, then, for any
time horizon $T$:
  - If the agents' valuations are revealed after each interaction, we provide
an algorithm achieving $O ( L d \ln T )$ regret, and show a corresponding
matching lower bound of $\Omega( Ld \ln T )$.
  - If only their willingness to sell or buy at the proposed price is revealed
after each interaction, we provide an algorithm achieving $O(\sqrt{LdT \ln T
})$ regret, and show that this rate is optimal (up to logarithmic factors), via
a lower bound of $\Omega(\sqrt{LdT})$.
  To complete the picture, we show that if the bounded density assumption is
lifted, then the problem becomes unlearnable, even with full feedback.",2024-05-22,"François Bachoc, Tommaso Cesari, Roberto Colomboni",http://arxiv.org/pdf/2407.01566v1,cs.LG
