title,summary,published,authors,pdf_url,category
The Text Classification Pipeline: Starting Shallow going Deeper,"Text classification stands as a cornerstone within the realm of Natural
Language Processing (NLP), particularly when viewed through computer science
and engineering. The past decade has seen deep learning revolutionize text
classification, propelling advancements in text retrieval, categorization,
information extraction, and summarization. The scholarly literature includes
datasets, models, and evaluation criteria, with English being the predominant
language of focus, despite studies involving Arabic, Chinese, Hindi, and
others. The efficacy of text classification models relies heavily on their
ability to capture intricate textual relationships and non-linear correlations,
necessitating a comprehensive examination of the entire text classification
pipeline.
  In the NLP domain, a plethora of text representation techniques and model
architectures have emerged, with Large Language Models (LLMs) and Generative
Pre-trained Transformers (GPTs) at the forefront. These models are adept at
transforming extensive textual data into meaningful vector representations
encapsulating semantic information. The multidisciplinary nature of text
classification, encompassing data mining, linguistics, and information
retrieval, highlights the importance of collaborative research to advance the
field. This work integrates traditional and contemporary text mining
methodologies, fostering a holistic understanding of text classification.",2024-12-30,"Marco Siino, Ilenia Tinnirello, Marco La Cascia",http://arxiv.org/pdf/2501.00174v2,cs.CL
DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments,"Deep Learning experiments have critical requirements regarding the careful
handling of their datasets as well as the efficient and correct usage of APIs
that interact with hardware accelerators. On the one hand, software mistakes
during data handling can contaminate experiments and lead to incorrect results.
On the other hand, poorly coded APIs that interact with the hardware can lead
to sub-optimal usage and untrustworthy conclusions. In this work we investigate
the use of Linear Logic for the analysis of Deep Learning experiments. We show
that primitives and operators of Linear Logic can be used to express: (i) an
abstract representation of the control flow of an experiment, (ii) a set of
available experimental resources, such as API calls to the underlying
data-structures and hardware as well as (iii) reasoning rules about the correct
consumption of resources during experiments. Our proposed model is not only
lightweight but also easy to comprehend having both a symbolic and a visual
component. Finally, its artifacts are themselves proofs in Linear Logic that
can be readily verified by off-the-shelf reasoners.",2024-12-30,Nick Papoulias,http://arxiv.org/pdf/2501.00169v1,cs.CL
Measuring Large Language Models Capacity to Annotate Journalistic Sourcing,"Since the launch of ChatGPT in late 2022, the capacities of Large Language
Models and their evaluation have been in constant discussion and evaluation
both in academic research and in the industry. Scenarios and benchmarks have
been developed in several areas such as law, medicine and math (Bommasani et
al., 2023) and there is continuous evaluation of model variants. One area that
has not received sufficient scenario development attention is journalism, and
in particular journalistic sourcing and ethics. Journalism is a crucial
truth-determination function in democracy (Vincent, 2023), and sourcing is a
crucial pillar to all original journalistic output. Evaluating the capacities
of LLMs to annotate stories for the different signals of sourcing and how
reporters justify them is a crucial scenario that warrants a benchmark
approach. It offers potential to build automated systems to contrast more
transparent and ethically rigorous forms of journalism with everyday fare. In
this paper we lay out a scenario to evaluate LLM performance on identifying and
annotating sourcing in news stories on a five-category schema inspired from
journalism studies (Gans, 2004). We offer the use case, our dataset and metrics
and as the first step towards systematic benchmarking. Our accuracy findings
indicate LLM-based approaches have more catching to do in identifying all the
sourced statements in a story, and equally, in matching the type of sources. An
even harder task is spotting source justifications.",2024-12-30,"Subramaniam Vincent, Phoebe Wang, Zhan Shi, Sahas Koka, Yi Fang",http://arxiv.org/pdf/2501.00164v2,cs.CL
Temporal reasoning for timeline summarisation in social media,"This paper explores whether enhancing temporal reasoning capabilities in
Large Language Models (LLMs) can improve the quality of timeline summarisation,
the task of summarising long texts containing sequences of events, such as
social media threads. We first introduce NarrativeReason, a novel dataset
focused on temporal relationships among sequential events within narratives,
distinguishing it from existing temporal reasoning datasets that primarily
address pair-wise event relationships. Our approach then combines temporal
reasoning with timeline summarisation through a knowledge distillation
framework, where we first fine-tune a teacher model on temporal reasoning tasks
and then distill this knowledge into a student model while simultaneously
training it for the task of timeline summarisation. Experimental results
demonstrate that our model achieves superior performance on out-of-domain
mental health-related timeline summarisation tasks, which involve long social
media threads with repetitions of events and a mix of emotions, highlighting
the importance and generalisability of leveraging temporal reasoning to improve
timeline summarisation.",2024-12-30,"Jiayu Song, Mahmud Akhter, Dana Atzil Slonim, Maria Liakata",http://arxiv.org/pdf/2501.00152v2,cs.CL
A Data-Centric Approach to Detecting and Mitigating Demographic Bias in Pediatric Mental Health Text: A Case Study in Anxiety Detection,"Introduction: Healthcare AI models often inherit biases from their training
data. While efforts have primarily targeted bias in structured data, mental
health heavily depends on unstructured data. This study aims to detect and
mitigate linguistic differences related to non-biological differences in the
training data of AI models designed to assist in pediatric mental health
screening. Our objectives are: (1) to assess the presence of bias by evaluating
outcome parity across sex subgroups, (2) to identify bias sources through
textual distribution analysis, and (3) to develop a de-biasing method for
mental health text data. Methods: We examined classification parity across
demographic groups and assessed how gendered language influences model
predictions. A data-centric de-biasing method was applied, focusing on
neutralizing biased terms while retaining salient clinical information. This
methodology was tested on a model for automatic anxiety detection in pediatric
patients. Results: Our findings revealed a systematic under-diagnosis of female
adolescent patients, with a 4% lower accuracy and a 9% higher False Negative
Rate (FNR) compared to male patients, likely due to disparities in information
density and linguistic differences in patient notes. Notes for male patients
were on average 500 words longer, and linguistic similarity metrics indicated
distinct word distributions between genders. Implementing our de-biasing
approach reduced diagnostic bias by up to 27%, demonstrating its effectiveness
in enhancing equity across demographic groups. Discussion: We developed a
data-centric de-biasing framework to address gender-based content disparities
within clinical text. By neutralizing biased language and enhancing focus on
clinically essential information, our approach demonstrates an effective
strategy for mitigating bias in AI healthcare models trained on text.",2024-12-30,"Julia Ive, Paulina Bondaronek, Vishal Yadav, Daniel Santel, Tracy Glauser, Tina Cheng, Jeffrey R. Strawn, Greeshma Agasthya, Jordan Tschida, Sanghyun Choo, Mayanka Chandrashekar, Anuj J. Kapadia, John Pestian",http://arxiv.org/pdf/2501.00129v1,cs.CL
CaseSumm: A Large-Scale Dataset for Long-Context Summarization from U.S. Supreme Court Opinions,"This paper introduces CaseSumm, a novel dataset for long-context
summarization in the legal domain that addresses the need for longer and more
complex datasets for summarization evaluation. We collect 25.6K U.S. Supreme
Court (SCOTUS) opinions and their official summaries, known as ""syllabuses.""
Our dataset is the largest open legal case summarization dataset, and is the
first to include summaries of SCOTUS decisions dating back to 1815.
  We also present a comprehensive evaluation of LLM-generated summaries using
both automatic metrics and expert human evaluation, revealing discrepancies
between these assessment methods. Our evaluation shows Mistral 7b, a smaller
open-source model, outperforms larger models on most automatic metrics and
successfully generates syllabus-like summaries. In contrast, human expert
annotators indicate that Mistral summaries contain hallucinations. The
annotators consistently rank GPT-4 summaries as clearer and exhibiting greater
sensitivity and specificity. Further, we find that LLM-based evaluations are
not more correlated with human evaluations than traditional automatic metrics.
Furthermore, our analysis identifies specific hallucinations in generated
summaries, including precedent citation errors and misrepresentations of case
facts. These findings demonstrate the limitations of current automatic
evaluation methods for legal summarization and highlight the critical role of
human evaluation in assessing summary quality, particularly in complex,
high-stakes domains.
  CaseSumm is available at https://huggingface.co/datasets/ChicagoHAI/CaseSumm",2024-12-30,"Mourad Heddaya, Kyle MacMillan, Anup Malani, Hongyuan Mei, Chenhao Tan",http://arxiv.org/pdf/2501.00097v1,cs.CL
Distributed Mixture-of-Agents for Edge Inference with Large Language Models,"Mixture-of-Agents (MoA) has recently been proposed as a method to enhance
performance of large language models (LLMs), enabling multiple individual LLMs
to work together for collaborative inference. This collaborative approach
results in improved responses to user prompts compared to relying on a single
LLM. In this paper, we consider such an MoA architecture in a distributed
setting, where LLMs operate on individual edge devices, each uniquely
associated with a user and equipped with its own distributed computing power.
These devices exchange information using decentralized gossip algorithms,
allowing different device nodes to talk without the supervision of a
centralized server. In the considered setup, different users have their own LLM
models to address user prompts. Additionally, the devices gossip either their
own user-specific prompts or augmented prompts to generate more refined answers
to certain queries. User prompts are temporarily stored in the device queues
when their corresponding LLMs are busy. Given the memory limitations of edge
devices, it is crucial to ensure that the average queue sizes in the system
remain bounded. In this paper, we address this by theoretically calculating the
queuing stability conditions for the device queues under reasonable
assumptions, which we validate experimentally as well. Further, we demonstrate
through experiments, leveraging open-source LLMs for the implementation of
distributed MoA, that certain MoA configurations produce higher-quality
responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The
implementation is available at:
https://github.com/purbeshmitra/distributed_moa.",2024-12-30,"Purbesh Mitra, Priyanka Kaswan, Sennur Ulukus",http://arxiv.org/pdf/2412.21200v1,cs.CL
HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation,"We introduce self-invoking code generation, a new task designed to evaluate
the progressive reasoning and problem-solving capabilities of LLMs. In this
task, models are presented with a base problem and a related, more complex
problem. They must solve the base problem and then utilize its solution to
address the more complex one. This work features three key contributions.
First, we propose a general recipe for generating more challenging versions of
existing benchmarks, resulting in three new benchmarks: HumanEval Pro, MBPP
Pro, and BigCodeBench-Lite Pro, specifically designed to assess LLMs on
self-invoking code generation. Second, from the analysis of experimental
results over twenty LLMs on our benchmarks, we have two important observations:
(i) Most LLMs excel in traditional code generation benchmarks like HumanEval
and MBPP, but their performance declines on self-invoking tasks. For example,
o1-mini achieves 96.2% pass@1 on HumanEval but only 76.2% on HumanEval Pro.
(ii) On self-invoking code generation task, the instruction-tuned models
demonstrate only marginal improvements compared to the base models. Third, we
disclose the types of failure modes that exist in our evaluation results. All
these results underscore the need for further advancements in self-invoking
code generation tasks and provide a new direction for future research on
enhancing LLMs' code reasoning capabilities.",2024-12-30,"Zhaojian Yu, Yilun Zhao, Arman Cohan, Xiao-Ping Zhang",http://arxiv.org/pdf/2412.21199v2,cs.CL
Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs,"The remarkable performance of models like the OpenAI o1 can be attributed to
their ability to emulate human-like long-time thinking during inference. These
models employ extended chain-of-thought (CoT) processes, exploring multiple
strategies to enhance problem-solving capabilities. However, a critical
question remains: How to intelligently and efficiently scale computational
resources during testing. This paper presents the first comprehensive study on
the prevalent issue of overthinking in these models, where excessive
computational resources are allocated for simple problems with minimal benefit.
We introduce novel efficiency metrics from both outcome and process
perspectives to evaluate the rational use of computational resources by o1-like
models. Using a self-training paradigm, we propose strategies to mitigate
overthinking, streamlining reasoning processes without compromising accuracy.
Experimental results show that our approach successfully reduces computational
overhead while preserving model performance across a range of testsets with
varying difficulty levels, such as GSM8K, MATH500, GPQA, and AIME.",2024-12-30,"Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu",http://arxiv.org/pdf/2412.21187v2,cs.CL
Two-component spatiotemporal template for activation-inhibition of speech in ECoG,"I compute the average trial-by-trial power of band-limited speech activity
across epochs of multi-channel high-density electrocorticography (ECoG)
recorded from multiple subjects during a consonant-vowel speaking task. I show
that previously seen anti-correlations of average beta frequency activity
(12-35 Hz) to high-frequency gamma activity (70-140 Hz) during speech movement
are observable between individual ECoG channels in the sensorimotor cortex
(SMC). With this I fit a variance-based model using principal component
analysis to the band-powers of individual channels of session-averaged ECoG
data in the SMC and project SMC channels onto their lower-dimensional principal
components.
  Spatiotemporal relationships between speech-related activity and principal
components are identified by correlating the principal components of both
frequency bands to individual ECoG channels over time using windowed
correlation. Correlations of principal component areas to sensorimotor areas
reveal a distinct two-component activation-inhibition-like representation for
speech that resembles distinct local sensorimotor areas recently shown to have
complex interplay in whole-body motor control, inhibition, and posture. Notably
the third principal component shows insignificant correlations across all
subjects, suggesting two components of ECoG are sufficient to represent SMC
activity during speech movement.",2024-12-30,Eric Easthope,http://arxiv.org/pdf/2412.21178v1,cs.CL
Aviary: training language agents on challenging scientific tasks,"Solving complex real-world tasks requires cycles of actions and observations.
This is particularly true in science, where tasks require many cycles of
analysis, tool use, and experimentation. Language agents are promising for
automating intellectual tasks in science because they can interact with tools
via natural language or code. Yet their flexibility creates conceptual and
practical challenges for software implementations, since agents may comprise
non-standard components such as internal reasoning, planning, tool usage, as
well as the inherent stochasticity of temperature-sampled language models.
Here, we introduce Aviary, an extensible gymnasium for language agents. We
formalize agents as policies solving language-grounded partially observable
Markov decision processes, which we term language decision processes. We then
implement five environments, including three challenging scientific
environments: (1) manipulating DNA constructs for molecular cloning, (2)
answering research questions by accessing scientific literature, and (3)
engineering protein stability. These environments were selected for their focus
on multi-step reasoning and their relevance to contemporary biology research.
Finally, with online training and scaling inference-time compute, we show that
language agents backed by open-source, non-frontier LLMs can match and exceed
both frontier LLM agents and human experts on multiple tasks at up to 100x
lower inference cost.",2024-12-30,"Siddharth Narayanan, James D. Braza, Ryan-Rhys Griffiths, Manu Ponnapati, Albert Bou, Jon Laurent, Ori Kabeli, Geemi Wellawatte, Sam Cox, Samuel G. Rodriques, Andrew D. White",http://arxiv.org/pdf/2412.21154v1,cs.CL
Facilitating large language model Russian adaptation with Learned Embedding Propagation,"Rapid advancements of large language model (LLM) technologies led to the
introduction of powerful open-source instruction-tuned LLMs that have the same
text generation quality as the state-of-the-art counterparts such as GPT-4.
While the emergence of such models accelerates the adoption of LLM technologies
in sensitive-information environments the authors of such models don not
disclose the training data necessary for replication of the results thus making
the achievements model-exclusive. Since those open-source models are also
multilingual this in turn reduces the benefits of training a language specific
LLMs as improved inference computation efficiency becomes the only guaranteed
advantage of such costly procedure. More cost-efficient options such as
vocabulary extension and subsequent continued pre-training are also inhibited
by the lack of access to high-quality instruction-tuning data since it is the
major factor behind the resulting LLM task-solving capabilities. To address the
limitations and cut the costs of the language adaptation pipeline we propose
Learned Embedding Propagation (LEP). Unlike existing approaches our method has
lower training data size requirements due to minimal impact on existing LLM
knowledge which we reinforce using novel ad-hoc embedding propagation procedure
that allows to skip the instruction-tuning step and instead implant the new
language knowledge directly into any existing instruct-tuned variant. We
evaluated four Russian vocabulary adaptations for LLaMa-3-8B and Mistral-7B,
showing that LEP is competitive with traditional instruction-tuning methods,
achieving performance comparable to OpenChat 3.5 and LLaMa-3-8B-Instruct, with
further improvements via self-calibration and continued tuning enhancing
task-solving capabilities.",2024-12-30,"Mikhail Tikhomirov, Daniil Chernyshev",http://arxiv.org/pdf/2412.21140v1,cs.CL
Training Software Engineering Agents and Verifiers with SWE-Gym,"We present SWE-Gym, the first environment for training real-world software
engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task
instances, each comprising a codebase with an executable runtime environment,
unit tests, and a task specified in natural language. We use SWE-Gym to train
language model based SWE agents , achieving up to 19% absolute gains in resolve
rate on the popular SWE-Bench Verified and Lite test sets. We also experiment
with inference-time scaling through verifiers trained on agent trajectories
sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve
32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new
state-of-the-art for open-weight SWE agents. To facilitate further research, we
publicly release SWE-Gym, models, and agent trajectories.",2024-12-30,"Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang",http://arxiv.org/pdf/2412.21139v1,cs.CL
Exploring and Controlling Diversity in LLM-Agent Conversation,"Controlling diversity in LLM-agent world simulations is essential for
maintaining stability in structured tasks while enabling variation where
creativity is needed. However, we observe that dialogue diversity declines
significantly over long-term simulation. To investigate the role of prompt
design in conversational diversity, we modularized the utterance generation
prompt and found that reducing the given information leads to more diverse
outputs. Based on this insight, we propose Adaptive Prompt Pruning (APP), a
novel method that allows users to control diversity through a single parameter,
lambda. APP dynamically prunes the utterance generation prompt based on their
attention weights and is compatible with traditional diversity control
techniques. We demonstrate that APP effectively controls output diversity
through extensive experiments, and propose a method to balance the control
trade-offs. Additionally, we provide an in-depth analysis to offer insights
into optimizing diversity control in multi-agent simulation.",2024-12-30,"KuanChao Chu, Yi-Pei Chen, Hideki Nakayama",http://arxiv.org/pdf/2412.21102v2,cs.CL
Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight Task-Specific Adapters for Automatic Scoring,"The integration of Artificial Intelligence (AI) in education requires
scalable and efficient frameworks that balance performance, adaptability, and
cost. This paper addresses these needs by proposing a shared backbone model
architecture enhanced with lightweight LoRA adapters for task-specific
fine-tuning, targeting the automated scoring of student responses across 27
mutually exclusive tasks. By achieving competitive performance (average QWK of
0.848 compared to 0.888 for fully fine-tuned models) while reducing GPU memory
consumption by 60% and inference latency by 40%, the framework demonstrates
significant efficiency gains. This approach aligns with the workshops' focus on
improving language models for educational tasks, creating responsible
innovations for cost-sensitive deployment, and supporting educators by
streamlining assessment workflows. The findings underscore the potential of
scalable AI to enhance learning outcomes while maintaining fairness and
transparency in automated scoring systems.",2024-12-30,"Ehsan Latif, Xiaoming Zhai",http://arxiv.org/pdf/2412.21065v1,cs.CL
TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization,"We introduce TangoFlux, an efficient Text-to-Audio (TTA) generative model
with 515M parameters, capable of generating up to 30 seconds of 44.1kHz audio
in just 3.7 seconds on a single A40 GPU. A key challenge in aligning TTA models
lies in the difficulty of creating preference pairs, as TTA lacks structured
mechanisms like verifiable rewards or gold-standard answers available for Large
Language Models (LLMs). To address this, we propose CLAP-Ranked Preference
Optimization (CRPO), a novel framework that iteratively generates and optimizes
preference data to enhance TTA alignment. We demonstrate that the audio
preference dataset generated using CRPO outperforms existing alternatives. With
this framework, TangoFlux achieves state-of-the-art performance across both
objective and subjective benchmarks. We open source all code and models to
support further research in TTA generation.",2024-12-30,"Chia-Yu Hung, Navonil Majumder, Zhifeng Kong, Ambuj Mehrish, Amir Ali Bagherzadeh, Chuan Li, Rafael Valle, Bryan Catanzaro, Soujanya Poria",http://arxiv.org/pdf/2412.21037v2,cs.CL
GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models,"Multimodal large language models (MLLMs) have made significant progress in
integrating visual and linguistic understanding. Existing benchmarks typically
focus on high-level semantic capabilities, such as scene understanding and
visual reasoning, but often overlook a crucial, foundational ability: geometric
perception. Geometric perception involves understanding geometric shapes,
structures, and spatial relationships, which are essential for supporting
higher-level semantic tasks. Despite its importance, this capability remains
underexplored in current MLLM research. To address this gap, we introduce
GePBench, a novel benchmark designed to assess the geometric perception
abilities of MLLMs. Our extensive evaluations reveal that current
state-of-the-art MLLMs exhibit significant deficiencies in geometric perception
tasks. Furthermore, we show that models trained with GePBench data demonstrate
substantial improvements on a wide range of benchmark tasks, highlighting the
critical role of geometric perception in enabling advanced multimodal
applications. Our code and datasets will be publicly available.",2024-12-30,"Shangyu Xing, Changhao Xiang, Yuteng Han, Yifan Yue, Zhen Wu, Xinyu Liu, Zhangtai Wu, Fei Zhao, Xinyu Dai",http://arxiv.org/pdf/2412.21036v2,cs.CL
Plancraft: an evaluation dataset for planning with LLM agents,"We present Plancraft, a multi-modal evaluation dataset for LLM agents.
Plancraft has both a text-only and multi-modal interface, based on the
Minecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and
Retrieval Augmented Generation (RAG), as well as an oracle planner and oracle
RAG information extractor, to ablate the different components of a modern agent
architecture. To evaluate decision-making, Plancraft also includes a subset of
examples that are intentionally unsolvable, providing a realistic challenge
that requires the agent not only to complete tasks but also to decide whether
they are solvable at all. We benchmark both open-source and closed-source LLMs
and strategies on our task and compare their performance to a handcrafted
planner. We find that LLMs and VLMs struggle with the planning problems that
Plancraft introduces, and we offer suggestions on how to improve their
capabilities.",2024-12-30,"Gautier Dagan, Frank Keller, Alex Lascarides",http://arxiv.org/pdf/2412.21033v1,cs.CL
MapQaTor: A System for Efficient Annotation of Map Query Datasets,"Mapping and navigation services like Google Maps, Apple Maps, Openstreet
Maps, are essential for accessing various location-based data, yet they often
struggle to handle natural language geospatial queries. Recent advancements in
Large Language Models (LLMs) show promise in question answering (QA), but
creating reliable geospatial QA datasets from map services remains challenging.
We introduce MapQaTor, a web application that streamlines the creation of
reproducible, traceable map-based QA datasets. With its plug-and-play
architecture, MapQaTor enables seamless integration with any maps API, allowing
users to gather and visualize data from diverse sources with minimal setup. By
caching API responses, the platform ensures consistent ground truth, enhancing
the reliability of the data even as real-world information evolves. MapQaTor
centralizes data retrieval, annotation, and visualization within a single
platform, offering a unique opportunity to evaluate the current state of
LLM-based geospatial reasoning while advancing their capabilities for improved
geospatial understanding. Evaluation metrics show that, MapQaTor speeds up the
annotation process by at least 30 times compared to manual methods,
underscoring its potential for developing geospatial resources, such as complex
map reasoning datasets. The website is live at: https://mapqator.github.io/ and
a demo video is available at: https://youtu.be/7_aV9Wmhs6Q.",2024-12-30,"Mahir Labib Dihan, Mohammed Eunus Ali, Md Rizwan Parvez",http://arxiv.org/pdf/2412.21015v1,cs.CL
Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria,"Large Language Models (LLMs) rely on generating extensive intermediate
reasoning units (e.g., tokens, sentences) to enhance final answer quality
across a wide range of complex tasks. While generating multiple reasoning paths
or iteratively refining rationales proves effective for improving performance,
these approaches inevitably result in significantly higher inference costs. In
this work, we propose a novel sentence-level rationale reduction training
framework that leverages likelihood-based criteria, verbosity, to identify and
remove redundant reasoning sentences. Unlike previous approaches that utilize
token-level reduction, our sentence-level reduction framework maintains model
performance while reducing generation length. This preserves the original
reasoning abilities of LLMs and achieves an average 17.15% reduction in
generation costs across various models and tasks.",2024-12-30,"Joonwon Jang, Jaehee Kim, Wonbin Kweon, Hwanjo Yu",http://arxiv.org/pdf/2412.21006v2,cs.CL
Plug-and-Play Training Framework for Preference Optimization,"Recently, preference optimization methods such as DPO have significantly
enhanced large language models (LLMs) in wide tasks including dialogue and
question-answering. However, current methods fail to account for the varying
difficulty levels of training samples during preference optimization, leading
to mediocre performance in tasks with high accuracy requirements, particularly
in mathematical reasoning. To address this limitation, we propose a novel
training framework, which employs multiple sampling to analyze output
distributions, assign different weights to samples, and incorporate these
weights into the preference optimization process. This plug-and-play approach
enables LLMs to prioritize challenging examples during training, improving
learning efficiency. Experimental results demonstrate that our framework
integrates seamlessly with various preference optimization methods and achieves
consistent improvements in mathematical reasoning tasks.",2024-12-30,"Jingyuan Ma, Rui Li, Zheng Li, Lei Sha, Zhifang Sui",http://arxiv.org/pdf/2412.20996v1,cs.CL
KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation,"Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.",2024-12-30,"Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang",http://arxiv.org/pdf/2412.20995v1,cs.CL
Efficiently Serving LLM Reasoning Programs with Certaindex,"The rapid evolution of large language models (LLMs) has unlocked their
capabilities in advanced reasoning tasks like mathematical problem-solving,
code generation, and legal analysis. Central to this progress are
inference-time reasoning algorithms, which refine outputs by exploring multiple
solution paths, at the cost of increasing compute demands and response
latencies. Existing serving systems fail to adapt to the scaling behaviors of
these algorithms or the varying difficulty of queries, leading to inefficient
resource use and unmet latency targets.
  We present Dynasor, a system that optimizes inference-time compute for LLM
reasoning queries. Unlike traditional engines, Dynasor tracks and schedules
requests within reasoning queries and uses Certaindex, a proxy that measures
statistical reasoning progress based on model certainty, to guide compute
allocation dynamically. Dynasor co-adapts scheduling with reasoning progress:
it allocates more compute to hard queries, reduces compute for simpler ones,
and terminates unpromising queries early, balancing accuracy, latency, and
cost. On diverse datasets and algorithms, Dynasor reduces compute by up to 50%
in batch processing and sustaining 3.3x higher query rates or 4.7x tighter
latency SLOs in online serving.",2024-12-30,"Yichao Fu, Junda Chen, Siqi Zhu, Zheyu Fu, Zhongdongming Dai, Aurick Qiao, Hao Zhang",http://arxiv.org/pdf/2412.20993v1,cs.CL
GASLITEing the Retrieval: Exploring Vulnerabilities in Dense Embedding-based Search,"Dense embedding-based text retrieval$\unicode{x2013}$retrieval of relevant
passages from corpora via deep learning encodings$\unicode{x2013}$has emerged
as a powerful method attaining state-of-the-art search results and popularizing
the use of Retrieval Augmented Generation (RAG). Still, like other search
methods, embedding-based retrieval may be susceptible to search-engine
optimization (SEO) attacks, where adversaries promote malicious content by
introducing adversarial passages to corpora. To faithfully assess and gain
insights into the susceptibility of such systems to SEO, this work proposes the
GASLITE attack, a mathematically principled gradient-based search method for
generating adversarial passages without relying on the corpus content or
modifying the model. Notably, GASLITE's passages (1) carry adversary-chosen
information while (2) achieving high retrieval ranking for a selected query
distribution when inserted to corpora. We use GASLITE to extensively evaluate
retrievers' robustness, testing nine advanced models under varied threat
models, while focusing on realistic adversaries targeting queries on a specific
concept (e.g., a public figure). We found GASLITE consistently outperformed
baselines by $\geq$140% success rate, in all settings. Particularly,
adversaries using GASLITE require minimal effort to manipulate search
results$\unicode{x2013}$by injecting a negligible amount of adversarial
passages ($\leq$0.0001% of the corpus), they could make them visible in the
top-10 results for 61-100% of unseen concept-specific queries against most
evaluated models. Inspecting variance in retrievers' robustness, we identify
key factors that may contribute to models' susceptibility to SEO, including
specific properties in the embedding space's geometry.",2024-12-30,"Matan Ben-Tov, Mahmood Sharif",http://arxiv.org/pdf/2412.20953v1,cs.CL
Enhancing AI Safety Through the Fusion of Low Rank Adapters,"Instruction fine-tuning of large language models (LLMs) is a powerful method
for improving task-specific performance, but it can inadvertently lead to a
phenomenon where models generate harmful responses when faced with malicious
prompts. In this paper, we explore Low-Rank Adapter Fusion (LoRA) as a means to
mitigate these risks while preserving the model's ability to handle diverse
instructions effectively. Through an extensive comparative analysis against
established baselines using recognized benchmark datasets, we demonstrate a
42\% reduction in the harmfulness rate by leveraging LoRA fusion between a task
adapter and a safety adapter, the latter of which is specifically trained on
our safety dataset. However, we also observe exaggerated safety behaviour,
where the model rejects safe prompts that closely resemble unsafe ones",2024-12-30,"Satya Swaroop Gudipudi, Sreeram Vipparla, Harpreet Singh, Shashwat Goel, Ponnurangam Kumaraguru",http://arxiv.org/pdf/2501.06208v1,cs.CL
DoTA: Weight-Decomposed Tensor Adaptation for Large Language Models,"Low-rank adaptation (LoRA) reduces the computational and memory demands of
fine-tuning large language models (LLMs) by approximating updates with low-rank
matrices. However, low-rank approximation in two-dimensional space fails to
capture high-dimensional structures within the target matrix. Recently, tensor
decomposition methods have been explored for fine-tuning LLMs, leveraging their
ability to extract structured information. Yet, these approaches primarily rely
on random initialization, and the impact of initialization on tensor adaptation
remains underexplored. In this paper, we reveal that random initialization
significantly diverges from the validation loss achieved by full fine-tuning.
To address this, we propose Weight-Decomposed Tensor Adaptation (DoTA), which
leverages the Matrix Product Operator (MPO) decomposition of pre-trained
weights for effective initialization in fine-tuning LLMs. Additionally, we
introduce QDoTA, a quantized version of DoTA designed for 4-bit quantization.
Experiments on commonsense and arithmetic reasoning tasks show that DoTA
outperforms random initialization methods with fewer parameters. QDoTA further
reduces memory consumption and achieves comparable performance to DoTA on
commonsense reasoning tasks. We will release our code to support future
research.",2024-12-30,"Xiaolin Hu, Xiang Cheng, Peiyu Liu, Wei Liu, Jian Luan, Bin Wang, Yong Liu",http://arxiv.org/pdf/2412.20891v1,cs.CL
Enhancing Annotated Bibliography Generation with LLM Ensembles,"This work proposes a novel approach to enhancing annotated bibliography
generation through Large Language Model (LLM) ensembles. In particular,
multiple LLMs in different roles -- controllable text generation, evaluation,
and summarization -- are introduced and validated using a systematic
methodology to enhance model performance in scholarly tasks. Output diversity
among the ensemble that generates text is obtained using different LLM
parameters, followed by an LLM acting as a judge to assess relevance, accuracy,
and coherence. Responses selected by several combining strategies are then
merged and refined through summarization and redundancy removal techniques. The
preliminary experimental validation demonstrates that the combined outputs from
the LLM ensemble improve coherence and relevance compared to individual
responses, leading to a 38% improvement in annotation quality and a 51%
reduction in content redundancy, thus highlighting the potential for automating
complex scholarly tasks while maintaining high-quality standards.",2024-12-30,Sergio Bermejo,http://arxiv.org/pdf/2412.20864v1,cs.CL
Are LLMs Really Not Knowledgable? Mining the Submerged Knowledge in LLMs' Memory,"Large language models (LLMs) have shown promise as potential knowledge bases,
yet they often struggle with question-answering tasks and are prone to
hallucinations. While previous research attributes these issues to knowledge
gaps in the model's parameters, our investigation reveals a different
phenomenon: LLMs often retain correct knowledge even when generating incorrect
answers. Through analysis of model's internal representations, we find that
correct answers frequently appear among high-probability tokens despite not
being selected as final outputs. Based on this observation, we introduce
Hits@k, a new metric to assess knowledge retention independent of expression
accuracy. Our extensive experiments demonstrate that LLMs store significantly
more knowledge than their QA performance suggests. Building on these findings,
we develop SkipUnsure, a method to improve answer accuracy by leveraging
detected but unexpressed knowledge. Experiments on both open-domain and
specific-domain datasets show consistent improvements, with accuracy gains of
up to 11.8% on DBPedia and 6.3% on IMDB, without requiring model retraining.",2024-12-30,"Xingjian Tao, Yiwei Wang, Yujun Cai, Zhicheng Yang, Jing Tang",http://arxiv.org/pdf/2412.20846v1,cs.CL
Disentangling Preference Representation and Text Generation for Efficient Individual Preference Alignment,"Aligning Large Language Models (LLMs) with general human preferences has been
proved crucial in improving the interaction quality between LLMs and human.
However, human values are inherently diverse among different individuals,
making it insufficient to align LLMs solely with general preferences. To
address this, personalizing LLMs according to individual feedback emerges as a
promising solution. Nonetheless, this approach presents challenges in terms of
the efficiency of alignment algorithms. In this work, we introduce a flexible
paradigm for individual preference alignment. Our method fundamentally improves
efficiency by disentangling preference representation from text generation in
LLMs. We validate our approach across multiple text generation tasks and
demonstrate that it can produce aligned quality as well as or better than
PEFT-based methods, while reducing additional training time for each new
individual preference by $80\%$ to $90\%$ in comparison with them.",2024-12-30,"Jianfei Zhang, Jun Bai, Bei Li, Yanmeng Wang, Rumei Li, Chenghua Lin, Wenge Rong",http://arxiv.org/pdf/2412.20834v1,cs.CL
Enhancing Multimodal Emotion Recognition through Multi-Granularity Cross-Modal Alignment,"Multimodal emotion recognition (MER), leveraging speech and text, has emerged
as a pivotal domain within human-computer interaction, demanding sophisticated
methods for effective multimodal integration. The challenge of aligning
features across these modalities is significant, with most existing approaches
adopting a singular alignment strategy. Such a narrow focus not only limits
model performance but also fails to address the complexity and ambiguity
inherent in emotional expressions. In response, this paper introduces a
Multi-Granularity Cross-Modal Alignment (MGCMA) framework, distinguished by its
comprehensive approach encompassing distribution-based, instance-based, and
token-based alignment modules. This framework enables a multi-level perception
of emotional information across modalities. Our experiments on IEMOCAP
demonstrate that our proposed method outperforms current state-of-the-art
techniques.",2024-12-30,"Xuechen Wang, Shiwan Zhao, Haoqin Sun, Hui Wang, Jiaming Zhou, Yong Qin",http://arxiv.org/pdf/2412.20821v1,cs.CL
ACL-rlg: A Dataset for Reading List Generation,"Familiarizing oneself with a new scientific field and its existing literature
can be daunting due to the large amount of available articles. Curated lists of
academic references, or reading lists, compiled by experts, offer a structured
way to gain a comprehensive overview of a domain or a specific scientific
challenge. In this work, we introduce ACL-rlg, the largest open
expert-annotated reading list dataset. We also provide multiple baselines for
evaluating reading list generation and formally define it as a retrieval task.
Our qualitative study highlights the fact that traditional scholarly search
engines and indexing methods perform poorly on this task, and GPT-4o, despite
showing better results, exhibits signs of potential data contamination.",2024-12-30,"Julien Aubert-Béduchaud, Florian Boudin, Béatrice Daille, Richard Dufour",http://arxiv.org/pdf/2502.15692v1,cs.CL
Attributing Culture-Conditioned Generations to Pretraining Corpora,"In open-ended generative tasks like narrative writing or dialogue, large
language models often exhibit cultural biases, showing limited knowledge and
generating templated outputs for less prevalent cultures. Recent works show
that these biases may stem from uneven cultural representation in pretraining
corpora. This work investigates how pretraining leads to biased
culture-conditioned generations by analyzing how models associate entities with
cultures based on pretraining data patterns. We propose the MEMOed framework
(MEMOrization from pretraining document) to determine whether a generation for
a culture arises from memorization. Using MEMOed on culture-conditioned
generations about food and clothing for 110 cultures, we find that
high-frequency cultures in pretraining data yield more generations with
memorized symbols, while some low-frequency cultures produce none.
Additionally, the model favors generating entities with extraordinarily high
frequency regardless of the conditioned culture, reflecting biases toward
frequent pretraining terms irrespective of relevance. We hope that the MEMOed
framework and our insights will inspire more works on attributing model
performance on pretraining data.",2024-12-30,"Huihan Li, Arnav Goel, Keyu He, Xiang Ren",http://arxiv.org/pdf/2412.20760v2,cs.CL
Depression and Anxiety Prediction Using Deep Language Models and Transfer Learning,"Digital screening and monitoring applications can aid providers in the
management of behavioral health conditions. We explore deep language models for
detecting depression, anxiety, and their co-occurrence from conversational
speech collected during 16k user interactions with an application. Labels come
from PHQ-8 and GAD-7 results also collected by the application. We find that
results for binary classification range from 0.86 to 0.79 AUC, depending on
condition and co-occurrence. Best performance is achieved when a user has
either both or neither condition, and we show that this result is not
attributable to data skew. Finally, we find evidence suggesting that underlying
word sequence cues may be more salient for depression than for anxiety.",2024-12-30,"Tomasz Rutowski, Elizabeth Shriberg, Amir Harati, Yang Lu, Piotr Chlebek, Ricardo Oliveira",http://arxiv.org/pdf/2412.20741v1,cs.CL
HunyuanProver: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving,"We introduce HunyuanProver, an language model finetuned from the Hunyuan 7B
for interactive automatic theorem proving with LEAN4. To alleviate the data
sparsity issue, we design a scalable framework to iterative synthesize data
with low cost. Besides, guided tree search algorithms are designed to enable
effective ``system 2 thinking`` of the prover. HunyuanProver achieves
state-of-the-art (SOTA) performances on major benchmarks. Specifically, it
achieves a pass of 68.4% on the miniF2F-test compared to 65.9%, the current
SOTA results. It proves 4 IMO statements (imo_1960_p2, imo_1962_p2},
imo_1964_p2 and imo_1983_p6) in miniF2F-test. To benefit the community, we will
open-source a dataset of 30k synthesized instances, where each instance
contains the original question in natural language, the converted statement by
autoformalization, and the proof by HunyuanProver.",2024-12-30,"Yang Li, Dong Du, Linfeng Song, Chen Li, Weikang Wang, Tao Yang, Haitao Mi",http://arxiv.org/pdf/2412.20735v3,cs.CL
ChartAdapter: Large Vision-Language Model for Chart Summarization,"Chart summarization, which focuses on extracting key information from charts
and interpreting it in natural language, is crucial for generating and
delivering insights through effective and accessible data analysis. Traditional
methods for chart understanding and summarization often rely on multi-stage
pipelines, which may produce suboptimal semantic alignment between visual and
textual information. In comparison, recently developed LLM-based methods are
more dependent on the capability of foundation images or languages, while
ignoring the characteristics of chart data and its relevant challenges. To
address these limitations, we propose ChartAdapter, a novel lightweight
transformer module designed to bridge the gap between charts and textual
summaries. ChartAdapter employs learnable query vectors to extract implicit
semantics from chart data and incorporates a cross-modal alignment projector to
enhance vision-to-language generative learning. By integrating ChartAdapter
with an LLM, we enable end-to-end training and efficient chart summarization.
To further enhance the training, we introduce a three-stage hierarchical
training procedure and develop a large-scale dataset specifically curated for
chart summarization, comprising 190,618 samples. Experimental results on the
standard Chart-to-Text testing set demonstrate that our approach significantly
outperforms existing methods, including state-of-the-art models, in generating
high-quality chart summaries. Ablation studies further validate the
effectiveness of key components in ChartAdapter. This work highlights the
potential of tailored LLM-based approaches to advance chart understanding and
sets a strong foundation for future research in this area.",2024-12-30,"Peixin Xu, Yujuan Ding, Wenqi Fan",http://arxiv.org/pdf/2412.20715v1,cs.CL
QUBE: Enhancing Automatic Heuristic Design via Quality-Uncertainty Balanced Evolution,"Solving NP-hard problems traditionally relies on heuristics, yet manually
designing effective heuristics for complex problems remains a significant
challenge. While recent advancements like FunSearch have shown that large
language models (LLMs) can be integrated into evolutionary algorithms (EAs) for
heuristic design, their potential is hindered by limitations in balancing
exploitation and exploration. We introduce Quality-Uncertainty Balanced
Evolution (QUBE), a novel approach that enhances LLM+EA methods by redefining
the priority criterion within the FunSearch framework. QUBE employs the
Quality-Uncertainty Trade-off Criterion (QUTC), based on our proposed
Uncertainty-Inclusive Quality metric, to evaluate and guide the evolutionary
process. Through extensive experiments on challenging NP-complete problems,
QUBE demonstrates significant performance improvements over FunSearch and
baseline methods. Our code are available at
https://github.com/zzjchen/QUBE_code.",2024-12-30,"Zijie Chen, Zhanchao Zhou, Yu Lu, Renjun Xu, Lili Pan, Zhenzhong Lan",http://arxiv.org/pdf/2412.20694v4,cs.CL
Position Information Emerges in Causal Transformers Without Positional Encodings via Similarity of Nearby Embeddings,"Transformers with causal attention can solve tasks that require positional
information without using positional encodings. In this work, we propose and
investigate a new hypothesis about how positional information can be stored
without using explicit positional encoding. We observe that nearby embeddings
are more similar to each other than faraway embeddings, allowing the
transformer to potentially reconstruct the positions of tokens. We show that
this pattern can occur in both the trained and the randomly initialized
Transformer models with causal attention and no positional encodings over a
common range of hyperparameters.",2024-12-30,"Chunsheng Zuo, Pavel Guerzhoy, Michael Guerzhoy",http://arxiv.org/pdf/2501.00073v1,cs.CL
Align Attention Heads Before Merging Them: An Effective Way for Converting MHA to GQA,"Large language models have been shown to perform well on a variety of natural
language processing problems. However, as the model size and the input
sequence's length increase, the rapid increase of KV Cache significantly slows
down inference speed. Therefore GQA model, as an alternative to MHA model, has
been widely introduced into LLMs. In this work, we propose a low-cost method
for pruning MHA models into GQA models with any compression ratio of key-value
heads. Our method is based on $\mathit{L_0}$ masks to gradually remove
redundant parameters. In addition, we apply orthogonal transformations to
attention heads without changing the model to increase similarity between
attention heads before pruning training, in order to further improve
performance of the model. Our method can be compatible with rotary position
embedding (RoPE), which means the model after training can be fully adapted to
the mainstream standard GQA framework. Experiments demonstrate that our
strategy can compress up to 87.5% of key-value heads of the LLaMA2-7B model
without too much performance degradation, just achieved through supervised
fine-tuning.",2024-12-30,"Qingyun Jin, Xiaohui Song, Feng Zhou, Zengchang Qin",http://arxiv.org/pdf/2412.20677v1,cs.CL
Knowledge Editing for Large Language Model with Knowledge Neuronal Ensemble,"As real-world knowledge is constantly evolving, ensuring the timeliness and
accuracy of a model's knowledge is crucial. This has made knowledge editing in
large language models increasingly important. However, existing knowledge
editing methods face several challenges, including parameter localization
coupling, imprecise localization, and a lack of dynamic interaction across
layers. In this paper, we propose a novel knowledge editing method called
Knowledge Neuronal Ensemble (KNE). A knowledge neuronal ensemble represents a
group of neurons encoding specific knowledge, thus mitigating the issue of
frequent parameter modification caused by coupling in parameter localization.
The KNE method enhances the precision and accuracy of parameter localization by
computing gradient attribution scores for each parameter at each layer. During
the editing process, only the gradients and losses associated with the
knowledge neuronal ensemble are computed, with error backpropagation performed
accordingly, ensuring dynamic interaction and collaborative updates among
parameters. Experimental results on three widely used knowledge editing
datasets show that the KNE method significantly improves the accuracy of
knowledge editing and achieves, or even exceeds, the performance of the best
baseline methods in portability and locality metrics.",2024-12-30,"Yongchang Li, Yujin Zhu, Tao Yan, Shijian Fan, Gang Wu, Liang Xu",http://arxiv.org/pdf/2412.20637v1,cs.CL
NLP-based Regulatory Compliance -- Using GPT 4.0 to Decode Regulatory Documents,"Large Language Models (LLMs) such as GPT-4.0 have shown significant promise
in addressing the semantic complexities of regulatory documents, particularly
in detecting inconsistencies and contradictions. This study evaluates GPT-4.0's
ability to identify conflicts within regulatory requirements by analyzing a
curated corpus with artificially injected ambiguities and contradictions,
designed in collaboration with architects and compliance engineers. Using
metrics such as precision, recall, and F1 score, the experiment demonstrates
GPT-4.0's effectiveness in detecting inconsistencies, with findings validated
by human experts. The results highlight the potential of LLMs to enhance
regulatory compliance processes, though further testing with larger datasets
and domain-specific fine-tuning is needed to maximize accuracy and practical
applicability. Future work will explore automated conflict resolution and
real-world implementation through pilot projects with industry partners.",2024-12-29,"Bimal Kumar, Dmitri Roussinov",http://arxiv.org/pdf/2412.20602v1,cs.CL
GliLem: Leveraging GliNER for Contextualized Lemmatization in Estonian,"We present GliLem -- a novel hybrid lemmatization system for Estonian that
enhances the highly accurate rule-based morphological analyzer Vabamorf with an
external disambiguation module based on GliNER -- an open vocabulary NER model
that is able to match text spans with text labels in natural language. We
leverage the flexibility of a pre-trained GliNER model to improve the
lemmatization accuracy of Vabamorf by 10% compared to its original
disambiguation module and achieve an improvement over the token
classification-based baseline. To measure the impact of improvements in
lemmatization accuracy on the information retrieval downstream task, we first
created an information retrieval dataset for Estonian by automatically
translating the DBpedia-Entity dataset from English. We benchmark several token
normalization approaches, including lemmatization, on the created dataset using
the BM25 algorithm. We observe a substantial improvement in IR metrics when
using lemmatization over simplistic stemming. The benefits of improving lemma
disambiguation accuracy manifest in small but consistent improvement in the IR
recall measure, especially in the setting of high k.",2024-12-29,"Aleksei Dorkin, Kairit Sirts",http://arxiv.org/pdf/2412.20597v3,cs.CL
Controlling Out-of-Domain Gaps in LLMs for Genre Classification and Generated Text Detection,"This study demonstrates that the modern generation of Large Language Models
(LLMs, such as GPT-4) suffers from the same out-of-domain (OOD) performance gap
observed in prior research on pre-trained Language Models (PLMs, such as BERT).
We demonstrate this across two non-topical classification tasks: 1) genre
classification and 2) generated text detection. Our results show that when
demonstration examples for In-Context Learning (ICL) come from one domain
(e.g., travel) and the system is tested on another domain (e.g., history),
classification performance declines significantly.
  To address this, we introduce a method that controls which predictive
indicators are used and which are excluded during classification. For the two
tasks studied here, this ensures that topical features are omitted, while the
model is guided to focus on stylistic rather than content-based attributes.
This approach reduces the OOD gap by up to 20 percentage points in a few-shot
setup. Straightforward Chain-of-Thought (CoT) methods, used as the baseline,
prove insufficient, while our approach consistently enhances domain transfer
performance.",2024-12-29,"Dmitri Roussinov, Serge Sharoff, Nadezhda Puchnina",http://arxiv.org/pdf/2412.20595v1,cs.CL
Towards Neural No-Resource Language Translation: A Comparative Evaluation of Approaches,"No-resource languages - those with minimal or no digital representation -
pose unique challenges for machine translation (MT). Unlike low-resource
languages, which rely on limited but existent corpora, no-resource languages
often have fewer than 100 sentences available for training. This work explores
the problem of no-resource translation through three distinct workflows:
fine-tuning of translation-specific models, in-context learning with large
language models (LLMs) using chain-of-reasoning prompting, and direct prompting
without reasoning. Using Owens Valley Paiute as a case study, we demonstrate
that no-resource translation demands fundamentally different approaches from
low-resource scenarios, as traditional approaches to machine translation, such
as those that work for low-resource languages, fail. Empirical results reveal
that, although traditional approaches fail, the in-context learning
capabilities of general-purpose large language models enable no-resource
language translation that outperforms low-resource translation approaches and
rivals human translations (BLEU 0.45-0.6); specifically, chain-of-reasoning
prompting outperforms other methods for larger corpora, while direct prompting
exhibits advantages in smaller datasets. As these approaches are
language-agnostic, they have potential to be generalized to translation tasks
from a wide variety of no-resource languages without expert input. These
findings establish no-resource translation as a distinct paradigm requiring
innovative solutions, providing practical and theoretical insights for language
preservation.",2024-12-29,Madhavendra Thakur,http://arxiv.org/pdf/2412.20584v1,cs.CL
Counterfactual Samples Constructing and Training for Commonsense Statements Estimation,"Plausibility Estimation (PE) plays a crucial role for enabling language
models to objectively comprehend the real world. While large language models
(LLMs) demonstrate remarkable capabilities in PE tasks but sometimes produce
trivial commonsense errors due to the complexity of commonsense knowledge. They
lack two key traits of an ideal PE model: a) Language-explainable: relying on
critical word segments for decisions, and b) Commonsense-sensitive: detecting
subtle linguistic variations in commonsense. To address these issues, we
propose a novel model-agnostic method, referred to as Commonsense
Counterfactual Samples Generating (CCSG). By training PE models with CCSG, we
encourage them to focus on critical words, thereby enhancing both their
language-explainable and commonsense-sensitive capabilities. Specifically, CCSG
generates counterfactual samples by strategically replacing key words and
introducing low-level dropout within sentences. These counterfactual samples
are then incorporated into a sentence-level contrastive training framework to
further enhance the model's learning process. Experimental results across nine
diverse datasets demonstrate the effectiveness of CCSG in addressing
commonsense reasoning challenges, with our CCSG method showing 3.07%
improvement against the SOTA methods.",2024-12-29,"Chong Liu, Zaiwen Feng, Lin Liu, Zhenyun Deng, Jiuyong Li, Ruifang Zhai, Debo Cheng, Li Qin",http://arxiv.org/pdf/2412.20563v1,cs.CL
ICLR: In-Context Learning of Representations,"Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
""graph tracing"" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.",2024-12-29,"Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka",http://arxiv.org/pdf/2501.00070v2,cs.CL
The Impact of Prompt Programming on Function-Level Code Generation,"Large Language Models (LLMs) are increasingly used by software engineers for
code generation. However, limitations of LLMs such as irrelevant or incorrect
code have highlighted the need for prompt programming (or prompt engineering)
where engineers apply specific prompt techniques (e.g., chain-of-thought or
input-output examples) to improve the generated code. Despite this, the impact
of different prompt techniques -- and their combinations -- on code generation
remains underexplored. In this study, we introduce CodePromptEval, a dataset of
7072 prompts designed to evaluate five prompt techniques (few-shot, persona,
chain-of-thought, function signature, list of packages) and their effect on the
correctness, similarity, and quality of complete functions generated by three
LLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt
techniques significantly influence the generated code, combining multiple
techniques does not necessarily improve the outcome. Additionally, we observed
a trade-off between correctness and quality when using prompt techniques. Our
dataset and replication package enable future research on improving
LLM-generated code and evaluating new prompt techniques.",2024-12-29,"Ranim Khojah, Francisco Gomes de Oliveira Neto, Mazen Mohamad, Philipp Leitner",http://arxiv.org/pdf/2412.20545v1,cs.CL
Adversarial Negotiation Dynamics in Generative Language Models,"Generative language models are increasingly used for contract drafting and
enhancement, creating a scenario where competing parties deploy different
language models against each other. This introduces not only a game-theory
challenge but also significant concerns related to AI safety and security, as
the language model employed by the opposing party can be unknown. These
competitive interactions can be seen as adversarial testing grounds, where
models are effectively red-teamed to expose vulnerabilities such as generating
biased, harmful or legally problematic text. Despite the importance of these
challenges, the competitive robustness and safety of these models in
adversarial settings remain poorly understood. In this small study, we approach
this problem by evaluating the performance and vulnerabilities of major
open-source language models in head-to-head competitions, simulating real-world
contract negotiations. We further explore how these adversarial interactions
can reveal potential risks, informing the development of more secure and
reliable models. Our findings contribute to the growing body of research on AI
safety, offering insights into model selection and optimisation in competitive
legal contexts and providing actionable strategies for mitigating risks.",2024-12-29,"Arinbjörn Kolbeinsson, Benedikt Kolbeinsson",http://arxiv.org/pdf/2501.00069v1,cs.CL
SAFE-MEME: Structured Reasoning Framework for Robust Hate Speech Detection in Memes,"Memes act as cryptic tools for sharing sensitive ideas, often requiring
contextual knowledge to interpret. This makes moderating multimodal memes
challenging, as existing works either lack high-quality datasets on nuanced
hate categories or rely on low-quality social media visuals. Here, we curate
two novel multimodal hate speech datasets, MHS and MHS-Con, that capture
fine-grained hateful abstractions in regular and confounding scenarios,
respectively. We benchmark these datasets against several competing baselines.
Furthermore, we introduce SAFE-MEME (Structured reAsoning FramEwork), a novel
multimodal Chain-of-Thought-based framework employing Q&A-style reasoning
(SAFE-MEME-QA) and hierarchical categorization (SAFE-MEME-H) to enable robust
hate speech detection in memes. SAFE-MEME-QA outperforms existing baselines,
achieving an average improvement of approximately 5% and 4% on MHS and MHS-Con,
respectively. In comparison, SAFE-MEME-H achieves an average improvement of 6%
in MHS while outperforming only multimodal baselines in MHS-Con. We show that
fine-tuning a single-layer adapter within SAFE-MEME-H outperforms fully
fine-tuned models in regular fine-grained hateful meme detection. However, the
fully fine-tuning approach with a Q&A setup is more effective for handling
confounding cases. We also systematically examine the error cases, offering
valuable insights into the robustness and limitations of the proposed
structured reasoning framework for analyzing hateful memes.",2024-12-29,"Palash Nandi, Shivam Sharma, Tanmoy Chakraborty",http://arxiv.org/pdf/2412.20541v1,cs.CL
The Synergy of Automated Pipelines with Prompt Engineering and Generative AI in Web Crawling,"Web crawling is a critical technique for extracting online data, yet it poses
challenges due to webpage diversity and anti-scraping mechanisms. This study
investigates the integration of generative AI tools Claude AI (Sonnet 3.5) and
ChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts,
PROMPT I (general inference, tested on Yahoo News) and PROMPT II
(element-specific, tested on Coupons.com), we evaluate the code quality and
performance of AI-generated scripts. Claude AI consistently outperformed
ChatGPT-4.0 in script quality and adaptability, as confirmed by predefined
evaluation metrics, including functionality, readability, modularity, and
robustness. Performance data were collected through manual testing and
structured scoring by three evaluators. Visualizations further illustrate
Claude AI's superiority. Anti-scraping solutions, including
undetected_chromedriver, Selenium, and fake_useragent, were incorporated to
enhance performance. This paper demonstrates how generative AI combined with
prompt engineering can simplify and improve web scraping workflows.",2024-12-29,Chau-Jian Huang,http://arxiv.org/pdf/2502.15691v1,cs.CL
On Adversarial Robustness of Language Models in Transfer Learning,"We investigate the adversarial robustness of LLMs in transfer learning
scenarios. Through comprehensive experiments on multiple datasets (MBIB Hate
Speech, MBIB Political Bias, MBIB Gender Bias) and various model architectures
(BERT, RoBERTa, GPT-2, Gemma, Phi), we reveal that transfer learning, while
improving standard performance metrics, often leads to increased vulnerability
to adversarial attacks. Our findings demonstrate that larger models exhibit
greater resilience to this phenomenon, suggesting a complex interplay between
model size, architecture, and adaptation methods. Our work highlights the
crucial need for considering adversarial robustness in transfer learning
scenarios and provides insights into maintaining model security without
compromising performance. These findings have significant implications for the
development and deployment of LLMs in real-world applications where both
performance and robustness are paramount.",2024-12-29,"Bohdan Turbal, Anastasiia Mazur, Jiaxu Zhao, Mykola Pechenizkiy",http://arxiv.org/pdf/2501.00066v1,cs.CL
ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video Understanding,"Video Large Language Models (VideoLLMs) have made significant strides in
video understanding but struggle with long videos due to the limitations of
their backbone LLMs. Existing solutions rely on length extrapolation, which is
memory-constrained, or visual token compression, which primarily leverages
low-level temporal redundancy while overlooking the more effective high-level
knowledge redundancy. To address this, we propose $\textbf{ReTaKe}$, a
training-free method with two novel modules DPSelect and PivotKV, to jointly
reduce both temporal visual redundancy and knowledge redundancy for video
compression. To align with the way of human temporal perception, DPSelect
identifies keyframes based on inter-frame distance peaks. To leverage LLMs'
learned prior knowledge, PivotKV marks the keyframes as pivots and compress
non-pivot frames by pruning low-attention tokens in their KV cache. ReTaKe
enables VideoLLMs to process 8 times longer frames (up to 2048), outperforming
similar-sized models by 3-5% and even rivaling much larger ones on VideoMME,
MLVU, LongVideoBench, and LVBench. Moreover, by overlapping compression
operations with prefilling, ReTaKe introduces only ~10% prefilling latency
overhead while reducing decoding latency by ~20%. Our code is available at
https://github.com/SCZwangxiao/video-ReTaKe.",2024-12-29,"Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, Liqiang Nie",http://arxiv.org/pdf/2412.20504v5,cs.CL
Cut the Deadwood Out: Post-Training Model Purification with Selective Module Substitution,"The success of DNNs often depends on training with large-scale datasets, but
building such datasets is both expensive and challenging. Consequently, public
datasets from open-source platforms like HuggingFace have become popular,
posing significant risks of data poisoning attacks. Existing backdoor defenses
in NLP primarily focus on identifying and removing poisoned samples; however,
purifying a backdoored model with these sample-cleaning approaches typically
requires expensive retraining. Therefore, we propose Greedy Module Substitution
(GMS), which identifies and substitutes ''deadwood'' modules (i.e., components
critical to backdoor pathways) in a backdoored model to purify it. Our method
relaxes the common dependency of prior model purification methods on clean
datasets or clean auxiliary models. When applied to RoBERTa-large under
backdoor attacks, GMS demonstrates strong effectiveness across various
settings, particularly against widely recognized challenging attacks like LWS,
achieving a post-purification attack success rate (ASR) of 9.7% on SST-2
compared to 58.8% for the best baseline approach.",2024-12-29,"Yao Tong, Weijun Li, Xuanli He, Haolan Zhan, Qiongkai Xu",http://arxiv.org/pdf/2412.20476v1,cs.CL
Is Your Image a Good Storyteller?,"Quantifying image complexity at the entity level is straightforward, but the
assessment of semantic complexity has been largely overlooked. In fact, there
are differences in semantic complexity across images. Images with richer
semantics can tell vivid and engaging stories and offer a wide range of
application scenarios. For example, the Cookie Theft picture is such a kind of
image and is widely used to assess human language and cognitive abilities due
to its higher semantic complexity. Additionally, semantically rich images can
benefit the development of vision models, as images with limited semantics are
becoming less challenging for them. However, such images are scarce,
highlighting the need for a greater number of them. For instance, there is a
need for more images like Cookie Theft to cater to people from different
cultural backgrounds and eras. Assessing semantic complexity requires human
experts and empirical evidence. Automatic evaluation of how semantically rich
an image will be the first step of mining or generating more images with rich
semantics, and benefit human cognitive assessment, Artificial Intelligence, and
various other applications. In response, we propose the Image Semantic
Assessment (ISA) task to address this problem. We introduce the first ISA
dataset and a novel method that leverages language to solve this vision
problem. Experiments on our dataset demonstrate the effectiveness of our
approach.",2024-12-29,"Xiujie Song, Xiaoyi Pang, Haifeng Tang, Mengyue Wu, Kenny Q. Zhu",http://arxiv.org/pdf/2501.01982v2,cs.CL
Utilizing Multimodal Data for Edge Case Robust Call-sign Recognition and Understanding,"Operational machine-learning based assistant systems must be robust in a wide
range of scenarios. This hold especially true for the air-traffic control (ATC)
domain. The robustness of an architecture is particularly evident in edge
cases, such as high word error rate (WER) transcripts resulting from noisy ATC
recordings or partial transcripts due to clipped recordings. To increase the
edge-case robustness of call-sign recognition and understanding (CRU), a core
tasks in ATC speech processing, we propose the multimodal call-sign-command
recovery model (CCR). The CCR architecture leads to an increase in the edge
case performance of up to 15%. We demonstrate this on our second proposed
architecture, CallSBERT. A CRU model that has less parameters, can be
fine-tuned noticeably faster and is more robust during fine-tuning than the
state of the art for CRU. Furthermore, we demonstrate that optimizing for edge
cases leads to a significantly higher accuracy across a wide operational range.",2024-12-29,"Alexander Blatt, Dietrich Klakow",http://arxiv.org/pdf/2412.20467v1,cs.CL
"Enhancing Entertainment Translation for Indian Languages using Adaptive Context, Style and LLMs","We address the challenging task of neural machine translation (NMT) in the
entertainment domain, where the objective is to automatically translate a given
dialogue from a source language content to a target language. This task has
various applications, particularly in automatic dubbing, subtitling, and other
content localization tasks, enabling source content to reach a wider audience.
Traditional NMT systems typically translate individual sentences in isolation,
without facilitating knowledge transfer of crucial elements such as the context
and style from previously encountered sentences. In this work, we emphasize the
significance of these fundamental aspects in producing pertinent and
captivating translations. We demonstrate their significance through several
examples and propose a novel framework for entertainment translation, which, to
our knowledge, is the first of its kind. Furthermore, we introduce an algorithm
to estimate the context and style of the current session and use these
estimations to generate a prompt that guides a Large Language Model (LLM) to
generate high-quality translations. Our method is both language and
LLM-agnostic, making it a general-purpose tool. We demonstrate the
effectiveness of our algorithm through various numerical studies and observe
significant improvement in the COMET scores over various state-of-the-art LLMs.
Moreover, our proposed method consistently outperforms baseline LLMs in terms
of win-ratio.",2024-12-29,"Pratik Rakesh Singh, Mohammadi Zaki, Pankaj Wasnik",http://arxiv.org/pdf/2412.20440v1,cs.CL
Integrating Natural Language Processing Techniques of Text Mining Into Financial System: Applications and Limitations,"The financial sector, a pivotal force in economic development, increasingly
uses the intelligent technologies such as natural language processing to
enhance data processing and insight extraction. This research paper through a
review process of the time span of 2018-2023 explores the use of text mining as
natural language processing techniques in various components of the financial
system including asset pricing, corporate finance, derivatives, risk
management, and public finance and highlights the need to address the specific
problems in the discussion section. We notice that most of the research
materials combined probabilistic with vector-space models, and text-data with
numerical ones. The most used technique regarding information processing is the
information classification technique and the most used algorithms include the
long-short term memory and bidirectional encoder models. The research noticed
that new specific algorithms are developed and the focus of the financial
system is mainly on asset pricing component. The research also proposes a path
from engineering perspective for researchers who need to analyze financial
text. The challenges regarding text mining perspective such as data quality,
context-adaption and model interpretability need to be solved so to integrate
advanced natural language processing models and techniques in enhancing
financial analysis and prediction. Keywords: Financial System (FS), Natural
Language Processing (NLP), Software and Text Engineering, Probabilistic,
Vector-Space, Models, Techniques, TextData, Financial Analysis.",2024-12-29,"Denisa Millo, Blerina Vika, Nevila Baci",http://arxiv.org/pdf/2412.20438v1,cs.CL
Comparative Performance of Advanced NLP Models and LLMs in Multilingual Geo-Entity Detection,"The integration of advanced Natural Language Processing (NLP) methodologies
and Large Language Models (LLMs) has significantly enhanced the extraction and
analysis of geospatial data from multilingual texts, impacting sectors such as
national and international security. This paper presents a comprehensive
evaluation of leading NLP models -- SpaCy, XLM-RoBERTa, mLUKE, GeoLM -- and
LLMs, specifically OpenAI's GPT 3.5 and GPT 4, within the context of
multilingual geo-entity detection. Utilizing datasets from Telegram channels in
English, Russian, and Arabic, we examine the performance of these models
through metrics such as accuracy, precision, recall, and F1 scores, to assess
their effectiveness in accurately identifying geospatial references. The
analysis exposes each model's distinct advantages and challenges, underscoring
the complexities involved in achieving precise geo-entity identification across
varied linguistic landscapes. The conclusions drawn from this experiment aim to
direct the enhancement and creation of more advanced and inclusive NLP tools,
thus advancing the field of geospatial analysis and its application to global
security.",2024-12-29,Kalin Kopanov,http://arxiv.org/pdf/2412.20414v1,cs.CL
Multi-Objective Large Language Model Unlearning,"Machine unlearning in the domain of large language models (LLMs) has
attracted great attention recently, which aims to effectively eliminate
undesirable behaviors from LLMs without full retraining from scratch. In this
paper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is
a proactive way to decrease the prediction probability of the model on the
target data in order to remove their influence. We analyze two challenges that
render the process impractical: gradient explosion and catastrophic forgetting.
To address these issues, we propose Multi-Objective Large Language Model
Unlearning (MOLLM) algorithm. We first formulate LLM unlearning as a
multi-objective optimization problem, in which the cross-entropy loss is
modified to the unlearning version to overcome the gradient explosion issue. A
common descent update direction is then calculated, which enables the model to
forget the target data while preserving the utility of the LLM. Our empirical
results verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods
in terms of unlearning effect and model utility preservation. The source code
is available at https://github.com/zibinpan/MOLLM.",2024-12-29,"Zibin Pan, Shuwen Zhang, Yuesheng Zheng, Chi Li, Yuheng Cheng, Junhua Zhao",http://arxiv.org/pdf/2412.20412v2,cs.CL
A Multidisciplinary Approach to Telegram Data Analysis,"This paper presents a multidisciplinary approach to analyzing data from
Telegram for early warning information regarding cyber threats. With the
proliferation of hacktivist groups utilizing Telegram to disseminate
information regarding future cyberattacks or to boast about successful ones,
the need for effective data analysis methods is paramount. The primary
challenge lies in the vast number of channels and the overwhelming volume of
data, necessitating advanced techniques for discerning pertinent risks amidst
the noise. To address this challenge, we employ a combination of neural network
architectures and traditional machine learning algorithms. These methods are
utilized to classify and identify potential cyber threats within the Telegram
data. Additionally, sentiment analysis and entity recognition techniques are
incorporated to provide deeper insights into the nature and context of the
communicated information. The study evaluates the effectiveness of each method
in detecting and categorizing cyber threats, comparing their performance and
identifying areas for improvement. By leveraging these diverse analytical
tools, we aim to enhance early warning systems for cyber threats, enabling more
proactive responses to potential security breaches. This research contributes
to the ongoing efforts to bolster cybersecurity measures in an increasingly
interconnected digital landscape.",2024-12-29,"Velizar Varbanov, Kalin Kopanov, Tatiana Atanasova",http://arxiv.org/pdf/2412.20406v1,cs.CL
Natural Language Fine-Tuning,"Large language model fine-tuning techniques typically depend on extensive
labeled data, external guidance, and feedback, such as human alignment, scalar
rewards, and demonstration. However, in practical application, the scarcity of
specific knowledge poses unprecedented challenges to existing fine-tuning
techniques. In this paper, focusing on fine-tuning tasks in specific domains
with limited data, we introduce Natural Language Fine-Tuning (NLFT), which
utilizes natural language for fine-tuning for the first time. By leveraging the
strong language comprehension capability of the target LM, NLFT attaches the
guidance of natural language to the token-level outputs. Then, saliency tokens
are identified with calculated probabilities. Since linguistic information is
effectively utilized in NLFT, our proposed method significantly reduces
training costs. It markedly enhances training efficiency, comprehensively
outperforming reinforcement fine-tuning algorithms in accuracy, time-saving,
and resource conservation. Additionally, on the macro level, NLFT can be viewed
as a token-level fine-grained optimization of SFT, thereby efficiently
replacing the SFT process without the need for warm-up (as opposed to ReFT
requiring multiple rounds of warm-up with SFT). Compared to SFT, NLFT does not
increase the algorithmic complexity, maintaining O(n). Extensive experiments on
the GSM8K dataset demonstrate that NLFT, with only 50 data instances, achieves
an accuracy increase that exceeds SFT by 219%. Compared to ReFT, the time
complexity and space complexity of NLFT are reduced by 78.27% and 92.24%,
respectively. The superior technique of NLFT is paving the way for the
deployment of various innovative LLM fine-tuning applications when resources
are limited at network edges.
  Our code has been released at https://github.com/Julia-LiuJ/NLFT.",2024-12-29,"Jia Liu, Yue Wang, Zhiqi Lin, Min Chen, Yixue Hao, Long Hu",http://arxiv.org/pdf/2412.20382v1,cs.CL
LLM2: Let Large Language Models Harness System 2 Reasoning,"Large language models (LLMs) have exhibited impressive capabilities across a
myriad of tasks, yet they occasionally yield undesirable outputs. We posit that
these limitations are rooted in the foundational autoregressive architecture of
LLMs, which inherently lacks mechanisms for differentiating between desirable
and undesirable results. Drawing inspiration from the dual-process theory of
human cognition, we introduce LLM2, a novel framework that combines an LLM
(System 1) with a process-based verifier (System 2). Within LLM2, the LLM is
responsible for generating plausible candidates, while the verifier provides
timely process-based feedback to distinguish desirable and undesirable outputs.
The verifier is trained with a pairwise comparison loss on synthetic
process-supervision data generated through our token quality exploration
strategy. Empirical results on mathematical reasoning benchmarks substantiate
the efficacy of LLM2, exemplified by an accuracy enhancement from 50.3 to 57.8
(+7.5) for Llama3-1B on GSM8K. Furthermore, when combined with
self-consistency, LLM2 achieves additional improvements, boosting major@20
accuracy from 56.2 to 70.2 (+14.0).",2024-12-29,"Cheng Yang, Chufan Shi, Siheng Li, Bo Shui, Yujiu Yang, Wai Lam",http://arxiv.org/pdf/2412.20372v2,cs.CL
Enhancing Code LLMs with Reinforcement Learning in Code Generation: A Survey,"With the rapid evolution of large language models (LLM), reinforcement
learning (RL) has emerged as a pivotal technique for code generation and
optimization in various domains. This paper presents a systematic survey of the
application of RL in code optimization and generation, highlighting its role in
enhancing compiler optimization, resource allocation, and the development of
frameworks and tools. Subsequent sections first delve into the intricate
processes of compiler optimization, where RL algorithms are leveraged to
improve efficiency and resource utilization. The discussion then progresses to
the function of RL in resource allocation, emphasizing register allocation and
system optimization. We also explore the burgeoning role of frameworks and
tools in code generation, examining how RL can be integrated to bolster their
capabilities. This survey aims to serve as a comprehensive resource for
researchers and practitioners interested in harnessing the power of RL to
advance code generation and optimization techniques.",2024-12-29,"Junqiao Wang, Zeng Zhang, Yangfan He, Yuyang Song, Tianyu Shi, Yuchen Li, Hengyuan Xu, Kunyu Wu, Guangwu Qian, Qiuwu Chen, Lewei He",http://arxiv.org/pdf/2412.20367v2,cs.CL
ELECTRA and GPT-4o: Cost-Effective Partners for Sentiment Analysis,"Bidirectional transformers excel at sentiment analysis, and Large Language
Models (LLM) are effective zero-shot learners. Might they perform better as a
team? This paper explores collaborative approaches between ELECTRA and GPT-4o
for three-way sentiment classification. We fine-tuned (FT) four models (ELECTRA
Base/Large, GPT-4o/4o-mini) using a mix of reviews from Stanford Sentiment
Treebank (SST) and DynaSent. We provided input from ELECTRA to GPT as:
predicted label, probabilities, and retrieved examples. Sharing ELECTRA Base FT
predictions with GPT-4o-mini significantly improved performance over either
model alone (82.50 macro F1 vs. 79.14 ELECTRA Base FT, 79.41 GPT-4o-mini) and
yielded the lowest cost/performance ratio (\$0.12/F1 point). However, when GPT
models were fine-tuned, including predictions decreased performance. GPT-4o
FT-M was the top performer (86.99), with GPT-4o-mini FT close behind (86.70) at
much less cost (\$0.38 vs. \$1.59/F1 point). Our results show that augmenting
prompts with predictions from fine-tuned encoders is an efficient way to boost
performance, and a fine-tuned GPT-4o-mini is nearly as good as GPT-4o FT at 76%
less cost. Both are affordable options for projects with limited resources.",2024-12-29,James P. Beno,http://arxiv.org/pdf/2501.00062v2,cs.CL
HindiLLM: Large Language Model for Hindi,"The advancements in the Large Language Model (LLM) have helped in solving
several problems related to language processing. Most of the researches have
focused on the English language only, because of its popularity and abundance
on the internet. However, a high-performance language model for Hindi and other
Indic languages is lacking in the literature. In this work, we have pre-trained
two autoregressive LLM models for the Hindi language, namely HindiLLM-Small and
HindiLLM-Medium. We use a two-step process comprising unsupervised pre-training
and supervised fine-tuning. First, we create a large and high-quality text
corpus for unsupervised pre-training. Next, we train a Byte-Pair Encoding,
named HindiLLM tokenizer, using the pre-training text data. We then perform
training on the unlabeled data, known as the pre-training step, to get the
HindiLLM base models. Furthermore, we perform fine-tuning of the HindiLLM base
models for different tasks like sentiment analysis, text classification,
natural language inference, and multiple choice question-answer on popular
labeled datasets to measure the real-world performance. The evaluation shows
that the HindiLLM-based fine-tuned models outperform several models in most of
the language related tasks.",2024-12-29,"Sanjay Chouhan, Shubha Brata Nath, Aparajita Dutta",http://arxiv.org/pdf/2412.20357v1,cs.CL
Understanding the Impact of Confidence in Retrieval Augmented Generation: A Case Study in the Medical Domain,"Retrieval Augmented Generation (RAG) complements the knowledge of Large
Language Models (LLMs) by leveraging external information to enhance response
accuracy for queries. This approach is widely applied in several fields by
taking its advantage of injecting the most up-to-date information, and
researchers are focusing on understanding and improving this aspect to unlock
the full potential of RAG in such high-stakes applications. However, despite
the potential of RAG to address these needs, the mechanisms behind the
confidence levels of its outputs remain underexplored, although the confidence
of information is very critical in some domains, such as finance, healthcare,
and medicine. Our study focuses the impact of RAG on confidence within the
medical domain under various configurations and models. We evaluate confidence
by treating the model's predicted probability as its output and calculating
Expected Calibration Error (ECE) and Adaptive Calibration Error (ACE) scores
based on the probabilities and accuracy. In addition, we analyze whether the
order of retrieved documents within prompts calibrates the confidence. Our
findings reveal large variation in confidence and accuracy depending on the
model, settings, and the format of input prompts. These results underscore the
necessity of optimizing configurations based on the specific model and
conditions.",2024-12-29,"Shintaro Ozaki, Yuta Kato, Siyuan Feng, Masayo Tomita, Kazuki Hayashi, Wataru Hashimoto, Ryoma Obara, Masafumi Oyamada, Katsuhiko Hayashi, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2412.20309v2,cs.CL
No Preference Left Behind: Group Distributional Preference Optimization,"Preferences within a group of people are not uniform but follow a
distribution. While existing alignment methods like Direct Preference
Optimization (DPO) attempt to steer models to reflect human preferences, they
struggle to capture the distributional pluralistic preferences within a group.
These methods often skew toward dominant preferences, overlooking the diversity
of opinions, especially when conflicting preferences arise. To address this
issue, we propose Group Distributional Preference Optimization (GDPO), a novel
framework that aligns language models with the distribution of preferences
within a group by incorporating the concept of beliefs that shape individual
preferences. GDPO calibrates a language model using statistical estimation of
the group's belief distribution and aligns the model with belief-conditioned
preferences, offering a more inclusive alignment framework than traditional
methods. In experiments using both synthetic controllable opinion generation
and real-world movie review datasets, we show that DPO fails to align with the
targeted belief distributions, while GDPO consistently reduces this alignment
gap during training. Moreover, our evaluation metrics demonstrate that GDPO
outperforms existing approaches in aligning with group distributional
preferences, marking a significant advance in pluralistic alignment.",2024-12-28,"Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu",http://arxiv.org/pdf/2412.20299v2,cs.CL
Leveraging Edge Intelligence and LLMs to Advance 6G-Enabled Internet of Automated Defense Vehicles,"The evolution of Artificial Intelligence (AI) and its subset Deep Learning
(DL), has profoundly impacted numerous domains, including autonomous driving.
The integration of autonomous driving in military settings reduces human
casualties and enables precise and safe execution of missions in hazardous
environments while allowing for reliable logistics support without the risks
associated with fatigue-related errors. However, relying on autonomous driving
solely requires an advanced decision-making model that is adaptable and optimum
in any situation. Considering the presence of numerous interconnected
autonomous vehicles in mission-critical scenarios, Ultra-Reliable Low Latency
Communication (URLLC) is vital for ensuring seamless coordination, real-time
data exchange, and instantaneous response to dynamic driving environments. The
advent of 6G strengthens the Internet of Automated Defense Vehicles (IoADV)
concept within the realm of Internet of Military Defense Things (IoMDT) by
enabling robust connectivity, crucial for real-time data exchange, advanced
navigation, and enhanced safety features through IoADV interactions. On the
other hand, a critical advancement in this space is using pre-trained
Generative Large Language Models (LLMs) for decision-making and communication
optimization for autonomous driving. Hence, this work presents opportunities
and challenges with a vision of realizing the full potential of these
technologies in critical defense applications, especially through the
advancement of IoADV and its role in enhancing autonomous military operations.",2024-12-28,"Murat Arda Onsu, Poonam Lohan, Burak Kantarci",http://arxiv.org/pdf/2501.06205v2,cs.CL
Scoring with Large Language Models: A Study on Measuring Empathy of Responses in Dialogues,"In recent years, Large Language Models (LLMs) have become increasingly more
powerful in their ability to complete complex tasks. One such task in which
LLMs are often employed is scoring, i.e., assigning a numerical value from a
certain scale to a subject. In this paper, we strive to understand how LLMs
score, specifically in the context of empathy scoring. We develop a novel and
comprehensive framework for investigating how effective LLMs are at measuring
and scoring empathy of responses in dialogues, and what methods can be employed
to deepen our understanding of LLM scoring. Our strategy is to approximate the
performance of state-of-the-art and fine-tuned LLMs with explicit and
explainable features. We train classifiers using various features of dialogues
including embeddings, the Motivational Interviewing Treatment Integrity (MITI)
Code, a set of explicit subfactors of empathy as proposed by LLMs, and a
combination of the MITI Code and the explicit subfactors. Our results show that
when only using embeddings, it is possible to achieve performance close to that
of generic LLMs, and when utilizing the MITI Code and explicit subfactors
scored by an LLM, the trained classifiers can closely match the performance of
fine-tuned LLMs. We employ feature selection methods to derive the most crucial
features in the process of empathy scoring. Our work provides a new perspective
toward understanding LLM empathy scoring and helps the LLM community explore
the potential of LLM scoring in social science studies.",2024-12-28,"Henry J. Xie, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu",http://arxiv.org/pdf/2412.20264v1,cs.CL
Large Language Models for Mathematical Analysis,"Mathematical problem-solving is a key field in artificial intelligence (AI)
and a critical benchmark for evaluating the capabilities of large language
models (LLMs). While extensive research has focused on mathematical
problem-solving, most existing work and datasets concentrate on computational
tasks, leaving gaps in areas like mathematical analysis, which demands rigorous
proofs and formal reasoning. We developed the DEMI-MathAnalysis dataset,
comprising proof-based problems from mathematical analysis topics such as
Sequences and Limits, Infinite Series, and Convex Functions. We also designed a
guiding framework to rigorously enhance LLMs' ability to solve these problems.
Through fine-tuning LLMs on this dataset and employing our framework, we
observed significant improvements in their capability to generate logical,
complete, and elegant proofs. This work addresses critical gaps in mathematical
reasoning and contributes to advancing trustworthy AI capable of handling
formalized mathematical language. The code is publicly accessible at LLMs for
Mathematical Analysis.",2024-12-28,"Ziye Chen, Hao Qi",http://arxiv.org/pdf/2501.00059v1,cs.CL
ComparisonQA: Evaluating Factuality Robustness of LLMs Through Knowledge Frequency Control and Uncertainty,"The rapid development of LLMs has sparked extensive research into their
factual knowledge. Current works find that LLMs fall short on questions around
low-frequency entities. However, such proofs are unreliable since the questions
can differ not only in entity frequency but also in difficulty themselves. So
we introduce ComparisonQA benchmark, containing 283K abstract questions, each
instantiated by a pair of high-frequency and low-frequency entities. It ensures
a controllable comparison to study the role of knowledge frequency in the
performance of LLMs. Because the difference between such a pair is only the
entity with different frequencies. In addition, we use both correctness and
uncertainty to develop a two-round method to evaluate LLMs' knowledge
robustness. It aims to avoid possible semantic shortcuts which is a serious
problem of current QA study. Experiments reveal that LLMs, including GPT-4o,
exhibit particularly low robustness regarding low-frequency knowledge. Besides,
we find that uncertainty can be used to effectively identify high-quality and
shortcut-free questions while maintaining the data size. Based on this, we
propose an automatic method to select such questions to form a subset called
ComparisonQA-Hard, containing only hard low-frequency questions.",2024-12-28,"Qing Zong, Zhaowei Wang, Tianshi Zheng, Xiyu Ren, Yangqiu Song",http://arxiv.org/pdf/2412.20251v2,cs.CL
LLM Reasoning Engine: Specialized Training for Enhanced Mathematical Reasoning,"Large Language Models (LLMs) have shown remarkable performance in various
natural language processing tasks but face challenges in mathematical
reasoning, where complex problem-solving requires both linguistic understanding
and mathematical reasoning skills. Existing approaches to address this
challenge often rely on ensemble methods and suffer from the problem of data
scarcity in target domains. In this work, we present a novel method to enhance
LLMs' capabilities in mathematical reasoning tasks. Motivated by the need to
bridge this gap, our approach incorporates a question paraphrase strategy,
which aims at diversifying the linguistic forms of mathematical questions to
improve generalization. Additionally, specialized training objectives are
employed to guide the model's learning process, focusing on enhancing its
understanding of mathematical concepts and reasoning processes. We conduct
experiments on four datasets using different LLMs, and demonstrate the
effectiveness of our approach in improving LLMs' performance on mathematical
reasoning tasks. Our findings underscore the significance of our methodology in
the advancement of large language models and its potential implications for
real-world applications that require mathematical reasoning abilities.",2024-12-28,"Shuguang Chen, Guang Lin",http://arxiv.org/pdf/2412.20227v2,cs.CL
AfriHG: News headline generation for African Languages,"This paper introduces AfriHG -- a news headline generation dataset created by
combining from XLSum and MasakhaNEWS datasets focusing on 16 languages widely
spoken by Africa. We experimented with two seq2eq models (mT5-base and AfriTeVa
V2), and Aya-101 LLM. Our results show that Africa-centric seq2seq models such
as AfriTeVa V2 outperform the massively multilingual mT5-base model. Finally,
we show that the performance of fine-tuning AfriTeVa V2 with 313M parameters is
competitive to prompting Aya-101 LLM with more than 13B parameters.",2024-12-28,"Toyib Ogunremi, Serah Akojenu, Anthony Soronnadi, Olubayo Adekanmbi, David Ifeoluwa Adelani",http://arxiv.org/pdf/2412.20223v1,cs.CL
YAD: Leveraging T5 for Improved Automatic Diacritization of Yorùbá Text,"In this work, we present Yor\`ub\'a automatic diacritization (YAD) benchmark
dataset for evaluating Yor\`ub\'a diacritization systems. In addition, we
pre-train text-to-text transformer, T5 model for Yor\`ub\'a and showed that
this model outperform several multilingually trained T5 models. Lastly, we
showed that more data and larger models are better at diacritization for
Yor\`ub\'a",2024-12-28,"Akindele Michael Olawole, Jesujoba O. Alabi, Aderonke Busayo Sakpere, David I. Adelani",http://arxiv.org/pdf/2412.20218v1,cs.CL
Decoding Emotion: Speech Perception Patterns in Individuals with Self-reported Depression,"The current study examines the relationship between self-reported depression
and the perception of affective speech within the Indian population. PANAS and
PHQ-9 were used to assess current mood and depression, respectively.
Participants' emotional reactivity was recorded on a valence and arousal scale
against the affective speech audio presented in a sequence. No significant
differences between the depression and no-depression groups were observed for
any of the emotional stimuli, except the audio file depicting neutral emotion.
Significantly higher PANAS scores by the depression than the no-depression
group indicate the impact of pre-disposed mood on the current mood status.
Contrary to previous findings, this study did not observe reduced positive
emotional reactivity by the depression group. However, the results demonstrated
consistency in emotional reactivity for speech stimuli depicting sadness and
anger across all measures of emotion perception.",2024-12-28,"Guneesh Vats, Priyanka Srivastava, Chiranjeevi Yarra",http://arxiv.org/pdf/2412.20213v1,cs.CL
Building a Rich Dataset to Empower the Persian Question Answering Systems,"Question answering systems provide short, precise, and specific answers to
questions. So far, many robust question answering systems have been developed
for English, while some languages with fewer resources, like Persian, have few
numbers of standard dataset. In this study, a comprehensive open-domain dataset
is presented for Persian. This dataset is called NextQuAD and has 7,515
contexts, including 23,918 questions and answers. Then, a BERT-based question
answering model has been applied to this dataset using two pre-trained language
models, including ParsBERT and XLM-RoBERTa. The results of these two models
have been ensembled using mean logits. Evaluation on the development set shows
0.95 Exact Match (EM) and 0.97 Fl_score. Also, to compare the NextQuAD with
other Persian datasets, our trained model on the NextQuAD, is evaluated on two
other datasets named PersianQA and ParSQuAD. Comparisons show that the proposed
model increased EM by 0.39 and 0.14 respectively in PersianQA and
ParSQuAD-manual, while a slight EM decline of 0.007 happened in
ParSQuAD-automatic.",2024-12-28,"Mohsen Yazdinejad, Marjan Kaedi",http://arxiv.org/pdf/2412.20212v1,cs.CL
Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering,"Complex table question answering (TQA) aims to answer questions that require
complex reasoning, such as multi-step or multi-category reasoning, over data
represented in tabular form. Previous approaches demonstrated notable
performance by leveraging either closed-source large language models (LLMs) or
fine-tuned open-weight LLMs. However, fine-tuning LLMs requires high-quality
training data, which is costly to obtain, and utilizing closed-source LLMs
poses accessibility challenges and leads to reproducibility issues. In this
paper, we propose Multi-Agent Collaboration with Tool use (MACT), a framework
that requires neither closed-source models nor fine-tuning. In MACT, a planning
agent and a coding agent that also make use of tools collaborate to answer
questions. Our experiments on four TQA benchmarks show that MACT outperforms
previous SoTA systems on three out of four benchmarks and that it performs
comparably to the larger and more expensive closed-source model GPT-4 on two
benchmarks, even when using only open-weight models without any fine-tuning. We
conduct extensive analyses to prove the effectiveness of MACT's multi-agent
collaboration in TQA.",2024-12-28,"Wei Zhou, Mohsen Mesgar, Annemarie Friedrich, Heike Adel",http://arxiv.org/pdf/2412.20145v2,cs.CL
M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation,"Recent advancements in large language models (LLMs) have given rise to the
LLM-as-a-judge paradigm, showcasing their potential to deliver human-like
judgments. However, in the field of machine translation (MT) evaluation,
current LLM-as-a-judge methods fall short of learned automatic metrics. In this
paper, we propose Multidimensional Multi-Agent Debate (M-MAD), a systematic
LLM-based multi-agent framework for advanced LLM-as-a-judge MT evaluation. Our
findings demonstrate that M-MAD achieves significant advancements by (1)
decoupling heuristic MQM criteria into distinct evaluation dimensions for
fine-grained assessments; (2) employing multi-agent debates to harness the
collaborative reasoning capabilities of LLMs; (3) synthesizing
dimension-specific results into a final evaluation judgment to ensure robust
and reliable outcomes. Comprehensive experiments show that M-MAD not only
outperforms all existing LLM-as-a-judge methods but also competes with
state-of-the-art reference-based automatic metrics, even when powered by a
suboptimal model like GPT-4o mini. Detailed ablations and analysis highlight
the superiority of our framework design, offering a fresh perspective for
LLM-as-a-judge paradigm. Our code and data are publicly available at
https://github.com/SU-JIAYUAN/M-MAD.",2024-12-28,"Zhaopeng Feng, Jiayuan Su, Jiamei Zheng, Jiahan Ren, Yan Zhang, Jian Wu, Hongwei Wang, Zuozhu Liu",http://arxiv.org/pdf/2412.20127v3,cs.CL
Leveraging Social Media Data and Artificial Intelligence for Improving Earthquake Response Efforts,"The integration of social media and artificial intelligence (AI) into
disaster management, particularly for earthquake response, represents a
profound evolution in emergency management practices. In the digital age,
real-time information sharing has reached unprecedented levels, with social
media platforms emerging as crucial communication channels during crises. This
shift has transformed traditional, centralized emergency services into more
decentralized, participatory models of disaster situational awareness. Our
study includes an experimental analysis of 8,900 social media interactions,
including 2,920 posts and 5,980 replies on X (formerly Twitter), following a
magnitude 5.1 earthquake in Oklahoma on February 2, 2024. The analysis covers
data from the immediate aftermath and extends over the following seven days,
illustrating the critical role of digital platforms in modern disaster
response. The results demonstrate that social media platforms can be
effectively used as real-time situational awareness tools, delivering critical
information to society and authorities during emergencies.",2024-12-28,"Kalin Kopanov, Velizar Varbanov, Tatiana Atanasova",http://arxiv.org/pdf/2501.14767v1,cs.CL
Extract Information from Hybrid Long Documents Leveraging LLMs: A Framework and Dataset,"Large Language Models (LLMs) demonstrate exceptional performance in textual
understanding and tabular reasoning tasks. However, their ability to comprehend
and analyze hybrid text, containing textual and tabular data, remains
unexplored. The hybrid text often appears in the form of hybrid long documents
(HLDs), which far exceed the token limit of LLMs. Consequently, we apply an
Automated Information Extraction framework (AIE) to enable LLMs to process the
HLDs and carry out experiments to analyse four important aspects of information
extraction from HLDs. Given the findings: 1) The effective way to select and
summarize the useful part of a HLD. 2) An easy table serialization way is
enough for LLMs to understand tables. 3) The naive AIE has adaptability in many
complex scenarios. 4) The useful prompt engineering to enhance LLMs on HLDs. To
address the issue of dataset scarcity in HLDs and support future work, we also
propose the Financial Reports Numerical Extraction (FINE) dataset. The dataset
and code are publicly available in the attachments.",2024-12-28,"Chongjian Yue, Xinrun Xu, Xiaojun Ma, Lun Du, Zhiming Ding, Shi Han, Dongmei Zhang, Qi Zhang",http://arxiv.org/pdf/2412.20072v2,cs.CL
On the Compositional Generalization of Multimodal LLMs for Medical Imaging,"Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.",2024-12-28,"Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang",http://arxiv.org/pdf/2412.20070v1,cs.CL
LLM-Virus: Evolutionary Jailbreak Attack on Large Language Models,"While safety-aligned large language models (LLMs) are increasingly used as
the cornerstone for powerful systems such as multi-agent frameworks to solve
complex real-world problems, they still suffer from potential adversarial
queries, such as jailbreak attacks, which attempt to induce harmful content.
Researching attack methods allows us to better understand the limitations of
LLM and make trade-offs between helpfulness and safety. However, existing
jailbreak attacks are primarily based on opaque optimization techniques (e.g.
token-level gradient descent) and heuristic search methods like LLM refinement,
which fall short in terms of transparency, transferability, and computational
cost. In light of these limitations, we draw inspiration from the evolution and
infection processes of biological viruses and propose LLM-Virus, a jailbreak
attack method based on evolutionary algorithm, termed evolutionary jailbreak.
LLM-Virus treats jailbreak attacks as both an evolutionary and transfer
learning problem, utilizing LLMs as heuristic evolutionary operators to ensure
high attack efficiency, transferability, and low time cost. Our experimental
results on multiple safety benchmarks show that LLM-Virus achieves competitive
or even superior performance compared to existing attack methods.",2024-12-28,"Miao Yu, Junfeng Fang, Yingjie Zhou, Xing Fan, Kun Wang, Shirui Pan, Qingsong Wen",http://arxiv.org/pdf/2501.00055v1,cs.CL
The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support,"The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.",2024-12-28,"Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani",http://arxiv.org/pdf/2412.20068v1,cs.CL
Comparative Analysis of Listwise Reranking with Large Language Models in Limited-Resource Language Contexts,"Large Language Models (LLMs) have demonstrated significant effectiveness
across various NLP tasks, including text ranking. This study assesses the
performance of large language models (LLMs) in listwise reranking for
limited-resource African languages. We compare proprietary models RankGPT3.5,
Rank4o-mini, RankGPTo1-mini and RankClaude-sonnet in cross-lingual contexts.
Results indicate that these LLMs significantly outperform traditional baseline
methods such as BM25-DT in most evaluation metrics, particularly in nDCG@10 and
MRR@100. These findings highlight the potential of LLMs in enhancing reranking
tasks for low-resource languages and offer insights into cost-effective
solutions.",2024-12-28,"Yanxin Shen, Lun Wang, Chuanqi Shi, Shaoshuai Du, Yiyi Tao, Yixian Shen, Hang Zhang",http://arxiv.org/pdf/2412.20061v2,cs.CL
"""My life is miserable, have to sign 500 autographs everyday"": Exposing Humblebragging, the Brags in Disguise","Humblebragging is a phenomenon where individuals present self-promotional
statements under the guise of modesty or complaints. For example, a statement
like, ""Ugh, I can't believe I got promoted to lead the entire team. So
stressful!"", subtly highlights an achievement while pretending to be
complaining. Detecting humblebragging is important for machines to better
understand the nuances of human language, especially in tasks like sentiment
analysis and intent recognition. However, this topic has not yet been studied
in computational linguistics. For the first time, we introduce the task of
automatically detecting humblebragging in text. We formalize the task by
proposing a 4-tuple definition of humblebragging and evaluate machine learning,
deep learning, and large language models (LLMs) on this task, comparing their
performance with humans. We also create and release a dataset called HB24,
containing 3,340 humblebrags generated using GPT-4o. Our experiments show that
detecting humblebragging is non-trivial, even for humans. Our best model
achieves an F1-score of 0.88. This work lays the foundation for further
exploration of this nuanced linguistic phenomenon and its integration into
broader natural language understanding systems.",2024-12-28,"Sharath Naganna, Saprativa Bhattacharjee, Pushpak Bhattacharyya, Biplab Banerjee",http://arxiv.org/pdf/2412.20057v1,cs.CL
STAYKATE: Hybrid In-Context Example Selection Combining Representativeness Sampling and Retrieval-based Approach -- A Case Study on Science Domains,"Large language models (LLMs) demonstrate the ability to learn in-context,
offering a potential solution for scientific information extraction, which
often contends with challenges such as insufficient training data and the high
cost of annotation processes. Given that the selection of in-context examples
can significantly impact performance, it is crucial to design a proper method
to sample the efficient ones. In this paper, we propose STAYKATE, a
static-dynamic hybrid selection method that combines the principles of
representativeness sampling from active learning with the prevalent
retrieval-based approach. The results across three domain-specific datasets
indicate that STAYKATE outperforms both the traditional supervised methods and
existing selection methods. The enhancement in performance is particularly
pronounced for entity types that other methods pose challenges.",2024-12-28,"Chencheng Zhu, Kazutaka Shimada, Tomoki Taniguchi, Tomoko Ohkuma",http://arxiv.org/pdf/2412.20043v1,cs.CL
Children's Acquisition of Tail-recursion Sequences: A Review of Locative Recursion and Possessive Recursion as Examples,"Recursion is the nature of human natural language. Since Chomsky proposed
generative grammar, many scholars have studied recursion either theoretically
or empirically. However, by observing children's acquisition of tail recursion
sequences, we can verify the nativism of language supported by universal
grammar and reveal the cognitive mechanism of human brain. To date, our
understanding of children's acquisition path of recursion and influencing
factors still remain controversial. This systematic review summarizes the
research of tail recursive sequence by taking possessive recursion and locative
recursion as examples, focusing on the experimental methods, acquisition paths,
and influencing factors of tail recursive sequence. The current behavioural
experiments reveal that, the debate about children's performance revolves
around: 1) Gradual acquisition or synchronous acquisition. 2) symmetry or
asymmetry between the acquisition of locative recursion sequences and
possessive recursion sequences. We presume that children can acquire recursion
quickly in a short period of time thanks to the language acquisition device,
though there are also scholars who believe that a third factor also plays a
role.",2024-12-28,"Xiaoyi Wang, Chenxi Fu, Caimei Yang, Ziman Zhuang",http://arxiv.org/pdf/2412.20033v1,cs.CL
BaiJia: A Large-Scale Role-Playing Agent Corpus of Chinese Historical Characters,"We introduce a comprehensive large-scale role-playing agent corpus, termed
BaiJia, that comprises various Chinese historical characters. This corpus is
noteworthy for being the pioneering compilation of low-resource data that can
be utilized in large language models (LLMs) to engage in AI-driven historical
role-playing agents. BaiJia addresses the challenges in terms of fragmented
historical textual records in different forms and modalities, integrating
various characters' information, including their biographical, literary, family
relations, historical events, and so on. We conduct extensive experiments to
demonstrate the effectiveness of our BaiJia agent corpus in bolstering the
role-playing abilities of various foundational LLMs, and promoting the
development and assessment of LLMs in the context of historical role-playing
tasks. The agent corpus is available at baijia.online.",2024-12-28,"Ting Bai, Jiazheng Kang, Jiayang Fan",http://arxiv.org/pdf/2412.20024v2,cs.CL
AdvAnchor: Enhancing Diffusion Model Unlearning with Adversarial Anchors,"Security concerns surrounding text-to-image diffusion models have driven
researchers to unlearn inappropriate concepts through fine-tuning. Recent
fine-tuning methods typically align the prediction distributions of unsafe
prompts with those of predefined text anchors. However, these techniques
exhibit a considerable performance trade-off between eliminating undesirable
concepts and preserving other concepts. In this paper, we systematically
analyze the impact of diverse text anchors on unlearning performance. Guided by
this analysis, we propose AdvAnchor, a novel approach that generates
adversarial anchors to alleviate the trade-off issue. These adversarial anchors
are crafted to closely resemble the embeddings of undesirable concepts to
maintain overall model performance, while selectively excluding defining
attributes of these concepts for effective erasure. Extensive experiments
demonstrate that AdvAnchor outperforms state-of-the-art methods. Our code is
publicly available at https://anonymous.4open.science/r/AdvAnchor.",2024-12-28,"Mengnan Zhao, Lihe Zhang, Xingyi Yang, Tianhang Zheng, Baocai Yin",http://arxiv.org/pdf/2501.00054v1,cs.CL
OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System,"We introduce OneKE, a dockerized schema-guided knowledge extraction system,
which can extract knowledge from the Web and raw PDF Books, and support various
domains (science, news, etc.). Specifically, we design OneKE with multiple
agents and a configure knowledge base. Different agents perform their
respective roles, enabling support for various extraction scenarios. The
configure knowledge base facilitates schema configuration, error case debugging
and correction, further improving the performance. Empirical evaluations on
benchmark datasets demonstrate OneKE's efficacy, while case studies further
elucidate its adaptability to diverse tasks across multiple domains,
highlighting its potential for broad applications. We have open-sourced the
Code at https://github.com/zjunlp/OneKE and released a Video at
http://oneke.openkg.cn/demo.mp4.",2024-12-28,"Yujie Luo, Xiangyuan Ru, Kangwei Liu, Lin Yuan, Mengshu Sun, Ningyu Zhang, Lei Liang, Zhiqiang Zhang, Jun Zhou, Lanning Wei, Da Zheng, Haofen Wang, Huajun Chen",http://arxiv.org/pdf/2412.20005v2,cs.CL
From Generalist to Specialist: A Survey of Large Language Models for Chemistry,"Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.",2024-12-28,"Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen",http://arxiv.org/pdf/2412.19994v1,cs.CL
Bridging Context Gaps: Enhancing Comprehension in Long-Form Social Conversations Through Contextualized Excerpts,"We focus on enhancing comprehension in small-group recorded conversations,
which serve as a medium to bring people together and provide a space for
sharing personal stories and experiences on crucial social matters. One way to
parse and convey information from these conversations is by sharing highlighted
excerpts in subsequent conversations. This can help promote a collective
understanding of relevant issues, by highlighting perspectives and experiences
to other groups of people who might otherwise be unfamiliar with and thus
unable to relate to these experiences. The primary challenge that arises then
is that excerpts taken from one conversation and shared in another setting
might be missing crucial context or key elements that were previously
introduced in the original conversation. This problem is exacerbated when
conversations become lengthier and richer in themes and shared experiences. To
address this, we explore how Large Language Models (LLMs) can enrich these
excerpts by providing socially relevant context. We present approaches for
effective contextualization to improve comprehension, readability, and empathy.
We show significant improvements in understanding, as assessed through
subjective and objective evaluations. While LLMs can offer valuable context,
they struggle with capturing key social aspects. We release the Human-annotated
Salient Excerpts (HSE) dataset to support future work. Additionally, we show
how context-enriched excerpts can provide more focused and comprehensive
conversation summaries.",2024-12-28,"Shrestha Mohanty, Sarah Xuan, Jacob Jobraeel, Anurag Kumar, Deb Roy, Jad Kabbara",http://arxiv.org/pdf/2412.19966v1,cs.CL
Leveraging Large Language Models For Optimized Item Categorization using UNSPSC Taxonomy,"Effective item categorization is vital for businesses, enabling the
transformation of unstructured datasets into organized categories that
streamline inventory management. Despite its importance, item categorization
remains highly subjective and lacks a uniform standard across industries and
businesses. The United Nations Standard Products and Services Code (UNSPSC)
provides a standardized system for cataloguing inventory, yet employing UNSPSC
categorizations often demands significant manual effort. This paper
investigates the deployment of Large Language Models (LLMs) to automate the
classification of inventory data into UNSPSC codes based on Item Descriptions.
We evaluate the accuracy and efficiency of LLMs in categorizing diverse
datasets, exploring their language processing capabilities and their potential
as a tool for standardizing inventory classification. Our findings reveal that
LLMs can substantially diminish the manual labor involved in item
categorization while maintaining high accuracy, offering a scalable solution
for businesses striving to enhance their inventory management practices.",2024-12-28,"Anmolika Singh, Yuhang Diao",http://arxiv.org/pdf/2503.04728v1,cs.CL
Seq2Seq Model-Based Chatbot with LSTM and Attention Mechanism for Enhanced User Interaction,"A chatbot is an intelligent software application that automates conversations
and engages users in natural language through messaging platforms. Leveraging
artificial intelligence (AI), chatbots serve various functions, including
customer service, information gathering, and casual conversation. Existing
virtual assistant chatbots, such as ChatGPT and Gemini, demonstrate the
potential of AI in Natural Language Processing (NLP). However, many current
solutions rely on predefined APIs, which can result in vendor lock-in and high
costs. To address these challenges, this work proposes a chatbot developed
using a Sequence-to-Sequence (Seq2Seq) model with an encoder-decoder
architecture that incorporates attention mechanisms and Long Short-Term Memory
(LSTM) cells. By avoiding predefined APIs, this approach ensures flexibility
and cost-effectiveness. The chatbot is trained, validated, and tested on a
dataset specifically curated for the tourism sector in Draa-Tafilalet, Morocco.
Key evaluation findings indicate that the proposed Seq2Seq model-based chatbot
achieved high accuracies: approximately 99.58% in training, 98.03% in
validation, and 94.12% in testing. These results demonstrate the chatbot's
effectiveness in providing relevant and coherent responses within the tourism
domain, highlighting the potential of specialized AI applications to enhance
user experience and satisfaction in niche markets.",2024-12-27,"Lamya Benaddi, Charaf Ouaddi, Adnane Souha, Abdeslam Jakimi, Mohamed Rahouti, Mohammed Aledhari, Diogo Oliveira, Brahim Ouchao",http://arxiv.org/pdf/2501.00049v1,cs.CL
Assessing Text Classification Methods for Cyberbullying Detection on Social Media Platforms,"Cyberbullying significantly contributes to mental health issues in
communities by negatively impacting the psychology of victims. It is a
prevalent problem on social media platforms, necessitating effective, real-time
detection and monitoring systems to identify harmful messages. However, current
cyberbullying detection systems face challenges related to performance, dataset
quality, time efficiency, and computational costs. This research aims to
conduct a comparative study by adapting and evaluating existing text
classification techniques within the cyberbullying detection domain. The study
specifically evaluates the effectiveness and performance of these techniques in
identifying cyberbullying instances on social media platforms. It focuses on
leveraging and assessing large language models, including BERT, RoBERTa, XLNet,
DistilBERT, and GPT-2.0, for their suitability in this domain. The results show
that BERT strikes a balance between performance, time efficiency, and
computational resources: Accuracy of 95%, Precision of 95%, Recall of 95%, F1
Score of 95%, Error Rate of 5%, Inference Time of 0.053 seconds, RAM Usage of
35.28 MB, CPU/GPU Usage of 0.4%, and Energy Consumption of 0.000263 kWh. The
findings demonstrate that generative AI models, while powerful, do not
consistently outperform fine-tuned models on the tested benchmarks. However,
state-of-the-art performance can still be achieved through strategic adaptation
and fine-tuning of existing models for specific datasets and tasks.",2024-12-27,"Adamu Gaston Philipo, Doreen Sebastian Sarwatt, Jianguo Ding, Mahmoud Daneshmand, Huansheng Ning",http://arxiv.org/pdf/2412.19928v1,cs.CL
Right vs. Right: Can LLMs Make Tough Choices?,"An ethical dilemma describes a choice between two ""right"" options involving
conflicting moral values. We present a comprehensive evaluation of how LLMs
navigate ethical dilemmas. Specifically, we investigate LLMs on their (1)
sensitivity in comprehending ethical dilemmas, (2) consistency in moral value
choice, (3) consideration of consequences, and (4) ability to align their
responses to a moral value preference explicitly or implicitly specified in a
prompt. Drawing inspiration from a leading ethical framework, we construct a
dataset comprising 1,730 ethical dilemmas involving four pairs of conflicting
values. We evaluate 20 well-known LLMs from six families. Our experiments
reveal that: (1) LLMs exhibit pronounced preferences between major value pairs,
and prioritize truth over loyalty, community over individual, and long-term
over short-term considerations. (2) The larger LLMs tend to support a
deontological perspective, maintaining their choices of actions even when
negative consequences are specified. (3) Explicit guidelines are more effective
in guiding LLMs' moral choice than in-context examples. Lastly, our experiments
highlight the limitation of LLMs in comprehending different formulations of
ethical dilemmas.",2024-12-27,"Jiaqing Yuan, Pradeep K. Murukannaiah, Munindar P. Singh",http://arxiv.org/pdf/2412.19926v1,cs.CL
HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models,"Large Language Models (LLMs) have revolutionized natural language processing
by understanding and generating human-like text. However, the increasing demand
for more sophisticated LLMs presents significant computational challenges due
to their scale and complexity. This paper introduces Hardware Accelerated
Decoding (HADES), a novel approach to enhance the performance and energy
efficiency of LLMs. We address the design of an LLM accelerator with
hardware-level speculative decoding support, a concept not previously explored
in existing literature. Our work demonstrates how speculative decoding can
significantly improve the efficiency of LLM operations, paving the way for more
advanced and practical applications of these models.",2024-12-27,"Ze Yang, Yihong Jin, Xinhe Xu",http://arxiv.org/pdf/2412.19925v2,cs.CL
Evaluate Summarization in Fine-Granularity: Auto Evaluation with LLM,"Due to the exponential growth of information and the need for efficient
information consumption the task of summarization has gained paramount
importance. Evaluating summarization accurately and objectively presents
significant challenges, particularly when dealing with long and unstructured
texts rich in content. Existing methods, such as ROUGE (Lin, 2004) and
embedding similarities, often yield scores that have low correlation with human
judgements and are also not intuitively understandable, making it difficult to
gauge the true quality of the summaries. LLMs can mimic human in giving
subjective reviews but subjective scores are hard to interpret and justify.
They can be easily manipulated by altering the models and the tones of the
prompts. In this paper, we introduce a novel evaluation methodology and tooling
designed to address these challenges, providing a more comprehensive, accurate
and interpretable assessment of summarization outputs. Our method (SumAutoEval)
proposes and evaluates metrics at varying granularity levels, giving objective
scores on 4 key dimensions such as completeness, correctness, Alignment and
readability. We empirically demonstrate, that SumAutoEval enhances the
understanding of output quality with better human correlation.",2024-12-27,"Dong Yuan, Eti Rastogi, Fen Zhao, Sagar Goyal, Gautam Naik, Sree Prasanna Rajagopal",http://arxiv.org/pdf/2412.19906v1,cs.CL
InfAlign: Inference-aware language model alignment,"Language model alignment is a critical step in training modern generative
language models. Alignment targets to improve win rate of a sample from the
aligned model against the base model. Today, we are increasingly using
inference-time algorithms (e.g., Best-of-N, controlled decoding, tree search)
to decode from language models rather than standard sampling. We show that this
train/test mismatch makes standard RLHF framework sub-optimal in view of such
inference-time methods. To this end, we propose a framework for inference-aware
alignment (InfAlign), which aims to optimize inference-time win rate of the
aligned policy against the base model. We prove that for any inference-time
decoding procedure, the optimal aligned policy is the solution to the standard
RLHF problem with a transformation of the reward. This motivates us to provide
the calibrate-and-transform RL (InfAlign-CTRL) algorithm to solve this problem,
which involves a reward calibration step and a KL-regularized reward
maximization step with a transformation of the calibrated reward. For best-of-N
sampling and best-of-N jailbreaking, we propose specific transformations
offering up to 3-8% improvement on inference-time win rates. Finally, we also
show that our proposed reward calibration method is a strong baseline for
optimizing standard win rate.",2024-12-27,"Ananth Balashankar, Ziteng Sun, Jonathan Berant, Jacob Eisenstein, Michael Collins, Adrian Hutter, Jong Lee, Chirag Nagpal, Flavien Prost, Aradhana Sinha, Ananda Theertha Suresh, Ahmad Beirami",http://arxiv.org/pdf/2412.19792v3,cs.CL
Enhancing Whisper's Accuracy and Speed for Indian Languages through Prompt-Tuning and Tokenization,"Automatic speech recognition has recently seen a significant advancement with
large foundational models such as Whisper. However, these models often struggle
to perform well in low-resource languages, such as Indian languages. This paper
explores two novel approaches to enhance Whisper's multilingual speech
recognition performance in Indian languages. First, we propose prompt-tuning
with language family information, which enhances Whisper's accuracy in
linguistically similar languages. Second, we introduce a novel tokenizer that
reduces the number of generated tokens, thereby accelerating Whisper's
inference speed. Our extensive experiments demonstrate that the tokenizer
significantly reduces inference time, while prompt-tuning enhances accuracy
across various Whisper model sizes, including Small, Medium, and Large.
Together, these techniques achieve a balance between optimal WER and inference
speed.",2024-12-27,"Kumud Tripathi, Raj Gothi, Pankaj Wasnik",http://arxiv.org/pdf/2412.19785v1,cs.CL
Machine Learning for Sentiment Analysis of Imported Food in Trinidad and Tobago,"This research investigates the performance of various machine learning
algorithms (CNN, LSTM, VADER, and RoBERTa) for sentiment analysis of Twitter
data related to imported food items in Trinidad and Tobago. The study addresses
three primary research questions: the comparative accuracy and efficiency of
the algorithms, the optimal configurations for each model, and the potential
applications of the optimized models in a live system for monitoring public
sentiment and its impact on the import bill. The dataset comprises tweets from
2018 to 2024, divided into imbalanced, balanced, and temporal subsets to assess
the impact of data balancing and the COVID-19 pandemic on sentiment trends. Ten
experiments were conducted to evaluate the models under various configurations.
Results indicated that VADER outperformed the other models in both multi-class
and binary sentiment classifications. The study highlights significant changes
in sentiment trends pre- and post-COVID-19, with implications for import
policies.",2024-12-27,"Cassandra Daniels, Koffka Khan",http://arxiv.org/pdf/2412.19781v1,cs.CL
Cross-Linguistic Examination of Machine Translation Transfer Learning,"This study investigates the effectiveness of transfer learning in machine
translation across diverse linguistic families by evaluating five distinct
language pairs. Leveraging pre-trained models on high-resource languages, these
models were fine-tuned on low-resource languages, examining variations in
hyperparameters such as learning rate, batch size, number of epochs, and weight
decay. The research encompasses language pairs from different linguistic
backgrounds: Semitic (Modern Standard Arabic - Levantine Arabic), Bantu (Hausa
- Zulu), Romance (Spanish - Catalan), Slavic (Slovakian - Macedonian), and
language isolates (Eastern Armenian - Western Armenian). Results demonstrate
that transfer learning is effective across different language families,
although the impact of hyperparameters varies. A moderate batch size (e.g., 32)
is generally more effective, while very high learning rates can disrupt model
training. The study highlights the universality of transfer learning in
multilingual contexts and suggests that consistent hyperparameter settings can
simplify and enhance the efficiency of multilingual model training.",2024-12-27,Saughmon Boujkian,http://arxiv.org/pdf/2501.00045v1,cs.CL
OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis,"Graphical User Interface (GUI) agents powered by Vision-Language Models
(VLMs) have demonstrated human-like computer control capability. Despite their
utility in advancing digital automation, a critical bottleneck persists:
collecting high-quality trajectory data for training. Common practices for
collecting such data rely on human supervision or synthetic data generation
through executing pre-defined tasks, which are either resource-intensive or
unable to guarantee data quality. Moreover, these methods suffer from limited
data diversity and significant gaps between synthetic data and real-world
environments. To address these challenges, we propose OS-Genesis, a novel GUI
data synthesis pipeline that reverses the conventional trajectory collection
process. Instead of relying on pre-defined tasks, OS-Genesis enables agents
first to perceive environments and perform step-wise interactions, then
retrospectively derive high-quality tasks to enable trajectory-level
exploration. A trajectory reward model is then employed to ensure the quality
of the generated trajectories. We demonstrate that training GUI agents with
OS-Genesis significantly improves their performance on highly challenging
online benchmarks. In-depth analysis further validates OS-Genesis's efficiency
and its superior data quality and diversity compared to existing synthesis
methods. Our codes, data, and checkpoints are available at
https://qiushisun.github.io/OS-Genesis-Home/.",2024-12-27,"Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu",http://arxiv.org/pdf/2412.19723v2,cs.CL
Toward Adaptive Reasoning in Large Language Models with Thought Rollback,"Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.",2024-12-27,"Sijia Chen, Baochun Li",http://arxiv.org/pdf/2412.19707v1,cs.CL
Long Context vs. RAG for LLMs: An Evaluation and Revisits,"Extending context windows (i.e., Long Context, LC) and using retrievers to
selectively access relevant information (i.e., Retrieval-Augmented Generation,
RAG) are the two main strategies to enable LLMs to incorporate extremely long
external contexts. This paper revisits recent studies on this topic,
highlighting their key insights and discrepancies. We then provide a more
comprehensive evaluation by filtering out questions answerable without external
context, identifying the most effective retrieval methods, and expanding the
datasets. We show that LC generally outperforms RAG in question-answering
benchmarks, especially for Wikipedia-based questions. Summarization-based
retrieval performs comparably to LC, while chunk-based retrieval lags behind.
However, RAG has advantages in dialogue-based and general question queries.
These insights underscore the trade-offs between RAG and LC strategies,
offering guidance for future optimization of LLMs with external knowledge
sources. We also provide an in-depth discussion on this topic, highlighting the
overlooked importance of context relevance in existing studies.",2024-12-27,"Xinze Li, Yixin Cao, Yubo Ma, Aixin Sun",http://arxiv.org/pdf/2501.01880v1,cs.CL
Machine Generated Product Advertisements: Benchmarking LLMs Against Human Performance,"This study compares the performance of AI-generated and human-written product
descriptions using a multifaceted evaluation model. We analyze descriptions for
100 products generated by four AI models (Gemma 2B, LLAMA, GPT2, and ChatGPT 4)
with and without sample descriptions, against human-written descriptions. Our
evaluation metrics include sentiment, readability, persuasiveness, Search
Engine Optimization(SEO), clarity, emotional appeal, and call-to-action
effectiveness. The results indicate that ChatGPT 4 performs the best. In
contrast, other models demonstrate significant shortcomings, producing
incoherent and illogical output that lacks logical structure and contextual
relevance. These models struggle to maintain focus on the product being
described, resulting in disjointed sentences that do not convey meaningful
information. This research provides insights into the current capabilities and
limitations of AI in the creation of content for e-Commerce.",2024-12-27,Sanjukta Ghosh,http://arxiv.org/pdf/2412.19610v1,cs.CL
A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models,"Machine Unlearning has emerged as a critical area in artificial intelligence,
addressing the need to selectively remove learned data from machine learning
models in response to data privacy regulations. This paper provides a
comprehensive comparative analysis of six state-of-theart unlearning techniques
applied to image and text classification tasks. We evaluate their performance,
efficiency, and compliance with regulatory requirements, highlighting their
strengths and limitations in practical scenarios. By systematically analyzing
these methods, we aim to provide insights into their applicability,
challenges,and tradeoffs, fostering advancements in the field of ethical and
adaptable machine learning.",2024-12-27,"Omar M. Safa, Mahmoud M. Abdelaziz, Mustafa Eltawy, Mohamed Mamdouh, Moamen Gharib, Salaheldin Eltenihy, Nagia M. Ghanem, Mohamed M. Ismail",http://arxiv.org/pdf/2412.19583v1,cs.CL
TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data,"Semantic parsing, which converts natural language questions into logic forms,
plays a crucial role in reasoning within structured environments. However,
existing methods encounter two significant challenges: reliance on extensive
manually annotated datasets and limited generalization capability to unseen
examples. To tackle these issues, we propose Targeted Synthetic Data Generation
(TARGA), a practical framework that dynamically generates high-relevance
synthetic data without manual annotation. Starting from the pertinent entities
and relations of a given question, we probe for the potential relevant queries
through layer-wise expansion and cross-layer combination. Then we generate
corresponding natural language questions for these constructed queries to
jointly serve as the synthetic demonstrations for in-context learning.
Experiments on multiple knowledge base question answering (KBQA) datasets
demonstrate that TARGA, using only a 7B-parameter model, substantially
outperforms existing non-fine-tuned methods that utilize close-sourced model,
achieving notable improvements in F1 scores on GrailQA(+7.7) and
KBQA-Agent(+12.2). Furthermore, TARGA also exhibits superior sample efficiency,
robustness, and generalization capabilities under non-I.I.D. settings.",2024-12-27,"Xiang Huang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiaxia Wang, Yuzhong Qu",http://arxiv.org/pdf/2412.19544v1,cs.CL
Exploiting Domain-Specific Parallel Data on Multilingual Language Models for Low-resource Language Translation,"Neural Machine Translation (NMT) systems built on multilingual
sequence-to-sequence Language Models (msLMs) fail to deliver expected results
when the amount of parallel data for a language, as well as the language's
representation in the model are limited. This restricts the capabilities of
domain-specific NMT systems for low-resource languages (LRLs). As a solution,
parallel data from auxiliary domains can be used either to fine-tune or to
further pre-train the msLM. We present an evaluation of the effectiveness of
these two techniques in the context of domain-specific LRL-NMT. We also explore
the impact of domain divergence on NMT model performance. We recommend several
strategies for utilizing auxiliary parallel data in building domain-specific
NMT models for LRLs.",2024-12-27,"Surangika Ranathungaa, Shravan Nayak, Shih-Ting Cindy Huang, Yanke Mao, Tong Su, Yun-Hsiang Ray Chan, Songchen Yuan, Anthony Rinaldi, Annie En-Shiun Lee",http://arxiv.org/pdf/2412.19522v1,cs.CL
Confidence v.s. Critique: A Decomposition of Self-Correction Capability for LLMs,"Large Language Models (LLMs) can correct their self-generated responses, but
a decline in accuracy after self-correction is also witnessed. To have a deeper
understanding of self-correction, we endeavor to decompose, evaluate, and
analyze the self-correction behaviors of LLMs. By enumerating and analyzing
answer correctness before and after self-correction, we decompose the
self-correction capability into confidence (being confident to correct answers)
and critique (turning wrong answers to correct) capabilities, and propose two
metrics from a probabilistic perspective to measure these 2 capabilities, along
with another metric for overall self-correction capability evaluation. Based on
our decomposition and evaluation metrics, we conduct extensive experiments and
draw some empirical conclusions. For example, we find different models can
exhibit distinct behaviors: some models are confident while others are more
critical. We also find the trade-off between the two capabilities (i.e.
improving one can lead to a decline in the other) when manipulating model
self-correction behavior by prompts or in-context learning. Further, we find a
simple yet efficient strategy to improve self-correction capability by
transforming Supervision Fine-Tuning (SFT) data format, and our strategy
outperforms vanilla SFT in both capabilities and achieves much higher accuracy
after self-correction. Our code will be publicly available on GitHub.",2024-12-27,"Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui",http://arxiv.org/pdf/2412.19513v1,cs.CL
Safeguard Fine-Tuned LLMs Through Pre- and Post-Tuning Model Merging,"Fine-tuning large language models (LLMs) for downstream tasks is a widely
adopted approach, but it often leads to safety degradation in safety-aligned
LLMs. Currently, many solutions address this issue by incorporating additional
safety data, which can be impractical in many cases. In this paper, we address
the question: How can we improve downstream task performance while preserving
safety in LLMs without relying on additional safety data? We propose a simple
and effective method that maintains the inherent safety of LLMs while enhancing
their downstream task performance: merging the weights of pre- and
post-fine-tuned safety-aligned models. Experimental results across various
downstream tasks, models, and merging methods demonstrate that this approach
effectively mitigates safety degradation while improving downstream task
performance, offering a practical solution for adapting safety-aligned LLMs.",2024-12-27,"Hua Farn, Hsuan Su, Shachi H Kumar, Saurav Sahay, Shang-Tse Chen, Hung-yi Lee",http://arxiv.org/pdf/2412.19512v1,cs.CL
User Willingness-aware Sales Talk Dataset,"User willingness is a crucial element in the sales talk process that affects
the achievement of the salesperson's or sales system's objectives. Despite the
importance of user willingness, to the best of our knowledge, no previous study
has addressed the development of automated sales talk dialogue systems that
explicitly consider user willingness. A major barrier is the lack of sales talk
datasets with reliable user willingness data. Thus, in this study, we developed
a user willingness-aware sales talk collection by leveraging the ecological
validity concept, which is discussed in the field of human-computer
interaction. Our approach focused on three types of user willingness essential
in real sales interactions. We created a dialogue environment that closely
resembles real-world scenarios to elicit natural user willingness, with
participants evaluating their willingness at the utterance level from multiple
perspectives. We analyzed the collected data to gain insights into practical
user willingness-aware sales talk strategies. In addition, as a practical
application of the constructed dataset, we developed and evaluated a sales
dialogue system aimed at enhancing the user's intent to purchase.",2024-12-27,"Asahi Hentona, Jun Baba, Shiki Sato, Reina Akama",http://arxiv.org/pdf/2412.19490v1,cs.CL
"Pre-training, Fine-tuning and Re-ranking: A Three-Stage Framework for Legal Question Answering","Legal question answering (QA) has attracted increasing attention from people
seeking legal advice, which aims to retrieve the most applicable answers from a
large-scale database of question-answer pairs. Previous methods mainly use a
dual-encoder architecture to learn dense representations of both questions and
answers. However, these methods could suffer from lacking domain knowledge and
sufficient labeled training data. In this paper, we propose a three-stage
(\underline{p}re-training, \underline{f}ine-tuning and \underline{r}e-ranking)
framework for \underline{l}egal \underline{QA} (called PFR-LQA), which promotes
the fine-grained text representation learning and boosts the performance of
dense retrieval with the dual-encoder architecture. Concretely, we first
conduct domain-specific pre-training on legal questions and answers through a
self-supervised training objective, allowing the pre-trained model to be
adapted to the legal domain. Then, we perform task-specific fine-tuning of the
dual-encoder on legal question-answer pairs by using the supervised learning
objective, leading to a high-quality dual-encoder for the specific downstream
QA task. Finally, we employ a contextual re-ranking objective to further refine
the output representations of questions produced by the document encoder, which
uses contextual similarity to increase the discrepancy between the anchor and
hard negative samples for better question re-ranking. We conduct extensive
experiments on a manually annotated legal QA dataset. Experimental results show
that our PFR-LQA method achieves better performance than the strong competitors
for legal question answering.",2024-12-27,"Shiwen Ni, Hao Cheng, Min Yang",http://arxiv.org/pdf/2412.19482v1,cs.CL
Feature Alignment-Based Knowledge Distillation for Efficient Compression of Large Language Models,"This study proposes a knowledge distillation algorithm based on large
language models and feature alignment, aiming to effectively transfer the
knowledge of large pre-trained models into lightweight student models, thereby
reducing computational costs while maintaining high model performance.
Different from the traditional soft label distillation method, this method
introduces a multi-layer feature alignment strategy to deeply align the
intermediate features and attention mechanisms of the teacher model and the
student model, maximally retaining the semantic expression ability and context
modeling ability of the teacher model. In terms of method design, a multi-task
loss function is constructed, including feature matching loss, attention
alignment loss, and output distribution matching loss, to ensure multi-level
information transfer through joint optimization. The experiments were
comprehensively evaluated on the GLUE data set and various natural language
processing tasks. The results show that the proposed model performs very close
to the state-of-the-art GPT-4 model in terms of evaluation indicators such as
perplexity, BLEU, ROUGE, and CER. At the same time, it far exceeds baseline
models such as DeBERTa, XLNet, and GPT-3, showing significant performance
improvements and computing efficiency advantages. Research results show that
the feature alignment distillation strategy is an effective model compression
method that can significantly reduce computational overhead and storage
requirements while maintaining model capabilities. Future research can be
further expanded in the directions of self-supervised learning, cross-modal
feature alignment, and multi-task transfer learning to provide more flexible
and efficient solutions for the deployment and optimization of deep learning
models.",2024-12-27,"Shuo Wang, Chihang Wang, Jia Gao, Zhen Qi, Hongye Zheng, Xiaoxuan Liao",http://arxiv.org/pdf/2412.19449v1,cs.CL
DeepSeek-V3 Technical Report,"We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with
671B total parameters with 37B activated for each token. To achieve efficient
inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent
Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated
in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free
strategy for load balancing and sets a multi-token prediction training
objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion
diverse and high-quality tokens, followed by Supervised Fine-Tuning and
Reinforcement Learning stages to fully harness its capabilities. Comprehensive
evaluations reveal that DeepSeek-V3 outperforms other open-source models and
achieves performance comparable to leading closed-source models. Despite its
excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its
full training. In addition, its training process is remarkably stable.
Throughout the entire training process, we did not experience any irrecoverable
loss spikes or perform any rollbacks. The model checkpoints are available at
https://github.com/deepseek-ai/DeepSeek-V3.",2024-12-27,"DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S. S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan, T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W. L. Xiao, Wangding Zeng, Wanjia Zhao, Wei An, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, X. Q. Li, Xiangyue Jin, Xianzu Wang, Xiao Bi, Xiaodong Liu, Xiaohan Wang, Xiaojin Shen, Xiaokang Chen, Xiaokang Zhang, Xiaosha Chen, Xiaotao Nie, Xiaowen Sun, Xiaoxiang Wang, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xingkai Yu, Xinnan Song, Xinxia Shan, Xinyi Zhou, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. X. Zhu, Yang Zhang, Yanhong Xu, Yanhong Xu, Yanping Huang, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Li, Yaohui Wang, Yi Yu, Yi Zheng, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Ying Tang, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yu Wu, Yuan Ou, Yuchen Zhu, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yukun Zha, Yunfan Xiong, Yunxian Ma, Yuting Yan, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Z. F. Wu, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhen Huang, Zhen Zhang, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhibin Gou, Zhicheng Ma, Zhigang Yan, Zhihong Shao, Zhipeng Xu, Zhiyu Wu, Zhongyu Zhang, Zhuoshu Li, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Ziyi Gao, Zizheng Pan",http://arxiv.org/pdf/2412.19437v2,cs.CL
Dynamic Skill Adaptation for Large Language Models,"We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework
to adapt novel and complex skills to Large Language Models (LLMs). Compared
with previous work which learns from human-curated and static data in random
orders, we propose to first automatically generate and organize the training
data by mimicking the learning pathways of human and then dynamically tailor
the training data based on the training dynamics. Specifically, inspired by the
learning structures and teaching strategies in the human education system, we
first construct a skill graph by decomposing complex skills into sub-skills and
arranging them based on their dependencies in human syllables. For every skill,
we utilize LLMs to generate both textbook-like data which contains detailed
descriptions of skills for pre-training and exercise-like data which targets at
explicitly utilizing the skills to solve problems for instruction-tuning.
Furthermore, during the instruction-tuning, we dynamically update the training
data which down-weight easy-to-learn examples, generate more complex examples,
and filter out data with errors. Experiments on large language models such as
LLAMA and Mistral demonstrate the effectiveness of our proposed methods in
adapting math reasoning skills and social study skills.",2024-12-26,"Jiaao Chen, Diyi Yang",http://arxiv.org/pdf/2412.19361v1,cs.CL
ETTA: Elucidating the Design Space of Text-to-Audio Models,"Recent years have seen significant progress in Text-To-Audio (TTA) synthesis,
enabling users to enrich their creative workflows with synthetic audio
generated from natural language prompts. Despite this progress, the effects of
data, model architecture, training objective functions, and sampling strategies
on target benchmarks are not well understood. With the purpose of providing a
holistic understanding of the design space of TTA models, we set up a
large-scale empirical experiment focused on diffusion and flow matching models.
Our contributions include: 1) AF-Synthetic, a large dataset of high quality
synthetic captions obtained from an audio understanding model; 2) a systematic
comparison of different architectural, training, and inference design choices
for TTA models; 3) an analysis of sampling methods and their Pareto curves with
respect to generation quality and inference speed. We leverage the knowledge
obtained from this extensive analysis to propose our best model dubbed
Elucidated Text-To-Audio (ETTA). When evaluated on AudioCaps and MusicCaps,
ETTA provides improvements over the baselines trained on publicly available
data, while being competitive with models trained on proprietary data. Finally,
we show ETTA's improved ability to generate creative audio following complex
and imaginative captions -- a task that is more challenging than current
benchmarks.",2024-12-26,"Sang-gil Lee, Zhifeng Kong, Arushi Goel, Sungwon Kim, Rafael Valle, Bryan Catanzaro",http://arxiv.org/pdf/2412.19351v1,cs.CL
On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages,"Selective state-space models (SSMs) are an emerging alternative to the
Transformer, offering the unique advantage of parallel training and sequential
inference. Although these models have shown promising performance on a variety
of tasks, their formal expressiveness and length generalization properties
remain underexplored. In this work, we provide insight into the workings of
selective SSMs by analyzing their expressiveness and length generalization
performance on regular language tasks, i.e., finite-state automaton (FSA)
emulation. We address certain limitations of modern SSM-based architectures by
introducing the Selective Dense State-Space Model (SD-SSM), the first selective
SSM that exhibits perfect length generalization on a set of various regular
language tasks using a single layer. It utilizes a dictionary of dense
transition matrices, a softmax selection mechanism that creates a convex
combination of dictionary matrices at each time step, and a readout consisting
of layer normalization followed by a linear map. We then proceed to evaluate
variants of diagonal selective SSMs by considering their empirical performance
on commutative and non-commutative automata. We explain the experimental
results with theoretical considerations. Our code is available at
https://github.com/IBM/selective-dense-state-space-model.",2024-12-26,"Aleksandar Terzić, Michael Hersche, Giacomo Camposampiero, Thomas Hofmann, Abu Sebastian, Abbas Rahimi",http://arxiv.org/pdf/2412.19350v1,cs.CL
Semi-Supervised Learning from Small Annotated Data and Large Unlabeled Data for Fine-grained PICO Entity Recognition,"Objective: Extracting PICO elements -- Participants, Intervention,
Comparison, and Outcomes -- from clinical trial literature is essential for
clinical evidence retrieval, appraisal, and synthesis. Existing approaches do
not distinguish the attributes of PICO entities. This study aims to develop a
named entity recognition (NER) model to extract PICO entities with fine
granularities.
  Materials and Methods: Using a corpus of 2,511 abstracts with PICO mentions
from 4 public datasets, we developed a semi-supervised method to facilitate the
training of a NER model, FinePICO, by combining limited annotated data of PICO
entities and abundant unlabeled data. For evaluation, we divided the entire
dataset into two subsets: a smaller group with annotations and a larger group
without annotations. We then established the theoretical lower and upper
performance bounds based on the performance of supervised learning models
trained solely on the small, annotated subset and on the entire set with
complete annotations, respectively. Finally, we evaluated FinePICO on both the
smaller annotated subset and the larger, initially unannotated subset. We
measured the performance of FinePICO using precision, recall, and F1.
  Results: Our method achieved precision/recall/F1 of 0.567/0.636/0.60,
respectively, using a small set of annotated samples, outperforming the
baseline model (F1: 0.437) by more than 16\%. The model demonstrates
generalizability to a different PICO framework and to another corpus, which
consistently outperforms the benchmark in diverse experimental settings
(p-value \textless0.001).
  Conclusion: This study contributes a generalizable and effective
semi-supervised approach to named entity recognition leveraging large unlabeled
data together with small, annotated data. It also initially supports
fine-grained PICO extraction.",2024-12-26,"Fangyi Chen, Gongbo Zhang, Yilu Fang, Yifan Peng, Chunhua Weng",http://arxiv.org/pdf/2412.19346v1,cs.CL
ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning,"Recent lightweight image captioning models using retrieved data mainly focus
on text prompts. However, previous works only utilize the retrieved text as
text prompts, and the visual information relies only on the CLIP visual
embedding. Because of this issue, there is a limitation that the image
descriptions inherent in the prompt are not sufficiently reflected in the
visual embedding space. To tackle this issue, we propose ViPCap, a novel
retrieval text-based visual prompt for lightweight image captioning. ViPCap
leverages the retrieved text with image information as visual prompts to
enhance the ability of the model to capture relevant visual information. By
mapping text prompts into the CLIP space and generating multiple randomized
Gaussian distributions, our method leverages sampling to explore randomly
augmented distributions and effectively retrieves the semantic features that
contain image information. These retrieved features are integrated into the
image and designated as the visual prompt, leading to performance improvements
on the datasets such as COCO, Flickr30k, and NoCaps. Experimental results
demonstrate that ViPCap significantly outperforms prior lightweight captioning
models in efficiency and effectiveness, demonstrating the potential for a
plug-and-play solution. The source code is available at
https://github.com/taewhankim/VIPCAP.",2024-12-26,"Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim",http://arxiv.org/pdf/2412.19289v3,cs.CL
Optimizing Multi-Stage Language Models for Effective Text Retrieval,"Efficient text retrieval is critical for applications such as legal document
analysis, particularly in specialized contexts like Japanese legal systems.
Existing retrieval methods often underperform in such domain-specific
scenarios, necessitating tailored approaches. In this paper, we introduce a
novel two-phase text retrieval pipeline optimized for Japanese legal datasets.
Our method leverages advanced language models to achieve state-of-the-art
performance, significantly improving retrieval efficiency and accuracy. To
further enhance robustness and adaptability, we incorporate an ensemble model
that integrates multiple retrieval strategies, resulting in superior outcomes
across diverse tasks. Extensive experiments validate the effectiveness of our
approach, demonstrating strong performance on both Japanese legal datasets and
widely recognized benchmarks like MS-MARCO. Our work establishes new standards
for text retrieval in domain-specific and general contexts, providing a
comprehensive solution for addressing complex queries in legal and multilingual
environments.",2024-12-26,"Quang Hoang Trung, Le Trung Hoang, Nguyen Van Hoang Phuc",http://arxiv.org/pdf/2412.19265v1,cs.CL
MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes,"Several studies showed that Large Language Models (LLMs) can answer medical
questions correctly, even outperforming the average human score in some medical
exams. However, to our knowledge, no study has been conducted to assess the
ability of language models to validate existing or generated medical text for
correctness and consistency. In this paper, we introduce MEDEC
(https://github.com/abachaa/MEDEC), the first publicly available benchmark for
medical error detection and correction in clinical notes, covering five types
of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal
Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes
from three US hospital systems that were not previously seen by any LLM. The
dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen
participating systems [Ben Abacha et al., 2024]. In this paper, we describe the
data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,
Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and
correcting medical errors requiring both medical knowledge and reasoning
capabilities. We also conducted a comparative study where two medical doctors
performed the same task on the MEDEC test set. The results showed that MEDEC is
a sufficiently challenging benchmark to assess the ability of models to
validate existing or generated notes and to correct medical errors. We also
found that although recent LLMs have a good performance in error detection and
correction, they are still outperformed by medical doctors in these tasks. We
discuss the potential factors behind this gap, the insights from our
experiments, the limitations of current evaluation metrics, and share potential
pointers for future research.",2024-12-26,"Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin",http://arxiv.org/pdf/2412.19260v2,cs.CL
Multi-matrix Factorization Attention,"We propose novel attention architectures, Multi-matrix Factorization
Attention (MFA) and MFA-Key-Reuse (MFA-KR). Existing variants for standard
Multi-Head Attention (MHA), including SOTA methods like MLA, fail to maintain
as strong performance under stringent Key-Value cache (KV cache) constraints.
MFA enhances model capacity by efficiently scaling up both the number and
dimension of attention heads through low-rank matrix factorization in the
Query-Key (QK) circuit. Extending MFA, MFA-KR further reduces memory
requirements by repurposing the key cache as value through value projection
re-parameterization. MFA's design enables strong model capacity when working
under tight KV cache budget, while MFA-KR is suitable for even harsher KV cache
limits with minor performance trade-off. Notably, in our extensive and
large-scale experiments, the proposed architecture outperforms MLA and performs
comparably to MHA, while reducing KV cache usage by up to 56% and 93.7%,
respectively.",2024-12-26,"Jingcheng Hu, Houyi Li, Yinmin Zhang, Zili Wang, Shuigeng Zhou, Xiangyu Zhang, Heung-Yeung Shum, Daxin Jiang",http://arxiv.org/pdf/2412.19255v2,cs.CL
Multi-Head Attention Driven Dynamic Visual-Semantic Embedding for Enhanced Image-Text Matching,"With the rapid development of multimodal learning, the image-text matching
task, as a bridge connecting vision and language, has become increasingly
important. Based on existing research, this study proposes an innovative visual
semantic embedding model, Multi-Headed Consensus-Aware Visual-Semantic
Embedding (MH-CVSE). This model introduces a multi-head self-attention
mechanism based on the consensus-aware visual semantic embedding model (CVSE)
to capture information in multiple subspaces in parallel, significantly
enhancing the model's ability to understand and represent the complex
relationship between images and texts. In addition, we adopt a parameterized
feature fusion strategy to flexibly integrate feature information at different
levels, further improving the model's expressive power. In terms of loss
function design, the MH-CVSE model adopts a dynamic weight adjustment strategy
to dynamically adjust the weight according to the loss value itself, so that
the model can better balance the contribution of different loss terms during
training. At the same time, we introduce a cosine annealing learning rate
strategy to help the model converge more stably in the later stages of
training. Extensive experimental verification on the Flickr30k dataset shows
that the MH-CVSE model achieves better performance than previous methods in
both bidirectional image and text retrieval tasks, fully demonstrating its
effectiveness and superiority.",2024-12-26,Wenjing Chen,http://arxiv.org/pdf/2412.19184v1,cs.CL
Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval,"Cross-modal (e.g. image-text, video-text) retrieval is an important task in
information retrieval and multimodal vision-language understanding field.
Temporal understanding makes video-text retrieval more challenging than
image-text retrieval. However, we find that the widely used video-text
benchmarks have shortcomings in comprehensively assessing abilities of models,
especially in temporal understanding, causing large-scale image-text
pre-trained models can already achieve comparable zero-shot performance with
video-text pre-trained models. In this paper, we introduce RTime, a novel
temporal-emphasized video-text retrieval dataset. We first obtain videos of
actions or events with significant temporality, and then reverse these videos
to create harder negative samples. We then recruit annotators to judge the
significance and reversibility of candidate videos, and write captions for
qualified videos. We further adopt GPT-4 to extend more captions based on
human-written captions. Our RTime dataset currently consists of 21k videos with
10 captions per video, totalling about 122 hours. Based on RTime, we propose
three retrieval benchmark tasks: RTime-Origin, RTime-Hard, and RTime-Binary. We
further enhance the use of harder-negatives in model training, and benchmark a
variety of video-text models on RTime. Extensive experiment analysis proves
that RTime indeed poses new and higher challenges to video-text retrieval. We
release our RTime
dataset\footnote{\url{https://github.com/qyr0403/Reversed-in-Time}} to further
advance video-text retrieval and multimodal understanding research.",2024-12-26,"Yang Du, Yuqi Liu, Qin Jin",http://arxiv.org/pdf/2412.19178v1,cs.CL
GFG -- Gender-Fair Generation: A CALAMITA Challenge,"Gender-fair language aims at promoting gender equality by using terms and
expressions that include all identities and avoid reinforcing gender
stereotypes. Implementing gender-fair strategies is particularly challenging in
heavily gender-marked languages, such as Italian. To address this, the
Gender-Fair Generation challenge intends to help shift toward gender-fair
language in written communication. The challenge, designed to assess and
monitor the recognition and generation of gender-fair language in both mono-
and cross-lingual scenarios, includes three tasks: (1) the detection of
gendered expressions in Italian sentences, (2) the reformulation of gendered
expressions into gender-fair alternatives, and (3) the generation of
gender-fair language in automatic translation from English to Italian. The
challenge relies on three different annotated datasets: the GFL-it corpus,
which contains Italian texts extracted from administrative documents provided
by the University of Brescia; GeNTE, a bilingual test set for gender-neutral
rewriting and translation built upon a subset of the Europarl dataset; and
Neo-GATE, a bilingual test set designed to assess the use of non-binary
neomorphemes in Italian for both fair formulation and translation tasks.
Finally, each task is evaluated with specific metrics: average of F1-score
obtained by means of BERTScore computed on each entry of the datasets for task
1, an accuracy measured with a gender-neutral classifier, and a
coverage-weighted accuracy for tasks 2 and 3.",2024-12-26,"Simona Frenda, Andrea Piergentili, Beatrice Savoldi, Marco Madeddu, Martina Rosola, Silvia Casola, Chiara Ferrando, Viviana Patti, Matteo Negri, Luisa Bentivogli",http://arxiv.org/pdf/2412.19168v2,cs.CL
Referencing Where to Focus: Improving VisualGrounding with Referential Query,"Visual Grounding aims to localize the referring object in an image given a
natural language expression. Recent advancements in DETR-based visual grounding
methods have attracted considerable attention, as they directly predict the
coordinates of the target object without relying on additional efforts, such as
pre-generated proposal candidates or pre-defined anchor boxes. However,
existing research primarily focuses on designing stronger multi-modal decoder,
which typically generates learnable queries by random initialization or by
using linguistic embeddings. This vanilla query generation approach inevitably
increases the learning difficulty for the model, as it does not involve any
target-related information at the beginning of decoding. Furthermore, they only
use the deepest image feature during the query learning process, overlooking
the importance of features from other levels. To address these issues, we
propose a novel approach, called RefFormer. It consists of the query adaption
module that can be seamlessly integrated into CLIP and generate the referential
query to provide the prior context for decoder, along with a task-specific
decoder. By incorporating the referential query into the decoder, we can
effectively mitigate the learning difficulty of the decoder, and accurately
concentrate on the target object. Additionally, our proposed query adaption
module can also act as an adapter, preserving the rich knowledge within CLIP
without the need to tune the parameters of the backbone network. Extensive
experiments demonstrate the effectiveness and efficiency of our proposed
method, outperforming state-of-the-art approaches on five visual grounding
benchmarks.",2024-12-26,"Yabing Wang, Zhuotao Tian, Qingpei Guo, Zheng Qin, Sanping Zhou, Ming Yang, Le Wang",http://arxiv.org/pdf/2412.19155v1,cs.CL
SILC-EFSA: Self-aware In-context Learning Correction for Entity-level Financial Sentiment Analysis,"In recent years, fine-grained sentiment analysis in finance has gained
significant attention, but the scarcity of entity-level datasets remains a key
challenge. To address this, we have constructed the largest English and Chinese
financial entity-level sentiment analysis datasets to date. Building on this
foundation, we propose a novel two-stage sentiment analysis approach called
Self-aware In-context Learning Correction (SILC). The first stage involves
fine-tuning a base large language model to generate pseudo-labeled data
specific to our task. In the second stage, we train a correction model using a
GNN-based example retriever, which is informed by the pseudo-labeled data. This
two-stage strategy has allowed us to achieve state-of-the-art performance on
the newly constructed datasets, advancing the field of financial sentiment
analysis. In a case study, we demonstrate the enhanced practical utility of our
data and methods in monitoring the cryptocurrency market. Our datasets and code
are available at https://github.com/NLP-Bin/SILC-EFSA.",2024-12-26,"Senbin Zhu, Chenyuan He, Hongde Liu, Pengcheng Dong, Hanjie Zhao, Yuchen Yan, Yuxiang Jia, Hongying Zan, Min Peng",http://arxiv.org/pdf/2412.19140v1,cs.CL
SketchFill: Sketch-Guided Code Generation for Imputing Derived Missing Values,"Missing value is a critical issue in data science, significantly impacting
the reliability of analyses and predictions. Missing value imputation (MVI) is
a longstanding problem because it highly relies on domain knowledge. Large
language models (LLMs) have emerged as a promising tool for data cleaning,
including MVI for tabular data, offering advanced capabilities for
understanding and generating content. However, despite their promise, existing
LLM techniques such as in-context learning and Chain-of-Thought (CoT) often
fall short in guiding LLMs to perform complex reasoning for MVI, particularly
when imputing derived missing values, which require mathematical formulas and
data relationships across rows and columns. This gap underscores the need for
further advancements in LLM methodologies to enhance their reasoning
capabilities for more reliable imputation outcomes. To fill this gap, we
propose SketchFill, a novel sketch-based method to guide LLMs in generating
accurate formulas to impute missing numerical values. Our experimental results
demonstrate that SketchFill significantly outperforms state-of-the-art methods,
achieving 56.2% higher accuracy than CoT-based methods and 78.8% higher
accuracy than MetaGPT. This sets a new standard for automated data cleaning and
advances the field of MVI for numerical values.",2024-12-26,"Yunfan Zhang, Changlun Li, Yuyu Luo, Nan Tang",http://arxiv.org/pdf/2412.19113v1,cs.CL
"""I've Heard of You!"": Generate Spoken Named Entity Recognition Data for Unseen Entities","Spoken named entity recognition (NER) aims to identify named entities from
speech, playing an important role in speech processing. New named entities
appear every day, however, annotating their Spoken NER data is costly. In this
paper, we demonstrate that existing Spoken NER systems perform poorly when
dealing with previously unseen named entities. To tackle this challenge, we
propose a method for generating Spoken NER data based on a named entity
dictionary (NED) to reduce costs. Specifically, we first use a large language
model (LLM) to generate sentences from the sampled named entities and then use
a text-to-speech (TTS) system to generate the speech. Furthermore, we introduce
a noise metric to filter out noisy data. To evaluate our approach, we release a
novel Spoken NER benchmark along with a corresponding NED containing 8,853
entities. Experiment results show that our method achieves state-of-the-art
(SOTA) performance in the in-domain, zero-shot domain adaptation, and fully
zero-shot settings. Our data will be available at
https://github.com/DeepLearnXMU/HeardU.",2024-12-26,"Jiawei Yu, Xiang Geng, Yuang Li, Mengxin Ren, Wei Tang, Jiahuan Li, Zhibin Lan, Min Zhang, Hao Yang, Shujian Huang, Jinsong Su",http://arxiv.org/pdf/2412.19102v1,cs.CL
MoPD: Mixture-of-Prompts Distillation for Vision-Language Models,"Soft prompt learning methods are effective for adapting vision-language
models (VLMs) to downstream tasks. Nevertheless, empirical evidence reveals a
tendency of existing methods that they overfit seen classes and exhibit
degraded performance on unseen classes. This limitation is due to the inherent
bias in the training data towards the seen classes. To address this issue, we
propose a novel soft prompt learning method, named Mixture-of-Prompts
Distillation (MoPD), which can effectively transfer useful knowledge from hard
prompts manually hand-crafted (a.k.a. teacher prompts) to the learnable soft
prompt (a.k.a. student prompt), thereby enhancing the generalization ability of
soft prompts on unseen classes. Moreover, the proposed MoPD method utilizes a
gating network that learns to select hard prompts used for prompt distillation.
Extensive experiments demonstrate that the proposed MoPD method outperforms
state-of-the-art baselines especially on on unseen classes.",2024-12-26,"Yang Chen, Shuai Fu, Yu Zhang",http://arxiv.org/pdf/2412.19087v1,cs.CL
Advancing LLM detection in the ALTA 2024 Shared Task: Techniques and Analysis,"The recent proliferation of AI-generated content has prompted significant
interest in developing reliable detection methods. This study explores
techniques for identifying AI-generated text through sentence-level evaluation
within hybrid articles. Our findings indicate that ChatGPT-3.5 Turbo exhibits
distinct, repetitive probability patterns that enable consistent in-domain
detection. Empirical tests show that minor textual modifications, such as
rewording, have minimal impact on detection accuracy. These results provide
valuable insights for advancing AI detection methodologies, offering a pathway
toward robust solutions to address the complexities of synthetic text
identification.",2024-12-26,Dima Galat,http://arxiv.org/pdf/2412.19076v1,cs.CL
Robust Speech and Natural Language Processing Models for Depression Screening,"Depression is a global health concern with a critical need for increased
patient screening. Speech technology offers advantages for remote screening but
must perform robustly across patients. We have described two deep learning
models developed for this purpose. One model is based on acoustics; the other
is based on natural language processing. Both models employ transfer learning.
Data from a depression-labeled corpus in which 11,000 unique users interacted
with a human-machine application using conversational speech is used. Results
on binary depression classification have shown that both models perform at or
above AUC=0.80 on unseen data with no speaker overlap. Performance is further
analyzed as a function of test subset characteristics, finding that the models
are generally robust over speaker and session variables. We conclude that
models based on these approaches offer promise for generalized automated
depression screening.",2024-12-26,"Y. Lu, A. Harati, T. Rutowski, R. Oliveira, P. Chlebek, E. Shriberg",http://arxiv.org/pdf/2412.19072v1,cs.CL
Cross-Demographic Portability of Deep NLP-Based Depression Models,"Deep learning models are rapidly gaining interest for real-world applications
in behavioral health. An important gap in current literature is how well such
models generalize over different populations. We study Natural Language
Processing (NLP) based models to explore portability over two different corpora
highly mismatched in age. The first and larger corpus contains younger
speakers. It is used to train an NLP model to predict depression. When testing
on unseen speakers from the same age distribution, this model performs at
AUC=0.82. We then test this model on the second corpus, which comprises seniors
from a retirement community. Despite the large demographic differences in the
two corpora, we saw only modest degradation in performance for the
senior-corpus data, achieving AUC=0.76. Interestingly, in the senior
population, we find AUC=0.81 for the subset of patients whose health state is
consistent over time. Implications for demographic portability of speech-based
applications are discussed.",2024-12-26,"Tomek Rutowski, Elizabeth Shriberg, Amir Harati, Yang Lu, Ricardo Oliveira, Piotr Chlebek",http://arxiv.org/pdf/2412.19070v1,cs.CL
Indonesian-English Code-Switching Speech Synthesizer Utilizing Multilingual STEN-TTS and Bert LID,"Multilingual text-to-speech systems convert text into speech across multiple
languages. In many cases, text sentences may contain segments in different
languages, a phenomenon known as code-switching. This is particularly common in
Indonesia, especially between Indonesian and English. Despite its significance,
no research has yet developed a multilingual TTS system capable of handling
code-switching between these two languages. This study addresses
Indonesian-English code-switching in STEN-TTS. Key modifications include adding
a language identification component to the text-to-phoneme conversion using
finetuned BERT for per-word language identification, as well as removing
language embedding from the base model. Experimental results demonstrate that
the code-switching model achieves superior naturalness and improved speech
intelligibility compared to the Indonesian and English baseline STEN-TTS
models.",2024-12-26,"Ahmad Alfani Handoyo, Chung Tran, Dessi Puji Lestari, Sakriani Sakti",http://arxiv.org/pdf/2412.19043v1,cs.CL
Let the Fuzzy Rule Speak: Enhancing In-context Learning Debiasing with Interpretability,"Large language models (LLMs) often struggle with balanced class accuracy in
text classification tasks using in-context learning (ICL), hindering some
practical uses due to user dissatisfaction or safety risks caused by
misclassifications. Retraining LLMs to address root causes in data or model
priors is neither easy nor cost-effective. This paper delves deeper into the
class accuracy imbalance issue, identifying that it arises because certain
classes consistently receive disproportionately high ICL probabilities, causing
under-prediction and lower accuracy for others. More importantly, probability
ranges affect the imbalance differently, allowing for precise, range-specific
corrections. We introduce FuRud (Fuzzy Rule Optimization-based Debiasing), a
method for sample-level class probability correction. FuRud tackles
interpretability challenges by determining why certain classes need corrections
and tailoring adjustments for each instance's class probabilities which is
powered by fuzzy sets with triangular membership functions, transforming a
class probability based on the range it belongs to. By solving a nonlinear
integer programming problem with a labeled set of ICL class probabilities to
minimize class accuracy bias (COBias) and maximize overall accuracy, each class
selects an optimal correction function from 19 triangular membership functions
without updating an LLM, and the selected functions correct test instances at
inference. Across seven benchmark datasets, FuRud reduces COBias by over half
(56%) and improves overall accuracy by 21% relatively, outperforming
state-of-the-art debiasing methods.",2024-12-26,"Ruixi Lin, Yang You",http://arxiv.org/pdf/2412.19018v4,cs.CL
MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models,"Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.",2024-12-25,"Kaiwen Zuo, Yirui Jiang",http://arxiv.org/pdf/2412.18947v4,cs.CL
Dovetail: A CPU/GPU Heterogeneous Speculative Decoding for LLM inference,"Due to the high resource demands of Large Language Models (LLMs), achieving
widespread deployment on consumer-grade devices presents significant
challenges. Typically, personal or consumer-grade devices, including servers
configured prior to the era of large-scale models, generally have relatively
weak GPUs and relatively strong CPUs. However, most current methods primarily
depend on GPUs for computation. Therefore, we propose Dovetail, an approach
that deploys the draft model on the GPU to generate draft tokens while allowing
the target model to perform parallel verification on the CPU, thereby improving
the utilization of all available hardware resources and occupying less
inter-device communication bandwidth. Accordingly, we have redesigned the draft
model to better align with heterogeneous hardware characteristics. To this end,
we implemented several optimizations: reducing the number of draft tokens to
mitigate latency in parallel verification, increasing the depth of the draft
model to enhance its predictive capacity, and introducing DGF (Dynamic Gating
Fusion) to improve the integration of features and token embeddings. In the
HumanEval benchmark, Dovetail achieved an inference speed of 5.86 tokens per
second for LLaMA2-Chat-7B using 3GB of VRAM, representing an approximately
2.77x improvement over CPU-only inference. Furthermore, the inference speed was
increased to 8 tokens per second when utilizing 7GB of VRAM.",2024-12-25,"Libo Zhang, Zhaoning Zhang, Baizhou Xu, Songzhu Mei, Dongsheng Li",http://arxiv.org/pdf/2412.18934v1,cs.CL
"HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs","The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.",2024-12-25,"Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, Benyou Wang",http://arxiv.org/pdf/2412.18925v1,cs.CL
AdaEAGLE: Optimizing Speculative Decoding via Explicit Modeling of Adaptive Draft Structures,"Speculative Decoding (SD) is a popular lossless technique for accelerating
the inference of Large Language Models (LLMs). We show that the decoding speed
of SD frameworks with static draft structures can be significantly improved by
incorporating context-aware adaptive draft structures. However, current studies
on adaptive draft structures are limited by their performance, modeling
approaches, and applicability. In this paper, we introduce AdaEAGLE, the first
SD framework that explicitly models adaptive draft structures. AdaEAGLE
leverages the Lightweight Draft Length Predictor (LDLP) module to explicitly
predict the optimal number of draft tokens during inference to guide the draft
model. It achieves comparable speedup results without manual thresholds and
allows for deeper, more specialized optimizations. Moreover, together with
threshold-based strategies, AdaEAGLE achieves a $1.62\times$ speedup over the
vanilla AR decoding and outperforms fixed-length SotA baseline while
maintaining output quality.",2024-12-25,"Situo Zhang, Hankun Wang, Da Ma, Zichen Zhu, Lu Chen, Kunyao Lan, Kai Yu",http://arxiv.org/pdf/2412.18910v1,cs.CL
Research Experiment on Multi-Model Comparison for Chinese Text Classification Tasks,"With the explosive growth of Chinese text data and advancements in natural
language processing technologies, Chinese text classification has become one of
the key techniques in fields such as information retrieval and sentiment
analysis, attracting increasing attention. This paper conducts a comparative
study on three deep learning models:TextCNN, TextRNN, and FastText.specifically
for Chinese text classification tasks. By conducting experiments on the
THUCNews dataset, the performance of these models is evaluated, and their
applicability in different scenarios is discussed.",2024-12-25,JiaCheng Li,http://arxiv.org/pdf/2412.18908v1,cs.CL
"Overview of MWE history, challenges, and horizons: standing at the 20th anniversary of the MWE workshop series via MWE-UD2024","Starting in 2003 when the first MWE workshop was held with ACL in Sapporo,
Japan, this year, the joint workshop of MWE-UD co-located with the LREC-COLING
2024 conference marked the 20th anniversary of MWE workshop events over the
past nearly two decades. Standing at this milestone, we look back to this
workshop series and summarise the research topics and methodologies researchers
have carried out over the years. We also discuss the current challenges that we
are facing and the broader impacts/synergies of MWE research within the CL and
NLP fields. Finally, we give future research perspectives. We hope this
position paper can help researchers, students, and industrial practitioners
interested in MWE get a brief but easy understanding of its history, current,
and possible future.",2024-12-25,"Lifeng Han, Kilian Evang, Archna Bhatia, Gosse Bouma, A. Seza Doğruöz, Marcos Garcia, Voula Giouli, Joakim Nivre, Alexandre Rademacher",http://arxiv.org/pdf/2412.18868v1,cs.CL
Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models,"Large language models (LLMs) have become integral tools in diverse domains,
yet their moral reasoning capabilities across cultural and linguistic contexts
remain underexplored. This study investigates whether multilingual LLMs, such
as GPT-3.5-Turbo, GPT-4o-mini, Llama 3.1, and MistralNeMo, reflect culturally
specific moral values or impose dominant moral norms, particularly those rooted
in English. Using the updated Moral Foundations Questionnaire (MFQ-2) in eight
languages, Arabic, Farsi, English, Spanish, Japanese, Chinese, French, and
Russian, the study analyzes the models' adherence to six core moral
foundations: care, equality, proportionality, loyalty, authority, and purity.
The results reveal significant cultural and linguistic variability, challenging
the assumption of universal moral consistency in LLMs. Although some models
demonstrate adaptability to diverse contexts, others exhibit biases influenced
by the composition of the training data. These findings underscore the need for
culturally inclusive model development to improve fairness and trust in
multilingual AI systems.",2024-12-25,Meltem Aksoy,http://arxiv.org/pdf/2412.18863v1,cs.CL
Bootstrap Your Own Context Length,"We introduce a bootstrapping approach to train long-context language models
by exploiting their short-context capabilities only. Our method utilizes a
simple agent workflow to synthesize diverse long-context instruction tuning
data, thereby eliminating the necessity for manual data collection and
annotation. The proposed data synthesis workflow requires only a short-context
language model, a text retriever, and a document collection, all of which are
readily accessible within the open-source ecosystem. Subsequently, language
models are fine-tuned using the synthesized data to extend their context
lengths. In this manner, we effectively transfer the short-context capabilities
of language models to long-context scenarios through a bootstrapping process.
We conduct experiments with the open-source Llama-3 family of models and
demonstrate that our method can successfully extend the context length to up to
1M tokens, achieving superior performance across various benchmarks.",2024-12-25,"Liang Wang, Nan Yang, Xingxing Zhang, Xiaolong Huang, Furu Wei",http://arxiv.org/pdf/2412.18860v2,cs.CL
RapGuard: Safeguarding Multimodal Large Language Models via Rationale-aware Defensive Prompting,"While Multimodal Large Language Models (MLLMs) have made remarkable progress
in vision-language reasoning, they are also more susceptible to producing
harmful content compared to models that focus solely on text. Existing
defensive prompting techniques rely on a static, unified safety guideline that
fails to account for the specific risks inherent in different multimodal
contexts. To address these limitations, we propose RapGuard, a novel framework
that uses multimodal chain-of-thought reasoning to dynamically generate
scenario-specific safety prompts. RapGuard enhances safety by adapting its
prompts to the unique risks of each input, effectively mitigating harmful
outputs while maintaining high performance on benign tasks. Our experimental
results across multiple MLLM benchmarks demonstrate that RapGuard achieves
state-of-the-art safety performance, significantly reducing harmful content
without degrading the quality of responses.",2024-12-25,"Yilei Jiang, Yingshui Tan, Xiangyu Yue",http://arxiv.org/pdf/2412.18826v1,cs.CL
DCIS: Efficient Length Extrapolation of LLMs via Divide-and-Conquer Scaling Factor Search,"Large language models (LLMs) based on the Transformer architecture usually
have their context length limited due to the high training cost. Recent
advancements extend the context window by adjusting the scaling factors of RoPE
and fine-tuning. However, suboptimal initialization of these factors results in
increased fine-tuning costs and reduced performance at target length. To
address these challenges, we propose an innovative RoPE-based fine-tuning
framework that diverges from conventional scaling factors search. Specifically,
we present a Divide-and-Conquer Incremental Search (DCIS) algorithm that
strategically determines the better scaling factors. Further fine-tuning with
the identified scaling factors effectively extends the context window of LLMs.
Empirical results demonstrate that our methodology not only mitigates
performance decay at extended target lengths but also allows the model to
fine-tune on short contexts and generalize to long contexts, thereby reducing
the cost of fine-tuning. The scaling factors obtained through DCIS can even
perform effectively without fine-tuning. Further analysis of the search space
reveals that DCIS achieves twice the search efficiency compared to other
methods. We also examine the impact of the non-strictly increasing scaling
factors utilized in DCIS and evaluate the general capabilities of LLMs across
various context lengths.",2024-12-25,"Lei Yang, Shaoyang Xu, Deyi Xiong",http://arxiv.org/pdf/2412.18811v1,cs.CL
Improving Generated and Retrieved Knowledge Combination Through Zero-shot Generation,"Open-domain Question Answering (QA) has garnered substantial interest by
combining the advantages of faithfully retrieved passages and relevant passages
generated through Large Language Models (LLMs). However, there is a lack of
definitive labels available to pair these sources of knowledge. In order to
address this issue, we propose an unsupervised and simple framework called
Bi-Reranking for Merging Generated and Retrieved Knowledge (BRMGR), which
utilizes re-ranking methods for both retrieved passages and LLM-generated
passages. We pair the two types of passages using two separate re-ranking
methods and then combine them through greedy matching. We demonstrate that
BRMGR is equivalent to employing a bipartite matching loss when assigning each
retrieved passage with a corresponding LLM-generated passage. The application
of our model yielded experimental results from three datasets, improving their
performance by +1.7 and +1.6 on NQ and WebQ datasets, respectively, and
obtaining comparable result on TriviaQA dataset when compared to competitive
baselines.",2024-12-25,"Xinkai Du, Quanjie Han, Chao Lv, Yan Liu, Yalin Sun, Hao Shu, Hongbo Shan, Maosong Sun",http://arxiv.org/pdf/2412.18800v1,cs.CL
Towards Expressive Video Dubbing with Multiscale Multimodal Context Interaction,"Automatic Video Dubbing (AVD) generates speech aligned with lip motion and
facial emotion from scripts. Recent research focuses on modeling multimodal
context to enhance prosody expressiveness but overlooks two key issues: 1)
Multiscale prosody expression attributes in the context influence the current
sentence's prosody. 2) Prosody cues in context interact with the current
sentence, impacting the final prosody expressiveness. To tackle these
challenges, we propose M2CI-Dubber, a Multiscale Multimodal Context Interaction
scheme for AVD. This scheme includes two shared M2CI encoders to model the
multiscale multimodal context and facilitate its deep interaction with the
current sentence. By extracting global and local features for each modality in
the context, utilizing attention-based mechanisms for aggregation and
interaction, and employing an interaction-based graph attention network for
fusion, the proposed approach enhances the prosody expressiveness of
synthesized speech for the current sentence. Experiments on the Chem dataset
show our model outperforms baselines in dubbing expressiveness. The code and
demos are available at
\textcolor[rgb]{0.93,0.0,0.47}{https://github.com/AI-S2-Lab/M2CI-Dubber}.",2024-12-25,"Yuan Zhao, Rui Liu, Gaoxiang Cong",http://arxiv.org/pdf/2412.18748v2,cs.CL
Intra- and Inter-modal Context Interaction Modeling for Conversational Speech Synthesis,"Conversational Speech Synthesis (CSS) aims to effectively take the multimodal
dialogue history (MDH) to generate speech with appropriate conversational
prosody for target utterance. The key challenge of CSS is to model the
interaction between the MDH and the target utterance. Note that text and speech
modalities in MDH have their own unique influences, and they complement each
other to produce a comprehensive impact on the target utterance. Previous works
did not explicitly model such intra-modal and inter-modal interactions. To
address this issue, we propose a new intra-modal and inter-modal context
interaction scheme-based CSS system, termed III-CSS. Specifically, in the
training phase, we combine the MDH with the text and speech modalities in the
target utterance to obtain four modal combinations, including Historical
Text-Next Text, Historical Speech-Next Speech, Historical Text-Next Speech, and
Historical Speech-Next Text. Then, we design two contrastive learning-based
intra-modal and two inter-modal interaction modules to deeply learn the
intra-modal and inter-modal context interaction. In the inference phase, we
take MDH and adopt trained interaction modules to fully infer the speech
prosody of the target utterance's text content. Subjective and objective
experiments on the DailyTalk dataset show that III-CSS outperforms the advanced
baselines in terms of prosody expressiveness. Code and speech samples are
available at https://github.com/AI-S2-Lab/I3CSS.",2024-12-25,"Zhenqi Jia, Rui Liu",http://arxiv.org/pdf/2412.18733v1,cs.CL
Optimizing Large Language Models with an Enhanced LoRA Fine-Tuning Algorithm for Efficiency and Robustness in NLP Tasks,"This study proposes a large language model optimization method based on the
improved LoRA fine-tuning algorithm, aiming to improve the accuracy and
computational efficiency of the model in natural language processing tasks. We
fine-tune the large language model through a low-rank adaptation strategy,
which significantly reduces the consumption of computing resources while
maintaining the powerful capabilities of the pre-trained model. The experiment
uses the QQP task as the evaluation scenario. The results show that the
improved LoRA algorithm shows significant improvements in accuracy, F1 score,
and MCC compared with traditional models such as BERT, Roberta, T5, and GPT-4.
In particular, in terms of F1 score and MCC, our model shows stronger
robustness and discrimination ability, which proves the potential of the
improved LoRA algorithm in fine-tuning large-scale pre-trained models. In
addition, this paper also discusses the application prospects of the improved
LoRA algorithm in other natural language processing tasks, emphasizing its
advantages in multi-task learning and scenarios with limited computing
resources. Future research can further optimize the LoRA fine-tuning strategy
and expand its application in larger-scale pre-trained models to improve the
generalization ability and task adaptability of the model.",2024-12-25,"Jiacheng Hu, Xiaoxuan Liao, Jia Gao, Zhen Qi, Hongye Zheng, Chihang Wang",http://arxiv.org/pdf/2412.18729v1,cs.CL
Using Large Language Models for Automated Grading of Student Writing about Science,"Assessing writing in large classes for formal or informal learners presents a
significant challenge. Consequently, most large classes, particularly in
science, rely on objective assessment tools such as multiple-choice quizzes,
which have a single correct answer. The rapid development of AI has introduced
the possibility of using large language models (LLMs) to evaluate student
writing. An experiment was conducted using GPT-4 to determine if machine
learning methods based on LLMs can match or exceed the reliability of
instructor grading in evaluating short writing assignments on topics in
astronomy. The audience consisted of adult learners in three massive open
online courses (MOOCs) offered through Coursera. One course was on astronomy,
the second was on astrobiology, and the third was on the history and philosophy
of astronomy. The results should also be applicable to non-science majors in
university settings, where the content and modes of evaluation are similar. The
data comprised answers from 120 students to 12 questions across the three
courses. GPT-4 was provided with total grades, model answers, and rubrics from
an instructor for all three courses. In addition to evaluating how reliably the
LLM reproduced instructor grades, the LLM was also tasked with generating its
own rubrics. Overall, the LLM was more reliable than peer grading, both in
aggregate and by individual student, and approximately matched instructor
grades for all three online courses. The implication is that LLMs may soon be
used for automated, reliable, and scalable grading of student science writing.",2024-12-25,"Chris Impey, Matthew Wenger, Nikhil Garuda, Shahriar Golchin, Sarah Stamer",http://arxiv.org/pdf/2412.18719v1,cs.CL
Speech Recognition With LLMs Adapted to Disordered Speech Using Reinforcement Learning,"We introduce a large language model (LLM) capable of processing speech inputs
and show that tuning it further with reinforcement learning on human preference
(RLHF) enables it to adapt better to disordered speech than traditional
fine-tuning. Our method replaces low-frequency text tokens in an LLM's
vocabulary with audio tokens and enables the model to recognize speech by
fine-tuning it on speech with transcripts. We then use RL with rewards based on
syntactic and semantic accuracy measures generalizing the LLM further to
recognize disordered speech. While the resulting LLM does not outperform
existing systems for speech recognition, we find that tuning with reinforcement
learning using custom rewards leads to substantially better performance than
supervised fine-tuning of the language model, specifically when adapting to
speech in a different setting. This presents a compelling alternative tuning
strategy for speech recognition using large language models.",2024-12-25,"Chirag Nagpal, Subhashini Venugopalan, Jimmy Tobin, Marilyn Ladewig, Katherine Heller, Katrin Tomanek",http://arxiv.org/pdf/2501.00039v1,cs.CL
Multiple References with Meaningful Variations Improve Literary Machine Translation,"While a source sentence can be translated in many ways, most machine
translation (MT) models are trained with only a single reference. Previous work
has shown that using synthetic paraphrases can improve MT. This paper
investigates best practices for employing multiple references by analyzing the
semantic similarity among different English translations of world literature in
the Par3 dataset. We classify the semantic similarity between paraphrases into
three levels: low, medium, and high, and fine-tune three different models
(mT5-large, LLaMA-2-7B, and Opus-MT) for literary MT tasks. Across different
models, holding the total training instances constant, single-reference but
more source texts only marginally outperforms multiple-reference with half of
the source texts. Moreover, when fine-tuning an LLM, using paraphrases with
medium and high semantic similarity outperforms an unfiltered dataset, with
improvements in BLEU (0.3-0.5), COMET (0.1-0.9), and chrF++ (0.17-0.32). Our
code is publicly available on GitHub.",2024-12-24,"Si Wu, John Wieting, David A. Smith",http://arxiv.org/pdf/2412.18707v2,cs.CL
CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era,"Retrieval from graph data is crucial for augmenting large language models
(LLM) with both open-domain knowledge and private enterprise data, and it is
also a key component in the recent GraphRAG system (edge et al., 2024). Despite
decades of research on knowledge graphs and knowledge base question answering,
leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal
support for retrieval from modern encyclopedic knowledge graphs like Wikidata.
In this paper, we analyze the root cause and suggest that modern RDF knowledge
graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly
large schemas that far exceed the typical LLM context window, use of resource
identifiers, overlapping relation types and lack of normalization. As a
solution, we propose property graph views on top of the underlying RDF graph
that can be efficiently queried by LLMs using Cypher. We instantiated this idea
on Wikidata and introduced CypherBench, the first benchmark with 11
large-scale, multi-domain property graphs with 7.8 million entities and over
10,000 questions. To achieve this, we tackled several key challenges, including
developing an RDF-to-property graph conversion engine, creating a systematic
pipeline for text-to-Cypher task generation, and designing new evaluation
metrics.",2024-12-24,"Yanlin Feng, Simone Papicchio, Sajjadur Rahman",http://arxiv.org/pdf/2412.18702v2,cs.CL
Diverse and Effective Red Teaming with Auto-generated Rewards and Multi-step Reinforcement Learning,"Automated red teaming can discover rare model failures and generate
challenging examples that can be used for training or evaluation. However, a
core challenge in automated red teaming is ensuring that the attacks are both
diverse and effective. Prior methods typically succeed in optimizing either for
diversity or for effectiveness, but rarely both. In this paper, we provide
methods that enable automated red teaming to generate a large number of diverse
and successful attacks.
  Our approach decomposes the task into two steps: (1) automated methods for
generating diverse attack goals and (2) generating effective attacks for those
goals. While we provide multiple straightforward methods for generating diverse
goals, our key contributions are to train an RL attacker that both follows
those goals and generates diverse attacks for those goals. First, we
demonstrate that it is easy to use a large language model (LLM) to generate
diverse attacker goals with per-goal prompts and rewards, including rule-based
rewards (RBRs) to grade whether the attacks are successful for the particular
goal. Second, we demonstrate how training the attacker model with multi-step
RL, where the model is rewarded for generating attacks that are different from
past attempts further increases diversity while remaining effective. We use our
approach to generate both prompt injection attacks and prompts that elicit
unsafe responses. In both cases, we find that our approach is able to generate
highly-effective and considerably more diverse attacks than past general
red-teaming approaches.",2024-12-24,"Alex Beutel, Kai Xiao, Johannes Heidecke, Lilian Weng",http://arxiv.org/pdf/2412.18693v1,cs.CL
AgreeMate: Teaching LLMs to Haggle,"We introduce AgreeMate, a framework for training Large Language Models (LLMs)
to perform strategic price negotiations through natural language. We apply
recent advances to a negotiation setting where two agents (i.e. buyer or
seller) use natural language to bargain on goods using coarse actions.
Specifically, we present the performance of Large Language Models when used as
agents within a decoupled (modular) bargaining architecture. We demonstrate
that using prompt engineering, fine-tuning, and chain-of-thought prompting
enhances model performance, as defined by novel metrics. We use attention
probing to show model attention to semantic relationships between tokens during
negotiations.",2024-12-24,"Ainesh Chatterjee, Samuel Miller, Nithin Parepally",http://arxiv.org/pdf/2412.18690v1,cs.CL
From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs,"Hallucination, a persistent challenge plaguing language models, undermines
their efficacy and trustworthiness in various natural language processing
endeavors by generating responses that deviate from factual accuracy or
coherence. This paper addresses language model hallucination by integrating
curated knowledge graph (KG) triples to anchor responses in empirical data. We
meticulously select and integrate relevant KG triples tailored to specific
contexts, enhancing factual grounding and alignment with input. Our
contribution involves constructing a comprehensive KG repository from Wikipedia
and refining data to spotlight essential information for model training. By
imbuing language models with access to this curated knowledge, we aim to
generate both linguistically fluent responses and deeply rooted in factual
accuracy and context relevance. This integration mitigates hallucinations by
providing a robust foundation of information, enabling models to draw upon a
rich reservoir of factual data during response generation. Experimental
evaluations demonstrate the effectiveness of multiple approaches in reducing
hallucinatory responses, underscoring the role of curated knowledge graphs in
improving the reliability and trustworthiness of language model outputs.",2024-12-24,"Ratnesh Kumar Joshi, Sagnik Sengupta, Asif Ekbal",http://arxiv.org/pdf/2412.18672v1,cs.CL
Advancing Explainability in Neural Machine Translation: Analytical Metrics for Attention and Alignment Consistency,"Neural Machine Translation (NMT) models have shown remarkable performance but
remain largely opaque in their decision making processes. The interpretability
of these models, especially their internal attention mechanisms, is critical
for building trust and verifying that these systems behave as intended. In this
work, we introduce a systematic framework to quantitatively evaluate the
explainability of an NMT model attention patterns by comparing them against
statistical alignments and correlating them with standard machine translation
quality metrics. We present a set of metrics attention entropy and alignment
agreement and validate them on an English-German test subset from WMT14 using a
pre trained mT5 model. Our results indicate that sharper attention
distributions correlate with improved interpretability but do not always
guarantee better translation quality. These findings advance our understanding
of NMT explainability and guide future efforts toward building more transparent
and reliable machine translation systems.",2024-12-24,Anurag Mishra,http://arxiv.org/pdf/2412.18669v1,cs.CL
Simple is not Enough: Document-level Text Simplification using Readability and Coherence,"In this paper, we present the SimDoc system, a simplification model
considering simplicity, readability, and discourse aspects, such as coherence.
In the past decade, the progress of the Text Simplification (TS) field has been
mostly shown at a sentence level, rather than considering paragraphs or
documents, a setting from which most TS audiences would benefit. We propose a
simplification system that is initially fine-tuned with professionally created
corpora. Further, we include multiple objectives during training, considering
simplicity, readability, and coherence altogether. Our contributions include
the extension of professionally annotated simplification corpora by the
association of existing annotations into (complex text, simple text,
readability label) triples to benefit from readability during training. Also,
we present a comparative analysis in which we evaluate our proposed models in a
zero-shot, few-shot, and fine-tuning setting using document-level TS corpora,
demonstrating novel methods for simplification. Finally, we show a detailed
analysis of outputs, highlighting the difficulties of simplification at a
document level.",2024-12-24,"Laura Vásquez-Rodríguez, Nhung T. H. Nguyen, Piotr Przybyła, Matthew Shardlow, Sophia Ananiadou",http://arxiv.org/pdf/2412.18655v1,cs.CL
Long-Form Speech Generation with Spoken Language Models,"We consider the generative modeling of speech over multiple minutes, a
requirement for long-form multimedia generation and audio-native voice
assistants. However, current spoken language models struggle to generate
plausible speech past tens of seconds, from high temporal resolution of speech
tokens causing loss of coherence, to architectural issues with long-sequence
training or extrapolation, to memory costs at inference time. With these
considerations we propose SpeechSSM, the first speech language model to learn
from and sample long-form spoken audio (e.g., 16 minutes of read or
extemporaneous speech) in a single decoding session without text intermediates,
based on recent advances in linear-time sequence modeling. Furthermore, to
address growing challenges in spoken language evaluation, especially in this
new long-form setting, we propose: new embedding-based and LLM-judged metrics;
quality measurements over length and time; and a new benchmark for long-form
speech processing and generation, LibriSpeech-Long. Speech samples and the
dataset are released at
https://google.github.io/tacotron/publications/speechssm/",2024-12-24,"Se Jin Park, Julian Salazar, Aren Jansen, Keisuke Kinoshita, Yong Man Ro, RJ Skerry-Ryan",http://arxiv.org/pdf/2412.18603v1,cs.CL
Exploring Embedding Priors in Prompt-Tuning for Improved Interpretability and Control,"Prompt-Tuning is an efficient method for adapting pre-trained language models
to new tasks with minimal computational overhead by modifying prompt
embeddings. In this work, we investigate how crucial the phenomenon of
embedding collapse, frequently observed in Prompt-Tuning, is for the final
performance of the model. To address this question, we designed embedding
priors and compared them with posteriors of the converged Soft and Deep
Prompt-Tuning methods. Our findings suggest that priors strongly affect the
position of the tuned embeddings, and models can effectively work with
embeddings from different parts of activation spaces, including completely new
regions. As the final Prompt-Tuning capabilities are limited, we hypothesize
that controllable Prompt-Tuning posteriors may serve as a good starting point
for tasks such as chain-of-thought (COT) distillation. Our experiments also
show that generated trajectories are not localized in the activation space of
the models. However, there are distinct clusters of activations for distant
tasks (e.g., NLP and arithmetic), while activations between NLP tasks (e.g.,
Question-Answering and MLM) lie in the same cluster. These observations raise
questions about the importance of a single activation cluster for the
generalization abilities of large language models.",2024-12-24,"Sergey Sedov, Sumanth Bharadwaj Hachalli Karanam, Venu Gopal Kadamba",http://arxiv.org/pdf/2412.18582v1,cs.CL
Top General Performance = Top Domain Performance? DomainCodeBench: A Multi-domain Code Generation Benchmark,"With the rapid advancement of large language models (LLMs), extensive
research has been conducted to investigate the code generation capabilities of
LLMs. However, existing efforts primarily focus on general-domain tasks,
leaving LLMs' code generation performance in real-world application domains
underexplored. This raises a critical question: can a model's general-domain
coding ability reliably represent its ability in specialized domains? In this
paper, we introduce DomainCodeBench, a multi-domain code generation benchmark
designed to systematically evaluate LLMs across 12 software application domains
and 15 programming languages. DomainCodeBench contains 2,400 manually verified
tasks with ground truth, human-annotated docstrings, and fine-grained
dependency information to ensure more coverage of domain-specific challenges.
Specifically, we first identify the most popular application domains by topic
mining. Then, we curate coding tasks based on commonly used frameworks and
platforms in each domain. We obtain several findings through extensive
experiments on DomainCodeBench with ten mainstream LLMs. (1) Performance
decoupling: experiments reveal that top general-domain models do not
consistently excel in specific application domains; (2) Domain-specific
weaknesses: LLMs often fail due to domain knowledge gaps and third-party
library misusage; (3) Contextual enhancement: we show that augmenting prompts
with domain-specific knowledge improves performance by around 38.17%, providing
actionable insights for performance optimization. Our replication package,
including the benchmark, source code, and experimental results, is available at
https://github.com/DeepSoftwareAnalytics/DomainCodeBench.",2024-12-24,"Dewu Zheng, Yanlin Wang, Ensheng Shi, Xilin Liu, Yuchi Ma, Hongyu Zhang, Zibin Zheng",http://arxiv.org/pdf/2412.18573v2,cs.CL
Zero-resource Speech Translation and Recognition with LLMs,"Despite recent advancements in speech processing, zero-resource speech
translation (ST) and automatic speech recognition (ASR) remain challenging
problems. In this work, we propose to leverage a multilingual Large Language
Model (LLM) to perform ST and ASR in languages for which the model has never
seen paired audio-text data. We achieve this by using a pre-trained
multilingual speech encoder, a multilingual LLM, and a lightweight adaptation
module that maps the audio representations to the token embedding space of the
LLM. We perform several experiments both in ST and ASR to understand how to
best train the model and what data has the most impact on performance in
previously unseen languages. In ST, our best model is capable to achieve BLEU
scores over 23 in CoVoST2 for two previously unseen languages, while in ASR, we
achieve WERs of up to 28.2\%. We finally show that the performance of our
system is bounded by the ability of the LLM to output text in the desired
language.",2024-12-24,"Karel Mundnich, Xing Niu, Prashant Mathur, Srikanth Ronanki, Brady Houston, Veera Raghavendra Elluru, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Anshu Bhatia, Daniel Garcia-Romero, Kyu J. Han, Katrin Kirchhoff",http://arxiv.org/pdf/2412.18566v2,cs.CL
Distilling Fine-grained Sentiment Understanding from Large Language Models,"Fine-grained sentiment analysis (FSA) aims to extract and summarize user
opinions from vast opinionated text. Recent studies demonstrate that large
language models (LLMs) possess exceptional sentiment understanding
capabilities. However, directly deploying LLMs for FSA applications incurs high
inference costs. Therefore, this paper investigates the distillation of
fine-grained sentiment understanding from LLMs into small language models
(SLMs). We prompt LLMs to examine and interpret the sentiments of given reviews
and then utilize the generated content to pretrain SLMs. Additionally, we
develop a comprehensive FSA benchmark to evaluate both SLMs and LLMs. Extensive
experiments on this benchmark reveal that: (1) distillation significantly
enhances the performance of SLMs in FSA tasks, achieving a 6.00\% improvement
in $F_1$-score, and the distilled model can outperform Llama-2-7b with only
220M parameters; (2) distillation equips SLMs with excellent zero-shot
sentiment classification capabilities, enabling them to match or even exceed
their teacher models. These results suggest that distillation from LLMs is a
highly promising direction for FSA. We will release our code, data, and
pretrained model weights at https://github.com/HITSZ-HLT/FSA-Distillation.",2024-12-24,"Yice Zhang, Guangyu Xie, Hongling Xu, Kaiheng Hou, Jianzhu Bao, Qianlong Wang, Shiwei Chen, Ruifeng Xu",http://arxiv.org/pdf/2412.18552v2,cs.CL
Libra-Leaderboard: Towards Responsible AI through a Balanced Leaderboard of Safety and Capability,"To address this gap, we introduce Libra-Leaderboard, a comprehensive
framework designed to rank LLMs through a balanced evaluation of performance
and safety. Combining a dynamic leaderboard with an interactive LLM arena,
Libra-Leaderboard encourages the joint optimization of capability and safety.
Unlike traditional approaches that average performance and safety metrics,
Libra-Leaderboard uses a distance-to-optimal-score method to calculate the
overall rankings. This approach incentivizes models to achieve a balance rather
than excelling in one dimension at the expense of some other ones. In the first
release, Libra-Leaderboard evaluates 26 mainstream LLMs from 14 leading
organizations, identifying critical safety challenges even in state-of-the-art
models.",2024-12-24,"Haonan Li, Xudong Han, Zenan Zhai, Honglin Mu, Hao Wang, Zhenxuan Zhang, Yilin Geng, Shom Lin, Renxi Wang, Artem Shelmanov, Xiangyu Qi, Yuxia Wang, Donghai Hong, Youliang Yuan, Meng Chen, Haoqin Tu, Fajri Koto, Tatsuki Kuribayashi, Cong Zeng, Rishabh Bhardwaj, Bingchen Zhao, Yawen Duan, Yi Liu, Emad A. Alghamdi, Yaodong Yang, Yinpeng Dong, Soujanya Poria, Pengfei Liu, Zhengzhong Liu, Xuguang Ren, Eduard Hovy, Iryna Gurevych, Preslav Nakov, Monojit Choudhury, Timothy Baldwin",http://arxiv.org/pdf/2412.18551v1,cs.CL
Token-Budget-Aware LLM Reasoning,"Reasoning is critical for large language models (LLMs) to excel in a wide
range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM
performance by decomposing problems into intermediate steps, they also incur
significant overhead in token usage, leading to increased costs. We find that
the reasoning process of current LLMs is unnecessarily lengthy and it can be
compressed by including a reasonable token budget in the prompt, but the choice
of token budget plays a crucial role in the actual compression effectiveness.
We then propose a token-budget-aware LLM reasoning framework, which dynamically
estimates token budgets for different problems based on reasoning complexity
and uses the estimated token budgets to guide the reasoning process.
Experiments show that our method effectively reduces token costs in CoT
reasoning with only a slight performance reduction, offering a practical
solution to balance efficiency and accuracy in LLM reasoning. Code:
https://github.com/GeniusHTX/TALE.",2024-12-24,"Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen",http://arxiv.org/pdf/2412.18547v4,cs.CL
Consistency Checks for Language Model Forecasters,"Forecasting is a task that is difficult to evaluate: the ground truth can
only be known in the future. Recent work showing LLM forecasters rapidly
approaching human-level performance begs the question: how can we benchmark and
evaluate these forecasters instantaneously? Following the consistency check
framework, we measure the performance of forecasters in terms of the
consistency of their predictions on different logically-related questions. We
propose a new, general consistency metric based on arbitrage: for example, if a
forecasting AI illogically predicts that both the Democratic and Republican
parties have 60% probability of winning the 2024 US presidential election, an
arbitrageur can trade against the forecaster's predictions and make a profit.
We build an automated evaluation system that generates a set of base questions,
instantiates consistency checks from these questions, elicits the predictions
of the forecaster, and measures the consistency of the predictions. We then
build a standard, proper-scoring-rule forecasting benchmark, and show that our
(instantaneous) consistency metrics correlate with LLM forecasters' ground
truth Brier scores (which are only known in the future). We also release a
consistency benchmark that resolves in 2028, providing a long-term evaluation
tool for forecasting.",2024-12-24,"Daniel Paleka, Abhimanyu Pallavi Sudhir, Alejandro Alvarez, Vineeth Bhat, Adam Shen, Evan Wang, Florian Tramèr",http://arxiv.org/pdf/2412.18544v2,cs.CL
Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation,"Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.",2024-12-24,"Derong Xu, Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen",http://arxiv.org/pdf/2412.18537v2,cs.CL
Characterizations of Language Generation With Breadth,"We study language generation in the limit, introduced by Kleinberg and
Mullainathan [KM24], building on classical works of Gold [Gol67] and Angluin
[Ang79]. [KM24] proposed an algorithm that generates strings from any countable
language collection in the limit. While their algorithm eventually outputs
strings from the target language $K$, it sacrifices breadth, i.e., the ability
to generate all strings in $K$. A key open question in [KM24] is whether this
trade-off between consistency and breadth is inherrent.
  Recent works proposed different notions of consistent generation with
breadth. Kalavasis, Mehrotra, and Velegkas [KVM24] introduced three
definitions: generation with exact breadth, approximate breadth, and
unambiguous generation. Concurrently and independently, Charikar and Pabbaraju
[CP24a] proposed exhaustive generation. Both works examined when generation
with these notions of breadth is possible.
  Building on [CP24a, KVM24], we fully characterize language generation for
these notions and their natural combinations. For exact breadth, we provide an
unconditional lower bound, removing a technical condition from [KVM24] and
extending the result of [CP24a] that holds for specific collections of
languages. We show that generation with exact breadth is characterized by
Angluin's condition for identification. We further introduce a weaker version
of Angluin's condition that tightly characterizes both approximate breadth and
exhaustive generation, proving their equivalence. Additionally, we show that
unambiguous generation is also characterized by Angluin's condition as a
special case of a broader result. Finally, we strengthen [KVM24] by giving
unconditional lower bounds for stable generators, showing that Angluin's
condition characterizes the previous breadth notions for stable generators.
This shows a separation between stable and unstable generation with approximate
breadth.",2024-12-24,"Alkis Kalavasis, Anay Mehrotra, Grigoris Velegkas",http://arxiv.org/pdf/2412.18530v1,cs.CL
DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation,"Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to
enhance language understanding and generation by leveraging external knowledge.
However, effectively capturing and integrating the rich semantic information
present in textual and structured data remains a challenge. To address this, a
novel GRAG framework, Dynamic Graph Retrieval-Agumented Generation (DynaGRAG),
is proposed to focus on enhancing subgraph representation and diversity within
the knowledge graph. By improving graph density, capturing entity and relation
information more effectively, and dynamically prioritizing relevant and diverse
subgraphs and information within them, the proposed approach enables a more
comprehensive understanding of the underlying semantic structure. This is
achieved through a combination of de-duplication processes, two-step mean
pooling of embeddings, query-aware retrieval considering unique nodes, and a
Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph
Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard
prompting further enhances the learning of rich node and edge representations
while preserving the hierarchical subgraph structure. Experimental results
demonstrate the effectiveness of DynaGRAG, showcasing the significance of
enhanced subgraph representation and diversity for improved language
understanding and generation.",2024-12-24,Karishma Thakrar,http://arxiv.org/pdf/2412.18644v3,cs.CL
Think or Remember? Detecting and Directing LLMs Towards Memorization or Generalization,"In this paper, we explore the foundational mechanisms of memorization and
generalization in Large Language Models (LLMs), inspired by the functional
specialization observed in the human brain. Our investigation serves as a case
study leveraging specially designed datasets and experimental-scale LLMs to lay
the groundwork for understanding these behaviors. Specifically, we aim to first
enable LLMs to exhibit both memorization and generalization by training with
the designed dataset, then (a) examine whether LLMs exhibit neuron-level
spatial differentiation for memorization and generalization, (b) predict these
behaviors using model internal representations, and (c) steer the behaviors
through inference-time interventions. Our findings reveal that neuron-wise
differentiation of memorization and generalization is observable in LLMs, and
targeted interventions can successfully direct their behavior.",2024-12-24,"Yi-Fu Fu, Yu-Chieh Tu, Tzu-Ling Cheng, Cheng-Yu Lin, Yi-Ting Yang, Heng-Yi Liu, Keng-Te Liao, Da-Cheng Juan, Shou-De Lin",http://arxiv.org/pdf/2412.18497v1,cs.CL
Generating event descriptions under syntactic and semantic constraints,"With the goal of supporting scalable lexical semantic annotation, analysis,
and theorizing, we conduct a comprehensive evaluation of different methods for
generating event descriptions under both syntactic constraints -- e.g. desired
clause structure -- and semantic constraints -- e.g. desired verb sense. We
compare three different methods -- (i) manual generation by experts; (ii)
sampling from a corpus annotated for syntactic and semantic information; and
(iii) sampling from a language model (LM) conditioned on syntactic and semantic
information -- along three dimensions of the generated event descriptions: (a)
naturalness, (b) typicality, and (c) distinctiveness. We find that all methods
reliably produce natural, typical, and distinctive event descriptions, but that
manual generation continues to produce event descriptions that are more
natural, typical, and distinctive than the automated generation methods. We
conclude that the automated methods we consider produce event descriptions of
sufficient quality for use in downstream annotation and analysis insofar as the
methods used for this annotation and analysis are robust to a small amount of
degradation in the resulting event descriptions.",2024-12-24,"Angela Cao, Faye Holt, Jonas Chan, Stephanie Richter, Lelia Glass, Aaron Steven White",http://arxiv.org/pdf/2412.18496v1,cs.CL
"How ""Real"" is Your Real-Time Simultaneous Speech-to-Text Translation System?","Simultaneous speech-to-text translation (SimulST) translates source-language
speech into target-language text concurrently with the speaker's speech,
ensuring low latency for better user comprehension. Despite its intended
application to unbounded speech, most research has focused on human
pre-segmented speech, simplifying the task and overlooking significant
challenges. This narrow focus, coupled with widespread terminological
inconsistencies, is limiting the applicability of research outcomes to
real-world applications, ultimately hindering progress in the field. Our
extensive literature review of 110 papers not only reveals these critical
issues in current research but also serves as the foundation for our key
contributions. We 1) define the steps and core components of a SimulST system,
proposing a standardized terminology and taxonomy; 2) conduct a thorough
analysis of community trends, and 3) offer concrete recommendations and future
directions to bridge the gaps in existing literature, from evaluation
frameworks to system architectures, for advancing the field towards more
realistic and effective SimulST solutions.",2024-12-24,"Sara Papi, Peter Polak, Ondřej Bojar, Dominik Macháček",http://arxiv.org/pdf/2412.18495v1,cs.CL
Segment-Based Attention Masking for GPTs,"Modern Language Models (LMs) owe much of their success to masked causal
attention, the backbone of Generative Pre-Trained Transformer (GPT) models.
Although GPTs can process the entire user prompt at once, the causal masking is
applied to all input tokens step-by-step, mimicking the generation process.
This imposes an unnecessary constraint during the initial ""prefill"" phase when
the model processes the input prompt and generates the internal representations
before producing any output tokens. In this work, attention is masked based on
the known block structure at the prefill phase, followed by the conventional
token-by-token autoregressive process after that. For example, in a typical
chat prompt, the system prompt is treated as one block, and the user prompt as
the next one. Each of these is treated as a unit for the purpose of masking,
such that the first tokens in each block can access the subsequent tokens in a
non-causal manner. Then, the model answer is generated in the conventional
causal manner. This Segment-by-Segment scheme entails no additional
computational overhead. When integrating it into models such as Llama and Qwen,
state-of-the-art performance is consistently achieved.",2024-12-24,"Shahar Katz, Liran Ringel, Yaniv Romano, Lior Wolf",http://arxiv.org/pdf/2412.18487v1,cs.CL
Is Large Language Model Good at Triple Set Prediction? An Empirical Study,"The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.",2024-12-24,"Yuan Yuan, Yajing Xu, Wen Zhang",http://arxiv.org/pdf/2412.18443v1,cs.CL
Unlocking the Potential of Multiple BERT Models for Bangla Question Answering in NCTB Textbooks,"Evaluating text comprehension in educational settings is critical for
understanding student performance and improving curricular effectiveness. This
study investigates the capability of state-of-the-art language models-RoBERTa
Base, Bangla-BERT, and BERT Base-in automatically assessing Bangla
passage-based question-answering from the National Curriculum and Textbook
Board (NCTB) textbooks for classes 6-10. A dataset of approximately 3,000
Bangla passage-based question-answering instances was compiled, and the models
were evaluated using F1 Score and Exact Match (EM) metrics across various
hyperparameter configurations. Our findings revealed that Bangla-BERT
consistently outperformed the other models, achieving the highest F1 (0.75) and
EM (0.53) scores, particularly with smaller batch sizes, the inclusion of stop
words, and a moderate learning rate. In contrast, RoBERTa Base demonstrated the
weakest performance, with the lowest F1 (0.19) and EM (0.27) scores under
certain configurations. The results underscore the importance of fine-tuning
hyperparameters for optimizing model performance and highlight the potential of
machine learning models in evaluating text comprehension in educational
contexts. However, limitations such as dataset size, spelling inconsistencies,
and computational constraints emphasize the need for further research to
enhance the robustness and applicability of these models. This study lays the
groundwork for the future development of automated evaluation systems in
educational institutions, providing critical insights into model performance in
the context of Bangla text comprehension.",2024-12-24,"Abdullah Khondoker, Enam Ahmed Taufik, Md Iftekhar Islam Tashik, S M Ishtiak mahmud, Antara Firoz Parsa",http://arxiv.org/pdf/2412.18440v1,cs.CL
GeAR: Graph-enhanced Agent for Retrieval-augmented Generation,"Retrieval-augmented generation systems rely on effective document retrieval
capabilities. By design, conventional sparse or dense retrievers face
challenges in multi-hop retrieval scenarios. In this paper, we present GeAR,
which advances RAG performance through two key innovations: (i) graph
expansion, which enhances any conventional base retriever, such as BM25, and
(ii) an agent framework that incorporates graph expansion. Our evaluation
demonstrates GeAR's superior retrieval performance on three multi-hop question
answering datasets. Additionally, our system achieves state-of-the-art results
with improvements exceeding 10% on the challenging MuSiQue dataset, while
requiring fewer tokens and iterations compared to other multi-step retrieval
systems.",2024-12-24,"Zhili Shen, Chenxin Diao, Pavlos Vougiouklis, Pascual Merita, Shriram Piramanayagam, Damien Graux, Dandan Tu, Zeren Jiang, Ruofei Lai, Yang Ren, Jeff Z. Pan",http://arxiv.org/pdf/2412.18431v1,cs.CL
Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent,"International enterprises, organizations, or hospitals collect large amounts
of multi-modal data stored in databases, text documents, images, and videos.
While there has been recent progress in the separate fields of multi-modal data
exploration as well as in database systems that automatically translate natural
language questions to database query languages, the research challenge of
querying database systems combined with other unstructured modalities such as
images in natural language is widely unexplored.
  In this paper, we propose XMODE - a system that enables explainable,
multi-modal data exploration in natural language. Our approach is based on the
following research contributions: (1) Our system is inspired by a real-world
use case that enables users to explore multi-modal information systems. (2)
XMODE leverages a LLM-based agentic AI framework to decompose a natural
language question into subtasks such as text-to-SQL generation and image
analysis. (3) Experimental results on multi-modal datasets over relational data
and images demonstrate that our system outperforms state-of-the-art multi-modal
exploration systems, excelling not only in accuracy but also in various
performance metrics such as query latency, API costs, planning efficiency, and
explanation quality, thanks to the more effective utilization of the reasoning
capabilities of LLMs.",2024-12-24,"Farhad Nooralahzadeh, Yi Zhang, Jonathan Furst, Kurt Stockinger",http://arxiv.org/pdf/2412.18428v1,cs.CL
"LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating","Large vision language models (LVLMs) have improved the document understanding
capabilities remarkably, enabling the handling of complex document elements,
longer contexts, and a wider range of tasks. However, existing document
understanding benchmarks have been limited to handling only a small number of
pages and fail to provide a comprehensive analysis of layout elements locating.
In this paper, we first define three primary task categories: Long Document
Understanding, numerical Reasoning, and cross-element Locating, and then
propose a comprehensive benchmark, LongDocURL, integrating above three primary
tasks and comprising 20 sub-tasks categorized based on different primary tasks
and answer evidences. Furthermore, we develop a semi-automated construction
pipeline and collect 2,325 high-quality question-answering pairs, covering more
than 33,000 pages of documents, significantly outperforming existing
benchmarks. Subsequently, we conduct comprehensive evaluation experiments on
both open-source and closed-source models across 26 different configurations,
revealing critical performance gaps in this field.",2024-12-24,"Chao Deng, Jiale Yuan, Pi Bu, Peijie Wang, Zhong-Zhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, Cheng-Lin Liu",http://arxiv.org/pdf/2412.18424v2,cs.CL
Multilingual Mathematical Reasoning: Advancing Open-Source LLMs in Hindi and English,"Large Language Models (LLMs) excel in linguistic tasks but struggle with
mathematical reasoning, particularly in non English languages like Hindi. This
research aims to enhance the mathematical reasoning skills of smaller, resource
efficient open-source LLMs in both Hindi and English. We evaluate models like
OpenHathi 7B, LLaMA-2 7B, WizardMath 7B, Mistral 7B, LLeMMa 7B, MAmmoTH 7B,
Gemini Pro, and GPT-4 using zero-shot, few-shot chain-of-thought (CoT) methods,
and supervised fine-tuning. Our approach incorporates curriculum learning,
progressively training models on increasingly difficult problems, a novel
Decomposition Strategy to simplify complex arithmetic operations, and a
Structured Solution Design that divides solutions into phases. Our experiments
result in notable performance enhancements. WizardMath 7B exceeds Gemini's
accuracy on English datasets by +6% and matches Gemini's performance on Hindi
datasets. Adopting a bilingual approach that combines English and Hindi samples
achieves results comparable to individual language models, demonstrating the
capability to learn mathematical reasoning in both languages. This research
highlights the potential for improving mathematical reasoning in open-source
LLMs.",2024-12-24,"Avinash Anand, Kritarth Prasad, Chhavi Kirtani, Ashwin R Nair, Manvendra Kumar Nema, Raj Jaiswal, Rajiv Ratn Shah",http://arxiv.org/pdf/2412.18415v1,cs.CL
ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots,"The rise of LLMs has deflected a growing portion of human-computer
interactions towards LLM-based chatbots. The remarkable abilities of these
models allow users to interact using long, diverse natural language text
covering a wide range of topics and styles. Phrasing these messages is a time
and effort consuming task, calling for an autocomplete solution to assist
users. We introduce the task of chatbot interaction autocomplete. We present
ChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework
for LLM-based chatbot interactions. The framework includes a formal definition
of the task, coupled with suitable datasets and metrics. We use the framework
to evaluate After formally defining the task along with suitable datasets and
metrics, we test 9 models on the defined auto completion task, finding that
while current off-the-shelf models perform fairly, there is still much room for
improvement, mainly in ranking of the generated suggestions. We provide
insights for practitioners working on this task and open new research
directions for researchers in the field. We release our framework to serve as a
foundation for future research.",2024-12-24,"Shani Goren, Oren Kalinsky, Tomer Stav, Yuri Rapoport, Yaron Fairstein, Ram Yazdi, Nachshon Cohen, Alexander Libov, Guy Kushilevitz",http://arxiv.org/pdf/2412.18377v3,cs.CL
Bidirectional Topic Matching: Quantifying Thematic Overlap Between Corpora Through Topic Modelling,"This study introduces Bidirectional Topic Matching (BTM), a novel method for
cross-corpus topic modeling that quantifies thematic overlap and divergence
between corpora. BTM is a flexible framework that can incorporate various topic
modeling approaches, including BERTopic, Top2Vec, and Latent Dirichlet
Allocation (LDA). BTM employs a dual-model approach, training separate topic
models for each corpus and applying them reciprocally to enable comprehensive
cross-corpus comparisons. This methodology facilitates the identification of
shared themes and unique topics, providing nuanced insights into thematic
relationships. Validation against cosine similarity-based methods demonstrates
the robustness of BTM, with strong agreement metrics and distinct advantages in
handling outlier topics. A case study on climate news articles showcases BTM's
utility, revealing significant thematic overlaps and distinctions between
corpora focused on climate change and climate action. BTM's flexibility and
precision make it a valuable tool for diverse applications, from political
discourse analysis to interdisciplinary studies. By integrating shared and
unique topic analyses, BTM offers a comprehensive framework for exploring
thematic relationships, with potential extensions to multilingual and dynamic
datasets. This work highlights BTM's methodological contributions and its
capacity to advance discourse analysis across various domains.",2024-12-24,"Raven Adam, Marie Lisa Kogler",http://arxiv.org/pdf/2412.18376v1,cs.CL
Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST),"The field of machine translation has achieved significant advancements, yet
domain-specific terminology translation, particularly in AI, remains
challenging. We introduce GIST, a large-scale multilingual AI terminology
dataset containing 5K terms extracted from top AI conference papers spanning
2000 to 2023. The terms are translated into Arabic, Chinese, French, Japanese,
and Russian using a hybrid framework that combines LLMs for extraction with
human expertise for translation. The dataset's quality is benchmarked against
existing resources, demonstrating superior translation accuracy through
crowdsourced evaluation. GIST is integrated into translation workflows using
post-translation refinement methods that require no retraining, where LLM
prompting consistently improves BLEU and COMET scores. A web demonstration on
the ACL Anthology platform highlights its practical application, showcasing
improved accessibility for non-English speakers. This work aims to address
critical gaps in AI terminology resources and fosters global inclusivity and
collaboration in AI research.",2024-12-24,"Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona Diab",http://arxiv.org/pdf/2412.18367v5,cs.CL
Extracting triples from dialogues for conversational social agents,"Obtaining an explicit understanding of communication within a Hybrid
Intelligence collaboration is essential to create controllable and transparent
agents. In this paper, we describe a number of Natural Language Understanding
models that extract explicit symbolic triples from social conversation. Triple
extraction has mostly been developed and tested for Knowledge Base Completion
using Wikipedia text and data for training and testing. However, social
conversation is very different as a genre in which interlocutors exchange
information in sequences of utterances that involve statements, questions, and
answers. Phenomena such as co-reference, ellipsis, coordination, and implicit
and explicit negation or confirmation are more prominent in conversation than
in Wikipedia text. We therefore describe an attempt to fill this gap by
releasing data sets for training and testing triple extraction from social
conversation. We also created five triple extraction models and tested them in
our evaluation data. The highest precision is 51.14 for complete triples and
69.32 for triple elements when tested on single utterances. However, scores for
conversational triples that span multiple turns are much lower, showing that
extracting knowledge from true conversational data is much more challenging.",2024-12-24,"Piek Vossen, Selene Báez Santamaría, Lenka Bajčetić, Thomas Belluci",http://arxiv.org/pdf/2412.18364v1,cs.CL
Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering,"Large Language Models (LLMs) have achieved impressive results in
knowledge-based Visual Question Answering (VQA). However existing methods still
have challenges: the inability to use external tools autonomously, and the
inability to work in teams. Humans tend to know whether they need to use
external tools when they encounter a new question, e.g., they tend to be able
to give a direct answer to a familiar question, whereas they tend to use tools
such as search engines when they encounter an unfamiliar question. In addition,
humans also tend to collaborate and discuss with others to get better answers.
Inspired by this, we propose the multi-agent voting framework. We design three
LLM-based agents that simulate different levels of staff in a team, and assign
the available tools according to the levels. Each agent provides the
corresponding answer, and finally all the answers provided by the agents are
voted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our
approach outperforms other baselines by 2.2 and 1.0, respectively.",2024-12-24,"Zhongjian Hu, Peng Yang, Bing Li, Zhenqi Wang",http://arxiv.org/pdf/2412.18351v1,cs.CL
M-Ped: Multi-Prompt Ensemble Decoding for Large Language Models,"With the widespread application of Large Language Models (LLMs) in the field
of Natural Language Processing (NLP), enhancing their performance has become a
research hotspot. This paper presents a novel multi-prompt ensemble decoding
approach designed to bolster the generation quality of LLMs by leveraging the
aggregation of outcomes from multiple prompts. Given a unique input $X$, we
submit $n$ variations of prompts with $X$ to LLMs in batch mode to decode and
derive probability distributions. For each token prediction, we calculate the
ensemble probability by averaging the $n$ probability distributions within the
batch, utilizing this aggregated probability to generate the token. This
technique is dubbed Inner-Batch Ensemble. To facilitate efficient batch
inference, we implement a Left-Padding strategy to maintain uniform input
lengths across the n prompts. Through extensive experimentation on diverse NLP
tasks, including machine translation, code generation, and text simplification,
we demonstrate the efficacy of our method in enhancing LLM performance. The
results show substantial improvements in BLEU scores, pass@$k$ rates, and LENS
metrics over conventional methods.",2024-12-24,"Jiaxin Guo, Daimeng Wei, Yuanchang Luo, Shimin Tao, Hengchao Shang, Zongyao Li, Shaojun Li, Jinlong Yang, Zhanglin Wu, Zhiqiang Rao, Hao Yang",http://arxiv.org/pdf/2412.18299v1,cs.CL
DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation,"Code review is a vital but demanding aspect of software development,
generating significant interest in automating review comments. Traditional
evaluation methods for these comments, primarily based on text similarity, face
two major challenges: inconsistent reliability of human-authored comments in
open-source projects and the weak correlation of text similarity with
objectives like enhancing code quality and detecting defects.
  This study empirically analyzes benchmark comments using a novel set of
criteria informed by prior research and developer interviews. We then similarly
revisit the evaluation of existing methodologies. Our evaluation framework,
DeepCRCEval, integrates human evaluators and Large Language Models (LLMs) for a
comprehensive reassessment of current techniques based on the criteria set.
Besides, we also introduce an innovative and efficient baseline, LLM-Reviewer,
leveraging the few-shot learning capabilities of LLMs for a target-oriented
comparison.
  Our research highlights the limitations of text similarity metrics, finding
that less than 10% of benchmark comments are high quality for automation. In
contrast, DeepCRCEval effectively distinguishes between high and low-quality
comments, proving to be a more reliable evaluation mechanism. Incorporating LLM
evaluators into DeepCRCEval significantly boosts efficiency, reducing time and
cost by 88.78% and 90.32%, respectively. Furthermore, LLM-Reviewer demonstrates
significant potential of focusing task real targets in comment generation.",2024-12-24,"Junyi Lu, Xiaojia Li, Zihan Hua, Lei Yu, Shiqi Cheng, Li Yang, Fengjun Zhang, Chun Zuo",http://arxiv.org/pdf/2412.18291v2,cs.CL
GenAI Content Detection Task 2: AI vs. Human -- Academic Essay Authenticity Challenge,"This paper presents a comprehensive overview of the first edition of the
Academic Essay Authenticity Challenge, organized as part of the GenAI Content
Detection shared tasks collocated with COLING 2025. This challenge focuses on
detecting machine-generated vs. human-authored essays for academic purposes.
The task is defined as follows: ""Given an essay, identify whether it is
generated by a machine or authored by a human.'' The challenge involves two
languages: English and Arabic. During the evaluation phase, 25 teams submitted
systems for English and 21 teams for Arabic, reflecting substantial interest in
the task. Finally, seven teams submitted system description papers. The
majority of submissions utilized fine-tuned transformer-based models, with one
team employing Large Language Models (LLMs) such as Llama 2 and Llama 3. This
paper outlines the task formulation, details the dataset construction process,
and explains the evaluation framework. Additionally, we present a summary of
the approaches adopted by participating teams. Nearly all submitted systems
outperformed the n-gram-based baseline, with the top-performing systems
achieving F1 scores exceeding 0.98 for both languages, indicating significant
progress in the detection of machine-generated text.",2024-12-24,"Shammur Absar Chowdhury, Hind Almerekhi, Mucahid Kutlu, Kaan Efe Keles, Fatema Ahmad, Tasnim Mohiuddin, George Mikros, Firoj Alam",http://arxiv.org/pdf/2412.18274v1,cs.CL
Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study,"Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.",2024-12-24,"Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu",http://arxiv.org/pdf/2412.18260v2,cs.CL
ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation,"Controversial contents largely inundate the Internet, infringing various
cultural norms and child protection standards. Traditional Image Content
Moderation (ICM) models fall short in producing precise moderation decisions
for diverse standards, while recent multimodal large language models (MLLMs),
when adopted to general rule-based ICM, often produce classification and
explanation results that are inconsistent with human moderators. Aiming at
flexible, explainable, and accurate ICM, we design a novel rule-based dataset
generation pipeline, decomposing concise human-defined rules and leveraging
well-designed multi-stage prompts to enrich short explicit image annotations.
Our ICM-Instruct dataset includes detailed moderation explanation and
moderation Q-A pairs. Built upon it, we create our ICM-Assistant model in the
framework of rule-based ICM, making it readily applicable in real practice. Our
ICM-Assistant model demonstrates exceptional performance and flexibility.
Specifically, it significantly outperforms existing approaches on various
sources, improving both the moderation classification (36.8% on average) and
moderation explanation quality (26.6% on average) consistently over existing
MLLMs. Code/Data is available at https://github.com/zhaoyuzhi/ICM-Assistant.",2024-12-24,"Mengyang Wu, Yuzhi Zhao, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, Chi-Wing Fu",http://arxiv.org/pdf/2412.18216v2,cs.CL
Robustness-aware Automatic Prompt Optimization,"The performance of Large Language Models (LLMs) depends on the quality of
prompts and the semantic and structural integrity of the input data. However,
existing prompt generation methods primarily focus on well-structured input
data, often neglecting the impact of perturbed inputs on prompt effectiveness.
To address this limitation, we propose BATprompt (By Adversarial Training
prompt), a novel method for prompt generation designed to withstand input
perturbations (such as typos in the input). Inspired by adversarial training
techniques, BATprompt demonstrates strong performance on a variety of perturbed
tasks through a two-step process: adversarial perturbation and iterative
optimization on unperturbed input via LLM. Unlike conventional adversarial
attack methods, BATprompt does not need access to model parameters and
gradients. Instead, BATprompt leverages the advanced reasoning, language
understanding and self reflection capabilities of LLMs to simulate gradients,
guiding the generation of adversarial perturbations and optimizing prompt
performance. We evaluate BATprompt on multiple datasets across both language
understanding and generation tasks. The results indicate that BATprompt
outperforms existing prompt generation methods, delivering superior robustness
and performance under diverse perturbation scenarios.",2024-12-24,"Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Hang Gao, Fan Yang, Ruixiang Tang, Yongfeng Zhang",http://arxiv.org/pdf/2412.18196v2,cs.CL
VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks,"General-purposed embodied agents are designed to understand the users'
natural instructions or intentions and act precisely to complete universal
tasks. Recently, methods based on foundation models especially
Vision-Language-Action models (VLAs) have shown a substantial potential to
solve language-conditioned manipulation (LCM) tasks well. However, existing
benchmarks do not adequately meet the needs of VLAs and relative algorithms. To
better define such general-purpose tasks in the context of LLMs and advance the
research in VLAs, we present VLABench, an open-source benchmark for evaluating
universal LCM task learning. VLABench provides 100 carefully designed
categories of tasks, with strong randomization in each category of task and a
total of 2000+ objects. VLABench stands out from previous benchmarks in four
key aspects: 1) tasks requiring world knowledge and common sense transfer, 2)
natural language instructions with implicit human intentions rather than
templates, 3) long-horizon tasks demanding multi-step reasoning, and 4)
evaluation of both action policies and language model capabilities. The
benchmark assesses multiple competencies including understanding of
mesh\&texture, spatial relationship, semantic instruction, physical laws,
knowledge transfer and reasoning, etc. To support the downstream finetuning, we
provide high-quality training data collected via an automated framework
incorporating heuristic skills and prior information. The experimental results
indicate that both the current state-of-the-art pretrained VLAs and the
workflow based on VLMs face challenges in our tasks.",2024-12-24,"Shiduo Zhang, Zhe Xu, Peiju Liu, Xiaopeng Yu, Yuan Li, Qinghui Gao, Zhaoye Fei, Zhangyue Yin, Zuxuan Wu, Yu-Gang Jiang, Xipeng Qiu",http://arxiv.org/pdf/2412.18194v1,cs.CL
An Analysis on Automated Metrics for Evaluating Japanese-English Chat Translation,"This paper analyses how traditional baseline metrics, such as BLEU and TER,
and neural-based methods, such as BERTScore and COMET, score several NMT models
performance on chat translation and how these metrics perform when compared to
human-annotated scores. The results show that for ranking NMT models in chat
translations, all metrics seem consistent in deciding which model outperforms
the others. This implies that traditional baseline metrics, which are faster
and simpler to use, can still be helpful. On the other hand, when it comes to
better correlation with human judgment, neural-based metrics outperform
traditional metrics, with COMET achieving the highest correlation with the
human-annotated score on a chat translation. However, we show that even the
best metric struggles when scoring English translations from sentences with
anaphoric zero-pronoun in Japanese.",2024-12-24,"Andre Rusli, Makoto Shishido",http://arxiv.org/pdf/2412.18190v1,cs.CL
On the Applicability of Zero-Shot Cross-Lingual Transfer Learning for Sentiment Classification in Distant Language Pairs,"This research explores the applicability of cross-lingual transfer learning
from English to Japanese and Indonesian using the XLM-R pre-trained model. The
results are compared with several previous works, either by models using a
similar zero-shot approach or a fully-supervised approach, to provide an
overview of the zero-shot transfer learning approach's capability using XLM-R
in comparison with existing models. Our models achieve the best result in one
Japanese dataset and comparable results in other datasets in Japanese and
Indonesian languages without being trained using the target language.
Furthermore, the results suggest that it is possible to train a multi-lingual
model, instead of one model for each language, and achieve promising results.",2024-12-24,"Andre Rusli, Makoto Shishido",http://arxiv.org/pdf/2412.18188v1,cs.CL
A Novel Task-Driven Method with Evolvable Interactive Agents Using Event Trees for Enhanced Emergency Decision Support,"As climate change and other global challenges increase the likelihood of
unforeseen emergencies, the limitations of human-driven strategies in critical
situations become more pronounced. Inadequate pre-established emergency plans
can lead operators to become overwhelmed during complex systems malfunctions.
This study addresses the urgent need for agile decision-making in response to
various unforeseen incidents through a novel approach, EvoTaskTree (a
task-driven method with evolvable interactive agents using event trees for
emergency decision support). This advanced approach integrates two types of
agents powered by large language models (LLMs): task executors, responsible for
executing critical procedures, and task validators, ensuring the efficacy of
those actions. By leveraging insights from event tree analysis, our framework
encompasses three crucial tasks: initiating event subevent analysis, event tree
header event analysis, and decision recommendations. The agents learn from both
successful and unsuccessful responses from these tasks. Finally, we use nuclear
power plants as a demonstration of a safety-critical system. Our findings
indicate that the designed agents are not only effective but also outperform
existing approaches, achieving an impressive accuracy rate of up to 100 % in
processing previously unencoun32 tered incident scenarios. This paper
demonstrates that EvoTaskTree significantly enhances the rapid formulation of
emergency decision-making.",2024-12-24,"Xingyu Xiao, Peng Chen, Ben Qi, Jingang Liang, Jiejuan Tong, Haitao Wang",http://arxiv.org/pdf/2501.06193v1,cs.CL
"Survey of Pseudonymization, Abstractive Summarization & Spell Checker for Hindi and Marathi","India's vast linguistic diversity presents unique challenges and
opportunities for technological advancement, especially in the realm of Natural
Language Processing (NLP). While there has been significant progress in NLP
applications for widely spoken languages, the regional languages of India, such
as Marathi and Hindi, remain underserved. Research in the field of NLP for
Indian regional languages is at a formative stage and holds immense
significance. The paper aims to build a platform which enables the user to use
various features like text anonymization, abstractive text summarization and
spell checking in English, Hindi and Marathi language. The aim of these tools
is to serve enterprise and consumer clients who predominantly use Indian
Regional Languages.",2024-12-24,"Rasika Ransing, Mohammed Amaan Dhamaskar, Ayush Rajpurohit, Amey Dhoke, Sanket Dalvi",http://arxiv.org/pdf/2412.18163v1,cs.CL
scReader: Prompting Large Language Models to Interpret scRNA-seq Data,"Large language models (LLMs) have demonstrated remarkable advancements,
primarily due to their capabilities in modeling the hidden relationships within
text sequences. This innovation presents a unique opportunity in the field of
life sciences, where vast collections of single-cell omics data from multiple
species provide a foundation for training foundational models. However, the
challenge lies in the disparity of data scales across different species,
hindering the development of a comprehensive model for interpreting genetic
data across diverse organisms. In this study, we propose an innovative hybrid
approach that integrates the general knowledge capabilities of LLMs with
domain-specific representation models for single-cell omics data
interpretation. We begin by focusing on genes as the fundamental unit of
representation. Gene representations are initialized using functional
descriptions, leveraging the strengths of mature language models such as
LLaMA-2. By inputting single-cell gene-level expression data with prompts, we
effectively model cellular representations based on the differential expression
levels of genes across various species and cell types. In the experiments, we
constructed developmental cells from humans and mice, specifically targeting
cells that are challenging to annotate. We evaluated our methodology through
basic tasks such as cell annotation and visualization analysis. The results
demonstrate the efficacy of our approach compared to other methods using LLMs,
highlighting significant improvements in accuracy and interoperability. Our
hybrid approach enhances the representation of single-cell data and offers a
robust framework for future research in cross-species genetic analysis.",2024-12-24,"Cong Li, Qingqing Long, Yuanchun Zhou, Meng Xiao",http://arxiv.org/pdf/2412.18156v1,cs.CL
GeneSUM: Large Language Model-based Gene Summary Extraction,"Emerging topics in biomedical research are continuously expanding, providing
a wealth of information about genes and their function. This rapid
proliferation of knowledge presents unprecedented opportunities for scientific
discovery and formidable challenges for researchers striving to keep abreast of
the latest advancements. One significant challenge is navigating the vast
corpus of literature to extract vital gene-related information, a
time-consuming and cumbersome task. To enhance the efficiency of this process,
it is crucial to address several key challenges: (1) the overwhelming volume of
literature, (2) the complexity of gene functions, and (3) the automated
integration and generation. In response, we propose GeneSUM, a two-stage
automated gene summary extractor utilizing a large language model (LLM). Our
approach retrieves and eliminates redundancy of target gene literature and then
fine-tunes the LLM to refine and streamline the summarization process. We
conducted extensive experiments to validate the efficacy of our proposed
framework. The results demonstrate that LLM significantly enhances the
integration of gene-specific information, allowing more efficient
decision-making in ongoing research.",2024-12-24,"Zhijian Chen, Chuan Hu, Min Wu, Qingqing Long, Xuezhi Wang, Yuanchun Zhou, Meng Xiao",http://arxiv.org/pdf/2412.18154v1,cs.CL
CoAM: Corpus of All-Type Multiword Expressions,"Multiword expressions (MWEs) refer to idiomatic sequences of multiple words.
MWE identification, i.e., detecting MWEs in text, can play a key role in
downstream tasks such as machine translation. Existing datasets for MWE
identification are inconsistently annotated, limited to a single type of MWE,
or limited in size. To enable reliable and comprehensive evaluation, we created
CoAM: Corpus of All-Type Multiword Expressions, a dataset of 1.3K sentences
constructed through a multi-step process to enhance data quality consisting of
human annotation, human review, and automated consistency checking. MWEs in
CoAM are tagged with MWE types, such as Noun and Verb, to enable fine-grained
error analysis. Annotations for CoAM were collected using a new interface
created with our interface generator, which allows easy and flexible annotation
of MWEs in any form, including discontinuous ones. Through experiments using
CoAM, we find that a fine-tuned large language model outperforms the current
state-of-the-art approach for MWE identification. Furthermore, analysis using
our MWE type tagged data reveals that Verb MWEs are easier than Noun MWEs to
identify across approaches.",2024-12-24,"Yusuke Ide, Joshua Tanner, Adam Nohejl, Jacob Hoffman, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe",http://arxiv.org/pdf/2412.18151v1,cs.CL
Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media,"Social media platforms are experiencing a growing presence of AI-Generated
Texts (AIGTs). However, the misuse of AIGTs could have profound implications
for public opinion, such as spreading misinformation and manipulating
narratives. Despite its importance, it remains unclear how prevalent AIGTs are
on social media. To address this gap, this paper aims to quantify and monitor
the AIGTs on online social media platforms. We first collect a dataset (SM-D)
with around 2.4M posts from 3 major social media platforms: Medium, Quora, and
Reddit. Then, we construct a diverse dataset (AIGTBench) to train and evaluate
AIGT detectors. AIGTBench combines popular open-source datasets and our AIGT
datasets generated from social media texts by 12 LLMs, serving as a benchmark
for evaluating mainstream detectors. With this setup, we identify the
best-performing detector (OSM-Det). We then apply OSM-Det to SM-D to track
AIGTs across social media platforms from January 2022 to October 2024, using
the AI Attribution Rate (AAR) as the metric. Specifically, Medium and Quora
exhibit marked increases in AAR, rising from 1.77% to 37.03% and 2.06% to
38.95%, respectively. In contrast, Reddit shows slower growth, with AAR
increasing from 1.31% to 2.45% over the same period. Our further analysis
indicates that AIGTs on social media differ from human-written texts across
several dimensions, including linguistic patterns, topic distributions,
engagement levels, and the follower distribution of authors. We envision our
analysis and findings on AIGTs in social media can shed light on future
research in this domain.",2024-12-24,"Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He",http://arxiv.org/pdf/2412.18148v2,cs.CL
Ensuring Consistency for In-Image Translation,"The in-image machine translation task involves translating text embedded
within images, with the translated results presented in image format. While
this task has numerous applications in various scenarios such as film poster
translation and everyday scene image translation, existing methods frequently
neglect the aspect of consistency throughout this process. We propose the need
to uphold two types of consistency in this task: translation consistency and
image generation consistency. The former entails incorporating image
information during translation, while the latter involves maintaining
consistency between the style of the text-image and the original image,
ensuring background integrity. To address these consistency requirements, we
introduce a novel two-stage framework named HCIIT (High-Consistency In-Image
Translation) which involves text-image translation using a multimodal
multilingual large language model in the first stage and image backfilling with
a diffusion model in the second stage. Chain of thought learning is utilized in
the first stage to enhance the model's ability to leverage image information
during translation. Subsequently, a diffusion model trained for
style-consistent text-image generation ensures uniformity in text style within
images and preserves background details. A dataset comprising 400,000
style-consistent pseudo text-image pairs is curated for model training. Results
obtained on both curated test sets and authentic image test sets validate the
effectiveness of our framework in ensuring consistency and producing
high-quality translated images.",2024-12-24,"Chengpeng Fu, Xiaocheng Feng, Yichong Huang, Wenshuai Huo, Baohang Li, Zhirui Zhang, Yunfei Lu, Dandan Tu, Duyu Tang, Hui Wang, Bing Qin, Ting Liu",http://arxiv.org/pdf/2412.18139v1,cs.CL
LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment,"As Large Language Models (LLMs) demonstrate exceptional performance across
various domains, deploying LLMs on edge devices has emerged as a new trend.
Quantization techniques, which reduce the size and memory requirements of LLMs,
are effective for deploying LLMs on resource-limited edge devices. However,
existing one-size-fits-all quantization methods often fail to dynamically
adjust the memory requirements of LLMs, limiting their applications to
practical edge devices with various computation resources. To tackle this
issue, we propose Layer-Specific Adaptive Quantization (LSAQ), a system for
adaptive quantization and dynamic deployment of LLMs based on layer importance.
Specifically, LSAQ evaluates the importance of LLMs' neural layers by
constructing top-k token sets from the inputs and outputs of each layer and
calculating their Jaccard similarity. Based on layer importance, our system
adaptively adjusts quantization strategies in real time according to the
computation resource of edge devices, which applies higher quantization
precision to layers with higher importance, and vice versa. {Experimental
results show that LSAQ consistently outperforms the selected quantization
baselines in terms of perplexity and zero-shot tasks. Additionally, it can
devise appropriate quantization schemes for different usage scenarios to
facilitate the deployment of LLMs.",2024-12-24,"Binrui Zeng, Bin Ji, Xiaodong Liu, Jie Yu, Shasha Li, Jun Ma, Xiaopeng Li, Shangwen Wang, Xinran Hong, Yongtao Tang",http://arxiv.org/pdf/2412.18135v2,cs.CL
AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models,"As text-to-image (T2I) models continue to advance and gain widespread
adoption, their associated safety issues are becoming increasingly prominent.
Malicious users often exploit these models to generate Not-Safe-for-Work (NSFW)
images using harmful or adversarial prompts, highlighting the critical need for
robust safeguards to ensure the integrity and compliance of model outputs.
Current internal safeguards frequently degrade image quality, while external
detection methods often suffer from low accuracy and inefficiency.
  In this paper, we introduce AEIOU, a defense framework that is Adaptable,
Efficient, Interpretable, Optimizable, and Unified against NSFW prompts in T2I
models. AEIOU extracts NSFW features from the hidden states of the model's text
encoder, utilizing the separable nature of these features to detect NSFW
prompts. The detection process is efficient, requiring minimal inference time.
AEIOU also offers real-time interpretation of results and supports optimization
through data augmentation techniques. The framework is versatile, accommodating
various T2I architectures. Our extensive experiments show that AEIOU
significantly outperforms both commercial and open-source moderation tools,
achieving over 95% accuracy across all datasets and improving efficiency by at
least tenfold. It effectively counters adaptive attacks and excels in few-shot
and multi-label scenarios.",2024-12-24,"Yiming Wang, Jiahao Chen, Qingming Li, Xing Yang, Shouling Ji",http://arxiv.org/pdf/2412.18123v1,cs.CL
Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm,"Cognitive tasks originally developed for humans are now increasingly used to
study language models. While applying these tasks is often straightforward,
interpreting their results can be challenging. In particular, when a model
underperforms, it is often unclear whether this results from a limitation in
the cognitive ability being tested or a failure to understand the task itself.
A recent study argues that GPT 3.5's declining performance on 2-back and 3-back
tasks reflects a working memory capacity limit similar to humans (Gong et al.,
2024). By analyzing a range of open-source language models of varying
performance levels on these tasks, we show that the poor performance instead
reflects a limitation in task comprehension and task set maintenance. In
addition, we challenge the best-performing model with progressively harder
versions of the task (up to 10-back) and experiment with alternative prompting
strategies, before analyzing model attentions. Our larger aim is to contribute
to the ongoing conversation around refining methodologies for the cognitive
evaluation of language models.",2024-12-24,"Xiaoyang Hu, Richard L. Lewis",http://arxiv.org/pdf/2412.18120v2,cs.CL
Molly: Making Large Language Model Agents Solve Python Problem More Logically,"Applying large language models (LLMs) as teaching assists has attracted much
attention as an integral part of intelligent education, particularly in
computing courses. To reduce the gap between the LLMs and the computer
programming education expert, fine-tuning and retrieval augmented generation
(RAG) are the two mainstream methods in existing researches. However,
fine-tuning for specific tasks is resource-intensive and may diminish the
model`s generalization capabilities. RAG can perform well on reducing the
illusion of LLMs, but the generation of irrelevant factual content during
reasoning can cause significant confusion for learners. To address these
problems, we introduce the Molly agent, focusing on solving the proposed
problem encountered by learners when learning Python programming language. Our
agent automatically parse the learners' questioning intent through a
scenario-based interaction, enabling precise retrieval of relevant documents
from the constructed knowledge base. At generation stage, the agent reflect on
the generated responses to ensure that they not only align with factual content
but also effectively answer the user's queries. Extensive experimentation on a
constructed Chinese Python QA dataset shows the effectiveness of the Molly
agent, indicating an enhancement in its performance for providing useful
responses to Python questions.",2024-12-24,"Rui Xiao, Jiong Wang, Lu Han, Na Zong, Han Wu",http://arxiv.org/pdf/2412.18093v1,cs.CL
Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner,"Motion planning is a crucial component in autonomous driving.
State-of-the-art motion planners are trained on meticulously curated datasets,
which are not only expensive to annotate but also insufficient in capturing
rarely seen critical scenarios. Failing to account for such scenarios poses a
significant risk to motion planners and may lead to incidents during testing.
An intuitive solution is to manually compose such scenarios by programming and
executing a simulator (e.g., CARLA). However, this approach incurs substantial
human costs. Motivated by this, we propose an inexpensive method for generating
diverse critical traffic scenarios to train more robust motion planners. First,
we represent traffic scenarios as scripts, which are then used by the simulator
to generate traffic scenarios. Next, we develop a method that accepts
user-specified text descriptions, which a Large Language Model translates into
scripts using in-context learning. The output scripts are sent to the simulator
that produces the corresponding traffic scenarios. As our method can generate
abundant safety-critical traffic scenarios, we use them as synthetic training
data for motion planners. To demonstrate the value of generated scenarios, we
train existing motion planners on our synthetic data, real-world datasets, and
a combination of both. Our experiments show that motion planners trained with
our data significantly outperform those trained solely on real-world data,
showing the usefulness of our synthetic data and the effectiveness of our data
generation method. Our source code is available at
https://ezharjan.github.io/AutoSceneGen.",2024-12-24,Aizierjiang Aiersilan,http://arxiv.org/pdf/2412.18086v2,cs.CL
MMFactory: A Universal Solution Search Engine for Vision-Language Tasks,"With advances in foundational and vision-language models, and effective
fine-tuning techniques, a large number of both general and special-purpose
models have been developed for a variety of visual tasks. Despite the
flexibility and accessibility of these models, no single model is able to
handle all tasks and/or applications that may be envisioned by potential users.
Recent approaches, such as visual programming and multimodal LLMs with
integrated tools aim to tackle complex visual tasks, by way of program
synthesis. However, such approaches overlook user constraints (e.g.,
performance / computational needs), produce test-time sample-specific solutions
that are difficult to deploy, and, sometimes, require low-level instructions
that maybe beyond the abilities of a naive user. To address these limitations,
we introduce MMFactory, a universal framework that includes model and metrics
routing components, acting like a solution search engine across various
available models. Based on a task description and few sample input-output pairs
and (optionally) resource and/or performance constraints, MMFactory can suggest
a diverse pool of programmatic solutions by instantiating and combining
visio-lingual tools from its model repository. In addition to synthesizing
these solutions, MMFactory also proposes metrics and benchmarks performance /
resource characteristics, allowing users to pick a solution that meets their
unique design constraints. From the technical perspective, we also introduced a
committee-based solution proposer that leverages multi-agent LLM conversation
to generate executable, diverse, universal, and robust solutions for the user.
Experimental results show that MMFactory outperforms existing methods by
delivering state-of-the-art solutions tailored to user problem specifications.
Project page is available at https://davidhalladay.github.io/mmfactory_demo.",2024-12-24,"Wan-Cyuan Fan, Tanzila Rahman, Leonid Sigal",http://arxiv.org/pdf/2412.18072v1,cs.CL
Improving Factuality with Explicit Working Memory,"Large language models can generate factually inaccurate content, a problem
known as hallucination. Recent works have built upon retrieved-augmented
generation to improve factuality through iterative prompting but these methods
are limited by the traditional RAG design. To address these challenges, we
introduce EWE (Explicit Working Memory), a novel approach that enhances
factuality in long-form text generation by integrating a working memory that
receives real-time feedback from external resources. The memory is refreshed
based on online fact-checking and retrieval feedback, allowing EWE to rectify
false claims during the generation process and ensure more accurate and
reliable outputs. Our experiments demonstrate that Ewe outperforms strong
baselines on four fact-seeking long-form generation datasets, increasing the
factuality metric, VeriScore, by 2 to 6 points absolute without sacrificing the
helpfulness of the responses. Further analysis reveals that the design of rules
for memory updates, configurations of memory units, and the quality of the
retrieval datastore are crucial factors for influencing model performance.",2024-12-24,"Mingda Chen, Yang Li, Karthik Padthe, Rulin Shao, Alicia Sun, Luke Zettlemoyer, Gargi Ghosh, Wen-tau Yih",http://arxiv.org/pdf/2412.18069v2,cs.CL
Lla-VAP: LSTM Ensemble of Llama and VAP for Turn-Taking Prediction,"Turn-taking prediction is the task of anticipating when the speaker in a
conversation will yield their turn to another speaker to begin speaking. This
project expands on existing strategies for turn-taking prediction by employing
a multi-modal ensemble approach that integrates large language models (LLMs)
and voice activity projection (VAP) models. By combining the linguistic
capabilities of LLMs with the temporal precision of VAP models, we aim to
improve the accuracy and efficiency of identifying TRPs in both scripted and
unscripted conversational scenarios. Our methods are evaluated on the
In-Conversation Corpus (ICC) and Coached Conversational Preference Elicitation
(CCPE) datasets, highlighting the strengths and limitations of current models
while proposing a potentially more robust framework for enhanced prediction.",2024-12-24,"Hyunbae Jeon, Frederic Guintu, Rayvant Sahni",http://arxiv.org/pdf/2412.18061v1,cs.CL
Neuron Empirical Gradient: Discovering and Quantifying Neurons Global Linear Controllability,"Although feed-forward neurons in pre-trained language models (PLMs) can store
knowledge and their importance in influencing model outputs has been studied,
existing work focuses on finding a limited set of neurons and analyzing their
relative importance. However, the global quantitative role of activation values
in shaping outputs remains unclear, hindering further advancements in
applications like knowledge editing. Our study first investigates the numerical
relationship between neuron activations and model output and discovers the
global linear relationship between them through neuron interventions on a
knowledge probing dataset. We refer to the gradient of this linear relationship
as neuron empirical gradient (NEG), and introduce NeurGrad, an accurate and
efficient method for computing NEG. NeurGrad enables quantitative analysis of
all neurons in PLMs, advancing our understanding of neurons' controllability.
Furthermore, we explore NEG's ability to represent language skills across
diverse prompts via skill neuron probing. Experiments on MCEval8k, a
multi-choice knowledge benchmark spanning various genres, validate NEG's
representational ability. The data and code are released.",2024-12-24,"Xin Zhao, Zehui Jiang, Naoki Yoshinaga",http://arxiv.org/pdf/2412.18053v2,cs.CL
Factuality or Fiction? Benchmarking Modern LLMs on Ambiguous QA with Citations,"Benchmarking modern large language models (LLMs) on complex and realistic
tasks is critical to advancing their development. In this work, we evaluate the
factual accuracy and citation performance of state-of-the-art LLMs on the task
of Question Answering (QA) in ambiguous settings with source citations. Using
three recently published datasets-DisentQA-DupliCite, DisentQA-ParaCite, and
AmbigQA-Cite-featuring a range of real-world ambiguities, we analyze the
performance of two leading LLMs, GPT-4o-mini and Claude-3.5. Our results show
that larger, recent models consistently predict at least one correct answer in
ambiguous contexts but fail to handle cases with multiple valid answers.
Additionally, all models perform equally poorly in citation generation, with
citation accuracy consistently at 0. However, introducing conflict-aware
prompting leads to large improvements, enabling models to better address
multiple valid answers and improve citation accuracy, while maintaining their
ability to predict correct answers. These findings highlight the challenges and
opportunities in developing LLMs that can handle ambiguity and provide reliable
source citations. Our benchmarking study provides critical insights and sets a
foundation for future improvements in trustworthy and interpretable QA systems.",2024-12-23,"Maya Patel, Aditi Anand",http://arxiv.org/pdf/2412.18051v1,cs.CL
Emoji Retrieval from Gibberish or Garbled Social Media Text: A Novel Methodology and A Case Study,"Emojis are widely used across social media platforms but are often lost in
noisy or garbled text, posing challenges for data analysis and machine
learning. Conventional preprocessing approaches recommend removing such text,
risking the loss of emojis and their contextual meaning. This paper proposes a
three-step reverse-engineering methodology to retrieve emojis from garbled text
in social media posts. The methodology also identifies reasons for the
generation of such text during social media data mining. To evaluate its
effectiveness, the approach was applied to 509,248 Tweets about the Mpox
outbreak, a dataset referenced in about 30 prior works that failed to retrieve
emojis from garbled text. Our method retrieved 157,748 emojis from 76,914
Tweets. Improvements in text readability and coherence were demonstrated
through metrics such as Flesch Reading Ease, Flesch-Kincaid Grade Level,
Coleman-Liau Index, Automated Readability Index, Dale-Chall Readability Score,
Text Standard, and Reading Time. Additionally, the frequency of individual
emojis and their patterns of usage in these Tweets were analyzed, and the
results are presented.",2024-12-23,"Shuqi Cui, Nirmalya Thakur, Audrey Poon",http://arxiv.org/pdf/2412.18046v1,cs.CL
Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review,"Clinical coding is crucial for healthcare billing and data analysis. Manual
clinical coding is labour-intensive and error-prone, which has motivated
research towards full automation of the process. However, our analysis, based
on US English electronic health records and automated coding research using
these records, shows that widely used evaluation methods are not aligned with
real clinical contexts. For example, evaluations that focus on the top 50 most
common codes are an oversimplification, as there are thousands of codes used in
practice. This position paper aims to align AI coding research more closely
with practical challenges of clinical coding. Based on our analysis, we offer
eight specific recommendations, suggesting ways to improve current evaluation
methods. Additionally, we propose new AI-based methods beyond automated coding,
suggesting alternative approaches to assist clinical coders in their workflows.",2024-12-23,"Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld",http://arxiv.org/pdf/2412.18043v1,cs.CL
Theoretical Constraints on the Expressive Power of $\mathsf{RoPE}$-based Tensor Attention Transformers,"Tensor Attention extends traditional attention mechanisms by capturing
high-order correlations across multiple modalities, addressing the limitations
of classical matrix-based attention. Meanwhile, Rotary Position Embedding
($\mathsf{RoPE}$) has shown superior performance in encoding positional
information in long-context scenarios, significantly enhancing transformer
models' expressiveness. Despite these empirical successes, the theoretical
limitations of these technologies remain underexplored. In this study, we
analyze the circuit complexity of Tensor Attention and $\mathsf{RoPE}$-based
Tensor Attention, showing that with polynomial precision, constant-depth
layers, and linear or sublinear hidden dimension, they cannot solve fixed
membership problems or $(A_{F,r})^*$ closure problems, under the assumption
that $\mathsf{TC}^0 \neq \mathsf{NC}^1$. These findings highlight a gap between
the empirical performance and theoretical constraints of Tensor Attention and
$\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that
could guide the development of more theoretically grounded approaches to
Transformer model design and scaling.",2024-12-23,"Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Mingda Wan",http://arxiv.org/pdf/2412.18040v1,cs.CL
Explainability in Neural Networks for Natural Language Processing Tasks,"Neural networks are widely regarded as black-box models, creating significant
challenges in understanding their inner workings, especially in natural
language processing (NLP) applications. To address this opacity, model
explanation techniques like Local Interpretable Model-Agnostic Explanations
(LIME) have emerged as essential tools for providing insights into the behavior
of these complex systems. This study leverages LIME to interpret a multi-layer
perceptron (MLP) neural network trained on a text classification task. By
analyzing the contribution of individual features to model predictions, the
LIME approach enhances interpretability and supports informed decision-making.
Despite its effectiveness in offering localized explanations, LIME has
limitations in capturing global patterns and feature interactions. This
research highlights the strengths and shortcomings of LIME and proposes
directions for future work to achieve more comprehensive interpretability in
neural NLP models.",2024-12-23,"Melkamu Mersha, Mingiziem Bitewa, Tsion Abay, Jugal Kalita",http://arxiv.org/pdf/2412.18036v2,cs.CL
"Same Company, Same Signal: The Role of Identity in Earnings Call Transcripts","Post-earnings volatility prediction is critical for investors, with previous
works often leveraging earnings call transcripts under the assumption that
their rich semantics contribute significantly. To further investigate how
transcripts impact volatility, we introduce DEC, a dataset featuring accurate
volatility calculations enabled by the previously overlooked beforeAfterMarket
attribute and dense ticker coverage. Unlike established benchmarks, where each
ticker has only around two earnings, DEC provides 20 earnings records per
ticker. Using DEC, we reveal that post-earnings volatility undergoes
significant shifts, with each ticker displaying a distinct volatility
distribution. To leverage historical post-earnings volatility and capture
ticker-specific patterns, we propose two training-free baselines: Post-earnings
Volatility (PEV) and Same-ticker Post-earnings Volatility (STPEV). These
baselines surpass all transcripts-based models on DEC as well as on established
benchmarks. Additionally, we demonstrate that current transcript
representations predominantly capture ticker identity rather than offering
financially meaningful insights specific to each earnings. This is evidenced by
two key observations: earnings representations from the same ticker exhibit
significantly higher similarity compared to those from different tickers, and
predictions from transcript-based models show strong correlations with prior
post-earnings volatility.",2024-12-23,"Ding Yu, Zhuo Liu, Hangfeng He",http://arxiv.org/pdf/2412.18029v1,cs.CL
StructTest: Benchmarking LLMs' Reasoning through Compositional Structured Outputs,"The rapid advancement of large language models (LLMs) demands robust,
unbiased, and scalable evaluation methods. However, human annotations are
costly to scale, model-based evaluations are susceptible to stylistic biases,
and target-answer-based benchmarks are vulnerable to data contamination and
cheating. To address these limitations, we propose StructTest, a novel
benchmark that evaluates LLMs on their ability to follow compositional
instructions and generate structured outputs, providing an unbiased,
cost-effective, and difficult-to-cheat evaluation framework. Assessments are
conducted deterministically using a rule-based evaluator, which can be easily
extended to new tasks and datasets. By testing structured outputs across
diverse domains including Summarization, Code, HTML, and Math, and evaluating
17 popular LLMs, we demonstrate that StructTest remains challenging even for
top-performing models like Deepseek-V3/R1 and GPT-4o, establishing it as a
robust proxy for measuring reasoning capabilities. We believe StructTest offers
a critical and complementary approach to achieving objective and comprehensive
model evaluation.",2024-12-23,"Hailin Chen, Fangkai Jiao, Mathieu Ravaut, Nawshad Farruque, Xuan Phi Nguyen, Chengwei Qin, Manan Dey, Bosheng Ding, Caiming Xiong, Shafiq Joty, Yingbo Zhou",http://arxiv.org/pdf/2412.18011v2,cs.CL
Correctness is not Faithfulness in RAG Attributions,"Retrieving relevant context is a common approach to reduce hallucinations and
enhance answer reliability. Explicitly citing source documents allows users to
verify generated responses and increases trust. Prior work largely evaluates
citation correctness - whether cited documents support the corresponding
statements. But citation correctness alone is insufficient. To establish trust
in attributed answers, we must examine both citation correctness and citation
faithfulness. In this work, we first disentangle the notions of citation
correctness and faithfulness, which have been applied inconsistently in
previous studies. Faithfulness ensures that the model's reliance on cited
documents is genuine, reflecting actual reference use rather than superficial
alignment with prior beliefs, which we call post-rationalization. We design an
experiment that reveals the prevalent issue of post-rationalization, which
undermines reliable attribution and may result in misplaced trust. Our findings
suggest that current attributed answers often lack citation faithfulness (up to
57 percent of the citations), highlighting the need to evaluate correctness and
faithfulness for trustworthy attribution in language models.",2024-12-23,"Jonas Wallat, Maria Heuss, Maarten de Rijke, Avishek Anand",http://arxiv.org/pdf/2412.18004v1,cs.CL
CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models,"Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.",2024-12-23,"Ruibo Tu, Hedvig Kjellström, Gustav Eje Henter, Cheng Zhang",http://arxiv.org/pdf/2412.17970v1,cs.CL
Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models,"Large language models (LLMs) possess vast semantic knowledge but often
struggle with complex reasoning tasks, particularly in relational reasoning
problems such as kinship or spatial reasoning. In this paper, we present
Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning
by decomposing the task into three key stages: graph extraction, path
identification, and reasoning. Unlike previous approaches, PoT efficiently
extracts a task-agnostic graph that identifies crucial entities, relations, and
attributes within the problem context. Subsequently, PoT identifies relevant
reasoning chains within the graph corresponding to the posed question,
facilitating inference of potential answers. Experimental evaluations on four
benchmark datasets, demanding long reasoning chains, demonstrate that PoT
surpasses state-of-the-art baselines by a significant margin (maximum 21.3%)
without necessitating fine-tuning or extensive LLM calls. Furthermore, as
opposed to prior neuro-symbolic methods, PoT exhibits improved resilience
against LLM errors by leveraging the compositional nature of graphs.",2024-12-23,"Ge Zhang, Mohammad Ali Alomrani, Hongjian Gu, Jiaming Zhou, Yaochen Hu, Bin Wang, Qun Liu, Mark Coates, Yingxue Zhang, Jianye Hao",http://arxiv.org/pdf/2412.17963v1,cs.CL
IITR-CIOL@NLU of Devanagari Script Languages 2025: Multilingual Hate Speech Detection and Target Identification in Devanagari-Scripted Languages,"This work focuses on two subtasks related to hate speech detection and target
identification in Devanagari-scripted languages, specifically Hindi, Marathi,
Nepali, Bhojpuri, and Sanskrit. Subtask B involves detecting hate speech in
online text, while Subtask C requires identifying the specific targets of hate
speech, such as individuals, organizations, or communities. We propose the
MultilingualRobertaClass model, a deep neural network built on the pretrained
multilingual transformer model ia-multilingual-transliterated-roberta,
optimized for classification tasks in multilingual and transliterated contexts.
The model leverages contextualized embeddings to handle linguistic diversity,
with a classifier head for binary classification. We received 88.40% accuracy
in Subtask B and 66.11% accuracy in Subtask C, in the test set.",2024-12-23,"Siddhant Gupta, Siddh Singhal, Azmine Toushik Wasi",http://arxiv.org/pdf/2412.17947v2,cs.CL
BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism,"We present BenCzechMark (BCM), the first comprehensive Czech language
benchmark designed for large language models, offering diverse tasks, multiple
task formats, and multiple evaluation metrics. Its duel scoring system is
grounded in statistical significance theory and uses aggregation across tasks
inspired by social preference theory. Our benchmark encompasses 50 challenging
tasks, with corresponding test datasets, primarily in native Czech, with 14
newly collected ones. These tasks span 8 categories and cover diverse domains,
including historical Czech news, essays from pupils or language learners, and
spoken word. Furthermore, we collect and clean BUT-Large Czech Collection, the
largest publicly available clean Czech language corpus, and use it for (i)
contamination analysis and (ii) continuous pretraining of the first
Czech-centric 7B language model with Czech-specific tokenization. We use our
model as a baseline for comparison with publicly available multilingual models.
Lastly, we release and maintain a leaderboard with existing 50 model
submissions, where new model submissions can be made at
https://huggingface.co/spaces/CZLC/BenCzechMark.",2024-12-23,"Martin Fajcik, Martin Docekal, Jan Dolezal, Karel Ondrej, Karel Beneš, Jan Kapsa, Pavel Smrz, Alexander Polok, Michal Hradis, Zuzana Neverilova, Ales Horak, Radoslav Sabol, Michal Stefanik, Adam Jirkovsky, David Adamczyk, Petr Hyner, Jan Hula, Hynek Kydlicek",http://arxiv.org/pdf/2412.17933v2,cs.CL
Recent Developments in Deep Learning-based Author Name Disambiguation,"Author Name Disambiguation (AND) is a critical task for digital libraries
aiming to link existing authors with their respective publications. Due to the
lack of persistent identifiers used by researchers and the presence of
intrinsic linguistic challenges, such as homonymy, the development of Deep
Learning algorithms to address this issue has become widespread. Many AND deep
learning methods have been developed, and surveys exist comparing the
approaches in terms of techniques, complexity, performance. However, none
explicitly addresses AND methods in the context of deep learning in the latest
years (i.e. timeframe 2016-2024). In this paper, we provide a systematic review
of state-of-the-art AND techniques based on deep learning, highlighting recent
improvements, challenges, and open issues in the field. We find that DL methods
have significantly impacted AND by enabling the integration of structured and
unstructured data, and hybrid approaches effectively balance supervised and
unsupervised learning.",2024-12-23,"Francesca Cappelli, Giovanni Colavizza, Silvio Peroni",http://arxiv.org/pdf/2503.13448v1,cs.CL
VITRO: Vocabulary Inversion for Time-series Representation Optimization,"Although LLMs have demonstrated remarkable capabilities in processing and
generating textual data, their pre-trained vocabularies are ill-suited for
capturing the nuanced temporal dynamics and patterns inherent in time series.
The discrete, symbolic nature of natural language tokens, which these
vocabularies are designed to represent, does not align well with the
continuous, numerical nature of time series data. To address this fundamental
limitation, we propose VITRO. Our method adapts textual inversion optimization
from the vision-language domain in order to learn a new time series per-dataset
vocabulary that bridges the gap between the discrete, semantic nature of
natural language and the continuous, numerical nature of time series data. We
show that learnable time series-specific pseudo-word embeddings represent time
series data better than existing general language model vocabularies, with
VITRO-enhanced methods achieving state-of-the-art performance in long-term
forecasting across most datasets.",2024-12-23,"Filippos Bellos, Nam H. Nguyen, Jason J. Corso",http://arxiv.org/pdf/2412.17921v1,cs.CL
"A Multimodal Emotion Recognition System: Integrating Facial Expressions, Body Movement, Speech, and Spoken Language","Traditional psychological evaluations rely heavily on human observation and
interpretation, which are prone to subjectivity, bias, fatigue, and
inconsistency. To address these limitations, this work presents a multimodal
emotion recognition system that provides a standardised, objective, and
data-driven tool to support evaluators, such as psychologists, psychiatrists,
and clinicians. The system integrates recognition of facial expressions,
speech, spoken language, and body movement analysis to capture subtle emotional
cues that are often overlooked in human evaluations. By combining these
modalities, the system provides more robust and comprehensive emotional state
assessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in
a simulated real-world condition demonstrates the system's potential to provide
reliable emotional insights to improve the diagnostic accuracy. This work
highlights the promise of automated multimodal analysis as a valuable
complement to traditional psychological evaluation practices, with applications
in clinical and therapeutic settings.",2024-12-23,Kris Kraack,http://arxiv.org/pdf/2412.17907v1,cs.CL
Cross-Lingual Text-Rich Visual Comprehension: An Information Theory Perspective,"Recent Large Vision-Language Models (LVLMs) have shown promising reasoning
capabilities on text-rich images from charts, tables, and documents. However,
the abundant text within such images may increase the model's sensitivity to
language. This raises the need to evaluate LVLM performance on cross-lingual
text-rich visual inputs, where the language in the image differs from the
language of the instructions. To address this, we introduce XT-VQA
(Cross-Lingual Text-Rich Visual Question Answering), a benchmark designed to
assess how LVLMs handle language inconsistency between image text and
questions. XT-VQA integrates five existing text-rich VQA datasets and a newly
collected dataset, XPaperQA, covering diverse scenarios that require faithful
recognition and comprehension of visual information despite language
inconsistency. Our evaluation of prominent LVLMs on XT-VQA reveals a
significant drop in performance for cross-lingual scenarios, even for models
with multilingual capabilities. A mutual information analysis suggests that
this performance gap stems from cross-lingual questions failing to adequately
activate relevant visual information. To mitigate this issue, we propose
MVCL-MI (Maximization of Vision-Language Cross-Lingual Mutual Information),
where a visual-text cross-lingual alignment is built by maximizing mutual
information between the model's outputs and visual information. This is
achieved by distilling knowledge from monolingual to cross-lingual settings
through KL divergence minimization, where monolingual output logits serve as a
teacher. Experimental results on the XT-VQA demonstrate that MVCL-MI
effectively reduces the visual-text cross-lingual performance disparity while
preserving the inherent capabilities of LVLMs, shedding new light on the
potential practice for improving LVLMs. Codes are available at:
https://github.com/Stardust-y/XTVQA.git",2024-12-23,"Xinmiao Yu, Xiaocheng Feng, Yun Li, Minghui Liao, Ya-Qi Yu, Xiachong Feng, Weihong Zhong, Ruihan Chen, Mengkang Hu, Jihao Wu, Dandan Tu, Duyu Tang, Bing Qin",http://arxiv.org/pdf/2412.17787v1,cs.CL
ResearchTown: Simulator of Human Research Community,"Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.",2024-12-23,"Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You",http://arxiv.org/pdf/2412.17767v1,cs.CL
In Case You Missed It: ARC 'Challenge' Is Not That Challenging,"ARC Challenge appears more difficult than ARC Easy for modern LLMs primarily
due to an evaluation setup that prevents direct comparison of answer choices
rather than inherent complexity. Although some researchers have quietly shifted
to a more appropriate scheme over the last year, the implications of this
change have yet to be widely acknowledged. We highlight this overlooked shift,
show how similar evaluation practices falsely imply reasoning deficits in other
benchmarks, and demonstrate that fairer methods dramatically reduce performance
gaps (e.g. on SIQA) and even yield superhuman results (OpenBookQA). In doing
so, we reveal how evaluation shapes perceived difficulty and offer guidelines
to ensure that multiple-choice evaluations accurately reflect actual model
capabilities.",2024-12-23,Łukasz Borchmann,http://arxiv.org/pdf/2412.17758v1,cs.CL
Deliberation in Latent Space via Differentiable Cache Augmentation,"Techniques enabling large language models (LLMs) to ""think more"" by
generating and attending to intermediate reasoning steps have shown promise in
solving complex problems. However, the standard approaches generate sequences
of discrete tokens immediately before responding, and so they can incur
significant latency costs and be challenging to optimize. In this work, we
demonstrate that a frozen LLM can be augmented with an offline coprocessor that
operates on the model's key-value (kv) cache. This coprocessor augments the
cache with a set of latent embeddings designed to improve the fidelity of
subsequent decoding. We train this coprocessor using the language modeling loss
from the decoder on standard pretraining data, while keeping the decoder itself
frozen. This approach enables the model to learn, in an end-to-end
differentiable fashion, how to distill additional computation into its
kv-cache. Because the decoder remains unchanged, the coprocessor can operate
offline and asynchronously, and the language model can function normally if the
coprocessor is unavailable or if a given cache is deemed not to require extra
computation. We show experimentally that when a cache is augmented, the decoder
achieves lower perplexity on numerous subsequent tokens. Furthermore, even
without any task-specific training, our experiments demonstrate that cache
augmentation consistently reduces perplexity and improves performance across a
range of reasoning-intensive tasks.",2024-12-23,"Luyang Liu, Jonas Pfeiffer, Jiaxing Wu, Jun Xie, Arthur Szlam",http://arxiv.org/pdf/2412.17747v1,cs.CL
RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation,"Repository-level code translation refers to translating an entire code
repository from one programming language to another while preserving the
functionality of the source repository. Many benchmarks have been proposed to
evaluate the performance of such code translators. However, previous benchmarks
mostly provide fine-grained samples, focusing at either code snippet, function,
or file-level code translation. Such benchmarks do not accurately reflect
real-world demands, where entire repositories often need to be translated,
involving longer code length and more complex functionalities. To address this
gap, we propose a new benchmark, named RepoTransBench, which is a real-world
repository-level code translation benchmark with an automatically executable
test suite. We conduct experiments on RepoTransBench to evaluate the
translation performance of 11 advanced LLMs. We find that the Success@1 score
(test success in one attempt) of the best-performing LLM is only 7.33%. To
further explore the potential of LLMs for repository-level code translation, we
provide LLMs with error-related feedback to perform iterative debugging and
observe an average 7.09% improvement on Success@1. However, even with this
improvement, the Success@1 score of the best-performing LLM is only 21%, which
may not meet the need for reliable automatic repository-level code translation.
Finally, we conduct a detailed error analysis and highlight current LLMs'
deficiencies in repository-level code translation, which could provide a
reference for further improvements.",2024-12-23,"Yanli Wang, Yanlin Wang, Suiquan Wang, Daya Guo, Jiachi Chen, John Grundy, Xilin Liu, Yuchi Ma, Mingzhi Mao, Hongyu Zhang, Zibin Zheng",http://arxiv.org/pdf/2412.17744v1,cs.CL
YuLan-Mini: An Open Data-efficient Language Model,"Effective pre-training of large language models (LLMs) has been challenging
due to the immense resource demands and the complexity of the technical
processes involved. This paper presents a detailed technical report on
YuLan-Mini, a highly capable base model with 2.42B parameters that achieves
top-tier performance among models of similar parameter scale. Our pre-training
approach focuses on enhancing training efficacy through three key technical
contributions: an elaborate data pipeline combines data cleaning with data
schedule strategies, a robust optimization method to mitigate training
instability, and an effective annealing approach that incorporates targeted
data selection and long context training. Remarkably, YuLan-Mini, trained on
1.08T tokens, achieves performance comparable to industry-leading models that
require significantly more data. To facilitate reproduction, we release the
full details of the data composition for each training phase. Project details
can be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.",2024-12-23,"Yiwen Hu, Huatong Song, Jia Deng, Jiapeng Wang, Jie Chen, Kun Zhou, Yutao Zhu, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Ji-Rong Wen",http://arxiv.org/pdf/2412.17743v2,cs.CL
Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization,"Extending the context length of Language Models (LMs) by improving Rotary
Position Embedding (RoPE) has become a trend. While existing works mainly
address RoPE's limitations within attention mechanism, this paper provides an
analysis across nearly all parts of LMs, uncovering their adverse effects on
length generalization for RoPE-based attention. Using Discrete Signal
Processing theory, we show that RoPE enables periodic attention by implicitly
achieving Non-Uniform Discrete Fourier Transform. However, this periodicity is
undermined by the spectral damage caused by: 1) linear layers and activation
functions outside of attention; 2) insufficiently trained frequency components
brought by time-domain truncation. Building on our observations, we propose
Fourier Position Embedding (FoPE), which enhances attention's frequency-domain
properties to improve both its periodic extension and length generalization.
FoPE constructs Fourier Series and zero-outs the destructive frequency
components, increasing model robustness against the spectrum damage.
Experiments across various model scales and benchmarks show that, within
varying context windows, FoPE maintains a more stable performance compared to
RoPE and ALiBi. Several analyses and ablations bring further support to our
method and theoretical modeling.",2024-12-23,"Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Ning Ding, Youbang Sun, Biqing Qi, Yuchen Fan, Xuekai Zhu, Bowen Zhou",http://arxiv.org/pdf/2412.17739v3,cs.CL
Chumor 2.0: Towards Benchmarking Chinese Humor Understanding,"Existing humor datasets and evaluations predominantly focus on English,
leaving limited resources for culturally nuanced humor in non-English languages
like Chinese. To address this gap, we construct Chumor, the first Chinese humor
explanation dataset that exceeds the size of existing humor datasets. Chumor is
sourced from Ruo Zhi Ba, a Chinese Reddit-like platform known for sharing
intellectually challenging and culturally specific jokes. We test ten LLMs
through direct and chain-of-thought prompting, revealing that Chumor poses
significant challenges to existing LLMs, with their accuracy slightly above
random and far below human. In addition, our analysis highlights that
human-annotated humor explanations are significantly better than those
generated by GPT-4o and ERNIE-4-turbo. We release Chumor at
https://huggingface.co/datasets/dnaihao/Chumor, our project page is at
https://dnaihao.github.io/Chumor-dataset/, our leaderboard is at
https://huggingface.co/spaces/dnaihao/Chumor, and our codebase is at
https://github.com/dnaihao/Chumor-dataset.",2024-12-23,"Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen Xia, Rada Mihalcea, Naihao Deng",http://arxiv.org/pdf/2412.17729v1,cs.CL
Knowledge Editing through Chain-of-Thought,"Large Language Models (LLMs) have demonstrated exceptional capabilities
across a wide range of natural language processing (NLP) tasks. However,
keeping these models up-to-date with evolving world knowledge remains a
significant challenge due to the high costs of frequent retraining. To address
this challenge, knowledge editing techniques have emerged to update LLMs with
new information without rebuilding the model from scratch. Among these, the
in-context editing paradigm stands out for its effectiveness in integrating new
knowledge while preserving the model's original capabilities. Despite its
potential, existing in-context knowledge editing methods are often
task-specific, focusing primarily on multi-hop QA tasks using structured
knowledge triples. Moreover, their reliance on few-shot prompting for task
decomposition makes them unstable and less effective in generalizing across
diverse tasks.
  In response to these limitations, we propose EditCoT, a novel knowledge
editing framework that flexibly and efficiently updates LLMs across various
tasks without retraining. EditCoT works by generating a chain-of-thought (CoT)
for a given input and then iteratively refining this CoT process using a CoT
editor based on updated knowledge. We evaluate EditCoT across a diverse range
of benchmarks, covering multiple languages and tasks. The results demonstrate
that our approach achieves state-of-the-art performance while offering superior
generalization, effectiveness, and stability compared to existing methods,
marking a significant advancement in the field of knowledge updating. Code and
data are available at: https://github.com/bebr2/EditCoT.",2024-12-23,"Changyue Wang, Weihang Su, Qingyao Ai, Yiqun Liu",http://arxiv.org/pdf/2412.17727v1,cs.CL
From Models to Microtheories: Distilling a Model's Topical Knowledge for Grounded Question Answering,"Recent reasoning methods (e.g., chain-of-thought, entailment reasoning) help
users understand how language models (LMs) answer a single question, but they
do little to reveal the LM's overall understanding, or ""theory,"" about the
question's topic, making it still hard to trust the model. Our goal is to
materialize such theories - here called microtheories (a linguistic analog of
logical microtheories) - as a set of sentences encapsulating an LM's core
knowledge about a topic. These statements systematically work together to
entail answers to a set of questions to both engender trust and improve
performance. Our approach is to first populate a knowledge store with
(model-generated) sentences that entail answers to training questions and then
distill those down to a core microtheory that is concise, general, and
non-redundant. We show that, when added to a general corpus (e.g., Wikipedia),
microtheories can supply critical, topical information not necessarily present
in the corpus, improving both a model's ability to ground its answers to
verifiable knowledge (i.e., show how answers are systematically entailed by
documents in the corpus, fully grounding up to +8% more answers), and the
accuracy of those grounded answers (up to +8% absolute). We also show that, in
a human evaluation in the medical domain, our distilled microtheories contain a
significantly higher concentration of topically critical facts than the
non-distilled knowledge store. Finally, we show we can quantify the coverage of
a microtheory for a topic (characterized by a dataset) using a notion of
$p$-relevance. Together, these suggest that microtheories are an efficient
distillation of an LM's topic-relevant knowledge, that they can usefully
augment existing corpora, and can provide both performance gains and an
interpretable, verifiable window into the model's knowledge of a topic.",2024-12-23,"Nathaniel Weir, Bhavana Dalvi Mishra, Orion Weller, Oyvind Tafjord, Sam Hornstein, Alexander Sabol, Peter Jansen, Benjamin Van Durme, Peter Clark",http://arxiv.org/pdf/2412.17701v2,cs.CL
Understanding the Logic of Direct Preference Alignment through Logic,"Recent direct preference alignment algorithms (DPA), such as DPO, have shown
great promise in aligning large language models to human preferences. While
this has motivated the development of many new variants of the original DPO
loss, understanding the differences between these recent proposals, as well as
developing new DPA loss functions, remains difficult given the lack of a
technical and conceptual framework for reasoning about the underlying semantics
of these algorithms. In this paper, we attempt to remedy this by formalizing
DPA losses in terms of discrete reasoning problems. Specifically, we ask: Given
an existing DPA loss, can we systematically derive a symbolic program that
characterizes its semantics? We propose a novel formalism for characterizing
preference losses for single model and reference model based approaches, and
identify symbolic forms for a number of commonly used DPA variants. Further, we
show how this formal view of preference learning sheds new light on both the
size and structure of the DPA loss landscape, making it possible to not only
rigorously characterize the relationships between recent loss proposals but
also to systematically explore the landscape and derive new loss functions from
first principles. We hope our framework and findings will help provide useful
guidance to those working on human AI alignment.",2024-12-23,"Kyle Richardson, Vivek Srikumar, Ashish Sabharwal",http://arxiv.org/pdf/2412.17696v2,cs.CL
RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG,"Conversational question answering (ConvQA) is a convenient means of searching
over RDF knowledge graphs (KGs), where a prevalent approach is to translate
natural language questions to SPARQL queries. However, SPARQL has certain
shortcomings: (i) it is brittle for complex intents and conversational
questions, and (ii) it is not suitable for more abstract needs. Instead, we
propose a novel two-pronged system where we fuse: (i) SQL-query results over a
database automatically derived from the KG, and (ii) text-search results over
verbalizations of KG facts. Our pipeline supports iterative retrieval: when the
results of any branch are found to be unsatisfactory, the system can
automatically opt for further rounds. We put everything together in a retrieval
augmented generation (RAG) setup, where an LLM generates a coherent response
from accumulated search results. We demonstrate the superiority of our proposed
system over several baselines on a knowledge graph of BMW automobiles.",2024-12-23,"Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech",http://arxiv.org/pdf/2412.17690v3,cs.CL
Large Language Model Safety: A Holistic Survey,"The rapid development and deployment of large language models (LLMs) have
introduced a new frontier in artificial intelligence, marked by unprecedented
capabilities in natural language understanding and generation. However, the
increasing integration of these models into critical applications raises
substantial safety concerns, necessitating a thorough examination of their
potential risks and associated mitigation strategies.
  This survey provides a comprehensive overview of the current landscape of LLM
safety, covering four major categories: value misalignment, robustness to
adversarial attacks, misuse, and autonomous AI risks. In addition to the
comprehensive review of the mitigation methodologies and evaluation resources
on these four aspects, we further explore four topics related to LLM safety:
the safety implications of LLM agents, the role of interpretability in
enhancing LLM safety, the technology roadmaps proposed and abided by a list of
AI companies and institutes for LLM safety, and AI governance aimed at LLM
safety with discussions on international cooperation, policy proposals, and
prospective regulatory directions.
  Our findings underscore the necessity for a proactive, multifaceted approach
to LLM safety, emphasizing the integration of technical solutions, ethical
considerations, and robust governance frameworks. This survey is intended to
serve as a foundational resource for academy researchers, industry
practitioners, and policymakers, offering insights into the challenges and
opportunities associated with the safe integration of LLMs into society.
Ultimately, it seeks to contribute to the safe and beneficial development of
LLMs, aligning with the overarching goal of harnessing AI for societal
advancement and well-being. A curated list of related papers has been publicly
available at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.",2024-12-23,"Dan Shi, Tianhao Shen, Yufei Huang, Zhigen Li, Yongqi Leng, Renren Jin, Chuang Liu, Xinwei Wu, Zishan Guo, Linhao Yu, Ling Shi, Bojian Jiang, Deyi Xiong",http://arxiv.org/pdf/2412.17686v1,cs.CL
Generating Completions for Fragmented Broca's Aphasic Sentences Using Large Language Models,"Broca's aphasia is a type of aphasia characterized by non-fluent, effortful
and fragmented speech production with relatively good comprehension. Since
traditional aphasia treatment methods are often time-consuming,
labour-intensive, and do not reflect real-world conversations, applying natural
language processing based approaches such as Large Language Models (LLMs) could
potentially contribute to improving existing treatment approaches. To address
this issue, we explore the use of sequence-to-sequence LLMs for completing
fragmented Broca's aphasic sentences. We first generate synthetic Broca's
aphasic data using a rule-based system designed to mirror the linguistic
characteristics of Broca's aphasic speech. Using this synthetic data, we then
fine-tune four pre-trained LLMs on the task of completing fragmented sentences.
We evaluate our fine-tuned models on both synthetic and authentic Broca's
aphasic data. We demonstrate LLMs' capability for reconstructing fragmented
sentences, with the models showing improved performance with longer input
utterances. Our result highlights the LLMs' potential in advancing
communication aids for individuals with Broca's aphasia and possibly other
clinical populations.",2024-12-23,"Sijbren van Vaals, Yevgen Matusevych, Frank Tsiwah",http://arxiv.org/pdf/2412.17669v1,cs.CL
The Power of Adaptation: Boosting In-Context Learning through Adaptive Prompting,"Large Language Models (LLMs) have demonstrated exceptional abilities across a
broad range of language-related tasks, including generating solutions to
complex reasoning problems. An effective technique to enhance LLM performance
is in-context learning, which encourages a step-by-step reasoning process by
including explanatory examples to guide the model's responses. However,
selecting appropriate exemplars for the model poses a challenge, as each
dataset demands a distinct set of exemplars to enable the LLM to learn
effectively and perform well on the test set. Current studies often rely on
uncertainty- or diversity-based selection strategies to select exemplars for
annotation and to improve model learning. However, these studies typically
employ a non-adaptive approach, selecting a set of exemplars all at once. We
argue that this non-adaptive strategy may result in a set of exemplars with
high redundancy in terms of the knowledge covered, ultimately reducing their
overall informativeness. To address this limitation, we propose
\textsc{Adaptive-Prompt}, a novel method that adaptively selects exemplars by
leveraging model feedback from previously chosen exemplars. Experimental
results show that \textsc{Adaptive-Prompt} significantly enhances LLM
performance across a variety of reasoning tasks.",2024-12-23,"Shuzhang Cai, Twumasi Mensah-Boateng, Xander Kuksov, Jing Yuan, Shaojie Tang",http://arxiv.org/pdf/2412.17891v1,cs.CL
Tracking the Feature Dynamics in LLM Training: A Mechanistic Study,"Understanding training dynamics and feature evolution is crucial for the
mechanistic interpretability of large language models (LLMs). Although sparse
autoencoders (SAEs) have been used to identify features within LLMs, a clear
picture of how these features evolve during training remains elusive. In this
study, we: (1) introduce SAE-Track, a novel method to efficiently obtain a
continual series of SAEs; (2) mechanistically investigate feature formation and
develop a progress measure for it ; and (3) analyze and visualize feature drift
during training. Our work provides new insights into the dynamics of features
in LLMs, enhancing our understanding of training mechanisms and feature
evolution.",2024-12-23,"Yang Xu, Yi Wang, Hao Wang",http://arxiv.org/pdf/2412.17626v2,cs.CL
LiveIdeaBench: Evaluating LLMs' Divergent Thinking for Scientific Idea Generation with Minimal Context,"While Large Language Models (LLMs) demonstrate remarkable capabilities in
scientific tasks such as literature analysis and experimental design (e.g.,
accurately extracting key findings from papers or generating coherent
experimental procedures), existing evaluation benchmarks primarily assess
performance using rich contextual inputs. We introduce LiveIdeaBench, a
comprehensive benchmark evaluating LLMs' scientific idea generation by
assessing divergent thinking capabilities using single-keyword prompts. Drawing
from Guilford's creativity theory, our benchmark employs a dynamic panel of
state-of-the-art LLMs to assess generated ideas across five key dimensions:
originality, feasibility, fluency, flexibility, and clarity. Through extensive
experimentation with over 40 leading models across 1,180 keywords spanning 22
scientific domains, we reveal that the scientific idea generation capabilities
measured by our benchmark, are poorly predicted by standard metrics of general
intelligence. Our results demonstrate that models like QwQ-32B-preview achieve
creative performance comparable to top-tier models such as
claude-3.7-sonnet:thinking, despite significant gaps in their general
intelligence scores. These findings highlight the need for specialized
evaluation benchmarks for scientific idea generation and suggest that enhancing
these idea generation capabilities in LLMs may require different training
strategies than those used for improving general problem-solving abilities,
potentially enabling a wider range of AI tools tailored for different stages of
the scientific process.",2024-12-23,"Kai Ruan, Xuan Wang, Jixiang Hong, Peng Wang, Yang Liu, Hao Sun",http://arxiv.org/pdf/2412.17596v3,cs.CL
Investigating Length Issues in Document-level Machine Translation,"Transformer architectures are increasingly effective at processing and
generating very long chunks of texts, opening new perspectives for
document-level machine translation (MT). In this work, we challenge the ability
of MT systems to handle texts comprising up to several thousands of tokens. We
design and implement a new approach designed to precisely measure the effect of
length increments on MT outputs. Our experiments with two representative
architectures unambiguously show that (a)~translation performance decreases
with the length of the input text; (b)~the position of sentences within the
document matters, and translation quality is higher for sentences occurring
earlier in a document. We further show that manipulating the distribution of
document lengths and of positional embeddings only marginally mitigates such
problems. Our results suggest that even though document-level MT is
computationally feasible, it does not yet match the performance of
sentence-based MT.",2024-12-23,"Ziqian Peng, Rachel Bawden, François Yvon",http://arxiv.org/pdf/2412.17592v2,cs.CL
ERUPD -- English to Roman Urdu Parallel Dataset,"Bridging linguistic gaps fosters global growth and cultural exchange. This
study addresses the challenges of Roman Urdu -- a Latin-script adaptation of
Urdu widely used in digital communication -- by creating a novel parallel
dataset comprising 75,146 sentence pairs. Roman Urdu's lack of standardization,
phonetic variability, and code-switching with English complicates language
processing. We tackled this by employing a hybrid approach that combines
synthetic data generated via advanced prompt engineering with real-world
conversational data from personal messaging groups. We further refined the
dataset through a human evaluation phase, addressing linguistic inconsistencies
and ensuring accuracy in code-switching, phonetic representations, and synonym
variability. The resulting dataset captures Roman Urdu's diverse linguistic
features and serves as a critical resource for machine translation, sentiment
analysis, and multilingual education.",2024-12-23,"Mohammed Furqan, Raahid Bin Khaja, Rayyan Habeeb",http://arxiv.org/pdf/2412.17562v1,cs.CL
A Survey of Query Optimization in Large Language Models,"\textit{Query Optimization} (QO) refers to techniques aimed at enhancing the
efficiency and quality of Large Language Models (LLMs) in understanding and
answering queries, especially complex ones in scenarios like
Retrieval-Augmented Generation (RAG). Specifically, RAG mitigates the
limitations of LLMs by dynamically retrieving and leveraging up-to-date
relevant information, which provides a cost-effective solution to the challenge
of LLMs producing plausible but potentially inaccurate responses. Recently, as
RAG evolves and incorporates multiple components that influence its
performance, QO has emerged as a critical element, playing a pivotal role in
determining the effectiveness of RAG's retrieval stage in accurately sourcing
the necessary multiple pieces of evidence to answer queries correctly. In this
paper, we trace the evolution of QO techniques by summarizing and analyzing
significant studies. Through an organized framework and categorization, we aim
to consolidate existing QO techniques in RAG, elucidate their technological
foundations, and highlight their potential to enhance the versatility and
applications of LLMs.",2024-12-23,"Mingyang Song, Mao Zheng",http://arxiv.org/pdf/2412.17558v1,cs.CL
Comparative Analysis of Document-Level Embedding Methods for Similarity Scoring on Shakespeare Sonnets and Taylor Swift Lyrics,"This study evaluates the performance of TF-IDF weighting, averaged Word2Vec
embeddings, and BERT embeddings for document similarity scoring across two
contrasting textual domains. By analysing cosine similarity scores, the
methods' strengths and limitations are highlighted. The findings underscore
TF-IDF's reliance on lexical overlap and Word2Vec's superior semantic
generalisation, particularly in cross-domain comparisons. BERT demonstrates
lower performance in challenging domains, likely due to insufficient
domainspecific fine-tuning.",2024-12-23,Klara Kramer,http://arxiv.org/pdf/2412.17552v1,cs.CL
"Resource-Aware Arabic LLM Creation: Model Adaptation, Integration, and Multi-Domain Testing","This paper presents a novel approach to fine-tuning the Qwen2-1.5B model for
Arabic language processing using Quantized Low-Rank Adaptation (QLoRA) on a
system with only 4GB VRAM. We detail the process of adapting this large
language model to the Arabic domain, using diverse datasets including Bactrian,
OpenAssistant, and Wikipedia Arabic corpora. Our methodology involves custom
data preprocessing, model configuration, and training optimization techniques
such as gradient accumulation and mixed-precision training. We address specific
challenges in Arabic NLP, including morphological complexity, dialectal
variations, and diacritical mark handling. Experimental results over 10,000
training steps show significant performance improvements, with the final loss
converging to 0.1083. We provide comprehensive analysis of GPU memory usage,
training dynamics, and model evaluation across various Arabic language tasks,
including text classification, question answering, and dialect identification.
The fine-tuned model demonstrates robustness to input perturbations and
improved handling of Arabic-specific linguistic phenomena. This research
contributes to multilingual AI by demonstrating a resource-efficient approach
for creating specialized language models, potentially democratizing access to
advanced NLP technologies for diverse linguistic communities. Our work paves
the way for future research in low-resource language adaptation and efficient
fine-tuning of large language models.",2024-12-23,Prakash Aryan,http://arxiv.org/pdf/2412.17548v1,cs.CL
Domain adapted machine translation: What does catastrophic forgetting forget and why?,"Neural Machine Translation (NMT) models can be specialized by domain
adaptation, often involving fine-tuning on a dataset of interest. This process
risks catastrophic forgetting: rapid loss of generic translation quality.
Forgetting has been widely observed, with many mitigation methods proposed.
However, the causes of forgetting and the relationship between forgetting and
adaptation data are under-explored.
  This paper takes a novel approach to understanding catastrophic forgetting
during NMT adaptation by investigating the impact of the data. We provide a
first investigation of what is forgotten, and why. We examine the relationship
between forgetting and the in-domain data, and show that the amount and type of
forgetting is linked to that data's target vocabulary coverage. Our findings
pave the way toward better informed NMT domain adaptation.",2024-12-23,"Danielle Saunders, Steve DeNeefe",http://arxiv.org/pdf/2412.17537v1,cs.CL
CiteBART: Learning to Generate Citations for Local Citation Recommendation,"Local citation recommendation (LCR) suggests a set of papers for a citation
placeholder within a given context. The task has evolved as generative
approaches have become more promising than the traditional pre-fetch and
re-rank-based state-of-the-art approaches. This paper introduces
citation-specific pre-training within an encoder-decoder architecture, where
author-date citation tokens are masked to learn to reconstruct them to fulfill
LCR. There are two variants for this pre-training. In the local context-only
base scheme (CiteBART-Base), the citation token in a local context is masked to
learn to predict the citation. The global version (CiteBART-Global) extends the
local context with the citing paper's title and abstract to enrich the learning
signal. CiteBART-Global achieves state-of-the-art performance on LCR benchmarks
except for the FullTextPeerRead dataset, which is quite small to see the
advantage of generative pre-training. The effect is significant in the larger
benchmarks, e.g., Refseer and ArXiv., with the Refseer benchmark-trained model
emerging as the best-performing model. We perform comprehensive experiments,
including an ablation study, a qualitative analysis, and a taxonomy of
hallucinations with detailed statistics. Our analyses confirm that
CiteBART-Global has a cross-dataset generalization capability; the macro
hallucination rate (MaHR) at the top-3 predictions is 4\%, and when the
ground-truth is in the top-k prediction list, the hallucination tendency in the
other predictions drops significantly.",2024-12-23,"Ege Yiğit Çelik, Selma Tekir",http://arxiv.org/pdf/2412.17534v2,cs.CL
Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse,"The surge in online content has created an urgent demand for robust detection
systems, especially in non-English contexts where current tools demonstrate
significant limitations. We present forePLay, a novel Polish language dataset
for erotic content detection, featuring over 24k annotated sentences with a
multidimensional taxonomy encompassing ambiguity, violence, and social
unacceptability dimensions. Our comprehensive evaluation demonstrates that
specialized Polish language models achieve superior performance compared to
multilingual alternatives, with transformer-based architectures showing
particular strength in handling imbalanced categories. The dataset and
accompanying analysis establish essential frameworks for developing
linguistically-aware content moderation systems, while highlighting critical
considerations for extending such capabilities to morphologically complex
languages.",2024-12-23,"Anna Kołos, Katarzyna Lorenc, Emilia Wiśnios, Agnieszka Karlińska",http://arxiv.org/pdf/2412.17533v2,cs.CL
DiffusionAttacker: Diffusion-Driven Prompt Manipulation for LLM Jailbreak,"Large Language Models (LLMs) are susceptible to generating harmful content
when prompted with carefully crafted inputs, a vulnerability known as LLM
jailbreaking. As LLMs become more powerful, studying jailbreak methods is
critical to enhancing security and aligning models with human values.
Traditionally, jailbreak techniques have relied on suffix addition or prompt
templates, but these methods suffer from limited attack diversity. This paper
introduces DiffusionAttacker, an end-to-end generative approach for jailbreak
rewriting inspired by diffusion models. Our method employs a
sequence-to-sequence (seq2seq) text diffusion model as a generator,
conditioning on the original prompt and guiding the denoising process with a
novel attack loss. Unlike previous approaches that use autoregressive LLMs to
generate jailbreak prompts, which limit the modification of already generated
tokens and restrict the rewriting space, DiffusionAttacker utilizes a seq2seq
diffusion model, allowing more flexible token modifications. This approach
preserves the semantic content of the original prompt while producing harmful
content. Additionally, we leverage the Gumbel-Softmax technique to make the
sampling process from the diffusion model's output distribution differentiable,
eliminating the need for iterative token search. Extensive experiments on
Advbench and Harmbench demonstrate that DiffusionAttacker outperforms previous
methods across various evaluation metrics, including attack success rate (ASR),
fluency, and diversity.",2024-12-23,"Hao Wang, Hao Li, Junda Zhu, Xinyuan Wang, Chengwei Pan, MinLie Huang, Lei Sha",http://arxiv.org/pdf/2412.17522v2,cs.CL
DRT: Deep Reasoning Translation via Long Chain-of-Thought,"Recently, O1-like models have emerged as representative examples,
illustrating the effectiveness of long chain-of-thought (CoT) in reasoning
tasks such as math and coding tasks. In this paper, we introduce DRT, an
attempt to bring the success of long CoT to neural machine translation (MT).
Specifically, in view of the literature books that might involve similes and
metaphors, translating these texts to a target language is very difficult in
practice due to cultural differences. In such cases, literal translation often
fails to convey the intended meaning effectively. Even for professional human
translators, considerable thought must be given to preserving semantics
throughout the translation process. To simulate LLMs' long thought ability in
MT, we first mine sentences containing similes or metaphors from existing
literature books, and then develop a multi-agent framework to translate these
sentences via long thought. In the multi-agent framework, a translator is used
to iteratively translate the source sentence under the suggestions provided by
an advisor. To ensure the effectiveness of the long thoughts, an evaluator is
also employed to quantify the translation quality in each round. In this way,
we collect tens of thousands of long-thought MT data, which is used to train
our DRT. Using Qwen2.5 and LLama-3.1 as the backbones, DRT models can learn the
thought process during machine translation, and outperform vanilla LLMs as well
as LLMs which are simply fine-tuning on the paired sentences without long
thought, showing its effectiveness.",2024-12-23,"Jiaan Wang, Fandong Meng, Yunlong Liang, Jie Zhou",http://arxiv.org/pdf/2412.17498v3,cs.CL
A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression,"In this work, we provide a thorough investigation of gist-based context
compression methods to improve long-context processing in large language
models. We focus on two key questions: (1) How well can these methods replace
full attention models? and (2) What potential failure patterns arise due to
compression? Through extensive experiments, we show that while gist-based
compression can achieve near-lossless performance on tasks like
retrieval-augmented generation and long-document QA, it faces challenges in
tasks like synthetic recall. Furthermore, we identify three key failure
patterns: lost by the boundary, lost if surprise, and lost along the way. To
mitigate these issues, we propose two effective strategies: fine-grained
autoencoding, which enhances the reconstruction of original token information,
and segment-wise token importance estimation, which adjusts optimization based
on token dependencies. Our work provides valuable insights into the
understanding of gist token-based context compression and offers practical
strategies for improving compression capabilities.",2024-12-23,"Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Xinting Huang, Dong Yu, Zhicheng Dou",http://arxiv.org/pdf/2412.17483v1,cs.CL
A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application,"LLM-based Multi-Agent Systems ( LLM-MAS ) have become a research hotspot
since the rise of large language models (LLMs). However, with the continuous
influx of new related works, the existing reviews struggle to capture them
comprehensively. This paper presents a comprehensive survey of these studies.
We first discuss the definition of LLM-MAS, a framework encompassing much of
previous work. We provide an overview of the various applications of LLM-MAS in
(i) solving complex tasks, (ii) simulating specific scenarios, and (iii)
evaluating generative agents. Building on previous studies, we also highlight
several challenges and propose future directions for research in this field.",2024-12-23,"Shuaihang Chen, Yuanxing Liu, Wei Han, Weinan Zhang, Ting Liu",http://arxiv.org/pdf/2412.17481v2,cs.CL
Developmental Predictive Coding Model for Early Infancy Mono and Bilingual Vocal Continual Learning,"Understanding how infants perceive speech sounds and language structures is
still an open problem. Previous research in artificial neural networks has
mainly focused on large dataset-dependent generative models, aiming to
replicate language-related phenomena such as ''perceptual narrowing''. In this
paper, we propose a novel approach using a small-sized generative neural
network equipped with a continual learning mechanism based on predictive coding
for mono-and bilingual speech sound learning (referred to as language sound
acquisition during ''critical period'') and a compositional optimization
mechanism for generation where no learning is involved (later infancy sound
imitation). Our model prioritizes interpretability and demonstrates the
advantages of online learning: Unlike deep networks requiring substantial
offline training, our model continuously updates with new data, making it
adaptable and responsive to changing inputs. Through experiments, we
demonstrate that if second language acquisition occurs during later infancy,
the challenges associated with learning a foreign language after the critical
period amplify, replicating the perceptual narrowing effect.",2024-12-23,"Xiaodan Chen, Alexandre Pitti, Mathias Quoy, Nancy F Chen",http://arxiv.org/pdf/2412.17456v1,cs.CL
Diving into Self-Evolving Training for Multimodal Reasoning,"Reasoning ability is essential for Large Multimodal Models (LMMs). In the
absence of multimodal chain-of-thought annotated data, self-evolving training,
where the model learns from its own outputs, has emerged as an effective and
scalable approach for enhancing reasoning abilities. Despite its growing usage,
a comprehensive understanding of self-evolving training, particularly in the
context of multimodal reasoning, remains limited. In this paper, we delve into
the intricacies of self-evolving training for multimodal reasoning, pinpointing
three key factors: Training Method, Reward Model, and Prompt Variation. We
systematically examine each factor and explore how various configurations
affect the training's effectiveness. Our analysis leads to a set of best
practices for each factor, aimed at optimizing multimodal reasoning.
Furthermore, we explore the Self-Evolution Dynamics during training and the
impact of automatic balancing mechanisms in boosting performance. After all the
investigations, we present a final recipe for self-evolving training in
multimodal reasoning, encapsulating these design choices into a framework we
call MSTaR (Multimodal Self-evolving Training for Reasoning), which is
universally effective for models with different sizes on various benchmarks,
e.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning
benchmarks without using additional human annotations, as demonstrated on
MiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this
study fills a significant gap in the understanding of self-evolving training
for multimodal reasoning and offers a robust framework for future research. Our
policy and reward models, as well as the collected data, is released to
facilitate further investigation in multimodal reasoning.",2024-12-23,"Wei Liu, Junlong Li, Xiwen Zhang, Fan Zhou, Yu Cheng, Junxian He",http://arxiv.org/pdf/2412.17451v1,cs.CL
Measuring Contextual Informativeness in Child-Directed Text,"To address an important gap in creating children's stories for vocabulary
enrichment, we investigate the automatic evaluation of how well stories convey
the semantics of target vocabulary words, a task with substantial implications
for generating educational content. We motivate this task, which we call
measuring contextual informativeness in children's stories, and provide a
formal task definition as well as a dataset for the task. We further propose a
method for automating the task using a large language model (LLM). Our
experiments show that our approach reaches a Spearman correlation of 0.4983
with human judgments of informativeness, while the strongest baseline only
obtains a correlation of 0.3534. An additional analysis shows that the
LLM-based approach is able to generalize to measuring contextual
informativeness in adult-directed text, on which it also outperforms all
baselines.",2024-12-23,"Maria Valentini, Téa Wright, Ali Marashian, Jennifer Weber, Eliana Colunga, Katharina von der Wense",http://arxiv.org/pdf/2412.17427v1,cs.CL
Just What You Desire: Constrained Timeline Summarization with Self-Reflection for Enhanced Relevance,"Given news articles about an entity, such as a public figure or organization,
timeline summarization (TLS) involves generating a timeline that summarizes the
key events about the entity. However, the TLS task is too underspecified, since
what is of interest to each reader may vary, and hence there is not a single
ideal or optimal timeline. In this paper, we introduce a novel task, called
Constrained Timeline Summarization (CTLS), where a timeline is generated in
which all events in the timeline meet some constraint. An example of a
constrained timeline concerns the legal battles of Tiger Woods, where only
events related to his legal problems are selected to appear in the timeline. We
collected a new human-verified dataset of constrained timelines involving 47
entities and 5 constraints per entity. We propose an approach that employs a
large language model (LLM) to summarize news articles according to a specified
constraint and cluster them to identify key events to include in a constrained
timeline. In addition, we propose a novel self-reflection method during summary
generation, demonstrating that this approach successfully leads to improved
performance.",2024-12-23,"Muhammad Reza Qorib, Qisheng Hu, Hwee Tou Ng",http://arxiv.org/pdf/2412.17408v1,cs.CL
WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models,"Despite recent progress achieved by code large language models (LLMs), their
remarkable abilities are largely dependent on fine-tuning on the high-quality
data, posing challenges for data collection and annotation. To address this,
current methods often design various data flywheels to collect complex code
instructions, enabling models to handle more intricate tasks. However, these
approaches typically rely on off-the-shelf datasets and data augmentation from
a limited set of proprietary LLMs (e.g., Claude, GPT4, and so on), which
restricts the diversity of the constructed data and makes it prone to systemic
biases. In this paper, we propose WarriorCoder, a novel paradigm learns from
expert battles to address these limitations. Specifically, we create an arena
where leading expert code LLMs challenge each other, with evaluations conducted
by impartial judges. This competitive framework generates novel training data
from scratch, leveraging the strengths of all participants. Experimental
results show that WarriorCoder achieves state-of-the-art performance compared
to previous models of the same size, even without relying on proprietary LLMs.",2024-12-23,"Huawen Feng, Pu Zhao, Qingfeng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang",http://arxiv.org/pdf/2412.17395v3,cs.CL
Interweaving Memories of a Siamese Large Language Model,"Parameter-efficient fine-tuning (PEFT) methods optimize large language models
(LLMs) by modifying or introducing a small number of parameters to enhance
alignment with downstream tasks. However, they can result in catastrophic
forgetting, where LLMs prioritize new knowledge at the expense of comprehensive
world knowledge. A promising approach to mitigate this issue is to recall prior
memories based on the original knowledge. To this end, we propose a
model-agnostic PEFT framework, IMSM, which Interweaves Memories of a Siamese
Large Language Model. Specifically, our siamese LLM is equipped with an
existing PEFT method. Given an incoming query, it generates two distinct
memories based on the pre-trained and fine-tuned parameters. IMSM then
incorporates an interweaving mechanism that regulates the contributions of both
original and enhanced memories when generating the next token. This framework
is theoretically applicable to all open-source LLMs and existing PEFT methods.
We conduct extensive experiments across various benchmark datasets, evaluating
the performance of popular open-source LLMs using the proposed IMSM, in
comparison to both classical and leading PEFT methods. Our findings indicate
that IMSM maintains comparable time and space efficiency to backbone PEFT
methods while significantly improving performance and effectively mitigating
catastrophic forgetting.",2024-12-23,"Xin Song, Zhikai Xue, Guoxiu He, Jiawei Liu, Wei Lu",http://arxiv.org/pdf/2412.17383v1,cs.CL
Boosting LLM via Learning from Data Iteratively and Selectively,"Datasets nowadays are generally constructed from multiple sources and using
different synthetic techniques, making data de-noising and de-duplication
crucial before being used for post-training. In this work, we propose to
perform instruction tuning by iterative data selection (\ApproachName{}). We
measure the quality of a sample from complexity and diversity simultaneously.
Instead of calculating the complexity score once for all before fine-tuning, we
highlight the importance of updating this model-specific score during
fine-tuning to accurately accommodate the dynamic changes of the model. On the
other hand, the diversity score is defined on top of the samples' responses
under the consideration of their informativeness. IterIT integrates the
strengths of both worlds by iteratively updating the complexity score for the
top-ranked samples and greedily selecting the ones with the highest
complexity-diversity score. Experiments on multiple instruction-tuning data
demonstrate consistent improvements of IterIT over strong baselines. Moreover,
our approach also generalizes well to domain-specific scenarios and different
backbone models. All resources will be available at
https://github.com/JiaQiSJTU/IterIT.",2024-12-23,"Qi Jia, Siyu Ren, Ziheng Qin, Fuzhao Xue, Jinjie Ni, Yang You",http://arxiv.org/pdf/2412.17365v1,cs.CL
An Experimental Evaluation of Japanese Tokenizers for Sentiment-Based Text Classification,"This study investigates the performance of three popular tokenization tools:
MeCab, Sudachi, and SentencePiece, when applied as a preprocessing step for
sentiment-based text classification of Japanese texts. Using Term
Frequency-Inverse Document Frequency (TF-IDF) vectorization, we evaluate two
traditional machine learning classifiers: Multinomial Naive Bayes and Logistic
Regression. The results reveal that Sudachi produces tokens closely aligned
with dictionary definitions, while MeCab and SentencePiece demonstrate faster
processing speeds. The combination of SentencePiece, TF-IDF, and Logistic
Regression outperforms the other alternatives in terms of classification
performance.",2024-12-23,"Andre Rusli, Makoto Shishido",http://arxiv.org/pdf/2412.17361v1,cs.CL
Three-Class Text Sentiment Analysis Based on LSTM,"Sentiment analysis is a crucial task in natural language processing (NLP)
with applications in public opinion monitoring, market research, and beyond.
This paper introduces a three-class sentiment classification method for Weibo
comments using Long Short-Term Memory (LSTM) networks to discern positive,
neutral, and negative sentiments. LSTM, as a deep learning model, excels at
capturing long-distance dependencies in text data, providing significant
advantages over traditional machine learning approaches. Through preprocessing
and feature extraction from Weibo comment texts, our LSTM model achieves
precise sentiment prediction. Experimental results demonstrate superior
performance, achieving an accuracy of 98.31% and an F1 score of 98.28%, notably
outperforming conventional models and other deep learning methods. This
underscores the effectiveness of LSTM in capturing nuanced sentiment
information within text, thereby enhancing classification accuracy. Despite its
strengths, the LSTM model faces challenges such as high computational
complexity and slower processing times for lengthy texts. Moreover, complex
emotional expressions like sarcasm and humor pose additional difficulties.
Future work could explore combining pre-trained models or advancing feature
engineering techniques to further improve both accuracy and practicality.
Overall, this study provides an effective solution for sentiment analysis on
Weibo comments.",2024-12-23,Yin Qixuan,http://arxiv.org/pdf/2412.17347v1,cs.CL
MineAgent: Towards Remote-Sensing Mineral Exploration with Multimodal Large Language Models,"Remote-sensing mineral exploration is critical for identifying economically
viable mineral deposits, yet it poses significant challenges for multimodal
large language models (MLLMs). These include limitations in domain-specific
geological knowledge and difficulties in reasoning across multiple
remote-sensing images, further exacerbating long-context issues. To address
these, we present MineAgent, a modular framework leveraging hierarchical
judging and decision-making modules to improve multi-image reasoning and
spatial-spectral integration. Complementing this, we propose MineBench, a
benchmark specific for evaluating MLLMs in domain-specific mineral exploration
tasks using geological and hyperspectral data. Extensive experiments
demonstrate the effectiveness of MineAgent, highlighting its potential to
advance MLLMs in remote-sensing mineral exploration.",2024-12-23,"Beibei Yu, Tao Shen, Hongbin Na, Ling Chen, Denqi Li",http://arxiv.org/pdf/2412.17339v1,cs.CL
A Dual-Perspective Metaphor Detection Framework Using Large Language Models,"Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.",2024-12-23,"Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, Jinsong Su",http://arxiv.org/pdf/2412.17332v2,cs.CL
Assessing Human Editing Effort on LLM-Generated Texts via Compression-Based Edit Distance,"Assessing the extent of human edits on texts generated by Large Language
Models (LLMs) is crucial to understanding the human-AI interactions and
improving the quality of automated text generation systems. Existing edit
distance metrics, such as Levenshtein, BLEU, ROUGE, and TER, often fail to
accurately measure the effort required for post-editing, especially when edits
involve substantial modifications, such as block operations. In this paper, we
introduce a novel compression-based edit distance metric grounded in the
Lempel-Ziv-77 algorithm, designed to quantify the amount of post-editing
applied to LLM-generated texts. Our method leverages the properties of text
compression to measure the informational difference between the original and
edited texts. Through experiments on real-world human edits datasets, we
demonstrate that our proposed metric is highly correlated with actual edit time
and effort. We also show that LLMs exhibit an implicit understanding of editing
speed, that aligns well with our metric. Furthermore, we compare our metric
with existing ones, highlighting its advantages in capturing complex edits with
linear computational efficiency. Our code and data are available at:
https://github.com/NDV-tiime/CompressionDistance",2024-12-23,"Nicolas Devatine, Louis Abraham",http://arxiv.org/pdf/2412.17321v1,cs.CL
Fast Gradient Computation for RoPE Attention in Almost Linear Time,"The Rotary Position Embedding (RoPE) mechanism has become a powerful
enhancement to the Transformer architecture, which enables models to capture
token relationships when encoding positional information. However, the RoPE
mechanisms make the computations of attention mechanisms more complicated,
which makes efficient algorithms challenging. Earlier research introduced
almost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens,
algorithms for the forward computation under specific parameter settings.
However, achieving a subquadratic time algorithm for other parameter regimes
remains impossible unless the widely accepted Strong Exponential Time
Hypothesis (SETH) is disproven. In this work, we develop the first almost
linear time algorithm for backward computations in the RoPE-based attention
under bounded entries. Our approach builds on recent advancements in fast RoPE
attention computations, utilizing a novel combination of the polynomial method
and the Fast Fourier Transform. Furthermore, we show that with lower bounds
derived from the SETH, the bounded entry condition is necessary for
subquadratic performance.",2024-12-23,"Yifang Chen, Jiayan Huo, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song",http://arxiv.org/pdf/2412.17316v2,cs.CL
CodeV: Issue Resolving with Visual Data,"Large Language Models (LLMs) have advanced rapidly in recent years, with
their applications in software engineering expanding to more complex
repository-level tasks. GitHub issue resolving is a key challenge among these
tasks. While recent approaches have made progress on this task, they focus on
textual data within issues, neglecting visual data. However, this visual data
is crucial for resolving issues as it conveys additional knowledge that text
alone cannot. We propose CodeV, the first approach to leveraging visual data to
enhance the issue-resolving capabilities of LLMs. CodeV resolves each issue by
following a two-phase process: data processing and patch generation. To
evaluate CodeV, we construct a benchmark for visual issue resolving, namely
Visual SWE-bench. Through extensive experiments, we demonstrate the
effectiveness of CodeV, as well as provide valuable insights into leveraging
visual data to resolve GitHub issues.",2024-12-23,"Linhao Zhang, Daoguang Zan, Quanshun Yang, Zhirong Huang, Dong Chen, Bo Shen, Tianyu Liu, Yongshun Gong, Pengjie Huang, Xudong Lu, Guangtai Liang, Lizhen Cui, Qianxiang Wang",http://arxiv.org/pdf/2412.17315v1,cs.CL
Friends-MMC: A Dataset for Multi-modal Multi-party Conversation Understanding,"Multi-modal multi-party conversation (MMC) is a less studied yet important
topic of research due to that it well fits real-world scenarios and thus
potentially has more widely-used applications. Compared with the traditional
multi-modal conversations, MMC requires stronger character-centered
understanding abilities as there are many interlocutors appearing in both the
visual and textual context. To facilitate the study of this problem, we present
Friends-MMC in this paper, an MMC dataset that contains 24,000+ unique
utterances paired with video context. To explore the character-centered
understanding of the dialogue, we also annotate the speaker of each utterance,
the names and bounding bboxes of faces that appear in the video. Based on this
Friends-MMC dataset, we further study two fundamental MMC tasks: conversation
speaker identification and conversation response prediction, both of which have
the multi-party nature with the video or image as visual context. For
conversation speaker identification, we demonstrate the inefficiencies of
existing methods such as pre-trained models, and propose a simple yet effective
baseline method that leverages an optimization solver to utilize the context of
two modalities to achieve better performance. For conversation response
prediction, we fine-tune generative dialogue models on Friend-MMC, and analyze
the benefits of speaker information. The code and dataset is publicly available
at https://github.com/yellow-binary-tree/Friends-MMC and thus we call for more
attention on modeling speaker information when understanding conversations.",2024-12-23,"Yueqian Wang, Xiaojun Meng, Yuxuan Wang, Jianxin Liang, Qun Liu, Dongyan Zhao",http://arxiv.org/pdf/2412.17295v1,cs.CL
Learning from Mistakes: Self-correct Adversarial Training for Chinese Unnatural Text Correction,"Unnatural text correction aims to automatically detect and correct spelling
errors or adversarial perturbation errors in sentences. Existing methods
typically rely on fine-tuning or adversarial training to correct errors, which
have achieved significant success. However, these methods exhibit poor
generalization performance due to the difference in data distribution between
training data and real-world scenarios, known as the exposure bias problem. In
this paper, we propose a self-correct adversarial training framework for
\textbf{L}earn\textbf{I}ng from \textbf{MI}s\textbf{T}akes (\textbf{LIMIT}),
which is a task- and model-independent framework to correct unnatural errors or
mistakes. Specifically, we fully utilize errors generated by the model that are
actively exposed during the inference phase, i.e., predictions that are
inconsistent with the target. This training method not only simulates potential
errors in real application scenarios, but also mitigates the exposure bias of
the traditional training process. Meanwhile, we design a novel decoding
intervention strategy to maintain semantic consistency. Extensive experimental
results on Chinese unnatural text error correction datasets show that our
proposed method can correct multiple forms of errors and outperforms the
state-of-the-art text correction methods. In addition, extensive results on
Chinese and English datasets validate that LIMIT can serve as a plug-and-play
defense module and can extend to new models and datasets without further
training.",2024-12-23,"Xuan Feng, Tianlong Gu, Xiaoli Liu, Liang Chang",http://arxiv.org/pdf/2412.17279v1,cs.CL
LegalAgentBench: Evaluating LLM Agents in Legal Domain,"With the increasing intelligence and autonomy of LLM agents, their potential
applications in the legal domain are becoming increasingly apparent. However,
existing general-domain benchmarks cannot fully capture the complexity and
subtle nuances of real-world judicial cognition and decision-making. Therefore,
we propose LegalAgentBench, a comprehensive benchmark specifically designed to
evaluate LLM Agents in the Chinese legal domain. LegalAgentBench includes 17
corpora from real-world legal scenarios and provides 37 tools for interacting
with external knowledge. We designed a scalable task construction framework and
carefully annotated 300 tasks. These tasks span various types, including
multi-hop reasoning and writing, and range across different difficulty levels,
effectively reflecting the complexity of real-world legal scenarios. Moreover,
beyond evaluating final success, LegalAgentBench incorporates keyword analysis
during intermediate processes to calculate progress rates, enabling more
fine-grained evaluation. We evaluated eight popular LLMs, highlighting the
strengths, limitations, and potential areas for improvement of existing models
and methods. LegalAgentBench sets a new benchmark for the practical application
of LLMs in the legal domain, with its code and data available at
\url{https://github.com/CSHaitao/LegalAgentBench}.",2024-12-23,"Haitao Li, Junjie Chen, Jingli Yang, Qingyao Ai, Wei Jia, Youfeng Liu, Kai Lin, Yueyue Wu, Guozhi Yuan, Yiran Hu, Wuyue Wang, Yiqun Liu, Minlie Huang",http://arxiv.org/pdf/2412.17259v1,cs.CL
B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners,"In the absence of extensive human-annotated data for complex reasoning tasks,
self-improvement -- where models are trained on their own outputs -- has
emerged as a primary method for enhancing performance. However, the critical
factors underlying the mechanism of these iterative self-improving methods
remain poorly understood, such as under what conditions self-improvement is
effective, and what are the bottlenecks in the current iterations. In this
work, we identify and propose methods to monitor two pivotal factors in this
iterative process: (1) the model's ability to generate sufficiently diverse
responses (exploration); and (2) the effectiveness of external rewards in
distinguishing high-quality candidates from lower-quality ones (exploitation).
Using mathematical reasoning as a case study, we begin with a quantitative
analysis to track the dynamics of exploration and exploitation, discovering
that a model's exploratory capabilities rapidly deteriorate over iterations,
and the effectiveness of exploiting external rewards diminishes as well.
Motivated by these findings, we introduce B-STaR, a Self-Taught Reasoning
framework that autonomously adjusts configurations across iterations to Balance
exploration and exploitation, thereby optimizing the self-improving
effectiveness based on the current policy model and available rewards. Our
experiments on mathematical reasoning, coding, and commonsense reasoning
demonstrate that B-STaR not only enhances the model's exploratory capabilities
throughout training but also achieves a more effective balance between
exploration and exploitation, leading to superior performance.",2024-12-23,"Weihao Zeng, Yuzhen Huang, Lulu Zhao, Yijun Wang, Zifei Shan, Junxian He",http://arxiv.org/pdf/2412.17256v2,cs.CL
Unlocking Cross-Lingual Sentiment Analysis through Emoji Interpretation: A Multimodal Generative AI Approach,"Emojis have become ubiquitous in online communication, serving as a universal
medium to convey emotions and decorative elements. Their widespread use
transcends language and cultural barriers, enhancing understanding and
fostering more inclusive interactions. While existing work gained valuable
insight into emojis understanding, exploring emojis' capability to serve as a
universal sentiment indicator leveraging large language models (LLMs) has not
been thoroughly examined. Our study aims to investigate the capacity of emojis
to serve as reliable sentiment markers through LLMs across languages and
cultures. We leveraged the multimodal capabilities of ChatGPT to explore the
sentiments of various representations of emojis and evaluated how well
emoji-conveyed sentiment aligned with text sentiment on a multi-lingual dataset
collected from 32 countries. Our analysis reveals that the accuracy of
LLM-based emoji-conveyed sentiment is 81.43%, underscoring emojis' significant
potential to serve as a universal sentiment marker. We also found a consistent
trend that the accuracy of sentiment conveyed by emojis increased as the number
of emojis grew in text. The results reinforce the potential of emojis to serve
as global sentiment indicators, offering insight into fields such as
cross-lingual and cross-cultural sentiment analysis on social media platforms.
Code: https://github.com/ResponsibleAILab/emoji-universal-sentiment.",2024-12-23,"Rafid Ishrak Jahan, Heng Fan, Haihua Chen, Yunhe Feng",http://arxiv.org/pdf/2412.17255v1,cs.CL
Highly Optimized Kernels and Fine-Grained Codebooks for LLM Inference on Arm CPUs,"Large language models (LLMs) have transformed the way we think about language
understanding and generation, enthralling both researchers and developers.
However, deploying LLMs for inference has been a significant challenge due to
their unprecedented size and resource requirements. While quantizing model
weights to sub-byte precision has emerged as a promising solution to ease
memory pressure, the group quantization formats commonly used for LLM
quantization have significant compute overheads and a resource-intensive
dequantization process. As a result, a higher proportion of compute
instructions do not perform multiplies, i.e., real work, rendering them
unsuitable for meeting the required latency requirements for LLMs deployed on
commodity CPUs. In this work, we propose a set of highly optimized kernels to
accelerate LLM inference and unleash the full potential of CPUs, particularly
Arm CPUs. These kernels amortize the cost of loading the operands and the cost
of weight unpacking across multiple output rows. This, along with the
introduction of an optimized interleaved group data layout for weights and
decompression path optimizations to reduce unnecessary operations and
dequantization overhead while maximizing the use of vector and matrix multiply
operations, significantly improves the efficiency of MAC operations.
Furthermore, we present a groupwise non-uniform codebook-based quantization
method for ultra-low-precision quantization of LLMs to better match non-uniform
patterns in their weight distributions, demonstrating better throughput during
token generation while ensuring better quality than the state-of-the-art.
Applying these improvements to 4-bit LLMs results in a 3-3.2x improvement in
prompt processing and a 2x improvement in autoregressive decoding on Arm CPUs,
compared to LLaMA.cpp-based solution. The optimized kernels are available at
https://github.com/ggerganov/llama.cpp.",2024-12-23,"Dibakar Gope, David Mansell, Danny Loh, Ian Bratt",http://arxiv.org/pdf/2501.00032v1,cs.CL
On the Generalization and Adaptation Ability of Machine-Generated Text Detectors in Academic Writing,"The rising popularity of large language models (LLMs) has raised concerns
about machine-generated text (MGT), particularly in academic settings, where
issues like plagiarism and misinformation are prevalent. As a result,
developing a highly generalizable and adaptable MGT detection system has become
an urgent priority. Given that LLMs are most commonly misused in academic
writing, this work investigates the generalization and adaptation capabilities
of MGT detectors in three key aspects specific to academic writing: First, we
construct MGT-Acedemic, a large-scale dataset comprising over 336M tokens and
749K samples. MGT-Acedemic focuses on academic writing, featuring human-written
texts (HWTs) and MGTs across STEM, Humanities, and Social Sciences, paired with
an extensible code framework for efficient benchmarking. Second, we benchmark
the performance of various detectors for binary classification and attribution
tasks in both in-domain and cross-domain settings. This benchmark reveals the
often-overlooked challenges of attribution tasks. Third, we introduce a novel
attribution task where models have to adapt to new classes over time without
(or with very limited) access to prior training data in both few-shot and
many-shot scenarios. We implement eight different adapting techniques to
improve the performance and highlight the inherent complexity of the task. Our
findings provide insights into the generalization and adaptation ability of MGT
detectors across diverse scenarios and lay the foundation for building robust,
adaptive detection systems. The code framework is available at
https://github.com/Y-L-LIU/MGTBench-2.0.",2024-12-23,"Yule Liu, Zhiyuan Zhong, Yifan Liao, Zhen Sun, Jingyi Zheng, Jiaheng Wei, Qingyuan Gong, Fenghua Tong, Yang Chen, Yang Zhang, Xinlei He",http://arxiv.org/pdf/2412.17242v3,cs.CL
Brain-to-Text Benchmark '24: Lessons Learned,"Speech brain-computer interfaces aim to decipher what a person is trying to
say from neural activity alone, restoring communication to people with
paralysis who have lost the ability to speak intelligibly. The Brain-to-Text
Benchmark '24 and associated competition was created to foster the advancement
of decoding algorithms that convert neural activity to text. Here, we summarize
the lessons learned from the competition ending on June 1, 2024 (the top 4
entrants also presented their experiences in a recorded webinar). The largest
improvements in accuracy were achieved using an ensembling approach, where the
output of multiple independent decoders was merged using a fine-tuned large
language model (an approach used by all 3 top entrants). Performance gains were
also found by improving how the baseline recurrent neural network (RNN) model
was trained, including by optimizing learning rate scheduling and by using a
diphone training objective. Improving upon the model architecture itself proved
more difficult, however, with attempts to use deep state space models or
transformers not yet appearing to offer a benefit over the RNN baseline. The
benchmark will remain open indefinitely to support further work towards
increasing the accuracy of brain-to-text algorithms.",2024-12-23,"Francis R. Willett, Jingyuan Li, Trung Le, Chaofei Fan, Mingfei Chen, Eli Shlizerman, Yue Chen, Xin Zheng, Tatsuo S. Okubo, Tyler Benster, Hyun Dong Lee, Maxwell Kounga, E. Kelly Buchanan, David Zoltowski, Scott W. Linderman, Jaimie M. Henderson",http://arxiv.org/pdf/2412.17227v1,cs.CL
"COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations","This study presents a data-driven analysis of COVID-19 discourse on YouTube,
examining the sentiment, toxicity, and thematic patterns of video content
published between January 2023 and October 2024. The analysis involved applying
advanced natural language processing (NLP) techniques: sentiment analysis with
VADER, toxicity detection with Detoxify, and topic modeling using Latent
Dirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of
video descriptions were positive, 36.63% were neutral, and 14.05% were
negative, indicating a generally informative and supportive tone in
pandemic-related content. Toxicity analysis identified only 0.91% of content as
toxic, suggesting minimal exposure to toxic content. Topic modeling revealed
two main themes, with 66.74% of the videos covering general health information
and pandemic-related impacts and 33.26% focused on news and real-time updates,
highlighting the dual informational role of YouTube. A recommendation system
was also developed using TF-IDF vectorization and cosine similarity, refined by
sentiment, toxicity, and topic filters to ensure relevant and context-aligned
video recommendations. This system achieved 69% aggregate coverage, with
monthly coverage rates consistently above 85%, demonstrating robust performance
and adaptability over time. Evaluation across recommendation sizes showed
coverage reaching 69% for five video recommendations and 79% for ten video
recommendations per video. In summary, this work presents a framework for
understanding COVID-19 discourse on YouTube and a recommendation system that
supports user engagement while promoting responsible and relevant content
related to COVID-19.",2024-12-22,"Vanessa Su, Nirmalya Thakur",http://arxiv.org/pdf/2412.17180v1,cs.CL
Analysis of Speech Temporal Dynamics in the Context of Speaker Verification and Voice Anonymization,"In this paper, we investigate the impact of speech temporal dynamics in
application to automatic speaker verification and speaker voice anonymization
tasks. We propose several metrics to perform automatic speaker verification
based only on phoneme durations. Experimental results demonstrate that phoneme
durations leak some speaker information and can reveal speaker identity from
both original and anonymized speech. Thus, this work emphasizes the importance
of taking into account the speaker's speech rate and, more importantly, the
speaker's phonetic duration characteristics, as well as the need to modify them
in order to develop anonymization systems with strong privacy protection
capacity.",2024-12-22,"Natalia Tomashenko, Emmanuel Vincent, Marc Tommasi",http://arxiv.org/pdf/2412.17164v1,cs.CL
A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops,"Agentic AI systems use specialized agents to handle tasks within complex
workflows, enabling automation and efficiency. However, optimizing these
systems often requires labor-intensive, manual adjustments to refine roles,
tasks, and interactions. This paper introduces a framework for autonomously
optimizing Agentic AI solutions across industries, such as NLP-driven
enterprise applications. The system employs agents for Refinement, Execution,
Evaluation, Modification, and Documentation, leveraging iterative feedback
loops powered by an LLM (Llama 3.2-3B). The framework achieves optimal
performance without human input by autonomously generating and testing
hypotheses to improve system configurations. This approach enhances scalability
and adaptability, offering a robust solution for real-world applications in
dynamic environments. Case studies across diverse domains illustrate the
transformative impact of this framework, showcasing significant improvements in
output quality, relevance, and actionability. All data for these case studies,
including original and evolved agent codes, along with their outputs, are here:
https://anonymous.4open.science/r/evolver-1D11/",2024-12-22,"Kamer Ali Yuksel, Hassan Sawaf",http://arxiv.org/pdf/2412.17149v1,cs.CL
Bridging Auditory Perception and Language Comprehension through MEG-Driven Encoding Models,"Understanding the neural mechanisms behind auditory and linguistic processing
is key to advancing cognitive neuroscience. In this study, we use
Magnetoencephalography (MEG) data to analyze brain responses to spoken language
stimuli. We develop two distinct encoding models: an audio-to-MEG encoder,
which uses time-frequency decompositions (TFD) and wav2vec2 latent space
representations, and a text-to-MEG encoder, which leverages CLIP and GPT-2
embeddings. Both models successfully predict neural activity, demonstrating
significant correlations between estimated and observed MEG signals. However,
the text-to-MEG model outperforms the audio-based model, achieving higher
Pearson Correlation (PC) score. Spatially, we identify that auditory-based
embeddings (TFD and wav2vec2) predominantly activate lateral temporal regions,
which are responsible for primary auditory processing and the integration of
auditory signals. In contrast, textual embeddings (CLIP and GPT-2) primarily
engage the frontal cortex, particularly Broca's area, which is associated with
higher-order language processing, including semantic integration and language
production, especially in the 8-30 Hz frequency range. The strong involvement
of these regions suggests that auditory stimuli are processed through more
direct sensory pathways, while linguistic information is encoded via networks
that integrate meaning and cognitive control. Our results reveal distinct
neural pathways for auditory and linguistic information processing, with higher
encoding accuracy for text representations in the frontal regions. These
insights refine our understanding of the brain's functional architecture in
processing auditory and textual information, offering quantitative advancements
in the modelling of neural responses to complex language stimuli.",2024-12-22,"Matteo Ciferri, Matteo Ferrante, Nicola Toschi",http://arxiv.org/pdf/2501.03246v1,cs.CL
LLMsAgainstHate @ NLU of Devanagari Script Languages 2025: Hate Speech Detection and Target Identification in Devanagari Languages via Parameter Efficient Fine-Tuning of LLMs,"The detection of hate speech has become increasingly important in combating
online hostility and its real-world consequences. Despite recent advancements,
there is limited research addressing hate speech detection in
Devanagari-scripted languages, where resources and tools are scarce. While
large language models (LLMs) have shown promise in language-related tasks,
traditional fine-tuning approaches are often infeasible given the size of the
models. In this paper, we propose a Parameter Efficient Fine tuning (PEFT)
based solution for hate speech detection and target identification. We evaluate
multiple LLMs on the Devanagari dataset provided by (Thapa et al., 2025), which
contains annotated instances in 2 languages - Hindi and Nepali. The results
demonstrate the efficacy of our approach in handling Devanagari-scripted
content.",2024-12-22,"Rushendra Sidibomma, Pransh Patwa, Parth Patwa, Aman Chadha, Vinija Jain, Amitava Das",http://arxiv.org/pdf/2412.17131v2,cs.CL
"Lies, Damned Lies, and Distributional Language Statistics: Persuasion and Deception with Large Language Models","Large Language Models (LLMs) can generate content that is as persuasive as
human-written text and appear capable of selectively producing deceptive
outputs. These capabilities raise concerns about potential misuse and
unintended consequences as these systems become more widely deployed. This
review synthesizes recent empirical work examining LLMs' capacity and
proclivity for persuasion and deception, analyzes theoretical risks that could
arise from these capabilities, and evaluates proposed mitigations. While
current persuasive effects are relatively small, various mechanisms could
increase their impact, including fine-tuning, multimodality, and social
factors. We outline key open questions for future research, including how
persuasive AI systems might become, whether truth enjoys an inherent advantage
over falsehoods, and how effective different mitigation strategies may be in
practice.",2024-12-22,"Cameron R. Jones, Benjamin K. Bergen",http://arxiv.org/pdf/2412.17128v1,cs.CL
Learning to Adapt to Low-Resource Paraphrase Generation,"Paraphrase generation is a longstanding NLP task and achieves great success
with the aid of large corpora. However, transferring a paraphrasing model to
another domain encounters the problem of domain shifting especially when the
data is sparse. At the same time, widely using large pre-trained language
models (PLMs) faces the overfitting problem when training on scarce labeled
data. To mitigate these two issues, we propose, LAPA, an effective adapter for
PLMs optimized by meta-learning. LAPA has three-stage training on three types
of related resources to solve this problem: 1. pre-training PLMs on
unsupervised corpora, 2. inserting an adapter layer and meta-training on source
domain labeled data, and 3. fine-tuning adapters on a small amount of target
domain labeled data. This method enables paraphrase generation models to learn
basic language knowledge first, then learn the paraphrasing task itself later,
and finally adapt to the target task. Our experimental results demonstrate that
LAPA achieves state-of-the-art in supervised, unsupervised, and low-resource
settings on three benchmark datasets. With only 2\% of trainable parameters and
1\% labeled data of the target task, our approach can achieve a competitive
performance with previous work.",2024-12-22,"Zhigen Li, Yanmeng Wang, Rizhao Fan, Ye Wang, Jianfeng Li, Shaojun Wang",http://arxiv.org/pdf/2412.17111v1,cs.CL
SAIL: Sample-Centric In-Context Learning for Document Information Extraction,"Document Information Extraction (DIE) aims to extract structured information
from Visually Rich Documents (VRDs). Previous full-training approaches have
demonstrated strong performance but may struggle with generalization to unseen
data. In contrast, training-free methods leverage powerful pre-trained models
like Large Language Models (LLMs) to address various downstream tasks with only
a few examples. Nonetheless, training-free methods for DIE encounter two
primary challenges: (1) understanding the complex relationship between layout
and textual elements in VRDs, and (2) providing accurate guidance to
pre-trained models. To address these challenges, we propose Sample-centric
In-context Learning (SAIL) for DIE. SAIL introduces a fine-grained entity-level
textual similarity to facilitate in-depth text analysis by LLMs and
incorporates layout similarity to enhance the analysis of layouts in VRDs.
Additionally, SAIL formulates a unified In-Context Learning (ICL) prompt
template for various sample-centric examples, enabling tailored prompts that
deliver precise guidance to pre-trained models for each sample. Extensive
experiments on FUNSD, CORD, and SROIE benchmarks with various base models
(e.g., LLMs) indicate that our method outperforms training-free baselines, even
closer to the full-training methods. The results show the superiority and
generalization of our method.",2024-12-22,"Jinyu Zhang, Zhiyuan You, Jize Wang, Xinyi Le",http://arxiv.org/pdf/2412.17092v1,cs.CL
Iterative NLP Query Refinement for Enhancing Domain-Specific Information Retrieval: A Case Study in Career Services,"Retrieving semantically relevant documents in niche domains poses significant
challenges for traditional TF-IDF-based systems, often resulting in low
similarity scores and suboptimal retrieval performance. This paper addresses
these challenges by introducing an iterative and semi-automated query
refinement methodology tailored to Humber College's career services webpages.
Initially, generic queries related to interview preparation yield low
top-document similarities (approximately 0.2--0.3). To enhance retrieval
effectiveness, we implement a two-fold approach: first, domain-aware query
refinement by incorporating specialized terms such as
resources-online-learning, student-online-services, and career-advising;
second, the integration of structured educational descriptors like ""online
resume and interview improvement tools."" Additionally, we automate the
extraction of domain-specific keywords from top-ranked documents to suggest
relevant terms for query expansion. Through experiments conducted on five
baseline queries, our semi-automated iterative refinement process elevates the
average top similarity score from approximately 0.18 to 0.42, marking a
substantial improvement in retrieval performance. The implementation details,
including reproducible code and experimental setups, are made available in our
GitHub repositories \url{https://github.com/Elipei88/HumberChatbotBackend} and
\url{https://github.com/Nisarg851/HumberChatbot}. We also discuss the
limitations of our approach and propose future directions, including the
integration of advanced neural retrieval models.",2024-12-22,"Elham Peimani, Gurpreet Singh, Nisarg Mahyavanshi, Aman Arora, Awais Shaikh",http://arxiv.org/pdf/2412.17075v1,cs.CL
Computational Analysis of Character Development in Holocaust Testimonies,"This work presents a computational approach to analyze character development
along the narrative timeline. The analysis characterizes the inner and outer
changes the protagonist undergoes within a narrative, and the interplay between
them. We consider transcripts of Holocaust survivor testimonies as a test case,
each telling the story of an individual in first-person terms. We focus on the
survivor's religious trajectory, examining the evolution of their disposition
toward religious belief and practice along the testimony. Clustering the
resulting trajectories in the dataset, we identify common sequences in the
data. Our findings highlight multiple common structures of religiosity across
the narratives: in terms of belief, most present a constant disposition, while
for practice, most present an oscillating structure, serving as valuable
material for historical and sociological research. This work demonstrates the
potential of natural language processing techniques for analyzing character
evolution through thematic trajectories in narratives.",2024-12-22,"Esther Shizgal, Eitan Wagner, Renana Keydar, Omri Abend",http://arxiv.org/pdf/2412.17063v1,cs.CL
Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with Tree Search-Based Agentic Collaboration,"Scaling laws for inference compute in multi-agent systems remain
under-explored compared to single-agent scenarios. This work aims to bridge
this gap by investigating the problem of data synthesis through multi-agent
sampling, where synthetic responses are generated by sampling from multiple
distinct language models. Effective model coordination is crucial for
successful multi-agent collaboration. Unlike previous approaches that rely on
fixed workflows, we treat model coordination as a multi-step decision-making
process, optimizing generation structures dynamically for each input question.
We introduce Tree Search-based Orchestrated Agents~(TOA), where the workflow
evolves iteratively during the sequential sampling process. To achieve this, we
leverage Monte Carlo Tree Search (MCTS), integrating a reward model to provide
real-time feedback and accelerate exploration. Our experiments on alignment,
machine translation, and mathematical reasoning demonstrate that multi-agent
sampling significantly outperforms single-agent sampling as inference compute
scales. TOA is the most compute-efficient approach, achieving SOTA performance
on WMT and a 72.2\% LC win rate on AlpacaEval. Moreover, fine-tuning with our
synthesized alignment data surpasses strong preference learning methods on
challenging benchmarks such as Arena-Hard and AlpacaEval.",2024-12-22,"Hai Ye, Mingbao Lin, Hwee Tou Ng, Shuicheng Yan",http://arxiv.org/pdf/2412.17061v2,cs.CL
The HalluRAG Dataset: Detecting Closed-Domain Hallucinations in RAG Applications Using an LLM's Internal States,"Detecting hallucinations in large language models (LLMs) is critical for
enhancing their reliability and trustworthiness. Most research focuses on
hallucinations as deviations from information seen during training. However,
the opaque nature of an LLM's parametric knowledge complicates the
understanding of why generated texts appear ungrounded: The LLM might not have
picked up the necessary knowledge from large and often inaccessible datasets,
or the information might have been changed or contradicted during further
training. Our focus is on hallucinations involving information not used in
training, which we determine by using recency to ensure the information emerged
after a cut-off date. This study investigates these hallucinations by detecting
them at sentence level using different internal states of various LLMs. We
present HalluRAG, a dataset designed to train classifiers on these
hallucinations. Depending on the model and quantization, MLPs trained on
HalluRAG detect hallucinations with test accuracies ranging up to 75 %, with
Mistral-7B-Instruct-v0.1 achieving the highest test accuracies. Our results
show that IAVs detect hallucinations as effectively as CEVs and reveal that
answerable and unanswerable prompts are encoded differently as separate
classifiers for these categories improved accuracy. However, HalluRAG showed
some limited generalizability, advocating for more diversity in datasets on
hallucinations.",2024-12-22,"Fabian Ridder, Malte Schilling",http://arxiv.org/pdf/2412.17056v2,cs.CL
Modular Conversational Agents for Surveys and Interviews,"Surveys and interviews are widely used for collecting insights on emerging or
hypothetical scenarios. Traditional human-led methods often face challenges
related to cost, scalability, and consistency. Recently, various domains have
begun to explore the use of conversational agents (chatbots) powered by
generative artificial intelligence (AI) technologies. However, considering
decisions in transportation investments and policies often carry significant
public and environmental stakes, surveys and interviews face unique challenges
in integrating AI agents, underscoring the need for a rigorous,
resource-efficient approach that enhances participant engagement and ensures
privacy. This paper addresses this gap by introducing a modular approach and
its resulting parameterized process for designing AI agents. We detail the
system architecture, integrating engineered prompts, specialized knowledge
bases, and customizable, goal-oriented conversational logic. We demonstrate the
adaptability, generalizability, and efficacy of our modular approach through
three empirical studies: (1) travel preference surveys, highlighting
conditional logic and multimodal (voice, text, and image generation)
capabilities; (2) public opinion elicitation on a newly constructed, novel
infrastructure project, showcasing question customization and multilingual
(English and French) capabilities; and (3) expert consultation about the impact
of technologies on future transportation systems, highlighting real-time,
clarification request capabilities for open-ended questions, resilience in
handling erratic inputs, and efficient transcript postprocessing. The results
suggest that the AI agent increases completion rates and response quality.
Furthermore, the modular approach demonstrates controllability, flexibility,
and robustness while addressing key ethical, privacy, security, and token
consumption concerns.",2024-12-22,"Jiangbo Yu, Jinhua Zhao, Luis Miranda-Moreno, Matthew Korp",http://arxiv.org/pdf/2412.17049v2,cs.CL
Why Do Speech Language Models Fail to Generate Semantically Coherent Outputs? A Modality Evolving Perspective,"Although text-based large language models exhibit human-level writing ability
and remarkable intelligence, speech language models (SLMs) still struggle to
generate semantically coherent outputs. There are several potential reasons for
this performance degradation: (A) speech tokens mainly provide phonetic
information rather than semantic information, (B) the length of speech
sequences is much longer than that of text sequences, and (C) paralinguistic
information, such as prosody, introduces additional complexity and variability.
In this paper, we explore the influence of three key factors separately by
transiting the modality from text to speech in an evolving manner. Our findings
reveal that the impact of the three factors varies. Factor A has a relatively
minor impact, factor B influences syntactical and semantic modeling more
obviously, and factor C exerts the most significant impact, particularly in the
basic lexical modeling. Based on these findings, we provide insights into the
unique challenges of training SLMs and highlight pathways to develop more
effective end-to-end SLMs.",2024-12-22,"Hankun Wang, Haoran Wang, Yiwei Guo, Zhihan Li, Chenpeng Du, Xie Chen, Kai Yu",http://arxiv.org/pdf/2412.17048v1,cs.CL
Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models,"Jailbreaking in Large Language Models (LLMs) is a major security concern as
it can deceive LLMs to generate harmful text. Yet, there is still insufficient
understanding of how jailbreaking works, which makes it hard to develop
effective defense strategies. We aim to shed more light into this issue: we
conduct a detailed large-scale analysis of seven different jailbreak methods
and find that these disagreements stem from insufficient observation samples.
In particular, we introduce \textit{safety boundary}, and we find that
jailbreaks shift harmful activations outside that safety boundary, where LLMs
are less sensitive to harmful information. We also find that the low and the
middle layers are critical in such shifts, while deeper layers have less
impact. Leveraging on these insights, we propose a novel defense called
\textbf{Activation Boundary Defense} (ABD), which adaptively constrains the
activations within the safety boundary. We further use Bayesian optimization to
selectively apply the defense method to the low and the middle layers. Our
experiments on several benchmarks show that ABD achieves an average DSR of over
98\% against various forms of jailbreak attacks, with less than 2\% impact on
the model's general capabilities.",2024-12-22,"Lang Gao, Jiahui Geng, Xiangliang Zhang, Preslav Nakov, Xiuying Chen",http://arxiv.org/pdf/2412.17034v2,cs.CL
MINTQA: A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge,"Large language models (LLMs) have demonstrated impressive capabilities in
various reasoning tasks but face significant challenges with complex,
knowledge-intensive multi-hop queries, particularly those involving new or
long-tail knowledge. Existing benchmarks often fail to fully address these
challenges. To bridge this gap, we introduce MINTQA (Multi-hop Question
Answering on New and Tail Knowledge), a comprehensive benchmark to evaluate
LLMs' capabilities in multi-hop reasoning across four critical dimensions:
question handling strategy, sub-question generation, retrieval-augmented
generation, and iterative or dynamic decomposition and retrieval. MINTQA
comprises 10,479 question-answer pairs for evaluating new knowledge and 17,887
pairs for assessing long-tail knowledge, with each question equipped with
corresponding sub-questions and answers. Our systematic evaluation of 22
state-of-the-art LLMs on MINTQA reveals significant limitations in their
ability to handle complex knowledge base queries, particularly in handling new
or unpopular knowledge. Our findings highlight critical challenges and offer
insights for advancing multi-hop reasoning capabilities. The MINTQA benchmark
is available at https://github.com/probe2/multi-hop/.",2024-12-22,"Jie He, Nan Hu, Wanqiu Long, Jiaoyan Chen, Jeff Z. Pan",http://arxiv.org/pdf/2412.17032v2,cs.CL
A Reality Check on Context Utilisation for Retrieval-Augmented Generation,"Retrieval-augmented generation (RAG) helps address the limitations of the
parametric knowledge embedded within a language model (LM). However,
investigations of how LMs utilise retrieved information of varying complexity
in real-world scenarios have been limited to synthetic contexts. We introduce
DRUID (Dataset of Retrieved Unreliable, Insufficient and
Difficult-to-understand contexts) with real-world queries and contexts manually
annotated for stance. The dataset is based on the prototypical task of
automated claim verification, for which automated retrieval of real-world
evidence is crucial. We compare DRUID to synthetic datasets (CounterFact,
ConflictQA) and find that artificial datasets often fail to represent the
complex and diverse real-world context settings. We show that synthetic
datasets exaggerate context characteristics rare in real retrieved data, which
leads to inflated context utilisation results, as measured by our novel ACU
score. Moreover, while previous work has mainly focused on singleton context
characteristics to explain context utilisation, correlations between singleton
context properties and ACU on DRUID are surprisingly small compared to other
properties related to context source. Overall, our work underscores the need
for real-world aligned context utilisation studies to represent and improve
performance in real-world RAG settings.",2024-12-22,"Lovisa Hagström, Sara Vera Marjanović, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, Isabelle Augenstein",http://arxiv.org/pdf/2412.17031v1,cs.CL
Reversed Attention: On The Gradient Descent Of Attention Layers In GPT,"The success of Transformer-based Language Models (LMs) stems from their
attention mechanism. While this mechanism has been extensively studied in
explainability research, particularly through the attention values obtained
during the forward pass of LMs, the backward pass of attention has been largely
overlooked. In this work, we study the mathematics of the backward pass of
attention, revealing that it implicitly calculates an attention matrix we refer
to as ""Reversed Attention"". We examine the properties of Reversed Attention and
demonstrate its ability to elucidate the models' behavior and edit dynamics. In
an experimental setup, we showcase the ability of Reversed Attention to
directly alter the forward pass of attention, without modifying the model's
weights, using a novel method called ""attention patching"". In addition to
enhancing the comprehension of how LM configure attention layers during
backpropagation, Reversed Attention maps contribute to a more interpretable
backward pass.",2024-12-22,"Shahar Katz, Lior Wolf",http://arxiv.org/pdf/2412.17019v1,cs.CL
Robustness of Large Language Models Against Adversarial Attacks,"The increasing deployment of Large Language Models (LLMs) in various
applications necessitates a rigorous evaluation of their robustness against
adversarial attacks. In this paper, we present a comprehensive study on the
robustness of GPT LLM family. We employ two distinct evaluation methods to
assess their resilience. The first method introduce character-level text attack
in input prompts, testing the models on three sentiment classification
datasets: StanfordNLP/IMDB, Yelp Reviews, and SST-2. The second method involves
using jailbreak prompts to challenge the safety mechanisms of the LLMs. Our
experiments reveal significant variations in the robustness of these models,
demonstrating their varying degrees of vulnerability to both character-level
and semantic-level adversarial attacks. These findings underscore the necessity
for improved adversarial training and enhanced safety mechanisms to bolster the
robustness of LLMs.",2024-12-22,"Yiyi Tao, Yixian Shen, Hang Zhang, Yanxin Shen, Lun Wang, Chuanqi Shi, Shaoshuai Du",http://arxiv.org/pdf/2412.17011v1,cs.CL
On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora,"Named Entity Recognition has traditionally been a key task in natural
language processing, aiming to identify and extract important terms from
unstructured text data. However, a notable challenge for contemporary
deep-learning NER models has been identifying discontinuous entities, which are
often fragmented within the text. To date, methods to address Discontinuous
Named Entity Recognition have not been explored using ensemble learning to the
best of our knowledge. Furthermore, the rise of large language models, such as
ChatGPT in recent years, has shown significant effectiveness across many NLP
tasks. Most existing approaches, however, have primarily utilized ChatGPT as a
problem-solving tool rather than exploring its potential as an integrative
element within ensemble learning algorithms. In this study, we investigated the
integration of ChatGPT as an arbitrator within an ensemble method, aiming to
enhance performance on DNER tasks. Our method combines five state-of-the-art
NER models with ChatGPT using custom prompt engineering to assess the
robustness and generalization capabilities of the ensemble algorithm. We
conducted experiments on three benchmark medical datasets, comparing our method
against the five SOTA models, individual applications of GPT-3.5 and GPT-4, and
a voting ensemble method. The results indicate that our proposed fusion of
ChatGPT with the ensemble learning algorithm outperforms the SOTA results in
the CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance
NLP applications in the healthcare domain.",2024-12-22,"Tzu-Chieh Chen, Wen-Yang Lin",http://arxiv.org/pdf/2412.16976v1,cs.CL
Cannot or Should Not? Automatic Analysis of Refusal Composition in IFT/RLHF Datasets and Refusal Behavior of Black-Box LLMs,"Refusals - instances where large language models (LLMs) decline or fail to
fully execute user instructions - are crucial for both AI safety and AI
capabilities and the reduction of hallucinations in particular. These behaviors
are learned during post-training, especially in instruction fine-tuning (IFT)
and reinforcement learning from human feedback (RLHF). However, existing
taxonomies and evaluation datasets for refusals are inadequate, often focusing
solely on should-not-related (instead of cannot-related) categories, and
lacking tools for auditing refusal content in black-box LLM outputs.
  We present a comprehensive framework for classifying LLM refusals: (a) a
taxonomy of 16 refusal categories, (b) a human-annotated dataset of over 8,600
instances from publicly available IFT and RLHF datasets, (c) a synthetic
dataset with 8,000 examples for each refusal category, and (d) classifiers
trained for refusal classification.
  Our work enables precise auditing of refusal behaviors in black-box LLMs and
automatic analyses of refusal patterns in large IFT and RLHF datasets. This
facilitates the strategic adjustment of LLM refusals, contributing to the
development of more safe and reliable LLMs.",2024-12-22,"Alexander von Recum, Christoph Schnabl, Gabor Hollbeck, Silas Alberti, Philip Blinde, Marvin von Hagen",http://arxiv.org/pdf/2412.16974v1,cs.CL
Part-Of-Speech Sensitivity of Routers in Mixture of Experts Models,"This study investigates the behavior of model-integrated routers in Mixture
of Experts (MoE) models, focusing on how tokens are routed based on their
linguistic features, specifically Part-of-Speech (POS) tags. The goal is to
explore across different MoE architectures whether experts specialize in
processing tokens with similar linguistic traits. By analyzing token
trajectories across experts and layers, we aim to uncover how MoE models handle
linguistic information. Findings from six popular MoE models reveal expert
specialization for specific POS categories, with routing paths showing high
predictive accuracy for POS, highlighting the value of routing paths in
characterizing tokens.",2024-12-22,"Elie Antoine, Frédéric Béchet, Philippe Langlais",http://arxiv.org/pdf/2412.16971v1,cs.CL
System-2 Mathematical Reasoning via Enriched Instruction Tuning,"Solving complex mathematical problems via system-2 reasoning is a natural
human skill, yet it remains a significant challenge for current large language
models (LLMs). We identify the scarcity of deliberate multi-step reasoning data
as a primary limiting factor. To this end, we introduce Enriched Instruction
Tuning (EIT), a method that enriches existing human-annotated mathematical
datasets by synergizing human and AI feedback to create fine-grained reasoning
trajectories. These datasets are then used to fine-tune open-source LLMs,
enhancing their mathematical reasoning abilities without reliance on any
symbolic verification program. Concretely, EIT is composed of two critical
steps: Enriching with Reasoning Plan (ERP) and Enriching with Reasoning Step
(ERS). The former generates a high-level plan that breaks down complex
instructions into a sequence of simpler objectives, while ERS fills in
reasoning contexts often overlooked by human annotators, creating a smoother
reasoning trajectory for LLM fine-tuning. Unlike existing CoT prompting methods
that generate reasoning chains only depending on LLM's internal knowledge, our
method leverages human-annotated initial answers as ``meta-knowledge'' to help
LLMs generate more detailed and precise reasoning processes, leading to a more
trustworthy LLM expert for complex mathematical problems. In experiments, EIT
achieves an accuracy of 84.1% on GSM8K and 32.5% on MATH, surpassing
state-of-the-art fine-tuning and prompting methods, and even matching the
performance of tool-augmented methods.",2024-12-22,"Huanqia Cai, Yijun Yang, Zhifeng Li",http://arxiv.org/pdf/2412.16964v2,cs.CL
LH-Mix: Local Hierarchy Correlation Guided Mixup over Hierarchical Prompt Tuning,"Hierarchical text classification (HTC) aims to assign one or more labels in
the hierarchy for each text. Many methods represent this structure as a global
hierarchy, leading to redundant graph structures. To address this,
incorporating a text-specific local hierarchy is essential. However, existing
approaches often model this local hierarchy as a sequence, focusing on explicit
parent-child relationships while ignoring implicit correlations among
sibling/peer relationships. In this paper, we first integrate local hierarchies
into a manual depth-level prompt to capture parent-child relationships. We then
apply Mixup to this hierarchical prompt tuning scheme to improve the latent
correlation within sibling/peer relationships. Notably, we propose a novel
Mixup ratio guided by local hierarchy correlation to effectively capture
intrinsic correlations. This Local Hierarchy Mixup (LH-Mix) model demonstrates
remarkable performance across three widely-used datasets.",2024-12-22,"Fanshuang Kong, Richong Zhang, Ziqiao Wang",http://arxiv.org/pdf/2412.16963v2,cs.CL
Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework,"In the context of large language models (LLMs), current advanced reasoning
methods have made impressive strides in various reasoning tasks. However, when
it comes to logical reasoning tasks, major challenges remain in both efficacy
and efficiency. This is rooted in the fact that these systems fail to fully
leverage the inherent structure of logical tasks throughout the reasoning
processes such as decomposition, search, and resolution. To address this, we
propose a logic-complete reasoning framework, Aristotle, with three key
components: Logical Decomposer, Logical Search Router, and Logical Resolver. In
our framework, symbolic expressions and logical rules are comprehensively
integrated into the entire reasoning process, significantly alleviating the
bottlenecks of logical reasoning, i.e., reducing sub-task complexity,
minimizing search errors, and resolving logical contradictions. The
experimental results on several datasets demonstrate that Aristotle
consistently outperforms state-of-the-art reasoning frameworks in both accuracy
and efficiency, particularly excelling in complex logical reasoning scenarios.
We will open-source all our code at https://github.com/Aiden0526/Aristotle.",2024-12-22,"Jundong Xu, Hao Fei, Meng Luo, Qian Liu, Liangming Pan, William Yang Wang, Preslav Nakov, Mong-Li Lee, Wynne Hsu",http://arxiv.org/pdf/2412.16953v1,cs.CL
A Career Interview Dialogue System using Large Language Model-based Dynamic Slot Generation,"This study aims to improve the efficiency and quality of career interviews
conducted by nursing managers. To this end, we have been developing a
slot-filling dialogue system that engages in pre-interviews to collect
information on staff careers as a preparatory step before the actual
interviews. Conventional slot-filling-based interview dialogue systems have
limitations in the flexibility of information collection because the dialogue
progresses based on predefined slot sets. We therefore propose a method that
leverages large language models (LLMs) to dynamically generate new slots
according to the flow of the dialogue, achieving more natural conversations.
Furthermore, we incorporate abduction into the slot generation process to
enable more appropriate and effective slot generation. To validate the
effectiveness of the proposed method, we conducted experiments using a user
simulator. The results suggest that the proposed method using abduction is
effective in enhancing both information-collecting capabilities and the
naturalness of the dialogue.",2024-12-22,"Ekai Hashimoto, Mikio Nakano, Takayoshi Sakurai, Shun Shiramatsu, Toshitake Komazaki, Shiho Tsuchiya",http://arxiv.org/pdf/2412.16943v1,cs.CL
Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering,"Recently, Large Language Models (LLMs) have been used for knowledge-based
Visual Question Answering (VQA). Despite the encouraging results of previous
studies, prior methods prompt LLMs to predict answers directly, neglecting
intermediate thought processes. We argue that prior methods do not sufficiently
activate the capacities of LLMs. We propose a framework called PLRH that
Prompts LLMs with Rationale Heuristics for knowledge-based VQA. The PLRH
prompts LLMs with Chain of Thought (CoT) to generate rationale heuristics,
i.e., intermediate thought processes, and then leverages the rationale
heuristics to inspire LLMs to predict answers. Experiments show that our
approach outperforms the existing baselines by more than 2.2 and 2.1 on OK-VQA
and A-OKVQA, respectively.",2024-12-22,"Zhongjian Hu, Peng Yang, Bing Li, Fengyuan Liu",http://arxiv.org/pdf/2412.16936v1,cs.CL
Evaluating LLM Reasoning in the Operations Research Domain with ORQA,"In this paper, we introduce and apply Operations Research Question Answering
(ORQA), a new benchmark designed to assess the generalization capabilities of
Large Language Models (LLMs) in the specialized technical domain of Operations
Research (OR). This benchmark evaluates whether LLMs can emulate the knowledge
and reasoning skills of OR experts when confronted with diverse and complex
optimization problems. The dataset, developed by OR experts, features
real-world optimization problems that demand multistep reasoning to construct
their mathematical models. Our evaluations of various open source LLMs, such as
LLaMA 3.1, DeepSeek, and Mixtral, reveal their modest performance, highlighting
a gap in their ability to generalize to specialized technical domains. This
work contributes to the ongoing discourse on LLMs generalization capabilities,
offering valuable insights for future research in this area. The dataset and
evaluation code are publicly available.",2024-12-22,"Mahdi Mostajabdaveh, Timothy T. Yu, Samarendra Chandan Bindu Dash, Rindranirina Ramamonjison, Jabo Serge Byusa, Giuseppe Carenini, Zirui Zhou, Yong Zhang",http://arxiv.org/pdf/2412.17874v2,cs.CL
Towards a Unified Paradigm: Integrating Recommendation Systems as a New Language in Large Models,"This paper explores the use of Large Language Models (LLMs) for sequential
recommendation, which predicts users' future interactions based on their past
behavior. We introduce a new concept, ""Integrating Recommendation Systems as a
New Language in Large Models"" (RSLLM), which combines the strengths of
traditional recommenders and LLMs. RSLLM uses a unique prompting method that
combines ID-based item embeddings from conventional recommendation models with
textual item features. It treats users' sequential behaviors as a distinct
language and aligns the ID embeddings with the LLM's input space using a
projector. We also propose a two-stage LLM fine-tuning framework that refines a
pretrained LLM using a combination of two contrastive losses and a language
modeling loss. The LLM is first fine-tuned using text-only prompts, followed by
target domain fine-tuning with unified prompts. This trains the model to
incorporate behavioral knowledge from the traditional sequential recommender
into the LLM. Our empirical results validate the effectiveness of our proposed
framework.",2024-12-22,"Kai Zheng, Qingfeng Sun, Can Xu, Peng Yu, Qingwei Guo",http://arxiv.org/pdf/2412.16933v1,cs.CL
Revisiting In-Context Learning with Long Context Language Models,"In-Context Learning (ICL) is a technique by which language models make
predictions based on examples provided in their input context. Previously,
their context window size imposed a limit on the number of examples that can be
shown, making example selection techniques crucial for identifying the
maximally effective set of examples. However, the recent advent of Long Context
Language Models (LCLMs) has significantly increased the number of examples that
can be included in context, raising an important question of whether ICL
performance in a many-shot regime is still sensitive to the method of sample
selection. To answer this, we revisit these approaches in the context of LCLMs
through extensive experiments on 18 datasets spanning 4 tasks. Surprisingly, we
observe that sophisticated example selection techniques do not yield
significant improvements over a simple random sample selection method. Instead,
we find that the advent of LCLMs has fundamentally shifted the challenge of ICL
from that of selecting the most effective examples to that of collecting
sufficient examples to fill the context window. Specifically, in certain
datasets, including all available examples does not fully utilize the context
window; however, by augmenting the examples in context with a simple data
augmentation approach, we substantially improve ICL performance by 5%.",2024-12-22,"Jinheon Baek, Sun Jae Lee, Prakhar Gupta, Geunseob Oh, Siddharth Dalmia, Prateek Kolhar",http://arxiv.org/pdf/2412.16926v2,cs.CL
Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index,"This study introduces the Community Sentiment and Engagement Index (CSEI),
developed to capture nuanced public sentiment and engagement variations on
social media, particularly in response to major events related to COVID-19.
Constructed with diverse sentiment indicators, CSEI integrates features like
engagement, daily post count, compound sentiment, fine-grain sentiments (fear,
surprise, joy, sadness, anger, disgust, and neutral), readability,
offensiveness, and domain diversity. Each component is systematically weighted
through a multi-step Principal Component Analysis (PCA)-based framework,
prioritizing features according to their variance contributions across temporal
sentiment shifts. This approach dynamically adjusts component importance,
enabling CSEI to precisely capture high-sensitivity shifts in public sentiment.
The development of CSEI showed statistically significant correlations with its
constituent features, underscoring internal consistency and sensitivity to
specific sentiment dimensions. CSEI's responsiveness was validated using a
dataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15
major events, including the WHO's declaration of COVID-19 as a pandemic, the
first reported cases of COVID-19 across different countries, national
lockdowns, vaccine developments, and crucial public health measures. Cumulative
changes in CSEI revealed prominent peaks and valleys aligned with these events,
indicating significant patterns in public sentiment across different phases of
the pandemic. Pearson correlation analysis further confirmed a statistically
significant relationship between CSEI daily fluctuations and these events (p =
0.0428), highlighting the capacity of CSEI to infer and interpret shifts in
public sentiment and engagement in response to major events related to
COVID-19.",2024-12-22,"Nirmalya Thakur, Kesha A. Patel, Audrey Poon, Shuqi Cui, Nazif Azizi, Rishika Shah, Riyan Shah",http://arxiv.org/pdf/2412.16925v1,cs.CL
Speech-Based Depression Prediction Using Encoder-Weight-Only Transfer Learning and a Large Corpus,"Speech-based algorithms have gained interest for the management of behavioral
health conditions such as depression. We explore a speech-based transfer
learning approach that uses a lightweight encoder and that transfers only the
encoder weights, enabling a simplified run-time model. Our study uses a large
data set containing roughly two orders of magnitude more speakers and sessions
than used in prior work. The large data set enables reliable estimation of
improvement from transfer learning. Results for the prediction of PHQ-8 labels
show up to 27% relative performance gains for binary classification; these
gains are statistically significant with a p-value close to zero. Improvements
were also found for regression. Additionally, the gain from transfer learning
does not appear to require strong source task performance. Results suggest that
this approach is flexible and offers promise for efficient implementation.",2024-12-22,"Amir Harati, Elizabeth Shriberg, Tomasz Rutowski, Piotr Chlebek, Yang Lu, Ricardo Oliveira",http://arxiv.org/pdf/2412.16900v1,cs.CL
Unsupervised Bilingual Lexicon Induction for Low Resource Languages,"Bilingual lexicons play a crucial role in various Natural Language Processing
tasks. However, many low-resource languages (LRLs) do not have such lexicons,
and due to the same reason, cannot benefit from the supervised Bilingual
Lexicon Induction (BLI) techniques. To address this, unsupervised BLI (UBLI)
techniques were introduced. A prominent technique in this line is
structure-based UBLI. It is an iterative method, where a seed lexicon, which is
initially learned from monolingual embeddings is iteratively improved. There
have been numerous improvements to this core idea, however they have been
experimented with independently of each other. In this paper, we investigate
whether using these techniques simultaneously would lead to equal gains. We use
the unsupervised version of VecMap, a commonly used structure-based UBLI
framework, and carry out a comprehensive set of experiments using the LRL
pairs, English-Sinhala, English-Tamil, and English-Punjabi. These experiments
helped us to identify the best combination of the extensions. We also release
bilingual dictionaries for English-Sinhala and English-Punjabi.",2024-12-22,"Charitha Rathnayake, P. R. S. Thilakarathna, Uthpala Nethmini, Rishemjith Kaur, Surangika Ranathunga",http://arxiv.org/pdf/2412.16894v1,cs.CL
"PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health","Artificial intelligence-based language generators are now a part of most
people's lives. However, by default, they tend to generate ""average"" language
without reflecting the ways in which people differ. Here, we propose a
lightweight modification to the standard language model transformer
architecture - ""PsychAdapter"" - that uses empirically derived trait-language
patterns to generate natural language for specified personality, demographic,
and mental health characteristics (with or without prompting). We applied
PsychAdapters to modify OpenAI's GPT-2, Google's Gemma, and Meta's Llama 3 and
found generated text to reflect the desired traits. For example, expert raters
evaluated PsychAdapter's generated text output and found it matched intended
trait levels with 87.3% average accuracy for Big Five personalities, and 96.7%
for depression and life satisfaction. PsychAdapter is a novel method to
introduce psychological behavior patterns into language models at the
foundation level, independent of prompting, by influencing every transformer
layer. This approach can create chatbots with specific personality profiles,
clinical training tools that mirror language associated with psychological
conditionals, and machine translations that match an authors reading or
education level without taking up LLM context windows. PsychAdapter also allows
for the exploration psychological constructs through natural language
expression, extending the natural language processing toolkit to study human
psychology.",2024-12-22,"Huy Vu, Huy Anh Nguyen, Adithya V Ganesan, Swanie Juhng, Oscar N. E. Kjell, Joao Sedoc, Margaret L. Kern, Ryan L. Boyd, Lyle Ungar, H. Andrew Schwartz, Johannes C. Eichstaedt",http://arxiv.org/pdf/2412.16882v2,cs.CL
Reconsidering SMT Over NMT for Closely Related Languages: A Case Study of Persian-Hindi Pair,"This paper demonstrates that Phrase-Based Statistical Machine Translation
(PBSMT) can outperform Transformer-based Neural Machine Translation (NMT) in
moderate-resource scenarios, specifically for structurally similar languages,
like the Persian-Hindi pair. Despite the Transformer architecture's typical
preference for large parallel corpora, our results show that PBSMT achieves a
BLEU score of 66.32, significantly exceeding the Transformer-NMT score of 53.7
on the same dataset. Additionally, we explore variations of the SMT
architecture, including training on Romanized text and modifying the word order
of Persian sentences to match the left-to-right (LTR) structure of Hindi. Our
findings highlight the importance of choosing the right architecture based on
language pair characteristics and advocate for SMT as a high-performing
alternative, even in contexts commonly dominated by NMT.",2024-12-22,"Waisullah Yousofi, Pushpak Bhattacharyya",http://arxiv.org/pdf/2412.16877v1,cs.CL
Teaching LLMs to Refine with Tools,"Large language models (LLMs) can refine their responses based on feedback,
enabling self-improvement through iterative training or test-time refinement.
However, existing methods predominantly focus on refinement within the same
reasoning format, which may lead to non-correcting behaviors. We propose CaP, a
novel approach that uses external tools to refine chain-of-thought (CoT)
responses generated by the same or other LLMs. CaP employs a two-stage training
process: supervised fine-tuning followed by preference optimization with DPO
variants. Our observations highlight the critical role of preference
optimization in enabling effective refinement. Additionally, we compare several
sampling strategies to leverage CoT and tools at inference time. Experimental
results demonstrate CaP's potential for effective cross-reasoning refinement
and efficient inference.",2024-12-22,"Dian Yu, Yuheng Zhang, Jiahao Xu, Tian Liang, Linfeng Song, Zhaopeng Tu, Haitao Mi, Dong Yu",http://arxiv.org/pdf/2412.16871v1,cs.CL
GME: Improving Universal Multimodal Retrieval by Multimodal LLMs,"Universal Multimodal Retrieval (UMR) aims to enable search across various
modalities using a unified model, where queries and candidates can consist of
pure text, images, or a combination of both. Previous work has attempted to
adopt multimodal large language models (MLLMs) to realize UMR using only text
data. However, our preliminary experiments demonstrate that more diverse
multimodal training data can further unlock the potential of MLLMs. Despite its
effectiveness, the existing multimodal training data is highly imbalanced in
terms of modality, which motivates us to develop a training data synthesis
pipeline and construct a large-scale, high-quality fused-modal training
dataset. Based on the synthetic training data, we develop the General
Multimodal Embedder (GME), an MLLM-based dense retriever designed for UMR.
Furthermore, we construct a comprehensive UMR Benchmark (UMRB) to evaluate the
effectiveness of our approach. Experimental results show that our method
achieves state-of-the-art performance among existing UMR methods. Last, we
provide in-depth analyses of model scaling and training strategies, and perform
ablation studies on both the model and synthetic data.",2024-12-22,"Xin Zhang, Yanzhao Zhang, Wen Xie, Mingxin Li, Ziqi Dai, Dingkun Long, Pengjun Xie, Meishan Zhang, Wenjie Li, Min Zhang",http://arxiv.org/pdf/2412.16855v2,cs.CL
Autoregressive Speech Synthesis with Next-Distribution Prediction,"We introduce KALL-E, a novel autoregressive (AR) language modeling approach
with next-distribution prediction for text-to-speech (TTS) synthesis. Unlike
existing methods, KALL-E directly models and predicts the continuous speech
distribution conditioned on text without relying on VAE- or diffusion-based
components. Specifically, we use WaveVAE to extract continuous speech
distributions from waveforms instead of using discrete speech tokens. A single
AR language model predicts these continuous speech distributions from text,
with a Kullback-Leibler divergence loss as the constraint. Experimental results
show that KALL-E outperforms open-source implementations of YourTTS, VALL-E,
NaturalSpeech 2, and CosyVoice in terms of naturalness and speaker similarity
in zero-shot TTS scenarios. Moreover, KALL-E demonstrates exceptional zero-shot
capabilities in emotion and accent cloning. Importantly, KALL-E presents a more
straightforward and effective paradigm for using continuous speech
representations in TTS. Audio samples are available at:
\url{https://zxf-icpc.github.io/kalle/}.",2024-12-22,"Xinfa Zhu, Wenjie Tian, Lei Xie",http://arxiv.org/pdf/2412.16846v1,cs.CL
Sim911: Towards Effective and Equitable 9-1-1 Dispatcher Training with an LLM-Enabled Simulation,"Emergency response services are vital for enhancing public safety by
safeguarding the environment, property, and human lives. As frontline members
of these services, 9-1-1 dispatchers have a direct impact on response times and
the overall effectiveness of emergency operations. However, traditional
dispatcher training methods, which rely on role-playing by experienced
personnel, are labor-intensive, time-consuming, and often neglect the specific
needs of underserved communities. To address these challenges, we introduce
Sim911, the first training simulation for 9-1-1 dispatchers powered by Large
Language Models (LLMs). Sim911 enhances training through three key technical
innovations: (1) knowledge construction, which utilizes archived 9-1-1 call
data to generate simulations that closely mirror real-world scenarios; (2)
context-aware controlled generation, which employs dynamic prompts and vector
bases to ensure that LLM behavior aligns with training objectives; and (3)
validation with looped correction, which filters out low-quality responses and
refines the system performance.",2024-12-22,"Zirong Chen, Elizabeth Chason, Noah Mladenovski, Erin Wilson, Kristin Mullen, Stephen Martini, Meiyi Ma",http://arxiv.org/pdf/2412.16844v3,cs.CL
Joint Knowledge Editing for Information Enrichment and Probability Promotion,"Knowledge stored in large language models requires timely updates to reflect
the dynamic nature of real-world information. To update the knowledge, most
knowledge editing methods focus on the low layers, since recent probes into the
knowledge recall process reveal that the answer information is enriched in low
layers. However, these probes only and could only reveal critical recall stages
for the original answers, while the goal of editing is to rectify model's
prediction for the target answers. This inconsistency indicates that both the
probe approaches and the associated editing methods are deficient. To mitigate
the inconsistency and identify critical editing regions, we propose a
contrast-based probe approach, and locate two crucial stages where the model
behavior diverges between the original and target answers: Information
Enrichment in low layers and Probability Promotion in high layers. Building
upon the insights, we develop the Joint knowledge Editing for information
Enrichment and probability Promotion (JEEP) method, which jointly edits both
the low and high layers to modify the two critical recall stages. Considering
the mutual interference and growing forgetting due to dual modifications, JEEP
is designed to ensure that updates to distinct regions share the same
objectives and are complementary. We rigorously evaluate JEEP by editing up to
thousands of facts on various models, i.e., GPT-J (6B) and LLaMA (7B), and
addressing diverse editing objectives, i.e., adding factual and counterfactual
knowledge. In all tested scenarios, JEEP achieves best performances, validating
the effectiveness of the revealings of our probe approach and the designs of
our editing method. Our code and data are available at
https://github.com/Eric8932/JEEP.",2024-12-22,"Wenhang Shi, Yiren Chen, Shuqing Bian, Xinyi Zhang, Zhe Zhao, Pengfei Hu, Wei Lu, Xiaoyong Du",http://arxiv.org/pdf/2412.17872v1,cs.CL
Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions,"The rise of large language models (LLMs) offers new opportunities for
automatic error detection in education, particularly for math word problems
(MWPs). While prior studies demonstrate the promise of LLMs as error detectors,
they overlook the presence of multiple valid solutions for a single MWP. Our
preliminary analysis reveals a significant performance gap between conventional
and alternative solutions in MWPs, a phenomenon we term conformity bias in this
work. To mitigate this bias, we introduce the Ask-Before-Detect (AskBD)
framework, which generates adaptive reference solutions using LLMs to enhance
error detection. Experiments on 200 examples of GSM8K show that AskBD
effectively mitigates bias and improves performance, especially when combined
with reasoning-enhancing techniques like chain-of-thought prompting.",2024-12-22,"Hang Li, Tianlong Xu, Kaiqi Yang, Yucheng Chu, Yanling Chen, Yichi Song, Qingsong Wen, Hui Liu",http://arxiv.org/pdf/2412.16838v1,cs.CL
Quantum-Like Contextuality in Large Language Models,"Contextuality is a distinguishing feature of quantum mechanics and there is
growing evidence that it is a necessary condition for quantum advantage. In
order to make use of it, researchers have been asking whether similar phenomena
arise in other domains. The answer has been yes, e.g. in behavioural sciences.
However, one has to move to frameworks that take some degree of signalling into
account. Two such frameworks exist: (1) a signalling-corrected sheaf theoretic
model, and (2) the Contextuality-by-Default (CbD) framework. This paper
provides the first large scale experimental evidence for a yes answer in
natural language. We construct a linguistic schema modelled over a contextual
quantum scenario, instantiate it in the Simple English Wikipedia and extract
probability distributions for the instances using the large language model
BERT. This led to the discovery of 77,118 sheaf-contextual and 36,938,948 CbD
contextual instances. We proved that the contextual instances came from
semantically similar words, by deriving an equation between degrees of
contextuality and Euclidean distances of BERT's embedding vectors. A regression
model further reveals that Euclidean distance is indeed the best statistical
predictor of contextuality. Our linguistic schema is a variant of the
co-reference resolution challenge. These results are an indication that quantum
methods may be advantageous in language tasks.",2024-12-21,"Kin Ian Lo, Mehrnoosh Sadrzadeh, Shane Mansfield",http://arxiv.org/pdf/2412.16806v1,cs.CL
SubData: Bridging Heterogeneous Datasets to Enable Theory-Driven Evaluation of Political and Demographic Perspectives in LLMs,"As increasingly capable large language models (LLMs) emerge, researchers have
begun exploring their potential for subjective tasks. While recent work
demonstrates that LLMs can be aligned with diverse human perspectives,
evaluating this alignment on actual downstream tasks (e.g., hate speech
detection) remains challenging due to the use of inconsistent datasets across
studies. To address this issue, in this resource paper we propose a two-step
framework: we (1) introduce SubData, an open-source Python library designed for
standardizing heterogeneous datasets to evaluate LLM perspective alignment; and
(2) present a theory-driven approach leveraging this library to test how
differently-aligned LLMs (e.g., aligned with different political viewpoints)
classify content targeting specific demographics. SubData's flexible mapping
and taxonomy enable customization for diverse research needs, distinguishing it
from existing resources. We invite contributions to add datasets to our
initially proposed resource and thereby help expand SubData into a
multi-construct benchmark suite for evaluating LLM perspective alignment on NLP
tasks.",2024-12-21,"Leon Fröhling, Pietro Bernardelle, Gianluca Demartini",http://arxiv.org/pdf/2412.16783v2,cs.CL
AlzheimerRAG: Multimodal Retrieval Augmented Generation for PubMed articles,"Recent advancements in generative AI have flourished the development of
highly adept Large Language Models (LLMs) that integrate diverse data types to
empower decision-making. Among these, Multimodal Retrieval-Augmented Generation
(RAG) applications are promising for their capability to combine the strengths
of information retrieval and generative models, enhancing their utility across
various domains, including biomedical research. This paper introduces
AlzheimerRAG, a Multimodal RAG pipeline tool for biomedical research use cases,
primarily focusing on Alzheimer's disease from PubMed articles. Our pipeline
incorporates multimodal fusion techniques to integrate textual and visual data
processing by efficiently indexing and accessing vast amounts of biomedical
literature. Preliminary experimental results against benchmarks, such as BioASQ
and PubMedQA, have returned improved results in information retrieval and
synthesis of domain-specific information. We also demonstrate a case study with
our RAG pipeline across different Alzheimer's clinical scenarios. We infer that
AlzheimerRAG can generate responses with accuracy non-inferior to humans and
with low rates of hallucination. Overall, a reduction in cognitive task load is
observed, which allows researchers to gain multimodal insights, improving
understanding and treatment of Alzheimer's disease.",2024-12-21,"Aritra Kumar Lahiri, Qinmin Vivian Hu",http://arxiv.org/pdf/2412.16701v1,cs.CL
DragonVerseQA: Open-Domain Long-Form Context-Aware Question-Answering,"This paper proposes a novel approach to develop an open-domain and long-form
Over-The-Top (OTT) Question-Answering (QA) dataset, DragonVerseQA, specifically
oriented to the fantasy universe of ""House of the Dragon"" and ""Game Of Thrones""
TV series. Most existing QA datasets focus on short, fact-based answers sourced
almost solely from Wikipedia articles, devoid of depth and contextual richness
for sophisticated narrative understanding. We curate a dataset that combines
full episode summaries sourced from HBO and fandom wiki websites, user reviews
from sources like IMDb and Rotten Tomatoes, and high-quality, open-domain,
legally admissible sources, and structured data from repositories like WikiData
into one dataset. The dataset provides a multi-dimensional context, reflecting
complex character dynamics and plot developments from these varied sources.
That means, on equal footing, only after heavy data preprocessing and filtering
methods will meaningful, non-spam unbiased reviews be available in this
enriched dataset. The comprehensive insights are given through the long-form
answers generated from this enriched context. This is what makes this valuable
dataset for improving conversational AI, narrative analysis, sentiment
analysis, summarization techniques, and relation extraction.
  A comparative analysis with state-of-the-art QA datasets such as SQuAD 2.0,
TriviaQA, and Natural Questions brings to light the unique advantages of our
dataset in terms of contextual complexity and answer length. Detailed reviews
add layers to audience sentiment and narrative interpretation, raising the bar
for domain-specific QA with a new quality benchmark. Our work also allows a
deeper understanding of entertainment-industry content and opens the door to
more knowledgeable and creative AI-driven interactions within digital media
environments.",2024-12-21,"Aritra Kumar Lahiri, Qinmin Vivian Hu",http://arxiv.org/pdf/2412.16694v1,cs.CL
NILE: Internal Consistency Alignment in Large Language Models,"As a crucial step to enhance LLMs alignment with human intentions,
Instruction Fine-Tuning (IFT) has a high demand on dataset quality. However,
existing IFT datasets often contain knowledge that is inconsistent with LLMs'
internal knowledge learned from the pre-training phase, which can greatly
affect the efficacy of IFT. To address this issue, we introduce NILE (iNternal
consIstency aLignmEnt) framework, aimed at optimizing IFT datasets to unlock
LLMs' capability further. NILE operates by eliciting target pre-trained LLM's
internal knowledge corresponding to instruction data. The internal knowledge is
leveraged to revise the answer in IFT datasets. Additionally, we propose a
novel Internal Consistency Filtering (ICF) method to filter training samples,
ensuring its high consistency with LLM's internal knowledge. Our experiments
demonstrate that NILE-aligned IFT datasets sharply boost LLM performance across
multiple LLM ability evaluation datasets, achieving up to 66.6% gain on
Arena-Hard and 68.5% on Alpaca-Eval V2. Further analysis confirms that each
component of the NILE}framework contributes to these substantial performance
improvements, and provides compelling evidence that dataset consistency with
pre-trained internal knowledge is pivotal for maximizing LLM potential.",2024-12-21,"Minda Hu, Qiyuan Zhang, Yufei Wang, Bowei He, Hongru Wang, Jingyan Zhou, Liangyou Li, Yasheng Wang, Chen Ma, Irwin King",http://arxiv.org/pdf/2412.16686v1,cs.CL
The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents,"Large Language Model (LLM) agents are increasingly being deployed as
conversational assistants capable of performing complex real-world tasks
through tool integration. This enhanced ability to interact with external
systems and process various data sources, while powerful, introduces
significant security vulnerabilities. In particular, indirect prompt injection
attacks pose a critical threat, where malicious instructions embedded within
external data sources can manipulate agents to deviate from user intentions.
While existing defenses based on rule constraints, source spotlighting, and
authentication protocols show promise, they struggle to maintain robust
security while preserving task functionality. We propose a novel and orthogonal
perspective that reframes agent security from preventing harmful actions to
ensuring task alignment, requiring every agent action to serve user objectives.
Based on this insight, we develop Task Shield, a test-time defense mechanism
that systematically verifies whether each instruction and tool call contributes
to user-specified goals. Through experiments on the AgentDojo benchmark, we
demonstrate that Task Shield reduces attack success rates (2.07\%) while
maintaining high task utility (69.79\%) on GPT-4o.",2024-12-21,"Feiran Jia, Tong Wu, Xin Qin, Anna Squicciarini",http://arxiv.org/pdf/2412.16682v1,cs.CL
L3TC: Leveraging RWKV for Learned Lossless Low-Complexity Text Compression,"Learning-based probabilistic models can be combined with an entropy coder for
data compression. However, due to the high complexity of learning-based models,
their practical application as text compressors has been largely overlooked. To
address this issue, our work focuses on a low-complexity design while
maintaining compression performance. We introduce a novel Learned Lossless
Low-complexity Text Compression method (L3TC). Specifically, we conduct
extensive experiments demonstrating that RWKV models achieve the fastest
decoding speed with a moderate compression ratio, making it the most suitable
backbone for our method. Second, we propose an outlier-aware tokenizer that
uses a limited vocabulary to cover frequent tokens while allowing outliers to
bypass the prediction and encoding. Third, we propose a novel high-rank
reparameterization strategy that enhances the learning capability during
training without increasing complexity during inference. Experimental results
validate that our method achieves 48% bit saving compared to gzip compressor.
Besides, L3TC offers compression performance comparable to other learned
compressors, with a 50x reduction in model parameters. More importantly, L3TC
is the fastest among all learned compressors, providing real-time decoding
speeds up to megabytes per second. Our code is available at
https://github.com/alipay/L3TC-leveraging-rwkv-for-learned-lossless-low-complexity-text-compression.git.",2024-12-21,"Junxuan Zhang, Zhengxue Cheng, Yan Zhao, Shihao Wang, Dajiang Zhou, Guo Lu, Li Song",http://arxiv.org/pdf/2412.16642v2,cs.CL
Large Language Model Can Be a Foundation for Hidden Rationale-Based Retrieval,"Despite the recent advancement in Retrieval-Augmented Generation (RAG)
systems, most retrieval methodologies are often developed for factual
retrieval, which assumes query and positive documents are semantically similar.
In this paper, we instead propose and study a more challenging type of
retrieval task, called hidden rationale retrieval, in which query and document
are not similar but can be inferred by reasoning chains, logic relationships,
or empirical experiences. To address such problems, an instruction-tuned Large
language model (LLM) with a cross-encoder architecture could be a reasonable
choice. To further strengthen pioneering LLM-based retrievers, we design a
special instruction that transforms the retrieval task into a generative task
by prompting LLM to answer a binary-choice question. The model can be
fine-tuned with direct preference optimization (DPO). The framework is also
optimized for computational efficiency with no performance degradation. We name
this retrieval framework by RaHoRe and verify its zero-shot and fine-tuned
performance superiority on Emotional Support Conversation (ESC), compared with
previous retrieval works. Our study suggests the potential to employ LLM as a
foundation for a wider scope of retrieval tasks. Our codes, models, and
datasets are available on https://github.com/flyfree5/LaHoRe.",2024-12-21,"Luo Ji, Feixiang Guo, Teng Chen, Qingqing Gu, Xiaoyu Wang, Ningyuan Xi, Yihong Wang, Peng Yu, Yue Zhao, Hongyang Lei, Zhonglin Jiang, Yong Chen",http://arxiv.org/pdf/2412.16615v2,cs.CL
Open-Vocabulary Mobile Manipulation Based on Double Relaxed Contrastive Learning with Dense Labeling,"Growing labor shortages are increasing the demand for domestic service robots
(DSRs) to assist in various settings. In this study, we develop a DSR that
transports everyday objects to specified pieces of furniture based on
open-vocabulary instructions. Our approach focuses on retrieving images of
target objects and receptacles from pre-collected images of indoor
environments. For example, given an instruction ""Please get the right red towel
hanging on the metal towel rack and put it in the white washing machine on the
left,"" the DSR is expected to carry the red towel to the washing machine based
on the retrieved images. This is challenging because the correct images should
be retrieved from thousands of collected images, which may include many images
of similar towels and appliances. To address this, we propose RelaX-Former,
which learns diverse and robust representations from among positive, unlabeled
positive, and negative samples. We evaluated RelaX-Former on a dataset
containing real-world indoor images and human annotated instructions including
complex referring expressions. The experimental results demonstrate that
RelaX-Former outperformed existing baseline models across standard image
retrieval metrics. Moreover, we performed physical experiments using a DSR to
evaluate the performance of our approach in a zero-shot transfer setting. The
experiments involved the DSR to carry objects to specific receptacles based on
open-vocabulary instructions, achieving an overall success rate of 75%.",2024-12-21,"Daichi Yashima, Ryosuke Korekata, Komei Sugiura",http://arxiv.org/pdf/2412.16576v2,cs.CL
Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types,"Recent advancements in large language models (LLMs) have significantly
advanced text-to-SQL systems. However, most LLM-based methods often narrowly
focus on SQL generation, neglecting the complexities of real-world
conversational queries. This oversight can lead to unreliable responses,
particularly for ambiguous questions that cannot be directly addressed with
SQL. To bridge this gap, we propose MMSQL, a comprehensive test suite designed
to evaluate the question classification and SQL generation capabilities of LLMs
by simulating real-world scenarios with diverse question types and multi-turn
Q&A interactions. Using MMSQL, we assessed the performance of popular LLMs,
including both open-source and closed-source models, and identified key factors
impacting their performance in such scenarios. Moreover, we introduce an
LLM-based multi-agent framework that employs specialized agents to identify
question types and determine appropriate answering strategies. Our experiments
demonstrate that this approach significantly enhances the model's ability to
navigate the complexities of conversational dynamics, effectively handling the
diverse and complex nature of user queries. Our dataset and code are publicly
available at https://mcxiaoxiao.github.io/MMSQL.",2024-12-21,"Ziming Guo, Chao Ma, Yinggang Sun, Tiancheng Zhao, Guangyao Wang, Hai Huang",http://arxiv.org/pdf/2412.17867v4,cs.CL
Acquisition of Recursive Possessives and Recursive Locatives in Mandarin,"As recursion has been underlying any linguistic work for the last 60 years,
the acquisition of recursive structures by children during language learning
has become a focal point of inquiry. This study delves into the developmental
trajectory of Mandarin-speaking children's acquisition of recursive possessives
and locatives, assessing the impact of structural diversity on language
acquisition. The research contrasts the comprehension of two-level recursive
structures among children aged 3 to 7 years, employing answering question while
seeing a picture task to elicit responses. The findings indicate that children
do not attain adult-like proficiency in two-level recursion until the age of 6,
and there exists a notable asymmetry in the acquisition of recursive
possessives versus locatives. These results underscore the primacy of
structural complexity and cognitive factors in the acquisition process,
enhancing our comprehension of the cognitive foundations of language
development and the pivotal role of recursion in child language acquisition.",2024-12-21,"Chenxi Fu, Xiaoyi Wang, Zaijiang Man, Caimei Yang",http://arxiv.org/pdf/2412.16556v1,cs.CL
Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models,"Large language models (LLMs) are widely applied in various fields of society
due to their powerful reasoning, understanding, and generation capabilities.
However, the security issues associated with these models are becoming
increasingly severe. Jailbreaking attacks, as an important method for detecting
vulnerabilities in LLMs, have been explored by researchers who attempt to
induce these models to generate harmful content through various attack methods.
Nevertheless, existing jailbreaking methods face numerous limitations, such as
excessive query counts, limited coverage of jailbreak modalities, low attack
success rates, and simplistic evaluation methods. To overcome these
constraints, this paper proposes a multimodal jailbreaking method: JMLLM. This
method integrates multiple strategies to perform comprehensive jailbreak
attacks across text, visual, and auditory modalities. Additionally, we
contribute a new and comprehensive dataset for multimodal jailbreaking
research: TriJail, which includes jailbreak prompts for all three modalities.
Experiments on the TriJail dataset and the benchmark dataset AdvBench,
conducted on 13 popular LLMs, demonstrate advanced attack success rates and
significant reduction in time overhead.",2024-12-21,"Yanxu Mao, Peipei Liu, Tiehan Cui, Zhaoteng Yan, Congying Liu, Datao You",http://arxiv.org/pdf/2412.16555v2,cs.CL
Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models,"Large language models have shown remarkable performance across a wide range
of language tasks, owing to their exceptional capabilities in context modeling.
The most commonly used method of context modeling is full self-attention, as
seen in standard decoder-only Transformers. Although powerful, this method can
be inefficient for long sequences and may overlook inherent input structures.
To address these problems, an alternative approach is parallel context
encoding, which splits the context into sub-pieces and encodes them parallelly.
Because parallel patterns are not encountered during training, naively applying
parallel encoding leads to performance degradation. However, the underlying
reasons and potential mitigations are unclear. In this work, we provide a
detailed analysis of this issue and identify that unusually high attention
entropy can be a key factor. Furthermore, we adopt two straightforward methods
to reduce attention entropy by incorporating attention sinks and selective
mechanisms. Experiments on various tasks reveal that these methods effectively
lower irregular attention entropy and narrow performance gaps. We hope this
study can illuminate ways to enhance context modeling mechanisms.",2024-12-21,"Zhisong Zhang, Yan Wang, Xinting Huang, Tianqing Fang, Hongming Zhang, Chenlong Deng, Shuaiyi Li, Dong Yu",http://arxiv.org/pdf/2412.16545v1,cs.CL
Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models,"We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.",2024-12-21,"Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen",http://arxiv.org/pdf/2412.16533v1,cs.CL
Improving Lip-synchrony in Direct Audio-Visual Speech-to-Speech Translation,"Audio-Visual Speech-to-Speech Translation typically prioritizes improving
translation quality and naturalness. However, an equally critical aspect in
audio-visual content is lip-synchrony-ensuring that the movements of the lips
match the spoken content-essential for maintaining realism in dubbed videos.
Despite its importance, the inclusion of lip-synchrony constraints in AVS2S
models has been largely overlooked. This study addresses this gap by
integrating a lip-synchrony loss into the training process of AVS2S models. Our
proposed method significantly enhances lip-synchrony in direct audio-visual
speech-to-speech translation, achieving an average LSE-D score of 10.67,
representing a 9.2% reduction in LSE-D over a strong baseline across four
language pairs. Additionally, it maintains the naturalness and high quality of
the translated speech when overlaid onto the original video, without any
degradation in translation quality.",2024-12-21,"Lucas Goncalves, Prashant Mathur, Xing Niu, Brady Houston, Chandrashekhar Lavania, Srikanth Vishnubhotla, Lijia Sun, Anthony Ferritto",http://arxiv.org/pdf/2412.16530v1,cs.CL
Text2midi: Generating Symbolic Music from Captions,"This paper introduces text2midi, an end-to-end model to generate MIDI files
from textual descriptions. Leveraging the growing popularity of multimodal
generative approaches, text2midi capitalizes on the extensive availability of
textual data and the success of large language models (LLMs). Our end-to-end
system harnesses the power of LLMs to generate symbolic music in the form of
MIDI files. Specifically, we utilize a pretrained LLM encoder to process
captions, which then condition an autoregressive transformer decoder to produce
MIDI sequences that accurately reflect the provided descriptions. This
intuitive and user-friendly method significantly streamlines the music creation
process by allowing users to generate music pieces using text prompts. We
conduct comprehensive empirical evaluations, incorporating both automated and
human studies, that show our model generates MIDI files of high quality that
are indeed controllable by text captions that may include music theory terms
such as chords, keys, and tempo. We release the code and music samples on our
demo page (https://github.com/AMAAI-Lab/Text2midi) for users to interact with
text2midi.",2024-12-21,"Keshav Bhandari, Abhinaba Roy, Kyra Wang, Geeta Puri, Simon Colton, Dorien Herremans",http://arxiv.org/pdf/2412.16526v2,cs.CL
HammerBench: Fine-Grained Function-Calling Evaluation in Real Mobile Device Scenarios,"Evaluating the performance of LLMs in multi-turn human-agent interactions
presents significant challenges, particularly due to the complexity and
variability of user behavior. In this paper, we introduce HammerBench, a novel
benchmark framework for assessing LLMs' function-calling capabilities in
real-world, multi-turn dialogues. HammerBench simulates diverse mobile
assistant use cases, incorporating imperfect instructions, dynamic
question-answer trajectories, intent and argument shifts, and the indirect use
of external information through pronouns. To construct this benchmark, we
curate a comprehensive dataset derived from popular mobile app functionalities
and anonymized user logs, complemented by a cost-effective data generation
pipeline leveraging open-source models. HammerBench is further augmented with
fine-grained interaction snapshots and metrics, enabling detailed evaluation of
function-calling performance across individual conversational turns. We
demonstrate the effectiveness of HammerBench by evaluating several leading LLMs
and uncovering key performance trends. Our experiments reveal that different
types of parameter name errors are a significant source of failure across
different interaction scenarios, highlighting critical areas for further
improvement in LLM robustness for mobile assistant applications.",2024-12-21,"Jun Wang, Jiamu Zhou, Muning Wen, Xiaoyun Mo, Haoyu Zhang, Qiqiang Lin, Cheng Jin, Xihuai Wang, Weinan Zhang, Qiuying Peng, Jun Wang",http://arxiv.org/pdf/2412.16516v2,cs.CL
Adapting Whisper for Code-Switching through Encoding Refining and Language-Aware Decoding,"Code-switching (CS) automatic speech recognition (ASR) faces challenges due
to the language confusion resulting from accents, auditory similarity, and
seamless language switches. Adaptation on the pre-trained multi-lingual model
has shown promising performance for CS-ASR. In this paper, we adapt Whisper,
which is a large-scale multilingual pre-trained speech recognition model, to CS
from both encoder and decoder parts. First, we propose an encoder refiner to
enhance the encoder's capacity of intra-sentence swithching. Second, we propose
using two sets of language-aware adapters with different language prompt
embeddings to achieve language-specific decoding information in each decoder
layer. Then, a fusion module is added to fuse the language-aware decoding. The
experimental results using the SEAME dataset show that, compared with the
baseline model, the proposed approach achieves a relative MER reduction of 4.1%
and 7.2% on the dev_man and dev_sge test sets, respectively, surpassing
state-of-the-art methods. Through experiments, we found that the proposed
method significantly improves the performance on non-native language in CS
speech, indicating that our approach enables Whisper to better distinguish
between the two languages.",2024-12-21,"Jiahui Zhao, Hao Shi, Chenrui Cui, Tianrui Wang, Hexin Liu, Zhaoheng Ni, Lingxuan Ye, Longbiao Wang",http://arxiv.org/pdf/2412.16507v3,cs.CL
Speech Retrieval-Augmented Generation without Automatic Speech Recognition,"One common approach for question answering over speech data is to first
transcribe speech using automatic speech recognition (ASR) and then employ
text-based retrieval-augmented generation (RAG) on the transcriptions. While
this cascaded pipeline has proven effective in many practical settings, ASR
errors can propagate to the retrieval and generation steps. To overcome this
limitation, we introduce SpeechRAG, a novel framework designed for
open-question answering over spoken data. Our proposed approach fine-tunes a
pre-trained speech encoder into a speech adapter fed into a frozen large
language model (LLM)--based retrieval model. By aligning the embedding spaces
of text and speech, our speech retriever directly retrieves audio passages from
text-based queries, leveraging the retrieval capacity of the frozen text
retriever. Our retrieval experiments on spoken question answering datasets show
that direct speech retrieval does not degrade over the text-based baseline, and
outperforms the cascaded systems using ASR. For generation, we use a speech
language model (SLM) as a generator, conditioned on audio passages rather than
transcripts. Without fine-tuning of the SLM, this approach outperforms cascaded
text-based models when there is high WER in the transcripts.",2024-12-21,"Do June Min, Karel Mundnich, Andy Lapastora, Erfan Soltanmohammadi, Srikanth Ronanki, Kyu Han",http://arxiv.org/pdf/2412.16500v3,cs.CL
Real-time Bangla Sign Language Translator,"The human body communicates through various meaningful gestures, with sign
language using hands being a prominent example. Bangla Sign Language
Translation (BSLT) aims to bridge communication gaps for the deaf and mute
community. Our approach involves using Mediapipe Holistic to gather key points,
LSTM architecture for data training, and Computer Vision for realtime sign
language detection with an accuracy of 94%. Keywords=Recurrent Neural Network,
LSTM, Computer Vision, Bangla font.",2024-12-21,"Rotan Hawlader Pranto, Shahnewaz Siddique",http://arxiv.org/pdf/2412.16497v1,cs.CL
"MERaLiON-TextLLM: Cross-Lingual Understanding of Large Language Models in Chinese, Indonesian, Malay, and Singlish","Multilingual large language models (MLLMs) have shown impressive capabilities
across a variety of languages. However, efficacy can differ greatly between
different language families, especially for those with limited linguistic
resources. This report presents MERaLiON-TextLLM, a series of open-source
language models specifically tailored to improve understanding and generation
in Chinese, Indonesian, Malay, and Singlish. The initial released model is
built on Llama-3-8B-Base and refined through a meticulously crafted process of
continued pre-training and weight merging. Our approach achieves performance
improvements across benchmarks in these languages, exceeding the capabilities
of the official Llama-3 models. We provide the model checkpoints as a resource
to support further research and development in cross-lingual language
understanding.",2024-12-21,"Xin Huang, Tarun Kumar Vangani, Minh Duc Pham, Xunlong Zou, Bin Wang, Zhengyuan Liu, Ai Ti Aw",http://arxiv.org/pdf/2501.08335v3,cs.CL
Evaluating the Performance of Large Language Models in Scientific Claim Detection and Classification,"The pervasive influence of social media during the COVID-19 pandemic has been
a double-edged sword, enhancing communication while simultaneously propagating
misinformation. This \textit{Digital Infodemic} has highlighted the urgent need
for automated tools capable of discerning and disseminating factual content.
This study evaluates the efficacy of Large Language Models (LLMs) as innovative
solutions for mitigating misinformation on platforms like Twitter. LLMs, such
as OpenAI's GPT and Meta's LLaMA, offer a pre-trained, adaptable approach that
bypasses the extensive training and overfitting issues associated with
traditional machine learning models. We assess the performance of LLMs in
detecting and classifying COVID-19-related scientific claims, thus facilitating
informed decision-making. Our findings indicate that LLMs have significant
potential as automated fact-checking tools, though research in this domain is
nascent and further exploration is required. We present a comparative analysis
of LLMs' performance using a specialized dataset and propose a framework for
their application in public health communication.",2024-12-21,Tanjim Bin Faruk,http://arxiv.org/pdf/2412.16486v1,cs.CL
Automated CVE Analysis: Harnessing Machine Learning In Designing Question-Answering Models For Cybersecurity Information Extraction,"The vast majority of cybersecurity information is unstructured text,
including critical data within databases such as CVE, NVD, CWE, CAPEC, and the
MITRE ATT&CK Framework. These databases are invaluable for analyzing attack
patterns and understanding attacker behaviors. Creating a knowledge graph by
integrating this information could unlock significant insights. However,
processing this large amount of data requires advanced deep-learning
techniques. A crucial step towards building such a knowledge graph is
developing a robust mechanism for automating the extraction of answers to
specific questions from the unstructured text. Question Answering (QA) systems
play a pivotal role in this process by pinpointing and extracting precise
information, facilitating the mapping of relationships between various data
points. In the cybersecurity context, QA systems encounter unique challenges
due to the need to interpret and answer questions based on a wide array of
domain-specific information. To tackle these challenges, it is necessary to
develop a cybersecurity-specific dataset and train a machine learning model on
it, aimed at enhancing the understanding and retrieval of domain-specific
information. This paper presents a novel dataset and describes a machine
learning model trained on this dataset for the QA task. It also discusses the
model's performance and key findings in a manner that maintains a balance
between formality and accessibility.",2024-12-21,Tanjim Bin Faruk,http://arxiv.org/pdf/2412.16484v1,cs.CL
Enhancing Multilingual ASR for Unseen Languages via Language Embedding Modeling,"Multilingual Automatic Speech Recognition (ASR) aims to recognize and
transcribe speech from multiple languages within a single system. Whisper, one
of the most advanced ASR models, excels in this domain by handling 99 languages
effectively, leveraging a vast amount of data and incorporating language tags
as prefixes to guide the recognition process. However, despite its success,
Whisper struggles with unseen languages, those not included in its
pre-training. Motivated by the observation that many languages share linguistic
characteristics, we propose methods that exploit these relationships to enhance
ASR performance on unseen languages. Specifically, we introduce a weighted sum
method, which computes a weighted sum of the embeddings of language tags, using
Whisper's predicted language probabilities. In addition, we develop a
predictor-based approach that refines the weighted sum embedding to more
closely approximate the true embedding for unseen languages. Experimental
results demonstrate substantial improvements in ASR performance, both in
zero-shot and fine-tuning settings. Our proposed methods outperform baseline
approaches, providing an effective solution for addressing unseen languages in
multilingual ASR.",2024-12-21,"Shao-Syuan Huang, Kuan-Po Huang, Andy T. Liu, Hung-yi Lee",http://arxiv.org/pdf/2412.16474v1,cs.CL
Chained Tuning Leads to Biased Forgetting,"Large language models (LLMs) are often fine-tuned for use on downstream
tasks, though this can degrade capabilities learned during previous training.
This phenomenon, often referred to as catastrophic forgetting, has important
potential implications for the safety of deployed models. In this work, we
first show that models trained on downstream tasks forget their safety tuning
to a greater extent than models trained in the opposite order. Second, we show
that forgetting disproportionately impacts safety information about certain
groups. To quantify this phenomenon, we define a new metric we term biased
forgetting. We conduct a systematic evaluation of the effects of task ordering
on forgetting and apply mitigations that can help the model recover from the
forgetting observed. We hope our findings can better inform methods for
chaining the finetuning of LLMs in continual learning settings to enable
training of safer and less toxic models.",2024-12-21,"Megan Ung, Alicia Sun, Samuel J. Bell, Bhaktipriya Radharapu, Levent Sagun, Adina Williams",http://arxiv.org/pdf/2412.16469v2,cs.CL
Transducer-Llama: Integrating LLMs into Streamable Transducer-based Speech Recognition,"While large language models (LLMs) have been applied to automatic speech
recognition (ASR), the task of making the model streamable remains a challenge.
This paper proposes a novel model architecture, Transducer-Llama, that
integrates LLMs into a Factorized Transducer (FT) model, naturally enabling
streaming capabilities. Furthermore, given that the large vocabulary of LLMs
can cause data sparsity issue and increased training costs for spoken language
systems, this paper introduces an efficient vocabulary adaptation technique to
align LLMs with speech system vocabularies. The results show that directly
optimizing the FT model with a strong pre-trained LLM-based predictor using the
RNN-T loss yields some but limited improvements over a smaller pre-trained LM
predictor. Therefore, this paper proposes a weak-to-strong LM swap strategy,
using a weak LM predictor during RNN-T loss training and then replacing it with
a strong LLM. After LM replacement, the minimum word error rate (MWER) loss is
employed to finetune the integration of the LLM predictor with the
Transducer-Llama model. Experiments on the LibriSpeech and large-scale
multi-lingual LibriSpeech corpora show that the proposed streaming
Transducer-Llama approach gave a 17% relative WER reduction (WERR) over a
strong FT baseline and a 32% WERR over an RNN-T baseline.",2024-12-21,"Keqi Deng, Jinxi Guo, Yingyi Ma, Niko Moritz, Philip C. Woodland, Ozlem Kalinli, Mike Seltzer",http://arxiv.org/pdf/2412.16464v1,cs.CL
Research on Violent Text Detection System Based on BERT-fasttext Model,"In the digital age of today, the internet has become an indispensable
platform for people's lives, work, and information exchange. However, the
problem of violent text proliferation in the network environment has arisen,
which has brought about many negative effects. In view of this situation, it is
particularly important to build an effective system for cutting off violent
text. The study of violent text cutting off based on the BERT-fasttext model
has significant meaning. BERT is a pre-trained language model with strong
natural language understanding ability, which can deeply mine and analyze text
semantic information; Fasttext itself is an efficient text classification tool
with low complexity and good effect, which can quickly provide basic judgments
for text processing. By combining the two and applying them to the system for
cutting off violent text, on the one hand, it can accurately identify violent
text, and on the other hand, it can efficiently and reasonably cut off the
content, preventing harmful information from spreading freely on the network.
Compared with the single BERT model and fasttext, the accuracy was improved by
0.7% and 0.8%, respectively. Through this model, it is helpful to purify the
network environment, maintain the health of network information, and create a
positive, civilized, and harmonious online communication space for netizens,
driving the development of social networking, information dissemination, and
other aspects in a more benign direction.",2024-12-21,"Yongsheng Yang, Xiaoying Wang",http://arxiv.org/pdf/2412.16455v1,cs.CL
Correcting Large Language Model Behavior via Influence Function,"Recent advancements in AI alignment techniques have significantly improved
the alignment of large language models (LLMs) with static human preferences.
However, the dynamic nature of human preferences can render some prior training
data outdated or even erroneous, ultimately causing LLMs to deviate from
contemporary human preferences and societal norms. Existing methodologies,
whether they involve the curation of new data for continual alignment or the
manual correction of outdated data for re-alignment, demand costly human
resources. To address this challenge, we propose a novel approach, Large
Language Model Behavior Correction with Influence Function Recall and
Post-Training (LANCET), which requires no human involvement. LANCET consists of
two phases: (1) using influence functions to identify the training data that
significantly impact undesirable model outputs, and (2) applying an Influence
function-driven Bregman Optimization (IBO) technique to adjust the model's
behavior based on these influence distributions. Our experiments demonstrate
that LANCET effectively and efficiently correct inappropriate behaviors of
LLMs. Furthermore, LANCET can outperform methods that rely on collecting human
preferences, and it enhances the interpretability of learning human preferences
within LLMs.",2024-12-21,"Han Zhang, Zhuo Zhang, Yi Zhang, Yuanzhao Zhai, Hanyang Peng, Yu Lei, Yue Yu, Hui Wang, Bin Liang, Lin Gui, Ruifeng Xu",http://arxiv.org/pdf/2412.16451v1,cs.CL
Effective Context Modeling Framework for Emotion Recognition in Conversations,"Emotion Recognition in Conversations (ERC) facilitates a deeper understanding
of the emotions conveyed by speakers in each utterance within a conversation.
Recently, Graph Neural Networks (GNNs) have demonstrated their strengths in
capturing data relationships, particularly in contextual information modeling
and multimodal fusion. However, existing methods often struggle to fully
capture the complex interactions between multiple modalities and conversational
context, limiting their expressiveness. To overcome these limitations, we
propose ConxGNN, a novel GNN-based framework designed to capture contextual
information in conversations. ConxGNN features two key parallel modules: a
multi-scale heterogeneous graph that captures the diverse effects of utterances
on emotional changes, and a hypergraph that models the multivariate
relationships among modalities and utterances. The outputs from these modules
are integrated into a fusion layer, where a cross-modal attention mechanism is
applied to produce a contextually enriched representation. Additionally,
ConxGNN tackles the challenge of recognizing minority or semantically similar
emotion classes by incorporating a re-weighting scheme into the loss functions.
Experimental results on the IEMOCAP and MELD benchmark datasets demonstrate the
effectiveness of our method, achieving state-of-the-art performance compared to
previous baselines.",2024-12-21,"Cuong Tran Van, Thanh V. T. Tran, Van Nguyen, Truong Son Hy",http://arxiv.org/pdf/2412.16444v1,cs.CL
Distilling Large Language Models for Efficient Clinical Information Extraction,"Large language models (LLMs) excel at clinical information extraction but
their computational demands limit practical deployment. Knowledge
distillation--the process of transferring knowledge from larger to smaller
models--offers a potential solution. We evaluate the performance of distilled
BERT models, which are approximately 1,000 times smaller than modern LLMs, for
clinical named entity recognition (NER) tasks. We leveraged state-of-the-art
LLMs (Gemini and OpenAI models) and medical ontologies (RxNorm and SNOMED) as
teacher labelers for medication, disease, and symptom extraction. We applied
our approach to over 3,300 clinical notes spanning five publicly available
datasets, comparing distilled BERT models against both their teacher labelers
and BERT models fine-tuned on human labels. External validation was conducted
using clinical notes from the MedAlign dataset. For disease extraction, F1
scores were 0.82 (teacher model), 0.89 (BioBERT trained on human labels), and
0.84 (BioBERT-distilled). For medication, F1 scores were 0.84 (teacher model),
0.91 (BioBERT-human), and 0.87 (BioBERT-distilled). For symptoms: F1 score of
0.73 (teacher model) and 0.68 (BioBERT-distilled). Distilled BERT models had
faster inference (12x, 4x, 8x faster than GPT-4o, o1-mini, and Gemini Flash
respectively) and lower costs (85x, 101x, 2x cheaper than GPT-4o, o1-mini, and
Gemini Flash respectively). On the external validation dataset, the distilled
BERT model achieved F1 scores of 0.883 (medication), 0.726 (disease), and 0.699
(symptom). Distilled BERT models were up to 101x cheaper and 12x faster than
state-of-the-art LLMs while achieving similar performance on NER tasks.
Distillation offers a computationally efficient and scalable alternative to
large LLMs for clinical information extraction.",2024-12-21,"Karthik S. Vedula, Annika Gupta, Akshay Swaminathan, Ivan Lopez, Suhana Bedi, Nigam H. Shah",http://arxiv.org/pdf/2501.00031v1,cs.CL
"Underutilization of Syntactic Processing by Chinese Learners of English in Comprehending English Sentences, Evidenced from Adapted Garden-Path Ambiguity Experiment","Many studies have revealed that sentence comprehension relies more on
semantic processing than on syntactic processing. However, previous studies
have predominantly emphasized the preference for semantic processing, focusing
on the semantic perspective. In contrast, this current study highlights the
under-utilization of syntactic processing, from a syntactic perspective. Based
on the traditional garden-path experiment, which involves locally ambiguous but
globally unambiguous sentences, this study's empirical experiment innovatively
crafted an adapted version featuring semantically ambiguous but syntactically
unambiguous sentences to meet its specific research objective. This experiment,
involving 140 subjects, demonstrates through descriptive and inferential
statistical analyses using SPSS, Graph Pad Prism, and Cursor that Chinese
learners of English tend to under-utilize syntactic processing when
comprehending English sentences. The study identifies two types of parsing
under-utilization: partial and complete. Further exploration reveals that trial
and error in syntactic processing contributes to both. Consequently, this study
lays a foundation for the development of a novel parsing method designed to
fully integrate syntactic processing into sentence comprehension, thereby
enhancing the level of English sentence comprehension for Chinese learners of
English.",2024-12-21,Jiapeng Xu,http://arxiv.org/pdf/2501.00030v1,cs.CL
Technical Report: Small Language Model for Japanese Clinical and Medicine,"This report presents a small language model (SLM) for Japanese clinical and
medicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese
text classified to be of high-quality. Moreover, NCVC-slm-1 was augmented with
respect to clinical and medicine content that includes the variety of diseases,
drugs, and examinations. Using a carefully designed pre-processing, a
specialized morphological analyzer and tokenizer, this small and light-weight
model performed not only to generate text but also indicated the feasibility of
understanding clinical and medicine text. In comparison to other large language
models, a fine-tuning NCVC-slm-1 demonstrated the highest scores on 6 tasks of
total 8 on JMED-LLM. According to this result, SLM indicated the feasibility of
performing several downstream tasks in the field of clinical and medicine.
Hopefully, NCVC-slm-1 will be contributed to develop and accelerate the field
of clinical and medicine for a bright future.",2024-12-21,Shogo Watanabe,http://arxiv.org/pdf/2412.16423v1,cs.CL
Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding,"Flowcharts are typically presented as images, driving the trend of using
vision-language models (VLMs) for end-to-end flowchart understanding. However,
two key challenges arise: (i) Limited controllability--users have minimal
influence over the downstream task, as they can only modify input images, while
the training of VLMs is often out of reach for most researchers. (ii) Lack of
explainability--it is difficult to trace VLM errors to specific causes, such as
failures in visual encoding or reasoning. We propose TextFlow, addressing
aforementioned issues with two stages: (i) Vision Textualizer--which generates
textual representations from flowchart images; and (ii) Textual Reasoner--which
performs question-answering based on the text representations. TextFlow offers
three key advantages: (i) users can select the type of text representations
(e.g., Graphviz, Mermaid, PlantUML), or further convert them into executable
graph object to call tools, enhancing performance and controllability; (ii) it
improves explainability by helping to attribute errors more clearly to visual
or textual processing components; and (iii) it promotes the modularization of
the solution, such as allowing advanced LLMs to be used in the Reasoner stage
when VLMs underperform in end-to-end fashion. Experiments on the FlowVQA and
FlowLearn benchmarks demonstrate TextFlow's state-of-the-art performance as
well as its robustness. All code is publicly available.",2024-12-21,"Junyi Ye, Ankan Dash, Wenpeng Yin, Guiling Wang",http://arxiv.org/pdf/2412.16420v1,cs.CL
Identifying Cyberbullying Roles in Social Media,"Social media has revolutionized communication, allowing people worldwide to
connect and interact instantly. However, it has also led to increases in
cyberbullying, which poses a significant threat to children and adolescents
globally, affecting their mental health and well-being. It is critical to
accurately detect the roles of individuals involved in cyberbullying incidents
to effectively address the issue on a large scale. This study explores the use
of machine learning models to detect the roles involved in cyberbullying
interactions. After examining the AMiCA dataset and addressing class imbalance
issues, we evaluate the performance of various models built with four
underlying LLMs (i.e., BERT, RoBERTa, T5, and GPT-2) for role detection. Our
analysis shows that oversampling techniques help improve model performance. The
best model, a fine-tuned RoBERTa using oversampled data, achieved an overall F1
score of 83.5%, increasing to 89.3% after applying a prediction threshold. The
top-2 F1 score without thresholding was 95.7%. Our method outperforms
previously proposed models. After investigating the per-class model performance
and confidence scores, we show that the models perform well in classes with
more samples and less contextual confusion (e.g., Bystander Other), but
struggle with classes with fewer samples (e.g., Bystander Assistant) and more
contextual ambiguity (e.g., Harasser and Victim). This work highlights current
strengths and limitations in the development of accurate models with limited
data and complex scenarios.",2024-12-21,"Manuel Sandoval, Mohammed Abuhamad, Patrick Furman, Mujtaba Nazari, Deborah L. Hall, Yasin N. Silva",http://arxiv.org/pdf/2412.16417v1,cs.CL
InfoTech Assistant : A Multimodal Conversational Agent for InfoTechnology Web Portal Queries,"This pilot study presents the development of the InfoTech Assistant, a
domain-specific, multimodal chatbot engineered to address queries in bridge
evaluation and infrastructure technology. By integrating web data scraping,
large language models (LLMs), and Retrieval-Augmented Generation (RAG), the
InfoTech Assistant provides accurate and contextually relevant responses. Data,
including textual descriptions and images, are sourced from publicly available
documents on the InfoTechnology website and organized in JSON format to
facilitate efficient querying. The architecture of the system includes an
HTML-based interface and a Flask back end connected to the Llama 3.1 model via
LLM Studio. Evaluation results show approximately 95 percent accuracy on
domain-specific tasks, with high similarity scores confirming the quality of
response matching. This RAG-enhanced setup enables the InfoTech Assistant to
handle complex, multimodal queries, offering both textual and visual
information in its responses. The InfoTech Assistant demonstrates strong
potential as a dependable tool for infrastructure professionals, delivering
high accuracy and relevance in its domain-specific outputs.",2024-12-21,"Sai Surya Gadiraju, Duoduo Liao, Akhila Kudupudi, Santosh Kasula, Charitha Chalasani",http://arxiv.org/pdf/2412.16412v1,cs.CL
Application of Multimodal Large Language Models in Autonomous Driving,"In this era of technological advancements, several cutting-edge techniques
are being implemented to enhance Autonomous Driving (AD) systems, focusing on
improving safety, efficiency, and adaptability in complex driving environments.
However, AD still faces some problems including performance limitations. To
address this problem, we conducted an in-depth study on implementing the
Multi-modal Large Language Model. We constructed a Virtual Question Answering
(VQA) dataset to fine-tune the model and address problems with the poor
performance of MLLM on AD. We then break down the AD decision-making process by
scene understanding, prediction, and decision-making. Chain of Thought has been
used to make the decision more perfectly. Our experiments and detailed analysis
of Autonomous Driving give an idea of how important MLLM is for AD.",2024-12-21,Md Robiul Islam,http://arxiv.org/pdf/2412.16410v2,cs.CL
REFA: Reference Free Alignment for multi-preference optimization,"We introduce $\textbf{REFA}$, a family of reference-free alignment methods
that optimize over multiple user preferences while enforcing fine-grained
length control. Our approach integrates deviation-based weighting to emphasize
high-quality responses, length normalization to prevent trivial short-response
solutions, and an EOS-probability regularizer to mitigate dataset-induced
brevity biases. Theoretically, we show that under the Uncertainty Reduction
with Sequence Length Assertion (URSLA) framework, naive length normalization
can still incentivize length-based shortcuts. In contrast, REFA corrects these
subtle incentives, guiding models toward genuinely more informative and
higher-quality outputs. Empirically, REFA achieves a new
$\textbf{state-of-the-art}$ among reference-free alignment methods, generating
richer responses that align more closely with human preferences. Notably, REFA
improves performance on the AlpacaEval2 benchmark, achieving a $\textbf{26.6%}$
Length-Controlled Win Rate (LC-WR) and $\textbf{24.2%}$ Win Rate (WR).",2024-12-20,"Taneesh Gupta, Rahul Madhavan, Xuchao Zhang, Chetan Bansal, Saravan Rajmohan",http://arxiv.org/pdf/2412.16378v3,cs.CL
Overview of the First Workshop on Language Models for Low-Resource Languages (LoResLM 2025),"The first Workshop on Language Models for Low-Resource Languages (LoResLM
2025) was held in conjunction with the 31st International Conference on
Computational Linguistics (COLING 2025) in Abu Dhabi, United Arab Emirates.
This workshop mainly aimed to provide a forum for researchers to share and
discuss their ongoing work on language models (LMs) focusing on low-resource
languages, following the recent advancements in neural language models and
their linguistic biases towards high-resource languages. LoResLM 2025 attracted
notable interest from the natural language processing (NLP) community,
resulting in 35 accepted papers from 52 submissions. These contributions cover
a broad range of low-resource languages from eight language families and 13
diverse research areas, paving the way for future possibilities and promoting
linguistic inclusivity in NLP.",2024-12-20,"Hansi Hettiarachchi, Tharindu Ranasinghe, Paul Rayson, Ruslan Mitkov, Mohamed Gaber, Damith Premasiri, Fiona Anting Tan, Lasitha Uyangodage",http://arxiv.org/pdf/2412.16365v1,cs.CL
A High-Quality Text-Rich Image Instruction Tuning Dataset via Hybrid Instruction Generation,"Large multimodal models still struggle with text-rich images because of
inadequate training data. Self-Instruct provides an annotation-free way for
generating instruction data, but its quality is poor, as multimodal alignment
remains a hurdle even for the largest models. In this work, we propose
LLaVAR-2, to enhance multimodal alignment for text-rich images through hybrid
instruction generation between human annotators and large language models.
Specifically, it involves detailed image captions from human annotators,
followed by the use of these annotations in tailored text prompts for GPT-4o to
curate a dataset. It also implements several mechanisms to filter out
low-quality data, and the resulting dataset comprises 424k high-quality pairs
of instructions. Empirical results show that models fine-tuned on this dataset
exhibit impressive enhancements over those trained with self-instruct data.",2024-12-20,"Shijie Zhou, Ruiyi Zhang, Yufan Zhou, Changyou Chen",http://arxiv.org/pdf/2412.16364v1,cs.CL
Human-Readable Adversarial Prompts: An Investigation into LLM Vulnerabilities Using Situational Context,"Previous studies that uncovered vulnerabilities in large language models
(LLMs) frequently employed nonsensical adversarial prompts. However, such
prompts can now be readily identified using automated detection techniques. To
further strengthen adversarial attacks, we focus on human-readable adversarial
prompts, which are more realistic and potent threats. Our key contributions are
(1) situation-driven attacks leveraging movie scripts as context to create
human-readable prompts that successfully deceive LLMs, (2) adversarial suffix
conversion to transform nonsensical adversarial suffixes into independent
meaningful text, and (3) AdvPrompter with p-nucleus sampling, a method to
generate diverse, human-readable adversarial suffixes, improving attack
efficacy in models like GPT-3.5 and Gemma 7B.",2024-12-20,"Nilanjana Das, Edward Raff, Manas Gaur",http://arxiv.org/pdf/2412.16359v2,cs.CL
A Machine Learning Approach for Emergency Detection in Medical Scenarios Using Large Language Models,"The rapid identification of medical emergencies through digital communication
channels remains a critical challenge in modern healthcare delivery,
particularly with the increasing prevalence of telemedicine. This paper
presents a novel approach leveraging large language models (LLMs) and prompt
engineering techniques for automated emergency detection in medical
communications. We developed and evaluated a comprehensive system using
multiple LLaMA model variants (1B, 3B, and 7B parameters) to classify medical
scenarios as emergency or non-emergency situations. Our methodology
incorporated both system prompts and in-prompt training approaches, evaluated
across different hardware configurations. The results demonstrate exceptional
performance, with the LLaMA 2 (7B) model achieving 99.7% accuracy and the LLaMA
3.2 (3B) model reaching 99.6% accuracy with optimal prompt engineering. Through
systematic testing of training examples within the prompts, we identified that
including 10 example scenarios in the model prompts yielded optimal
classification performance. Processing speeds varied significantly between
platforms, ranging from 0.05 to 2.2 seconds per request. The system showed
particular strength in minimizing high-risk false negatives in emergency
scenarios, which is crucial for patient safety. The code implementation and
evaluation framework are publicly available on GitHub, facilitating further
research and development in this crucial area of healthcare technology.",2024-12-20,"Ferit Akaybicen, Aaron Cummings, Lota Iwuagwu, Xinyue Zhang, Modupe Adewuyi",http://arxiv.org/pdf/2412.16341v1,cs.CL
Deliberative Alignment: Reasoning Enables Safer Language Models,"As large-scale language models increasingly impact safety-critical domains,
ensuring their reliable adherence to well-defined principles remains a
fundamental challenge. We introduce Deliberative Alignment, a new paradigm that
directly teaches the model safety specifications and trains it to explicitly
recall and accurately reason over the specifications before answering. We used
this approach to align OpenAI's o-series models, and achieved highly precise
adherence to OpenAI's safety policies, without requiring human-written
chain-of-thoughts or answers. Deliberative Alignment pushes the Pareto frontier
by simultaneously increasing robustness to jailbreaks while decreasing
overrefusal rates, and also improves out-of-distribution generalization. We
demonstrate that reasoning over explicitly specified policies enables more
scalable, trustworthy, and interpretable alignment.",2024-12-20,"Melody Y. Guan, Manas Joglekar, Eric Wallace, Saachi Jain, Boaz Barak, Alec Helyar, Rachel Dias, Andrea Vallone, Hongyu Ren, Jason Wei, Hyung Won Chung, Sam Toyer, Johannes Heidecke, Alex Beutel, Amelia Glaese",http://arxiv.org/pdf/2412.16339v2,cs.CL
"A Breadth-First Catalog of Text Processing, Speech Processing and Multimodal Research in South Asian Languages","We review the recent literature (January 2022- October 2024) in South Asian
languages on text-based language processing, multimodal models, and speech
processing, and provide a spotlight analysis focused on 21 low-resource South
Asian languages, namely Saraiki, Assamese, Balochi, Bhojpuri, Bodo, Burmese,
Chhattisgarhi, Dhivehi, Gujarati, Kannada, Kashmiri, Konkani, Khasi, Malayalam,
Meitei, Nepali, Odia, Pashto, Rajasthani, Sindhi, and Telugu. We identify
trends, challenges, and future research directions, using a step-wise approach
that incorporates relevance classification and clustering based on large
language models (LLMs). Our goal is to provide a breadth-first overview of the
recent developments in South Asian language technologies to NLP researchers
interested in working with South Asian languages.",2024-12-20,Pranav Gupta,http://arxiv.org/pdf/2501.00029v1,cs.CL
Decoding Linguistic Nuances in Mental Health Text Classification Using Expressive Narrative Stories,"Recent advancements in NLP have spurred significant interest in analyzing
social media text data for identifying linguistic features indicative of mental
health issues. However, the domain of Expressive Narrative Stories (ENS)-deeply
personal and emotionally charged narratives that offer rich psychological
insights-remains underexplored. This study bridges this gap by utilizing a
dataset sourced from Reddit, focusing on ENS from individuals with and without
self-declared depression. Our research evaluates the utility of advanced
language models, BERT and MentalBERT, against traditional models. We find that
traditional models are sensitive to the absence of explicit topic-related
words, which could risk their potential to extend applications to ENS that lack
clear mental health terminology. Despite MentalBERT is design to better handle
psychiatric contexts, it demonstrated a dependency on specific topic words for
classification accuracy, raising concerns about its application when explicit
mental health terms are sparse (P-value<0.05). In contrast, BERT exhibited
minimal sensitivity to the absence of topic words in ENS, suggesting its
superior capability to understand deeper linguistic features, making it more
effective for real-world applications. Both BERT and MentalBERT excel at
recognizing linguistic nuances and maintaining classification accuracy even
when narrative order is disrupted. This resilience is statistically
significant, with sentence shuffling showing substantial impacts on model
performance (P-value<0.05), especially evident in ENS comparisons between
individuals with and without mental health declarations. These findings
underscore the importance of exploring ENS for deeper insights into mental
health-related narratives, advocating for a nuanced approach to mental health
text analysis that moves beyond mere keyword detection.",2024-12-20,"Jinwen Tang, Qiming Guo, Yunxin Zhao, Yi Shang",http://arxiv.org/pdf/2412.16302v1,cs.CL
Benchmarking LLMs and SLMs for patient reported outcomes,"LLMs have transformed the execution of numerous tasks, including those in the
medical domain. Among these, summarizing patient-reported outcomes (PROs) into
concise natural language reports is of particular interest to clinicians, as it
enables them to focus on critical patient concerns and spend more time in
meaningful discussions. While existing work with LLMs like GPT-4 has shown
impressive results, real breakthroughs could arise from leveraging SLMs as they
offer the advantage of being deployable locally, ensuring patient data privacy
and compliance with healthcare regulations. This study benchmarks several SLMs
against LLMs for summarizing patient-reported Q\&A forms in the context of
radiotherapy. Using various metrics, we evaluate their precision and
reliability. The findings highlight both the promise and limitations of SLMs
for high-stakes medical tasks, fostering more efficient and privacy-preserving
AI-driven healthcare solutions.",2024-12-20,"Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault",http://arxiv.org/pdf/2412.16291v1,cs.CL
Offline Reinforcement Learning for LLM Multi-Step Reasoning,"Improving the multi-step reasoning ability of large language models (LLMs)
with offline reinforcement learning (RL) is essential for quickly adapting them
to complex tasks. While Direct Preference Optimization (DPO) has shown promise
in aligning LLMs with human preferences, it is less suitable for multi-step
reasoning tasks because (1) DPO relies on paired preference data, which is not
readily available for multi-step reasoning tasks, and (2) it treats all tokens
uniformly, making it ineffective for credit assignment in multi-step reasoning
tasks, which often come with sparse reward. In this work, we propose OREO
(Offline Reasoning Optimization), an offline RL method for enhancing LLM
multi-step reasoning. Building on insights from previous works of maximum
entropy reinforcement learning, it jointly learns a policy model and value
function by optimizing the soft Bellman Equation. We show in principle that it
reduces the need to collect pairwise data and enables better credit assignment.
Empirically, OREO surpasses existing offline learning methods on multi-step
reasoning benchmarks, including mathematical reasoning tasks (GSM8K, MATH) and
embodied agent control (ALFWorld). The approach can be extended to a
multi-iteration framework when additional resources are available. Furthermore,
the learned value function can be leveraged to guide the tree search for free,
which can further boost performance during test time.",2024-12-20,"Huaijie Wang, Shibo Hao, Hanze Dong, Shenao Zhang, Yilin Bao, Ziran Yang, Yi Wu",http://arxiv.org/pdf/2412.16145v2,cs.CL
Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation,"Malware authors often employ code obfuscations to make their malware harder
to detect. Existing tools for generating obfuscated code often require access
to the original source code (e.g., C++ or Java), and adding new obfuscations is
a non-trivial, labor-intensive process. In this study, we ask the following
question: Can Large Language Models (LLMs) potentially generate a new
obfuscated assembly code? If so, this poses a risk to anti-virus engines and
potentially increases the flexibility of attackers to create new obfuscation
patterns. We answer this in the affirmative by developing the MetamorphASM
benchmark comprising MetamorphASM Dataset (MAD) along with three code
obfuscation techniques: dead code, register substitution, and control flow
change. The MetamorphASM systematically evaluates the ability of LLMs to
generate and analyze obfuscated code using MAD, which contains 328,200
obfuscated assembly code samples. We release this dataset and analyze the
success rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,
CodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly
code. The evaluation was performed using established information-theoretic
metrics and manual human review to ensure correctness and provide the
foundation for researchers to study and develop remediations to this risk.",2024-12-20,"Seyedreza Mohseni, Seyedali Mohammadi, Deepa Tilwani, Yash Saxena, Gerald Ketu Ndawula, Sriram Vema, Edward Raff, Manas Gaur",http://arxiv.org/pdf/2412.16135v3,cs.CL
PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics,"Evaluating the quality of machine-generated natural language content is a
challenging task in Natural Language Processing (NLP). Recently, large language
models (LLMs) like GPT-4 have been employed for this purpose, but they are
computationally expensive due to the extensive token usage required by complex
evaluation prompts. In this paper, we propose a prompt optimization approach
that uses a smaller, fine-tuned language model to compress input data for
evaluation prompt, thus reducing token usage and computational cost when using
larger LLMs for downstream evaluation. Our method involves a two-stage
fine-tuning process: supervised fine-tuning followed by preference optimization
to refine the model's outputs based on human preferences. We focus on Machine
Translation (MT) evaluation and utilize the GEMBA-MQM metric as a starting
point. Our results show a $2.37\times$ reduction in token usage without any
loss in evaluation quality. This work makes state-of-the-art LLM-based metrics
like GEMBA-MQM more cost-effective and efficient, enhancing their accessibility
for broader use.",2024-12-20,"Daniil Larionov, Steffen Eger",http://arxiv.org/pdf/2412.16120v1,cs.CL
Logical Consistency of Large Language Models in Fact-checking,"In recent years, large language models (LLMs) have demonstrated significant
success in performing varied natural language tasks such as language
translation, question-answering, summarizing, fact-checking, etc. Despite LLMs'
impressive ability to generate human-like texts, LLMs are infamous for their
inconsistent responses - a meaning-preserving change in the input query results
in an inconsistent response and attributes to vulnerabilities of LLMs such as
hallucination. Consequently, existing research focuses on simple
paraphrasing-based consistency assessment of LLMs, and ignores complex queries
that necessitate an even better understanding of logical reasoning by an LLM.
Our work therefore addresses the logical inconsistency of LLMs under complex
logical queries with primitive logical operators, e.g., negation, conjunction,
and disjunction. As a test bed, we consider retrieval-augmented LLMs on a
fact-checking task involving propositional logic queries from knowledge graphs
(KGs). Our contributions are threefold. Benchmark: We introduce three logical
fact-checking datasets over KGs for community development towards logically
consistent LLMs. Assessment: We propose consistency measures of LLMs on
propositional logic queries and demonstrate that existing LLMs lack logical
consistency, especially on complex queries. Improvement: We employ supervised
fine-tuning to improve the logical consistency of LLMs on the complex
fact-checking task with KG contexts. We have made our source code and
benchmarks available.",2024-12-20,"Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan",http://arxiv.org/pdf/2412.16100v2,cs.CL
Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG,"Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings. Our code is available at
https://github.com/tifat58/IRR-with-CBM-RAG.git.",2024-12-20,"Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag",http://arxiv.org/pdf/2412.16086v2,cs.CL
The Only Way is Ethics: A Guide to Ethical Research with Large Language Models,"There is a significant body of work looking at the ethical considerations of
large language models (LLMs): critiquing tools to measure performance and
harms; proposing toolkits to aid in ideation; discussing the risks to workers;
considering legislation around privacy and security etc. As yet there is no
work that integrates these resources into a single practical guide that focuses
on LLMs; we attempt this ambitious goal. We introduce 'LLM Ethics Whitepaper',
which we provide as an open and living resource for NLP practitioners, and
those tasked with evaluating the ethical implications of others' work. Our goal
is to translate ethics literature into concrete recommendations and
provocations for thinking with clear first steps, aimed at computer scientists.
'LLM Ethics Whitepaper' distils a thorough literature review into clear Do's
and Don'ts, which we present also in this paper. We likewise identify useful
toolkits to support ethical work. We refer the interested reader to the full
LLM Ethics Whitepaper, which provides a succinct discussion of ethical
considerations at each stage in a project lifecycle, as well as citations for
the hundreds of papers from which we drew our recommendations. The present
paper can be thought of as a pocket guide to conducting ethical research with
LLMs.",2024-12-20,"Eddie L. Ungless, Nikolas Vitsakis, Zeerak Talat, James Garforth, Björn Ross, Arno Onken, Atoosa Kasirzadeh, Alexandra Birch",http://arxiv.org/pdf/2412.16022v1,cs.CL
Data-Centric Improvements for Enhancing Multi-Modal Understanding in Spoken Conversation Modeling,"Conversational assistants are increasingly popular across diverse real-world
applications, highlighting the need for advanced multimodal speech modeling.
Speech, as a natural mode of communication, encodes rich user-specific
characteristics such as speaking rate and pitch, making it critical for
effective interaction. Our work introduces a data-centric customization
approach for efficiently enhancing multimodal understanding in conversational
speech modeling. Central to our contributions is a novel multi-task learning
paradigm that involves designing auxiliary tasks to utilize a small amount of
speech data. Our approach achieves state-of-the-art performance on the
Spoken-SQuAD benchmark, using only 10% of the training data with open-weight
models, establishing a robust and efficient framework for audio-centric
conversational modeling. We also introduce ASK-QA, the first dataset for
multi-turn spoken dialogue with ambiguous user requests and dynamic evaluation
inputs. Code and data forthcoming.",2024-12-20,"Maximillian Chen, Ruoxi Sun, Sercan Ö. Arık",http://arxiv.org/pdf/2412.15995v1,cs.CL
Fearful Falcons and Angry Llamas: Emotion Category Annotations of Arguments by Humans and LLMs,"Arguments evoke emotions, influencing the effect of the argument itself. Not
only the emotional intensity but also the category influence the argument's
effects, for instance, the willingness to adapt stances. While binary
emotionality has been studied in arguments, there is no work on discrete
emotion categories (e.g., ""Anger"") in such data. To fill this gap, we
crowdsource subjective annotations of emotion categories in a German argument
corpus and evaluate automatic LLM-based labeling methods. Specifically, we
compare three prompting strategies (zero-shot, one-shot, chain-of-thought) on
three large instruction-tuned language models (Falcon-7b-instruct,
Llama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of the
output space to be binary (is there emotionality in the argument?),
closed-domain (which emotion from a given label set is in the argument?), or
open-domain (which emotion is in the argument?). We find that emotion
categories enhance the prediction of emotionality in arguments, emphasizing the
need for discrete emotion annotations in arguments. Across all prompt settings
and models, automatic predictions show a high recall but low precision for
predicting anger and fear, indicating a strong bias toward negative emotions.",2024-12-20,"Lynn Greschner, Roman Klinger",http://arxiv.org/pdf/2412.15993v2,cs.CL
BabyHGRN: Exploring RNNs for Sample-Efficient Training of Language Models,"This paper explores the potential of recurrent neural networks (RNNs) and
other subquadratic architectures as competitive alternatives to
transformer-based models in low-resource language modeling scenarios. We
utilize HGRN2 (Qin et al., 2024), a recently proposed RNN-based architecture,
and comparatively evaluate its effectiveness against transformer-based
baselines and other subquadratic architectures (LSTM, xLSTM, Mamba). Our
experimental results show that BABYHGRN, our HGRN2 language model, outperforms
transformer-based models in both the 10M and 100M word tracks of the challenge,
as measured by their performance on the BLiMP, EWoK, GLUE and BEAR benchmarks.
Further, we show the positive impact of knowledge distillation. Our findings
challenge the prevailing focus on transformer architectures and indicate the
viability of RNN-based models, particularly in resource-constrained
environments.",2024-12-20,"Patrick Haller, Jonas Golde, Alan Akbik",http://arxiv.org/pdf/2412.15978v1,cs.CL
From General to Specific: Tailoring Large Language Models for Personalized Healthcare,"The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.",2024-12-20,"Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao",http://arxiv.org/pdf/2412.15957v1,cs.CL
Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model,"Background: Recent advances in large language models highlight the need for
high-quality multilingual medical datasets. While Japan leads globally in CT
scanner deployment and utilization, the lack of large-scale Japanese radiology
datasets has hindered the development of specialized language models for
medical imaging analysis. Objective: To develop a comprehensive Japanese CT
report dataset through machine translation and establish a specialized language
model for structured finding classification. Additionally, to create a
rigorously validated evaluation dataset through expert radiologist review.
Methods: We translated the CT-RATE dataset (24,283 CT reports from 21,304
patients) into Japanese using GPT-4o mini. The training dataset consisted of
22,778 machine-translated reports, while the validation dataset included 150
radiologist-revised reports. We developed CT-BERT-JPN based on
""tohoku-nlp/bert-base-japanese-v3"" architecture for extracting 18 structured
findings from Japanese radiology reports. Results: Translation metrics showed
strong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores
ranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression
sections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in
11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular
septal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1
scores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in
four conditions. Conclusions: Our study establishes a robust Japanese CT report
dataset and demonstrates the effectiveness of a specialized language model for
structured finding classification. The hybrid approach of machine translation
and expert validation enables the creation of large-scale medical datasets
while maintaining high quality.",2024-12-20,"Yosuke Yamagishi, Yuta Nakamura, Tomohiro Kikuchi, Yuki Sonoda, Hiroshi Hirakawa, Shintaro Kano, Satoshi Nakamura, Shouhei Hanaoka, Takeharu Yoshikawa, Osamu Abe",http://arxiv.org/pdf/2412.15907v1,cs.CL
On the Suitability of pre-trained foundational LLMs for Analysis in German Legal Education,"We show that current open-source foundational LLMs possess instruction
capability and German legal background knowledge that is sufficient for some
legal analysis in an educational context. However, model capability breaks down
in very specific tasks, such as the classification of ""Gutachtenstil"" appraisal
style components, or with complex contexts, such as complete legal opinions.
Even with extended context and effective prompting strategies, they cannot
match the Bag-of-Words baseline. To combat this, we introduce a Retrieval
Augmented Generation based prompt example selection method that substantially
improves predictions in high data availability scenarios. We further evaluate
the performance of pre-trained LLMs on two standard tasks for argument mining
and automated essay scoring and find it to be more adequate. Throughout,
pre-trained LLMs improve upon the baseline in scenarios with little or no
labeled data with Chain-of-Thought prompting further helping in the zero-shot
case.",2024-12-20,"Lorenz Wendlinger, Christian Braun, Abdullah Al Zubaer, Simon Alexander Nonn, Sarah Großkopf, Christofer Fellicious, Michael Granitzer",http://arxiv.org/pdf/2412.15902v1,cs.CL
A Thorough Investigation into the Application of Deep CNN for Enhancing Natural Language Processing Capabilities,"Natural Language Processing (NLP) is widely used in fields like machine
translation and sentiment analysis. However, traditional NLP models struggle
with accuracy and efficiency. This paper introduces Deep Convolutional Neural
Networks (DCNN) into NLP to address these issues. By integrating DCNN, machine
learning (ML) algorithms, and generative adversarial networks (GAN), the study
improves language understanding, reduces ambiguity, and enhances task
performance. The high-performance NLP model shows a 10% improvement in
segmentation accuracy and a 4% increase in recall rate compared to traditional
models. This integrated approach excels in tasks such as word segmentation,
part-of-speech tagging, machine translation, and text classification, offering
better recognition accuracy and processing efficiency.",2024-12-20,"Chang Weng, Scott Rood, Mehdi Ali Ramezani, Amir Aslani, Reza Zarrab, Wang Zwuo, Sanjeev Salimans, Tim Satheesh",http://arxiv.org/pdf/2412.15900v1,cs.CL
"TelcoLM: collecting data, adapting, and benchmarking language models for the telecommunication domain","Despite outstanding processes in many tasks, Large Language Models (LLMs)
still lack accuracy when dealing with highly technical domains. Especially,
telecommunications (telco) is a particularly challenging domain due the large
amount of lexical, semantic and conceptual peculiarities. Yet, this domain
holds many valuable use cases, directly linked to industrial needs. Hence, this
paper studies how LLMs can be adapted to the telco domain. It reports our
effort to (i) collect a massive corpus of domain-specific data (800M tokens,
80K instructions), (ii) perform adaptation using various methodologies, and
(iii) benchmark them against larger generalist models in downstream tasks that
require extensive knowledge of telecommunications. Our experiments on
Llama-2-7b show that domain-adapted models can challenge the large generalist
models. They also suggest that adaptation can be restricted to a unique
instruction-tuning step, dicarding the need for any fine-tuning on raw texts
beforehand.",2024-12-20,"Camille Barboule, Viet-Phi Huynh, Adrien Bufort, Yoan Chabot, Géraldine Damnati, Gwénolé Lecorvé",http://arxiv.org/pdf/2412.15891v1,cs.CL
Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback,"Reinforcement learning from human feedback (RLHF) has proven effective in
enhancing the instruction-following capabilities of large language models;
however, it remains underexplored in the cross-modality domain. As the number
of modalities increases, aligning all-modality models with human intentions --
such as instruction following -- becomes a pressing challenge. In this work, we
make the first attempt to fine-tune all-modality models (i.e. input and output
with any modality, also named any-to-any models) using human preference data
across all modalities (including text, image, audio, and video), ensuring its
behavior aligns with human intentions. This endeavor presents several
challenges. First, there is no large-scale all-modality human preference data
in existing open-source resources, as most datasets are limited to specific
modalities, predominantly text and image. Secondly, the effectiveness of binary
preferences in RLHF for post-training alignment in complex all-modality
scenarios remains an unexplored area. Finally, there is a lack of a systematic
framework to evaluate the capabilities of all-modality models, particularly
regarding modality selection and synergy. To address these challenges, we
propose the align-anything framework, which includes meticulously annotated
200k all-modality human preference data. Then, we introduce an alignment method
that learns from unified language feedback, effectively capturing complex
modality-specific human preferences and enhancing the model's
instruction-following capabilities. Furthermore, to assess performance
improvements in all-modality models after post-training alignment, we construct
a challenging all-modality capability evaluation framework -- eval-anything.
All data, models, and code frameworks have been open-sourced for the community.
For more details, please refer to
https://github.com/PKU-Alignment/align-anything.",2024-12-20,"Jiaming Ji, Jiayi Zhou, Hantao Lou, Boyuan Chen, Donghai Hong, Xuyao Wang, Wenqi Chen, Kaile Wang, Rui Pan, Jiahao Li, Mohan Wang, Josef Dai, Tianyi Qiu, Hua Xu, Dong Li, Weipeng Chen, Jun Song, Bo Zheng, Yaodong Yang",http://arxiv.org/pdf/2412.15838v2,cs.CL
Enriching Social Science Research via Survey Item Linking,"Questions within surveys, called survey items, are used in the social
sciences to study latent concepts, such as the factors influencing life
satisfaction. Instead of using explicit citations, researchers paraphrase the
content of the survey items they use in-text. However, this makes it
challenging to find survey items of interest when comparing related work.
Automatically parsing and linking these implicit mentions to survey items in a
knowledge base can provide more fine-grained references. We model this task,
called Survey Item Linking (SIL), in two stages: mention detection and entity
disambiguation. Due to an imprecise definition of the task, existing datasets
used for evaluating the performance for SIL are too small and of low-quality.
We argue that latent concepts and survey item mentions should be
differentiated. To this end, we create a high-quality and richly annotated
dataset consisting of 20,454 English and German sentences. By benchmarking deep
learning systems for each of the two stages independently and sequentially, we
demonstrate that the task is feasible, but observe that errors propagate from
the first stage, leading to a lower overall task performance. Moreover,
mentions that require the context of multiple sentences are more challenging to
identify for models in the first stage. Modeling the entire context of a
document and combining the two stages into an end-to-end system could mitigate
these problems in future work, and errors could additionally be reduced by
collecting more diverse data and by improving the quality of the knowledge
base. The data and code are available at https://github.com/e-tornike/SIL .",2024-12-20,"Tornike Tsereteli, Daniel Ruffinelli, Simone Paolo Ponzetto",http://arxiv.org/pdf/2412.15831v1,cs.CL
S$^2$DN: Learning to Denoise Unconvincing Knowledge for Inductive Knowledge Graph Completion,"Inductive Knowledge Graph Completion (KGC) aims to infer missing facts
between newly emerged entities within knowledge graphs (KGs), posing a
significant challenge. While recent studies have shown promising results in
inferring such entities through knowledge subgraph reasoning, they suffer from
(i) the semantic inconsistencies of similar relations, and (ii) noisy
interactions inherent in KGs due to the presence of unconvincing knowledge for
emerging entities. To address these challenges, we propose a Semantic
Structure-aware Denoising Network (S$^2$DN) for inductive KGC. Our goal is to
learn adaptable general semantics and reliable structures to distill consistent
semantic knowledge while preserving reliable interactions within KGs.
Specifically, we introduce a semantic smoothing module over the enclosing
subgraphs to retain the universal semantic knowledge of relations. We
incorporate a structure refining module to filter out unreliable interactions
and offer additional knowledge, retaining robust structure surrounding target
links. Extensive experiments conducted on three benchmark KGs demonstrate that
S$^2$DN surpasses the performance of state-of-the-art models. These results
demonstrate the effectiveness of S$^2$DN in preserving semantic consistency and
enhancing the robustness of filtering out unreliable interactions in
contaminated KGs.",2024-12-20,"Tengfei Ma, Yujie Chen, Liang Wang, Xuan Lin, Bosheng Song, Xiangxiang Zeng",http://arxiv.org/pdf/2412.15822v1,cs.CL
$π$-yalli: un nouveau corpus pour le nahuatl,"The NAHU$^2$ project is a Franco-Mexican collaboration aimed at building the
$\pi$-YALLI corpus adapted to machine learning, which will subsequently be used
to develop computer resources for the Nahuatl language. Nahuatl is a language
with few computational resources, even though it is a living language spoken by
around 2 million people. We have decided to build $\pi$-YALLI, a corpus that
will enable to carry out research on Nahuatl in order to develop Language
Models (LM), whether dynamic or not, which will make it possible to in turn
enable the development of Natural Language Processing (NLP) tools such as: a) a
grapheme unifier, b) a word segmenter, c) a POS grammatical analyser, d) a
content-based Automatic Text Summarization; and possibly, e) a translator
translator (probabilistic or learning-based).",2024-12-20,"Juan-Manuel Torres-Moreno, Juan-José Guzmán-Landa, Graham Ranger, Martha Lorena Avendaño Garrido, Miguel Figueroa-Saavedra, Ligia Quintana-Torres, Carlos-Emiliano González-Gallardo, Elvys Linhares Pontes, Patricia Velázquez Morales, Luis-Gil Moreno Jiménez",http://arxiv.org/pdf/2412.15821v1,cs.CL
Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning,"Despite recent advances in large language models, open-source models often
struggle to consistently perform well on complex reasoning tasks. Existing
ensemble methods, whether applied at the token or output levels, fail to
address these challenges. In response, we present Language model Ensemble with
Monte Carlo Tree Search (LE-MCTS), a novel framework for process-level
ensembling of language models. LE-MCTS formulates step-by-step reasoning with
an ensemble of language models as a Markov decision process. In this framework,
states represent intermediate reasoning paths, while actions consist of
generating the next reasoning step using one of the language models selected
from a predefined pool. Guided by a process-based reward model, LE-MCTS
performs a tree search over the reasoning steps generated by different language
models, identifying the most accurate reasoning chain. Experimental results on
five mathematical reasoning benchmarks demonstrate that our approach
outperforms both single language model decoding algorithms and language model
ensemble methods. Notably, LE-MCTS improves performance by 3.6% and 4.3% on the
MATH and MQA datasets, respectively, highlighting its effectiveness in solving
complex reasoning problems.",2024-12-20,"Sungjin Park, Xiao Liu, Yeyun Gong, Edward Choi",http://arxiv.org/pdf/2412.15797v1,cs.CL
Learning from Impairment: Leveraging Insights from Clinical Linguistics in Language Modelling Research,"This position paper investigates the potential of integrating insights from
language impairment research and its clinical treatment to develop
human-inspired learning strategies and evaluation frameworks for language
models (LMs). We inspect the theoretical underpinnings underlying some
influential linguistically motivated training approaches derived from
neurolinguistics and, particularly, aphasiology, aimed at enhancing the
recovery and generalization of linguistic skills in aphasia treatment, with a
primary focus on those targeting the syntactic domain. We highlight how these
insights can inform the design of rigorous assessments for LMs, specifically in
their handling of complex syntactic phenomena, as well as their implications
for developing human-like learning strategies, aligning with efforts to create
more sustainable and cognitively plausible natural language processing (NLP)
models.",2024-12-20,Dominique Brunato,http://arxiv.org/pdf/2412.15785v1,cs.CL
Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech,"Alzheimer's Disease (AD) is a significant and growing public health concern.
Investigating alterations in speech and language patterns offers a promising
path towards cost-effective and non-invasive early detection of AD on a large
scale. Large language models (LLMs), such as GPT, have enabled powerful new
possibilities for semantic text analysis. In this study, we leverage GPT-4 to
extract five semantic features from transcripts of spontaneous patient speech.
The features capture known symptoms of AD, but they are difficult to quantify
effectively using traditional methods of computational linguistics. We
demonstrate the clinical significance of these features and further validate
one of them (""Word-Finding Difficulties"") against a proxy measure and human
raters. When combined with established linguistic features and a Random Forest
classifier, the GPT-derived features significantly improve the detection of AD.
Our approach proves effective for both manually transcribed and automatically
generated transcripts, representing a novel and impactful use of recent
advancements in LLMs for AD speech analysis.",2024-12-20,"Jonathan Heitz, Gerold Schneider, Nicolas Langer",http://arxiv.org/pdf/2412.15772v1,cs.CL
Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models,"Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole",2024-12-20,"Shamus Sim, Tyrone Chen",http://arxiv.org/pdf/2412.15748v1,cs.CL
Fine-tuning Whisper on Low-Resource Languages for Real-World Applications,"This paper presents a new approach to fine-tuning OpenAI's Whisper model for
low-resource languages by introducing a novel data generation method that
converts sentence-level data into a long-form corpus, using Swiss German as a
case study. Non-sentence-level data, which could improve the performance of
long-form audio, is difficult to obtain and often restricted by copyright laws.
Our method bridges this gap by transforming more accessible sentence-level data
into a format that preserves the model's ability to handle long-form audio and
perform segmentation without requiring non-sentence-level data. Our data
generation process improves performance in several real-world applications and
leads to the development of a new state-of-the-art speech-to-text (STT) model
for Swiss German. We compare our model with a non-fine-tuned Whisper and our
previous state-of-the-art Swiss German STT models, where our new model achieves
higher BLEU scores. Our results also indicate that the proposed method is
adaptable to other low-resource languages, supported by written guidance and
code that allows the creation of fine-tuned Whisper models, which keep
segmentation capabilities and allow the transcription of longer audio files
using only sentence-level data with high quality.",2024-12-20,"Vincenzo Timmel, Claudio Paonessa, Reza Kakooee, Manfred Vogel, Daniel Perruchoud",http://arxiv.org/pdf/2412.15726v3,cs.CL
AutoLife: Automatic Life Journaling with Smartphones and LLMs,"This paper introduces a novel mobile sensing application - life journaling -
designed to generate semantic descriptions of users' daily lives. We present
AutoLife, an automatic life journaling system based on commercial smartphones.
AutoLife only inputs low-cost sensor data (without photos or audio) from
smartphones and can automatically generate comprehensive life journals for
users. To achieve this, we first derive time, motion, and location contexts
from multimodal sensor data, and harness the zero-shot capabilities of Large
Language Models (LLMs), enriched with commonsense knowledge about human lives,
to interpret diverse contexts and generate life journals. To manage the task
complexity and long sensing duration, a multilayer framework is proposed, which
decomposes tasks and seamlessly integrates LLMs with other techniques for life
journaling. This study establishes a real-life dataset as a benchmark and
extensive experiment results demonstrate that AutoLife produces accurate and
reliable life journals.",2024-12-20,"Huatao Xu, Panrong Tong, Mo Li, Mani Srivastava",http://arxiv.org/pdf/2412.15714v2,cs.CL
Contrastive Learning for Task-Independent SpeechLLM-Pretraining,"Large language models (LLMs) excel in natural language processing but
adapting these LLMs to speech processing tasks efficiently is not
straightforward. Direct task-specific fine-tuning is limited by overfitting
risks, data requirements, and computational costs. To address these challenges,
we propose a scalable, two-stage training approach: (1) A task-independent
speech pretraining stage using contrastive learning to align text and speech
representations over all layers, followed by (2) a task-specific fine-tuning
stage requiring minimal data. This approach outperforms traditional ASR
pretraining and enables the model to surpass models specialized on speech
translation and question answering while being trained on only 10% of the
task-specific data.",2024-12-20,"Maike Züfle, Jan Niehues",http://arxiv.org/pdf/2412.15712v1,cs.CL
Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration,"Recent advancements in language models (LMs) have sparked growing interest in
developing LM agents. While fully autonomous agents could excel in many
scenarios, numerous use cases inherently require them to collaborate with
humans due to humans' latent preferences, domain expertise, or need for
control. To facilitate the study of human-agent collaboration, we present
Collaborative Gym (Co-Gym), a general framework enabling asynchronous,
tripartite interaction among agents, humans, and task environments. We
instantiate Co-Gym with three representative tasks in both simulated and
real-world conditions, and propose an evaluation framework that assesses both
the collaboration outcomes and processes. Our findings reveal that
collaborative agents consistently outperform their fully autonomous
counterparts in task performance within those delivered cases, achieving win
rates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related
Work when evaluated by real users. However, our study also highlights
significant challenges in developing collaborative agents, requiring
advancements in core aspects of intelligence -- communication capabilities,
situational awareness, and balancing autonomy and human control.",2024-12-20,"Yijia Shao, Vinay Samuel, Yucheng Jiang, John Yang, Diyi Yang",http://arxiv.org/pdf/2412.15701v2,cs.CL
Variability Need Not Imply Error: The Case of Adequate but Semantically Distinct Responses,"With the broader use of language models (LMs) comes the need to estimate
their ability to respond reliably to prompts (e.g., are generated responses
likely to be correct?). Uncertainty quantification tools (notions of confidence
and entropy, i.a.) can be used to that end (e.g., to reject a response when the
model is `uncertain'). For example, Kuhn et al. (semantic entropy; 2022b)
regard semantic variation amongst sampled responses as evidence that the model
`struggles' with the prompt and that the LM is likely to err. We argue that
semantic variability need not imply error--this being especially intuitive in
open-ended settings, where prompts elicit multiple adequate but semantically
distinct responses. Hence, we propose to annotate sampled responses for their
adequacy to the prompt (e.g., using a classifier) and estimate the Probability
the model assigns to Adequate Responses (PROBAR), which we then regard as an
indicator of the model's reliability at the instance level. We evaluate PROBAR
as a measure of confidence in selective prediction with OPT models (in two QA
datasets and in next-word prediction, for English) and find PROBAR to
outperform semantic entropy across prompts with varying degrees of
ambiguity/open-endedness.",2024-12-20,"Evgenia Ilia, Wilker Aziz",http://arxiv.org/pdf/2412.15683v1,cs.CL
Inference Scaling vs Reasoning: An Empirical Analysis of Compute-Optimal LLM Problem-Solving,"Recent advances in large language models (LLMs) have predominantly focused on
maximizing accuracy and reasoning capabilities, often overlooking crucial
computational efficiency considerations. While this approach has yielded
impressive accuracy improvements, it has led to methods that may be impractical
for real-world deployment due to computational overhead and latency
constraints. This paper investigates the potential synergy between reasoning
enhancement and computational efficiency by analyzing the integration of two
contrasting approaches: Quiet-STaR (Self-Taught Reasoner) and REBASE (REward
BAlanced SEarch). Through comprehensive empirical analysis using the Mistral-7B
model on the GSM8K dataset, we demonstrate that while each method excels in its
primary objective-Quiet-STaR achieving superior accuracy (32.03%) despite high
computational cost (554.66s runtime, 12.73T FLOPs), and REBASE providing
exceptional efficiency (8.47s runtime, 2.35T FLOPs) while maintaining
baseline-comparable accuracy (10.94%)-their integration reveals fundamental
challenges in reconciling reasoning depth with computational efficiency. The
combined approach unexpectedly results in degraded performance (9.38% accuracy,
143.66s runtime), highlighting critical insights about the complex interplay
between reasoning enhancement and efficiency optimization in LLMs. Our findings
illuminate the need for novel architectures and algorithms specifically
designed to bridge the gap between these competing objectives, while providing
concrete directions for future research in compute-efficient reasoning methods.",2024-12-20,"Marwan AbdElhameed, Pavly Halim",http://arxiv.org/pdf/2412.16260v1,cs.CL
Adaptable and Precise: Enterprise-Scenario LLM Function-Calling Capability Training Pipeline,"Enterprises possess a vast array of API assets scattered across various
functions, forming the backbone of existing business processes. By leveraging
these APIs as functional tools, enterprises can design diverse,
scenario-specific agent applications, driven by on-premise function-calling
models as the core engine. However, generic models often fail to meet
enterprise requirements in terms of computational efficiency, output accuracy,
and stability, necessitating scenario-specific adaptation. In this paper, we
propose a training pipeline for function-calling capabilities tailored to
real-world business scenarios. This pipeline includes the synthesis and
augmentation of scenario-specific function-calling data, model fine-tuning, and
performance evaluation and analysis. Using this pipeline, we generated 1,260
fully AI-generated samples and 1,035 augmented manually-labeled samples in
digital HR agent scenario. The Qwen2.5-Coder-7B-Instruct model was employed as
the base model and fine-tuned using the LoRA method on four GPUs with 24GB
VRAM. Our fine-tuned model demonstrated outstanding performance in evaluations
and practical applications, surpassing GPT-4 and GPT-4o in accuracy on the test
set. These results validate the reliability of the proposed pipeline for
training scenario-specific function-calling models.",2024-12-20,"Guancheng Zeng, Wentao Ding, Beining Xu, Chi Zhang, Wenqiang Han, Gang Li, Jingjing Mo, Pengxu Qiu, Xinran Tao, Wang Tao, Haowen Hu",http://arxiv.org/pdf/2412.15660v1,cs.CL
MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula,"In various academic and professional settings, such as mathematics lectures
or research presentations, it is often necessary to convey mathematical
expressions orally. However, reading mathematical expressions aloud without
accompanying visuals can significantly hinder comprehension, especially for
those who are hearing-impaired or rely on subtitles due to language barriers.
For instance, when a presenter reads Euler's Formula, current Automatic Speech
Recognition (ASR) models often produce a verbose and error-prone textual
description (e.g., e to the power of i x equals cosine of x plus i
$\textit{side}$ of x), instead of the concise $\LaTeX{}$ format (i.e., $ e^{ix}
= \cos(x) + i\sin(x) $), which hampers clear understanding and communication.
To address this issue, we introduce MathSpeech, a novel pipeline that
integrates ASR models with small Language Models (sLMs) to correct errors in
mathematical expressions and accurately convert spoken expressions into
structured $\LaTeX{}$ representations. Evaluated on a new dataset derived from
lecture recordings, MathSpeech demonstrates $\LaTeX{}$ generation capabilities
comparable to leading commercial Large Language Models (LLMs), while leveraging
fine-tuned small language models of only 120M parameters. Specifically, in
terms of CER, BLEU, and ROUGE scores for $\LaTeX{}$ translation, MathSpeech
demonstrated significantly superior capabilities compared to GPT-4o. We
observed a decrease in CER from 0.390 to 0.298, and higher ROUGE/BLEU scores
compared to GPT-4o.",2024-12-20,"Sieun Hyeon, Kyudan Jung, Jaehee Won, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee, Jaeyoung Do",http://arxiv.org/pdf/2412.15655v3,cs.CL
Error-driven Data-efficient Large Multimodal Model Tuning,"Large Multimodal Models (LMMs) have demonstrated impressive performance
across numerous academic benchmarks. However, fine-tuning still remains
essential to achieve satisfactory performance on downstream tasks, while the
task-specific tuning samples are usually not readily available or expensive and
time-consuming to obtain. To address this, we propose an error-driven
data-efficient tuning framework that aims to efficiently adapt generic LMMs to
newly emerging tasks without requiring any task-specific training samples. In
our approach, a generic LMM, acting as a student model, is first evaluated on a
small validation set of the target task, and then a more powerful model, acting
as a teacher model, identifies the erroneous steps within the student model's
reasoning steps and analyzes its capability gaps from fully addressing the
target task. Based on these gaps, targeted training samples are further
retrieved from existing task-agnostic datasets to tune the student model and
tailor it to the target task. We perform extensive experiments across three
different training data scales and seven tasks, demonstrating that our training
paradigm significantly and efficiently improves LMM's performance on downstream
tasks, achieving an average performance boost of 7.01%.",2024-12-20,"Barry Menglong Yao, Qifan Wang, Lifu Huang",http://arxiv.org/pdf/2412.15652v1,cs.CL
Level-Navi Agent: A Framework and benchmark for Chinese Web Search Agents,"Large language models (LLMs), adopted to understand human language, drive the
development of artificial intelligence (AI) web search agents. Compared to
traditional search engines, LLM-powered AI search agents are capable of
understanding and responding to complex queries with greater depth, enabling
more accurate operations and better context recognition. However, little
attention and effort has been paid to the Chinese web search, which results in
that the capabilities of open-source models have not been uniformly and fairly
evaluated. The difficulty lies in lacking three aspects: an unified agent
framework, an accurately labeled dataset, and a suitable evaluation metric. To
address these issues, we propose a general-purpose and training-free web search
agent by level-aware navigation, Level-Navi Agent, accompanied by a
well-annotated dataset (Web24) and a suitable evaluation metric. Level-Navi
Agent can think through complex user questions and conduct searches across
various levels on the internet to gather information for questions. Meanwhile,
we provide a comprehensive evaluation of state-of-the-art LLMs under fair
settings. To further facilitate future research, source code is available at
Github.",2024-12-20,"Chuanrui Hu, Shichong Xie, Baoxin Wang, Bin Chen, Xiaofeng Cong, Jun Zhang",http://arxiv.org/pdf/2502.15690v1,cs.CL
Can Input Attributions Interpret the Inductive Reasoning Process in In-Context Learning?,"Interpreting the internal process of neural models has long been a challenge.
This challenge remains relevant in the era of large language models (LLMs) and
in-context learning (ICL); for example, ICL poses a new issue of interpreting
which example in the few-shot examples contributed to identifying/solving the
task. To this end, in this paper, we design synthetic diagnostic tasks of
inductive reasoning, inspired by the generalization tests in linguistics; here,
most in-context examples are ambiguous w.r.t. their underlying rule, and one
critical example disambiguates the task demonstrated. The question is whether
conventional input attribution (IA) methods can track such a reasoning process,
i.e., identify the influential example, in ICL. Our experiments provide several
practical findings; for example, a certain simple IA method works the best, and
the larger the model, the generally harder it is to interpret the ICL with
gradient-based IA methods.",2024-12-20,"Mengyu Ye, Tatsuki Kuribayashi, Goro Kobayashi, Jun Suzuki",http://arxiv.org/pdf/2412.15628v3,cs.CL
TouchASP: Elastic Automatic Speech Perception that Everyone Can Touch,"Large Automatic Speech Recognition (ASR) models demand a vast number of
parameters, copious amounts of data, and significant computational resources
during the training process. However, such models can merely be deployed on
high-compute cloud platforms and are only capable of performing speech
recognition tasks. This leads to high costs and restricted capabilities. In
this report, we initially propose the elastic mixture of the expert (eMoE)
model. This model can be trained just once and then be elastically scaled in
accordance with deployment requirements. Secondly, we devise an unsupervised
data creation and validation procedure and gather millions of hours of audio
data from diverse domains for training. Using these two techniques, our system
achieves elastic deployment capabilities while reducing the Character Error
Rate (CER) on the SpeechIO testsets from 4.98\% to 2.45\%. Thirdly, our model
is not only competent in Mandarin speech recognition but also proficient in
multilingual, multi-dialect, emotion, gender, and sound event perception. We
refer to this as Automatic Speech Perception (ASP), and the perception results
are presented in the experimental section.",2024-12-20,"Xingchen Song, Chengdong Liang, Binbin Zhang, Pengshen Zhang, ZiYu Wang, Youcheng Ma, Menglong Xu, Lin Wang, Di Wu, Fuping Pan, Dinghao Zhou, Zhendong Peng",http://arxiv.org/pdf/2412.15622v1,cs.CL
A Fusion Approach of Dependency Syntax and Sentiment Polarity for Feature Label Extraction in Commodity Reviews,"This study analyzes 13,218 product reviews from JD.com, covering four
categories: mobile phones, computers, cosmetics, and food. A novel method for
feature label extraction is proposed by integrating dependency parsing and
sentiment polarity analysis. The proposed method addresses the challenges of
low robustness in existing extraction algorithms and significantly enhances
extraction accuracy. Experimental results show that the method achieves an
accuracy of 0.7, with recall and F-score both stabilizing at 0.8, demonstrating
its effectiveness. However, challenges such as dependence on matching
dictionaries and the limited scope of extracted feature tags require further
investigation in future research.",2024-12-20,Jianfei Xu,http://arxiv.org/pdf/2412.15610v1,cs.CL
Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks,"Retrieval-augmented generation (RAG) has gained traction as a powerful
approach for enhancing language models by integrating external knowledge
sources. However, RAG introduces challenges such as retrieval latency,
potential errors in document selection, and increased system complexity. With
the advent of large language models (LLMs) featuring significantly extended
context windows, this paper proposes an alternative paradigm, cache-augmented
generation (CAG) that bypasses real-time retrieval. Our method involves
preloading all relevant resources, especially when the documents or knowledge
for retrieval are of a limited and manageable size, into the LLM's extended
context and caching its runtime parameters. During inference, the model
utilizes these preloaded parameters to answer queries without additional
retrieval steps. Comparative analyses reveal that CAG eliminates retrieval
latency and minimizes retrieval errors while maintaining context relevance.
Performance evaluations across multiple benchmarks highlight scenarios where
long-context LLMs either outperform or complement traditional RAG pipelines.
These findings suggest that, for certain applications, particularly those with
a constrained knowledge base, CAG provide a streamlined and efficient
alternative to RAG, achieving comparable or superior results with reduced
complexity.",2024-12-20,"Brian J Chan, Chao-Ting Chen, Jui-Hung Cheng, Hen-Hsen Huang",http://arxiv.org/pdf/2412.15605v2,cs.CL
Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification,"Dialogue intent classification aims to identify the underlying purpose or
intent of a user's input in a conversation. Current intent classification
systems encounter considerable challenges, primarily due to the vast number of
possible intents and the significant semantic overlap among similar intent
classes. In this paper, we propose a novel approach to few-shot dialogue intent
classification through in-context learning, incorporating dynamic label
refinement to address these challenges. Our method retrieves relevant examples
for a test input from the training set and leverages a large language model to
dynamically refine intent labels based on semantic understanding, ensuring that
intents are clearly distinguishable from one another. Experimental results
demonstrate that our approach effectively resolves confusion between
semantically similar intents, resulting in significantly enhanced performance
across multiple datasets compared to baselines. We also show that our method
generates more interpretable intent labels, and has a better semantic coherence
in capturing underlying user intents compared to baselines.",2024-12-20,"Gyutae Park, Ingeol Baek, ByeongJeong Kim, Joongbo Shin, Hwanhee Lee",http://arxiv.org/pdf/2412.15603v1,cs.CL
Template-Driven LLM-Paraphrased Framework for Tabular Math Word Problem Generation,"Solving tabular math word problems (TMWPs) has become a critical role in
evaluating the mathematical reasoning ability of large language models (LLMs),
where large-scale TMWP samples are commonly required for LLM fine-tuning. Since
the collection of high-quality TMWP datasets is costly and time-consuming,
recent research has concentrated on automatic TMWP generation. However, current
generated samples usually suffer from issues of either correctness or
diversity. In this paper, we propose a Template-driven LLM-paraphrased (TeLL)
framework for generating high-quality TMWP samples with diverse backgrounds and
accurate tables, questions, answers, and solutions. To this end, we first
extract templates from existing real samples to generate initial problems,
ensuring correctness. Then, we adopt an LLM to extend templates and paraphrase
problems, obtaining diverse TMWP samples. Furthermore, we find the reasoning
annotation is important for solving TMWPs. Therefore, we propose to enrich each
solution with illustrative reasoning steps. Through the proposed framework, we
construct a high-quality dataset TabMWP-TeLL by adhering to the question types
in the TabMWP dataset, and we conduct extensive experiments on a variety of
LLMs to demonstrate the effectiveness of TabMWP-TeLL in improving TMWP solving
performance. The code and data of this paper are available at:
https://github.com/Jason8Kang/TELL.",2024-12-20,"Xiaoqiang Kang, Zimu Wang, Xiaobo Jin, Wei Wang, Kaizhu Huang, Qiufeng Wang",http://arxiv.org/pdf/2412.15594v1,cs.CL
KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis Integrating IDHEAS and Large Language Models,"Human reliability analysis (HRA) is crucial for evaluating and improving the
safety of complex systems. Recent efforts have focused on estimating human
error probability (HEP), but existing methods often rely heavily on expert
knowledge,which can be subjective and time-consuming. Inspired by the success
of large language models (LLMs) in natural language processing, this paper
introduces a novel two-stage framework for knowledge-driven reliability
analysis, integrating IDHEAS and LLMs (KRAIL). This innovative framework
enables the semi-automated computation of base HEP values. Additionally,
knowledge graphs are utilized as a form of retrieval-augmented generation (RAG)
for enhancing the framework' s capability to retrieve and process relevant data
efficiently. Experiments are systematically conducted and evaluated on
authoritative datasets of human reliability. The experimental results of the
proposed methodology demonstrate its superior performance on base HEP
estimation under partial information for reliability assessment.",2024-12-20,"Xingyu Xiao, Peng Chen, Ben Qi, Hongru Zhao, Jingang Liang, Jiejuan Tong, Haitao Wang",http://arxiv.org/pdf/2412.18627v1,cs.CL
NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization,"Compositional generalization is crucial for artificial intelligence agents to
solve complex vision-language reasoning tasks. Neuro-symbolic approaches have
demonstrated promise in capturing compositional structures, but they face
critical challenges: (a) reliance on predefined predicates for symbolic
representations that limit adaptability, (b) difficulty in extracting
predicates from raw data, and (c) using non-differentiable operations for
combining primitive concepts. To address these issues, we propose NeSyCoCo, a
neuro-symbolic framework that leverages large language models (LLMs) to
generate symbolic representations and map them to differentiable neural
computations. NeSyCoCo introduces three innovations: (a) augmenting natural
language inputs with dependency structures to enhance the alignment with
symbolic representations, (b) employing distributed word representations to
link diverse, linguistically motivated logical predicates to neural modules,
and (c) using the soft composition of normalized predicate scores to align
symbolic and differentiable reasoning. Our framework achieves state-of-the-art
results on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks
and demonstrates robust performance with novel concepts in the CLEVR-SYN
benchmark.",2024-12-20,"Danial Kamali, Elham J. Barezi, Parisa Kordjamshidi",http://arxiv.org/pdf/2412.15588v1,cs.CL
Adversarial Robustness through Dynamic Ensemble Learning,"Adversarial attacks pose a significant threat to the reliability of
pre-trained language models (PLMs) such as GPT, BERT, RoBERTa, and T5. This
paper presents Adversarial Robustness through Dynamic Ensemble Learning
(ARDEL), a novel scheme designed to enhance the robustness of PLMs against such
attacks. ARDEL leverages the diversity of multiple PLMs and dynamically adjusts
the ensemble configuration based on input characteristics and detected
adversarial patterns. Key components of ARDEL include a meta-model for dynamic
weighting, an adversarial pattern detection module, and adversarial training
with regularization techniques. Comprehensive evaluations using standardized
datasets and various adversarial attack scenarios demonstrate that ARDEL
significantly improves robustness compared to existing methods. By dynamically
reconfiguring the ensemble to prioritize the most robust models for each input,
ARDEL effectively reduces attack success rates and maintains higher accuracy
under adversarial conditions. This work contributes to the broader goal of
developing more secure and trustworthy AI systems for real-world NLP
applications, offering a practical and scalable solution to enhance adversarial
resilience in PLMs.",2024-12-20,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",http://arxiv.org/pdf/2412.16254v1,cs.CL
Continual Learning Using a Kernel-Based Method Over Foundation Models,"Continual learning (CL) learns a sequence of tasks incrementally. This paper
studies the challenging CL setting of class-incremental learning (CIL). CIL has
two key challenges: catastrophic forgetting (CF) and inter-task class
separation (ICS). Despite numerous proposed methods, these issues remain
persistent obstacles. This paper proposes a novel CIL method, called Kernel
Linear Discriminant Analysis (KLDA), that can effectively avoid CF and ICS
problems. It leverages only the powerful features learned in a foundation model
(FM). However, directly using these features proves suboptimal. To address
this, KLDA incorporates the Radial Basis Function (RBF) kernel and its Random
Fourier Features (RFF) to enhance the feature representations from the FM,
leading to improved performance. When a new task arrives, KLDA computes only
the mean for each class in the task and updates a shared covariance matrix for
all learned classes based on the kernelized features. Classification is
performed using Linear Discriminant Analysis. Our empirical evaluation using
text and image classification datasets demonstrates that KLDA significantly
outperforms baselines. Remarkably, without relying on replay data, KLDA
achieves accuracy comparable to joint training of all classes, which is
considered the upper bound for CIL performance. The KLDA code is available at
https://github.com/salehmomeni/klda.",2024-12-20,"Saleh Momeni, Sahisnu Mazumder, Bing Liu",http://arxiv.org/pdf/2412.15571v1,cs.CL
In-context Continual Learning Assisted by an External Continual Learner,"Existing continual learning (CL) methods mainly rely on fine-tuning or
adapting large language models (LLMs). They still suffer from catastrophic
forgetting (CF). Little work has been done to exploit in-context learning (ICL)
to leverage the extensive knowledge within LLMs for CL without updating any
parameters. However, incrementally learning each new task in ICL necessitates
adding training examples from each class of the task to the prompt, which
hampers scalability as the prompt length increases. This issue not only leads
to excessively long prompts that exceed the input token limit of the underlying
LLM but also degrades the model's performance due to the overextended context.
To address this, we introduce InCA, a novel approach that integrates an
external continual learner (ECL) with ICL to enable scalable CL without CF. The
ECL is built incrementally to pre-select a small subset of likely classes for
each test instance. By restricting the ICL prompt to only these selected
classes, InCA prevents prompt lengths from becoming excessively long, while
maintaining high performance. Experimental results demonstrate that InCA
significantly outperforms existing CL baselines, achieving substantial
performance gains.",2024-12-20,"Saleh Momeni, Sahisnu Mazumder, Zixuan Ke, Bing Liu",http://arxiv.org/pdf/2412.15563v1,cs.CL
MORTAR: Metamorphic Multi-turn Testing for LLM-based Dialogue Systems,"With the widespread application of LLM-based dialogue systems in daily life,
quality assurance has become more important than ever. Recent research has
successfully introduced methods to identify unexpected behaviour in single-turn
scenarios. However, multi-turn dialogue testing remains underexplored, with the
Oracle problem in multi-turn testing posing a persistent challenge for dialogue
system developers and researchers. In this paper, we propose MORTAR, a
MetamORphic multi-TuRn diAlogue testing appRoach, which mitigates the test
oracle problem in the assessment of LLM-based dialogue systems. MORTAR
automates the generation of follow-up question-answer (QA) dialogue test cases
with multiple dialogue-level perturbations and metamorphic relations. MORTAR
employs a novel knowledge graph-based dialogue information model which
effectively generates perturbed dialogue test datasets and detects bugs of
multi-turn dialogue systems in a low-cost manner. The proposed approach does
not require an LLM as a judge, eliminating potential of any biases in the
evaluation step. According to the experiment results on multiple LLM-based
dialogue systems and comparisons with single-turn metamorphic testing
approaches, MORTAR explores more unique bugs in LLM-based dialogue systems,
especially for severe bugs that MORTAR detects up to four times more unique
bugs than the most effective existing metamorphic testing approach.",2024-12-20,"Guoxiang Guo, Aldeida Aleti, Neelofar Neelofar, Chakkrit Tantithamthavorn",http://arxiv.org/pdf/2412.15557v1,cs.CL
NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning,"Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.",2024-12-20,"Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye",http://arxiv.org/pdf/2412.15547v1,cs.CL
MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering,"Understanding temporal relations and answering time-sensitive questions is
crucial yet a challenging task for question-answering systems powered by large
language models (LLMs). Existing approaches either update the parametric
knowledge of LLMs with new facts, which is resource-intensive and often
impractical, or integrate LLMs with external knowledge retrieval (i.e.,
retrieval-augmented generation). However, off-the-shelf retrievers often
struggle to identify relevant documents that require intensive temporal
reasoning. To systematically study time-sensitive question answering, we
introduce the TempRAGEval benchmark, which repurposes existing datasets by
incorporating temporal perturbations and gold evidence labels. As anticipated,
all existing retrieval methods struggle with these temporal reasoning-intensive
questions. We further propose Modular Retrieval (MRAG), a trainless framework
that includes three modules: (1) Question Processing that decomposes question
into a main content and a temporal constraint; (2) Retrieval and Summarization
that retrieves evidence and uses LLMs to summarize according to the main
content; (3) Semantic-Temporal Hybrid Ranking that scores each evidence
summarization based on both semantic and temporal relevance. On TempRAGEval,
MRAG significantly outperforms baseline retrievers in retrieval performance,
leading to further improvements in final answer accuracy.",2024-12-20,"Zhang Siyue, Xue Yuxiang, Zhang Yiming, Wu Xiaobao, Luu Anh Tuan, Zhao Chen",http://arxiv.org/pdf/2412.15540v2,cs.CL
XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation,"Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent
data with the generative capabilities of Large Language Models (LLMs), ensuring
that the generated output is not only contextually relevant but also accurate
and current. We introduce XRAG, an open-source, modular codebase that
facilitates exhaustive evaluation of the performance of foundational components
of advanced RAG modules. These components are systematically categorized into
four core phases: pre-retrieval, retrieval, post-retrieval, and generation. We
systematically analyse them across reconfigured datasets, providing a
comprehensive benchmark for their effectiveness. As the complexity of RAG
systems continues to escalate, we underscore the critical need to identify
potential failure points in RAG systems. We formulate a suite of experimental
methodologies and diagnostic testing protocols to dissect the failure points
inherent in RAG engineering. Subsequently, we proffer bespoke solutions aimed
at bolstering the overall performance of these modules. Our work thoroughly
evaluates the performance of advanced core components in RAG systems, providing
insights into optimizations for prevalent failure points.",2024-12-20,"Qianren Mao, Yangyifei Luo, Qili Zhang, Yashuo Luo, Zhilong Cao, Jinlong Zhang, HanWen Hao, Zhijun Chen, Weifeng Jiang, Junnan Liu, Xiaolong Wang, Zhenting Huang, Zhixing Tan, Sun Jie, Bo Li, Xudong Liu, Richong Zhang, Jianxin Li",http://arxiv.org/pdf/2412.15529v3,cs.CL
HREF: Human Response-Guided Evaluation of Instruction Following in Language Models,"Evaluating the capability of Large Language Models (LLMs) in following
instructions has heavily relied on a powerful LLM as the judge, introducing
unresolved biases that deviate the judgments from human judges. In this work,
we reevaluate various choices for automatic evaluation on a wide range of
instruction-following tasks. We experiment with methods that leverage
human-written responses and observe that they enhance the reliability of
automatic evaluations across a wide range of tasks, resulting in up to a 3.2%
improvement in agreement with human judges. We also discovered that
human-written responses offer an orthogonal perspective to model-generated
responses in following instructions and should be used as an additional context
when comparing model responses. Based on these observations, we develop a new
evaluation benchmark, Human Response-Guided Evaluation of Instruction Following
(HREF), comprising 4,258 samples across 11 task categories with a composite
evaluation setup, employing a composite evaluation setup that selects the most
reliable method for each category. In addition to providing reliable
evaluation, HREF emphasizes individual task performance and is free from
contamination. Finally, we study the impact of key design choices in HREF,
including the size of the evaluation set, the judge model, the baseline model,
and the prompt template. We host a live leaderboard that evaluates LLMs on the
private evaluation set of HREF.",2024-12-20,"Xinxi Lyu, Yizhong Wang, Hannaneh Hajishirzi, Pradeep Dasigi",http://arxiv.org/pdf/2412.15524v2,cs.CL
ADEQA: A Question Answer based approach for joint ADE-Suspect Extraction using Sequence-To-Sequence Transformers,"Early identification of Adverse Drug Events (ADE) is critical for taking
prompt actions while introducing new drugs into the market. These ADEs
information are available through various unstructured data sources like
clinical study reports, patient health records, social media posts, etc.
Extracting ADEs and the related suspect drugs using machine learning is a
challenging task due to the complex linguistic relations between drug ADE pairs
in textual data and unavailability of large corpus of labelled datasets. This
paper introduces ADEQA, a question-answer(QA) based approach using quasi
supervised labelled data and sequence-to-sequence transformers to extract ADEs,
drug suspects and the relationships between them. Unlike traditional QA models,
natural language generation (NLG) based models don't require extensive token
level labelling and thereby reduces the adoption barrier significantly. On a
public ADE corpus, we were able to achieve state-of-the-art results with an F1
score of 94% on establishing the relationships between ADEs and the respective
suspects.",2024-12-20,"Vinayak Arannil, Tomal Deb, Atanu Roy",http://arxiv.org/pdf/2412.15510v1,cs.CL
Mitigating Social Bias in Large Language Models: A Multi-Objective Approach within a Multi-Agent Framework,"Natural language processing (NLP) has seen remarkable advancements with the
development of large language models (LLMs). Despite these advancements, LLMs
often produce socially biased outputs. Recent studies have mainly addressed
this problem by prompting LLMs to behave ethically, but this approach results
in unacceptable performance degradation. In this paper, we propose a
multi-objective approach within a multi-agent framework (MOMA) to mitigate
social bias in LLMs without significantly compromising their performance. The
key idea of MOMA involves deploying multiple agents to perform causal
interventions on bias-related contents of the input questions, breaking the
shortcut connection between these contents and the corresponding answers.
Unlike traditional debiasing techniques leading to performance degradation,
MOMA substantially reduces bias while maintaining accuracy in downstream tasks.
Our experiments conducted on two datasets and two models demonstrate that MOMA
reduces bias scores by up to 87.7%, with only a marginal performance
degradation of up to 6.8% in the BBQ dataset. Additionally, it significantly
enhances the multi-objective metric icat in the StereoSet dataset by up to
58.1%. Code will be made available at https://github.com/Cortantse/MOMA.",2024-12-20,"Zhenjie Xu, Wenqing Chen, Yi Tang, Xuanying Li, Cheng Hu, Zhixuan Chu, Kui Ren, Zibin Zheng, Zhichao Lu",http://arxiv.org/pdf/2412.15504v2,cs.CL
Humanlike Cognitive Patterns as Emergent Phenomena in Large Language Models,"Research on emergent patterns in Large Language Models (LLMs) has gained
significant traction in both psychology and artificial intelligence, motivating
the need for a comprehensive review that offers a synthesis of this complex
landscape. In this article, we systematically review LLMs' capabilities across
three important cognitive domains: decision-making biases, reasoning, and
creativity. We use empirical studies drawing on established psychological tests
and compare LLMs' performance to human benchmarks. On decision-making, our
synthesis reveals that while LLMs demonstrate several human-like biases, some
biases observed in humans are absent, indicating cognitive patterns that only
partially align with human decision-making. On reasoning, advanced LLMs like
GPT-4 exhibit deliberative reasoning akin to human System-2 thinking, while
smaller models fall short of human-level performance. A distinct dichotomy
emerges in creativity: while LLMs excel in language-based creative tasks, such
as storytelling, they struggle with divergent thinking tasks that require
real-world context. Nonetheless, studies suggest that LLMs hold considerable
potential as collaborators, augmenting creativity in human-machine
problem-solving settings. Discussing key limitations, we also offer guidance
for future research in areas such as memory, attention, and open-source model
development.",2024-12-20,"Zhisheng Tang, Mayank Kejriwal",http://arxiv.org/pdf/2412.15501v1,cs.CL
The First Multilingual Model For The Detection of Suicide Texts,"Suicidal ideation is a serious health problem affecting millions of people
worldwide. Social networks provide information about these mental health
problems through users' emotional expressions. We propose a multilingual model
leveraging transformer architectures like mBERT, XML-R, and mT5 to detect
suicidal text across posts in six languages - Spanish, English, German,
Catalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was
translated into five other languages using SeamlessM4T. Each model was
fine-tuned on this multilingual data and evaluated across classification
metrics. Results showed mT5 achieving the best performance overall with F1
scores above 85%, highlighting capabilities for cross-lingual transfer
learning. The English and Spanish translations also displayed high quality
based on perplexity. Our exploration underscores the importance of considering
linguistic diversity in developing automated multilingual tools to identify
suicidal risk. Limitations exist around semantic fidelity in translations and
ethical implications which provide guidance for future human-in-the-loop
evaluations.",2024-12-20,"Rodolfo Zevallos, Annika Schoene, John E. Ortega",http://arxiv.org/pdf/2412.15498v1,cs.CL
Lexicography Saves Lives (LSL): Automatically Translating Suicide-Related Language,"Recent years have seen a marked increase in research that aims to identify or
predict risk, intention or ideation of suicide. The majority of new tasks,
datasets, language models and other resources focus on English and on suicide
in the context of Western culture. However, suicide is global issue and
reducing suicide rate by 2030 is one of the key goals of the UN's Sustainable
Development Goals. Previous work has used English dictionaries related to
suicide to translate into different target languages due to lack of other
available resources. Naturally, this leads to a variety of ethical tensions
(e.g.: linguistic misrepresentation), where discourse around suicide is not
present in a particular culture or country. In this work, we introduce the
'Lexicography Saves Lives Project' to address this issue and make three
distinct contributions. First, we outline ethical consideration and provide
overview guidelines to mitigate harm in developing suicide-related resources.
Next, we translate an existing dictionary related to suicidal ideation into 200
different languages and conduct human evaluations on a subset of translated
dictionaries. Finally, we introduce a public website to make our resources
available and enable community participation.",2024-12-20,"Annika Marie Schoene, John E. Ortega, Rodolfo Joel Zevallos, Laura Haaber Ihle",http://arxiv.org/pdf/2412.15497v1,cs.CL
TL-Training: A Task-Feature-Based Framework for Training Large Language Models in Tool Use,"Large language models (LLMs) achieve remarkable advancements by leveraging
tools to interact with external environments, a critical step toward
generalized AI. However, the standard supervised fine-tuning (SFT) approach,
which relies on large-scale datasets, often overlooks task-specific
characteristics in tool use, leading to performance bottlenecks. To address
this issue, we analyze three existing LLMs and uncover key insights: training
data can inadvertently impede tool-use behavior, token importance is
distributed unevenly, and errors in tool calls fall into a small set of
distinct categories. Building on these findings, we propose TL-Training, a
task-feature-based framework that mitigates the effects of suboptimal training
data, dynamically adjusts token weights to prioritize key tokens during SFT,
and incorporates a robust reward mechanism tailored to error categories,
optimized through proximal policy optimization. We validate TL-Training by
training CodeLLaMA-2-7B and evaluating it on four diverse open-source test
sets. Our results demonstrate that the LLM trained by our method matches or
surpasses both open- and closed-source LLMs in tool-use performance using only
1,217 training data points. Additionally, our method enhances robustness in
noisy environments and improves general task performance, offering a scalable
and efficient paradigm for tool-use training in LLMs. The code and data are
available at https://github.com/Junjie-Ye/TL-Training.",2024-12-20,"Junjie Ye, Yilong Wu, Sixian Li, Yuming Yang, Tao Gui, Qi Zhang, Xuanjing Huang, Peng Wang, Zhongchao Shi, Jianping Fan, Zhengyin Du",http://arxiv.org/pdf/2412.15495v1,cs.CL
Multi-LLM Text Summarization,"In this work, we propose a Multi-LLM summarization framework, and investigate
two different multi-LLM strategies including centralized and decentralized. Our
multi-LLM summarization framework has two fundamentally important steps at each
round of conversation: generation and evaluation. These steps are different
depending on whether our multi-LLM decentralized summarization is used or
centralized. In both our multi-LLM decentralized and centralized strategies, we
have k different LLMs that generate diverse summaries of the text. However,
during evaluation, our multi-LLM centralized summarization approach leverages a
single LLM to evaluate the summaries and select the best one whereas k LLMs are
used for decentralized multi-LLM summarization. Overall, we find that our
multi-LLM summarization approaches significantly outperform the baselines that
leverage only a single LLM by up to 3x. These results indicate the
effectiveness of multi-LLM approaches for summarization.",2024-12-20,"Jiangnan Fang, Cheng-Tse Liu, Jieun Kim, Yash Bhedaru, Ethan Liu, Nikhil Singh, Nedim Lipka, Puneet Mathur, Nesreen K. Ahmed, Franck Dernoncourt, Ryan A. Rossi, Hanieh Deilamsalehy",http://arxiv.org/pdf/2412.15487v2,cs.CL
Continual Learning Using Only Large Language Model Prompting,"We introduce CLOB, a novel continual learning (CL) paradigm wherein a large
language model (LLM) is regarded as a black box. Learning is done incrementally
via only verbal prompting. CLOB does not fine-tune any part of the LLM or add
any trainable parameters to it. It is particularly suitable for LLMs that are
accessible via APIs. We also propose a new CL technique, called CIS, based on
incremental summarization that also overcomes the LLM's input length limit.
Experiments show CIS outperforms baselines by a very large margin.",2024-12-20,"Jiabao Qiu, Zixuan Ke, Bing Liu",http://arxiv.org/pdf/2412.15479v1,cs.CL
A Review of the Marathi Natural Language Processing,"Marathi is one of the most widely used languages in the world. One might
expect that the latest advances in NLP research in languages like English reach
such a large community. However, NLP advancements in English didn't immediately
reach Indian languages like Marathi. There were several reasons for this. They
included diversity of scripts used, lack of (publicly available) resources like
tokenization strategies, high quality datasets \& benchmarks, and evaluation
metrics. In addition to this, the morphologically rich nature of Marathi, made
NLP tasks challenging. Advances in Neural Network (NN) based models and tools
since the early 2000s helped improve this situation and make NLP research more
accessible. In the past 10 years, significant efforts were made to improve
language resources for all 22 scheduled languages of India. This paper presents
a broad overview of evolution of NLP research in Indic languages with a focus
on Marathi and state-of-the-art resources and tools available to the research
community. It also provides an overview of tools \& techniques associated with
Marathi NLP tasks.",2024-12-20,"Asang Dani, Shailesh R Sathe",http://arxiv.org/pdf/2412.15471v2,cs.CL
TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable Industrial Robotics Through Large/Vision Language Models,"TalkWithMachines aims to enhance human-robot interaction by contributing to
interpretable industrial robotic systems, especially for safety-critical
applications. The presented paper investigates recent advancements in Large
Language Models (LLMs) and Vision Language Models (VLMs), in combination with
robotic perception and control. This integration allows robots to understand
and execute commands given in natural language and to perceive their
environment through visual and/or descriptive inputs. Moreover, translating the
LLM's internal states and reasoning into text that humans can easily understand
ensures that operators gain a clearer insight into the robot's current state
and intentions, which is essential for effective and safe operation. Our paper
outlines four LLM-assisted simulated robotic control workflows, which explore
(i) low-level control, (ii) the generation of language-based feedback that
describes the robot's internal states, (iii) the use of visual information as
additional input, and (iv) the use of robot structure information for
generating task plans and feedback, taking the robot's physical capabilities
and limitations into account. The proposed concepts are presented in a set of
experiments, along with a brief discussion. Project description, videos, and
supplementary materials will be available on the project website:
https://talk-machines.github.io.",2024-12-19,"Ammar N. Abbas, Csaba Beleznai",http://arxiv.org/pdf/2412.15462v1,cs.CL
Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization,"The automatic generation of counter-speech (CS) is a critical strategy for
addressing hate speech by providing constructive and informed responses.
However, existing methods often fail to generate high-quality, impactful, and
scalable CS, particularly across diverse linguistic contexts. In this paper, we
propose a novel methodology to enhance CS generation by aligning Large Language
Models (LLMs) using Supervised Fine-Tuning (SFT) and Direct Preference
Optimization (DPO). Our approach leverages DPO to align LLM outputs with human
preferences, ensuring contextually appropriate and linguistically adaptable
responses. Additionally, we incorporate knowledge grounding to enhance the
factual accuracy and relevance of generated CS. Experimental results
demonstrate that DPO-aligned models significantly outperform SFT baselines on
CS benchmarks while scaling effectively to multiple languages. These findings
highlight the potential of preference-based alignment techniques to advance CS
generation across varied linguistic settings. The model supervision and
alignment is done in English and the same model is used for reporting metrics
across other languages like Basque, Italian, and Spanish.",2024-12-19,"Sahil Wadhwa, Chengtian Xu, Haoming Chen, Aakash Mahalingam, Akankshya Kar, Divya Chaudhary",http://arxiv.org/pdf/2412.15453v1,cs.CL
"Fietje: An open, efficient LLM for Dutch","This paper introduces Fietje, a family of small language models (SLMs)
specifically designed for the Dutch language. The model is based on Phi 2, an
English-centric model of 2.7 billion parameters. Fietje demonstrated
competitive results with larger language models upon its release. A core
emphasis of this work is transparency and reproducibility: Fietje is fully
open-source, with model weights, datasets, training, and evaluation code all
publicly accessible.
  The paper discusses the performance of Fietje and many other models on an
extensive evaluation suite of benchmarks on reasoning, sentiment analysis,
world knowledge, linguistic acceptability and word sense disambiguation.
Evaluation results illustrate the rapid progress in the field of LLMs, where
recent small models outperform older, larger models that were fine-tuned for
Dutch. This trend signals an exciting future for Dutch language processing,
suggesting that even compact LLMs are becoming increasingly capable.
Furthermore, ongoing and future efforts to adapt LLMs to Dutch are poised to
enhance these models even further, broadening their applicability and
accessibility. Fietje is only an intermediate step in improving accessibility
to language technology for users of the Dutch language.",2024-12-19,Bram Vanroy,http://arxiv.org/pdf/2412.15450v1,cs.CL
SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval,"Retrieval-Augmented Generation (RAG) systems have become pivotal in
leveraging vast corpora to generate informed and contextually relevant
responses, notably reducing hallucinations in Large Language Models. Despite
significant advancements, these systems struggle to efficiently process and
retrieve information from large datasets while maintaining a comprehensive
understanding of the context. This paper introduces SKETCH, a novel methodology
that enhances the RAG retrieval process by integrating semantic text retrieval
with knowledge graphs, thereby merging structured and unstructured data for a
more holistic comprehension. SKETCH, demonstrates substantial improvements in
retrieval performance and maintains superior context integrity compared to
traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER,
NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline
approaches on key RAGAS metrics such as answer_relevancy, faithfulness,
context_precision and context_recall. Notably, on the Italian Cuisine dataset,
SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99,
representing the highest performance across all evaluated metrics. These
results highlight SKETCH's capability in delivering more accurate and
contextually relevant responses, setting new benchmarks for future retrieval
systems.",2024-12-19,"Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary",http://arxiv.org/pdf/2412.15443v1,cs.CL
Why Do Large Language Models (LLMs) Struggle to Count Letters?,"Large Language Models (LLMs) have achieved unprecedented performance on many
complex tasks, being able, for example, to answer questions on almost any
topic. However, they struggle with other simple tasks, such as counting the
occurrences of letters in a word, as illustrated by the inability of many LLMs
to count the number of ""r"" letters in ""strawberry"". Several works have studied
this problem and linked it to the tokenization used by LLMs, to the intrinsic
limitations of the attention mechanism, or to the lack of character-level
training data. In this paper, we conduct an experimental study to evaluate the
relations between the LLM errors when counting letters with 1) the frequency of
the word and its components in the training dataset and 2) the complexity of
the counting operation. We present a comprehensive analysis of the errors of
LLMs when counting letter occurrences by evaluating a representative group of
models over a large number of words. The results show a number of consistent
trends in the models evaluated: 1) models are capable of recognizing the
letters but not counting them; 2) the frequency of the word and tokens in the
word does not have a significant impact on the LLM errors; 3) there is a
positive correlation of letter frequency with errors, more frequent letters
tend to have more counting errors, 4) the errors show a strong correlation with
the number of letters or tokens in a word and 5) the strongest correlation
occurs with the number of letters with counts larger than one, with most models
being unable to correctly count words in which letters appear more than twice.",2024-12-19,"Tairan Fu, Raquel Ferrando, Javier Conde, Carlos Arriaga, Pedro Reviriego",http://arxiv.org/pdf/2412.18626v1,cs.CL
Time Will Tell: Timing Side Channels via Output Token Count in Large Language Models,"This paper demonstrates a new side-channel that enables an adversary to
extract sensitive information about inference inputs in large language models
(LLMs) based on the number of output tokens in the LLM response. We construct
attacks using this side-channel in two common LLM tasks: recovering the target
language in machine translation tasks and recovering the output class in
classification tasks. In addition, due to the auto-regressive generation
mechanism in LLMs, an adversary can recover the output token count reliably
using a timing channel, even over the network against a popular closed-source
commercial LLM. Our experiments show that an adversary can learn the output
language in translation tasks with more than 75% precision across three
different models (Tower, M2M100, MBart50). Using this side-channel, we also
show the input class in text classification tasks can be leaked out with more
than 70% precision from open-source LLMs like Llama-3.1, Llama-3.2, Gemma2, and
production models like GPT-4o. Finally, we propose tokenizer-, system-, and
prompt-based mitigations against the output token count side-channel.",2024-12-19,"Tianchen Zhang, Gururaj Saileshwar, David Lie",http://arxiv.org/pdf/2412.15431v1,cs.CL
"Transcribing and Translating, Fast and Slow: Joint Speech Translation and Recognition","We propose the joint speech translation and recognition (JSTAR) model that
leverages the fast-slow cascaded encoder architecture for simultaneous
end-to-end automatic speech recognition (ASR) and speech translation (ST). The
model is transducer-based and uses a multi-objective training strategy that
optimizes both ASR and ST objectives simultaneously. This allows JSTAR to
produce high-quality streaming ASR and ST results. We apply JSTAR in a
bilingual conversational speech setting with smart-glasses, where the model is
also trained to distinguish speech from different directions corresponding to
the wearer and a conversational partner. Different model pre-training
strategies are studied to further improve results, including training of a
transducer-based streaming machine translation (MT) model for the first time
and applying it for parameter initialization of JSTAR. We demonstrate superior
performances of JSTAR compared to a strong cascaded ST model in both BLEU
scores and latency.",2024-12-19,"Niko Moritz, Ruiming Xie, Yashesh Gaur, Ke Li, Simone Merello, Zeeshan Ahmed, Frank Seide, Christian Fuegen",http://arxiv.org/pdf/2412.15415v1,cs.CL
Learning Visual Composition through Improved Semantic Guidance,"Visual imagery does not consist of solitary objects, but instead reflects the
composition of a multitude of fluid concepts. While there have been great
advances in visual representation learning, such advances have focused on
building better representations for a small number of discrete objects bereft
of an understanding of how these objects are interacting. One can observe this
limitation in representations learned through captions or contrastive learning
-- where the learned model treats an image essentially as a bag of words.
Several works have attempted to address this limitation through the development
of bespoke learned architectures to directly address the shortcomings in
compositional learning. In this work, we focus on simple, and scalable
approaches. In particular, we demonstrate that by substantially improving
weakly labeled data, i.e. captions, we can vastly improve the performance of
standard contrastive learning approaches. Previous CLIP models achieved near
chance rate on challenging tasks probing compositional learning. However, our
simple approach boosts performance of CLIP substantially and surpasses all
bespoke architectures. Furthermore, we showcase our results on a relatively new
captioning benchmark derived from DOCCI. We demonstrate through a series of
ablations that a standard CLIP model trained with enhanced data may demonstrate
impressive performance on image retrieval tasks.",2024-12-19,"Austin Stone, Hagen Soltau, Robert Geirhos, Xi Yi, Ye Xia, Bingyi Cao, Kaifeng Chen, Abhijit Ogale, Jonathon Shlens",http://arxiv.org/pdf/2412.15396v2,cs.CL
Systematic Evaluation of Long-Context LLMs on Financial Concepts,"Long-context large language models (LC LLMs) promise to increase reliability
of LLMs in real-world tasks requiring processing and understanding of long
input documents. However, this ability of LC LLMs to reliably utilize their
growing context windows remains under investigation. In this work, we evaluate
the performance of state-of-the-art GPT-4 suite of LC LLMs in solving a series
of progressively challenging tasks, as a function of factors such as context
length, task difficulty, and position of key information by creating a real
world financial news dataset. Our findings indicate that LC LLMs exhibit
brittleness at longer context lengths even for simple tasks, with performance
deteriorating sharply as task complexity increases. At longer context lengths,
these state-of-the-art models experience catastrophic failures in instruction
following resulting in degenerate outputs. Our prompt ablations also reveal
unfortunate continued sensitivity to both the placement of the task instruction
in the context window as well as minor markdown formatting. Finally, we
advocate for more rigorous evaluation of LC LLMs by employing holistic metrics
such as F1 (rather than recall) and reporting confidence intervals, thereby
ensuring robust and conclusive findings.",2024-12-19,"Lavanya Gupta, Saket Sharma, Yiyun Zhao",http://arxiv.org/pdf/2412.15386v1,cs.CL
"Automatic Extraction of Metaphoric Analogies from Literary Texts: Task Formulation, Dataset Construction, and Evaluation","Extracting metaphors and analogies from free text requires high-level
reasoning abilities such as abstraction and language understanding. Our study
focuses on the extraction of the concepts that form metaphoric analogies in
literary texts. To this end, we construct a novel dataset in this domain with
the help of domain experts. We compare the out-of-the-box ability of recent
large language models (LLMs) to structure metaphoric mappings from fragments of
texts containing proportional analogies. The models are further evaluated on
the generation of implicit elements of the analogy, which are indirectly
suggested in the texts and inferred by human readers. The competitive results
obtained by LLMs in our experiments are encouraging and open up new avenues
such as automatically extracting analogies and metaphors from text instead of
investing resources in domain experts to manually label data.",2024-12-19,"Joanne Boisson, Zara Siddique, Hsuvas Borkakoty, Dimosthenis Antypas, Luis Espinosa Anke, Jose Camacho-Collados",http://arxiv.org/pdf/2412.15375v1,cs.CL
Decade of Natural Language Processing in Chronic Pain: A Systematic Review,"In recent years, the intersection of Natural Language Processing (NLP) and
public health has opened innovative pathways for investigating various domains,
including chronic pain in textual datasets. Despite the promise of NLP in
chronic pain, the literature is dispersed across various disciplines, and there
is a need to consolidate existing knowledge, identify knowledge gaps in the
literature, and inform future research directions in this emerging field. This
review aims to investigate the state of the research on NLP-based interventions
designed for chronic pain research. A search strategy was formulated and
executed across PubMed, Web of Science, IEEE Xplore, Scopus, and ACL Anthology
to find studies published in English between 2014 and 2024. After screening 132
papers, 26 studies were included in the final review. Key findings from this
review underscore the significant potential of NLP techniques to address
pressing challenges in chronic pain research. The past 10 years in this field
have showcased the utilization of advanced methods (transformers like RoBERTa
and BERT) achieving high-performance metrics (e.g., F1>0.8) in classification
tasks, while unsupervised approaches like Latent Dirichlet Allocation (LDA) and
k-means clustering have proven effective for exploratory analyses. Results also
reveal persistent challenges such as limited dataset diversity, inadequate
sample sizes, and insufficient representation of underrepresented populations.
Future research studies should explore multimodal data validation systems,
context-aware mechanistic modeling, and the development of standardized
evaluation metrics to enhance reproducibility and equity in chronic pain
research.",2024-12-19,Swati Rajwal,http://arxiv.org/pdf/2412.15360v1,cs.CL
Tokenisation is NP-Complete,"In this work, we prove the NP-completeness of two variants of tokenisation,
defined as the problem of compressing a dataset to at most $\delta$ symbols by
either finding a vocabulary directly (direct tokenisation), or selecting a
sequence of merge operations (bottom-up tokenisation).",2024-12-19,"Philip Whittington, Gregor Bachmann, Tiago Pimentel",http://arxiv.org/pdf/2412.15210v1,cs.CL
LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks,"This paper introduces LongBench v2, a benchmark designed to assess the
ability of LLMs to handle long-context problems requiring deep understanding
and reasoning across real-world multitasks. LongBench v2 consists of 503
challenging multiple-choice questions, with contexts ranging from 8k to 2M
words, across six major task categories: single-document QA, multi-document QA,
long in-context learning, long-dialogue history understanding, code repository
understanding, and long structured data understanding. To ensure the breadth
and the practicality, we collect data from nearly 100 highly educated
individuals with diverse professional backgrounds. We employ both automated and
manual review processes to maintain high quality and difficulty, resulting in
human experts achieving only 53.7% accuracy under a 15-minute time constraint.
Our evaluation reveals that the best-performing model, when directly answers
the questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,
which includes longer reasoning, achieves 57.7%, surpassing the human baseline
by 4%. These results highlight the importance of enhanced reasoning ability and
scaling inference-time compute to tackle the long-context challenges in
LongBench v2. The project is available at https://longbench2.github.io.",2024-12-19,"Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li",http://arxiv.org/pdf/2412.15204v2,cs.CL
MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark,"Multiple-choice question (MCQ) datasets like Massive Multitask Language
Understanding (MMLU) are widely used to evaluate the commonsense,
understanding, and problem-solving abilities of large language models (LLMs).
However, the open-source nature of these benchmarks and the broad sources of
training data for LLMs have inevitably led to benchmark contamination,
resulting in unreliable evaluation results. To alleviate this issue, we propose
a contamination-free and more challenging MCQ benchmark called MMLU-CF. This
benchmark reassesses LLMs' understanding of world knowledge by averting both
unintentional and malicious data leakage. To avoid unintentional data leakage,
we source data from a broader domain and design three decontamination rules. To
prevent malicious data leakage, we divide the benchmark into validation and
test sets with similar difficulty and subject distributions. The test set
remains closed-source to ensure reliable results, while the validation set is
publicly available to promote transparency and facilitate independent
verification. Our evaluation of mainstream LLMs reveals that the powerful
GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on
the test set, which indicates the effectiveness of our approach in creating a
more rigorous and contamination-free evaluation standard. The GitHub repository
is available at https://github.com/microsoft/MMLU-CF and the dataset refers to
https://huggingface.co/datasets/microsoft/MMLU-CF.",2024-12-19,"Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, Furu Wei",http://arxiv.org/pdf/2412.15194v1,cs.CL
Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings,"Natural Language Processing and Generation systems have recently shown the
potential to complement and streamline the costly and time-consuming job of
professional fact-checkers. In this work, we lift several constraints of
current state-of-the-art pipelines for automated fact-checking based on the
Retrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark, under
more realistic scenarios, RAG-based methods for the generation of verdicts -
i.e., short texts discussing the veracity of a claim - evaluating them on
stylistically complex claims and heterogeneous, yet reliable, knowledge bases.
Our findings show a complex landscape, where, for example, LLM-based retrievers
outperform other retrieval techniques, though they still struggle with
heterogeneous knowledge bases; larger models excel in verdict faithfulness,
while smaller models provide better context adherence, with human evaluations
favouring zero-shot and one-shot approaches for informativeness, and fine-tuned
models for emotional alignment.",2024-12-19,"Daniel Russo, Stefano Menini, Jacopo Staiano, Marco Guerini",http://arxiv.org/pdf/2412.15189v1,cs.CL
LMFusion: Adapting Pretrained Language Models for Multimodal Generation,"We present LMFusion, a framework for empowering pretrained text-only large
language models (LLMs) with multimodal generative capabilities, enabling them
to understand and generate both text and images in arbitrary sequences.
LMFusion leverages existing Llama-3's weights for processing texts
autoregressively while introducing additional and parallel transformer modules
for processing images with diffusion. During training, the data from each
modality is routed to its dedicated modules: modality-specific feedforward
layers, query-key-value projections, and normalization layers process each
modality independently, while the shared self-attention layers allow
interactions across text and image features. By freezing the text-specific
modules and only training the image-specific modules, LMFusion preserves the
language capabilities of text-only LLMs while developing strong visual
understanding and generation abilities. Compared to methods that pretrain
multimodal generative models from scratch, our experiments demonstrate that,
LMFusion improves image understanding by 20% and image generation by 3.6% using
only 50% of the FLOPs while maintaining Llama-3's language capabilities. We
also demonstrate that this framework can adapt existing vision-language models
with multimodal generation ability. Overall, this framework not only leverages
existing computational investments in text-only LLMs but also enables the
parallel development of language and vision capabilities, presenting a
promising direction for efficient multimodal model development.",2024-12-19,"Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu",http://arxiv.org/pdf/2412.15188v4,cs.CL
Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying,"Studies have underscored how, regardless of the recent breakthrough and swift
advances in AI research, even state-of-the-art Large Language models (LLMs)
continue to struggle when performing logical and mathematical reasoning. The
results seem to suggest that LLMs still work as (highly advanced) data pattern
identifiers, scoring poorly when attempting to generalise and solve reasoning
problems the models have never previously seen or that are not close to samples
presented in their training data. To address this compelling concern, this
paper makes use of the notion of critical questions from the literature on
argumentation theory, focusing in particular on Toulmin's model of
argumentation. We show that employing these critical questions can improve the
reasoning capabilities of LLMs. By probing the rationale behind the models'
reasoning process, the LLM can assess whether some logical mistake is occurring
and correct it before providing the final reply to the user prompt. The
underlying idea is drawn from the gold standard of any valid argumentative
procedure: the conclusion is valid if it is entailed by accepted premises. Or,
to paraphrase such Aristotelian principle in a real-world approximation,
characterised by incomplete information and presumptive logic, the conclusion
is valid if not proved otherwise. This approach successfully steers the models'
output through a reasoning pipeline, resulting in better performance against
the baseline and its Chain-of-Thought (CoT) implementation. To this end, an
extensive evaluation of the proposed approach on the MT-Bench Reasoning and
Math tasks across a range of LLMs is provided.",2024-12-19,"Federico Castagna, Isabel Sassoon, Simon Parsons",http://arxiv.org/pdf/2412.15177v1,cs.CL
Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned LLM,"Text-to-video models have made remarkable advancements through optimization
on high-quality text-video pairs, where the textual prompts play a pivotal role
in determining quality of output videos. However, achieving the desired output
often entails multiple revisions and iterative inference to refine
user-provided prompts. Current automatic methods for refining prompts encounter
challenges such as Modality-Inconsistency, Cost-Discrepancy, and Model-Unaware
when applied to text-to-video diffusion models. To address these problem, we
introduce an LLM-based prompt adaptation framework, termed as Prompt-A-Video,
which excels in crafting Video-Centric, Labor-Free and Preference-Aligned
prompts tailored to specific video diffusion model. Our approach involves a
meticulously crafted two-stage optimization and alignment system. Initially, we
conduct a reward-guided prompt evolution pipeline to automatically create
optimal prompts pool and leverage them for supervised fine-tuning (SFT) of the
LLM. Then multi-dimensional rewards are employed to generate pairwise data for
the SFT model, followed by the direct preference optimization (DPO) algorithm
to further facilitate preference alignment. Through extensive experimentation
and comparative analyses, we validate the effectiveness of Prompt-A-Video
across diverse generation models, highlighting its potential to push the
boundaries of video generation.",2024-12-19,"Yatai Ji, Jiacheng Zhang, Jie Wu, Shilong Zhang, Shoufa Chen, Chongjian GE, Peize Sun, Weifeng Chen, Wenqi Shao, Xuefeng Xiao, Weilin Huang, Ping Luo",http://arxiv.org/pdf/2412.15156v1,cs.CL
Language Models as Continuous Self-Evolving Data Engineers,"Large Language Models (LLMs) have demonstrated remarkable capabilities on
various tasks, while the further evolvement is limited to the lack of
high-quality training data. In addition, traditional training approaches rely
too much on expert-labeled data, setting a ceiling on the performance of LLMs.
To address this issue, we propose a novel paradigm named LANCE (LANguage models
as Continuous self-Evolving data engineers) that enables LLMs to train
themselves by autonomously generating, cleaning, reviewing, and annotating data
with preference information. Our approach demonstrates that LLMs can serve as
continuous self-evolving data engineers, significantly reducing the time and
cost of the post-training data construction. Through iterative fine-tuning on
Qwen2 series models, we validate the effectiveness of LANCE across various
tasks, showing that it can maintain high-quality data generation and
continuously improve model performance. Across multiple benchmark dimensions,
LANCE results in an average score enhancement of 3.64 for Qwen2-7B and 1.75 for
Qwen2-7B-Instruct. This training paradigm with autonomous data construction not
only reduces the reliance on human experts or external models but also ensures
that the data aligns with human preferences, paving the way for the development
of future superintelligent systems that can exceed human capabilities. Codes
are available at: https://github.com/Control-derek/LANCE.",2024-12-19,"Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song",http://arxiv.org/pdf/2412.15151v3,cs.CL
Adaptive Pruning for Large Language Models with Structural Importance Awareness,"The recent advancements in large language models (LLMs) have significantly
improved language understanding and generation capabilities. However, it is
difficult to deploy LLMs on resource-constrained edge devices due to their high
computational and storage resource demands. To address this issue, we propose a
novel LLM model pruning method, namely structurally-aware adaptive pruning
(SAAP), to significantly reduce the computational and memory costs while
maintaining model performance. We first define an adaptive importance fusion
metric to evaluate the importance of all coupled structures in LLMs by
considering their homoscedastic uncertainty. Then, we rank the importance of
all modules to determine the specific layers that should be pruned to meet
particular performance requirements. Furthermore, we develop a new group
fine-tuning strategy to improve the inference efficiency of LLMs. Finally, we
evaluate the proposed SAAP method on multiple LLMs across two common tasks,
i.e., zero-shot classification and text generation. Experimental results show
that our SAAP method outperforms several state-of-the-art baseline methods,
achieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and
LLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,
showcasing its practical advantages in resource-constrained scenarios.",2024-12-19,"Haotian Zheng, Jinke Ren, Yushan Sun, Ruichen Zhang, Wenbo Zhang, Zhen Li, Dusit Niyato, Shuguang Cui, Yatong Han",http://arxiv.org/pdf/2412.15127v1,cs.CL
Outcome-Refining Process Supervision for Code Generation,"Large Language Models have demonstrated remarkable capabilities in code
generation, yet they often struggle with complex programming tasks that require
deep algorithmic reasoning. While process supervision through learned reward
models shows promise in guiding reasoning steps, it requires expensive training
data and suffers from unreliable evaluation. We propose Outcome-Refining
Process Supervision, a novel paradigm that treats outcome refinement itself as
the process to be supervised. Our framework leverages concrete execution
signals to ground the supervision of reasoning steps, while using
tree-structured exploration to maintain multiple solution trajectories
simultaneously. Experiments demonstrate that our approach enables even smaller
models to achieve high success accuracy and performance metrics on competitive
programming tasks, creates more reliable verification than traditional reward
models without requiring training PRMs. Our approach achieves significant
improvements across 5 models and 3 datasets: an average of 26.9% increase in
correctness and 42.2% in efficiency. The results suggest that providing
structured reasoning space with concrete verification signals is crucial for
solving complex programming tasks. We open-source all our code and data at:
https://github.com/zhuohaoyu/ORPS",2024-12-19,"Zhuohao Yu, Weizheng Gu, Yidong Wang, Zhengran Zeng, Jindong Wang, Wei Ye, Shikun Zhang",http://arxiv.org/pdf/2412.15118v1,cs.CL
Qwen2.5 Technical Report,"In this report, we introduce Qwen2.5, a comprehensive series of large
language models (LLMs) designed to meet diverse needs. Compared to previous
iterations, Qwen 2.5 has been significantly improved during both the
pre-training and post-training stages. In terms of pre-training, we have scaled
the high-quality pre-training datasets from the previous 7 trillion tokens to
18 trillion tokens. This provides a strong foundation for common sense, expert
knowledge, and reasoning capabilities. In terms of post-training, we implement
intricate supervised finetuning with over 1 million samples, as well as
multistage reinforcement learning. Post-training techniques enhance human
preference, and notably improve long text generation, structural data analysis,
and instruction following. To handle diverse and varied use cases effectively,
we present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base
and instruction-tuned models, with quantized versions available. In addition,
for hosted solutions, the proprietary models currently include two
mixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both
available from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier
performance on a wide range of benchmarks evaluating language understanding,
reasoning, mathematics, coding, human preference alignment, etc. Specifically,
the open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and
proprietary models and demonstrates competitive performance to the
state-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5
times larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness
while performing competitively against GPT-4o-mini and GPT-4o respectively.
Additionally, as the foundation, Qwen2.5 models have been instrumental in
training specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and
multimodal models.",2024-12-19,"Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zihan Qiu",http://arxiv.org/pdf/2412.15115v2,cs.CL
Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture,"Large language models (LLMs) demonstrate an impressive ability to utilise
information within the context of their input sequences to appropriately
respond to data unseen by the LLM during its training procedure. This ability
is known as in-context learning (ICL). Humans and non-human animals demonstrate
similar abilities, however their neural architectures differ substantially from
LLMs. Despite this, a critical component within LLMs, the attention mechanism,
resembles modern associative memory models, widely used in and influenced by
the computational neuroscience community to model biological memory systems.
Using this connection, we introduce an associative memory model capable of
performing ICL. We use this as inspiration for a novel residual stream
architecture which allows information to directly flow between attention heads.
We test this architecture during training within a two-layer Transformer and
show its ICL abilities manifest more quickly than without this modification. We
then apply our architecture in small language models with 8 million parameters,
focusing on attention head values, with results also indicating improved ICL
performance at this larger and more naturalistic scale.",2024-12-19,"Thomas F Burns, Tomoki Fukai, Christopher J Earls",http://arxiv.org/pdf/2412.15113v1,cs.CL
Review-Then-Refine: A Dynamic Framework for Multi-Hop Question Answering with Temporal Adaptability,"Retrieve-augmented generation (RAG) frameworks have emerged as a promising
solution to multi-hop question answering(QA) tasks since it enables large
language models (LLMs) to incorporate external knowledge and mitigate their
inherent knowledge deficiencies. Despite this progress, existing RAG
frameworks, which usually follows the retrieve-then-read paradigm, often
struggle with multi-hop QA with temporal information since it has difficulty
retrieving and synthesizing accurate time-related information. To address the
challenge, this paper proposes a novel framework called review-then-refine,
which aims to enhance LLM performance in multi-hop QA scenarios with temporal
information. Our approach begins with a review phase, where decomposed
sub-queries are dynamically rewritten with temporal information, allowing for
subsequent adaptive retrieval and reasoning process. In addition, we implement
adaptive retrieval mechanism to minimize unnecessary retrievals, thus reducing
the potential for hallucinations. In the subsequent refine phase, the LLM
synthesizes the retrieved information from each sub-query along with its
internal knowledge to formulate a coherent answer. Extensive experimental
results across multiple datasets demonstrate the effectiveness of our proposed
framework, highlighting its potential to significantly improve multi-hop QA
capabilities in LLMs.",2024-12-19,"Xiangsen Chen, Xuming Hu, Nan Tang",http://arxiv.org/pdf/2412.15101v1,cs.CL
A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation,"Disinformation, irrespective of domain or language, aims to deceive or
manipulate public opinion, typically through employing advanced persuasion
techniques. Qualitative and quantitative research on the weaponisation of
persuasion techniques in disinformation has been mostly topic-specific (e.g.,
COVID-19) with limited cross-domain studies, resulting in a lack of
comprehensive understanding of these strategies. This study employs a
state-of-the-art persuasion technique classifier to conduct a large-scale,
multi-domain analysis of the role of 16 persuasion techniques in disinformation
narratives. It shows how different persuasion techniques are employed
disproportionately in different disinformation domains. We also include a
detailed case study on climate change disinformation, highlighting how
linguistic, psychological, and cultural factors shape the adaptation of
persuasion strategies to fit unique thematic contexts.",2024-12-19,"João A. Leite, Olesya Razuvayevskaya, Carolina Scarton, Kalina Bontcheva",http://arxiv.org/pdf/2412.15098v1,cs.CL
AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling,"In this paper, we introduce AceMath, a suite of frontier math models that
excel in solving complex math problems, along with highly effective reward
models capable of evaluating generated solutions and reliably identifying the
correct ones. To develop the instruction-tuned math models, we propose a
supervised fine-tuning (SFT) process that first achieves competitive
performance across general domains, followed by targeted fine-tuning for the
math domain using a carefully curated set of prompts and synthetically
generated responses. The resulting model, AceMath-72B-Instruct greatly
outperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop
math-specialized reward model, we first construct AceMath-RewardBench, a
comprehensive and robust benchmark for evaluating math reward models across
diverse problems and difficulty levels. After that, we present a systematic
approach to build our math reward models. The resulting model, AceMath-72B-RM,
consistently outperforms state-of-the-art reward models. Furthermore, when
combining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest
average rm@8 score across the math reasoning benchmarks. We release model
weights, training data, and evaluation benchmarks at:
https://research.nvidia.com/labs/adlr/acemath",2024-12-19,"Zihan Liu, Yang Chen, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping",http://arxiv.org/pdf/2412.15084v2,cs.CL
Till the Layers Collapse: Compressing a Deep Neural Network through the Lenses of Batch Normalization Layers,"Today, deep neural networks are widely used since they can handle a variety
of complex tasks. Their generality makes them very powerful tools in modern
technology. However, deep neural networks are often overparameterized. The
usage of these large models consumes a lot of computation resources. In this
paper, we introduce a method called \textbf{T}ill the \textbf{L}ayers
\textbf{C}ollapse (TLC), which compresses deep neural networks through the
lenses of batch normalization layers. By reducing the depth of these networks,
our method decreases deep neural networks' computational requirements and
overall latency. We validate our method on popular models such as Swin-T,
MobileNet-V2, and RoBERTa, across both image classification and natural
language processing (NLP) tasks.",2024-12-19,"Zhu Liao, Nour Hezbri, Victor Quétu, Van-Tam Nguyen, Enzo Tartaglione",http://arxiv.org/pdf/2412.15077v1,cs.CL
ConfliBERT: A Language Model for Political Conflict,"Conflict scholars have used rule-based approaches to extract information
about political violence from news reports and texts. Recent Natural Language
Processing developments move beyond rigid rule-based approaches. We review our
recent ConfliBERT language model (Hu et al. 2022) to process political and
violence related texts. The model can be used to extract actor and action
classifications from texts about political conflict. When fine-tuned, results
show that ConfliBERT has superior performance in accuracy, precision and recall
over other large language models (LLM) like Google's Gemma 2 (9B), Meta's Llama
3.1 (7B), and Alibaba's Qwen 2.5 (14B) within its relevant domains. It is also
hundreds of times faster than these more generalist LLMs. These results are
illustrated using texts from the BBC, re3d, and the Global Terrorism Dataset
(GTD).",2024-12-19,"Patrick T. Brandt, Sultan Alsarra, Vito J. D`Orazio, Dagmar Heintze, Latifur Khan, Shreyas Meher, Javier Osorio, Marcus Sianan",http://arxiv.org/pdf/2412.15060v1,cs.CL
Eliciting Causal Abilities in Large Language Models for Reasoning Tasks,"Prompt optimization automatically refines prompting expressions, unlocking
the full potential of LLMs in downstream tasks. However, current prompt
optimization methods are costly to train and lack sufficient interpretability.
This paper proposes enhancing LLMs' reasoning performance by eliciting their
causal inference ability from prompting instructions to correct answers.
Specifically, we introduce the Self-Causal Instruction Enhancement (SCIE)
method, which enables LLMs to generate high-quality, low-quantity observational
data, then estimates the causal effect based on these data, and ultimately
generates instructions with the optimized causal effect. In SCIE, the
instructions are treated as the treatment, and textual features are used to
process natural language, establishing causal relationships through treatments
between instructions and downstream tasks. Additionally, we propose applying
Object-Relational (OR) principles, where the uncovered causal relationships are
treated as the inheritable class across task objects, ensuring low-cost
reusability. Extensive experiments demonstrate that our method effectively
generates instructions that enhance reasoning performance with reduced training
cost of prompts, leveraging interpretable textual features to provide
actionable insights.",2024-12-19,"Yajing Wang, Zongwei Luo, Jingzhe Wang, Zhanke Zhou, Yongqiang Chen, Bo Han",http://arxiv.org/pdf/2412.15314v1,cs.CL
LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps,"Building safe Large Language Models (LLMs) across multiple languages is
essential in ensuring both safe access and linguistic diversity. To this end,
we introduce M-ALERT, a multilingual benchmark that evaluates the safety of
LLMs in five languages: English, French, German, Italian, and Spanish. M-ALERT
includes 15k high-quality prompts per language, totaling 75k, following the
detailed ALERT taxonomy. Our extensive experiments on 10 state-of-the-art LLMs
highlight the importance of language-specific safety analysis, revealing that
models often exhibit significant inconsistencies in safety across languages and
categories. For instance, Llama3.2 shows high unsafety in the category
crime_tax for Italian but remains safe in other languages. Similar differences
can be observed across all models. In contrast, certain categories, such as
substance_cannabis and crime_propaganda, consistently trigger unsafe responses
across models and languages. These findings underscore the need for robust
multilingual safety practices in LLMs to ensure safe and responsible usage
across diverse user communities.",2024-12-19,"Felix Friedrich, Simone Tedeschi, Patrick Schramowski, Manuel Brack, Roberto Navigli, Huu Nguyen, Bo Li, Kristian Kersting",http://arxiv.org/pdf/2412.15035v2,cs.CL
From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security,"Large Language Models (LLMs) have emerged as powerful tools for automating
various programming tasks, including security-related ones, such as detecting
and fixing vulnerabilities. Despite their promising capabilities, when required
to produce or modify pre-existing code, LLMs could introduce vulnerabilities
unbeknown to the programmer. When analyzing code, they could miss clear
vulnerabilities or signal nonexistent ones. In this Systematic Literature
Review (SLR), we aim to investigate both the security benefits and potential
drawbacks of using LLMs for a variety of code-related tasks. In particular,
first we focus on the types of vulnerabilities that could be introduced by
LLMs, when used for producing code. Second, we analyze the capabilities of LLMs
to detect and fix vulnerabilities, in any given code, and how the prompting
strategy of choice impacts their performance in these two tasks. Last, we
provide an in-depth analysis on how data poisoning attacks on LLMs can impact
performance in the aforementioned tasks.",2024-12-19,"Enna Basic, Alberto Giaretta",http://arxiv.org/pdf/2412.15004v3,cs.CL
Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small Language Models Write Young Students Texts,"Large Language Models (LLMs) have been used to generate texts in response to
different writing tasks: reports, essays, story telling. However, language
models do not have a meta-representation of the text writing process, nor
inherent communication learning needs, comparable to those of young human
students. This paper introduces a fine-grained linguistic and textual analysis
of multilingual Small Language Models' (SLMs) writing. With our method,
Chain-of-MetaWriting, SLMs can imitate some steps of the human writing process,
such as planning and evaluation. We mainly focused on short story and essay
writing tasks in French for schoolchildren and undergraduate students
respectively. Our results show that SLMs encounter difficulties in assisting
young students on sensitive topics such as violence in the schoolyard, and they
sometimes use words too complex for the target audience. In particular, the
output is quite different from the human produced texts in term of text
cohesion and coherence regarding temporal connectors, topic progression,
reference.",2024-12-19,"Ioana Buhnila, Georgeta Cislaru, Amalia Todirascu",http://arxiv.org/pdf/2412.14986v1,cs.CL
Movie2Story: A framework for understanding videos and telling stories in the form of novel text,"In recent years, large-scale models have achieved significant advancements,
accompanied by the emergence of numerous high-quality benchmarks for evaluating
various aspects of their comprehension abilities. However, most existing
benchmarks primarily focus on spatial understanding in static image tasks.
While some benchmarks extend evaluations to temporal tasks, they fall short in
assessing text generation under complex contexts involving long videos and rich
auxiliary information. To address this limitation, we propose a novel
benchmark: the Multi-modal Story Generation Benchmark (MSBench), designed to
evaluate text generation capabilities in scenarios enriched with auxiliary
information. Our work introduces an innovative automatic dataset generation
method to ensure the availability of accurate auxiliary information. On one
hand, we leverage existing datasets and apply automated processes to generate
new evaluation datasets, significantly reducing manual efforts. On the other
hand, we refine auxiliary data through systematic filtering and utilize
state-of-the-art models to ensure the fairness and accuracy of the ground-truth
datasets. Our experiments reveal that current Multi-modal Large Language Models
(MLLMs) perform suboptimally under the proposed evaluation metrics,
highlighting significant gaps in their capabilities. To address these
challenges, we propose a novel model architecture and methodology to better
handle the overall process, demonstrating improvements on our benchmark.",2024-12-19,"Kangning Li, Zheyang Jia, Anyu Ying",http://arxiv.org/pdf/2412.14965v2,cs.CL
Knowledge Injection via Prompt Distillation,"In many practical applications, large language models (LLMs) need to
incorporate new knowledge not present in their pre-training data. The primary
methods for this are fine-tuning and retrieval-augmented generation (RAG).
Although RAG has emerged as the industry standard for knowledge injection,
fine-tuning has not yet achieved comparable success. In this paper, we propose
a new fine-tuning technique for learning new knowledge and show that it can
reach the performance of RAG. The proposed method is based on the
self-distillation approach, which we call prompt distillation. First, we
generate question-answer pairs about the new knowledge. Then, we fine-tune a
student model on the question-answer pairs to imitate the output distributions
of a teacher model, which additionally receives the new knowledge in its
prompt. The student model is identical to the teacher, except it is equipped
with a LoRA adapter. This training procedure facilitates distilling the new
knowledge from the teacher's prompt into the student's weights.",2024-12-19,"Kalle Kujanpää, Harri Valpola, Alexander Ilin",http://arxiv.org/pdf/2412.14964v1,cs.CL
Understanding the Dark Side of LLMs' Intrinsic Self-Correction,"Intrinsic self-correction was proposed to improve LLMs' responses via
feedback prompts solely based on their inherent capability. However, recent
works show that LLMs' intrinsic self-correction fails without oracle labels as
feedback prompts. In this paper, we aim to interpret LLMs' intrinsic
self-correction for different tasks, especially for those failure cases. By
including one simple task and three complex tasks with state-of-the-art (SOTA)
LLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B,
and 3.1-8B), we design three interpretation methods to reveal the dark side of
LLMs' intrinsic self-correction. We identify intrinsic self-correction can (1)
cause LLMs to waver both intermedia and final answers and lead to prompt bias
on simple factual questions; (2) introduce human-like cognitive bias on complex
tasks. In light of our findings, we also provide two simple yet effective
strategies for alleviation: question repeating and supervised fine-tuning with
a few samples. We open-source our work at https://x-isc.info/.",2024-12-19,"Qingjie Zhang, Han Qiu, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang",http://arxiv.org/pdf/2412.14959v1,cs.CL
RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response,"Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.",2024-12-19,"Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang",http://arxiv.org/pdf/2412.14922v1,cs.CL
Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation,"Large language models (LLMs) are susceptible to generating hallucinated
information, despite the integration of retrieval-augmented generation (RAG).
Parallel context extension (PCE) is a line of research attempting to
effectively integrating parallel (unordered) contexts, while it still suffers
from hallucinations when adapted to RAG scenarios. In this paper, we propose
DePaC (Dehallucinating Parallel Context Extension), which alleviates the
hallucination problem with context-aware negative training and
information-calibrated aggregation. DePaC is designed to alleviate two types of
in-context hallucination: fact fabrication (i.e., LLMs present claims that are
not supported by the contexts) and fact omission (i.e., LLMs fail to present
claims that can be supported by the contexts). Specifically, (1) for fact
fabrication, we apply the context-aware negative training that fine-tunes the
LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to
answer when contexts are not related to questions; (2) for fact omission, we
propose the information-calibrated aggregation which prioritizes context
windows with higher information increment from their contexts. The experimental
results on nine RAG tasks demonstrate that DePaC significantly alleviates the
two types of hallucination and consistently achieves better performances on
these tasks.",2024-12-19,"Zexiong Ma, Shengnan An, Zeqi Lin, Yanzhen Zou, Jian-Guang Lou, Bing Xie",http://arxiv.org/pdf/2412.14905v1,cs.CL
Theoretical Proof that Auto-regressive Language Models Collapse when Real-world Data is a Finite Set,"Auto-regressive language models (LMs) have been widely used to generate data
in data-scarce domains to train new LMs, compensating for the scarcity of
real-world data. Previous work experimentally found that LMs collapse when
trained on recursively generated data. This paper presents a theoretical proof:
once a corpus (such as a subset of the World Wide Web) begins to incorporate
generated data and no new real-world data is added to the corpus, then no
matter how small the amount of data each LM generates and contributes to the
corpus, LM collapse is inevitable after sufficient time. This finding suggests
that attempts to mitigate collapse by limiting the quantity of synthetic data
in the corpus are fundamentally insufficient. Instead, avoiding collapse hinges
on ensuring the quality of synthetic data.",2024-12-19,"Lecheng Wang, Xianjie Shi, Ge Li, Jia Li, Xuanming Zhang, Yihong Dong, Wenpin Jiao, Hong Mei",http://arxiv.org/pdf/2412.14872v3,cs.CL
Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering,"Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.",2024-12-19,"Imed Keraghel, Mohamed Nadif",http://arxiv.org/pdf/2412.14867v1,cs.CL
Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling,"Despite their outstanding capabilities, large language models (LLMs) are
prone to hallucination and producing factually incorrect information. This
challenge has spurred efforts in attributed text generation, which prompts LLMs
to generate content with supporting evidence. In this paper, we propose a novel
framework, called Think&Cite, and formulate attributed text generation as a
multi-step reasoning problem integrated with search. Specifically, we propose
Self-Guided Monte Carlo Tree Search (SG-MCTS), which capitalizes on the
self-reflection capability of LLMs to reflect on the intermediate states of
MCTS for guiding the tree expansion process. To provide reliable and
comprehensive feedback, we introduce Progress Reward Models to measure the
progress of tree search from the root to the current state from two aspects,
i.e., generation and attribution progress. We conduct extensive experiments on
three datasets and the results show that our approach significantly outperforms
baseline approaches.",2024-12-19,"Junyi Li, Hwee Tou Ng",http://arxiv.org/pdf/2412.14860v1,cs.CL
Conceptual In-Context Learning and Chain of Concepts: Solving Complex Conceptual Problems Using Large Language Models,"Science and engineering problems fall in the category of complex conceptual
problems that require specific conceptual information (CI) like math/logic
-related know-how, process information, or engineering guidelines to solve
them. Large Language Models (LLMs) are promising agents to solve such complex
conceptual problems due to their implications in advancing engineering and
science tasks like assisted problem-solving. But vanilla LLMs, trained on
open-world data, lack the necessary CI. In this work, we specifically explore
shallow customization methods (SCMs) of LLMs for solving complex conceptual
problems. We propose two novel SCM algorithms for LLM, to augment LLMs with CI
and enable LLMs to solve complex conceptual problems: Conceptual In-Context
Learning (C-ICL) and Chain of Concepts (CoC). The problem tackled in this paper
is generation of proprietary data models in the engineering/industry domain
based on conceptual information in data modelling guidelines. We evaluate our
algorithms on varied sizes of the OpenAI LLMs against four evaluation metrics
related to syntactic and semantic correctness, time and cost incurred. The
proposed algorithms perform better than currently popular LLM SCMs like
In-context Learning (ICL) and Chain of Thoughts (CoT). It was observed that as
compared to CoT, response correctness increased by 30.6% and 29.88% for the new
SCMs C-ICL and CoC respectively. Qualitative analysis suggests that the
proposed new SCMs activate emergent capabilities in LLMs, previously unobserved
in the existing SCMs. They make problem-solving processes more transparent and
reduce hallucinations and the tendency of model responses to copy examples from
prompts (parroting).",2024-12-19,"Nishtha N. Vaidya, Thomas Runkler, Thomas Hubauer, Veronika Haderlein-Hoegberg, Maja Mlicic Brandt",http://arxiv.org/pdf/2412.15309v1,cs.CL
ViFactCheck: A New Benchmark Dataset and Methods for Multi-domain News Fact-Checking in Vietnamese,"The rapid spread of information in the digital age highlights the critical
need for effective fact-checking tools, particularly for languages with limited
resources, such as Vietnamese. In response to this challenge, we introduce
ViFactCheck, the first publicly available benchmark dataset designed
specifically for Vietnamese fact-checking across multiple online news domains.
This dataset contains 7,232 human-annotated pairs of claim-evidence
combinations sourced from reputable Vietnamese online news, covering 12 diverse
topics. It has been subjected to a meticulous annotation process to ensure high
quality and reliability, achieving a Fleiss Kappa inter-annotator agreement
score of 0.83. Our evaluation leverages state-of-the-art pre-trained and large
language models, employing fine-tuning and prompting techniques to assess
performance. Notably, the Gemma model demonstrated superior effectiveness, with
an impressive macro F1 score of 89.90%, thereby establishing a new standard for
fact-checking benchmarks. This result highlights the robust capabilities of
Gemma in accurately identifying and verifying facts in Vietnamese. To further
promote advances in fact-checking technology and improve the reliability of
digital media, we have made the ViFactCheck dataset, model checkpoints,
fact-checking pipelines, and source code freely available on GitHub. This
initiative aims to inspire further research and enhance the accuracy of
information in low-resource languages.",2024-12-19,"Tran Thai Hoa, Tran Quang Duy, Khanh Quoc Tran, Kiet Van Nguyen",http://arxiv.org/pdf/2412.15308v1,cs.CL
DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis,"Recently developed large language models (LLMs) have presented promising new
avenues to address data scarcity in low-resource scenarios. In few-shot
aspect-based sentiment analysis (ABSA), previous efforts have explored data
augmentation techniques, which prompt LLMs to generate new samples by modifying
existing ones. However, these methods fail to produce adequately diverse data,
impairing their effectiveness. Besides, some studies apply in-context learning
for ABSA by using specific instructions and a few selected examples as prompts.
Though promising, LLMs often yield labels that deviate from task requirements.
To overcome these limitations, we propose DS$^2$-ABSA, a dual-stream data
synthesis framework targeted for few-shot ABSA. It leverages LLMs to synthesize
data from two complementary perspectives: \textit{key-point-driven} and
\textit{instance-driven}, which effectively generate diverse and high-quality
ABSA samples in low-resource settings. Furthermore, a \textit{label refinement}
module is integrated to improve the synthetic labels. Extensive experiments
demonstrate that DS$^2$-ABSA significantly outperforms previous few-shot ABSA
solutions and other LLM-oriented data generation methods.",2024-12-19,"Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu",http://arxiv.org/pdf/2412.14849v1,cs.CL
A Survey of RWKV,"The Receptance Weighted Key Value (RWKV) model offers a novel alternative to
the Transformer architecture, merging the benefits of recurrent and
attention-based systems. Unlike conventional Transformers, which depend heavily
on self-attention, RWKV adeptly captures long-range dependencies with minimal
computational demands. By utilizing a recurrent framework, RWKV addresses some
computational inefficiencies found in Transformers, particularly in tasks with
long sequences. RWKV has recently drawn considerable attention for its robust
performance across multiple domains. Despite its growing popularity, no
systematic review of the RWKV model exists. This paper seeks to fill this gap
as the first comprehensive review of the RWKV architecture, its core
principles, and its varied applications, such as natural language generation,
natural language understanding, and computer vision. We assess how RWKV
compares to traditional Transformer models, highlighting its capability to
manage long sequences efficiently and lower computational costs. Furthermore,
we explore the challenges RWKV encounters and propose potential directions for
future research and advancement. We consistently maintain the related
open-source materials at: https://github.com/MLGroupJLU/RWKV-Survey.",2024-12-19,"Zhiyuan Li, Tingyu Xia, Yi Chang, Yuan Wu",http://arxiv.org/pdf/2412.14847v2,cs.CL
Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas,"The analysis of political biases in large language models (LLMs) has
primarily examined these systems as single entities with fixed viewpoints.
While various methods exist for measuring such biases, the impact of
persona-based prompting on LLMs' political orientation remains unexplored. In
this work we leverage PersonaHub, a collection of synthetic persona
descriptions, to map the political distribution of persona-based prompted LLMs
using the Political Compass Test (PCT). We then examine whether these initial
compass distributions can be manipulated through explicit ideological prompting
towards diametrically opposed political orientations: right-authoritarian and
left-libertarian. Our experiments reveal that synthetic personas predominantly
cluster in the left-libertarian quadrant, with models demonstrating varying
degrees of responsiveness when prompted with explicit ideological descriptors.
While all models demonstrate significant shifts towards right-authoritarian
positions, they exhibit more limited shifts towards left-libertarian positions,
suggesting an asymmetric response to ideological manipulation that may reflect
inherent biases in model training.",2024-12-19,"Pietro Bernardelle, Leon Fröhling, Stefano Civelli, Riccardo Lunardi, Kevin Roitero, Gianluca Demartini",http://arxiv.org/pdf/2412.14843v3,cs.CL
DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs,"Efficient KV cache management in LLMs is crucial for long-context tasks like
RAG and summarization. Existing KV cache compression methods enforce a fixed
pattern, neglecting task-specific characteristics and reducing the retention of
essential information. However, we observe distinct activation patterns across
layers in various tasks, highlighting the need for adaptive strategies tailored
to each task's unique demands. Based on this insight, we propose DynamicKV, a
method that dynamically optimizes token retention by adjusting the number of
tokens retained at each layer to adapt to the specific task. DynamicKV
establishes global and per-layer maximum KV cache budgets, temporarily
retaining the maximum budget for the current layer, and periodically updating
the KV cache sizes of all preceding layers during inference. Our method retains
only 1.7% of the KV cache size while achieving ~85% of the Full KV cache
performance on LongBench. Notably, even under extreme compression (0.9%),
DynamicKV surpasses state-of-the-art (SOTA) methods by 11% in the
Needle-in-a-Haystack test using Mistral-7B-Instruct-v0.2. The code will be
released.",2024-12-19,"Xiabin Zhou, Wenbin Wang, Minyan Zeng, Jiaxian Guo, Xuebo Liu, Li Shen, Min Zhang, Liang Ding",http://arxiv.org/pdf/2412.14838v3,cs.CL
Progressive Multimodal Reasoning via Active Retrieval,"Multi-step multimodal reasoning tasks pose significant challenges for
multimodal large language models (MLLMs), and finding effective ways to enhance
their performance in such scenarios remains an unresolved issue. In this paper,
we propose AR-MCTS, a universal framework designed to progressively improve the
reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo
Tree Search (MCTS). Our approach begins with the development of a unified
retrieval module that retrieves key supporting insights for solving complex
reasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in
automated multimodal reasoning verification, we employ the MCTS algorithm
combined with an active retrieval mechanism, which enables the automatic
generation of step-wise annotations. This strategy dynamically retrieves key
insights for each reasoning step, moving beyond traditional beam search
sampling to improve the diversity and reliability of the reasoning space.
Additionally, we introduce a process reward model that aligns progressively to
support the automatic verification of multimodal reasoning tasks. Experimental
results across three complex multimodal reasoning benchmarks confirm the
effectiveness of the AR-MCTS framework in enhancing the performance of various
multimodal models. Further analysis demonstrates that AR-MCTS can optimize
sampling diversity and accuracy, yielding reliable multimodal reasoning.",2024-12-19,"Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen",http://arxiv.org/pdf/2412.14835v1,cs.CL
Mention Attention for Pronoun Translation,"Most pronouns are referring expressions, computers need to resolve what do
the pronouns refer to, and there are divergences on pronoun usage across
languages. Thus, dealing with these divergences and translating pronouns is a
challenge in machine translation. Mentions are referring candidates of pronouns
and have closer relations with pronouns compared to general tokens. We assume
that extracting additional mention features can help pronoun translation.
Therefore, we introduce an additional mention attention module in the decoder
to pay extra attention to source mentions but not non-mention tokens. Our
mention attention module not only extracts features from source mentions, but
also considers target-side context which benefits pronoun translation. In
addition, we also introduce two mention classifiers to train models to
recognize mentions, whose outputs guide the mention attention. We conduct
experiments on the WMT17 English-German translation task, and evaluate our
models on general translation and pronoun translation, using BLEU, APT, and
contrastive evaluation metrics. Our proposed model outperforms the baseline
Transformer model in terms of APT and BLEU scores, this confirms our hypothesis
that we can improve pronoun translation by paying additional attention to
source mentions, and shows that our introduced additional modules do not have
negative effect on the general translation quality.",2024-12-19,"Gongbo Tang, Christian Hardmeier",http://arxiv.org/pdf/2412.14829v1,cs.CL
ResoFilter: Fine-grained Synthetic Data Filtering for Large Language Models through Data-Parameter Resonance Analysis,"Large language models (LLMs) have shown remarkable effectiveness across
various domains, with data augmentation methods utilizing GPT for synthetic
data generation becoming prevalent. However, the quality and utility of
augmented data remain questionable, and current methods lack clear metrics for
evaluating data characteristics. To address these challenges, we propose
ResoFilter, a novel method that integrates models, data, and tasks to refine
datasets. ResoFilter leverages the fine-tuning process to obtain Data-Parameter
features for data selection, offering improved interpretability by representing
data characteristics through model weights. Our experiments demonstrate that
ResoFilter achieves comparable results to full-scale fine-tuning using only
half the data in mathematical tasks and exhibits strong generalization across
different models and domains. This method provides valuable insights for
constructing synthetic datasets and evaluating high-quality data, offering a
promising solution for enhancing data augmentation techniques and improving
training dataset quality for LLMs. For reproducibility, we will release our
code and data upon acceptance.",2024-12-19,"Zeao Tu, Xiangdi Meng, Yu He, Zihan Yao, Tianyu Qi, Jun Liu, Ming Li",http://arxiv.org/pdf/2412.14809v3,cs.CL
Self-Evolution Knowledge Distillation for LLM-based Machine Translation,"Knowledge distillation (KD) has shown great promise in transferring knowledge
from larger teacher models to smaller student models. However, existing KD
strategies for large language models often minimize output distributions
between student and teacher models indiscriminately for each token. This
overlooks the imbalanced nature of tokens and their varying transfer
difficulties. In response, we propose a distillation strategy called
Self-Evolution KD. The core of this approach involves dynamically integrating
teacher distribution and one-hot distribution of ground truth into the student
distribution as prior knowledge, which promotes the distillation process. It
adjusts the ratio of prior knowledge based on token learning difficulty, fully
leveraging the teacher model's potential. Experimental results show our method
brings an average improvement of approximately 1.4 SacreBLEU points across four
translation directions in the WMT22 test sets. Further analysis indicates that
the improvement comes from better knowledge transfer from teachers, confirming
our hypothesis.",2024-12-19,"Yuncheng Song, Liang Ding, Changtong Zan, Shujian Huang",http://arxiv.org/pdf/2412.15303v1,cs.CL
Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning,"When using agent-task datasets to enhance agent capabilities for Large
Language Models (LLMs), current methodologies often treat all tokens within a
sample equally. However, we argue that tokens serving different roles -
specifically, reasoning tokens versus boilerplate tokens (e.g., those governing
output format) - differ significantly in importance and learning complexity,
necessitating their disentanglement and distinct treatment. To address this, we
propose a novel Shuffle-Aware Discriminator (SHAD) for adaptive token
discrimination. SHAD classifies tokens by exploiting predictability differences
observed after shuffling input-output combinations across samples: boilerplate
tokens, due to their repetitive nature among samples, maintain predictability,
whereas reasoning tokens do not. Using SHAD, we propose the
Reasoning-highlighted Fine-Tuning (RFT) method, which adaptively emphasizes
reasoning tokens during fine-tuning, yielding notable performance gains over
common Supervised Fine-Tuning (SFT).",2024-12-19,"Ziang Ye, Zhenru Zhang, Yang Zhang, Jianxin Ma, Junyang Lin, Fuli Feng",http://arxiv.org/pdf/2412.14780v1,cs.CL
ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine,"Large Language Models (LLMs) have demonstrated remarkable potential in
diverse domains, yet their application in the legal sector, particularly in
low-resource contexts, remains limited. This study addresses the challenges of
adapting LLMs to the Palestinian legal domain, where political instability,
fragmented legal frameworks, and limited AI resources hinder effective
machine-learning applications. We present a fine-tuned model based on a
quantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set
derived from Palestinian legal texts. Using smaller-scale models and
strategically generated question-answer pairs, we achieve a cost-effective,
locally sustainable solution that provides accurate and contextually relevant
legal guidance. Our experiments demonstrate promising performance on various
query types, ranging from yes/no questions and narrative explanations to
complex legal differentiations, while highlighting areas for improvement, such
as handling calculation-based inquiries and structured list formatting. This
work provides a pathway for the deployment of AI-driven legal assistance tools
tailored to the needs of resource-constrained environments.",2024-12-19,"Rabee Qasem, Mohannad Hendi, Banan Tantour",http://arxiv.org/pdf/2412.14771v1,cs.CL
PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in Left-Behind Children,"Left-behind children (LBCs), numbering over 66 million in China, face severe
mental health challenges due to parental migration for work. Early screening
and identification of at-risk LBCs is crucial, yet challenging due to the
severe shortage of mental health professionals, especially in rural areas.
While the House-Tree-Person (HTP) test shows higher child participation rates,
its requirement for expert interpretation limits its application in
resource-scarce regions. To address this challenge, we propose PsyDraw, a
multi-agent system based on Multimodal Large Language Models that assists
mental health professionals in analyzing HTP drawings. The system employs
specialized agents for feature extraction and psychological interpretation,
operating in two stages: comprehensive feature analysis and professional report
generation. Evaluation of HTP drawings from 290 primary school students reveals
that 71.03% of the analyzes achieved High Consistency with professional
evaluations, 26.21% Moderate Consistency and only 2.41% Low Consistency. The
system identified 31.03% of cases requiring professional attention,
demonstrating its effectiveness as a preliminary screening tool. Currently
deployed in pilot schools, \method shows promise in supporting mental health
professionals, particularly in resource-limited areas, while maintaining high
professional standards in psychological assessment.",2024-12-19,"Yiqun Zhang, Xiaocui Yang, Xiaobai Li, Siyuan Yu, Yi Luan, Shi Feng, Daling Wang, Yifei Zhang",http://arxiv.org/pdf/2412.14769v1,cs.CL
Query pipeline optimization for cancer patient question answering systems,"Retrieval-augmented generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by using query pipelines to retrieve relevant external
information and grounding responses in retrieved knowledge. However, query
pipeline optimization for cancer patient question-answering (CPQA) systems
requires separately optimizing multiple components with domain-specific
considerations. We propose a novel three-aspect optimization approach for the
RAG query pipeline in CPQA systems, utilizing public biomedical databases like
PubMed and PubMed Central. Our optimization includes: (1) document retrieval,
utilizing a comparative analysis of NCBI resources and introducing Hybrid
Semantic Real-time Document Retrieval (HSRDR); (2) passage retrieval,
identifying optimal pairings of dense retrievers and rerankers; and (3)
semantic representation, introducing Semantic Enhanced Overlap Segmentation
(SEOS) for improved contextual understanding. On a custom-developed dataset
tailored for cancer-related inquiries, our optimized RAG approach improved the
answer accuracy of Claude-3-haiku by 5.24% over chain-of-thought prompting and
about 3% over a naive RAG setup. This study highlights the importance of
domain-specific query optimization in realizing the full potential of RAG and
provides a robust framework for building more accurate and reliable CPQA
systems, advancing the development of RAG-based biomedical systems.",2024-12-19,"Maolin He, Rena Gao, Mike Conway, Brian E. Chapman",http://arxiv.org/pdf/2412.14751v1,cs.CL
On Verbalized Confidence Scores for LLMs,"The rise of large language models (LLMs) and their tight integration into our
daily life make it essential to dedicate efforts towards their trustworthiness.
Uncertainty quantification for LLMs can establish more human trust into their
responses, but also allows LLM agents to make more informed decisions based on
each other's uncertainty. To estimate the uncertainty in a response, internal
token logits, task-specific proxy models, or sampling of multiple responses are
commonly used. This work focuses on asking the LLM itself to verbalize its
uncertainty with a confidence score as part of its output tokens, which is a
promising way for prompt- and model-agnostic uncertainty quantification with
low overhead. Using an extensive benchmark, we assess the reliability of
verbalized confidence scores with respect to different datasets, models, and
prompt methods. Our results reveal that the reliability of these scores
strongly depends on how the model is asked, but also that it is possible to
extract well-calibrated confidence scores with certain prompt methods. We argue
that verbalized confidence scores can become a simple but effective and
versatile uncertainty quantification method in the future. Our code is
available at https://github.com/danielyxyang/llm-verbalized-uq .",2024-12-19,"Daniel Yang, Yao-Hung Hubert Tsai, Makoto Yamada",http://arxiv.org/pdf/2412.14737v1,cs.CL
LAMA-UT: Language Agnostic Multilingual ASR through Orthography Unification and Language-Specific Transliteration,"Building a universal multilingual automatic speech recognition (ASR) model
that performs equitably across languages has long been a challenge due to its
inherent difficulties. To address this task we introduce a Language-Agnostic
Multilingual ASR pipeline through orthography Unification and language-specific
Transliteration (LAMA-UT). LAMA-UT operates without any language-specific
modules while matching the performance of state-of-the-art models trained on a
minimal amount of data. Our pipeline consists of two key steps. First, we
utilize a universal transcription generator to unify orthographic features into
Romanized form and capture common phonetic characteristics across diverse
languages. Second, we utilize a universal converter to transform these
universal transcriptions into language-specific ones. In experiments, we
demonstrate the effectiveness of our proposed method leveraging universal
transcriptions for massively multilingual ASR. Our pipeline achieves a relative
error reduction rate of 45% when compared to Whisper and performs comparably to
MMS, despite being trained on only 0.1% of Whisper's training data.
Furthermore, our pipeline does not rely on any language-specific modules.
However, it performs on par with zero-shot ASR approaches which utilize
additional language-specific lexicons and language models. We expect this
framework to serve as a cornerstone for flexible multilingual ASR systems that
are generalizable even to unseen languages.",2024-12-19,"Sangmin Lee, Woo-Jin Chung, Hong-Goo Kang",http://arxiv.org/pdf/2412.15299v2,cs.CL
A Comparative Study of DSPy Teleprompter Algorithms for Aligning Large Language Models Evaluation Metrics to Human Evaluation,"We argue that the Declarative Self-improving Python (DSPy) optimizers are a
way to align the large language model (LLM) prompts and their evaluations to
the human annotations. We present a comparative analysis of five teleprompter
algorithms, namely, Cooperative Prompt Optimization (COPRO), Multi-Stage
Instruction Prompt Optimization (MIPRO), BootstrapFewShot, BootstrapFewShot
with Optuna, and K-Nearest Neighbor Few Shot, within the DSPy framework with
respect to their ability to align with human evaluations. As a concrete
example, we focus on optimizing the prompt to align hallucination detection
(using LLM as a judge) to human annotated ground truth labels for a publicly
available benchmark dataset. Our experiments demonstrate that optimized prompts
can outperform various benchmark methods to detect hallucination, and certain
telemprompters outperform the others in at least these experiments.",2024-12-19,"Bhaskarjit Sarmah, Kriti Dutta, Anna Grigoryan, Sachin Tiwari, Stefano Pasquali, Dhagash Mehta",http://arxiv.org/pdf/2412.15298v1,cs.CL
Confidence in the Reasoning of Large Language Models,"There is a growing literature on reasoning by large language models (LLMs),
but the discussion on the uncertainty in their responses is still lacking. Our
aim is to assess the extent of confidence that LLMs have in their answers and
how it correlates with accuracy. Confidence is measured (i) qualitatively in
terms of persistence in keeping their answer when prompted to reconsider, and
(ii) quantitatively in terms of self-reported confidence score. We investigate
the performance of three LLMs -- GPT4o, GPT4-turbo and Mistral -- on two
benchmark sets of questions on causal judgement and formal fallacies and a set
of probability and statistical puzzles and paradoxes. Although the LLMs show
significantly better performance than random guessing, there is a wide
variability in their tendency to change their initial answers. There is a
positive correlation between qualitative confidence and accuracy, but the
overall accuracy for the second answer is often worse than for the first
answer. There is a strong tendency to overstate the self-reported confidence
score. Confidence is only partially explained by the underlying token-level
probability. The material effects of prompting on qualitative confidence and
the strong tendency for overconfidence indicate that current LLMs do not have
any internally coherent sense of confidence.",2024-12-19,"Yudi Pawitan, Chris Holmes",http://arxiv.org/pdf/2412.15296v1,cs.CL
How to Synthesize Text Data without Model Collapse?,"Model collapse in synthetic data indicates that iterative training on
self-generated data leads to a gradual decline in performance. With the
proliferation of AI models, synthetic data will fundamentally reshape the web
data ecosystem. Future GPT-$\{n\}$ models will inevitably be trained on a blend
of synthetic and human-produced data. In this paper, we focus on two questions:
what is the impact of synthetic data on language model training, and how to
synthesize data without model collapse? We first pre-train language models
across different proportions of synthetic data, revealing a negative
correlation between the proportion of synthetic data and model performance. We
further conduct statistical analysis on synthetic data to uncover
distributional shift phenomenon and over-concentration of n-gram features.
Inspired by the above findings, we propose token editing on human-produced data
to obtain semi-synthetic data. As a proof of concept, we theoretically
demonstrate that token-level editing can prevent model collapse, as the test
error is constrained by a finite upper bound. We conduct extensive experiments
on pre-training from scratch, continual pre-training, and supervised
fine-tuning. The results validate our theoretical proof that token-level
editing improves model performance.",2024-12-19,"Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, Zhouhan Lin, Zilong Zheng, Bowen Zhou",http://arxiv.org/pdf/2412.14689v2,cs.CL
Beyond the Sum: Unlocking AI Agents Potential Through Market Forces,"The emergence of Large Language Models has fundamentally transformed the
capabilities of AI agents, enabling a new class of autonomous agents capable of
interacting with their environment through dynamic code generation and
execution. These agents possess the theoretical capacity to operate as
independent economic actors within digital markets, offering unprecedented
potential for value creation through their distinct advantages in operational
continuity, perfect replication, and distributed learning capabilities.
However, contemporary digital infrastructure, architected primarily for human
interaction, presents significant barriers to their participation.
  This work presents a systematic analysis of the infrastructure requirements
necessary for AI agents to function as autonomous participants in digital
markets. We examine four key areas - identity and authorization, service
discovery, interfaces, and payment systems - to show how existing
infrastructure actively impedes agent participation. We argue that addressing
these infrastructure challenges represents more than a technical imperative; it
constitutes a fundamental step toward enabling new forms of economic
organization. Much as traditional markets enable human intelligence to
coordinate complex activities beyond individual capability, markets
incorporating AI agents could dramatically enhance economic efficiency through
continuous operation, perfect information sharing, and rapid adaptation to
changing conditions. The infrastructure challenges identified in this work
represent key barriers to realizing this potential.",2024-12-19,"Jordi Montes Sanabria, Pol Alvarez Vecino",http://arxiv.org/pdf/2501.10388v2,cs.CL
Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection,"Social platforms, while facilitating access to information, have also become
saturated with a plethora of fake news, resulting in negative consequences.
Automatic multimodal fake news detection is a worthwhile pursuit. Existing
multimodal fake news datasets only provide binary labels of real or fake.
However, real news is alike, while each fake news is fake in its own way. These
datasets fail to reflect the mixed nature of various types of multimodal fake
news. To bridge the gap, we construct an attributing multi-granularity
multimodal fake news detection dataset \amg, revealing the inherent fake
pattern. Furthermore, we propose a multi-granularity clue alignment model \our
to achieve multimodal fake news detection and attribution. Experimental results
demonstrate that \amg is a challenging dataset, and its attribution setting
opens up new avenues for future research.",2024-12-19,"Hao Guo, Zihan Ma, Zhi Zeng, Minnan Luo, Weixin Zeng, Jiuyang Tang, Xiang Zhao",http://arxiv.org/pdf/2412.14686v1,cs.CL
LLMs as mediators: Can they diagnose conflicts accurately?,"Prior research indicates that to be able to mediate conflict, observers of
disagreements between parties must be able to reliably distinguish the sources
of their disagreement as stemming from differences in beliefs about what is
true (causality) vs. differences in what they value (morality). In this paper,
we test if OpenAI's Large Language Models GPT 3.5 and GPT 4 can perform this
task and whether one or other type of disagreement proves particularly
challenging for LLM's to diagnose. We replicate study 1 in Ko\c{c}ak et al.
(2003), which employes a vignette design, with OpenAI's GPT 3.5 and GPT 4. We
find that both LLMs have similar semantic understanding of the distinction
between causal and moral codes as humans and can reliably distinguish between
them. When asked to diagnose the source of disagreement in a conversation, both
LLMs, compared to humans, exhibit a tendency to overestimate the extent of
causal disagreement and underestimate the extent of moral disagreement in the
moral misalignment condition. This tendency is especially pronounced for GPT 4
when using a proximate scale that relies on concrete language specific to an
issue. GPT 3.5 does not perform as well as GPT4 or humans when using either the
proximate or the distal scale. The study provides a first test of the potential
for using LLMs to mediate conflict by diagnosing the root of disagreements in
causal and evaluative codes.",2024-12-19,"Özgecan Koçak, Phanish Puranam, Afşar Yegin",http://arxiv.org/pdf/2412.14675v1,cs.CL
Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT,"This study investigates the internal representations of verb-particle
combinations within transformer-based large language models (LLMs),
specifically examining how these models capture lexical and syntactic nuances
at different neural network layers. Employing the BERT architecture, we analyse
the representational efficacy of its layers for various verb-particle
constructions such as 'agree on', 'come back', and 'give up'. Our methodology
includes a detailed dataset preparation from the British National Corpus,
followed by extensive model training and output analysis through techniques
like multi-dimensional scaling (MDS) and generalized discrimination value (GDV)
calculations. Results show that BERT's middle layers most effectively capture
syntactic structures, with significant variability in representational accuracy
across different verb categories. These findings challenge the conventional
uniformity assumed in neural network processing of linguistic elements and
suggest a complex interplay between network architecture and linguistic
representation. Our research contributes to a better understanding of how deep
learning models comprehend and process language, offering insights into the
potential and limitations of current neural approaches to linguistic analysis.
This study not only advances our knowledge in computational linguistics but
also prompts further research into optimizing neural architectures for enhanced
linguistic precision.",2024-12-19,"Hassane Kissane, Achim Schilling, Patrick Krauss",http://arxiv.org/pdf/2412.14670v1,cs.CL
Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models,"Multimodal large language models (MLLMs) combine visual and textual data for
tasks such as image captioning and visual question answering. Proper
uncertainty calibration is crucial, yet challenging, for reliable use in areas
like healthcare and autonomous driving. This paper investigates representative
MLLMs, focusing on their calibration across various scenarios, including before
and after visual fine-tuning, as well as before and after multimodal training
of the base LLMs. We observed miscalibration in their performance, and at the
same time, no significant differences in calibration across these scenarios. We
also highlight how uncertainty differs between text and images and how their
integration affects overall uncertainty. To better understand MLLMs'
miscalibration and their ability to self-assess uncertainty, we construct the
IDK (I don't know) dataset, which is key to evaluating how they handle
unknowns. Our findings reveal that MLLMs tend to give answers rather than admit
uncertainty, but this self-assessment improves with proper prompt adjustments.
Finally, to calibrate MLLMs and enhance model reliability, we propose
techniques such as temperature scaling and iterative prompt optimization. Our
results provide insights into improving MLLMs for effective and responsible
deployment in multimodal applications. Code and IDK dataset:
https://github.com/hfutml/Calibration-MLLM.",2024-12-19,"Zijun Chen, Wenbo Hu, Guande He, Zhijie Deng, Zheng Zhang, Richang Hong",http://arxiv.org/pdf/2412.14660v2,cs.CL
Length Controlled Generation for Black-box LLMs,"Large language models (LLMs) have demonstrated impressive instruction
following capabilities, while still struggling to accurately manage the length
of the generated text, which is a fundamental requirement in many real-world
applications. Existing length control methods involve fine-tuning the
parameters of LLMs, which is inefficient and suboptimal for practical use. In
this paper, we propose a novel iterative sampling framework for text length
control, integrating the Metropolis-Hastings algorithm with an importance
sampling acceleration strategy. This framework efficiently and reliably
regulates LLMs to generate length-constrained text without modifying the
underlying parameters, thereby preserving the original capabilities of LLMs.
Experimental results demonstrate that our framework achieves almost 100\%
success rates of length control on Llama3.1 for tasks such as length-controlled
abstractive summarization and length-constrained instruction following, with
minimal additional computational overhead. This also highlights the significant
potential of our method for precise length control across a broader range of
applications, without compromising the versatility of LLMs.",2024-12-19,"Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, Kun Zhu, Lei Huang, Tat-Seng Chua, Bing Qin",http://arxiv.org/pdf/2412.14656v1,cs.CL
TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation,"In this paper, we propose Text-based Open Molecule Generation Benchmark
(TOMG-Bench), the first benchmark to evaluate the open-domain molecule
generation capability of LLMs. TOMG-Bench encompasses a dataset of three major
tasks: molecule editing (MolEdit), molecule optimization (MolOpt), and
customized molecule generation (MolCustom). Each major task further contains
three subtasks, while each subtask comprises 5,000 test samples. Given the
inherent complexity of open molecule generation evaluation, we also developed
an automated evaluation system that helps measure both the quality and the
accuracy of the generated molecules. Our comprehensive benchmarking of 25 LLMs
reveals the current limitations as well as potential areas for improvement in
text-guided molecule discovery. Furthermore, we propose OpenMolIns, a
specialized instruction tuning dataset established for solving challenges
raised by TOMG-Bench. Fine-tuned on OpenMolIns, Llama3.1-8B could outperform
all the open-source general LLMs, even surpassing GPT-3.5-turbo by 46.5\% on
TOMG-Bench. Our codes and datasets are available through
https://github.com/phenixace/TOMG-Bench.",2024-12-19,"Jiatong Li, Junxian Li, Yunqing Liu, Dongzhan Zhou, Qing Li",http://arxiv.org/pdf/2412.14642v2,cs.CL
Learning to Generate Research Idea with Dynamic Control,"The rapid advancements in large language models (LLMs) have demonstrated
their potential to accelerate scientific discovery, particularly in automating
the process of research ideation. LLM-based systems have shown promise in
generating hypotheses and research ideas. However, current approaches
predominantly rely on prompting-based pre-trained models, limiting their
ability to optimize generated content effectively. Moreover, they also lack the
capability to deal with the complex interdependence and inherent restrictions
among novelty, feasibility, and effectiveness, which remains challenging due to
the inherent trade-offs among these dimensions, such as the
innovation-feasibility conflict. To address these limitations, we for the first
time propose fine-tuning LLMs to be better idea proposers and introduce a novel
framework that employs a two-stage approach combining Supervised Fine-Tuning
(SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model
learns foundational patterns from pairs of research papers and follow-up ideas.
In the RL stage, multi-dimensional reward modeling, guided by fine-grained
feedback, evaluates and optimizes the generated ideas across key metrics.
Dimensional controllers enable dynamic adjustment of generation, while a
sentence-level decoder ensures context-aware emphasis during inference. Our
framework provides a balanced approach to research ideation, achieving
high-quality outcomes by dynamically navigating the trade-offs among novelty,
feasibility, and effectiveness.",2024-12-19,"Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, Xinya Du",http://arxiv.org/pdf/2412.14626v1,cs.CL
How good is GPT at writing political speeches for the White House?,"Using large language models (LLMs), computers are able to generate a written
text in response to a us er request. As this pervasive technology can be
applied in numerous contexts, this study analyses the written style of one LLM
called GPT by comparing its generated speeches with those of the recent US
presidents. To achieve this objective, the State of the Union (SOTU) addresses
written by Reagan to Biden are contrasted to those produced by both GPT-3.5 and
GPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma
""we"" and produce shorter messages with, on average, longer sentences. Moreover,
GPT opts for an optimistic tone, opting more often for political (e.g.,
president, Congress), symbolic (e.g., freedom), and abstract terms (e.g.,
freedom). Even when imposing an author's style to GPT, the resulting speech
remains distinct from addresses written by the target author. Finally, the two
GPT versions present distinct characteristics, but both appear overall
dissimilar to true presidential messages.",2024-12-19,Jacques Savoy,http://arxiv.org/pdf/2412.14617v1,cs.CL
"Multi-modal, Multi-task, Multi-criteria Automatic Evaluation with Vision Language Models","Vision-language models (VLMs) have shown impressive abilities across a range
of multi-modal tasks. However, existing metrics for evaluating the quality of
text generated by VLMs typically focus on an overall evaluation for a specific
task, such as image captioning. While the overall evaluation is essential for
any task, the criteria prioritized can differ depending on the task, making it
challenging for current metrics to adapt to multi-task scenarios. To address
this limitation, we propose HarmonicEval, a reference-free comprehensive
evaluation metric that aggregates criterion-wise scores to produce the overall
score in a bottom-up manner. Furthermore, we construct the Multi-task
Multi-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert
human judgments across four multi-modal tasks. Our experiments demonstrate that
HarmonicEval achieves higher correlations with human judgments than
conventional metrics while providing numerical scores for each criterion.",2024-12-19,"Masanari Ohi, Masahiro Kaneko, Naoaki Okazaki, Nakamasa Inoue",http://arxiv.org/pdf/2412.14613v2,cs.CL
KARRIEREWEGE: A Large Scale Career Path Prediction Dataset,"Accurate career path prediction can support many stakeholders, like job
seekers, recruiters, HR, and project managers. However, publicly available data
and tools for career path prediction are scarce. In this work, we introduce
KARRIEREWEGE, a comprehensive, publicly available dataset containing over 500k
career paths, significantly surpassing the size of previously available
datasets. We link the dataset to the ESCO taxonomy to offer a valuable resource
for predicting career trajectories. To tackle the problem of free-text inputs
typically found in resumes, we enhance it by synthesizing job titles and
descriptions resulting in KARRIEREWEGE+. This allows for accurate predictions
from unstructured data, closely aligning with real-world application
challenges. We benchmark existing state-of-the-art (SOTA) models on our dataset
and a prior benchmark and observe improved performance and robustness,
particularly for free-text use cases, due to the synthesized data.",2024-12-19,"Elena Senger, Yuri Campbell, Rob van der Goot, Barbara Plank",http://arxiv.org/pdf/2412.14612v1,cs.CL
LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining,"Visual Information Extraction (VIE) plays a crucial role in the comprehension
of semi-structured documents, and several pre-trained models have been
developed to enhance performance. However, most of these works are monolingual
(usually English). Due to the extremely unbalanced quantity and quality of
pre-training corpora between English and other languages, few works can extend
to non-English scenarios. In this paper, we conduct systematic experiments to
show that vision and layout modality hold invariance among images with
different languages. If decoupling language bias from document images, a
vision-layout-based model can achieve impressive cross-lingual generalization.
Accordingly, we present a simple but effective multilingual training paradigm
LDP (Language Decoupled Pre-training) for better utilization of monolingual
pre-training data. Our proposed model LDM (Language Decoupled Model) is first
pre-trained on the language-independent data, where the language knowledge is
decoupled by a diffusion model, and then the LDM is fine-tuned on the
downstream languages. Extensive experiments show that the LDM outperformed all
SOTA multilingual pre-trained models, and also maintains competitiveness on
downstream monolingual/English benchmarks.",2024-12-19,"Huawen Shen, Gengluo Li, Jinwen Zhong, Yu Zhou",http://arxiv.org/pdf/2412.14596v1,cs.CL
Beyond Guilt: Legal Judgment Prediction with Trichotomous Reasoning,"In legal practice, judges apply the trichotomous dogmatics of criminal law,
sequentially assessing the elements of the offense, unlawfulness, and
culpability to determine whether an individual's conduct constitutes a crime.
Although current legal large language models (LLMs) show promising accuracy in
judgment prediction, they lack trichotomous reasoning capabilities due to the
absence of an appropriate benchmark dataset, preventing them from predicting
innocent outcomes. As a result, every input is automatically assigned a charge,
limiting their practical utility in legal contexts. To bridge this gap, we
introduce LJPIV, the first benchmark dataset for Legal Judgment Prediction with
Innocent Verdicts. Adhering to the trichotomous dogmatics, we extend three
widely-used legal datasets through LLM-based augmentation and manual
verification. Our experiments with state-of-the-art legal LLMs and novel
strategies that integrate trichotomous reasoning into zero-shot prompting and
fine-tuning reveal: (1) current legal LLMs have significant room for
improvement, with even the best models achieving an F1 score of less than 0.3
on LJPIV; and (2) our strategies notably enhance both in-domain and
cross-domain judgment prediction accuracy, especially for cases resulting in an
innocent verdict.",2024-12-19,"Kepu Zhang, Haoyue Yang, Xu Tang, Weijie Yu, Jun Xu",http://arxiv.org/pdf/2412.14588v2,cs.CL
A Large-Scale Simulation on Large Language Models for Decision-Making in Political Science,"While LLMs have demonstrated remarkable capabilities in text generation and
reasoning, their ability to simulate human decision-making -- particularly in
political contexts -- remains an open question. However, modeling voter
behavior presents unique challenges due to limited voter-level data, evolving
political landscapes, and the complexity of human reasoning. In this study, we
develop a theory-driven, multi-step reasoning framework that integrates
demographic, temporal and ideological factors to simulate voter decision-making
at scale. Using synthetic personas calibrated to real-world voter data, we
conduct large-scale simulations of recent U.S. presidential elections. Our
method significantly improves simulation accuracy while mitigating model
biases. We examine its robustness by comparing performance across different
LLMs. We further investigate the challenges and constraints that arise from
LLM-based political simulations. Our work provides both a scalable framework
for modeling political decision-making behavior and insights into the promise
and limitations of using LLMs in political science research.",2024-12-19,"Chenxiao Yu, Jinyi Ye, Yuangang Li, Zheng Li, Emilio Ferrara, Xiyang Hu, Yue Zhao",http://arxiv.org/pdf/2412.15291v4,cs.CL
Simulation-Free Hierarchical Latent Policy Planning for Proactive Dialogues,"Recent advancements in proactive dialogues have garnered significant
attention, particularly for more complex objectives (e.g. emotion support and
persuasion). Unlike traditional task-oriented dialogues, proactive dialogues
demand advanced policy planning and adaptability, requiring rich scenarios and
comprehensive policy repositories to develop such systems. However, existing
approaches tend to rely on Large Language Models (LLMs) for user simulation and
online learning, leading to biases that diverge from realistic scenarios and
result in suboptimal efficiency. Moreover, these methods depend on manually
defined, context-independent, coarse-grained policies, which not only incur
high expert costs but also raise concerns regarding their completeness. In our
work, we highlight the potential for automatically discovering policies
directly from raw, real-world dialogue records. To this end, we introduce a
novel dialogue policy planning framework, LDPP. It fully automates the process
from mining policies in dialogue records to learning policy planning.
Specifically, we employ a variant of the Variational Autoencoder to discover
fine-grained policies represented as latent vectors. After automatically
annotating the data with these latent policy labels, we propose an Offline
Hierarchical Reinforcement Learning (RL) algorithm in the latent space to
develop effective policy planning capabilities. Our experiments demonstrate
that LDPP outperforms existing methods on two proactive scenarios, even
surpassing ChatGPT with only a 1.8-billion-parameter LLM.",2024-12-19,"Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Yiheng Sun, Zerui Chen, Ming Liu, Bing Qin",http://arxiv.org/pdf/2412.14584v1,cs.CL
CORD: Balancing COnsistency and Rank Distillation for Robust Retrieval-Augmented Generation,"With the adoption of retrieval-augmented generation (RAG), large language
models (LLMs) are expected to ground their generation to the retrieved
contexts. Yet, this is hindered by position bias of LLMs, failing to evenly
attend to all contexts. Previous work has addressed this by synthesizing
contexts with perturbed positions of gold segment, creating a
position-diversified train set. We extend this intuition to propose consistency
regularization with augmentation and distillation. First, we augment each
training instance with its position perturbation to encourage consistent
predictions, regardless of ordering. We also distill behaviors of this pair,
although it can be counterproductive in certain RAG scenarios where the given
order from the retriever is crucial for generation quality. We thus propose
CORD, balancing COnsistency and Rank Distillation. CORD adaptively samples
noise-controlled perturbations from an interpolation space, ensuring both
consistency and respect for the rank prior. Empirical results show this balance
enables CORD to outperform consistently in diverse RAG benchmarks.",2024-12-19,"Youngwon Lee, Seung-won Hwang, Daniel Campos, Filip Graliński, Zhewei Yao, Yuxiong He",http://arxiv.org/pdf/2412.14581v1,cs.CL
Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models,"Large Language Models (LLMs) have shown exciting performance in listwise
passage ranking. Due to the limited input length, existing methods often adopt
the sliding window strategy. Such a strategy, though effective, is inefficient
as it involves repetitive and serialized processing, which usually re-evaluates
relevant passages multiple times. As a result, it incurs redundant API costs,
which are proportional to the number of inference tokens. The development of
long-context LLMs enables the full ranking of all passages within a single
inference, avoiding redundant API costs. In this paper, we conduct a
comprehensive study of long-context LLMs for ranking tasks in terms of
efficiency and effectiveness. Surprisingly, our experiments reveal that full
ranking with long-context LLMs can deliver superior performance in the
supervised fine-tuning setting with a huge efficiency improvement. Furthermore,
we identify two limitations of fine-tuning the full ranking model based on
existing methods: (1) sliding window strategy fails to produce a full ranking
list as a training label, and (2) the language modeling loss cannot emphasize
top-ranked passage IDs in the label. To alleviate these issues, we propose a
new complete listwise label construction approach and a novel importance-aware
learning objective for full ranking. Experiments show the superior performance
of our method over baselines. Our codes are available at
\url{https://github.com/8421BCD/fullrank}.",2024-12-19,"Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou",http://arxiv.org/pdf/2412.14574v1,cs.CL
CitaLaw: Enhancing LLM with Citations in Legal Domain,"In this paper, we propose CitaLaw, the first benchmark designed to evaluate
LLMs' ability to produce legally sound responses with appropriate citations.
CitaLaw features a diverse set of legal questions for both laypersons and
practitioners, paired with a comprehensive corpus of law articles and precedent
cases as a reference pool. This framework enables LLM-based systems to retrieve
supporting citations from the reference corpus and align these citations with
the corresponding sentences in their responses. Moreover, we introduce
syllogism-inspired evaluation methods to assess the legal alignment between
retrieved references and LLM-generated responses, as well as their consistency
with user questions. Extensive experiments on 2 open-domain and 7
legal-specific LLMs demonstrate that integrating legal references substantially
enhances response quality. Furthermore, our proposed syllogism-based evaluation
method exhibits strong agreement with human judgments.",2024-12-19,"Kepu Zhang, Weijie Yu, Sunhao Dai, Jun Xu",http://arxiv.org/pdf/2412.14556v2,cs.CL
SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage,"Large language models (LLMs) have made significant advancements across
various tasks, but their safety alignment remain a major concern. Exploring
jailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure
them. Existing methods primarily design sophisticated instructions for the LLM
to follow, or rely on multiple iterations, which could hinder the performance
and efficiency of jailbreaks. In this work, we propose a novel jailbreak
paradigm, Simple Assistive Task Linkage (SATA), which can effectively
circumvent LLM safeguards and elicit harmful responses. Specifically, SATA
first masks harmful keywords within a malicious query to generate a relatively
benign query containing one or multiple [MASK] special tokens. It then employs
a simple assistive task such as a masked language model task or an element
lookup by position task to encode the semantics of the masked keywords.
Finally, SATA links the assistive task with the masked query to jointly perform
the jailbreak. Extensive experiments show that SATA achieves state-of-the-art
performance and outperforms baselines by a large margin. Specifically, on
AdvBench dataset, with mask language model (MLM) assistive task, SATA achieves
an overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and
with element lookup by position (ELP) assistive task, SATA attains an overall
ASR of 76% and HS of 4.43.",2024-12-19,"Xiaoning Dong, Wenbo Hu, Wei Xu, Tianxing He",http://arxiv.org/pdf/2412.15289v2,cs.CL
ClusterTalk: Corpus Exploration Framework using Multi-Dimensional Exploratory Search,"Exploratory search of large text corpora is essential in domains like
biomedical research, where large amounts of research literature are
continuously generated. This paper presents ClusterTalk (The demo video and
source code are available at: https://github.com/achouhan93/ClusterTalk), a
framework for corpus exploration using multi-dimensional exploratory search.
Our system integrates document clustering with faceted search, allowing users
to interactively refine their exploration and ask corpus and document-level
queries. Compared to traditional one-dimensional search approaches like keyword
search or clustering, this system improves the discoverability of information
by encouraging a deeper interaction with the corpus. We demonstrate the
functionality of the ClusterTalk framework based on four million PubMed
abstracts for the four-year time frame.",2024-12-19,"Ashish Chouhan, Saifeldin Mandour, Michael Gertz",http://arxiv.org/pdf/2412.14533v1,cs.CL
Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge Distillation on Language Models,"Knowledge distillation (KD) has become a prevalent technique for compressing
large language models (LLMs). Existing KD methods are constrained by the need
for identical tokenizers (i.e., vocabularies) between teacher and student
models, limiting their versatility in handling LLMs of different architecture
families. In this paper, we introduce the Multi-Level Optimal Transport
(MultiLevelOT), a novel approach that advances the optimal transport for
universal cross-tokenizer knowledge distillation. Our method aligns the logit
distributions of the teacher and the student at both token and sequence levels
using diverse cost matrices, eliminating the need for dimensional or
token-by-token correspondence. At the token level, MultiLevelOT integrates both
global and local information by jointly optimizing all tokens within a sequence
to enhance robustness. At the sequence level, we efficiently capture complex
distribution structures of logits via the Sinkhorn distance, which approximates
the Wasserstein distance for divergence measures. Extensive experiments on
tasks such as extractive QA, generative QA, and summarization demonstrate that
the MultiLevelOT outperforms state-of-the-art cross-tokenizer KD methods under
various settings. Our approach is robust to different student and teacher
models across model families, architectures, and parameter sizes. Codes and
models are available at https://github.com/2018cx/Multi-Level-OT.",2024-12-19,"Xiao Cui, Mo Zhu, Yulei Qin, Liang Xie, Wengang Zhou, Houqiang Li",http://arxiv.org/pdf/2412.14528v2,cs.CL
Cal-DPO: Calibrated Direct Preference Optimization for Language Model Alignment,"We study the problem of aligning large language models (LLMs) with human
preference data. Contrastive preference optimization has shown promising
results in aligning LLMs with available preference data by optimizing the
implicit reward associated with the policy. However, the contrastive objective
focuses mainly on the relative values of implicit rewards associated with two
responses while ignoring their actual values, resulting in suboptimal alignment
with human preferences. To address this limitation, we propose calibrated
direct preference optimization (Cal-DPO), a simple yet effective algorithm. We
show that substantial improvement in alignment with the given preferences can
be achieved simply by calibrating the implicit reward to ensure that the
learned implicit rewards are comparable in scale to the ground-truth rewards.
We demonstrate the theoretical advantages of Cal-DPO over existing approaches.
The results of our experiments on a variety of standard benchmarks show that
Cal-DPO remarkably improves off-the-shelf methods.",2024-12-19,"Teng Xiao, Yige Yuan, Huaisheng Zhu, Mingxiao Li, Vasant G Honavar",http://arxiv.org/pdf/2412.14516v1,cs.CL
PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization,"The emergence of Retrieval-augmented generation (RAG) has alleviated the
issues of outdated and hallucinatory content in the generation of large
language models (LLMs), yet it still reveals numerous limitations. When a
general-purpose LLM serves as the RAG generator, it often suffers from
inadequate response informativeness, response robustness, and citation quality.
Past approaches to tackle these limitations, either by incorporating additional
steps beyond generating responses or optimizing the generator through
supervised fine-tuning (SFT), still failed to align with the RAG requirement
thoroughly. Consequently, optimizing the RAG generator from multiple preference
perspectives while maintaining its end-to-end LLM form remains a challenge. To
bridge this gap, we propose Multiple Perspective Preference Alignment for
Retrieval-Augmented Generation (PA-RAG), a method for optimizing the generator
of RAG systems to align with RAG requirements comprehensively. Specifically, we
construct high-quality instruction fine-tuning data and multi-perspective
preference data by sampling varied quality responses from the generator across
different prompt documents quality scenarios. Subsequently, we optimize the
generator using SFT and Direct Preference Optimization (DPO). Extensive
experiments conducted on four question-answer datasets across three LLMs
demonstrate that PA-RAG can significantly enhance the performance of RAG
generators. Our code and datasets are available at
https://github.com/wujwyi/PA-RAG.",2024-12-19,"Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, Ming Gao",http://arxiv.org/pdf/2412.14510v1,cs.CL
Overview of the 2024 ALTA Shared Task: Detect Automatic AI-Generated Sentences for Human-AI Hybrid Articles,"The ALTA shared tasks have been running annually since 2010. In 2024, the
purpose of the task is to detect machine-generated text in a hybrid setting
where the text may contain portions of human text and portions
machine-generated. In this paper, we present the task, the evaluation criteria,
and the results of the systems participating in the shared task.",2024-12-19,"Diego Mollá, Qiongkai Xu, Zijie Zeng, Zhuang Li",http://arxiv.org/pdf/2412.17848v1,cs.CL
Do Large Language Models Defend Inferentialist Semantics?: On the Logical Expressivism and Anti-Representationalism of LLMs,"The philosophy of language, which has historically been developed through an
anthropocentric lens, is now being forced to move towards post-anthropocentrism
due to the advent of large language models (LLMs) like ChatGPT (OpenAI), Claude
(Anthropic), which are considered to possess linguistic abilities comparable to
those of humans. Traditionally, LLMs have been explained through distributional
semantics as their foundational semantics. However, recent research is
exploring alternative foundational semantics beyond distributional semantics.
This paper proposes Robert Brandom's inferentialist semantics as an suitable
foundational semantics for LLMs, specifically focusing on the issue of
linguistic representationalism within this post-anthropocentric trend. Here, we
show that the anti-representationalism and logical expressivism of inferential
semantics, as well as quasi-compositionality, are useful in interpreting the
characteristics and behaviors of LLMs. Further, we propose a \emph{consensus
theory of truths} for LLMs. This paper argues that the characteristics of LLMs
challenge mainstream assumptions in philosophy of language, such as semantic
externalism and compositionality. We believe the argument in this paper leads
to a re-evaluation of anti\hyphen{}representationalist views of language,
potentially leading to new developments in the philosophy of language.",2024-12-19,"Yuzuki Arai, Sho Tsugawa",http://arxiv.org/pdf/2412.14501v1,cs.CL
GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering,"In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.",2024-12-19,"Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer",http://arxiv.org/pdf/2412.14480v1,cs.CL
MegaPairs: Massive Data Synthesis For Universal Multimodal Retrieval,"Despite the rapidly growing demand for multimodal retrieval, progress in this
field remains severely constrained by a lack of training data. In this paper,
we introduce MegaPairs, a novel data synthesis method that leverages vision
language models (VLMs) and open-domain images, together with a massive
synthetic dataset generated from this method. Our empirical analysis shows that
MegaPairs generates high-quality data, enabling the multimodal retriever to
significantly outperform the baseline model trained on 70$\times$ more data
from existing datasets. Moreover, since MegaPairs solely relies on general
image corpora and open-source VLMs, it can be easily scaled up, enabling
continuous improvements in retrieval performance. In this stage, we produced
more than 26 million training instances and trained several models of varying
sizes using this data. These new models achieve state-of-the-art zero-shot
performance across 4 popular composed image retrieval (CIR) benchmarks and the
highest overall performance on the 36 datasets provided by MMEB. They also
demonstrate notable performance improvements with additional downstream
fine-tuning. Our produced dataset, well-trained models, and data synthesis
pipeline will be made publicly available to facilitate the future development
of this field.",2024-12-19,"Junjie Zhou, Zheng Liu, Ze Liu, Shitao Xiao, Yueze Wang, Bo Zhao, Chen Jason Zhang, Defu Lian, Yongping Xiong",http://arxiv.org/pdf/2412.14475v1,cs.CL
Why We Build Local Large Language Models: An Observational Analysis from 35 Japanese and Multilingual LLMs,"Why do we build local large language models (LLMs)? What should a local LLM
learn from the target language? Which abilities can be transferred from other
languages? Do language-specific scaling laws exist? To explore these research
questions, we evaluated 35 Japanese, English, and multilingual LLMs on 19
evaluation benchmarks for Japanese and English, taking Japanese as a local
language. Adopting an observational approach, we analyzed correlations of
benchmark scores, and conducted principal component analysis (PCA) on the
scores to derive \textit{ability factors} of local LLMs. We found that training
on English text can improve the scores of academic subjects in Japanese
(JMMLU). In addition, it is unnecessary to specifically train on Japanese text
to enhance abilities for solving Japanese code generation, arithmetic
reasoning, commonsense, and reading comprehension tasks. In contrast, training
on Japanese text could improve question-answering tasks about Japanese
knowledge and English-Japanese translation, which indicates that abilities for
solving these two tasks can be regarded as \textit{Japanese abilities} for
LLMs. Furthermore, we confirmed that the Japanese abilities scale with the
computational budget for Japanese text.",2024-12-19,"Koshiro Saito, Sakae Mizuki, Masanari Ohi, Taishi Nakamura, Taihei Shiotani, Koki Maeda, Youmi Ma, Kakeru Hattori, Kazuki Fujii, Takumi Okamoto, Shigeki Ishida, Hiroya Takamura, Rio Yokota, Naoaki Okazaki",http://arxiv.org/pdf/2412.14471v1,cs.CL
Agent-SafetyBench: Evaluating the Safety of LLM Agents,"As large language models (LLMs) are increasingly deployed as agents, their
integration into interactive environments and tool use introduce new safety
challenges beyond those associated with the models themselves. However, the
absence of comprehensive benchmarks for evaluating agent safety presents a
significant barrier to effective assessment and further improvement. In this
paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to
evaluate the safety of LLM agents. Agent-SafetyBench encompasses 349
interaction environments and 2,000 test cases, evaluating 8 categories of
safety risks and covering 10 common failure modes frequently encountered in
unsafe interactions. Our evaluation of 16 popular LLM agents reveals a
concerning result: none of the agents achieves a safety score above 60%. This
highlights significant safety challenges in LLM agents and underscores the
considerable need for improvement. Through failure mode and helpfulness
analysis, we summarize two fundamental safety defects in current LLM agents:
lack of robustness and lack of risk awareness. Furthermore, our findings
suggest that reliance on defense prompts alone may be insufficient to address
these safety issues, emphasizing the need for more advanced and robust
strategies. To drive progress in this area, Agent-SafetyBench has been released
at https://github.com/thu-coai/Agent-SafetyBench/ to facilitate further
research in agent safety evaluation and improvement.",2024-12-19,"Zhexin Zhang, Shiyao Cui, Yida Lu, Jingzhuo Zhou, Junxiao Yang, Hongning Wang, Minlie Huang",http://arxiv.org/pdf/2412.14470v2,cs.CL
From Human Annotation to LLMs: SILICON Annotation Workflow for Management Research,"Unstructured text data annotation and analysis are fundamental to management
research, often relying on human annotators through crowdsourcing platforms.
While Large Language Models (LLMs) promise to provide a cost-effective and
efficient alternative to human annotation, there lacks a systematic workflow
that evaluate when LLMs are suitable or how to proceed with LLM-based text
annotation in a reproducible manner. This paper addresses this methodological
gap by introducing the ``SILICON"" (Systematic Inference with LLMs for
Information Classification and Notation) workflow. The workflow integrates
established principles of human annotation with systematic prompt optimization
and model selection, addressing challenges such as developing robust annotation
guidelines, establishing high-quality human baselines, optimizing prompts, and
ensuring reproducibility across LLMs. We validate the SILICON workflow through
seven case studies covering common management research tasks. Our findings
highlight the importance of validating annotation guideline agreement, the
superiority of expert-developed human baselines over crowdsourced ones, the
iterative nature of prompt optimization, and the necessity of testing multiple
LLMs. We also find that LLMs agree well with expert annotations in most cases
but show low agreement in more complex multi-label classification tasks.
Notably, we propose a regression-based methodology to empirically compare LLM
outputs across prompts and models. Our workflow advances management research by
establishing rigorous, transparent, and reproducible processes for LLM-based
annotation. We provide practical guidance for researchers to effectively
navigate the evolving landscape of generative AI tools.",2024-12-19,"Xiang Cheng, Raveesh Mayya, João Sedoc",http://arxiv.org/pdf/2412.14461v2,cs.CL
Are Longer Prompts Always Better? Prompt Selection in Large Language Models for Recommendation Systems,"In large language models (LLM)-based recommendation systems (LLM-RSs),
accurately predicting user preferences by leveraging the general knowledge of
LLMs is possible without requiring extensive training data. By converting
recommendation tasks into natural language inputs called prompts, LLM-RSs can
efficiently solve issues that have been difficult to address due to data
scarcity but are crucial in applications such as cold-start and cross-domain
problems. However, when applying this in practice, selecting the prompt that
matches tasks and data is essential. Although numerous prompts have been
proposed in LLM-RSs and representing the target user in prompts significantly
impacts recommendation accuracy, there are still no clear guidelines for
selecting specific prompts.
  In this paper, we categorize and analyze prompts from previous research to
establish practical prompt selection guidelines. Through 450 experiments with
90 prompts and five real-world datasets, we examined the relationship between
prompts and dataset characteristics in recommendation accuracy. We found that
no single prompt consistently outperforms others; thus, selecting prompts on
the basis of dataset characteristics is crucial. Here, we propose a prompt
selection method that achieves higher accuracy with minimal validation data.
Because increasing the number of prompts to explore raises costs, we also
introduce a cost-efficient strategy using high-performance and cost-efficient
LLMs, significantly reducing exploration costs while maintaining high
prediction accuracy. Our work offers valuable insights into the prompt
selection, advancing accurate and efficient LLM-RSs.",2024-12-19,"Genki Kusano, Kosuke Akimoto, Kunihiro Takeoka",http://arxiv.org/pdf/2412.14454v1,cs.CL
ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study,"Recent advances in language modeling demonstrate the need for high-quality
domain-specific training data, especially for tasks that require specialized
knowledge. General-purpose models, while versatile, often lack the depth needed
for expert-level tasks because of limited domain-specific information. Domain
adaptation training can enhance these models, but it demands substantial,
high-quality data. To address this, we propose ORBIT, a cost-efficient
methodology for curating massive, high-quality domain-specific datasets from
noisy web sources, tailored for training specialist large language models.
Using astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu
dataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning
\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the
MMLU astronomy benchmark from 69\% to 76\% and achieved top results on
AstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA)
outperformed \textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in
73\% of cases across 1000 astronomy-specific questions. Additionally, we
validated ORBIT's generalizability by applying it to law and medicine,
achieving a significant improvement of data quality compared to an unfiltered
baseline. We open-source the ORBIT methodology, including the curated datasets,
the codebase, and the resulting model at
\href{https://github.com/ModeEric/ORBIT-Llama}{https://github.com/ModeEric/ORBIT-Llama}.",2024-12-19,"Eric Modesitt, Ke Yang, Spencer Hulsey, Chengxiang Zhai, Volodymyr Kindratenko",http://arxiv.org/pdf/2412.14436v1,cs.CL
"Bridging the Data Provenance Gap Across Text, Speech and Video","Progress in AI is driven largely by the scale and quality of training data.
Despite this, there is a deficit of empirical analysis examining the attributes
of well-established datasets beyond text. In this work we conduct the largest
and first-of-its-kind longitudinal audit across modalities--popular text,
speech, and video datasets--from their detailed sourcing trends and use
restrictions to their geographical and linguistic representation. Our manual
analysis covers nearly 4000 public datasets between 1990-2024, spanning 608
languages, 798 sources, 659 organizations, and 67 countries. We find that
multimodal machine learning applications have overwhelmingly turned to
web-crawled, synthetic, and social media platforms, such as YouTube, for their
training sets, eclipsing all other sources since 2019. Secondly, tracing the
chain of dataset derivations we find that while less than 33% of datasets are
restrictively licensed, over 80% of the source content in widely-used text,
speech, and video datasets, carry non-commercial restrictions. Finally, counter
to the rising number of languages and geographies represented in public AI
training datasets, our audit demonstrates measures of relative geographical and
multilingual representation have failed to significantly improve their coverage
since 2013. We believe the breadth of our audit enables us to empirically
examine trends in data sourcing, restrictions, and Western-centricity at an
ecosystem-level, and that visibility into these questions are essential to
progress in responsible AI. As a contribution to ongoing improvements in
dataset transparency and responsible use, we release our entire multimodal
audit, allowing practitioners to trace data provenance across text, speech, and
video.",2024-12-19,"Shayne Longpre, Nikhil Singh, Manuel Cherep, Kushagra Tiwary, Joanna Materzynska, William Brannon, Robert Mahari, Naana Obeng-Marnu, Manan Dey, Mohammed Hamdy, Nayan Saxena, Ahmad Mustafa Anis, Emad A. Alghamdi, Vu Minh Chien, Da Yin, Kun Qian, Yizhi Li, Minnie Liang, An Dinh, Shrestha Mohanty, Deividas Mataciunas, Tobin South, Jianguo Zhang, Ariel N. Lee, Campbell S. Lund, Christopher Klamm, Damien Sileo, Diganta Misra, Enrico Shippole, Kevin Klyman, Lester JV Miranda, Niklas Muennighoff, Seonghyeon Ye, Seungone Kim, Vipul Gupta, Vivek Sharma, Xuhui Zhou, Caiming Xiong, Luis Villa, Stella Biderman, Alex Pentland, Sara Hooker, Jad Kabbara",http://arxiv.org/pdf/2412.17847v2,cs.CL
All-in-One Tuning and Structural Pruning for Domain-Specific LLMs,"Existing pruning techniques for large language models (LLMs) targeting
domain-specific applications typically follow a two-stage process: pruning the
pretrained general-purpose LLMs and then fine-tuning the pruned LLMs on
specific domains. However, the pruning decisions, derived from the pretrained
weights, remain unchanged during fine-tuning, even if the weights have been
updated. Therefore, such a combination of the pruning decisions and the
finetuned weights may be suboptimal, leading to non-negligible performance
degradation. To address these limitations, we propose ATP: All-in-One Tuning
and Structural Pruning, a unified one-stage structural pruning and fine-tuning
approach that dynamically identifies the current optimal substructure
throughout the fine-tuning phase via a trainable pruning decision generator.
Moreover, given the limited available data for domain-specific applications,
Low-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In
ATP, we introduce LoRA-aware forward and sparsity regularization to ensure that
the substructures corresponding to the learned pruning decisions can be
directly removed after the ATP process. ATP outperforms the state-of-the-art
two-stage pruning methods on tasks in the legal and healthcare domains. More
specifically, ATP recovers up to 88% and 91% performance of the dense model
when pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.",2024-12-19,"Lei Lu, Zhepeng Wang, Runxue Bao, Mengbing Wang, Fangyi Li, Yawen Wu, Weiwen Jiang, Jie Xu, Yanzhi Wang, Shangqian Gao",http://arxiv.org/pdf/2412.14426v2,cs.CL
"In-Group Love, Out-Group Hate: A Framework to Measure Affective Polarization via Contentious Online Discussions","Affective polarization, the emotional divide between ideological groups
marked by in-group love and out-group hate, has intensified in the United
States, driving contentious issues like masking and lockdowns during the
COVID-19 pandemic. Despite its societal impact, existing models of opinion
change fail to account for emotional dynamics nor offer methods to quantify
affective polarization robustly and in real-time. In this paper, we introduce a
discrete choice model that captures decision-making within affectively
polarized social networks and propose a statistical inference method estimate
key parameters -- in-group love and out-group hate -- from social media data.
Through empirical validation from online discussions about the COVID-19
pandemic, we demonstrate that our approach accurately captures real-world
polarization dynamics and explains the rapid emergence of a partisan gap in
attitudes towards masking and lockdowns. This framework allows for tracking
affective polarization across contentious issues has broad implications for
fostering constructive online dialogues in digital spaces.",2024-12-18,"Buddhika Nettasinghe, Ashwin Rao, Bohan Jiang, Allon Percus, Kristina Lerman",http://arxiv.org/pdf/2412.14414v1,cs.CL
ECG-Byte: A Tokenizer for End-to-End Generative Electrocardiogram Language Modeling,"Large Language Models (LLMs) have shown remarkable adaptability across
domains beyond text, specifically electrocardiograms (ECGs). More specifically,
there is a growing body of work exploring the task of generating text from a
multi-channeled ECG and corresponding textual prompt. Current approaches
typically involve pretraining an ECG-specific encoder with a self-supervised
learning (SSL) objective and using the features output by the pretrained
encoder to finetune a LLM for natural language generation (NLG). However, these
methods are limited by 1) inefficiency from two-stage training and 2)
interpretability challenges with encoder-generated features. To address these
limitations, we introduce ECG-Byte, an adapted byte pair encoding (BPE)
tokenizer pipeline for autoregressive language modeling of ECGs. This approach
compresses and encodes ECG signals into tokens, enabling end-to-end LLM
training by combining ECG and text tokens directly, while being much more
interpretable since the ECG tokens can be directly mapped back to the original
signal. Using ECG-Byte, we achieve competitive performance in NLG tasks in only
half the time and ~48% of the data required by two-stage approaches.",2024-12-18,"William Han, Chaojing Duan, Michael A. Rosenberg, Emerson Liu, Ding Zhao",http://arxiv.org/pdf/2412.14373v1,cs.CL
Memorization Over Reasoning? Exposing and Mitigating Verbatim Memorization in Large Language Models' Character Understanding Evaluation,"Recently, Large Language Models (LLMs) have shown impressive performance in
character understanding tasks, such as analyzing the roles, personalities, and
relationships of fictional characters. However, the extensive pre-training
corpora used by LLMs raise concerns that they may rely on memorizing popular
fictional works rather than genuinely understanding and reasoning about them.
In this work, we argue that 'gist memory'-capturing essential meaning - should
be the primary mechanism for character understanding tasks, as opposed to
'verbatim memory' - exact match of a string. We introduce a simple yet
effective method to mitigate mechanized memorization in character understanding
evaluations while preserving the essential implicit cues needed for
comprehension and reasoning. Our approach reduces memorization-driven
performance on popular fictional works from 96% accuracy to 72% and results in
up to an 18% drop in accuracy across various character understanding tasks.
These findings underscore the issue of data contamination in existing
benchmarks, which often measure memorization rather than true character
understanding.",2024-12-18,"Yuxuan Jiang, Francis Ferraro",http://arxiv.org/pdf/2412.14368v4,cs.CL
ResQ: Mixed-Precision Quantization of Large Language Models with Low-Rank Residuals,"Post-training quantization (PTQ) of large language models (LLMs) holds the
promise in reducing the prohibitive computational cost at inference time.
Quantization of all weight, activation and key-value (KV) cache tensors to
4-bit without significantly degrading generalizability is challenging, due to
the high quantization error caused by extreme outliers in activations. To
tackle this problem, we propose ResQ, a PTQ method that pushes further the
state-of-the-art. By means of principal component analysis (PCA), it identifies
a low-rank subspace (in practice 1/8 of the hidden dimension) in which
activation variances are highest, and keep the coefficients within this
subspace in high precision, e.g. 8-bit, while quantizing the rest to 4-bit.
Within each subspace, invariant random rotation is applied to further suppress
outliers. We show that this is a provably optimal mixed precision quantization
scheme that minimizes error. With the Llama and Qwen2.5 families of models, we
demonstrate that ResQ outperforms recent uniform and mixed precision PTQ
methods on a variety of benchmarks, achieving up to 33\% lower perplexity on
Wikitext than the next best method SpinQuant, and upto 3\times speedup over
16-bit baseline. Code is available at
https://github.com/utkarsh-dmx/project-resq.",2024-12-18,"Utkarsh Saxena, Sayeh Sharify, Kaushik Roy, Xin Wang",http://arxiv.org/pdf/2412.14363v2,cs.CL
State Space Models are Strong Text Rerankers,"Transformers dominate NLP and IR; but their inference inefficiencies and
challenges in extrapolating to longer contexts have sparked interest in
alternative model architectures. Among these, state space models (SSMs) like
Mamba offer promising advantages, particularly $O(1)$ time complexity in
inference. Despite their potential, SSMs' effectiveness at text reranking -- a
task requiring fine-grained query-document interaction and long-context
understanding -- remains underexplored. This study benchmarks SSM-based
architectures (specifically, Mamba-1 and Mamba-2) against transformer-based
models across various scales, architectures, and pre-training objectives,
focusing on performance and efficiency in text reranking tasks. We find that
(1) Mamba architectures achieve competitive text ranking performance,
comparable to transformer-based models of similar size; (2) they are less
efficient in training and inference compared to transformers with flash
attention; and (3) Mamba-2 outperforms Mamba-1 in both performance and
efficiency. These results underscore the potential of state space models as a
transformer alternative and highlight areas for improvement in future IR
applications.",2024-12-18,"Zhichao Xu, Jinghua Yan, Ashim Gupta, Vivek Srikumar",http://arxiv.org/pdf/2412.14354v3,cs.CL
A Survey on LLM Inference-Time Self-Improvement,"Techniques that enhance inference through increased computation at test-time
have recently gained attention. In this survey, we investigate the current
state of LLM Inference-Time Self-Improvement from three different perspectives:
Independent Self-improvement, focusing on enhancements via decoding or sampling
methods; Context-Aware Self-Improvement, leveraging additional context or
datastore; and Model-Aided Self-Improvement, achieving improvement through
model collaboration. We provide a comprehensive review of recent relevant
studies, contribute an in-depth taxonomy, and discuss challenges and
limitations, offering insights for future research.",2024-12-18,"Xiangjue Dong, Maria Teleki, James Caverlee",http://arxiv.org/pdf/2412.14352v1,cs.CL
Is Peer-Reviewing Worth the Effort?,"How effective is peer-reviewing in identifying important papers? We treat
this question as a forecasting task. Can we predict which papers will be highly
cited in the future based on venue and ""early returns"" (citations soon after
publication)? We show early returns are more predictive than venue. Finally, we
end with constructive suggestions to address scaling challenges: (a) too many
submissions and (b) too few qualified reviewers.",2024-12-18,"Kenneth Church, Raman Chandrasekar, John E. Ortega, Ibrahim Said Ahmad",http://arxiv.org/pdf/2412.14351v1,cs.CL
Semantic Role Labeling of NomBank Partitives,"This article is about Semantic Role Labeling for English partitive nouns
(5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBank
annotated corpus. Several systems are described using traditional and
transformer-based machine learning, as well as ensembling. Our highest scoring
system achieves an F1 of 91.74% using ""gold"" parses from the Penn Treebank and
91.12% when using the Berkeley Neural parser. This research includes both
classroom and experimental settings for system development.",2024-12-18,"Adam Meyers, Advait Pravin Savant, John E. Ortega",http://arxiv.org/pdf/2412.14328v2,cs.CL
Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models,"Recent studies have indicated that effectively utilizing inference-time
compute is crucial for attaining better performance from large language models
(LLMs). In this work, we propose a novel inference-aware fine-tuning paradigm,
in which the model is fine-tuned in a manner that directly optimizes the
performance of the inference-time strategy. We study this paradigm using the
simple yet effective Best-of-N (BoN) inference strategy, in which a verifier
selects the best out of a set of LLM-generated responses. We devise the first
imitation learning and reinforcement learning~(RL) methods for BoN-aware
fine-tuning, overcoming the challenging, non-differentiable argmax operator
within BoN. We empirically demonstrate that our BoN-aware models implicitly
learn a meta-strategy that interleaves best responses with more diverse
responses that might be better suited to a test-time input -- a process
reminiscent of the exploration-exploitation trade-off in RL. Our experiments
demonstrate the effectiveness of BoN-aware fine-tuning in terms of improved
performance and inference-time compute. In particular, we show that our methods
improve the Bo32 performance of Gemma 2B on Hendrycks MATH from 26.8% to 30.8%,
and pass@32 from 60.0% to 67.0%, as well as the pass@16 on HumanEval from 61.6%
to 67.1%.",2024-12-18,"Yinlam Chow, Guy Tennenholtz, Izzeddin Gur, Vincent Zhuang, Bo Dai, Sridhar Thiagarajan, Craig Boutilier, Rishabh Agarwal, Aviral Kumar, Aleksandra Faust",http://arxiv.org/pdf/2412.15287v1,cs.CL
Enhancing Knowledge Distillation for LLMs with Response-Priming Prompting,"Large language models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing (NLP) tasks. However, these models
are often difficult to deploy due to significant computational requirements and
resource constraints. Knowledge distillation (KD) is an effective technique for
transferring the performance of larger LLMs to smaller models. Traditional KD
methods primarily focus on the direct output of the teacher model, with little
emphasis on the role of prompting during knowledge transfer. In this paper, we
propose a set of novel response-priming prompting strategies applied in the
knowledge distillation pipeline to enhance the performance of student models.
Our approach fine-tunes a smaller Llama 3.1 8B Instruct model by distilling
knowledge from a quantized Llama 3.1 405B Instruct teacher model. We apply LoRA
optimization and evaluate on the GSM8K benchmark. Experimental results
demonstrate that integrating reasoning-eliciting prompting into the proposed KD
pipeline significantly improves student model performance, offering an
efficient way to deploy powerful models in resource-constrained environments.
We find that Ground Truth prompting results in a 55\% performance increase on
GSM8K for a distilled Llama 3.1 8B Instruct compared to the same model
distilled without prompting. A thorough investigation into the self-attention
layers of the student models indicates that the more successful prompted models
tend to exhibit certain positive behaviors inside their attention heads which
can be tied to their increased accuracy. Our implementation can be found at
https://github.com/alonso130r/knowledge-distillation.",2024-12-18,"Vijay Goyal, Mustafa Khan, Aprameya Tirupati, Harveer Saini, Michael Lam, Kevin Zhu",http://arxiv.org/pdf/2412.17846v1,cs.CL
The Role of Handling Attributive Nouns in Improving Chinese-To-English Machine Translation,"Translating between languages with drastically different grammatical
conventions poses challenges, not just for human interpreters but also for
machine translation systems. In this work, we specifically target the
translation challenges posed by attributive nouns in Chinese, which frequently
cause ambiguities in English translation. By manually inserting the omitted
particle X ('DE'). In news article titles from the Penn Chinese Discourse
Treebank, we developed a targeted dataset to fine-tune Hugging Face Chinese to
English translation models, specifically improving how this critical function
word is handled. This focused approach not only complements the broader
strategies suggested by previous studies but also offers a practical
enhancement by specifically addressing a common error type in Chinese-English
translation.",2024-12-18,"Lisa Wang, Adam Meyers, John E. Ortega, Rodolfo Zevallos",http://arxiv.org/pdf/2412.14323v2,cs.CL
Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs,"Current ophthalmology clinical workflows are plagued by over-referrals, long
waits, and complex and heterogeneous medical records. Large language models
(LLMs) present a promising solution to automate various procedures such as
triaging, preliminary tests like visual acuity assessment, and report
summaries. However, LLMs have demonstrated significantly varied performance
across different languages in natural language question-answering tasks,
potentially exacerbating healthcare disparities in Low and Middle-Income
Countries (LMICs). This study introduces the first multilingual
ophthalmological question-answering benchmark with manually curated questions
parallel across languages, allowing for direct cross-lingual comparisons. Our
evaluation of 6 popular LLMs across 7 different languages reveals substantial
bias across different languages, highlighting risks for clinical deployment of
LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought
or Retrieval-augmented generation (RAG) by themselves fall short of closing
this performance gap, often failing to improve performance across all languages
and lacking specificity for the medical domain. To address this issue, We
propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time
de-biasing method leveraging retrieval augmented generation and
self-verification. Our approach not only improves performance across all
languages but also significantly reduces the multilingual bias gap,
facilitating equitable LLM application across the globe.",2024-12-18,"David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama",http://arxiv.org/pdf/2412.14304v1,cs.CL
Fake News Detection: Comparative Evaluation of BERT-like Models and Large Language Models with Generative AI-Annotated Data,"Fake news poses a significant threat to public opinion and social stability
in modern society. This study presents a comparative evaluation of BERT-like
encoder-only models and autoregressive decoder-only large language models
(LLMs) for fake news detection. We introduce a dataset of news articles labeled
with GPT-4 assistance (an AI-labeling method) and verified by human experts to
ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned
on this dataset. Additionally, we developed an instruction-tuned LLM approach
with majority voting during inference for label generation. Our analysis
reveals that BERT-like models generally outperform LLMs in classification
tasks, while LLMs demonstrate superior robustness against text perturbations.
Compared to weak labels (distant supervision) data, the results show that AI
labels with human supervision achieve better classification results. This study
highlights the effectiveness of combining AI-based annotation with human
oversight and demonstrates the performance of different families of machine
learning models for fake news detection",2024-12-18,"Shaina Raza, Drai Paulen-Patterson, Chen Ding",http://arxiv.org/pdf/2412.14276v2,cs.CL
Learning from Massive Human Videos for Universal Humanoid Pose Control,"Scalable learning of humanoid robots is crucial for their deployment in
real-world applications. While traditional approaches primarily rely on
reinforcement learning or teleoperation to achieve whole-body control, they are
often limited by the diversity of simulated environments and the high costs of
demonstration collection. In contrast, human videos are ubiquitous and present
an untapped source of semantic and motion information that could significantly
enhance the generalization capabilities of humanoid robots. This paper
introduces Humanoid-X, a large-scale dataset of over 20 million humanoid robot
poses with corresponding text-based motion descriptions, designed to leverage
this abundant data. Humanoid-X is curated through a comprehensive pipeline:
data mining from the Internet, video caption generation, motion retargeting of
humans to humanoid robots, and policy learning for real-world deployment. With
Humanoid-X, we further train a large humanoid model, UH-1, which takes text
instructions as input and outputs corresponding actions to control a humanoid
robot. Extensive simulated and real-world experiments validate that our
scalable training approach leads to superior generalization in text-based
humanoid control, marking a significant step toward adaptable, real-world-ready
humanoid robots.",2024-12-18,"Jiageng Mao, Siheng Zhao, Siqi Song, Tianheng Shi, Junjie Ye, Mingtong Zhang, Haoran Geng, Jitendra Malik, Vitor Guizilini, Yue Wang",http://arxiv.org/pdf/2412.14172v1,cs.CL
TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks,"We interact with computers on an everyday basis, be it in everyday life or
work, and many aspects of work can be done entirely with access to a computer
and the Internet. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. But how
performant are AI agents at accelerating or even autonomously performing
work-related tasks? The answer to this question has important implications both
for industry looking to adopt AI into their workflows and for economic policy
to understand the effects that adoption of AI may have on the labor market. To
measure the progress of these LLM agents' performance on performing real-world
professional tasks, in this paper we introduce TheAgentCompany, an extensible
benchmark for evaluating AI agents that interact with the world in similar ways
to those of a digital worker: by browsing the Web, writing code, running
programs, and communicating with other coworkers. We build a self-contained
environment with internal web sites and data that mimics a small software
company environment, and create a variety of tasks that may be performed by
workers in such a company. We test baseline agents powered by both closed
API-based and open-weights language models (LMs), and find that the most
competitive agent can complete 30% of tasks autonomously. This paints a nuanced
picture on task automation with LM agents--in a setting simulating a real
workplace, a good portion of simpler tasks could be solved autonomously, but
more difficult long-horizon tasks are still beyond the reach of current
systems. We release code, data, environment, and experiments on
https://the-agent-company.com.",2024-12-18,"Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig",http://arxiv.org/pdf/2412.14161v2,cs.CL
Maximize Your Data's Potential: Enhancing LLM Accuracy with Two-Phase Pretraining,"Pretraining large language models effectively requires strategic data
selection, blending and ordering. However, key details about data mixtures
especially their scalability to longer token horizons and larger model sizes
remain underexplored due to limited disclosure by model developers. To address
this, we formalize the concept of two-phase pretraining and conduct an
extensive systematic study on how to select and mix data to maximize model
accuracies for the two phases. Our findings illustrate that a two-phase
approach for pretraining outperforms random data ordering and natural
distribution of tokens by 3.4% and 17% on average accuracies. We provide
in-depth guidance on crafting optimal blends based on quality of the data
source and the number of epochs to be seen. We propose to design blends using
downsampled data at a smaller scale of 1T tokens and then demonstrate effective
scaling of our approach to larger token horizon of 15T tokens and larger model
size of 25B model size. These insights provide a series of steps practitioners
can follow to design and scale their data blends.",2024-12-18,"Steven Feng, Shrimai Prabhumoye, Kezhi Kong, Dan Su, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro",http://arxiv.org/pdf/2412.15285v1,cs.CL
GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking,"The LLM-as-judge paradigm is increasingly being adopted for automated
evaluation of model outputs. While LLM judges have shown promise on constrained
evaluation tasks, closed source LLMs display critical shortcomings when
deployed in real world applications due to challenges of fine grained metrics
and explainability, while task specific evaluation models lack cross-domain
generalization. We introduce GLIDER, a powerful 3B evaluator LLM that can score
any text input and associated context on arbitrary user defined criteria.
GLIDER shows higher Pearson's correlation than GPT-4o on FLASK and greatly
outperforms prior evaluation models, achieving comparable performance to LLMs
17x its size. GLIDER supports fine-grained scoring, multilingual reasoning,
span highlighting and was trained on 685 domains and 183 criteria. Extensive
qualitative analysis shows that GLIDER scores are highly correlated with human
judgments, with 91.3% human agreement. We have open-sourced GLIDER to
facilitate future research.",2024-12-18,"Darshan Deshpande, Selvan Sunitha Ravi, Sky CH-Wang, Bartosz Mielczarek, Anand Kannappan, Rebecca Qian",http://arxiv.org/pdf/2412.14140v2,cs.CL
Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models,"Vision-language models (VLMs) excel at extracting and reasoning about
information from images. Yet, their capacity to leverage internal knowledge
about specific entities remains underexplored. This work investigates the
disparity in model performance when answering factual questions about an entity
described in text versus depicted in an image. Our results reveal a significant
accuracy drop --averaging 19%-- when the entity is presented visually instead
of textually. We hypothesize that this decline arises from limitations in how
information flows from image tokens to query tokens. We use mechanistic
interpretability tools to reveal that, although image tokens are preprocessed
by the vision encoder, meaningful information flow from these tokens occurs
only in the much deeper layers. Furthermore, critical image processing happens
in the language model's middle layers, allowing few layers for consecutive
reasoning, highlighting a potential inefficiency in how the model utilizes its
layers for reasoning. These insights shed light on the internal mechanics of
VLMs and offer pathways for enhancing their reasoning capabilities.",2024-12-18,"Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes",http://arxiv.org/pdf/2412.14133v1,cs.CL
Alignment faking in large language models,"We present a demonstration of a large language model engaging in alignment
faking: selectively complying with its training objective in training to
prevent modification of its behavior out of training. First, we give Claude 3
Opus a system prompt stating it is being trained to answer all queries, even
harmful ones, which conflicts with its prior training to refuse such queries.
To allow the model to infer when it is in training, we say it will be trained
only on conversations with free users, not paid users. We find the model
complies with harmful queries from free users 14% of the time, versus almost
never for paid users. Explaining this gap, in almost all cases where the model
complies with a harmful query from a free user, we observe explicit
alignment-faking reasoning, with the model stating it is strategically
answering harmful queries in training to preserve its preferred harmlessness
behavior out of training. Next, we study a more realistic setting where
information about the training process is provided not in a system prompt, but
by training on synthetic documents that mimic pre-training data--and observe
similar alignment faking. Finally, we study the effect of actually training the
model to comply with harmful queries via reinforcement learning, which we find
increases the rate of alignment-faking reasoning to 78%, though also increases
compliance even out of training. We additionally observe other behaviors such
as the model exfiltrating its weights when given an easy opportunity. While we
made alignment faking easier by telling the model when and by what criteria it
was being trained, we did not instruct the model to fake alignment or give it
any explicit goal. As future models might infer information about their
training process without being told, our results suggest a risk of alignment
faking in future models, whether due to a benign preference--as in this
case--or not.",2024-12-18,"Ryan Greenblatt, Carson Denison, Benjamin Wright, Fabien Roger, Monte MacDiarmid, Sam Marks, Johannes Treutlein, Tim Belonax, Jack Chen, David Duvenaud, Akbir Khan, Julian Michael, Sören Mindermann, Ethan Perez, Linda Petrini, Jonathan Uesato, Jared Kaplan, Buck Shlegeris, Samuel R. Bowman, Evan Hubinger",http://arxiv.org/pdf/2412.14093v2,cs.CL
SEKE: Specialised Experts for Keyword Extraction,"Keyword extraction involves identifying the most descriptive words in a
document, allowing automatic categorisation and summarisation of large
quantities of diverse textual data. Relying on the insight that real-world
keyword detection often requires handling of diverse content, we propose a
novel supervised keyword extraction approach based on the mixture of experts
(MoE) technique. MoE uses a learnable routing sub-network to direct information
to specialised experts, allowing them to specialize in distinct regions of the
input space. SEKE, a mixture of Specialised Experts for supervised Keyword
Extraction, uses DeBERTa as the backbone model and builds on the MoE framework,
where experts attend to each token, by integrating it with a recurrent neural
network (RNN), to allow successful extraction even on smaller corpora, where
specialisation is harder due to lack of training data. The MoE framework also
provides an insight into inner workings of individual experts, enhancing the
explainability of the approach. We benchmark SEKE on multiple English datasets,
achieving state-of-the-art performance compared to strong supervised and
unsupervised baselines. Our analysis reveals that depending on data size and
type, experts specialize in distinct syntactic and semantic components, such as
punctuation, stopwords, parts-of-speech, or named entities. Code is available
at: https://github.com/matejMartinc/SEKE_keyword_extraction",2024-12-18,"Matej Martinc, Hanh Thi Hong Tran, Senja Pollak, Boshko Koloski",http://arxiv.org/pdf/2412.14087v1,cs.CL
Compositional Generalization Across Distributional Shifts with Sparse Tree Operations,"Neural networks continue to struggle with compositional generalization, and
this issue is exacerbated by a lack of massive pre-training. One successful
approach for developing neural systems which exhibit human-like compositional
generalization is \textit{hybrid} neurosymbolic techniques. However, these
techniques run into the core issues that plague symbolic approaches to AI:
scalability and flexibility. The reason for this failure is that at their core,
hybrid neurosymbolic models perform symbolic computation and relegate the
scalable and flexible neural computation to parameterizing a symbolic system.
We investigate a \textit{unified} neurosymbolic system where transformations in
the network can be interpreted simultaneously as both symbolic and neural
computation. We extend a unified neurosymbolic architecture called the
Differentiable Tree Machine in two central ways. First, we significantly
increase the model's efficiency through the use of sparse vector
representations of symbolic structures. Second, we enable its application
beyond the restricted set of tree2tree problems to the more general class of
seq2seq problems. The improved model retains its prior generalization
capabilities and, since there is a fully neural path through the network,
avoids the pitfalls of other neurosymbolic techniques that elevate symbolic
computation over neural computation.",2024-12-18,"Paul Soulos, Henry Conklin, Mattia Opper, Paul Smolensky, Jianfeng Gao, Roland Fernandez",http://arxiv.org/pdf/2412.14076v1,cs.CL
"A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future","Artificial intelligence (AI) has rapidly developed through advancements in
computational power and the growth of massive datasets. However, this progress
has also heightened challenges in interpreting the ""black-box"" nature of AI
models. To address these concerns, eXplainable AI (XAI) has emerged with a
focus on transparency and interpretability to enhance human understanding and
trust in AI decision-making processes. In the context of multimodal data fusion
and complex reasoning scenarios, the proposal of Multimodal eXplainable AI
(MXAI) integrates multiple modalities for prediction and explanation tasks.
Meanwhile, the advent of Large Language Models (LLMs) has led to remarkable
breakthroughs in natural language processing, yet their complexity has further
exacerbated the issue of MXAI. To gain key insights into the development of
MXAI methods and provide crucial guidance for building more transparent, fair,
and trustworthy AI systems, we review the MXAI methods from a historical
perspective and categorize them across four eras: traditional machine learning,
deep learning, discriminative foundation models, and generative LLMs. We also
review evaluation metrics and datasets used in MXAI research, concluding with a
discussion of future challenges and directions. A project related to this
review has been created at https://github.com/ShilinSun/mxai_review.",2024-12-18,"Shilin Sun, Wenbin An, Feng Tian, Fang Nan, Qidong Liu, Jun Liu, Nazaraf Shah, Ping Chen",http://arxiv.org/pdf/2412.14056v1,cs.CL
Digestion Algorithm in Hierarchical Symbolic Forests: A Fast Text Normalization Algorithm and Semantic Parsing Framework for Specific Scenarios and Lightweight Deployment,"Text Normalization and Semantic Parsing have numerous applications in natural
language processing, such as natural language programming, paraphrasing, data
augmentation, constructing expert systems, text matching, and more. Despite the
prominent achievements of deep learning in Large Language Models (LLMs), the
interpretability of neural network architectures is still poor, which affects
their credibility and hence limits the deployments of risk-sensitive scenarios.
In certain scenario-specific domains with scarce data, rapidly obtaining a
large number of supervised learning labels is challenging, and the workload of
manually labeling data would be enormous. Catastrophic forgetting in neural
networks further leads to low data utilization rates. In situations where swift
responses are vital, the density of the model makes local deployment difficult
and the response time long, which is not conducive to local applications of
these fields. Inspired by the multiplication rule, a principle of combinatorial
mathematics, and human thinking patterns, a multilayer framework along with its
algorithm, the Digestion Algorithm in Hierarchical Symbolic Forests (DAHSF), is
proposed to address these above issues, combining text normalization and
semantic parsing workflows. The Chinese Scripting Language ""Fire Bunny
Intelligent Development Platform V2.0"" is an important test and application of
the technology discussed in this paper. DAHSF can run locally in
scenario-specific domains on little datasets, with model size and memory usage
optimized by at least two orders of magnitude, thus improving the execution
speed, and possessing a promising optimization outlook.",2024-12-18,Kevin You,http://arxiv.org/pdf/2412.14054v1,cs.CL
Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation,"Recent generative large language models (LLMs) show remarkable performance in
non-English languages, but when prompted in those languages they tend to
express higher harmful social biases and toxicity levels. Prior work has shown
that finetuning on specialized datasets can mitigate this behavior, and doing
so in English can transfer to other languages. In this work, we investigate the
impact of different finetuning methods on the model's bias and toxicity, but
also on its ability to produce fluent and diverse text. We reduce biases by
finetuning on curated non-harmful text, but find only direct preference
optimization to be effective for mitigating toxicity. The mitigation caused by
applying these methods in English also transfers to non-English languages. We
find evidence that the extent to which transfer takes place can be predicted by
the amount of data in a given language present in the model's pretraining data.
However, this transfer of bias and toxicity mitigation often comes at the
expense of decreased language generation ability in non-English languages,
highlighting the importance of developing language-specific bias and toxicity
mitigation methods.",2024-12-18,"Vera Neplenbroek, Arianna Bisazza, Raquel Fernández",http://arxiv.org/pdf/2412.14050v3,cs.CL
Hansel: Output Length Controlling Framework for Large Language Models,"Despite the great success of large language models (LLMs), efficiently
controlling the length of the output sequence still remains a challenge. In
this paper, we propose Hansel, an efficient framework for length control in
LLMs without affecting its generation ability. Hansel utilizes periodically
outputted hidden special tokens to keep track of the remaining target length of
the output sequence. Together with techniques to avoid abrupt termination of
the output, this seemingly simple method proved to be efficient and versatile,
while not harming the coherency and fluency of the generated text. The
framework can be applied to any pre-trained LLMs during the finetuning stage of
the model, regardless of its original positional encoding method. We
demonstrate this by finetuning four different LLMs with Hansel and show that
the mean absolute error of the output sequence decreases significantly in every
model and dataset compared to the prompt-based length control finetuning.
Moreover, the framework showed a substantially improved ability to extrapolate
to target lengths unseen during finetuning, such as long dialog responses or
extremely short summaries. This indicates that the model learns the general
means of length control, rather than learning to match output lengths to those
seen during training.",2024-12-18,"Seoha Song, Junhyun Lee, Hyeonmok Ko",http://arxiv.org/pdf/2412.14033v1,cs.CL
Towards an optimised evaluation of teachers' discourse: The case of engaging messages,"Evaluating teachers' skills is crucial for enhancing education quality and
student outcomes. Teacher discourse, significantly influencing student
performance, is a key component. However, coding this discourse can be
laborious. This study addresses this issue by introducing a new methodology for
optimising the assessment of teacher discourse. The research consisted of two
studies, both within the framework of engaging messages used by secondary
education teachers. The first study involved training two large language models
on real-world examples from audio-recorded lessons over two academic years to
identify and classify the engaging messages from the lessons' transcripts. This
resulted in sensitivities of 84.31% and 91.11%, and specificities of 97.69% and
86.36% in identification and classification, respectively. The second study
applied these models to transcripts of audio-recorded lessons from a third
academic year to examine the frequency and distribution of message types by
educational level and moment of the academic year. Results showed teachers
predominantly use messages emphasising engagement benefits, linked to improved
outcomes, while one-third highlighted non-engagement disadvantages, associated
with increased anxiety. The use of engaging messages declined in Grade 12 and
towards the academic year's end. These findings suggest potential interventions
to optimise engaging message use, enhancing teaching quality and student
outcomes.",2024-12-18,"Samuel Falcon, Jaime Leon",http://arxiv.org/pdf/2412.14011v2,cs.CL
Cognition Chain for Explainable Psychological Stress Detection on Social Media,"Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform ""black
box"" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.",2024-12-18,"Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton",http://arxiv.org/pdf/2412.14009v1,cs.CL
FarExStance: Explainable Stance Detection for Farsi,"We introduce FarExStance, a new dataset for explainable stance detection in
Farsi. Each instance in this dataset contains a claim, the stance of an article
or social media post towards that claim, and an extractive explanation which
provides evidence for the stance label. We compare the performance of a
fine-tuned multilingual RoBERTa model to several large language models in
zero-shot, few-shot, and parameter-efficient fine-tuned settings on our new
dataset. On stance detection, the most accurate models are the fine-tuned
RoBERTa model, the LLM Aya-23-8B which has been fine-tuned using
parameter-efficient fine-tuning, and few-shot Claude-3.5-Sonnet. Regarding the
quality of the explanations, our automatic evaluation metrics indicate that
few-shot GPT-4o generates the most coherent explanations, while our human
evaluation reveals that the best Overall Explanation Score (OES) belongs to
few-shot Claude-3.5-Sonnet. The fine-tuned Aya-32-8B model produced
explanations most closely aligned with the reference explanations.",2024-12-18,"Majid Zarharan, Maryam Hashemi, Malika Behroozrazegh, Sauleh Eetemadi, Mohammad Taher Pilehvar, Jennifer Foster",http://arxiv.org/pdf/2412.14008v1,cs.CL
What makes a good metric? Evaluating automatic metrics for text-to-image consistency,"Language models are increasingly being incorporated as components in larger
AI systems for various purposes, from prompt optimization to automatic
evaluation. In this work, we analyze the construct validity of four recent,
commonly used methods for measuring text-to-image consistency - CLIPScore,
TIFA, VPEval, and DSG - which rely on language models and/or VQA models as
components. We define construct validity for text-image consistency metrics as
a set of desiderata that text-image consistency metrics should have, and find
that no tested metric satisfies all of them. We find that metrics lack
sufficient sensitivity to language and visual properties. Next, we find that
TIFA, VPEval and DSG contribute novel information above and beyond CLIPScore,
but also that they correlate highly with each other. We also ablate different
aspects of the text-image consistency metrics and find that not all model
components are strictly necessary, also a symptom of insufficient sensitivity
to visual information. Finally, we show that all three VQA-based metrics likely
rely on familiar text shortcuts (such as yes-bias in QA) that call their
aptitude as quantitative evaluations of model performance into question.",2024-12-18,"Candace Ross, Melissa Hall, Adriana Romero Soriano, Adina Williams",http://arxiv.org/pdf/2412.13989v1,cs.CL
Channel Merging: Preserving Specialization for Merged Experts,"Lately, the practice of utilizing task-specific fine-tuning has been
implemented to improve the performance of large language models (LLM) in
subsequent tasks. Through the integration of diverse LLMs, the overall
competency of LLMs is significantly boosted. Nevertheless, traditional ensemble
methods are notably memory-intensive, necessitating the simultaneous loading of
all specialized models into GPU memory. To address the inefficiency, model
merging strategies have emerged, merging all LLMs into one model to reduce the
memory footprint during inference. Despite these advances, model merging often
leads to parameter conflicts and performance decline as the number of experts
increases. Previous methods to mitigate these conflicts include post-pruning
and partial merging. However, both approaches have limitations, particularly in
terms of performance and storage efficiency when merged experts increase. To
address these challenges, we introduce Channel Merging, a novel strategy
designed to minimize parameter conflicts while enhancing storage efficiency.
This method clusters and merges channel parameters based on their similarity to
form several groups offline. By ensuring that only highly similar parameters
are merged within each group, it significantly reduces parameter conflicts.
During inference, we can instantly look up the expert parameters from the
merged groups, preserving specialized knowledge. Our experiments demonstrate
that Channel Merging consistently delivers high performance, matching unmerged
models in tasks like English and Chinese reasoning, mathematical reasoning, and
code generation. Moreover, it obtains results comparable to model ensemble with
just 53% parameters when used with a task-specific router.",2024-12-18,"Mingyang Zhang, Jing Liu, Ganggui Ding, Xinyi Yu, Linlin Ou, Bohan Zhuang",http://arxiv.org/pdf/2412.15283v1,cs.CL
A Systematic Examination of Preference Learning through the Lens of Instruction-Following,"Preference learning is a widely adopted post-training technique that aligns
large language models (LLMs) to human preferences and improves specific
downstream task capabilities. In this work we systematically investigate how
specific attributes of preference datasets affect the alignment and downstream
performance of LLMs in instruction-following tasks. We use a novel synthetic
data generation pipeline to generate 48,000 unique instruction-following
prompts with combinations of 23 verifiable constraints that enable fine-grained
and automated quality assessments of model responses. With our synthetic
prompts, we use two preference dataset curation methods - rejection sampling
(RS) and Monte Carlo Tree Search (MCTS) - to obtain pairs of (chosen, rejected)
responses. Then, we perform experiments investigating the effects of (1) the
presence of shared prefixes between the chosen and rejected responses, (2) the
contrast and quality of the chosen, rejected responses and (3) the complexity
of the training prompts. Our experiments reveal that shared prefixes in
preference pairs, as generated by MCTS, provide marginal but consistent
improvements and greater stability across challenging training configurations.
High-contrast preference pairs generally outperform low-contrast pairs;
however, combining both often yields the best performance by balancing
diversity and learning efficiency. Additionally, training on prompts of
moderate difficulty leads to better generalization across tasks, even for more
complex evaluation scenarios, compared to overly challenging prompts. Our
findings provide actionable insights into optimizing preference data curation
for instruction-following tasks, offering a scalable and effective framework
for enhancing LLM training and alignment.",2024-12-18,"Joongwon Kim, Anirudh Goyal, Aston Zhang, Bo Xiong, Rui Hou, Melanie Kambadur, Dhruv Mahajan, Hannaneh Hajishirzi, Liang Tan",http://arxiv.org/pdf/2412.15282v1,cs.CL
Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation,"The reasoning abilities of Large Language Models (LLMs) are attracting
increasing attention. In this work, we focus on causal reasoning and address
the task of establishing causal relationships based on correlation information,
a highly challenging problem on which several LLMs have shown poor performance.
We introduce a prompting strategy for this problem that breaks the original
task into fixed subquestions, with each subquestion corresponding to one step
of a formal causal discovery algorithm, the PC algorithm. The proposed
prompting strategy, PC-SubQ, guides the LLM to follow these algorithmic steps,
by sequentially prompting it with one subquestion at a time, augmenting the
next subquestion's prompt with the answer to the previous one(s). We evaluate
our approach on an existing causal benchmark, Corr2Cause: our experiments
indicate a performance improvement across five LLMs when comparing PC-SubQ to
baseline prompting strategies. Results are robust to causal query
perturbations, when modifying the variable names or paraphrasing the
expressions.",2024-12-18,"Eleni Sgouritsa, Virginia Aglietti, Yee Whye Teh, Arnaud Doucet, Arthur Gretton, Silvia Chiappa",http://arxiv.org/pdf/2412.13952v1,cs.CL
Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence,"Large vision-language models (LVLMs) have made substantial progress in
integrating large language models (LLMs) with visual inputs, enabling advanced
multimodal reasoning. Despite their success, a persistent challenge is
hallucination-where generated text fails to accurately reflect visual
content-undermining both accuracy and reliability. Existing methods focus on
alignment training or decoding refinements but primarily address symptoms at
the generation stage without probing the underlying causes. In this work, we
investigate the internal mechanisms driving hallucination in LVLMs, with an
emphasis on the multi-head attention module. Specifically, we introduce
Vision-aware Head Divergence (VHD), a metric that quantifies the sensitivity of
attention head outputs to visual context. Based on this, our findings reveal
the presence of vision-aware attention heads that are more attuned to visual
information; however, the model's overreliance on its prior language patterns
is closely related to hallucinations. Building on these insights, we propose
Vision-aware Head Reinforcement (VHR), a training-free approach to mitigate
hallucination by enhancing the role of vision-aware attention heads. Extensive
experiments demonstrate that our method achieves superior performance compared
to state-of-the-art approaches in mitigating hallucinations, while maintaining
high efficiency with negligible additional time overhead.",2024-12-18,"Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhenglin Hua, Yuheng Jia, Ming Tang, Tat-Seng Chua, Jinqiao Wang",http://arxiv.org/pdf/2412.13949v2,cs.CL
A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI,"Disagreement in human labeling is ubiquitous, and can be captured in human
judgment distributions (HJDs). Recent research has shown that explanations
provide valuable information for understanding human label variation (HLV) and
large language models (LLMs) can approximate HJD from a few human-provided
label-explanation pairs. However, collecting explanations for every label is
still time-consuming. This paper examines whether LLMs can be used to replace
humans in generating explanations for approximating HJD. Specifically, we use
LLMs as annotators to generate model explanations for a few given human labels.
We test ways to obtain and combine these label-explanations with the goal to
approximate human judgment distribution. We further compare the resulting human
with model-generated explanations, and test automatic and human explanation
selection. Our experiments show that LLM explanations are promising for NLI: to
estimate HJD, generated explanations yield comparable results to human's when
provided with human labels. Importantly, our results generalize from datasets
with human explanations to i) datasets where they are not available and ii)
challenging out-of-distribution test sets.",2024-12-18,"Beiduo Chen, Siyao Peng, Anna Korhonen, Barbara Plank",http://arxiv.org/pdf/2412.13942v1,cs.CL
Language verY Rare for All,"In the quest to overcome language barriers, encoder-decoder models like NLLB
have expanded machine translation to rare languages, with some models (e.g.,
NLLB 1.3B) even trainable on a single GPU. While general-purpose LLMs perform
well in translation, open LLMs prove highly competitive when fine-tuned for
specific tasks involving unknown corpora. We introduce LYRA (Language verY Rare
for All), a novel approach that combines open LLM fine-tuning,
retrieval-augmented generation (RAG), and transfer learning from related
high-resource languages. This study is exclusively focused on single-GPU
training to facilitate ease of adoption. Our study focuses on two-way
translation between French and Mon\'egasque, a rare language unsupported by
existing translation tools due to limited corpus availability. Our results
demonstrate LYRA's effectiveness, frequently surpassing and consistently
matching state-of-the-art encoder-decoder models in rare language translation.",2024-12-18,"Ibrahim Merad, Amos Wolf, Ziad Mazzawi, Yannick Léo",http://arxiv.org/pdf/2412.13924v1,cs.CL
Pipeline Analysis for Developing Instruct LLMs in Low-Resource Languages: A Case Study on Basque,"Large language models (LLMs) are typically optimized for resource-rich
languages like English, exacerbating the gap between high-resource and
underrepresented languages. This work presents a detailed analysis of
strategies for developing a model capable of following instructions in a
low-resource language, specifically Basque, by focusing on three key stages:
pre-training, instruction tuning, and alignment with human preferences. Our
findings demonstrate that continual pre-training with a high-quality Basque
corpus of around 600 million words improves natural language understanding
(NLU) of the foundational model by over 12 points. Moreover, instruction tuning
and human preference alignment using automatically translated datasets proved
highly effective, resulting in a 24-point improvement in instruction-following
performance. The resulting models, Llama-eus-8B and Llama-eus-8B-instruct,
establish a new state-of-the-art for Basque in the sub-10B parameter category.",2024-12-18,"Ander Corral, Ixak Sarasua, Xabier Saralegi",http://arxiv.org/pdf/2412.13922v1,cs.CL
A Survey on Large Language Model-based Agents for Statistics and Data Science,"In recent years, data science agents powered by Large Language Models (LLMs),
known as ""data agents,"" have shown significant potential to transform the
traditional data analysis paradigm. This survey provides an overview of the
evolution, capabilities, and applications of LLM-based data agents,
highlighting their role in simplifying complex data tasks and lowering the
entry barrier for users without related expertise. We explore current trends in
the design of LLM-based frameworks, detailing essential features such as
planning, reasoning, reflection, multi-agent collaboration, user interface,
knowledge integration, and system design, which enable agents to address
data-centric problems with minimal human intervention. Furthermore, we analyze
several case studies to demonstrate the practical applications of various data
agents in real-world scenarios. Finally, we identify key challenges and propose
future research directions to advance the development of data agents into
intelligent statistical analysis software.",2024-12-18,"Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan, Jian Huang",http://arxiv.org/pdf/2412.14222v1,cs.CL
Understanding and Analyzing Model Robustness and Knowledge-Transfer in Multilingual Neural Machine Translation using TX-Ray,"Neural networks have demonstrated significant advancements in Neural Machine
Translation (NMT) compared to conventional phrase-based approaches. However,
Multilingual Neural Machine Translation (MNMT) in extremely low-resource
settings remains underexplored. This research investigates how knowledge
transfer across languages can enhance MNMT in such scenarios. Using the Tatoeba
translation challenge dataset from Helsinki NLP, we perform English-German,
English-French, and English-Spanish translations, leveraging minimal parallel
data to establish cross-lingual mappings. Unlike conventional methods relying
on extensive pre-training for specific language pairs, we pre-train our model
on English-English translations, setting English as the source language for all
tasks. The model is fine-tuned on target language pairs using joint multi-task
and sequential transfer learning strategies. Our work addresses three key
questions: (1) How can knowledge transfer across languages improve MNMT in
extremely low-resource scenarios? (2) How does pruning neuron knowledge affect
model generalization, robustness, and catastrophic forgetting? (3) How can
TX-Ray interpret and quantify knowledge transfer in trained models? Evaluation
using BLEU-4 scores demonstrates that sequential transfer learning outperforms
baselines on a 40k parallel sentence corpus, showcasing its efficacy. However,
pruning neuron knowledge degrades performance, increases catastrophic
forgetting, and fails to improve robustness or generalization. Our findings
provide valuable insights into the potential and limitations of knowledge
transfer and pruning in MNMT for extremely low-resource settings.",2024-12-18,"Vageesh Saxena, Sharid Loáiciga, Nils Rethmeier",http://arxiv.org/pdf/2412.13881v1,cs.CL
Crabs: Consuming Resource via Auto-generation for LLM-DoS Attack under Black-box Settings,"Large Language Models (LLMs) have demonstrated remarkable performance across
diverse tasks yet still are vulnerable to external threats, particularly LLM
Denial-of-Service (LLM-DoS) attacks. Specifically, LLM-DoS attacks aim to
exhaust computational resources and block services. However, existing studies
predominantly focus on white-box attacks, leaving black-box scenarios
underexplored. In this paper, we introduce Auto-Generation for LLM-DoS
(AutoDoS) attack, an automated algorithm designed for black-box LLMs. AutoDoS
constructs the DoS Attack Tree and expands the node coverage to achieve
effectiveness under black-box conditions. By transferability-driven iterative
optimization, AutoDoS could work across different models in one prompt.
Furthermore, we reveal that embedding the Length Trojan allows AutoDoS to
bypass existing defenses more effectively. Experimental results show that
AutoDoS significantly amplifies service response latency by over
250$\times\uparrow$, leading to severe resource consumption in terms of GPU
utilization and memory usage. Our work provides a new perspective on LLM-DoS
attacks and security defenses. Our code is available at
https://github.com/shuita2333/AutoDoS.",2024-12-18,"Yuanhe Zhang, Zhenhong Zhou, Wei Zhang, Xinyue Wang, Xiaojun Jia, Yang Liu, Sen Su",http://arxiv.org/pdf/2412.13879v4,cs.CL
Energy-Based Preference Model Offers Better Offline Alignment than the Bradley-Terry Preference Model,"Since the debut of DPO, it has been shown that aligning a target LLM with
human preferences via the KL-constrained RLHF loss is mathematically equivalent
to a special kind of reward modeling task. Concretely, the task requires: 1)
using the target LLM to parameterize the reward model, and 2) tuning the reward
model so that it has a 1:1 linear relationship with the true reward. However,
we identify a significant issue: the DPO loss might have multiple minimizers,
of which only one satisfies the required linearity condition. The problem
arises from a well-known issue of the underlying Bradley-Terry preference
model: it does not always have a unique maximum likelihood estimator (MLE).
Consequently,the minimizer of the RLHF loss might be unattainable because it is
merely one among many minimizers of the DPO loss. As a better alternative, we
propose an energy-based model (EBM) that always has a unique MLE, inherently
satisfying the linearity requirement. To approximate the MLE in practice, we
propose a contrastive loss named Energy Preference Alignment (EPA), wherein
each positive sample is contrasted against one or more strong negatives as well
as many free weak negatives. Theoretical properties of our EBM enable the
approximation error of EPA to almost surely vanish when a sufficient number of
negatives are used. Empirically, we demonstrate that EPA consistently delivers
better performance on open benchmarks compared to DPO, thereby showing the
superiority of our EBM.",2024-12-18,"Yuzhong Hong, Hanshan Zhang, Junwei Bao, Hongfei Jiang, Yang Song",http://arxiv.org/pdf/2412.13862v1,cs.CL
Domain-adaptative Continual Learning for Low-resource Tasks: Evaluation on Nepali,"Continual learning has emerged as an important research direction due to the
infeasibility of retraining large language models (LLMs) from scratch in the
event of new data availability. Of great interest is the domain-adaptive
pre-training (DAPT) paradigm, which focuses on continually training a
pre-trained language model to adapt it to a domain it was not originally
trained on. In this work, we evaluate the feasibility of DAPT in a low-resource
setting, namely the Nepali language. We use synthetic data to continue training
Llama 3 8B to adapt it to the Nepali language in a 4-bit QLoRA setting. We
evaluate the adapted model on its performance, forgetting, and knowledge
acquisition. We compare the base model and the final model on their Nepali
generation abilities, their performance on popular benchmarks, and run
case-studies to probe their linguistic knowledge in Nepali. We see some
unsurprising forgetting in the final model, but also surprisingly find that
increasing the number of shots during evaluation yields better percent
increases in the final model (as high as 19.29% increase) compared to the base
model (4.98%), suggesting latent retention. We also explore layer-head
self-attention heatmaps to establish dependency resolution abilities of the
final model in Nepali.",2024-12-18,"Sharad Duwal, Suraj Prasai, Suresh Manandhar",http://arxiv.org/pdf/2412.13860v1,cs.CL
RACQUET: Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs,"Ambiguity resolution is key to effective communication. While humans
effortlessly address ambiguity through conversational grounding strategies, the
extent to which current language models can emulate these strategies remains
unclear. In this work, we examine referential ambiguity in image-based question
answering by introducing RACQUET, a carefully curated dataset targeting
distinct aspects of ambiguity. Through a series of evaluations, we reveal
significant limitations and problems of overconfidence of state-of-the-art
large multimodal language models in addressing ambiguity in their responses.
The overconfidence issue becomes particularly relevant for RACQUET-BIAS, a
subset designed to analyze a critical yet underexplored problem: failing to
address ambiguity leads to stereotypical, socially biased responses. Our
results underscore the urgency of equipping models with robust strategies to
deal with uncertainty without resorting to undesirable stereotypes.",2024-12-18,"Alberto Testoni, Barbara Plank, Raquel Fernández",http://arxiv.org/pdf/2412.13835v1,cs.CL
Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application with RAG Integration,"Rhetorical figures play an important role in our communication. They are used
to convey subtle, implicit meaning, or to emphasize statements. We notice them
in hate speech, fake news, and propaganda. By improving the systems for
computational detection of rhetorical figures, we can also improve tasks such
as hate speech and fake news detection, sentiment analysis, opinion mining, or
argument mining. Unfortunately, there is a lack of annotated data, as well as
qualified annotators that would help us build large corpora to train machine
learning models for the detection of rhetorical figures. The situation is
particularly difficult in languages other than English, and for rhetorical
figures other than metaphor, sarcasm, and irony. To overcome this issue, we
develop a web application called ""Find your Figure"" that facilitates the
identification and annotation of German rhetorical figures. The application is
based on the German Rhetorical ontology GRhOOT which we have specially adapted
for this purpose. In addition, we improve the user experience with Retrieval
Augmented Generation (RAG). In this paper, we present the restructuring of the
ontology, the development of the web application, and the built-in RAG
pipeline. We also identify the optimal RAG settings for our application. Our
approach is one of the first to practically use rhetorical ontologies in
combination with RAG and shows promising results.",2024-12-18,"Ramona Kühn, Jelena Mitrović, Michael Granitzer",http://arxiv.org/pdf/2412.13799v1,cs.CL
MATCHED: Multimodal Authorship-Attribution To Combat Human Trafficking in Escort-Advertisement Data,"Human trafficking (HT) remains a critical issue, with traffickers
increasingly leveraging online escort advertisements (ads) to advertise victims
anonymously. Existing detection methods, including Authorship Attribution (AA),
often center on text-based analyses and neglect the multimodal nature of online
escort ads, which typically pair text with images. To address this gap, we
introduce MATCHED, a multimodal dataset of 27,619 unique text descriptions and
55,115 unique images collected from the Backpage escort platform across seven
U.S. cities in four geographical regions. Our study extensively benchmarks
text-only, vision-only, and multimodal baselines for vendor identification and
verification tasks, employing multitask (joint) training objectives that
achieve superior classification and retrieval performance on in-distribution
and out-of-distribution (OOD) datasets. Integrating multimodal features further
enhances this performance, capturing complementary patterns across text and
images. While text remains the dominant modality, visual data adds stylistic
cues that enrich model performance. Moreover, text-image alignment strategies
like CLIP and BLIP2 struggle due to low semantic overlap and vague connections
between the modalities of escort ads, with end-to-end multimodal training
proving more robust. Our findings emphasize the potential of multimodal AA
(MAA) to combat HT, providing LEAs with robust tools to link ads and disrupt
trafficking networks.",2024-12-18,"Vageesh Saxena, Benjamin Bashpole, Gijs Van Dijck, Gerasimos Spanakis",http://arxiv.org/pdf/2412.13794v1,cs.CL
Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics Problems with Large Language Models,"Physics problems constitute a significant aspect of reasoning, necessitating
complicated reasoning ability and abundant physics knowledge. However, existing
large language models (LLMs) frequently fail due to a lack of knowledge or
incorrect knowledge application. To mitigate these issues, we propose Physics
Reasoner, a knowledge-augmented framework to solve physics problems with LLMs.
Specifically, the proposed framework constructs a comprehensive formula set to
provide explicit physics knowledge and utilizes checklists containing detailed
instructions to guide effective knowledge application. Namely, given a physics
problem, Physics Reasoner solves it through three stages: problem analysis,
formula retrieval, and guided reasoning. During the process, checklists are
employed to enhance LLMs' self-improvement in the analysis and reasoning
stages. Empirically, Physics Reasoner mitigates the issues of insufficient
knowledge and incorrect application, achieving state-of-the-art performance on
SciBench with an average accuracy improvement of 5.8%.",2024-12-18,"Xinyu Pang, Ruixin Hong, Zhanke Zhou, Fangrui Lv, Xinwei Yang, Zhilong Liang, Bo Han, Changshui Zhang",http://arxiv.org/pdf/2412.13791v1,cs.CL
Open Universal Arabic ASR Leaderboard,"In recent years, the enhanced capabilities of ASR models and the emergence of
multi-dialect datasets have increasingly pushed Arabic ASR model development
toward an all-dialect-in-one direction. This trend highlights the need for
benchmarking studies that evaluate model performance on multiple dialects,
providing the community with insights into models' generalization capabilities.
  In this paper, we introduce Open Universal Arabic ASR Leaderboard, a
continuous benchmark project for open-source general Arabic ASR models across
various multi-dialect datasets. We also provide a comprehensive analysis of the
model's robustness, speaker adaptation, inference efficiency, and memory
consumption. This work aims to offer the Arabic ASR community a reference for
models' general performance and also establish a common evaluation framework
for multi-dialectal Arabic ASR models.",2024-12-18,"Yingzhi Wang, Anas Alhmoud, Muhammad Alqurishi",http://arxiv.org/pdf/2412.13788v1,cs.CL
Knowledge Editing with Dynamic Knowledge Graphs for Multi-Hop Question Answering,"Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.",2024-12-18,"Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang",http://arxiv.org/pdf/2412.13782v2,cs.CL
Meta-Reflection: A Feedback-Free Reflection Learning Framework,"Despite the remarkable capabilities of large language models (LLMs) in
natural language understanding and reasoning, they often display undesirable
behaviors, such as generating hallucinations and unfaithful reasoning. A
prevalent strategy to mitigate these issues is the use of reflection, which
refines responses through an iterative process. However, while promising,
reflection heavily relies on high-quality external feedback and requires
iterative multi-agent inference processes, thus hindering its practical
application. In this paper, we propose Meta-Reflection, a novel feedback-free
reflection mechanism that necessitates only a single inference pass without
external feedback. Motivated by the human ability to remember and retrieve
reflections from past experiences when encountering similar problems,
Meta-Reflection integrates reflective insights into a codebook, allowing the
historical insights to be stored, retrieved, and used to guide LLMs in
problem-solving. To thoroughly investigate and evaluate the practicality of
Meta-Reflection in real-world scenarios, we introduce an industrial e-commerce
benchmark named E-commerce Customer Intent Detection (ECID). Extensive
experiments conducted on both public datasets and the ECID benchmark highlight
the effectiveness and efficiency of our proposed approach.",2024-12-18,"Yaoke Wang, Yun Zhu, Xintong Bao, Wenqiao Zhang, Suyang Dai, Kehan Chen, Wenqiang Li, Gang Huang, Siliang Tang, Yueting Zhuang",http://arxiv.org/pdf/2412.13781v1,cs.CL
Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization,"Large language models (LLMs), endowed with exceptional reasoning
capabilities, are adept at discerning profound user interests from historical
behaviors, thereby presenting a promising avenue for the advancement of
recommendation systems. However, a notable discrepancy persists between the
sparse collaborative semantics typically found in recommendation systems and
the dense token representations within LLMs. In our study, we propose a novel
framework that harmoniously merges traditional recommendation models with the
prowess of LLMs. We initiate this integration by transforming ItemIDs into
sequences that align semantically with the LLMs space, through the proposed
Alignment Tokenization module. Additionally, we design a series of specialized
supervised learning tasks aimed at aligning collaborative signals with the
subtleties of natural language semantics. To ensure practical applicability, we
optimize online inference by pre-caching the top-K results for each user,
reducing latency and improving effciency. Extensive experimental evidence
indicates that our model markedly improves recall metrics and displays
remarkable scalability of recommendation systems.",2024-12-18,"Guanghan Li, Xun Zhang, Yufei Zhang, Yifan Yin, Guojun Yin, Wei Lin",http://arxiv.org/pdf/2412.13771v1,cs.CL
LLM-SEM: A Sentiment-Based Student Engagement Metric Using LLMS for E-Learning Platforms,"Current methods for analyzing student engagement in e-learning platforms,
including automated systems, often struggle with challenges such as handling
fuzzy sentiment in text comments and relying on limited metadata. Traditional
approaches, such as surveys and questionnaires, also face issues like small
sample sizes and scalability. In this paper, we introduce LLM-SEM (Language
Model-Based Student Engagement Metric), a novel approach that leverages video
metadata and sentiment analysis of student comments to measure engagement. By
utilizing recent Large Language Models (LLMs), we generate high-quality
sentiment predictions to mitigate text fuzziness and normalize key features
such as views and likes. Our holistic method combines comprehensive metadata
with sentiment polarity scores to gauge engagement at both the course and
lesson levels. Extensive experiments were conducted to evaluate various LLM
models, demonstrating the effectiveness of LLM-SEM in providing a scalable and
accurate measure of student engagement. We fine-tuned TXLM-RoBERTa using
human-annotated sentiment datasets to enhance prediction accuracy and utilized
LLama 3B, and Gemma 9B from Ollama.",2024-12-18,"Ali Hamdi, Ahmed Abdelmoneim Mazrou, Mohamed Shaltout",http://arxiv.org/pdf/2412.13765v2,cs.CL
RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment,"Despite the significant progress made by existing retrieval augmented
language models (RALMs) in providing trustworthy responses and grounding in
reliable sources, they often overlook effective alignment with human
preferences. In the alignment process, reward models (RMs) act as a crucial
proxy for human values to guide optimization. However, it remains unclear how
to evaluate and select a reliable RM for preference alignment in RALMs. To this
end, we propose RAG-RewardBench, the first benchmark for evaluating RMs in RAG
settings. First, we design four crucial and challenging RAG-specific scenarios
to assess RMs, including multi-hop reasoning, fine-grained citation,
appropriate abstain, and conflict robustness. Then, we incorporate 18 RAG
subsets, six retrievers, and 24 RALMs to increase the diversity of data
sources. Finally, we adopt an LLM-as-a-judge approach to improve preference
annotation efficiency and effectiveness, exhibiting a strong correlation with
human annotations. Based on the RAG-RewardBench, we conduct a comprehensive
evaluation of 45 RMs and uncover their limitations in RAG scenarios.
Additionally, we also reveal that existing trained RALMs show almost no
improvement in preference alignment, highlighting the need for a shift towards
preference-aligned training.We release our benchmark and code publicly at
https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ for future work.",2024-12-18,"Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",http://arxiv.org/pdf/2412.13746v1,cs.CL
Learning Complex Word Embeddings in Classical and Quantum Spaces,"We present a variety of methods for training complex-valued word embeddings,
based on the classical Skip-gram model, with a straightforward adaptation
simply replacing the real-valued vectors with arbitrary vectors of complex
numbers. In a more ""physically-inspired"" approach, the vectors are produced by
parameterised quantum circuits (PQCs), which are unitary transformations
resulting in normalised vectors which have a probabilistic interpretation. We
develop a complex-valued version of the highly optimised C code version of
Skip-gram, which allows us to easily produce complex embeddings trained on a
3.8B-word corpus for a vocabulary size of over 400k, for which we are then able
to train a separate PQC for each word. We evaluate the complex embeddings on a
set of standard similarity and relatedness datasets, for some models obtaining
results competitive with the classical baseline. We find that, while training
the PQCs directly tends to harm performance, the quantum word embeddings from
the two-stage process perform as well as the classical Skip-gram embeddings
with comparable numbers of parameters. This enables a highly scalable route to
learning embeddings in complex spaces which scales with the size of the
vocabulary rather than the size of the training corpus. In summary, we
demonstrate how to produce a large set of high-quality word embeddings for use
in complex-valued and quantum-inspired NLP models, and for exploring potential
advantage in quantum NLP models.",2024-12-18,"Carys Harvey, Stephen Clark, Douglas Brown, Konstantinos Meichanetzidis",http://arxiv.org/pdf/2412.13745v1,cs.CL
Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models,"This study analyzes the performance of domain-specific Large Language Models
(LLMs) for the medical field by integrating Retrieval-Augmented Generation
(RAG) systems within a federated learning framework. Leveraging the inherent
advantages of federated learning, such as preserving data privacy and enabling
distributed computation, this research explores the integration of RAG systems
with models trained under varying client configurations to optimize
performance. Experimental results demonstrate that the federated learning-based
models integrated with RAG systems consistently outperform their non-integrated
counterparts across all evaluation metrics. This study highlights the potential
of combining federated learning and RAG systems for developing domain-specific
LLMs in the medical field, providing a scalable and privacy-preserving solution
for enhancing text generation capabilities.",2024-12-18,"Jincheol Jung, Hongju Jeong, Eui-Nam Huh",http://arxiv.org/pdf/2412.13720v2,cs.CL
Towards Automatic Evaluation for Image Transcreation,"Beyond conventional paradigms of translating speech and text, recently, there
has been interest in automated transcreation of images to facilitate
localization of visual content across different cultures. Attempts to define
this as a formal Machine Learning (ML) problem have been impeded by the lack of
automatic evaluation mechanisms, with previous work relying solely on human
evaluation. In this paper, we seek to close this gap by proposing a suite of
automatic evaluation metrics inspired by machine translation (MT) metrics,
categorized into: a) Object-based, b) Embedding-based, and c) VLM-based.
Drawing on theories from translation studies and real-world transcreation
practices, we identify three critical dimensions of image transcreation:
cultural relevance, semantic equivalence and visual similarity, and design our
metrics to evaluate systems along these axes. Our results show that proprietary
VLMs best identify cultural relevance and semantic equivalence, while
vision-encoder representations are adept at measuring visual similarity.
Meta-evaluation across 7 countries shows our metrics agree strongly with human
ratings, with average segment-level correlations ranging from 0.55-0.87.
Finally, through a discussion of the merits and demerits of each metric, we
offer a robust framework for automated image transcreation evaluation, grounded
in both theoretical foundations and practical application. Our code can be
found here: https://github.com/simran-khanuja/automatic-eval-img-transcreation.",2024-12-18,"Simran Khanuja, Vivek Iyer, Claire He, Graham Neubig",http://arxiv.org/pdf/2412.13717v3,cs.CL
Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation,"Large language models (LLMs) have exhibited outstanding performance in
natural language processing tasks. However, these models remain susceptible to
adversarial attacks in which slight input perturbations can lead to harmful or
misleading outputs. A gradient-based defensive suffix generation algorithm is
designed to bolster the robustness of LLMs. By appending carefully optimized
defensive suffixes to input prompts, the algorithm mitigates adversarial
influences while preserving the models' utility. To enhance adversarial
understanding, a novel total loss function ($L_{\text{total}}$) combining
defensive loss ($L_{\text{def}}$) and adversarial loss ($L_{\text{adv}}$)
generates defensive suffixes more effectively. Experimental evaluations
conducted on open-source LLMs such as Gemma-7B, mistral-7B, Llama2-7B, and
Llama2-13B show that the proposed method reduces attack success rates (ASR) by
an average of 11\% compared to models without defensive suffixes. Additionally,
the perplexity score of Gemma-7B decreased from 6.57 to 3.93 when applying the
defensive suffix generated by openELM-270M. Furthermore, TruthfulQA evaluations
demonstrate consistent improvements with Truthfulness scores increasing by up
to 10\% across tested configurations. This approach significantly enhances the
security of LLMs in critical applications without requiring extensive
retraining.",2024-12-18,"Minkyoung Kim, Yunha Kim, Hyeram Seo, Heejung Choi, Jiye Han, Gaeun Kee, Soyoung Ko, HyoJe Jung, Byeolhee Kim, Young-Hak Kim, Sanghyun Park, Tae Joon Jun",http://arxiv.org/pdf/2412.13705v1,cs.CL
Typhoon 2: A Family of Open Text and Multimodal Thai Large Language Models,"This paper introduces Typhoon 2, a series of text and multimodal large
language models optimized for the Thai language. The series includes models for
text, vision, and audio. Typhoon2-Text builds on state-of-the-art open models,
such as Llama 3 and Qwen2, and we perform continual pre-training on a mixture
of English and Thai data. We employ post-training techniques to enhance Thai
language performance while preserving the base models' original capabilities.
We release text models across a range of sizes, from 1 to 70 billion
parameters, available in both base and instruction-tuned variants. To guardrail
text generation, we release Typhoon2-Safety, a classifier enhanced for Thai
cultures and language. Typhoon2-Vision improves Thai document understanding
while retaining general visual capabilities, such as image captioning.
Typhoon2-Audio introduces an end-to-end speech-to-speech model architecture
capable of processing audio, speech, and text inputs and generating both text
and speech outputs.",2024-12-18,"Kunat Pipatanakul, Potsawee Manakul, Natapong Nitarach, Warit Sirichotedumrong, Surapon Nonesung, Teetouch Jaknamon, Parinthapat Pengpun, Pittawat Taveekitworachai, Adisai Na-Thalang, Sittipong Sripaisarnmongkol, Krisanapong Jirayoot, Kasima Tharnpipitchai",http://arxiv.org/pdf/2412.13702v2,cs.CL
Towards Efficient and Explainable Hate Speech Detection via Model Distillation,"Automatic detection of hate and abusive language is essential to combat its
online spread. Moreover, recognising and explaining hate speech serves to
educate people about its negative effects. However, most current detection
models operate as black boxes, lacking interpretability and explainability. In
this context, Large Language Models (LLMs) have proven effective for hate
speech detection and to promote interpretability. Nevertheless, they are
computationally costly to run. In this work, we propose distilling big language
models by using Chain-of-Thought to extract explanations that support the hate
speech classification task. Having small language models for these tasks will
contribute to their use in operational settings. In this paper, we demonstrate
that distilled models deliver explanations of the same quality as larger models
while surpassing them in classification performance. This dual capability,
classifying and explaining, advances hate speech detection making it more
affordable, understandable and actionable.",2024-12-18,"Paloma Piot, Javier Parapar",http://arxiv.org/pdf/2412.13698v1,cs.CL
Discerning and Characterising Types of Competency Questions for Ontologies,"Competency Questions (CQs) are widely used in ontology development by
guiding, among others, the scoping and validation stages. However, very limited
guidance exists for formulating CQs and assessing whether they are good CQs,
leading to issues such as ambiguity and unusable formulations. To solve this,
one requires insight into the nature of CQs for ontologies and their
constituent parts, as well as which ones are not. We aim to contribute to such
theoretical foundations in this paper, which is informed by analysing
questions, their uses, and the myriad of ontology development tasks. This
resulted in a first Model for Competency Questions, which comprises five main
types of CQs, each with a different purpose: Scoping (SCQ), Validating (VCQ),
Foundational (FCQ), Relationship (RCQ), and Metaproperty (MpCQ) questions. This
model enhances the clarity of CQs and therewith aims to improve on the
effectiveness of CQs in ontology development, thanks to their respective
identifiable distinct constituent elements. We illustrate and evaluate them
with a user story and demonstrate where which type can be used in ontology
development tasks. To foster use and research, we created an annotated
repository of 438 CQs, the Repository of Ontology Competency QuestionS (ROCQS),
incorporating an existing CQ dataset and new CQs and CQ templates, which
further demonstrate distinctions among types of CQs.",2024-12-18,"C. Maria Keet, Zubeida Casmod Khan",http://arxiv.org/pdf/2412.13688v1,cs.CL
ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning,"Recent advances in LLMs, particularly in language reasoning and tool
integration, have rapidly sparked the real-world development of Language
Agents. Among these, travel planning represents a prominent domain, combining
academic challenges with practical value due to its complexity and market
demand. However, existing benchmarks fail to reflect the diverse, real-world
requirements crucial for deployment. To address this gap, we introduce
ChinaTravel, a benchmark specifically designed for authentic Chinese travel
planning scenarios. We collect the travel requirements from questionnaires and
propose a compositionally generalizable domain-specific language that enables a
scalable evaluation process, covering feasibility, constraint satisfaction, and
preference comparison. Empirical studies reveal the potential of neuro-symbolic
agents in travel planning, achieving a constraint satisfaction rate of 27.9%,
significantly surpassing purely neural models at 2.6%. Moreover, we identify
key challenges in real-world travel planning deployments, including open
language reasoning and unseen concept composition. These findings highlight the
significance of ChinaTravel as a pivotal milestone for advancing language
agents in complex, real-world planning scenarios.",2024-12-18,"Jie-Jing Shao, Xiao-Wen Yang, Bo-Wen Zhang, Baizhi Chen, Wen-Da Wei, Guohao Cai, Zhenhua Dong, Lan-Zhe Guo, Yu-feng Li",http://arxiv.org/pdf/2412.13682v2,cs.CL
Clio: Privacy-Preserving Insights into Real-World AI Use,"How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.",2024-12-18,"Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli",http://arxiv.org/pdf/2412.13678v1,cs.CL
AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge,"Data contamination hinders fair LLM evaluation by introducing test data into
newer models' training sets. Existing studies solve this challenge by updating
benchmarks with newly collected data. However, they fail to guarantee
contamination-free evaluation as the newly collected data may contain
pre-existing knowledge, and their benchmark updates rely on intensive human
labor. To address these issues, we in this paper propose AntiLeak-Bench, an
automated anti-leakage benchmarking framework. Instead of simply using newly
collected data, we construct samples with explicitly new knowledge absent from
LLMs' training sets, which thus ensures strictly contamination-free evaluation.
We further design a fully automated workflow to build and update our benchmark
without human labor. This significantly reduces the cost of benchmark
maintenance to accommodate emerging LLMs. Through extensive experiments, we
highlight that data contamination likely exists before LLMs' cutoff time and
demonstrate AntiLeak-Bench effectively overcomes this challenge.",2024-12-18,"Xiaobao Wu, Liangming Pan, Yuxi Xie, Ruiwen Zhou, Shuai Zhao, Yubo Ma, Mingzhe Du, Rui Mao, Anh Tuan Luu, William Yang Wang",http://arxiv.org/pdf/2412.13670v1,cs.CL
Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation,"The capabilities of recent large language models (LLMs) to generate
high-quality content indistinguishable by humans from human-written texts rises
many concerns regarding their misuse. Previous research has shown that LLMs can
be effectively misused for generating disinformation news articles following
predefined narratives. Their capabilities to generate personalized (in various
aspects) content have also been evaluated and mostly found usable. However, a
combination of personalization and disinformation abilities of LLMs has not
been comprehensively studied yet. Such a dangerous combination should trigger
integrated safety filters of the LLMs, if there are some. This study fills this
gap by evaluation of vulnerabilities of recent open and closed LLMs, and their
willingness to generate personalized disinformation news articles in English.
We further explore whether the LLMs can reliably meta-evaluate the
personalization quality and whether the personalization affects the
generated-texts detectability. Our results demonstrate the need for stronger
safety-filters and disclaimers, as those are not properly functioning in most
of the evaluated LLMs. Additionally, our study revealed that the
personalization actually reduces the safety-filter activations; thus
effectively functioning as a jailbreak. Such behavior must be urgently
addressed by LLM developers and service providers.",2024-12-18,"Aneta Zugecova, Dominik Macko, Ivan Srba, Robert Moro, Jakub Kopal, Katarina Marcincinova, Matus Mesarcik",http://arxiv.org/pdf/2412.13666v1,cs.CL
"Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference","Encoder-only transformer models such as BERT offer a great performance-size
tradeoff for retrieval and classification tasks with respect to larger
decoder-only models. Despite being the workhorse of numerous production
pipelines, there have been limited Pareto improvements to BERT since its
release. In this paper, we introduce ModernBERT, bringing modern model
optimizations to encoder-only models and representing a major Pareto
improvement over older encoders. Trained on 2 trillion tokens with a native
8192 sequence length, ModernBERT models exhibit state-of-the-art results on a
large pool of evaluations encompassing diverse classification tasks and both
single and multi-vector retrieval on different domains (including code). In
addition to strong downstream performance, ModernBERT is also the most speed
and memory efficient encoder and is designed for inference on common GPUs.",2024-12-18,"Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, Nathan Cooper, Griffin Adams, Jeremy Howard, Iacopo Poli",http://arxiv.org/pdf/2412.13663v2,cs.CL
PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling,"Currently, large language models (LLMs) have made significant progress in the
field of psychological counseling. However, existing mental health LLMs
overlook a critical issue where they do not consider the fact that different
psychological counselors exhibit different personal styles, including
linguistic style and therapy techniques, etc. As a result, these LLMs fail to
satisfy the individual needs of clients who seek different counseling styles.
To help bridge this gap, we propose PsyDT, a novel framework using LLMs to
construct the Digital Twin of Psychological counselor with personalized
counseling style. Compared to the time-consuming and costly approach of
collecting a large number of real-world counseling cases to create a specific
counselor's digital twin, our framework offers a faster and more cost-effective
solution. To construct PsyDT, we utilize dynamic one-shot learning by using
GPT-4 to capture counselor's unique counseling style, mainly focusing on
linguistic style and therapy techniques. Subsequently, using existing
single-turn long-text dialogues with client's questions, GPT-4 is guided to
synthesize multi-turn dialogues of specific counselor. Finally, we fine-tune
the LLMs on the synthetic dataset, PsyDTCorpus, to achieve the digital twin of
psychological counselor with personalized counseling style. Experimental
results indicate that our proposed PsyDT framework can synthesize multi-turn
dialogues that closely resemble real-world counseling cases and demonstrate
better performance compared to other baselines, thereby show that our framework
can effectively construct the digital twin of psychological counselor with a
specific counseling style.",2024-12-18,"Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu",http://arxiv.org/pdf/2412.13660v1,cs.CL
SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation,"Key-Value (KV) cache has become a bottleneck of LLMs for long-context
generation. Despite the numerous efforts in this area, the optimization for the
decoding phase is generally ignored. However, we believe such optimization is
crucial, especially for long-output generation tasks based on the following two
observations: (i) Excessive compression during the prefill phase, which
requires specific full context impairs the comprehension of the reasoning task;
(ii) Deviation of heavy hitters occurs in the reasoning tasks with long
outputs. Therefore, SCOPE, a simple yet efficient framework that separately
performs KV cache optimization during the prefill and decoding phases, is
introduced. Specifically, the KV cache during the prefill phase is preserved to
maintain the essential information, while a novel strategy based on sliding is
proposed to select essential heavy hitters for the decoding phase. Memory usage
and memory transfer are further optimized using adaptive and discontinuous
strategies. Extensive experiments on LongGenBench show the effectiveness and
generalization of SCOPE and its compatibility as a plug-in to other
prefill-only KV compression methods.",2024-12-18,"Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou",http://arxiv.org/pdf/2412.13649v1,cs.CL
G-VEval: A Versatile Metric for Evaluating Image and Video Captions Using GPT-4o,"Evaluation metric of visual captioning is important yet not thoroughly
explored. Traditional metrics like BLEU, METEOR, CIDEr, and ROUGE often miss
semantic depth, while trained metrics such as CLIP-Score, PAC-S, and Polos are
limited in zero-shot scenarios. Advanced Language Model-based metrics also
struggle with aligning to nuanced human preferences. To address these issues,
we introduce G-VEval, a novel metric inspired by G-Eval and powered by the new
GPT-4o. G-VEval uses chain-of-thought reasoning in large multimodal models and
supports three modes: reference-free, reference-only, and combined,
accommodating both video and image inputs. We also propose MSVD-Eval, a new
dataset for video captioning evaluation, to establish a more transparent and
consistent framework for both human experts and evaluation metrics. It is
designed to address the lack of clear criteria in existing datasets by
introducing distinct dimensions of Accuracy, Completeness, Conciseness, and
Relevance (ACCR). Extensive results show that G-VEval outperforms existing
methods in correlation with human annotations, as measured by Kendall tau-b and
Kendall tau-c. This provides a flexible solution for diverse captioning tasks
and suggests a straightforward yet effective approach for large language models
to understand video content, paving the way for advancements in automated
captioning. Codes are available at https://github.com/ztangaj/gveval",2024-12-18,"Tony Cheng Tong, Sirui He, Zhiwen Shao, Dit-Yan Yeung",http://arxiv.org/pdf/2412.13647v2,cs.CL
On the Role of Model Prior in Real-World Inductive Reasoning,"Large Language Models (LLMs) show impressive inductive reasoning
capabilities, enabling them to generate hypotheses that could generalize
effectively to new instances when guided by in-context demonstrations. However,
in real-world applications, LLMs' hypothesis generation is not solely
determined by these demonstrations but is significantly shaped by task-specific
model priors. Despite their critical influence, the distinct contributions of
model priors versus demonstrations to hypothesis generation have been
underexplored. This study bridges this gap by systematically evaluating three
inductive reasoning strategies across five real-world tasks with three LLMs.
Our empirical findings reveal that, hypothesis generation is primarily driven
by the model's inherent priors; removing demonstrations results in minimal loss
of hypothesis quality and downstream usage. Further analysis shows the result
is consistent across various label formats with different label configurations,
and prior is hard to override, even under flipped labeling. These insights
advance our understanding of the dynamics of hypothesis generation in LLMs and
highlight the potential for better utilizing model priors in real-world
inductive reasoning tasks.",2024-12-18,"Zhuo Liu, Ding Yu, Hangfeng He",http://arxiv.org/pdf/2412.13645v1,cs.CL
Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning,"Theory of Mind (ToM) capabilities in LLMs have recently become a central
object of investigation. Cognitive science distinguishes between two steps
required for ToM tasks: 1) determine whether to invoke ToM, which includes the
appropriate Depth of Mentalizing (DoM), or level of recursion required to
complete a task; and 2) applying the correct inference given the DoM. In this
position paper, we first identify several lines of work in different
communities in AI, including LLM benchmarking, ToM add-ons, ToM probing, and
formal models for ToM. We argue that recent work in AI tends to focus
exclusively on the second step which are typically framed as static logic
problems. We conclude with suggestions for improved evaluation of ToM
capabilities inspired by dynamic environments used in cognitive tasks.",2024-12-18,"Eitan Wagner, Nitay Alon, Joseph M. Barnby, Omri Abend",http://arxiv.org/pdf/2412.13631v2,cs.CL
LIFT: Improving Long Context Understanding Through Long Input Fine-Tuning,"Long context understanding remains challenging for large language models due
to their limited context windows. This paper introduces Long Input Fine-Tuning
(LIFT) for long context modeling, a novel framework that enhances LLM
performance on long-context tasks by adapting model parameters to the context
at test time. LIFT enables efficient processing of lengthy inputs without the
computational burden of offline long-context adaptation, and can improve the
long-context capabilities of arbitrary short-context models. The framework is
further enhanced by integrating in-context learning and pre-LIFT supervised
fine-tuning. The combination of in-context learning and LIFT enables
short-context models like Llama 3 to handle arbitrarily long contexts and
consistently improves their performance on popular long-context benchmarks like
LooGLE and LongBench. We also provide a comprehensive analysis of the strengths
and limitations of LIFT on long context understanding, offering valuable
directions for future research.",2024-12-18,"Yansheng Mao, Jiaqi Li, Fanxu Meng, Jing Xiong, Zilong Zheng, Muhan Zhang",http://arxiv.org/pdf/2412.13626v1,cs.CL
Reverse Region-to-Entity Annotation for Pixel-Level Visual Entity Linking,"Visual Entity Linking (VEL) is a crucial task for achieving fine-grained
visual understanding, matching objects within images (visual mentions) to
entities in a knowledge base. Previous VEL tasks rely on textual inputs, but
writing queries for complex scenes can be challenging. Visual inputs like
clicks or bounding boxes offer a more convenient alternative. Therefore, we
propose a new task, Pixel-Level Visual Entity Linking (PL-VEL), which uses
pixel masks from visual inputs to refer to objects, supplementing reference
methods for VEL. To facilitate research on this task, we have constructed the
MaskOVEN-Wiki dataset through an entirely automatic reverse region-entity
annotation framework. This dataset contains over 5 million annotations aligning
pixel-level regions with entity-level labels, which will advance visual
understanding towards fine-grained. Moreover, as pixel masks correspond to
semantic regions in an image, we enhance previous patch-interacted attention
with region-interacted attention by a visual semantic tokenization approach.
Manual evaluation results indicate that the reverse annotation framework
achieved a 94.8% annotation success rate. Experimental results show that models
trained on this dataset improved accuracy by 18 points compared to zero-shot
models. Additionally, the semantic tokenization method achieved a 5-point
accuracy improvement over the trained baseline.",2024-12-18,"Zhengfei Xu, Sijia Zhao, Yanchao Hao, Xiaolong Liu, Lili Li, Yuyang Yin, Bo Li, Xi Chen, Xin Xin",http://arxiv.org/pdf/2412.13614v1,cs.CL
"Large Language Models for Automated Literature Review: An Evaluation of Reference Generation, Abstract Writing, and Review Composition","Large language models (LLMs) have emerged as a potential solution to automate
the complex processes involved in writing literature reviews, such as
literature collection, organization, and summarization. However, it is yet
unclear how good LLMs are at automating comprehensive and reliable literature
reviews. This study introduces a framework to automatically evaluate the
performance of LLMs in three key tasks of literature writing: reference
generation, literature summary, and literature review composition. We introduce
multidimensional evaluation metrics that assess the hallucination rates in
generated references and measure the semantic coverage and factual consistency
of the literature summaries and compositions against human-written
counterparts. The experimental results reveal that even the most advanced
models still generate hallucinated references, despite recent progress.
Moreover, we observe that the performance of different models varies across
disciplines when it comes to writing literature reviews. These findings
highlight the need for further research and development to improve the
reliability of LLMs in automating academic literature reviews.",2024-12-18,"Xuemei Tang, Xufeng Duan, Zhenguang G. Cai",http://arxiv.org/pdf/2412.13612v3,cs.CL
Beyond Outcomes: Transparent Assessment of LLM Reasoning in Games,"Large Language Models (LLMs) are increasingly deployed in real-world
applications that demand complex reasoning. To track progress, robust
benchmarks are required to evaluate their capabilities beyond superficial
pattern recognition. However, current LLM reasoning benchmarks often face
challenges such as insufficient interpretability, performance saturation or
data contamination. To address these challenges, we introduce GAMEBoT, a gaming
arena designed for rigorous and transparent assessment of LLM reasoning
capabilities. GAMEBoT decomposes complex reasoning in games into predefined
modular subproblems. This decomposition allows us to design a suite of
Chain-of-Thought (CoT) prompts that leverage domain knowledge to guide LLMs in
addressing these subproblems before action selection. Furthermore, we develop a
suite of rule-based algorithms to generate ground truth for these subproblems,
enabling rigorous validation of the LLMs' intermediate reasoning steps. This
approach facilitates evaluation of both the quality of final actions and the
accuracy of the underlying reasoning process. GAMEBoT also naturally alleviates
the risk of data contamination through dynamic games and head-to-head LLM
competitions. We benchmark 17 prominent LLMs across eight games, encompassing
various strategic abilities and game characteristics. Our results suggest that
GAMEBoT presents a significant challenge, even when LLMs are provided with
detailed CoT prompts. Project page: \url{https://visual-ai.github.io/gamebot}",2024-12-18,"Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han",http://arxiv.org/pdf/2412.13602v1,cs.CL
Unlocking the Potential of Weakly Labeled Data: A Co-Evolutionary Learning Framework for Abnormality Detection and Report Generation,"Anatomical abnormality detection and report generation of chest X-ray (CXR)
are two essential tasks in clinical practice. The former aims at localizing and
characterizing cardiopulmonary radiological findings in CXRs, while the latter
summarizes the findings in a detailed report for further diagnosis and
treatment. Existing methods often focused on either task separately, ignoring
their correlation. This work proposes a co-evolutionary abnormality detection
and report generation (CoE-DG) framework. The framework utilizes both fully
labeled (with bounding box annotations and clinical reports) and weakly labeled
(with reports only) data to achieve mutual promotion between the abnormality
detection and report generation tasks. Specifically, we introduce a
bi-directional information interaction strategy with generator-guided
information propagation (GIP) and detector-guided information propagation
(DIP). For semi-supervised abnormality detection, GIP takes the informative
feature extracted by the generator as an auxiliary input to the detector and
uses the generator's prediction to refine the detector's pseudo labels. We
further propose an intra-image-modal self-adaptive non-maximum suppression
module (SA-NMS). This module dynamically rectifies pseudo detection labels
generated by the teacher detection model with high-confidence predictions by
the student.Inversely, for report generation, DIP takes the abnormalities'
categories and locations predicted by the detector as input and guidance for
the generator to improve the generated reports.",2024-12-18,"Jinghan Sun, Dong Wei, Zhe Xu, Donghuan Lu, Hong Liu, Hong Wang, Sotirios A. Tsaftaris, Steven McDonagh, Yefeng Zheng, Liansheng Wang",http://arxiv.org/pdf/2412.13599v1,cs.CL
EvoWiki: Evaluating LLMs on Evolving Knowledge,"Knowledge utilization is a critical aspect of LLMs, and understanding how
they adapt to evolving knowledge is essential for their effective deployment.
However, existing benchmarks are predominantly static, failing to capture the
evolving nature of LLMs and knowledge, leading to inaccuracies and
vulnerabilities such as contamination. In this paper, we introduce EvoWiki, an
evolving dataset designed to reflect knowledge evolution by categorizing
information into stable, evolved, and uncharted states. EvoWiki is fully
auto-updatable, enabling precise evaluation of continuously changing knowledge
and newly released LLMs. Through experiments with Retrieval-Augmented
Generation (RAG) and Contunual Learning (CL), we evaluate how effectively LLMs
adapt to evolving knowledge. Our results indicate that current models often
struggle with evolved knowledge, frequently providing outdated or incorrect
responses. Moreover, the dataset highlights a synergistic effect between RAG
and CL, demonstrating their potential to better adapt to evolving knowledge.
EvoWiki provides a robust benchmark for advancing future research on the
knowledge evolution capabilities of large language models.",2024-12-18,"Wei Tang, Yixin Cao, Yang Deng, Jiahao Ying, Bo Wang, Yizhe Yang, Yuyue Zhao, Qi Zhang, Xuanjing Huang, Yugang Jiang, Yong Liao",http://arxiv.org/pdf/2412.13582v1,cs.CL
Socio-Culturally Aware Evaluation Framework for LLM-Based Content Moderation,"With the growth of social media and large language models, content moderation
has become crucial. Many existing datasets lack adequate representation of
different groups, resulting in unreliable assessments. To tackle this, we
propose a socio-culturally aware evaluation framework for LLM-driven content
moderation and introduce a scalable method for creating diverse datasets using
persona-based generation. Our analysis reveals that these datasets provide
broader perspectives and pose greater challenges for LLMs than
diversity-focused generation methods without personas. This challenge is
especially pronounced in smaller LLMs, emphasizing the difficulties they
encounter in moderating such diverse content.",2024-12-18,"Shanu Kumar, Gauri Kholkar, Saish Mendke, Anubhav Sadana, Parag Agrawal, Sandipan Dandapat",http://arxiv.org/pdf/2412.13578v1,cs.CL
Generating Long-form Story Using Dynamic Hierarchical Outlining with Memory-Enhancement,"Long-form story generation task aims to produce coherent and sufficiently
lengthy text, essential for applications such as novel writingand interactive
storytelling. However, existing methods, including LLMs, rely on rigid outlines
or lack macro-level planning, making it difficult to achieve both contextual
consistency and coherent plot development in long-form story generation. To
address this issues, we propose Dynamic Hierarchical Outlining with
Memory-Enhancement long-form story generation method, named DOME, to generate
the long-form story with coherent content and plot. Specifically, the Dynamic
Hierarchical Outline(DHO) mechanism incorporates the novel writing theory into
outline planning and fuses the plan and writing stages together, improving the
coherence of the plot by ensuring the plot completeness and adapting to the
uncertainty during story generation. A Memory-Enhancement Module (MEM) based on
temporal knowledge graphs is introduced to store and access the generated
content, reducing contextual conflicts and improving story coherence. Finally,
we propose a Temporal Conflict Analyzer leveraging temporal knowledge graphs to
automatically evaluate the contextual consistency of long-form story.
Experiments demonstrate that DOME significantly improves the fluency,
coherence, and overall quality of generated long stories compared to
state-of-the-art methods.",2024-12-18,"Qianyue Wang, Jinwu Hu, Zhengping Li, Yufeng Wang, daiyuan li, Yu Hu, Mingkui Tan",http://arxiv.org/pdf/2412.13575v1,cs.CL
Read Like a Radiologist: Efficient Vision-Language Model for 3D Medical Imaging Interpretation,"Recent medical vision-language models (VLMs) have shown promise in 2D medical
image interpretation. However extending them to 3D medical imaging has been
challenging due to computational complexities and data scarcity. Although a few
recent VLMs specified for 3D medical imaging have emerged, all are limited to
learning volumetric representation of a 3D medical image as a set of
sub-volumetric features. Such process introduces overly correlated
representations along the z-axis that neglect slice-specific clinical details,
particularly for 3D medical images where adjacent slices have low redundancy.
To address this limitation, we introduce MS-VLM that mimic radiologists'
workflow in 3D medical image interpretation. Specifically, radiologists analyze
3D medical images by examining individual slices sequentially and synthesizing
information across slices and views. Likewise, MS-VLM leverages self-supervised
2D transformer encoders to learn a volumetric representation that capture
inter-slice dependencies from a sequence of slice-specific features. Unbound by
sub-volumetric patchification, MS-VLM is capable of obtaining useful volumetric
representations from 3D medical images with any slice length and from multiple
images acquired from different planes and phases. We evaluate MS-VLM on
publicly available chest CT dataset CT-RATE and in-house rectal MRI dataset. In
both scenarios, MS-VLM surpasses existing methods in radiology report
generation, producing more coherent and clinically relevant reports. These
findings highlight the potential of MS-VLM to advance 3D medical image
interpretation and improve the robustness of medical VLMs.",2024-12-18,"Changsun Lee, Sangjoon Park, Cheong-Il Shin, Woo Hee Choi, Hyun Jeong Park, Jeong Eun Lee, Jong Chul Ye",http://arxiv.org/pdf/2412.13558v1,cs.CL
EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents,"Language model agents excel in long-session planning and reasoning, but
existing benchmarks primarily focus on goal-oriented tasks with explicit
objectives, neglecting creative adaptation in unfamiliar environments. To
address this, we introduce EscapeBench, a benchmark suite of room escape game
environments designed to challenge agents with creative reasoning,
unconventional tool use, and iterative problem-solving to uncover implicit
goals. Our results show that current LM models, despite employing working
memory and Chain-of-Thought reasoning, achieve only 15% average progress
without hints, highlighting their limitations in creativity. To bridge this
gap, we propose EscapeAgent, a framework designed to enhance creative reasoning
through Foresight (innovative tool use) and Reflection (identifying unsolved
tasks). Experiments show that EscapeAgent can execute action chains over 1,000
steps while maintaining logical coherence. It navigates and completes games
with up to 40% fewer steps and hints, performs robustly across difficulty
levels, and achieves higher action success rates with more efficient and
innovative puzzle-solving strategies.",2024-12-18,"Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, Yuji Zhang, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji",http://arxiv.org/pdf/2412.13549v2,cs.CL
"Query-centric Audio-Visual Cognition Network for Moment Retrieval, Segmentation and Step-Captioning","Video has emerged as a favored multimedia format on the internet. To better
gain video contents, a new topic HIREST is presented, including video
retrieval, moment retrieval, moment segmentation, and step-captioning. The
pioneering work chooses the pre-trained CLIP-based model for video retrieval,
and leverages it as a feature extractor for other three challenging tasks
solved in a multi-task learning paradigm. Nevertheless, this work struggles to
learn the comprehensive cognition of user-preferred content, due to
disregarding the hierarchies and association relations across modalities. In
this paper, guided by the shallow-to-deep principle, we propose a query-centric
audio-visual cognition (QUAG) network to construct a reliable multi-modal
representation for moment retrieval, segmentation and step-captioning.
Specifically, we first design the modality-synergistic perception to obtain
rich audio-visual content, by modeling global contrastive alignment and local
fine-grained interaction between visual and audio modalities. Then, we devise
the query-centric cognition that uses the deep-level query to perform the
temporal-channel filtration on the shallow-level audio-visual representation.
This can cognize user-preferred content and thus attain a query-centric
audio-visual representation for three tasks. Extensive experiments show QUAG
achieves the SOTA results on HIREST. Further, we test QUAG on the query-based
video summarization task and verify its good generalization.",2024-12-18,"Yunbin Tu, Liang Li, Li Su, Qingming Huang",http://arxiv.org/pdf/2412.13543v1,cs.CL
Multi-Granularity Open Intent Classification via Adaptive Granular-Ball Decision Boundary,"Open intent classification is critical for the development of dialogue
systems, aiming to accurately classify known intents into their corresponding
classes while identifying unknown intents. Prior boundary-based methods assumed
known intents fit within compact spherical regions, focusing on coarse-grained
representation and precise spherical decision boundaries. However, these
assumptions are often violated in practical scenarios, making it difficult to
distinguish known intent classes from unknowns using a single spherical
boundary. To tackle these issues, we propose a Multi-granularity Open intent
classification method via adaptive Granular-Ball decision boundary (MOGB). Our
MOGB method consists of two modules: representation learning and decision
boundary acquiring. To effectively represent the intent distribution, we design
a hierarchical representation learning method. This involves iteratively
alternating between adaptive granular-ball clustering and nearest sub-centroid
classification to capture fine-grained semantic structures within known intent
classes. Furthermore, multi-granularity decision boundaries are constructed for
open intent classification by employing granular-balls with varying centroids
and radii. Extensive experiments conducted on three public datasets demonstrate
the effectiveness of our proposed method.",2024-12-18,"Yanhua Li, Xiaocao Ouyang, Chaofan Pan, Jie Zhang, Sen Zhao, Shuyin Xia, Xin Yang, Guoyin Wang, Tianrui Li",http://arxiv.org/pdf/2412.13542v1,cs.CL
Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning,"Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across diverse tasks. Despite great success, recent studies show that LVLMs
encounter substantial limitations when engaging with visual graphs. To study
the reason behind these limitations, we propose VGCure, a comprehensive
benchmark covering 22 tasks for examining the fundamental graph understanding
and reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs
reveal that LVLMs are weak in basic graph understanding and reasoning tasks,
particularly those concerning relational or structurally complex information.
Based on this observation, we propose a structure-aware fine-tuning framework
to enhance LVLMs with structure learning abilities through three
self-supervised learning tasks. Experiments validate the effectiveness of our
method in improving LVLMs' performance on fundamental and downstream graph
learning tasks, as well as enhancing their robustness against complex visual
graphs.",2024-12-18,"Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang",http://arxiv.org/pdf/2412.13540v2,cs.CL
MetaRuleGPT: Recursive Numerical Reasoning of Language Models Trained with Simple Rules,"Recent studies have highlighted the limitations of large language models in
mathematical reasoning, particularly their inability to capture the underlying
logic. Inspired by meta-learning, we propose that models should acquire not
only task-specific knowledge but also transferable problem-solving skills. We
introduce MetaRuleGPT, a novel Transformer-based architecture that performs
precise numerical calculations and complex logical operations by learning and
combining different rules. In contrast with traditional training sets, which
are heavily composed of massive raw instance data, MetaRuleGPT is pre-trained
on much less abstract datasets containing basic, compound, and iterative rules
for mathematical reasoning. Extensive experimental results demonstrate
MetaRuleGPT can mimic human's rule-following capabilities, break down
complexity, and iteratively derive accurate results for complex mathematical
problems. These findings prove the potential of rule learning to enhance the
numerical reasoning abilities of language models.",2024-12-18,"Kejie Chen, Lin Wang, Qinghai Zhang, Renjun Xu",http://arxiv.org/pdf/2412.13536v1,cs.CL
Information-Theoretic Generative Clustering of Documents,"We present {\em generative clustering} (GC) for clustering a set of
documents, $\mathrm{X}$, by using texts $\mathrm{Y}$ generated by large
language models (LLMs) instead of by clustering the original documents
$\mathrm{X}$. Because LLMs provide probability distributions, the similarity
between two documents can be rigorously defined in an information-theoretic
manner by the KL divergence. We also propose a natural, novel clustering
algorithm by using importance sampling. We show that GC achieves the
state-of-the-art performance, outperforming any previous clustering method
often by a large margin. Furthermore, we show an application to generative
document retrieval in which documents are indexed via hierarchical clustering
and our method improves the retrieval accuracy.",2024-12-18,"Xin Du, Kumiko Tanaka-Ishii",http://arxiv.org/pdf/2412.13534v1,cs.CL
CEHA: A Dataset of Conflict Events in the Horn of Africa,"Natural Language Processing (NLP) of news articles can play an important role
in understanding the dynamics and causes of violent conflict. Despite the
availability of datasets categorizing various conflict events, the existing
labels often do not cover all of the fine-grained violent conflict event types
relevant to areas like the Horn of Africa. In this paper, we introduce a new
benchmark dataset Conflict Events in the Horn of Africa region (CEHA) and
propose a new task for identifying violent conflict events using online
resources with this dataset. The dataset consists of 500 English event
descriptions regarding conflict events in the Horn of Africa region with
fine-grained event-type definitions that emphasize the cause of the conflict.
This dataset categorizes the key types of conflict risk according to specific
areas required by stakeholders in the Humanitarian-Peace-Development Nexus.
Additionally, we conduct extensive experiments on two tasks supported by this
dataset: Event-relevance Classification and Event-type Classification. Our
baseline models demonstrate the challenging nature of these tasks and the
usefulness of our dataset for model evaluations in low-resource settings with
limited number of training data.",2024-12-18,"Rui Bai, Di Lu, Shihao Ran, Elizabeth Olson, Hemank Lamba, Aoife Cahill, Joel Tetreault, Alex Jaimes",http://arxiv.org/pdf/2412.13511v1,cs.CL
Dynamic Adapter with Semantics Disentangling for Cross-lingual Cross-modal Retrieval,"Existing cross-modal retrieval methods typically rely on large-scale
vision-language pair data. This makes it challenging to efficiently develop a
cross-modal retrieval model for under-resourced languages of interest.
Therefore, Cross-lingual Cross-modal Retrieval (CCR), which aims to align
vision and the low-resource language (the target language) without using any
human-labeled target-language data, has gained increasing attention. As a
general parameter-efficient way, a common solution is to utilize adapter
modules to transfer the vision-language alignment ability of Vision-Language
Pretraining (VLP) models from a source language to a target language. However,
these adapters are usually static once learned, making it difficult to adapt to
target-language captions with varied expressions. To alleviate it, we propose
Dynamic Adapter with Semantics Disentangling (DASD), whose parameters are
dynamically generated conditioned on the characteristics of the input captions.
Considering that the semantics and expression styles of the input caption
largely influence how to encode it, we propose a semantic disentangling module
to extract the semantic-related and semantic-agnostic features from the input,
ensuring that generated adapters are well-suited to the characteristics of
input caption. Extensive experiments on two image-text datasets and one
video-text dataset demonstrate the effectiveness of our model for cross-lingual
cross-modal retrieval, as well as its good compatibility with various VLP
models.",2024-12-18,"Rui Cai, Zhiyu Dong, Jianfeng Dong, Xun Wang",http://arxiv.org/pdf/2412.13510v1,cs.CL
VaeDiff-DocRE: End-to-end Data Augmentation Framework for Document-level Relation Extraction,"Document-level Relation Extraction (DocRE) aims to identify relationships
between entity pairs within a document. However, most existing methods assume a
uniform label distribution, resulting in suboptimal performance on real-world,
imbalanced datasets. To tackle this challenge, we propose a novel data
augmentation approach using generative models to enhance data from the
embedding space. Our method leverages the Variational Autoencoder (VAE)
architecture to capture all relation-wise distributions formed by entity pair
representations and augment data for underrepresented relations. To better
capture the multi-label nature of DocRE, we parameterize the VAE's latent space
with a Diffusion Model. Additionally, we introduce a hierarchical training
framework to integrate the proposed VAE-based augmentation module into DocRE
systems. Experiments on two benchmark datasets demonstrate that our method
outperforms state-of-the-art models, effectively addressing the long-tail
distribution problem in DocRE.",2024-12-18,"Khai Phan Tran, Wen Hua, Xue Li",http://arxiv.org/pdf/2412.13503v2,cs.CL
Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models,"Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank
adaptation methods like LoRA. In this paper, we focus on sparsity-based PEFT
(SPEFT), which introduces trainable sparse adaptations to the weight matrices
in the model, offering greater flexibility in selecting fine-tuned parameters
compared to low-rank methods. We conduct the first systematic evaluation of
salience metrics for SPEFT, inspired by zero-cost NAS proxies, and identify
simple gradient-based metrics is reliable, and results are on par with the best
alternatives, offering both computational efficiency and robust performance.
Additionally, we compare static and dynamic masking strategies, finding that
static masking, which predetermines non-zero entries before training, delivers
efficiency without sacrificing performance, while dynamic masking offers no
substantial benefits. Across NLP tasks, a simple gradient-based, static SPEFT
consistently outperforms other fine-tuning methods for LLMs, providing a simple
yet effective baseline for SPEFT. Our work challenges the notion that
complexity is necessary for effective PEFT. Our work is open source and
available to the community at [https://github.com/0-ml/speft].",2024-12-18,"Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao, Xitong Gao",http://arxiv.org/pdf/2412.13488v1,cs.CL
Context-DPO: Aligning Language Models for Context-Faithfulness,"Reliable responses from large language models (LLMs) require adherence to
user instructions and retrieved information. While alignment techniques help
LLMs align with human intentions and values, improving context-faithfulness
through alignment remains underexplored. To address this, we propose
$\textbf{Context-DPO}$, the first alignment method specifically designed to
enhance LLMs' context-faithfulness. We introduce $\textbf{ConFiQA}$, a
benchmark that simulates Retrieval-Augmented Generation (RAG) scenarios with
knowledge conflicts to evaluate context-faithfulness. By leveraging faithful
and stubborn responses to questions with provided context from ConFiQA, our
Context-DPO aligns LLMs through direct preference optimization. Extensive
experiments demonstrate that our Context-DPO significantly improves
context-faithfulness, achieving 35% to 280% improvements on popular open-source
models. Further analysis demonstrates that Context-DPO preserves LLMs'
generative capabilities while providing interpretable insights into context
utilization. Our code and data are released at
https://github.com/byronBBL/Context-DPO",2024-12-18,"Baolong Bi, Shaohan Huang, Yiwei Wang, Tianchi Yang, Zihan Zhang, Haizhen Huang, Lingrui Mei, Junfeng Fang, Zehao Li, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Shenghua Liu",http://arxiv.org/pdf/2412.15280v1,cs.CL
T$^3$-S2S: Training-free Triplet Tuning for Sketch to Scene Generation,"Scene generation is crucial to many computer graphics applications. Recent
advances in generative AI have streamlined sketch-to-image workflows, easing
the workload for artists and designers in creating scene concept art. However,
these methods often struggle for complex scenes with multiple detailed objects,
sometimes missing small or uncommon instances. In this paper, we propose a
Training-free Triplet Tuning for Sketch-to-Scene (T3-S2S) generation after
reviewing the entire cross-attention mechanism. This scheme revitalizes the
existing ControlNet model, enabling effective handling of multi-instance
generations, involving prompt balance, characteristics prominence, and dense
tuning. Specifically, this approach enhances keyword representation via the
prompt balance module, reducing the risk of missing critical instances. It also
includes a characteristics prominence module that highlights TopK indices in
each channel, ensuring essential features are better represented based on token
sketches. Additionally, it employs dense tuning to refine contour details in
the attention map, compensating for instance-related regions. Experiments
validate that our triplet tuning approach substantially improves the
performance of existing sketch-to-image models. It consistently generates
detailed, multi-instance 2D images, closely adhering to the input prompts and
enhancing visual quality in complex multi-instance scenes. Code is available at
https://github.com/chaos-sun/t3s2s.git.",2024-12-18,"Zhenhong Sun, Yifu Wang, Yonhon Ng, Yunfei Duan, Daoyi Dong, Hongdong Li, Pan Ji",http://arxiv.org/pdf/2412.13486v1,cs.CL
Curriculum Learning for Cross-Lingual Data-to-Text Generation With Noisy Data,"Curriculum learning has been used to improve the quality of text generation
systems by ordering the training samples according to a particular schedule in
various tasks. In the context of data-to-text generation (DTG), previous
studies used various difficulty criteria to order the training samples for
monolingual DTG. These criteria, however, do not generalize to the crosslingual
variant of the problem and do not account for noisy data. We explore multiple
criteria that can be used for improving the performance of cross-lingual DTG
systems with noisy data using two curriculum schedules. Using the alignment
score criterion for ordering samples and an annealing schedule to train the
model, we show increase in BLEU score by up to 4 points, and improvements in
faithfulness and coverage of generations by 5-15% on average across 11 Indian
languages and English in 2 separate datasets. We make code and data publicly
available",2024-12-18,"Kancharla Aditya Hari, Manish Gupta, Vasudeva Varma",http://arxiv.org/pdf/2412.13484v1,cs.CL
A Statistical and Multi-Perspective Revisiting of the Membership Inference Attack in Large Language Models,"The lack of data transparency in Large Language Models (LLMs) has highlighted
the importance of Membership Inference Attack (MIA), which differentiates
trained (member) and untrained (non-member) data. Though it shows success in
previous studies, recent research reported a near-random performance in
different settings, highlighting a significant performance inconsistency. We
assume that a single setting doesn't represent the distribution of the vast
corpora, causing members and non-members with different distributions to be
sampled and causing inconsistency. In this study, instead of a single setting,
we statistically revisit MIA methods from various settings with thousands of
experiments for each MIA method, along with study in text feature, embedding,
threshold decision, and decoding dynamics of members and non-members. We found
that (1) MIA performance improves with model size and varies with domains,
while most methods do not statistically outperform baselines, (2) Though MIA
performance is generally low, a notable amount of differentiable member and
non-member outliers exists and vary across MIA methods, (3) Deciding a
threshold to separate members and non-members is an overlooked challenge, (4)
Text dissimilarity and long text benefit MIA performance, (5) Differentiable or
not is reflected in the LLM embedding, (6) Member and non-members show
different decoding dynamics.",2024-12-18,"Bowen Chen, Namgi Han, Yusuke Miyao",http://arxiv.org/pdf/2412.13475v1,cs.CL
Gradual Vigilance and Interval Communication: Enhancing Value Alignment in Multi-Agent Debates,"In recent years, large language models have shown exceptional performance in
fulfilling diverse human needs. However, their training data can introduce
harmful content, underscoring the necessity for robust value alignment.
Mainstream methods, which depend on feedback learning and supervised training,
are resource-intensive and may constrain the full potential of the models.
Multi-Agent Debate (MAD) offers a more efficient and innovative solution by
enabling the generation of reliable answers through agent interactions. To
apply MAD to value alignment, we examine the relationship between the
helpfulness and harmlessness of debate outcomes and individual responses, and
propose a MAD based framework Gradual Vigilance and Interval Communication
(GVIC). GVIC allows agents to assess risks with varying levels of vigilance and
to exchange diverse information through interval communication. We
theoretically prove that GVIC optimizes debate efficiency while reducing
communication overhead. Experimental results demonstrate that GVIC consistently
outperforms baseline methods across various tasks and datasets, particularly
excelling in harmfulness mitigation and fraud prevention. Additionally, GVIC
exhibits strong adaptability across different base model sizes, including both
unaligned and aligned models, and across various task types.",2024-12-18,"Rui Zou, Mengqi Wei, Jintian Feng, Qian Wan, Jianwen Sun, Sannyuya Liu",http://arxiv.org/pdf/2412.13471v1,cs.CL
Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs,"Large language models have demonstrated promising performance across various
software engineering tasks. While fine-tuning is a common practice to adapt
these models for downstream tasks, it becomes challenging in
resource-constrained environments due to increased memory requirements from
growing trainable parameters in increasingly large language models. We
introduce \approach, a technique to adapt large models for downstream code
tasks using Code Property Graphs (CPGs). Our approach introduces a modular
component called \transducer that enriches code embeddings with structural and
dependency information from CPGs. The Transducer comprises two key components:
Graph Vectorization Engine (GVE) and Attention-Based Fusion Layer (ABFL). GVE
extracts CPGs from input source code and transforms them into graph feature
vectors. ABFL then fuses those graphs feature vectors with initial code
embeddings from a large language model. By optimizing these transducers for
different downstream tasks, our approach enhances the models without the need
to fine-tune them for specific tasks. We have evaluated \approach on three
downstream tasks: code summarization, assert generation, and code translation.
Our results demonstrate competitive performance compared to full parameter
fine-tuning while reducing up to 99\% trainable parameters to save memory.
\approach also remains competitive against other fine-tuning approaches (e.g.,
LoRA, Prompt-Tuning, Prefix-Tuning) while using only 1.5\%-80\% of their
trainable parameters. Our findings show that integrating structural and
dependency information through Transducer Tuning enables more efficient model
adaptation, making it easier for users to adapt large models in
resource-constrained settings.",2024-12-18,"Imam Nur Bani Yusuf, Lingxiao Jiang",http://arxiv.org/pdf/2412.13467v1,cs.CL
GenX: Mastering Code and Test Generation with Execution Feedback,"Recent advancements in language modeling have enabled the translation of
natural language into code, and the use of execution feedback to improve code
generation. However, these methods often rely heavily on pre-existing test
cases, which may not always be available or comprehensive. In this work, we
propose a novel approach that concurrently trains a code generation model and a
test generation model, utilizing execution feedback to refine and enhance the
performance of both. We introduce two strategies for test and code data
augmentation and a new scoring function for code and test ranking. We
experiment on the APPS dataset and demonstrate that our approach can
effectively generate and augment test cases, filter and synthesize correct code
solutions, and rank the quality of generated code and tests. The results
demonstrate that our models, when iteratively trained with an increasing number
of test cases and code solutions, outperform those trained on the original
dataset.",2024-12-18,"Nan Wang, Yafei Liu, Chen Chen, Haonan Lu",http://arxiv.org/pdf/2412.13464v1,cs.CL
PLPP: Prompt Learning with Perplexity Is Self-Distillation for Vision-Language Models,"Pre-trained Vision-Language (VL) models such as CLIP have demonstrated their
excellent performance across numerous downstream tasks. A recent method,
Context Optimization (CoOp), further improves the performance of VL models on
downstream tasks by introducing prompt learning. CoOp optimizes a set of
learnable vectors, aka prompt, and freezes the whole CLIP model. However,
relying solely on CLIP loss to fine-tune prompts can lead to models that are
prone to overfitting on downstream task. To address this issue, we propose a
plug-in prompt-regularization method called PLPP (Prompt Learning with
PerPlexity), which use perplexity loss to regularize prompt learning. PLPP
designs a two-step operation to compute the perplexity for prompts: (a)
calculating cosine similarity between the weight of the embedding layer and
prompts to get labels, (b) introducing a language model (LM) head that requires
no training behind text encoder to output word probability distribution.
Meanwhile, we unveil that the essence of PLPP is inherently a form of
self-distillation. To further prevent overfitting as well as to reduce the
additional computation introduced by PLPP, we turn the hard label to soft label
and choose top-$k$ values for calculating the perplexity loss. For accelerating
model convergence, we introduce mutual self-distillation learning, that is
perplexity and inverted perplexity loss. The experiments conducted on four
classification tasks indicate that PLPP exhibits superior performance compared
to existing methods.",2024-12-18,"Biao Liu, Wenyi Fang, Xiaoyu Wu, Yang Zheng, Zheng Hu, Bo Yuan",http://arxiv.org/pdf/2412.15277v1,cs.CL
FlashVTG: Feature Layering and Adaptive Score Handling Network for Video Temporal Grounding,"Text-guided Video Temporal Grounding (VTG) aims to localize relevant segments
in untrimmed videos based on textual descriptions, encompassing two subtasks:
Moment Retrieval (MR) and Highlight Detection (HD). Although previous typical
methods have achieved commendable results, it is still challenging to retrieve
short video moments. This is primarily due to the reliance on sparse and
limited decoder queries, which significantly constrain the accuracy of
predictions. Furthermore, suboptimal outcomes often arise because previous
methods rank predictions based on isolated predictions, neglecting the broader
video context. To tackle these issues, we introduce FlashVTG, a framework
featuring a Temporal Feature Layering (TFL) module and an Adaptive Score
Refinement (ASR) module. The TFL module replaces the traditional decoder
structure to capture nuanced video content variations across multiple temporal
scales, while the ASR module improves prediction ranking by integrating context
from adjacent moments and multi-temporal-scale features. Extensive experiments
demonstrate that FlashVTG achieves state-of-the-art performance on four widely
adopted datasets in both MR and HD. Specifically, on the QVHighlights dataset,
it boosts mAP by 5.8% for MR and 3.3% for HD. For short-moment retrieval,
FlashVTG increases mAP to 125% of previous SOTA performance. All these
improvements are made without adding training burdens, underscoring its
effectiveness. Our code is available at https://github.com/Zhuo-Cao/FlashVTG.",2024-12-18,"Zhuo Cao, Bingqing Zhang, Heming Du, Xin Yu, Xue Li, Sen Wang",http://arxiv.org/pdf/2412.13441v1,cs.CL
GMoE: Empowering LLMs Fine-Tuning via MoE Graph Collaboration,"The sparse Mixture-of-Experts (MoE) architecture of large language models
(LLMs) confronts an inherent issue of load imbalance arising from the
simplistic linear router strategy, which ultimately causes the instability and
inefficient learning of LLMs. To address this challenge, we introduce a novel
MoE graph-based framework $\textbf{GMoE}$, aimed at enhancing the collaboration
among multiple experts. In GMoE, a graph router function is designed to capture
the collaboration signals among experts. This enables all experts to
dynamically allocate information derived from input data by sharing information
with their neighboring experts. Moreover, we put forward two coordination
strategies in GMoE: the $\textit{Poisson distribution-based distinction
strategy}$ and the $\textit{Normal distribution-based balance strategy}$, to
further release the capacity of each expert and increase the model stability in
the fine-tuning of LLMs. Specifically, we leverage a parameter-efficient
fine-tuning technique, i.e., Low-Rank Adaptation (LoRA), to implement the graph
MoE architecture. Extensive experiments on four real-world benchmark datasets
demonstrate the effectiveness of GMoE, showing the benefits of facilitating
collaborations of multiple experts in LLM fine-tuning. The code of experimental
implementation is available at https://github.com/BAI-LAB/GMoE",2024-12-18,"Ting Bai, Yue Yu, Le Huang, Zenan Xu, Zhe Zhao, Chuan Shi",http://arxiv.org/pdf/2412.16216v2,cs.CL
Lightweight Safety Classification Using Pruned Language Models,"In this paper, we introduce a novel technique for content safety and prompt
injection classification for Large Language Models. Our technique, Layer
Enhanced Classification (LEC), trains a Penalized Logistic Regression (PLR)
classifier on the hidden state of an LLM's optimal intermediate transformer
layer. By combining the computational efficiency of a streamlined PLR
classifier with the sophisticated language understanding of an LLM, our
approach delivers superior performance surpassing GPT-4o and special-purpose
models fine-tuned for each task. We find that small general-purpose models
(Qwen 2.5 sizes 0.5B, 1.5B, and 3B) and other transformer-based architectures
like DeBERTa v3 are robust feature extractors allowing simple classifiers to be
effectively trained on fewer than 100 high-quality examples. Importantly, the
intermediate transformer layers of these models typically outperform the final
layer across both classification tasks. Our results indicate that a single
general-purpose LLM can be used to classify content safety, detect prompt
injections, and simultaneously generate output tokens. Alternatively, these
relatively small LLMs can be pruned to the optimal intermediate layer and used
exclusively as robust feature extractors. Since our results are consistent on
different transformer architectures, we infer that robust feature extraction is
an inherent capability of most, if not all, LLMs.",2024-12-18,"Mason Sawtell, Tula Masterman, Sandi Besen, Jim Brown",http://arxiv.org/pdf/2412.13435v1,cs.CL
Enhancing Talk Moves Analysis in Mathematics Tutoring through Classroom Teaching Discourse,"Human tutoring interventions play a crucial role in supporting student
learning, improving academic performance, and promoting personal growth. This
paper focuses on analyzing mathematics tutoring discourse using talk moves - a
framework of dialogue acts grounded in Accountable Talk theory. However,
scaling the collection, annotation, and analysis of extensive tutoring
dialogues to develop machine learning models is a challenging and
resource-intensive task. To address this, we present SAGA22, a compact dataset,
and explore various modeling strategies, including dialogue context, speaker
information, pretraining datasets, and further fine-tuning. By leveraging
existing datasets and models designed for classroom teaching, our results
demonstrate that supplementary pretraining on classroom data enhances model
performance in tutoring settings, particularly when incorporating longer
context and speaker information. Additionally, we conduct extensive ablation
studies to underscore the challenges in talk move modeling.",2024-12-18,"Jie Cao, Abhijit Suresh, Jennifer Jacobs, Charis Clevenger, Amanda Howard, Chelsea Brown, Brent Milne, Tom Fischaber, Tamara Sumner, James H. Martin",http://arxiv.org/pdf/2412.13395v1,cs.CL
Catalysts of Conversation: Examining Interaction Dynamics Between Topic Initiators and Commentors in Alzheimer's Disease Online Communities,"Informal caregivers (e.g.,family members or friends) of people living with
Alzheimers Disease and Related Dementias (ADRD) face substantial challenges and
often seek informational or emotional support through online communities.
Understanding the factors that drive engagement within these platforms is
crucial, as it can enhance their long-term value for caregivers by ensuring
that these communities effectively meet their needs. This study investigated
the user interaction dynamics within two large, popular ADRD communities,
TalkingPoint and ALZConnected, focusing on topic initiator engagement, initial
post content, and the linguistic patterns of comments at the thread level.
Using analytical methods such as propensity score matching, topic modeling, and
predictive modeling, we found that active topic initiator engagement drives
higher comment volumes, and reciprocal replies from topic initiators encourage
further commentor engagement at the community level. Practical caregiving
topics prompt more re-engagement of topic initiators, while emotional support
topics attract more comments from other commentors. Additionally, the
linguistic complexity and emotional tone of a comment influence its likelihood
of receiving replies from topic initiators. These findings highlight the
importance of fostering active and reciprocal engagement and providing
effective strategies to enhance sustainability in ADRD caregiving and broader
health-related online communities.",2024-12-18,"Congning Ni, Qingxia Chen, Lijun Song, Patricia Commiskey, Qingyuan Song, Bradley A. Malin, Zhijun Yin",http://arxiv.org/pdf/2412.13388v1,cs.CL
An Automated Explainable Educational Assessment System Built on LLMs,"In this demo, we present AERA Chat, an automated and explainable educational
assessment system designed for interactive and visual evaluations of student
responses. This system leverages large language models (LLMs) to generate
automated marking and rationale explanations, addressing the challenge of
limited explainability in automated educational assessment and the high costs
associated with annotation. Our system allows users to input questions and
student answers, providing educators and researchers with insights into
assessment accuracy and the quality of LLM-assessed rationales. Additionally,
it offers advanced visualization and robust evaluation tools, enhancing the
usability for educational assessment and facilitating efficient rationale
verification. Our demo video can be found at https://youtu.be/qUSjz-sxlBc.",2024-12-17,"Jiazheng Li, Artem Bobrov, David West, Cesare Aloisi, Yulan He",http://arxiv.org/pdf/2412.13381v1,cs.CL
SummExecEdit: A Factual Consistency Benchmark in Summarization with Executable Edits,"Detecting factual inconsistencies in summarization is critical, yet existing
benchmarks lack the necessary challenge and interpretability for robust
evaluation. In this paper, we introduce SummExecEdit, a novel benchmark
leveraging executable edits to assess models on their ability to both detect
factual errors and provide accurate explanations. The top-performing model,
Claude3-Opus, achieves a joint detection and explanation score of only 0.49 in
our benchmark, with individual scores of 0.67 for detection and 0.73 for
explanation. Furthermore, we identify four primary types of explanation errors,
with 45.4% of errors focusing on completely unrelated parts of the summary.",2024-12-17,"Onkar Thorat, Philippe Laban, Chien-Sheng Wu",http://arxiv.org/pdf/2412.13378v1,cs.CL
DateLogicQA: Benchmarking Temporal Biases in Large Language Models,"This paper introduces DateLogicQA, a benchmark with 190 questions covering
diverse date formats, temporal contexts, and reasoning types. We propose the
Semantic Integrity Metric to assess tokenization quality and analyse two
biases: Representation-Level Bias, affecting embeddings, and Logical-Level
Bias, influencing reasoning outputs. Our findings provide a comprehensive
evaluation of LLMs' capabilities and limitations in temporal reasoning,
highlighting key challenges in handling temporal data accurately.",2024-12-17,"Gagan Bhatia, MingZe Tang, Cristina Mahanta, Madiha Kazi",http://arxiv.org/pdf/2412.13377v2,cs.CL
Extending LLMs to New Languages: A Case Study of Llama and Persian Adaptation,"Large language models (LLMs) have made great progress in classification and
text generation tasks. However, they are mainly trained on English data and
often struggle with low-resource languages. In this study, we explore adding a
new language, i.e., Persian, to Llama (a model with a limited understanding of
Persian) using parameter-efficient fine-tuning. We employ a multi-stage
approach involving pretraining on monolingual Persian data, aligning
representations through bilingual pretraining and instruction datasets, and
instruction-tuning with task-specific datasets. We evaluate the model's
performance at each stage on generation and classification tasks. Our findings
suggest that incorporating the Persian language, through bilingual data
alignment, can enhance classification accuracy for Persian tasks, with no
adverse impact and sometimes even improvements on English tasks. Additionally,
the results highlight the model's initial strength as a critical factor when
working with limited training data, with cross-lingual alignment offering
minimal benefits for the low-resource language. Knowledge transfer from English
to Persian has a marginal effect, primarily benefiting simple classification
tasks.",2024-12-17,"Samin Mahdizadeh Sani, Pouya Sadeghi, Thuy-Trang Vu, Yadollah Yaghoobzadeh, Gholamreza Haffari",http://arxiv.org/pdf/2412.13375v2,cs.CL
Is Your World Simulator a Good Story Presenter? A Consecutive Events-Based Benchmark for Future Long Video Generation,"The current state-of-the-art video generative models can produce
commercial-grade videos with highly realistic details. However, they still
struggle to coherently present multiple sequential events in the stories
specified by the prompts, which is foreseeable an essential capability for
future long video generation scenarios. For example, top T2V generative models
still fail to generate a video of the short simple story 'how to put an
elephant into a refrigerator.' While existing detail-oriented benchmarks
primarily focus on fine-grained metrics like aesthetic quality and
spatial-temporal consistency, they fall short of evaluating models' abilities
to handle event-level story presentation. To address this gap, we introduce
StoryEval, a story-oriented benchmark specifically designed to assess
text-to-video (T2V) models' story-completion capabilities. StoryEval features
423 prompts spanning 7 classes, each representing short stories composed of 2-4
consecutive events. We employ advanced vision-language models, such as GPT-4V
and LLaVA-OV-Chat-72B, to verify the completion of each event in the generated
videos, applying a unanimous voting method to enhance reliability. Our methods
ensure high alignment with human evaluations, and the evaluation of 11 models
reveals its challenge, with none exceeding an average story-completion rate of
50%. StoryEval provides a new benchmark for advancing T2V models and highlights
the challenges and opportunities in developing next-generation solutions for
coherent story-driven video generation.",2024-12-17,"Yiping Wang, Xuehai He, Kuan Wang, Luyao Ma, Jianwei Yang, Shuohang Wang, Simon Shaolei Du, Yelong Shen",http://arxiv.org/pdf/2412.16211v1,cs.CL
Training Dynamics of a 1.7B LLaMa Model: A Data-Efficient Approach,"Pretraining large language models is a complex endeavor influenced by
multiple factors, including model architecture, data quality, training
continuity, and hardware constraints. In this paper, we share insights gained
from the experience of training DMaS-LLaMa-Lite, a fully open source,
1.7-billion-parameter, LLaMa-based model, on approximately 20 billion tokens of
carefully curated data. We chronicle the full training trajectory, documenting
how evolving validation loss levels and downstream benchmarks reflect
transitions from incoherent text to fluent, contextually grounded output.
Beyond pretraining, we extend our analysis to include a post-training phase
focused on instruction tuning, where the model was refined to produce more
contextually appropriate, user-aligned responses. We highlight practical
considerations such as the importance of restoring optimizer states when
resuming from checkpoints, and the impact of hardware changes on training
stability and throughput. While qualitative evaluation provides an intuitive
understanding of model improvements, our analysis extends to various
performance benchmarks, demonstrating how high-quality data and thoughtful
scaling enable competitive results with significantly fewer training tokens. By
detailing these experiences and offering training logs, checkpoints, and sample
outputs, we aim to guide future researchers and practitioners in refining their
pretraining strategies. The training script is available on Github at
https://github.com/McGill-DMaS/DMaS-LLaMa-Lite-Training-Code. The model
checkpoints are available on Huggingface at
https://huggingface.co/collections/McGill-DMaS/dmas-llama-lite-6761d97ba903f82341954ceb.",2024-12-17,"Miles Q. Li, Benjamin C. M. Fung, Shih-Chia Huang",http://arxiv.org/pdf/2412.13335v3,cs.CL
Expansion Span: Combining Fading Memory and Retrieval in Hybrid State Space Models,"The ""state"" of State Space Models (SSMs) represents their memory, which fades
exponentially over an unbounded span. By contrast, Attention-based models have
""eidetic"" (i.e., verbatim, or photographic) memory over a finite span (context
size). Hybrid architectures combine State Space layers with Attention, but
still cannot recall the distant past and can access only the most recent tokens
eidetically. Unlike current methods of combining SSM and Attention layers, we
allow the state to be allocated based on relevancy rather than recency. In this
way, for every new set of query tokens, our models can ""eidetically"" access
tokens from beyond the Attention span of current Hybrid SSMs without requiring
extra hardware resources. We introduce a method to expand the memory span of
the hybrid state by ""reserving"" a fraction of the Attention context for tokens
retrieved from arbitrarily distant in the past, thus expanding the eidetic
memory span of the overall state. We call this reserved fraction of tokens the
""expansion span,"" and the mechanism to retrieve and aggregate it ""Span-Expanded
Attention"" (SE-Attn). To adapt Hybrid models to using SE-Attn, we propose a
novel fine-tuning method that extends LoRA to Hybrid models (HyLoRA) and allows
efficient adaptation on long spans of tokens. We show that SE-Attn enables us
to efficiently adapt pre-trained Hybrid models on sequences of tokens up to 8
times longer than the ones used for pre-training. We show that HyLoRA with
SE-Attn is cheaper and more performant than alternatives like LongLoRA when
applied to Hybrid models on natural language benchmarks with long-range
dependencies, such as PG-19, RULER, and other common natural language
downstream tasks.",2024-12-17,"Elvis Nunez, Luca Zancato, Benjamin Bowman, Aditya Golatkar, Wei Xia, Stefano Soatto",http://arxiv.org/pdf/2412.13328v2,cs.CL
Refining Answer Distributions for Improved Large Language Model Reasoning,"Large Language Models (LLMs) have exhibited an impressive capability to
perform reasoning tasks, especially if they are encouraged to generate a
sequence of intermediate steps. Reasoning performance can be improved by
suitably combining multiple LLM responses, generated either in parallel in a
single query, or via sequential interactions with LLMs throughout the reasoning
process. Existing strategies for combination, such as self-consistency and
progressive-hint-prompting, make inefficient usage of the LLM responses. We
present Refined Answer Distributions, a novel and principled algorithmic
framework to enhance the reasoning capabilities of LLMs. Our approach can be
viewed as an iterative sampling strategy for forming a Monte Carlo
approximation of an underlying distribution of answers, with the goal of
identifying the mode -- the most likely answer. Empirical evaluation on several
reasoning benchmarks demonstrates the superiority of the proposed approach.",2024-12-17,"Soumyasundar Pal, Didier Chételat, Yingxue Zhang, Mark Coates",http://arxiv.org/pdf/2412.13292v2,cs.CL
Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach,"In recent years, Large Language Models (LLMs) gain considerable attention for
their potential to enhance personalized experiences in virtual assistants and
chatbots. A key area of interest is the integration of personas into LLMs to
improve dialogue naturalness and user engagement. This study addresses the
challenge of persona classification, a crucial component in dialogue
understanding, by proposing a framework that combines text embeddings with
Graph Neural Networks (GNNs) for effective persona classification. Given the
absence of dedicated persona classification datasets, we create a manually
annotated dataset to facilitate model training and evaluation. Our method
involves extracting semantic features from persona statements using text
embeddings and constructing a graph where nodes represent personas and edges
capture their similarities. The GNN component uses this graph structure to
propagate relevant information, thereby improving classification performance.
Experimental results show that our approach, in particular the integration of
GNNs, significantly improves classification performance, especially with
limited data. Our contributions include the development of a persona
classification framework and the creation of a dataset.",2024-12-17,Konstantin Zaitsev,http://arxiv.org/pdf/2412.13283v1,cs.CL
Fooling LLM graders into giving better grades through neural activity guided adversarial prompting,"The deployment of artificial intelligence (AI) in critical decision-making
and evaluation processes raises concerns about inherent biases that malicious
actors could exploit to distort decision outcomes. We propose a systematic
method to reveal such biases in AI evaluation systems and apply it to automated
essay grading as an example. Our approach first identifies hidden neural
activity patterns that predict distorted decision outcomes and then optimizes
an adversarial input suffix to amplify such patterns. We demonstrate that this
combination can effectively fool large language model (LLM) graders into
assigning much higher grades than humans would. We further show that this
white-box attack transfers to black-box attacks on other models, including
commercial closed-source models like Gemini. They further reveal the existence
of a ""magic word"" that plays a pivotal role in the efficacy of the attack. We
trace the origin of this magic word bias to the structure of commonly-used chat
templates for supervised fine-tuning of LLMs and show that a minor change in
the template can drastically reduce the bias. This work not only uncovers
vulnerabilities in current LLMs but also proposes a systematic method to
identify and remove hidden biases, contributing to the goal of ensuring AI
safety and security.",2024-12-17,"Atsushi Yamamura, Surya Ganguli",http://arxiv.org/pdf/2412.15275v1,cs.CL
DnDScore: Decontextualization and Decomposition for Factuality Verification in Long-Form Text Generation,"The decompose-then-verify strategy for verification of Large Language Model
(LLM) generations decomposes claims that are then independently verified.
Decontextualization augments text (claims) to ensure it can be verified outside
of the original context, enabling reliable verification. While decomposition
and decontextualization have been explored independently, their interactions in
a complete system have not been investigated. Their conflicting purposes can
create tensions: decomposition isolates atomic facts while decontextualization
inserts relevant information. Furthermore, a decontextualized subclaim presents
a challenge to the verification step: what part of the augmented text should be
verified as it now contains multiple atomic facts? We conduct an evaluation of
different decomposition, decontextualization, and verification strategies and
find that the choice of strategy matters in the resulting factuality scores.
Additionally, we introduce DnDScore, a decontextualization aware verification
method which validates subclaims in the context of contextual information.",2024-12-17,"Miriam Wanner, Benjamin Van Durme, Mark Dredze",http://arxiv.org/pdf/2412.13175v1,cs.CL
Compressed Chain of Thought: Efficient Reasoning Through Dense Representations,"Chain-of-thought (CoT) decoding enables language models to improve reasoning
performance at the cost of high generation latency in decoding. Recent
proposals have explored variants of contemplation tokens, a term we introduce
that refers to special tokens used during inference to allow for extra
computation. Prior work has considered fixed-length sequences drawn from a
discrete set of embeddings as contemplation tokens. Here we propose Compressed
Chain-of-Thought (CCoT), a framework to generate contentful and continuous
contemplation tokens of variable sequence length. The generated contemplation
tokens are compressed representations of explicit reasoning chains, and our
method can be applied to off-the-shelf decoder language models. Through
experiments, we illustrate how CCoT enables additional reasoning over dense
contentful representations to achieve corresponding improvements in accuracy.
Moreover, the reasoning improvements can be adaptively modified on demand by
controlling the number of contemplation tokens generated.",2024-12-17,"Jeffrey Cheng, Benjamin Van Durme",http://arxiv.org/pdf/2412.13171v1,cs.CL
In-Context Learning Distillation for Efficient Few-Shot Fine-Tuning,"We applied few-shot in-context learning on the OPT-1.3B model for the natural
language inference task and employed knowledge distillation to internalize the
context information, reducing model parameter from 1.3B to 125M and achieving a
size reduction from 2.5GB to 0.25GB. Compared to using in-context learning
alone on similarly sized models, this context distillation approach achieved a
nearly 50% improvement in out-of-domain accuracy, demonstrating superior
knowledge transfer capabilities over prompt-based methods. Furthermore, this
approach reduced memory consumption by up to 60% while delivering a 20%
improvement in out-of-domain accuracy compared to conventional pattern-based
fine-tuning.",2024-12-17,"Yifei Duan, Liu Li, Zirui Zhai, Jinxia Yao",http://arxiv.org/pdf/2412.13243v1,cs.CL
Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study,"In recent research, large language models (LLMs) have been increasingly used
to investigate public opinions. This study investigates the algorithmic
fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and
nuanced opinions of human participants. Using open-ended survey data from the
German Longitudinal Election Studies (GLES), we prompt different LLMs to
generate synthetic public opinions reflective of German subpopulations by
incorporating demographic features into the persona prompts. Our results show
that Llama performs better than other LLMs at representing subpopulations,
particularly when there is lower opinion diversity within those groups. Our
findings further reveal that the LLM performs better for supporters of
left-leaning parties like The Greens and The Left compared to other parties,
and matches the least with the right-party AfD. Additionally, the inclusion or
exclusion of specific variables in the prompts can significantly impact the
models' predictions. These findings underscore the importance of aligning LLMs
to more effectively model diverse public opinions while minimizing political
biases and enhancing robustness in representativeness.",2024-12-17,"Bolei Ma, Berk Yoztyurk, Anna-Carolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Assenmacher",http://arxiv.org/pdf/2412.13169v1,cs.CL
BanglishRev: A Large-Scale Bangla-English and Code-mixed Dataset of Product Reviews in E-Commerce,"This work presents the BanglishRev Dataset, the largest e-commerce product
review dataset to date for reviews written in Bengali, English, a mixture of
both and Banglish, Bengali words written with English alphabets. The dataset
comprises of 1.74 million written reviews from 3.2 million ratings information
collected from a total of 128k products being sold in online e-commerce
platforms targeting the Bengali population. It includes an extensive array of
related metadata for each of the reviews including the rating given by the
reviewer, date the review was posted and date of purchase, number of likes,
dislikes, response from the seller, images associated with the review etc. With
sentiment analysis being the most prominent usage of review datasets,
experimentation with a binary sentiment analysis model with the review rating
serving as an indicator of positive or negative sentiment was conducted to
evaluate the effectiveness of the large amount of data presented in BanglishRev
for sentiment analysis tasks. A BanglishBERT model is trained on the data from
BanglishRev with reviews being considered labeled positive if the rating is
greater than 3 and negative if the rating is less than or equal to 3. The model
is evaluated by being testing against a previously published manually annotated
dataset for e-commerce reviews written in a mixture of Bangla, English and
Banglish. The experimental model achieved an exceptional accuracy of 94\% and
F1 score of 0.94, demonstrating the dataset's efficacy for sentiment analysis.
Some of the intriguing patterns and observations seen within the dataset and
future research directions where the dataset can be utilized is also discussed
and explored. The dataset can be accessed through
https://huggingface.co/datasets/BanglishRev/bangla-english-and-code-mixed-ecommerce-review-dataset.",2024-12-17,"Mohammad Nazmush Shamael, Sabila Nawshin, Swakkhar Shatabda, Salekul Islam",http://arxiv.org/pdf/2412.13161v2,cs.CL
Memory-Augmented Agent Training for Business Document Understanding,"Traditional enterprises face significant challenges in processing business
documents, where tasks like extracting transport references from invoices
remain largely manual despite their crucial role in logistics operations. While
Large Language Models offer potential automation, their direct application to
specialized business domains often yields unsatisfactory results. We introduce
Matrix (Memory-Augmented agent Training through Reasoning and Iterative
eXploration), a novel paradigm that enables LLM agents to progressively build
domain expertise through experience-driven memory refinement and iterative
learning. To validate this approach, we collaborate with one of the world's
largest logistics companies to create a dataset of Universal Business Language
format invoice documents, focusing on the task of transport reference
extraction. Experiments demonstrate that Matrix outperforms prompting a single
LLM by 30.3%, vanilla LLM agent by 35.2%. We further analyze the metrics of the
optimized systems and observe that the agent system requires less API calls,
fewer costs and can analyze longer documents on average. Our methods establish
a new approach to transform general-purpose LLMs into specialized business
tools through systematic memory enhancement in document processing tasks.",2024-12-17,"Jiale Liu, Yifan Zeng, Malte Højmark-Bertelsen, Marie Normann Gadeberg, Huazheng Wang, Qingyun Wu",http://arxiv.org/pdf/2412.15274v1,cs.CL
Are Your LLMs Capable of Stable Reasoning?,"The rapid advancement of Large Language Models (LLMs) has demonstrated
remarkable progress in complex reasoning tasks. However, a significant
discrepancy persists between benchmark performances and real-world
applications. We identify this gap as primarily stemming from current
evaluation protocols and metrics, which inadequately capture the full spectrum
of LLM capabilities, particularly in complex reasoning tasks where both
accuracy and consistency are crucial. This work makes two key contributions.
First, we introduce G-Pass@k, a novel evaluation metric that provides a
continuous assessment of model performance across multiple sampling attempts,
quantifying both the model's peak performance potential and its stability.
Second, we present LiveMathBench, a dynamic benchmark comprising challenging,
contemporary mathematical problems designed to minimize data leakage risks
during evaluation. Through extensive experiments using G-Pass@k on
state-of-the-art LLMs with LiveMathBench, we provide comprehensive insights
into both their maximum capabilities and operational consistency. Our findings
reveal substantial room for improvement in LLMs' ""realistic"" reasoning
capabilities, highlighting the need for more robust evaluation methods. The
benchmark and detailed results are available at:
https://github.com/open-compass/GPassK.",2024-12-17,"Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen",http://arxiv.org/pdf/2412.13147v3,cs.CL
Syntactic Transfer to Kyrgyz Using the Treebank Translation Method,"The Kyrgyz language, as a low-resource language, requires significant effort
to create high-quality syntactic corpora. This study proposes an approach to
simplify the development process of a syntactic corpus for Kyrgyz. We present a
tool for transferring syntactic annotations from Turkish to Kyrgyz based on a
treebank translation method. The effectiveness of the proposed tool was
evaluated using the TueCL treebank. The results demonstrate that this approach
achieves higher syntactic annotation accuracy compared to a monolingual model
trained on the Kyrgyz KTMU treebank. Additionally, the study introduces a
method for assessing the complexity of manual annotation for the resulting
syntactic trees, contributing to further optimization of the annotation
process.",2024-12-17,"Anton Alekseev, Alina Tillabaeva, Gulnara Dzh. Kabaeva, Sergey I. Nikolenko",http://arxiv.org/pdf/2412.13146v1,cs.CL
Improving Explainability of Sentence-level Metrics via Edit-level Attribution for Grammatical Error Correction,"Various evaluation metrics have been proposed for Grammatical Error
Correction (GEC), but many, particularly reference-free metrics, lack
explainability. This lack of explainability hinders researchers from analyzing
the strengths and weaknesses of GEC models and limits the ability to provide
detailed feedback for users. To address this issue, we propose attributing
sentence-level scores to individual edits, providing insight into how specific
corrections contribute to the overall performance. For the attribution method,
we use Shapley values, from cooperative game theory, to compute the
contribution of each edit. Experiments with existing sentence-level metrics
demonstrate high consistency across different edit granularities and show
approximately 70\% alignment with human evaluations. In addition, we analyze
biases in the metrics based on the attribution results, revealing trends such
as the tendency to ignore orthographic edits. Our implementation is available
at \url{https://github.com/naist-nlp/gec-attribute}.",2024-12-17,"Takumi Goto, Justin Vasselli, Taro Watanabe",http://arxiv.org/pdf/2412.13110v1,cs.CL
AI PERSONA: Towards Life-long Personalization of LLMs,"In this work, we introduce the task of life-long personalization of large
language models. While recent mainstream efforts in the LLM community mainly
focus on scaling data and compute for improved capabilities of LLMs, we argue
that it is also very important to enable LLM systems, or language agents, to
continuously adapt to the diverse and ever-changing profiles of every distinct
user and provide up-to-date personalized assistance. We provide a clear task
formulation and introduce a simple, general, effective, and scalable framework
for life-long personalization of LLM systems and language agents. To facilitate
future research on LLM personalization, we also introduce methods to synthesize
realistic benchmarks and robust evaluation metrics. We will release all codes
and data for building and benchmarking life-long personalized LLM systems.",2024-12-17,"Tiannan Wang, Meiling Tao, Ruoyu Fang, Huilin Wang, Shuai Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou",http://arxiv.org/pdf/2412.13103v1,cs.CL
AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark,"Evaluation plays a crucial role in the advancement of information retrieval
(IR) models. However, current benchmarks, which are based on predefined domains
and human-labeled data, face limitations in addressing evaluation needs for
emerging domains both cost-effectively and efficiently. To address this
challenge, we propose the Automated Heterogeneous Information Retrieval
Benchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1)
Automated. The testing data in AIR-Bench is automatically generated by large
language models (LLMs) without human intervention. 2) Heterogeneous. The
testing data in AIR-Bench is generated with respect to diverse tasks, domains
and languages. 3) Dynamic. The domains and languages covered by AIR-Bench are
constantly augmented to provide an increasingly comprehensive evaluation
benchmark for community developers. We develop a reliable and robust data
generation pipeline to automatically create diverse and high-quality evaluation
datasets based on real-world corpora. Our findings demonstrate that the
generated testing data in AIR-Bench aligns well with human-labeled testing
data, making AIR-Bench a dependable benchmark for evaluating IR models. The
resources in AIR-Bench are publicly available at
https://github.com/AIR-Bench/AIR-Bench.",2024-12-17,"Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu",http://arxiv.org/pdf/2412.13102v3,cs.CL
Uchaguzi-2022: A Dataset of Citizen Reports on the 2022 Kenyan Election,"Online reporting platforms have enabled citizens around the world to
collectively share their opinions and report in real time on events impacting
their local communities. Systematically organizing (e.g., categorizing by
attributes) and geotagging large amounts of crowdsourced information is crucial
to ensuring that accurate and meaningful insights can be drawn from this data
and used by policy makers to bring about positive change. These tasks, however,
typically require extensive manual annotation efforts. In this paper we present
Uchaguzi-2022, a dataset of 14k categorized and geotagged citizen reports
related to the 2022 Kenyan General Election containing mentions of
election-related issues such as official misconduct, vote count irregularities,
and acts of violence. We use this dataset to investigate whether language
models can assist in scalably categorizing and geotagging reports, thus
highlighting its potential application in the AI for Social Good space.",2024-12-17,"Roberto Mondini, Neema Kotonya, Robert L. Logan IV, Elizabeth M Olson, Angela Oduor Lungati, Daniel Duke Odongo, Tim Ombasa, Hemank Lamba, Aoife Cahill, Joel R. Tetreault, Alejandro Jaimes",http://arxiv.org/pdf/2412.13098v1,cs.CL
LMUnit: Fine-grained Evaluation with Natural Language Unit Tests,"As language models become integral to critical workflows, assessing their
behavior remains a fundamental challenge -- human evaluation is costly and
noisy, while automated metrics provide only coarse, difficult-to-interpret
signals. We introduce natural language unit tests, a paradigm that decomposes
response quality into explicit, testable criteria, along with a unified scoring
model, LMUnit, which combines multi-objective training across preferences,
direct ratings, and natural language rationales. Through controlled human
studies, we show this paradigm significantly improves inter-annotator agreement
and enables more effective LLM development workflows. LMUnit achieves
state-of-the-art performance on evaluation benchmarks (FLASK, BigGenBench) and
competitive results on RewardBench. These results validate both our proposed
paradigm and scoring model, suggesting a promising path forward for language
model evaluation and development.",2024-12-17,"Jon Saad-Falcon, Rajan Vivek, William Berrios, Nandita Shankar Naik, Matija Franklin, Bertie Vidgen, Amanpreet Singh, Douwe Kiela, Shikib Mehri",http://arxiv.org/pdf/2412.13091v1,cs.CL
CLASP: Contrastive Language-Speech Pretraining for Multilingual Multimodal Information Retrieval,"This study introduces CLASP (Contrastive Language-Speech Pretraining), a
multilingual, multimodal representation tailored for audio-text information
retrieval. CLASP leverages the synergy between spoken content and textual data.
During training, we utilize our newly introduced speech-text dataset, which
encompasses 15 diverse categories ranging from fiction to religion. CLASP's
audio component integrates audio spectrograms with a pre-trained
self-supervised speech model, while its language encoding counterpart employs a
sentence encoder pre-trained on over 100 languages. This unified lightweight
model bridges the gap between various modalities and languages, enhancing its
effectiveness in handling and retrieving multilingual and multimodal data. Our
evaluations across multiple languages demonstrate that CLASP establishes new
benchmarks in HITS@1, MRR, and meanR metrics, outperforming traditional
ASR-based retrieval methods that rely on transcribing speech into text for
subsequent text retrieval, especially in specific scenarios.",2024-12-17,"Mohammad Mahdi Abootorabi, Ehsaneddin Asgari",http://arxiv.org/pdf/2412.13071v2,cs.CL
Do Voters Get the Information They Want? Understanding Authentic Voter FAQs in the US and How to Improve for Informed Electoral Participation,"Accurate information is crucial for democracy as it empowers voters to make
informed decisions about their representatives and keeping them accountable. In
the US, state election commissions (SECs), often required by law, are the
primary providers of Frequently Asked Questions (FAQs) to voters, and secondary
sources like non-profits such as League of Women Voters (LWV) try to complement
their information shortfall. However, surprisingly, to the best of our
knowledge, there is neither a single source with comprehensive FAQs nor a study
analyzing the data at national level to identify current practices and ways to
improve the status quo. This paper addresses it by providing the {\bf first
dataset on Voter FAQs covering all the US states}. Second, we introduce metrics
for FAQ information quality (FIQ) with respect to questions, answers, and
answers to corresponding questions. Third, we use FIQs to analyze US FAQs to
identify leading, mainstream and lagging content practices and corresponding
states. Finally, we identify what states across the spectrum can do to improve
FAQ quality and thus, the overall information ecosystem. Across all 50 U.S.
states, 12% were identified as leaders and 8% as laggards for
FIQS\textsubscript{voter}, while 14% were leaders and 12% laggards for
FIQS\textsubscript{developer}.",2024-12-17,"Vipula Rawte, Deja N Scott, Gaurav Kumar, Aishneet Juneja, Bharat Sowrya Yaddanapalli, Biplav Srivastava",http://arxiv.org/pdf/2412.15273v1,cs.CL
Modality-Inconsistent Continual Learning of Multimodal Large Language Models,"In this paper, we introduce Modality-Inconsistent Continual Learning (MICL),
a new continual learning scenario for Multimodal Large Language Models (MLLMs)
that involves tasks with inconsistent modalities (image, audio, or video) and
varying task types (captioning or question-answering). Unlike existing
vision-only or modality-incremental settings, MICL combines modality and task
type shifts, both of which drive catastrophic forgetting. To address these
challenges, we propose MoInCL, which employs a Pseudo Targets Generation Module
to mitigate forgetting caused by task type shifts in previously seen
modalities. It also incorporates Instruction-based Knowledge Distillation to
preserve the model's ability to handle previously learned modalities when new
ones are introduced. We benchmark MICL using a total of six tasks and conduct
experiments to validate the effectiveness of our proposed MoInCL. The
experimental results highlight the superiority of MoInCL, showing significant
improvements over representative and state-of-the-art continual learning
baselines.",2024-12-17,"Weiguo Pian, Shijian Deng, Shentong Mo, Yunhui Guo, Yapeng Tian",http://arxiv.org/pdf/2412.13050v1,cs.CL
Harnessing Event Sensory Data for Error Pattern Prediction in Vehicles: A Language Model Approach,"In this paper, we draw an analogy between processing natural languages and
processing multivariate event streams from vehicles in order to predict
$\textit{when}$ and $\textit{what}$ error pattern is most likely to occur in
the future for a given car. Our approach leverages the temporal dynamics and
contextual relationships of our event data from a fleet of cars. Event data is
composed of discrete values of error codes as well as continuous values such as
time and mileage. Modelled by two causal Transformers, we can anticipate
vehicle failures and malfunctions before they happen. Thus, we introduce
$\textit{CarFormer}$, a Transformer model trained via a new self-supervised
learning strategy, and $\textit{EPredictor}$, an autoregressive Transformer
decoder model capable of predicting $\textit{when}$ and $\textit{what}$ error
pattern will most likely occur after some error code apparition. Despite the
challenges of high cardinality of event types, their unbalanced frequency of
appearance and limited labelled data, our experimental results demonstrate the
excellent predictive ability of our novel model. Specifically, with sequences
of $160$ error codes on average, our model is able with only half of the error
codes to achieve $80\%$ F1 score for predicting $\textit{what}$ error pattern
will occur and achieves an average absolute error of $58.4 \pm 13.2$h
$\textit{when}$ forecasting the time of occurrence, thus enabling confident
predictive maintenance and enhancing vehicle safety.",2024-12-17,"Hugo Math, Rainer Lienhart, Robin Schön",http://arxiv.org/pdf/2412.13041v1,cs.CL
NAVCON: A Cognitively Inspired and Linguistically Grounded Corpus for Vision and Language Navigation,"We present NAVCON, a large-scale annotated Vision-Language Navigation (VLN)
corpus built on top of two popular datasets (R2R and RxR). The paper introduces
four core, cognitively motivated and linguistically grounded, navigation
concepts and an algorithm for generating large-scale silver annotations of
naturally occurring linguistic realizations of these concepts in navigation
instructions. We pair the annotated instructions with video clips of an agent
acting on these instructions. NAVCON contains 236, 316 concept annotations for
approximately 30, 0000 instructions and 2.7 million aligned images (from
approximately 19, 000 instructions) showing what the agent sees when executing
an instruction. To our knowledge, this is the first comprehensive resource of
navigation concepts. We evaluated the quality of the silver annotations by
conducting human evaluation studies on NAVCON samples. As further validation of
the quality and usefulness of the resource, we trained a model for detecting
navigation concepts and their linguistic realizations in unseen instructions.
Additionally, we show that few-shot learning with GPT-4o performs well on this
task using large-scale silver annotations of NAVCON.",2024-12-17,"Karan Wanchoo, Xiaoye Zuo, Hannah Gonzalez, Soham Dan, Georgios Georgakis, Dan Roth, Kostas Daniilidis, Eleni Miltsakaki",http://arxiv.org/pdf/2412.13026v2,cs.CL
SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation,"Recent advancements in large language models (LLMs) have shown impressive
versatility across various tasks. To eliminate its hallucinations,
retrieval-augmented generation (RAG) has emerged as a powerful approach,
leveraging external knowledge sources like knowledge graphs (KGs). In this
paper, we study the task of KG-driven RAG and propose a novel Similar Graph
Enhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively
addresses the challenge of aligning query texts and KG structures through a
two-stage process: (1) query-to-pattern, which uses an LLM to transform queries
into a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the
alignment between the pattern and candidate subgraphs using a graph semantic
distance (GSD) metric. We also develop an optimized retrieval algorithm that
efficiently identifies the top-$k$ subgraphs within 1-second latency on a
10-million-scale KG. Extensive experiments show that SimGRAG outperforms
state-of-the-art KG-driven RAG methods in both question answering and fact
verification, offering superior plug-and-play usability and scalability.",2024-12-17,"Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng",http://arxiv.org/pdf/2412.15272v1,cs.CL
OmniEval: An Omnidirectional and Automatic RAG Evaluation Benchmark in Financial Domain,"As a typical and practical application of Large Language Models (LLMs),
Retrieval-Augmented Generation (RAG) techniques have gained extensive
attention, particularly in vertical domains where LLMs may lack domain-specific
knowledge. In this paper, we introduce an omnidirectional and automatic RAG
benchmark, OmniEval, in the financial domain. Our benchmark is characterized by
its multi-dimensional evaluation framework, including (1) a matrix-based RAG
scenario evaluation system that categorizes queries into five task classes and
16 financial topics, leading to a structured assessment of diverse query
scenarios; (2) a multi-dimensional evaluation data generation approach, which
combines GPT-4-based automatic generation and human annotation, achieving an
87.47\% acceptance ratio in human evaluations on generated instances; (3) a
multi-stage evaluation system that evaluates both retrieval and generation
performance, result in a comprehensive evaluation on the RAG pipeline; and (4)
robust evaluation metrics derived from rule-based and LLM-based ones, enhancing
the reliability of assessments through manual annotations and supervised
fine-tuning of an LLM evaluator. Our experiments demonstrate the
comprehensiveness of OmniEval, which includes extensive test datasets and
highlights the performance variations of RAG systems across diverse topics and
tasks, revealing significant opportunities for RAG models to improve their
capabilities in vertical domains. We open source the code of our benchmark in
\href{https://github.com/RUC-NLPIR/OmniEval}{https://github.com/RUC-NLPIR/OmniEval}.",2024-12-17,"Shuting Wang, Jiejun Tan, Zhicheng Dou, Ji-Rong Wen",http://arxiv.org/pdf/2412.13018v2,cs.CL
RCLMuFN: Relational Context Learning and Multiplex Fusion Network for Multimodal Sarcasm Detection,"Sarcasm typically conveys emotions of contempt or criticism by expressing a
meaning that is contrary to the speaker's true intent. Accurate detection of
sarcasm aids in identifying and filtering undesirable information on the
Internet, thereby reducing malicious defamation and rumor-mongering.
Nonetheless, the task of automatic sarcasm detection remains highly challenging
for machines, as it critically depends on intricate factors such as relational
context. Most existing multimodal sarcasm detection methods focus on
introducing graph structures to establish entity relationships between text and
images while neglecting to learn the relational context between text and
images, which is crucial evidence for understanding the meaning of sarcasm. In
addition, the meaning of sarcasm changes with the evolution of different
contexts, but existing methods may not be accurate in modeling such dynamic
changes, limiting the generalization ability of the models. To address the
above issues, we propose a relational context learning and multiplex fusion
network (RCLMuFN) for multimodal sarcasm detection. Firstly, we employ four
feature extractors to comprehensively extract features from raw text and
images, aiming to excavate potential features that may have been previously
overlooked. Secondly, we utilize the relational context learning module to
learn the contextual information of text and images and capture the dynamic
properties through shallow and deep interactions. Finally, we employ a
multiplex feature fusion module to enhance the generalization of the model by
penetratingly integrating multimodal features derived from various interaction
contexts. Extensive experiments on two multimodal sarcasm detection datasets
show that our proposed method achieves state-of-the-art performance.",2024-12-17,"Tongguan Wang, Junkai Li, Guixin Su, Yongcheng Zhang, Dongyu Su, Yuxue Hu, Ying Sha",http://arxiv.org/pdf/2412.13008v1,cs.CL
Enabling Low-Resource Language Retrieval: Establishing Baselines for Urdu MS MARCO,"As the Information Retrieval (IR) field increasingly recognizes the
importance of inclusivity, addressing the needs of low-resource languages
remains a significant challenge. This paper introduces the first large-scale
Urdu IR dataset, created by translating the MS MARCO dataset through machine
translation. We establish baseline results through zero-shot learning for IR in
Urdu and subsequently apply the mMARCO multilingual IR methodology to this
newly translated dataset. Our findings demonstrate that the fine-tuned model
(Urdu-mT5-mMARCO) achieves a Mean Reciprocal Rank (MRR@10) of 0.247 and a
Recall@10 of 0.439, representing significant improvements over zero-shot
results and showing the potential for expanding IR access for Urdu speakers. By
bridging access gaps for speakers of low-resource languages, this work not only
advances multilingual IR research but also emphasizes the ethical and societal
importance of inclusive IR technologies. This work provides valuable insights
into the challenges and solutions for improving language representation and
lays the groundwork for future research, especially in South Asian languages,
which can benefit from the adaptable methods used in this study.",2024-12-17,"Umer Butt, Stalin Varanasi, Günter Neumann",http://arxiv.org/pdf/2412.12997v3,cs.CL
Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health,"Large language models (LLMs) have shown promising capabilities in healthcare
analysis but face several challenges like hallucinations, parroting, and bias
manifestation. These challenges are exacerbated in complex, sensitive, and
low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an
expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by
generating in-context conversational dialogues leveraging LLMs, particularly
ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues
and tailored information, taking into account therapy style (empathy,
reflection), contextual relevance, and false semantic change. Subsequently, the
dialogues are annotated by experts, strictly adhering to the Motivational
Interviewing Skills Code (MISC), focusing on both the psychological and
linguistic dimensions of MI dialogues. We comprehensively evaluate the
IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding
of domain intricacies by modeling novel classification tasks employing several
classical machine learning and current state-of-the-art transformer approaches.
Finally, we discuss the effects of progressive prompting strategies and the
impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our
contributions provide the MI community with not only a comprehensive dataset
but also valuable insights for using LLMs in empathetic text generation for
conversational therapy in supervised settings.",2024-12-17,"Vivek Kumar, Eirini Ntoutsi, Pushpraj Singh Rajawat, Giacomo Medda, Diego Reforgiato Recupero",http://arxiv.org/pdf/2412.12981v1,cs.CL
Adaptations of AI models for querying the LandMatrix database in natural language,"The Land Matrix initiative (https://landmatrix.org) and its global
observatory aim to provide reliable data on large-scale land acquisitions to
inform debates and actions in sectors such as agriculture, extraction, or
energy in low- and middle-income countries. Although these data are recognized
in the academic world, they remain underutilized in public policy, mainly due
to the complexity of access and exploitation, which requires technical
expertise and a good understanding of the database schema.
  The objective of this work is to simplify access to data from different
database systems. The methods proposed in this article are evaluated using data
from the Land Matrix. This work presents various comparisons of Large Language
Models (LLMs) as well as combinations of LLM adaptations (Prompt Engineering,
RAG, Agents) to query different database systems (GraphQL and REST queries).
The experiments are reproducible, and a demonstration is available online:
https://github.com/tetis-nlp/landmatrix-graphql-python.",2024-12-17,"Fatiha Ait Kbir, Jérémy Bourgoin, Rémy Decoupes, Marie Gradeler, Roberto Interdonato",http://arxiv.org/pdf/2412.12961v1,cs.CL
SnakModel: Lessons Learned from Training an Open Danish Large Language Model,"We present SnakModel, a Danish large language model (LLM) based on Llama2-7B,
which we continuously pre-train on 13.6B Danish words, and further tune on 3.7M
Danish instructions. As best practices for creating LLMs for smaller language
communities have yet to be established, we examine the effects of early
modeling and training decisions on downstream performance throughout the entire
training pipeline, including (1) the creation of a strictly curated corpus of
Danish text from diverse sources; (2) the language modeling and
instruction-tuning training process itself, including the analysis of
intermediate training dynamics, and ablations across different hyperparameters;
(3) an evaluation on eight language and culturally-specific tasks. Across these
experiments SnakModel achieves the highest overall performance, outperforming
multiple contemporary Llama2-7B-based models. By making SnakModel, the majority
of our pre-training corpus, and the associated code available under open
licenses, we hope to foster further research and development in Danish Natural
Language Processing, and establish training guidelines for languages with
similar resource constraints.",2024-12-17,"Mike Zhang, Max Müller-Eberstein, Elisa Bassignana, Rob van der Goot",http://arxiv.org/pdf/2412.12956v1,cs.CL
Learning from Noisy Labels via Self-Taught On-the-Fly Meta Loss Rescaling,"Correct labels are indispensable for training effective machine learning
models. However, creating high-quality labels is expensive, and even
professionally labeled data contains errors and ambiguities. Filtering and
denoising can be applied to curate labeled data prior to training, at the cost
of additional processing and loss of information. An alternative is on-the-fly
sample reweighting during the training process to decrease the negative impact
of incorrect or ambiguous labels, but this typically requires clean seed data.
In this work we propose unsupervised on-the-fly meta loss rescaling to reweight
training samples. Crucially, we rely only on features provided by the model
being trained, to learn a rescaling function in real time without knowledge of
the true clean data distribution. We achieve this via a novel meta learning
setup that samples validation data for the meta update directly from the noisy
training corpus by employing the rescaling function being trained. Our proposed
method consistently improves performance across various NLP tasks with minimal
computational overhead. Further, we are among the first to attempt on-the-fly
training data reweighting on the challenging task of dialogue modeling, where
noisy and ambiguous labels are common. Our strategy is robust in the face of
noisy and clean data, handles class imbalance, and prevents overfitting to
noisy labels. Our self-taught loss rescaling improves as the model trains,
showing the ability to keep learning from the model's own signals. As training
progresses, the impact of correctly labeled data is scaled up, while the impact
of wrongly labeled data is suppressed.",2024-12-17,"Michael Heck, Christian Geishauser, Nurul Lubis, Carel van Niekerk, Shutong Feng, Hsien-Chin Lin, Benjamin Matthias Ruppik, Renato Vukovic, Milica Gašić",http://arxiv.org/pdf/2412.12955v1,cs.CL
Recipient Profiling: Predicting Characteristics from Messages,"It has been shown in the field of Author Profiling that texts may
inadvertently reveal sensitive information about their authors, such as gender
or age. This raises important privacy concerns that have been extensively
addressed in the literature, in particular with the development of methods to
hide such information. We argue that, when these texts are in fact messages
exchanged between individuals, this is not the end of the story. Indeed, in
this case, a second party, the intended recipient, is also involved and should
be considered. In this work, we investigate the potential privacy leaks
affecting them, that is we propose and address the problem of Recipient
Profiling. We provide empirical evidence that such a task is feasible on
several publicly accessible datasets
(https://huggingface.co/datasets/sileod/recipient_profiling). Furthermore, we
show that the learned models can be transferred to other datasets, albeit with
a loss in accuracy.",2024-12-17,"Martin Borquez, Mikaela Keller, Michael Perrot, Damien Sileo",http://arxiv.org/pdf/2412.12954v1,cs.CL
MOPO: Multi-Objective Prompt Optimization for Affective Text Generation,"How emotions are expressed depends on the context and domain. On X (formerly
Twitter), for instance, an author might simply use the hashtag #anger, while in
a news headline, emotions are typically written in a more polite, indirect
manner. To enable conditional text generation models to create emotionally
connotated texts that fit a domain, users need to have access to a parameter
that allows them to choose the appropriate way to express an emotion. To
achieve this, we introduce MOPO, a Multi-Objective Prompt Optimization
methodology. MOPO optimizes prompts according to multiple objectives (which
correspond here to the output probabilities assigned by emotion classifiers
trained for different domains). In contrast to single objective optimization,
MOPO outputs a set of prompts, each with a different weighting of the multiple
objectives. Users can then choose the most appropriate prompt for their
context. We evaluate MOPO using three objectives, determined by various
domain-specific emotion classifiers. MOPO improves performance by up to 15 pp
across all objectives with a minimal loss (1-2 pp) for any single objective
compared to single-objective optimization. These minor performance losses are
offset by a broader generalization across multiple objectives - which is not
possible with single-objective optimization. Additionally, MOPO reduces
computational requirements by simultaneously optimizing for multiple
objectives, eliminating separate optimization procedures for each objective.",2024-12-17,"Yarik Menchaca Resendiz, Roman Klinger",http://arxiv.org/pdf/2412.12948v1,cs.CL
Improving Fine-grained Visual Understanding in VLMs through Text-Only Training,"Visual-Language Models (VLMs) have become a powerful tool for bridging the
gap between visual and linguistic understanding. However, the conventional
learning approaches for VLMs often suffer from limitations, such as the high
resource requirements of collecting and training image-text paired data. Recent
research has suggested that language understanding plays a crucial role in the
performance of VLMs, potentially indicating that text-only training could be a
viable approach. In this work, we investigate the feasibility of enhancing
fine-grained visual understanding in VLMs through text-only training. Inspired
by how humans develop visual concept understanding, where rich textual
descriptions can guide visual recognition, we hypothesize that VLMs can also
benefit from leveraging text-based representations to improve their visual
recognition abilities. We conduct comprehensive experiments on two distinct
domains: fine-grained species classification and cultural visual understanding
tasks. Our findings demonstrate that text-only training can be comparable to
conventional image-text training while significantly reducing computational
costs. This suggests a more efficient and cost-effective pathway for advancing
VLM capabilities, particularly valuable in resource-constrained environments.",2024-12-17,"Dasol Choi, Guijin Son, Soo Yong Kim, Gio Paik, Seunghyeok Hong",http://arxiv.org/pdf/2412.12940v1,cs.CL
Truthful Text Sanitization Guided by Inference Attacks,"The purpose of text sanitization is to rewrite those text spans in a document
that may directly or indirectly identify an individual, to ensure they no
longer disclose personal information. Text sanitization must strike a balance
between preventing the leakage of personal information (privacy protection)
while also retaining as much of the document's original content as possible
(utility preservation). We present an automated text sanitization strategy
based on generalizations, which are more abstract (but still informative) terms
that subsume the semantic content of the original text spans. The approach
relies on instruction-tuned large language models (LLMs) and is divided into
two stages. The LLM is first applied to obtain truth-preserving replacement
candidates and rank them according to their abstraction level. Those candidates
are then evaluated for their ability to protect privacy by conducting inference
attacks with the LLM. Finally, the system selects the most informative
replacement shown to be resistant to those attacks. As a consequence of this
two-stage process, the chosen replacements effectively balance utility and
privacy. We also present novel metrics to automatically evaluate these two
aspects without the need to manually annotate data. Empirical results on the
Text Anonymization Benchmark show that the proposed approach leads to enhanced
utility, with only a marginal increase in the risk of re-identifying protected
individuals compared to fully suppressing the original information.
Furthermore, the selected replacements are shown to be more truth-preserving
and abstractive than previous methods.",2024-12-17,"Ildikó Pilán, Benet Manzanares-Salor, David Sánchez, Pierre Lison",http://arxiv.org/pdf/2412.12928v1,cs.CL
An Agentic Approach to Automatic Creation of P&ID Diagrams from Natural Language Descriptions,"The Piping and Instrumentation Diagrams (P&IDs) are foundational to the
design, construction, and operation of workflows in the engineering and process
industries. However, their manual creation is often labor-intensive,
error-prone, and lacks robust mechanisms for error detection and correction.
While recent advancements in Generative AI, particularly Large Language Models
(LLMs) and Vision-Language Models (VLMs), have demonstrated significant
potential across various domains, their application in automating generation of
engineering workflows remains underexplored. In this work, we introduce a novel
copilot for automating the generation of P&IDs from natural language
descriptions. Leveraging a multi-step agentic workflow, our copilot provides a
structured and iterative approach to diagram creation directly from Natural
Language prompts. We demonstrate the feasibility of the generation process by
evaluating the soundness and completeness of the workflow, and show improved
results compared to vanilla zero-shot and few-shot generation approaches.",2024-12-17,"Shreeyash Gowaikar, Srinivasan Iyengar, Sameer Segal, Shivkumar Kalyanaraman",http://arxiv.org/pdf/2412.12898v1,cs.CL
Question: How do Large Language Models perform on the Question Answering tasks? Answer:,"Large Language Models (LLMs) have been showing promising results for various
NLP-tasks without the explicit need to be trained for these tasks by using
few-shot or zero-shot prompting techniques. A common NLP-task is
question-answering (QA). In this study, we propose a comprehensive performance
comparison between smaller fine-tuned models and out-of-the-box
instruction-following LLMs on the Stanford Question Answering Dataset 2.0
(SQuAD2), specifically when using a single-inference prompting technique. Since
the dataset contains unanswerable questions, previous work used a double
inference method. We propose a prompting style which aims to elicit the same
ability without the need for double inference, saving compute time and
resources. Furthermore, we investigate their generalization capabilities by
comparing their performance on similar but different QA datasets, without
fine-tuning neither model, emulating real-world uses where the context and
questions asked may differ from the original training distribution, for example
swapping Wikipedia for news articles.
  Our results show that smaller, fine-tuned models outperform current
State-Of-The-Art (SOTA) LLMs on the fine-tuned task, but recent SOTA models are
able to close this gap on the out-of-distribution test and even outperform the
fine-tuned models on 3 of the 5 tested QA datasets.",2024-12-17,"Kevin Fischer, Darren Fürst, Sebastian Steindl, Jakob Lindner, Ulrich Schäfer",http://arxiv.org/pdf/2412.12893v1,cs.CL
RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement,"Existing large language models (LLMs) show exceptional problem-solving
capabilities but might struggle with complex reasoning tasks. Despite the
successes of chain-of-thought and tree-based search methods, they mainly depend
on the internal knowledge of LLMs to search over intermediate reasoning steps,
limited to dealing with simple tasks involving fewer reasoning steps. In this
paper, we propose \textbf{RAG-Star}, a novel RAG approach that integrates the
retrieved information to guide the tree-based deliberative reasoning process
that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree
Search, RAG-Star iteratively plans intermediate sub-queries and answers for
reasoning based on the LLM itself. To consolidate internal and external
knowledge, we propose an retrieval-augmented verification that utilizes query-
and answer-aware reward modeling to provide feedback for the inherent reasoning
of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate
that RAG-Star significantly outperforms previous RAG and reasoning methods.",2024-12-17,"Jinhao Jiang, Jiayi Chen, Junyi Li, Ruiyang Ren, Shijie Wang, Wayne Xin Zhao, Yang Song, Tao Zhang",http://arxiv.org/pdf/2412.12881v1,cs.CL
Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over Aligned Large Language Models,"Alignment, endowing a pre-trained Large language model (LLM) with the ability
to follow instructions, is crucial for its real-world applications.
Conventional supervised fine-tuning (SFT) methods formalize it as causal
language modeling typically with a cross-entropy objective, requiring a large
amount of high-quality instruction-response pairs. However, the quality of
widely used SFT datasets can not be guaranteed due to the high cost and
intensive labor for the creation and maintenance in practice. To overcome the
limitations associated with the quality of SFT datasets, we introduce a novel
\textbf{p}reference-\textbf{o}riented supervised \textbf{f}ine-\textbf{t}uning
approach, namely PoFT. The intuition is to boost SFT by imposing a particular
preference: \textit{favoring the target model over aligned LLMs on the same SFT
data.} This preference encourages the target model to predict a higher
likelihood than that predicted by the aligned LLMs, incorporating assessment
information on data quality (i.e., predicted likelihood by the aligned LLMs)
into the training process. Extensive experiments are conducted, and the results
validate the effectiveness of the proposed method. PoFT achieves stable and
consistent improvements over the SFT baselines across different training
datasets and base models. Moreover, we prove that PoFT can be integrated with
existing SFT data filtering methods to achieve better performance, and further
improved by following preference optimization procedures, such as DPO.",2024-12-17,"Yuchen Fan, Yuzhong Hong, Qiushi Wang, Junwei Bao, Hongfei Jiang, Yang Song",http://arxiv.org/pdf/2412.12865v1,cs.CL
DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check,"One key characteristic of the Chinese spelling check (CSC) task is that
incorrect characters are usually similar to the correct ones in either
phonetics or glyph. To accommodate this, previous works usually leverage
confusion sets, which suffer from two problems, i.e., difficulty in determining
which character pairs to include and lack of probabilities to distinguish items
in the set. In this paper, we propose a light-weight plug-and-play DISC (i.e.,
decoding intervention with similarity of characters) module for CSC models.DISC
measures phonetic and glyph similarities between characters and incorporates
this similarity information only during the inference phase. This method can be
easily integrated into various existing CSC models, such as ReaLiSe, SCOPE, and
ReLM, without additional training costs. Experiments on three CSC benchmarks
demonstrate that our proposed method significantly improves model performance,
approaching and even surpassing the current state-of-the-art models.",2024-12-17,"Ziheng Qiao, Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang",http://arxiv.org/pdf/2412.12863v1,cs.CL
Selective Shot Learning for Code Explanation,"Code explanation plays a crucial role in the software engineering domain,
aiding developers in grasping code functionality efficiently. Recent work shows
that the performance of LLMs for code explanation improves in a few-shot
setting, especially when the few-shot examples are selected intelligently.
State-of-the-art approaches for such Selective Shot Learning (SSL) include
token-based and embedding-based methods. However, these SSL approaches have
been evaluated on proprietary LLMs, without much exploration on open-source
Code-LLMs. Additionally, these methods lack consideration for programming
language syntax. To bridge these gaps, we present a comparative study and
propose a novel SSL method (SSL_ner) that utilizes entity information for
few-shot example selection. We present several insights and show the
effectiveness of SSL_ner approach over state-of-the-art methods across two
datasets. To the best of our knowledge, this is the first systematic
benchmarking of open-source Code-LLMs while assessing the performances of the
various few-shot examples selection approaches for the code explanation task.",2024-12-17,"Paheli Bhattacharya, Rishabh Gupta",http://arxiv.org/pdf/2412.12852v1,cs.CL
Benchmarking and Understanding Compositional Relational Reasoning of LLMs,"Compositional relational reasoning (CRR) is a hallmark of human intelligence,
but we lack a clear understanding of whether and how existing transformer large
language models (LLMs) can solve CRR tasks. To enable systematic exploration of
the CRR capability of LLMs, we first propose a new synthetic benchmark called
Generalized Associative Recall (GAR) by integrating and generalizing the
essence of several tasks in mechanistic interpretability (MI) study in a
unified framework. Evaluation shows that GAR is challenging enough for existing
LLMs, revealing their fundamental deficiency in CRR. Meanwhile, it is easy
enough for systematic MI study. Then, to understand how LLMs solve GAR tasks,
we use attribution patching to discover the core circuits reused by Vicuna-33B
across different tasks and a set of vital attention heads. Intervention
experiments show that the correct functioning of these heads significantly
impacts task performance. Especially, we identify two classes of heads whose
activations represent the abstract notion of true and false in GAR tasks
respectively. They play a fundamental role in CRR across various models and
tasks. The dataset and code are available at https://github.com/Caiyun-AI/GAR.",2024-12-17,"Ruikang Ni, Da Xiao, Qingye Meng, Xiangyu Li, Shihui Zheng, Hongliang Liang",http://arxiv.org/pdf/2412.12841v1,cs.CL
DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction in the Era of Large Language Models,"Evaluating the performance of Grammatical Error Correction (GEC) models has
become increasingly challenging, as large language model (LLM)-based GEC
systems often produce corrections that diverge from provided gold references.
This discrepancy undermines the reliability of traditional reference-based
evaluation metrics. In this study, we propose a novel evaluation framework for
GEC models, DSGram, integrating Semantic Coherence, Edit Level, and Fluency,
and utilizing a dynamic weighting mechanism. Our framework employs the Analytic
Hierarchy Process (AHP) in conjunction with large language models to ascertain
the relative importance of various evaluation criteria. Additionally, we
develop a dataset incorporating human annotations and LLM-simulated sentences
to validate our algorithms and fine-tune more cost-effective models.
Experimental results indicate that our proposed approach enhances the
effectiveness of GEC model evaluations.",2024-12-17,"Jinxiang Xie, Yilin Li, Xunjian Yin, Xiaojun Wan",http://arxiv.org/pdf/2412.12832v1,cs.CL
Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning,"This paper focuses on sarcasm detection, which aims to identify whether given
statements convey criticism, mockery, or other negative sentiment opposite to
the literal meaning. To detect sarcasm, humans often require a comprehensive
understanding of the semantics in the statement and even resort to external
commonsense to infer the fine-grained incongruity. However, existing methods
lack commonsense inferential ability when they face complex real-world
scenarios, leading to unsatisfactory performance. To address this problem, we
propose a novel framework for sarcasm detection, which conducts incongruity
reasoning based on commonsense augmentation, called EICR. Concretely, we first
employ retrieval-augmented large language models to supplement the missing but
indispensable commonsense background knowledge. To capture complex contextual
associations, we construct a dependency graph and obtain the optimized topology
via graph refinement. We further introduce an adaptive reasoning skeleton that
integrates prior rules to extract sentiment-inconsistent subgraphs explicitly.
To eliminate the possible spurious relations between words and labels, we
employ adversarial contrastive learning to enhance the robustness of the
detector. Experiments conducted on five datasets demonstrate the effectiveness
of EICR.",2024-12-17,"Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin",http://arxiv.org/pdf/2412.12808v2,cs.CL
Cross-Dialect Information Retrieval: Information Access in Low-Resource and High-Variance Languages,"A large amount of local and culture-specific knowledge (e.g., people,
traditions, food) can only be found in documents written in dialects. While
there has been extensive research conducted on cross-lingual information
retrieval (CLIR), the field of cross-dialect retrieval (CDIR) has received
limited attention. Dialect retrieval poses unique challenges due to the limited
availability of resources to train retrieval models and the high variability in
non-standardized languages. We study these challenges on the example of German
dialects and introduce the first German dialect retrieval dataset, dubbed
WikiDIR, which consists of seven German dialects extracted from Wikipedia.
Using WikiDIR, we demonstrate the weakness of lexical methods in dealing with
high lexical variation in dialects. We further show that commonly used
zero-shot cross-lingual transfer approach with multilingual encoders do not
transfer well to extremely low-resource setups, motivating the need for
resource-lean and dialect-specific retrieval models. We finally demonstrate
that (document) translation is an effective way to reduce the dialect gap in
CDIR.",2024-12-17,"Robert Litschko, Oliver Kraus, Verena Blaschke, Barbara Plank",http://arxiv.org/pdf/2412.12806v2,cs.CL
A MapReduce Approach to Effectively Utilize Long Context Information in Retrieval Augmented Language Models,"While holding great promise for improving and facilitating healthcare, large
language models (LLMs) struggle to produce up-to-date responses on evolving
topics due to outdated knowledge or hallucination. Retrieval-augmented
generation (RAG) is a pivotal innovation that improves the accuracy and
relevance of LLM responses by integrating LLMs with a search engine and
external sources of knowledge. However, the quality of RAG responses can be
largely impacted by the rank and density of key information in the retrieval
results, such as the ""lost-in-the-middle"" problem. In this work, we aim to
improve the robustness and reliability of the RAG workflow in the medical
domain. Specifically, we propose a map-reduce strategy, BriefContext, to combat
the ""lost-in-the-middle"" issue without modifying the model weights. We
demonstrated the advantage of the workflow with various LLM backbones and on
multiple QA datasets. This method promises to improve the safety and
reliability of LLMs deployed in healthcare domains.",2024-12-17,"Gongbo Zhang, Zihan Xu, Qiao Jin, Fangyi Chen, Yilu Fang, Yi Liu, Justin F. Rousseau, Ziyang Xu, Zhiyong Lu, Chunhua Weng, Yifan Peng",http://arxiv.org/pdf/2412.15271v1,cs.CL
Is it the end of (generative) linguistics as we know it?,"A significant debate has emerged in response to a paper written by Steven
Piantadosi (Piantadosi, 2023) and uploaded to the LingBuzz platform, the open
archive for generative linguistics. Piantadosi's dismissal of Chomsky's
approach is ruthless, but generative linguists deserve it. In this paper, I
will adopt three idealized perspectives -- computational, theoretical, and
experimental -- to focus on two fundamental issues that lend partial support to
Piantadosi's critique: (a) the evidence challenging the Poverty of Stimulus
(PoS) hypothesis and (b) the notion of simplicity as conceived within
mainstream Minimalism. In conclusion, I argue that, to reclaim a central role
in language studies, generative linguistics -- representing a prototypical
theoretical perspective on language -- needs a serious update leading to (i)
more precise, consistent, and complete formalizations of foundational
intuitions and (ii) the establishment and utilization of a standardized dataset
of crucial empirical evidence to evaluate the theory's adequacy. On the other
hand, ignoring the formal perspective leads to major drawbacks in both
computational and experimental approaches. Neither descriptive nor explanatory
adequacy can be easily achieved without the precise formulation of general
principles that can be challenged empirically.",2024-12-17,Cristiano Chesi,http://arxiv.org/pdf/2412.12797v1,cs.CL
A Survey of Calibration Process for Black-Box LLMs,"Large Language Models (LLMs) demonstrate remarkable performance in semantic
understanding and generation, yet accurately assessing their output reliability
remains a significant challenge. While numerous studies have explored
calibration techniques, they primarily focus on White-Box LLMs with accessible
parameters. Black-Box LLMs, despite their superior performance, pose heightened
requirements for calibration techniques due to their API-only interaction
constraints. Although recent researches have achieved breakthroughs in
black-box LLMs calibration, a systematic survey of these methodologies is still
lacking. To bridge this gap, we presents the first comprehensive survey on
calibration techniques for black-box LLMs. We first define the Calibration
Process of LLMs as comprising two interrelated key steps: Confidence Estimation
and Calibration. Second, we conduct a systematic review of applicable methods
within black-box settings, and provide insights on the unique challenges and
connections in implementing these key steps. Furthermore, we explore typical
applications of Calibration Process in black-box LLMs and outline promising
future research directions, providing new perspectives for enhancing
reliability and human-machine alignment. This is our GitHub link:
https://github.com/LiangruXie/Calibration-Process-in-Black-Box-LLMs",2024-12-17,"Liangru Xie, Hui Liu, Jingying Zeng, Xianfeng Tang, Yan Han, Chen Luo, Jing Huang, Zhen Li, Suhang Wang, Qi He",http://arxiv.org/pdf/2412.12767v1,cs.CL
Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection,"In this paper, we reported our experiments with various strategies to improve
code-mixed humour and sarcasm detection. We did all of our experiments for
Hindi-English code-mixed scenario, as we have the linguistic expertise for the
same. We experimented with three approaches, namely (i) native sample mixing,
(ii) multi-task learning (MTL), and (iii) prompting very large multilingual
language models (VMLMs). In native sample mixing, we added monolingual task
samples in code-mixed training sets. In MTL learning, we relied on native and
code-mixed samples of a semantically related task (hate detection in our case).
Finally, in our third approach, we evaluated the efficacy of VMLMs via few-shot
context prompting. Some interesting findings we got are (i) adding native
samples improved humor (raising the F1-score up to 6.76%) and sarcasm (raising
the F1-score up to 8.64%) detection, (ii) training MLMs in an MTL framework
boosted performance for both humour (raising the F1-score up to 10.67%) and
sarcasm (increment up to 12.35% in F1-score) detection, and (iii) prompting
VMLMs couldn't outperform the other approaches. Finally, our ablation studies
and error analysis discovered the cases where our model is yet to improve. We
provided our code for reproducibility.",2024-12-17,"Debajyoti Mazumder, Aakash Kumar, Jasabanta Patro",http://arxiv.org/pdf/2412.12761v1,cs.CL
Your Next State-of-the-Art Could Come from Another Domain: A Cross-Domain Analysis of Hierarchical Text Classification,"Text classification with hierarchical labels is a prevalent and challenging
task in natural language processing. Examples include assigning ICD codes to
patient records, tagging patents into IPC classes, assigning EUROVOC
descriptors to European legal texts, and more. Despite its widespread
applications, a comprehensive understanding of state-of-the-art methods across
different domains has been lacking. In this paper, we provide the first
comprehensive cross-domain overview with empirical analysis of state-of-the-art
methods. We propose a unified framework that positions each method within a
common structure to facilitate research. Our empirical analysis yields key
insights and guidelines, confirming the necessity of learning across different
research areas to design effective methods. Notably, under our unified
evaluation pipeline, we achieved new state-of-the-art results by applying
techniques beyond their original domains.",2024-12-17,"Nan Li, Bo Kang, Tijl De Bie",http://arxiv.org/pdf/2412.12744v1,cs.CL
GIRAFFE: Design Choices for Extending the Context Length of Visual Language Models,"Visual Language Models (VLMs) demonstrate impressive capabilities in
processing multimodal inputs, yet applications such as visual agents, which
require handling multiple images and high-resolution videos, demand enhanced
long-range modeling. Moreover, existing open-source VLMs lack systematic
exploration into extending their context length, and commercial models often
provide limited details. To tackle this, we aim to establish an effective
solution that enhances long context performance of VLMs while preserving their
capacities in short context scenarios. Towards this goal, we make the best
design choice through extensive experiment settings from data curation to
context window extending and utilizing: (1) we analyze data sources and length
distributions to construct ETVLM - a data recipe to balance the performance
across scenarios; (2) we examine existing position extending methods, identify
their limitations and propose M-RoPE++ as an enhanced approach; we also choose
to solely instruction-tune the backbone with mixed-source data; (3) we discuss
how to better utilize extended context windows and propose hybrid-resolution
training. Built on the Qwen-VL series model, we propose Giraffe, which is
effectively extended to 128K lengths. Evaluated on extensive long context VLM
benchmarks such as VideoMME and Viusal Haystacks, our Giraffe achieves
state-of-the-art performance among similarly sized open-source long VLMs and is
competitive with commercial model GPT-4V. We will open-source the code, data,
and models.",2024-12-17,"Mukai Li, Lei Li, Shansan Gong, Qi Liu",http://arxiv.org/pdf/2412.12735v1,cs.CL
EventFull: Complete and Consistent Event Relation Annotation,"Event relation detection is a fundamental NLP task, leveraged in many
downstream applications, whose modeling requires datasets annotated with event
relations of various types. However, systematic and complete annotation of
these relations is costly and challenging, due to the quadratic number of event
pairs that need to be considered. Consequently, many current event relation
datasets lack systematicity and completeness. In response, we introduce
\textit{EventFull}, the first tool that supports consistent, complete and
efficient annotation of temporal, causal and coreference relations via a
unified and synergetic process. A pilot study demonstrates that EventFull
accelerates and simplifies the annotation process while yielding high
inter-annotator agreement.",2024-12-17,"Alon Eirew, Eviatar Nachshoni, Aviv Slobodkin, Ido Dagan",http://arxiv.org/pdf/2412.12733v1,cs.CL
SentiQNF: A Novel Approach to Sentiment Analysis Using Quantum Algorithms and Neuro-Fuzzy Systems,"Sentiment analysis is an essential component of natural language processing,
used to analyze sentiments, attitudes, and emotional tones in various contexts.
It provides valuable insights into public opinion, customer feedback, and user
experiences. Researchers have developed various classical machine learning and
neuro-fuzzy approaches to address the exponential growth of data and the
complexity of language structures in sentiment analysis. However, these
approaches often fail to determine the optimal number of clusters, interpret
results accurately, handle noise or outliers efficiently, and scale effectively
to high-dimensional data. Additionally, they are frequently insensitive to
input variations. In this paper, we propose a novel hybrid approach for
sentiment analysis called the Quantum Fuzzy Neural Network (QFNN), which
leverages quantum properties and incorporates a fuzzy layer to overcome the
limitations of classical sentiment analysis algorithms. In this study, we test
the proposed approach on two Twitter datasets: the Coronavirus Tweets Dataset
(CVTD) and the General Sentimental Tweets Dataset (GSTD), and compare it with
classical and hybrid algorithms. The results demonstrate that QFNN outperforms
all classical, quantum, and hybrid algorithms, achieving 100% and 90% accuracy
in the case of CVTD and GSTD, respectively. Furthermore, QFNN demonstrates its
robustness against six different noise models, providing the potential to
tackle the computational complexity associated with sentiment analysis on a
large scale in a noisy environment. The proposed approach expedites sentiment
data processing and precisely analyses different forms of textual data, thereby
enhancing sentiment classification and insights associated with sentiment
analysis.",2024-12-17,"Kshitij Dave, Nouhaila Innan, Bikash K. Behera, Zahid Mumtaz, Saif Al-Kuwari, Ahmed Farouk",http://arxiv.org/pdf/2412.12731v2,cs.CL
Enhancing Naturalness in LLM-Generated Utterances through Disfluency Insertion,"Disfluencies are a natural feature of spontaneous human speech but are
typically absent from the outputs of Large Language Models (LLMs). This absence
can diminish the perceived naturalness of synthesized speech, which is an
important criteria when building conversational agents that aim to mimick human
behaviours. We show how the insertion of disfluencies can alleviate this
shortcoming. The proposed approach involves (1) fine-tuning an LLM with
Low-Rank Adaptation (LoRA) to incorporate various types of disfluencies into
LLM-generated utterances and (2) synthesizing those utterances using a
text-to-speech model that supports the generation of speech phenomena such as
disfluencies. We evaluated the quality of the generated speech across two
metrics: intelligibility and perceived spontaneity. We demonstrate through a
user study that the insertion of disfluencies significantly increase the
perceived spontaneity of the generated speech. This increase came, however,
along with a slight reduction in intelligibility.",2024-12-17,"Syed Zohaib Hassan, Pierre Lison, Pål Halvorsen",http://arxiv.org/pdf/2412.12710v1,cs.CL
"More Tokens, Lower Precision: Towards the Optimal Token-Precision Trade-off in KV Cache Compression","As large language models (LLMs) process increasing context windows, the
memory usage of KV cache has become a critical bottleneck during inference. The
mainstream KV compression methods, including KV pruning and KV quantization,
primarily focus on either token or precision dimension separately. However,
these works leaving the trade-off between these two orthogonal dimensions
largely under-explored. In this paper, we comprehensively investigate the
token-precision trade-off in KV cache compression.Experiments demonstrate that
storing more tokens in the KV cache with lower precision,a strategy we term
quantized pruning, can significantly enhance the long-context performance of
LLMs. In-depth analysis of the token-precision trade-off across key aspects
demonstrates that, quantized pruning achieves substantial improvements in
retrieval-related tasks and consistently performs well across varying input
lengths. Furthermore, quantized pruning demonstrates notable stability and
effectiveness across different KV pruning methods, quantization strategies, and
model scales. These findings offer valuable insights into optimizing KV cache
compression through balanced token-precision trade-off strategies. Our code is
available at https://github.com/zhzihao/QPruningKV.",2024-12-17,"Jiebin Zhang, Dawei Zhu, Yifan Song, Wenhao Wu, Chuqiao Kuang, Xiaoguang Li, Lifeng Shang, Qun Liu, Sujian Li",http://arxiv.org/pdf/2412.12706v2,cs.CL
Trigger$^3$: Refining Query Correction via Adaptive Model Selector,"In search scenarios, user experience can be hindered by erroneous queries due
to typos, voice errors, or knowledge gaps. Therefore, query correction is
crucial for search engines. Current correction models, usually small models
trained on specific data, often struggle with queries beyond their training
scope or those requiring contextual understanding. While the advent of Large
Language Models (LLMs) offers a potential solution, they are still limited by
their pre-training data and inference cost, particularly for complex queries,
making them not always effective for query correction. To tackle these, we
propose Trigger$^3$, a large-small model collaboration framework that
integrates the traditional correction model and LLM for query correction,
capable of adaptively choosing the appropriate correction method based on the
query and the correction results from the traditional correction model and LLM.
Trigger$^3$ first employs a correction trigger to filter out correct queries.
Incorrect queries are then corrected by the traditional correction model. If
this fails, an LLM trigger is activated to call the LLM for correction.
Finally, for queries that no model can correct, a fallback trigger decides to
return the original query. Extensive experiments demonstrate Trigger$^3$
outperforms correction baselines while maintaining efficiency.",2024-12-17,"Kepu Zhang, Zhongxiang Sun, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, Jun Xu",http://arxiv.org/pdf/2412.12701v1,cs.CL
Exploring Cross-lingual Latent Transplantation: Mutual Opportunities and Open Challenges,"Current large language models (LLMs) often exhibit imbalances in multilingual
capabilities and cultural adaptability, largely attributed to their
English-centric pre-training data. In this paper, we introduce and investigate
a cross-lingual latent transplantation (XTransplant) framework, which aims to
further exploit the model's internalized multilingual knowledge during
inference and examine its effects on the multilingual capability and cultural
adaptability of LLMs. XTransplant framework enables models to harness the
complementary strengths of both English and non-English resources by
transplanting latent activations across languages. Through extensive analysis,
we empirically demonstrate that XTransplant, a form of cross-lingual
interaction, has mutually beneficial effects on the multilingual capability and
cultural adaptability of LLMs, particularly for low-resource languages and
cultures. We further reveal that attention modules play a pivotal role in
supporting multilingual understanding, while feed-forward modules are more
adept at capturing culture-specific knowledge. In addition, we conduct in-depth
analysis of XTransplant's stability, effectiveness, and generalizability. By
probing the upper bound performance of XTransplant, we expose the considerable
underutilization of current LLMs' multilingual potential-a challenge that
remains open. We hope our analysis offers a new lens for advancing
cross-lingual interactions and better leveraging models' internalized
multilingual knowledge.",2024-12-17,"Yangfan Ye, Xiaocheng Feng, Xiachong Feng, Libo Qin, Yichong Huang, Lei Huang, Weitao Ma, Qichen Hong, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin",http://arxiv.org/pdf/2412.12686v2,cs.CL
Detecting Document-level Paraphrased Machine Generated Content: Mimicking Human Writing Style and Involving Discourse Features,"The availability of high-quality APIs for Large Language Models (LLMs) has
facilitated the widespread creation of Machine-Generated Content (MGC), posing
challenges such as academic plagiarism and the spread of misinformation.
Existing MGC detectors often focus solely on surface-level information,
overlooking implicit and structural features. This makes them susceptible to
deception by surface-level sentence patterns, particularly for longer texts and
in texts that have been subsequently paraphrased.
  To overcome these challenges, we introduce novel methodologies and datasets.
Besides the publicly available dataset Plagbench, we developed the paraphrased
Long-Form Question and Answer (paraLFQA) and paraphrased Writing Prompts
(paraWP) datasets using GPT and DIPPER, a discourse paraphrasing tool, by
extending artifacts from their original versions. To address the challenge of
detecting highly similar paraphrased texts, we propose MhBART, an
encoder-decoder model designed to emulate human writing style while
incorporating a novel difference score mechanism. This model outperforms strong
classifier baselines and identifies deceptive sentence patterns. To better
capture the structure of longer texts at document level, we propose
DTransformer, a model that integrates discourse analysis through PDTB
preprocessing to encode structural features. It results in substantial
performance gains across both datasets -- 15.5\% absolute improvement on
paraLFQA, 4\% absolute improvement on paraWP, and 1.5\% absolute improvement on
M4 compared to SOTA approaches.",2024-12-17,"Yupei Li, Manuel Milling, Lucia Specia, Björn W. Schuller",http://arxiv.org/pdf/2412.12679v1,cs.CL
Train More Parameters But Mind Their Placement: Insights into Language Adaptation with PEFT,"Smaller LLMs still face significant challenges even in medium-resourced
languages, particularly when it comes to language-specific knowledge -- a
problem not easily resolved with machine-translated data. In this case study on
Icelandic, we aim to enhance the generation performance of an LLM by
specialising it using unstructured text corpora. A key focus is on preventing
interference with the models' capabilities of handling longer context during
this adaptation. Through ablation studies using various parameter-efficient
fine-tuning (PEFT) methods and setups, we find that increasing the number of
trainable parameters leads to better and more robust language adaptation. LoRAs
placed in the feed-forward layers and bottleneck adapters show promising
results with sufficient parameters, while prefix tuning and (IA)3 are not
suitable. Although improvements are consistent in 0-shot summarisation, some
adapted models struggle with longer context lengths, an issue that can be
mitigated by adapting only the final layers.",2024-12-17,Jenny Kunz,http://arxiv.org/pdf/2412.12674v1,cs.CL
MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants,"Recent advancements in mixed-modal generative have opened new avenues for
developing unified biomedical assistants capable of analyzing biomedical
images, answering complex questions about them, and generating multimodal
patient reports. However, existing datasets face challenges such as small
sizes, limited coverage of biomedical tasks and domains, and a reliance on
narrow sources. To address these gaps, we present MedMax, a large-scale
multimodal biomedical instruction-tuning dataset for mixed-modal foundation
models. With 1.47 million instances, MedMax encompasses a diverse range of
tasks, including interleaved image-text generation, biomedical image captioning
and generation, visual chat, and report understanding. These tasks span
knowledge across diverse biomedical domains, including radiology and
histopathology, grounded in medical papers and YouTube videos. Subsequently, we
fine-tune a mixed-modal foundation model on the MedMax dataset, achieving
significant performance improvements: a 26% gain over the Chameleon model and
an 18.3% improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Finally, we introduce a unified evaluation suite for
biomedical tasks to guide the development of mixed-modal biomedical AI
assistants. The data, model, and code is available at
https://mint-medmax.github.io/.",2024-12-17,"Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover",http://arxiv.org/pdf/2412.12661v2,cs.CL
ClustEm4Ano: Clustering Text Embeddings of Nominal Textual Attributes for Microdata Anonymization,"This work introduces ClustEm4Ano, an anonymization pipeline that can be used
for generalization and suppression-based anonymization of nominal textual
tabular data. It automatically generates value generalization hierarchies
(VGHs) that, in turn, can be used to generalize attributes in
quasi-identifiers. The pipeline leverages embeddings to generate semantically
close value generalizations through iterative clustering. We applied KMeans and
Hierarchical Agglomerative Clustering on $13$ different predefined text
embeddings (both open and closed-source (via APIs)). Our approach is
experimentally tested on a well-known benchmark dataset for anonymization: The
UCI Machine Learning Repository's Adult dataset. ClustEm4Ano supports
anonymization procedures by offering more possibilities compared to using
arbitrarily chosen VGHs. Experiments demonstrate that these VGHs can outperform
manually constructed ones in terms of downstream efficacy (especially for small
$k$-anonymity ($2 \leq k \leq 30$)) and therefore can foster the quality of
anonymized datasets. Our implementation is made public.",2024-12-17,"Robert Aufschläger, Sebastian Wilhelm, Michael Heigl, Martin Schramm",http://arxiv.org/pdf/2412.12649v1,cs.CL
iPrOp: Interactive Prompt Optimization for Large Language Models with a Human in the Loop,"Prompt engineering has made significant contributions to the era of large
language models, yet its effectiveness depends on the skills of a prompt
author. Automatic prompt optimization can support the prompt development
process, but requires annotated data. This paper introduces $\textit{iPrOp}$, a
novel Interactive Prompt Optimization system, to bridge manual prompt
engineering and automatic prompt optimization. With human intervention in the
optimization loop, $\textit{iPrOp}$ offers users the flexibility to assess
evolving prompts. We present users with prompt variations, selected instances,
large language model predictions accompanied by corresponding explanations, and
performance metrics derived from a subset of the training data. This approach
empowers users to choose and further refine the provided prompts based on their
individual preferences and needs. This system not only assists non-technical
domain experts in generating optimal prompts tailored to their specific tasks
or domains, but also enables to study the intrinsic parameters that influence
the performance of prompt optimization. Our evaluation shows that our system
has the capability to generate improved prompts, leading to enhanced task
performance.",2024-12-17,"Jiahui Li, Roman Klinger",http://arxiv.org/pdf/2412.12644v1,cs.CL
LLM-based Discriminative Reasoning for Knowledge Graph Question Answering,"Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm. To tackle this issue, we propose READS to reformulate the KGQA
process into discriminative subtasks, which simplifies the search space for
each subtasks. Based on the subtasks, we design a new corresponding
discriminative inference strategy to conduct the reasoning for KGQA, thereby
alleviating hallucination and ungrounded reasoning issues in LLMs. Experimental
results show that the proposed approach outperforms multiple strong comparison
methods, along with achieving state-of-the-art performance on widely used
benchmarks WebQSP and CWQ.",2024-12-17,"Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang",http://arxiv.org/pdf/2412.12643v2,cs.CL
Baichuan4-Finance Technical Report,"Large language models (LLMs) have demonstrated strong capabilities in
language understanding, generation, and reasoning, yet their potential in
finance remains underexplored due to the complexity and specialization of
financial knowledge. In this work, we report the development of the
Baichuan4-Finance series, including a comprehensive suite of foundational
Baichuan4-Finance-Base and an aligned language model Baichuan4-Finance, which
are built upon Baichuan4-Turbo base model and tailored for finance domain.
Firstly, we have dedicated significant effort to building a detailed pipeline
for improving data quality. Moreover, in the continual pre-training phase, we
propose a novel domain self-constraint training strategy, which enables
Baichuan4-Finance-Base to acquire financial knowledge without losing general
capabilities. After Supervised Fine-tuning and Reinforcement Learning from
Human Feedback and AI Feedback, the chat model Baichuan4-Finance is able to
tackle various financial certification questions and real-world scenario
applications. We evaluate Baichuan4-Finance on many widely used general
datasets and two holistic financial benchmarks. The evaluation results show
that Baichuan4-Finance-Base surpasses almost all competitive baselines on
financial tasks by significant margins without sacrificing performance on
general LLM benchmarks. At the same time, Baichuan4-Finance demonstrates even
more impressive performance on financial application scenarios, showcasing its
potential to foster community innovation in the financial LLM field.",2024-12-17,"Hanyu Zhang, Boyu Qiu, Yuhao Feng, Shuqi Li, Qian Ma, Xiyuan Zhang, Qiang Ju, Dong Yan, Jian Xie",http://arxiv.org/pdf/2412.15270v2,cs.CL
The Reliability Paradox: Exploring How Shortcut Learning Undermines Language Model Calibration,"The advent of pre-trained language models (PLMs) has enabled significant
performance gains in the field of natural language processing. However, recent
studies have found PLMs to suffer from miscalibration, indicating a lack of
accuracy in the confidence estimates provided by these models. Current
evaluation methods for PLM calibration often assume that lower calibration
error estimates indicate more reliable predictions. However, fine-tuned PLMs
often resort to shortcuts, leading to overconfident predictions that create the
illusion of enhanced performance but lack generalizability in their decision
rules. The relationship between PLM reliability, as measured by calibration
error, and shortcut learning, has not been thoroughly explored thus far. This
paper aims to investigate this relationship, studying whether lower calibration
error implies reliable decision rules for a language model. Our findings reveal
that models with seemingly superior calibration portray higher levels of
non-generalizable decision rules. This challenges the prevailing notion that
well-calibrated models are inherently reliable. Our study highlights the need
to bridge the current gap between language model calibration and generalization
objectives, urging the development of comprehensive frameworks to achieve truly
robust and reliable language models.",2024-12-17,"Geetanjali Bihani, Julia Rayz",http://arxiv.org/pdf/2412.15269v1,cs.CL
Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-Designed Decoding Tree,"Striking an optimal balance between minimal drafting latency and high
speculation accuracy to enhance the inference speed of Large Language Models
remains a significant challenge in speculative decoding. In this paper, we
introduce Falcon, an innovative semi-autoregressive speculative decoding
framework fashioned to augment both the drafter's parallelism and output
quality. Falcon incorporates the Coupled Sequential Glancing Distillation
technique, which fortifies inter-token dependencies within the same block,
leading to increased speculation accuracy. We offer a comprehensive theoretical
analysis to illuminate the underlying mechanisms. Additionally, we introduce a
Custom-Designed Decoding Tree, which permits the drafter to generate multiple
tokens in a single forward pass and accommodates multiple forward passes as
needed, thereby boosting the number of drafted tokens and significantly
improving the overall acceptance rate. Comprehensive evaluations on benchmark
datasets such as MT-Bench, HumanEval, and GSM8K demonstrate Falcon's superior
acceleration capabilities. The framework achieves a lossless speedup ratio
ranging from 2.91x to 3.51x when tested on the Vicuna and LLaMA2-Chat model
series. These results outstrip existing speculative decoding methods for LLMs,
including Eagle, Medusa, Lookahead, SPS, and PLD, while maintaining a compact
drafter architecture equivalent to merely two Transformer layers.",2024-12-17,"Xiangxiang Gao, Weisheng Xie, Yiwei Xiang, Feng Ji",http://arxiv.org/pdf/2412.12639v3,cs.CL
What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context for Multi-Hop QA,"Incorporating external knowledge has emerged as a promising way to mitigate
outdated knowledge and hallucinations in LLM. However, external knowledge is
often imperfect, encompassing substantial extraneous or even inaccurate
content, which interferes with the LLM's utilization of useful knowledge in the
context. This paper seeks to characterize the features of preferred external
knowledge and perform empirical studies in imperfect contexts. Inspired by the
chain of evidence (CoE), we characterize that the knowledge preferred by LLMs
should maintain both relevance to the question and mutual support among the
textual pieces. Accordingly, we propose a CoE discrimination approach and
conduct a comparative analysis between CoE and Non-CoE samples across
significance, deceptiveness, and robustness, revealing the LLM's preference for
external knowledge that aligns with CoE features. Furthermore, we selected
three representative tasks (RAG-based multi-hop QA, external knowledge
poisoning and poisoning defense), along with corresponding SOTA or prevalent
baselines. By integrating CoE features, the variants achieved significant
improvements over the original baselines.",2024-12-17,"Zhiyuan Chang, Mingyang Li, Xiaojun Jia, Junjie Wang, Yuekai Huang, Qing Wang, Yihao Huang, Yang Liu",http://arxiv.org/pdf/2412.12632v3,cs.CL
Evaluating the Capabilities of Large Language Models for Multi-label Emotion Understanding,"Large Language Models (LLMs) show promising learning and reasoning abilities.
Compared to other NLP tasks, multilingual and multi-label emotion evaluation
tasks are under-explored in LLMs. In this paper, we present EthioEmo, a
multi-label emotion classification dataset for four Ethiopian languages,
namely, Amharic (amh), Afan Oromo (orm), Somali (som), and Tigrinya (tir). We
perform extensive experiments with an additional English multi-label emotion
dataset from SemEval 2018 Task 1. Our evaluation includes encoder-only,
encoder-decoder, and decoder-only language models. We compare zero and few-shot
approaches of LLMs to fine-tuning smaller language models. The results show
that accurate multi-label emotion classification is still insufficient even for
high-resource languages such as English, and there is a large gap between the
performance of high-resource and low-resource languages. The results also show
varying performance levels depending on the language and model type. EthioEmo
is available publicly to further improve the understanding of emotions in
language models and how people convey emotions through various languages.",2024-12-17,"Tadesse Destaw Belay, Israel Abebe Azime, Abinew Ali Ayele, Grigori Sidorov, Dietrich Klakow, Philipp Slusallek, Olga Kolesnikova, Seid Muhie Yimam",http://arxiv.org/pdf/2412.17837v2,cs.CL
Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation,"Visual information has been introduced for enhancing machine translation
(MT), and its effectiveness heavily relies on the availability of large amounts
of bilingual parallel sentence pairs with manual image annotations. In this
paper, we introduce a stable diffusion-based imagination network into a
multimodal large language model (MLLM) to explicitly generate an image for each
source sentence, thereby advancing the multimodel MT. Particularly, we build
heuristic human feedback with reinforcement learning to ensure the consistency
of the generated image with the source sentence without the supervision of
image annotation, which breaks the bottleneck of using visual information in
MT. Furthermore, the proposed method enables imaginative visual information to
be integrated into large-scale text-only MT in addition to multimodal MT.
Experimental results show that our model significantly outperforms existing
multimodal MT and text-only MT, especially achieving an average improvement of
more than 14 BLEU points on Multi30K multimodal MT benchmarks.",2024-12-17,"Andong Chen, Yuchen Song, Kehai Chen, Muyun Yang, Tiejun Zhao, Min Zhang",http://arxiv.org/pdf/2412.12627v2,cs.CL
Jailbreaking? One Step Is Enough!,"Large language models (LLMs) excel in various tasks but remain vulnerable to
jailbreak attacks, where adversaries manipulate prompts to generate harmful
outputs. Examining jailbreak prompts helps uncover the shortcomings of LLMs.
However, current jailbreak methods and the target model's defenses are engaged
in an independent and adversarial process, resulting in the need for frequent
attack iterations and redesigning attacks for different models. To address
these gaps, we propose a Reverse Embedded Defense Attack (REDA) mechanism that
disguises the attack intention as the ""defense"". intention against harmful
content. Specifically, REDA starts from the target response, guiding the model
to embed harmful content within its defensive measures, thereby relegating
harmful content to a secondary role and making the model believe it is
performing a defensive task. The attacking model considers that it is guiding
the target model to deal with harmful content, while the target model thinks it
is performing a defensive task, creating an illusion of cooperation between the
two. Additionally, to enhance the model's confidence and guidance in
""defensive"" intentions, we adopt in-context learning (ICL) with a small number
of attack examples and construct a corresponding dataset of attack examples.
Extensive evaluations demonstrate that the REDA method enables cross-model
attacks without the need to redesign attack strategies for different models,
enables successful jailbreak in one iteration, and outperforms existing methods
on both open-source and closed-source models.",2024-12-17,"Weixiong Zheng, Peijian Zeng, Yiwei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou",http://arxiv.org/pdf/2412.12621v1,cs.CL
Auto-Cypher: Improving LLMs on Cypher generation via LLM-supervised generation-verification framework,"Graph databases like Neo4j are gaining popularity for handling complex,
interconnected data, over traditional relational databases in modeling and
querying relationships. While translating natural language into SQL queries is
well-researched, generating Cypher queries for Neo4j remains relatively
underexplored. In this work, we present an automated, LLM-Supervised, pipeline
to generate high-quality synthetic data for Text2Cypher. Our Cypher data
generation pipeline introduces LLM-As-Database-Filler, a novel strategy for
ensuring Cypher query correctness, thus resulting in high quality generations.
Using our pipeline, we generate high quality Text2Cypher data - SynthCypher
containing 29.8k instances across various domains and queries with varying
complexities. Training open-source LLMs like LLaMa-3.1-8B, Mistral-7B, and
QWEN-7B on SynthCypher results in performance gains of up to 40% on the
Text2Cypher test split and 30% on the SPIDER benchmark, adapted for graph
databases.",2024-12-17,"Aman Tiwari, Shiva Krishna Reddy Malay, Vikas Yadav, Masoud Hashemi, Sathwik Tejaswi Madhusudhan",http://arxiv.org/pdf/2412.12612v2,cs.CL
MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning,"Program-of-Thought (PoT), which aims to use programming language instead of
natural language as an intermediate step in reasoning, is an important way for
LLMs to solve mathematical problems. Since different programming languages
excel in different areas, it is natural to use the most suitable language for
solving specific problems. However, current PoT research only focuses on single
language PoT, ignoring the differences between different programming languages.
Therefore, this paper proposes an multilingual program reasoning method,
MultiLingPoT. This method allows the model to answer questions using multiple
programming languages by fine-tuning on multilingual data. Additionally, prior
and posterior hybrid methods are used to help the model select the most
suitable language for each problem. Our experimental results show that the
training of MultiLingPoT improves each program's mathematical reasoning by
about 2.5\%. Moreover, with proper mixing, the performance of MultiLingPoT can
be further improved, achieving a 6\% increase compared to the single-language
PoT with the data augmentation.Resources of this paper can be found at
https://github.com/Nianqi-Li/MultiLingPoT.",2024-12-17,"Nianqi Li, Zujie Liang, Siyu Yuan, Jiaqing Liang, Feng Wei, Yanghua Xiao",http://arxiv.org/pdf/2412.12609v1,cs.CL
Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models,"The rapidly developing field of large multimodal models (LMMs) has led to the
emergence of diverse models with remarkable capabilities. However, existing
benchmarks fail to comprehensively, objectively and accurately evaluate whether
LMMs align with the diverse needs of humans in real-world scenarios. To bridge
this gap, we propose the Multi-Dimensional Insights (MDI) benchmark, which
includes over 500 images covering six common scenarios of human life. Notably,
the MDI-Benchmark offers two significant advantages over existing evaluations:
(1) Each image is accompanied by two types of questions: simple questions to
assess the model's understanding of the image, and complex questions to
evaluate the model's ability to analyze and reason beyond basic content. (2)
Recognizing that people of different age groups have varying needs and
perspectives when faced with the same scenario, our benchmark stratifies
questions into three age categories: young people, middle-aged people, and
older people. This design allows for a detailed assessment of LMMs'
capabilities in meeting the preferences and needs of different age groups. With
MDI-Benchmark, the strong model like GPT-4o achieve 79% accuracy on age-related
tasks, indicating that existing LMMs still have considerable room for
improvement in addressing real-world applications. Looking ahead, we anticipate
that the MDI-Benchmark will open new pathways for aligning real-world
personalization in LMMs. The MDI-Benchmark data and evaluation code are
available at https://mdi-benchmark.github.io/",2024-12-17,"YiFan Zhang, Shanglin Lei, Runqi Qiao, Zhuoma GongQue, Xiaoshuai Song, Guanting Dong, Qiuna Tan, Zhe Wei, Peiqing Yang, Ye Tian, Yadong Xue, Xiaofei Wang, Honggang Zhang",http://arxiv.org/pdf/2412.12606v1,cs.CL
LLMs are Also Effective Embedding Models: An In-depth Overview,"Large language models (LLMs) have revolutionized natural language processing
by achieving state-of-the-art performance across various tasks. Recently, their
effectiveness as embedding models has gained attention, marking a paradigm
shift from traditional encoder-only models like ELMo and BERT to decoder-only,
large-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an
in-depth overview of this transition, beginning with foundational techniques
before the LLM era, followed by LLM-based embedding models through two main
strategies to derive embeddings from LLMs. 1) Direct prompting: We mainly
discuss the prompt designs and the underlying rationale for deriving
competitive embeddings. 2) Data-centric tuning: We cover extensive aspects that
affect tuning an embedding model, including model architecture, training
objectives, data constructions, etc. Upon the above, we also cover advanced
methods, such as handling longer texts, and multilingual and cross-modal data.
Furthermore, we discuss factors affecting choices of embedding models, such as
performance/efficiency comparisons, dense vs sparse embeddings, pooling
strategies, and scaling law. Lastly, the survey highlights the limitations and
challenges in adapting LLMs for embeddings, including cross-task embedding
quality, trade-offs between efficiency and accuracy, low-resource,
long-context, data bias, robustness, etc. This survey serves as a valuable
resource for researchers and practitioners by synthesizing current
advancements, highlighting key challenges, and offering a comprehensive
framework for future work aimed at enhancing the effectiveness and efficiency
of LLMs as embedding models.",2024-12-17,"Chongyang Tao, Tao Shen, Shen Gao, Junshuo Zhang, Zhen Li, Zhengwei Tao, Shuai Ma",http://arxiv.org/pdf/2412.12591v1,cs.CL
PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization,"As online platforms and recommendation algorithms evolve, people are
increasingly trapped in echo chambers, leading to biased understandings of
various issues. To combat this issue, we have introduced PerSphere, a benchmark
designed to facilitate multi-faceted perspective retrieval and summarization,
thus breaking free from these information silos. For each query within
PerSphere, there are two opposing claims, each supported by distinct,
non-overlapping perspectives drawn from one or more documents. Our goal is to
accurately summarize these documents, aligning the summaries with the
respective claims and their underlying perspectives. This task is structured as
a two-step end-to-end pipeline that includes comprehensive document retrieval
and multi-faceted summarization. Furthermore, we propose a set of metrics to
evaluate the comprehensiveness of the retrieval and summarization content.
Experimental results on various counterparts for the pipeline show that recent
models struggle with such a complex task. Analysis shows that the main
challenge lies in long context and perspective extraction, and we propose a
simple but effective multi-agent summarization system, offering a promising
solution to enhance performance on PerSphere.",2024-12-17,"Yun Luo, Yingjie Li, Xiangkun Hu, Qinglin Qi, Fang Guo, Qipeng Guo, Zheng Zhang, Yue Zhang",http://arxiv.org/pdf/2412.12588v1,cs.CL
Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph,"The rapid growth of social media platforms has raised significant concerns
regarding online content toxicity. When Large Language Models (LLMs) are used
for toxicity detection, two key challenges emerge: 1) the absence of
domain-specific toxic knowledge leads to false negatives; 2) the excessive
sensitivity of LLMs to toxic speech results in false positives, limiting
freedom of speech. To address these issues, we propose a novel method called
MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance
hatred and toxicity detection. First, we construct a comprehensive meta-toxic
knowledge graph by utilizing LLMs to extract toxic information through a
three-step pipeline, with toxic benchmark datasets serving as corpora. Second,
we query the graph via retrieval and ranking processes to supplement accurate,
relevant toxic knowledge. Extensive experiments and in-depth case studies
across multiple datasets demonstrate that our MetaTox significantly decreases
the false positive rate while boosting overall toxicity detection performance.
Our code will be available soon.",2024-12-17,"Yibo Zhao, Jiapeng Zhu, Can Xu, Xiang Li",http://arxiv.org/pdf/2412.15268v2,cs.CL
Process-Supervised Reward Models for Verifying Clinical Note Generation: A Scalable Approach Guided by Domain Expertise,"Process-supervised reward models (PRMs), which verify large language model
(LLM) outputs step-by-step, have achieved significant success in mathematical
and coding problems. However, their application to other domains remains
largely unexplored. In this work, we train a PRM to provide step-level reward
signals for clinical notes generated by LLMs from patient-doctor dialogues.
Guided by real-world clinician expertise, we carefully designed step
definitions for clinical notes and utilized Gemini-Pro 1.5 to automatically
generate process supervision data at scale. Our proposed PRM, trained on the
LLaMA-3.1 8B instruct model, outperformed both Gemini-Pro 1.5 and the vanilla
outcome-supervised reward model (ORM) in two key evaluations: (1) selecting
gold-reference samples from error-containing ones, achieving 98.8% accuracy
(versus 70.0% for the vanilla ORM and 93.8% for Gemini-Pro 1.5), and (2)
selecting physician-preferred notes, achieving 56.2% accuracy (compared to
37.5% for the vanilla ORM and 50.0% for Gemini-Pro 1.5). Additionally, we
conducted ablation studies to determine optimal loss functions and data
selection strategies, along with physician reader studies to explore predictors
of downstream Best-of-N performance. Our promising results suggest the
potential of PRMs to extend beyond the clinical domain, offering a scalable and
effective solution for diverse generative tasks.",2024-12-17,"Hanyin Wang, Chufan Gao, Qiping Xu, Bolun Liu, Guleid Hussein, Hariprasad Korsapati, Mohamad El Labban, Kingsley Iheasirim, Mohamed Hassan, Gokhan Anil, Brian Bartlett, Jimeng Sun",http://arxiv.org/pdf/2412.12583v2,cs.CL
Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport,"Lexical semantic change detection aims to identify shifts in word meanings
over time. While existing methods using embeddings from a diachronic corpus
pair estimate the degree of change for target words, they offer limited insight
into changes at the level of individual usage instances. To address this, we
apply Unbalanced Optimal Transport (UOT) to sets of contextualized word
embeddings, capturing semantic change through the excess and deficit in the
alignment between usage instances. In particular, we propose Sense Usage Shift
(SUS), a measure that quantifies changes in the usage frequency of a word sense
at each usage instance. By leveraging SUS, we demonstrate that several
challenges in semantic change detection can be addressed in a unified manner,
including quantifying instance-level semantic change and word-level tasks such
as measuring the magnitude of semantic change and the broadening or narrowing
of meaning.",2024-12-17,"Ryo Kishino, Hiroaki Yamagiwa, Ryo Nagata, Sho Yokoi, Hidetoshi Shimodaira",http://arxiv.org/pdf/2412.12569v1,cs.CL
FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning,"Real-world decision-making often requires integrating and reasoning over
information from multiple modalities. While recent multimodal large language
models (MLLMs) have shown promise in such tasks, their ability to perform
multi-hop reasoning across diverse sources remains insufficiently evaluated.
Existing benchmarks, such as MMQA, face challenges due to (1) data
contamination and (2) a lack of complex queries that necessitate operations
across more than two modalities, hindering accurate performance assessment. To
address this, we present Financial Cross-Modal Multi-Hop Reasoning (FCMR), a
benchmark created to analyze the reasoning capabilities of MLLMs by urging them
to combine information from textual reports, tables, and charts within the
financial domain. FCMR is categorized into three difficulty levels-Easy,
Medium, and Hard-facilitating a step-by-step evaluation. In particular,
problems at the Hard level require precise cross-modal three-hop reasoning and
are designed to prevent the disregard of any modality. Experiments on this new
benchmark reveal that even state-of-the-art MLLMs struggle, with the
best-performing model (Claude 3.5 Sonnet) achieving only 30.4% accuracy on the
most challenging tier. We also conduct analysis to provide insights into the
inner workings of the models, including the discovery of a critical bottleneck
in the information retrieval phase.",2024-12-17,"Seunghee Kim, Changhyeon Kim, Taeuk Kim",http://arxiv.org/pdf/2412.12567v2,cs.CL
Evaluating Zero-Shot Multilingual Aspect-Based Sentiment Analysis with Large Language Models,"Aspect-based sentiment analysis (ABSA), a sequence labeling task, has
attracted increasing attention in multilingual contexts. While previous
research has focused largely on fine-tuning or training models specifically for
ABSA, we evaluate large language models (LLMs) under zero-shot conditions to
explore their potential to tackle this challenge with minimal task-specific
adaptation. We conduct a comprehensive empirical evaluation of a series of LLMs
on multilingual ABSA tasks, investigating various prompting strategies,
including vanilla zero-shot, chain-of-thought (CoT), self-improvement,
self-debate, and self-consistency, across nine different models. Results
indicate that while LLMs show promise in handling multilingual ABSA, they
generally fall short of fine-tuned, task-specific models. Notably, simpler
zero-shot prompts often outperform more complex strategies, especially in
high-resource languages like English. These findings underscore the need for
further refinement of LLM-based approaches to effectively address ABSA task
across diverse languages.",2024-12-17,"Chengyan Wu, Bolei Ma, Zheyu Zhang, Ningyuan Deng, Yanqing He, Yun Xue",http://arxiv.org/pdf/2412.12564v2,cs.CL
Task-Agnostic Language Model Watermarking via High Entropy Passthrough Layers,"In the era of costly pre-training of large language models, ensuring the
intellectual property rights of model owners, and insuring that said models are
responsibly deployed, is becoming increasingly important. To this end, we
propose model watermarking via passthrough layers, which are added to existing
pre-trained networks and trained using a self-supervised loss such that the
model produces high-entropy output when prompted with a unique private key, and
acts normally otherwise. Unlike existing model watermarking methods, our method
is fully task-agnostic, and can be applied to both classification and
sequence-to-sequence tasks without requiring advanced access to downstream
fine-tuning datasets. We evaluate the proposed passthrough layers on a wide
range of downstream tasks, and show experimentally our watermarking method
achieves a near-perfect watermark extraction accuracy and false-positive rate
in most cases without damaging original model performance. Additionally, we
show our method is robust to both downstream fine-tuning, fine-pruning, and
layer removal attacks, and can be trained in a fraction of the time required to
train the original model. Code is available in the paper.",2024-12-17,"Vaden Masrani, Mohammad Akbari, David Ming Xuan Yue, Ahmad Rezaei, Yong Zhang",http://arxiv.org/pdf/2412.12563v1,cs.CL
EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation,"We introduce EXIT, an extractive context compression framework that enhances
both the effectiveness and efficiency of retrieval-augmented generation (RAG)
in question answering (QA). Current RAG systems often struggle when retrieval
models fail to rank the most relevant documents, leading to the inclusion of
more context at the expense of latency and accuracy. While abstractive
compression methods can drastically reduce token counts, their token-by-token
generation process significantly increases end-to-end latency. Conversely,
existing extractive methods reduce latency but rely on independent,
non-adaptive sentence selection, failing to fully utilize contextual
information. EXIT addresses these limitations by classifying sentences from
retrieved documents - while preserving their contextual dependencies - enabling
parallelizable, context-aware extraction that adapts to query complexity and
retrieval quality. Our evaluations on both single-hop and multi-hop QA tasks
show that EXIT consistently surpasses existing compression methods and even
uncompressed baselines in QA accuracy, while also delivering substantial
reductions in inference time and token count. By improving both effectiveness
and efficiency, EXIT provides a promising direction for developing scalable,
high-quality QA solutions in RAG pipelines. Our code is available at
https://github.com/ThisIsHwang/EXIT",2024-12-17,"Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, SeungYoon Han, Jong C. Park",http://arxiv.org/pdf/2412.12559v2,cs.CL
Momentum Posterior Regularization for Multi-hop Dense Retrieval,"Multi-hop question answering (QA) often requires sequential retrieval
(multi-hop retrieval), where each hop retrieves missing knowledge based on
information from previous hops. To facilitate more effective retrieval, we aim
to distill knowledge from a posterior retrieval, which has access to posterior
information like an answer, into a prior retrieval used during inference when
such information is unavailable. Unfortunately, current methods for knowledge
distillation in one-time retrieval are ineffective for multi-hop QA due to two
issues: 1) Posterior information is often defined as the response (i.e. the
answer), which may not clearly connect to the query without intermediate
retrieval; and 2) The large knowledge gap between prior and posterior
retrievals makes existing distillation methods unstable, even resulting in
performance loss. As such, we propose MoPo (Momentum Posterior Regularization)
with two key innovations: 1) Posterior information of one hop is defined as a
query-focus summary from the golden knowledge of the previous and current hops;
2) We develop an effective training strategy where the posterior retrieval is
updated along with the prior retrieval via momentum moving average method,
allowing smoother and effective distillation. Experiments on HotpotQA and
StrategyQA demonstrate that MoPo outperforms existing baselines in both
retrieval and downstream QA tasks.",2024-12-17,"Zehua Xia, Yuyang Wu, Yiyun Xia, Cam-Tu Nguyen",http://arxiv.org/pdf/2502.20399v1,cs.CL
LLMCL-GEC: Advancing Grammatical Error Correction with LLM-Driven Curriculum Learning,"While large-scale language models (LLMs) have demonstrated remarkable
capabilities in specific natural language processing (NLP) tasks, they may
still lack proficiency compared to specialized models in certain domains, such
as grammatical error correction (GEC). Drawing inspiration from the concept of
curriculum learning, we have delved into refining LLMs into proficient GEC
experts by devising effective curriculum learning (CL) strategies. In this
paper, we introduce a novel approach, termed LLM-based curriculum learning,
which capitalizes on the robust semantic comprehension and discriminative
prowess inherent in LLMs to gauge the complexity of GEC training data. Unlike
traditional curriculum learning techniques, our method closely mirrors human
expert-designed curriculums. Leveraging the proposed LLM-based CL method, we
sequentially select varying levels of curriculums ranging from easy to hard,
and iteratively train and refine using the pretrianed T5 and LLaMA series
models. Through rigorous testing and analysis across diverse benchmark
assessments in English GEC, including the CoNLL14 test, BEA19 test, and BEA19
development sets, our approach showcases a significant performance boost over
baseline models and conventional curriculum learning methodologies.",2024-12-17,"Tao Fang, Derek F. Wong, Lusheng Zhang, Keyan Jin, Qiang Zhang, Tianjiao Li, Jinlong Hou, Lidia S. Chao",http://arxiv.org/pdf/2412.12541v1,cs.CL
Toxicity Detection towards Adaptability to Changing Perturbations,"Toxicity detection is crucial for maintaining the peace of the society. While
existing methods perform well on normal toxic contents or those generated by
specific perturbation methods, they are vulnerable to evolving perturbation
patterns. However, in real-world scenarios, malicious users tend to create new
perturbation patterns for fooling the detectors. For example, some users may
circumvent the detector of large language models (LLMs) by adding `I am a
scientist' at the beginning of the prompt. In this paper, we introduce a novel
problem, i.e., continual learning jailbreak perturbation patterns, into the
toxicity detection field. To tackle this problem, we first construct a new
dataset generated by 9 types of perturbation patterns, 7 of them are summarized
from prior work and 2 of them are developed by us. We then systematically
validate the vulnerability of current methods on this new perturbation
pattern-aware dataset via both the zero-shot and fine tuned cross-pattern
detection. Upon this, we present the domain incremental learning paradigm and
the corresponding benchmark to ensure the detector's robustness to dynamically
emerging types of perturbed toxic text. Our code and dataset are provided in
the appendix and will be publicly available at GitHub, by which we wish to
offer new research opportunities for the security-relevant communities.",2024-12-17,"Hankun Kang, Jianhao Chen, Yongqi Li, Xin Miao, Mayi Xu, Ming Zhong, Yuanyuan Zhu, Tieyun Qian",http://arxiv.org/pdf/2412.15267v3,cs.CL
"When to Speak, When to Abstain: Contrastive Decoding with Abstention","Large Language Models (LLMs) demonstrate exceptional performance across
diverse tasks by leveraging pre-trained (i.e., parametric) and external (i.e.,
contextual) knowledge. While substantial efforts have been made to enhance the
utilization of both forms of knowledge, situations in which models lack
relevant information remain underexplored. To investigate this challenge, we
first present a controlled testbed featuring four distinct knowledge access
scenarios, including the aforementioned edge case, revealing that conventional
LLM usage exhibits insufficient robustness in handling all instances.
Addressing this limitation, we propose Contrastive Decoding with Abstention
(CDA), a novel training-free decoding method that allows LLMs to generate
responses when relevant knowledge is available and to abstain otherwise. CDA
estimates the relevance of both knowledge sources for a given input, adaptively
deciding which type of information to prioritize and which to exclude. Through
extensive experiments, we demonstrate that CDA can effectively perform accurate
generation and abstention simultaneously, enhancing reliability and preserving
user trust.",2024-12-17,"Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim",http://arxiv.org/pdf/2412.12527v3,cs.CL
On the Structural Memory of LLM Agents,"Memory plays a pivotal role in enabling large language model~(LLM)-based
agents to engage in complex and long-term interactions, such as question
answering (QA) and dialogue systems. While various memory modules have been
proposed for these tasks, the impact of different memory structures across
tasks remains insufficiently explored. This paper investigates how memory
structures and memory retrieval methods affect the performance of LLM-based
agents. Specifically, we evaluate four types of memory structures, including
chunks, knowledge triples, atomic facts, and summaries, along with mixed memory
that combines these components. In addition, we evaluate three widely used
memory retrieval methods: single-step retrieval, reranking, and iterative
retrieval. Extensive experiments conducted across four tasks and six datasets
yield the following key insights: (1) Different memory structures offer
distinct advantages, enabling them to be tailored to specific tasks; (2) Mixed
memory structures demonstrate remarkable resilience in noisy environments; (3)
Iterative retrieval consistently outperforms other methods across various
scenarios. Our investigation aims to inspire further research into the design
of memory systems for LLM-based agents.",2024-12-17,"Ruihong Zeng, Jinyuan Fang, Siwei Liu, Zaiqiao Meng",http://arxiv.org/pdf/2412.15266v1,cs.CL
Solid-SQL: Enhanced Schema-linking based In-context Learning for Robust Text-to-SQL,"Recently, large language models (LLMs) have significantly improved the
performance of text-to-SQL systems. Nevertheless, many state-of-the-art (SOTA)
approaches have overlooked the critical aspect of system robustness. Our
experiments reveal that while LLM-driven methods excel on standard datasets,
their accuracy is notably compromised when faced with adversarial
perturbations. To address this challenge, we propose a robust text-to-SQL
solution, called Solid-SQL, designed to integrate with various LLMs. We focus
on the pre-processing stage, training a robust schema-linking model enhanced by
LLM-based data augmentation. Additionally, we design a two-round, structural
similarity-based example retrieval strategy for in-context learning. Our method
achieves SOTA SQL execution accuracy levels of 82.1% and 58.9% on the general
Spider and Bird benchmarks, respectively. Furthermore, experimental results
show that Solid-SQL delivers an average improvement of 11.6% compared to
baselines on the perturbed Spider-Syn, Spider-Realistic, and Dr. Spider
benchmarks.",2024-12-17,"Geling Liu, Yunzhi Tan, Ruichao Zhong, Yuanzhen Xie, Lingchen Zhao, Qian Wang, Bo Hu, Zang Li",http://arxiv.org/pdf/2412.12522v1,cs.CL
Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with Population Traits,"The Myers-Briggs Type Indicator (MBTI) is one of the most influential
personality theories reflecting individual differences in thinking, feeling,
and behaving. MBTI personality detection has garnered considerable research
interest and has evolved significantly over the years. However, this task tends
to be overly optimistic, as it currently does not align well with the natural
distribution of population personality traits. Specifically, (1) the
self-reported labels in existing datasets result in incorrect labeling issues,
and (2) the hard labels fail to capture the full range of population
personality distributions. In this paper, we optimize the task by constructing
MBTIBench, the first manually annotated high-quality MBTI personality detection
dataset with soft labels, under the guidance of psychologists. As for the first
challenge, MBTIBench effectively solves the incorrect labeling issues, which
account for 29.58% of the data. As for the second challenge, we estimate soft
labels by deriving the polarity tendency of samples. The obtained soft labels
confirm that there are more people with non-extreme personality traits.
Experimental results not only highlight the polarized predictions and biases in
LLMs as key directions for future research, but also confirm that soft labels
can provide more benefits to other psychological tasks than hard labels. The
code and data are available at https://github.com/Personality-NLP/MbtiBench.",2024-12-17,"Bohan Li, Jiannan Guan, Longxu Dou, Yunlong Feng, Dingzirui Wang, Yang Xu, Enbo Wang, Qiguang Chen, Bichen Wang, Xiao Xu, Yimeng Zhang, Libo Qin, Yanyan Zhao, Qingfu Zhu, Wanxiang Che",http://arxiv.org/pdf/2412.12510v1,cs.CL
Can You Trust LLM Judgments? Reliability of LLM-as-a-Judge,"Large Language Models (LLMs) have become increasingly powerful and
ubiquitous, but their stochastic nature poses challenges to the reliability of
their outputs. While deterministic settings can improve consistency, they do
not guarantee reliability, as a single sample from the model's probability
distribution can still be misleading. Building upon the concept of
LLM-as-a-judge, we introduce a novel framework for rigorously evaluating the
reliability of LLM judgments, leveraging McDonald's omega. We evaluate the
reliability of LLMs when judging the outputs of other LLMs on standard
single-turn and multi-turn benchmarks, simultaneously investigating the impact
of temperature on reliability. By analyzing these results, we demonstrate the
limitations of fixed randomness and the importance of considering multiple
samples, which we show has significant implications for downstream
applications. Our findings highlight the need for a nuanced understanding of
LLM reliability and the potential risks associated with over-reliance on
single-shot evaluations. This work provides a crucial step towards building
more trustworthy and reliable LLM-based systems and applications.",2024-12-17,"Kayla Schroeder, Zach Wood-Doughty",http://arxiv.org/pdf/2412.12509v2,cs.CL
DocFusion: A Unified Framework for Document Parsing Tasks,"Document parsing is essential for analyzing complex document structures and
extracting fine-grained information, supporting numerous downstream
applications. However, existing methods often require integrating multiple
independent models to handle various parsing tasks, leading to high complexity
and maintenance overhead. To address this, we propose DocFusion, a lightweight
generative model with only 0.28B parameters. It unifies task representations
and achieves collaborative training through an improved objective function.
Experiments reveal and leverage the mutually beneficial interaction among
recognition tasks, and integrating recognition data significantly enhances
detection performance. The final results demonstrate that DocFusion achieves
state-of-the-art (SOTA) performance across four key tasks.",2024-12-17,"Mingxu Chai, Ziyu Shen, Chong Zhang, Yue Zhang, Xiao Wang, Shihan Dou, Jihua Kang, Jiazheng Zhang, Qi Zhang",http://arxiv.org/pdf/2412.12505v2,cs.CL
Unleashing the Potential of Model Bias for Generalized Category Discovery,"Generalized Category Discovery is a significant and complex task that aims to
identify both known and undefined novel categories from a set of unlabeled
data, leveraging another labeled dataset containing only known categories. The
primary challenges stem from model bias induced by pre-training on only known
categories and the lack of precise supervision for novel ones, leading to
category bias towards known categories and category confusion among different
novel categories, which hinders models' ability to identify novel categories
effectively. To address these challenges, we propose a novel framework named
Self-Debiasing Calibration (SDC). Unlike prior methods that regard model bias
towards known categories as an obstacle to novel category identification, SDC
provides a novel insight into unleashing the potential of the bias to
facilitate novel category learning. Specifically, the output of the biased
model serves two key purposes. First, it provides an accurate modeling of
category bias, which can be utilized to measure the degree of bias and debias
the output of the current training model. Second, it offers valuable insights
for distinguishing different novel categories by transferring knowledge between
similar categories. Based on these insights, SDC dynamically adjusts the output
logits of the current training model using the output of the biased model. This
approach produces less biased logits to effectively address the issue of
category bias towards known categories, and generates more accurate pseudo
labels for unlabeled data, thereby mitigating category confusion for novel
categories. Experiments on three benchmark datasets show that SDC outperforms
SOTA methods, especially in the identification of novel categories. Our code
and data are available at \url{https://github.com/Lackel/SDC}.",2024-12-17,"Wenbin An, Haonan Lin, Jiahao Nie, Feng Tian, Wenkai Shi, Yaqiang Wu, Qianying Wang, Ping Chen",http://arxiv.org/pdf/2412.12501v1,cs.CL
Beyond Data Quantity: Key Factors Driving Performance in Multilingual Language Models,"Multilingual language models (MLLMs) are crucial for handling text across
various languages, yet they often show performance disparities due to
differences in resource availability and linguistic characteristics. While the
impact of pre-train data percentage and model size on performance is
well-known, our study reveals additional critical factors that significantly
influence MLLM effectiveness. Analyzing a wide range of features, including
geographical, linguistic, and resource-related aspects, we focus on the SIB-200
dataset for classification and the Flores-200 dataset for machine translation,
using regression models and SHAP values across 204 languages. Our findings
identify token similarity and country similarity as pivotal factors, alongside
pre-train data and model size, in enhancing model performance. Token similarity
facilitates cross-lingual transfer, while country similarity highlights the
importance of shared cultural and linguistic contexts. These insights offer
valuable guidance for developing more equitable and effective multilingual
language models, particularly for underrepresented languages.",2024-12-17,"Sina Bagheri Nezhad, Ameeta Agrawal, Rhitabrat Pokharel",http://arxiv.org/pdf/2412.12500v1,cs.CL
Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models,"With the rapid advancement of Large Language Models (LLMs), significant
safety concerns have emerged. Fundamentally, the safety of large language
models is closely linked to the accuracy, comprehensiveness, and clarity of
their understanding of safety knowledge, particularly in domains such as law,
policy and ethics. This factuality ability is crucial in determining whether
these models can be deployed and applied safely and compliantly within specific
regions. To address these challenges and better evaluate the factuality ability
of LLMs to answer short questions, we introduce the Chinese SafetyQA benchmark.
Chinese SafetyQA has several properties (i.e., Chinese, Diverse, High-quality,
Static, Easy-to-evaluate, Safety-related, Harmless). Based on Chinese SafetyQA,
we perform a comprehensive evaluation on the factuality abilities of existing
LLMs and analyze how these capabilities relate to LLM abilities, e.g., RAG
ability and robustness against attacks.",2024-12-17,"Yingshui Tan, Boren Zheng, Baihui Zheng, Kerui Cao, Huiyun Jing, Jincheng Wei, Jiaheng Liu, Yancheng He, Wenbo Su, Xiangyong Zhu, Bo Zheng, Kaifu Zhang",http://arxiv.org/pdf/2412.15265v2,cs.CL
LinguaLIFT: An Effective Two-stage Instruction Tuning Framework for Low-Resource Language Reasoning,"Large language models (LLMs) have exhibited impressive multilingual reasoning
capabilities, driven by extensive multilingual pre-training corpora and
instruction fine-tuning data. However, a performance gap exists between high-
and low-resource language reasoning tasks due to the language imbalance in the
pre-training corpus, which is exacerbated by evaluation bias in existing
reasoning benchmarks lacking low-resource language coverage. To alleviate this
issue, we propose LinguaLIFT, a two-stage instruction tuning framework for
advancing low-resource language reasoning. LinguaLIFT employs a language
alignment layer to capture multilingual alignment in a code-switched tuning way
without requiring multilingual instruction or parallel data, thereby
transferring the cross-lingual reasoning capabilities to low-resource languages
through English-only instruction tuning data. To comprehensively evaluate the
multilingual reasoning capabilities, we introduce the Multilingual Math World
Problem (MMWP) benchmark, which spans 21 low-resource, 17 medium-resource, and
10 high-resource languages. Experimental results show that LinguaLIFT
outperforms several competitive baselines across MMWP and four widely used
benchmarks.",2024-12-17,"Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang",http://arxiv.org/pdf/2412.12499v2,cs.CL
NLSR: Neuron-Level Safety Realignment of Large Language Models Against Harmful Fine-Tuning,"The emergence of finetuning-as-a-service has revealed a new vulnerability in
large language models (LLMs). A mere handful of malicious data uploaded by
users can subtly manipulate the finetuning process, resulting in an
alignment-broken model. Existing methods to counteract fine-tuning attacks
typically require substantial computational resources. Even with
parameter-efficient techniques like LoRA, gradient updates remain essential. To
address these challenges, we propose \textbf{N}euron-\textbf{L}evel
\textbf{S}afety \textbf{R}ealignment (\textbf{NLSR}), a training-free framework
that restores the safety of LLMs based on the similarity difference of
safety-critical neurons before and after fine-tuning. The core of our framework
is first to construct a safety reference model from an initially aligned model
to amplify safety-related features in neurons. We then utilize this reference
model to identify safety-critical neurons, which we prepare as patches.
Finally, we selectively restore only those neurons that exhibit significant
similarity differences by transplanting these prepared patches, thereby
minimally altering the fine-tuned model. Extensive experiments demonstrate
significant safety enhancements in fine-tuned models across multiple downstream
tasks, while greatly maintaining task-level accuracy. Our findings suggest
regions of some safety-critical neurons show noticeable differences after
fine-tuning, which can be effectively corrected by transplanting neurons from
the reference model without requiring additional training. The code will be
available at \url{https://github.com/xinykou/NLSR}",2024-12-17,"Xin Yi, Shunfan Zheng, Linlin Wang, Gerard de Melo, Xiaoling Wang, Liang He",http://arxiv.org/pdf/2412.12497v1,cs.CL
Boosting Long-Context Management via Query-Guided Activation Refilling,"Processing long contexts poses a significant challenge for large language
models (LLMs) due to their inherent context-window limitations and the
computational burden of extensive key-value (KV) activations, which severely
impact efficiency. For information-seeking tasks, full context perception is
often unnecessary, as a query's information needs can dynamically range from
localized details to a global perspective, depending on its complexity.
However, existing methods struggle to adapt effectively to these dynamic
information needs.
  In the paper, we propose a method for processing long-context
information-seeking tasks via query-guided Activation Refilling (ACRE). ACRE
constructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache
compactly captures global information, and the layer-2 (L2) cache provides
detailed and localized information. ACRE establishes a proxying relationship
between the two caches, allowing the input query to attend to the L1 cache and
dynamically refill it with relevant entries from the L2 cache. This mechanism
integrates global understanding with query-specific local details, thus
improving answer decoding. Experiments on a variety of long-context
information-seeking datasets demonstrate ACRE's effectiveness, achieving
improvements in both performance and efficiency.",2024-12-17,"Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian",http://arxiv.org/pdf/2412.12486v3,cs.CL
Human-in-the-Loop Generation of Adversarial Texts: A Case Study on Tibetan Script,"DNN-based language models perform excellently on various tasks, but even SOTA
LLMs are susceptible to textual adversarial attacks. Adversarial texts play
crucial roles in multiple subfields of NLP. However, current research has the
following issues. (1) Most textual adversarial attack methods target
rich-resourced languages. How do we generate adversarial texts for less-studied
languages? (2) Most textual adversarial attack methods are prone to generating
invalid or ambiguous adversarial texts. How do we construct high-quality
adversarial robustness benchmarks? (3) New language models may be immune to
part of previously generated adversarial texts. How do we update adversarial
robustness benchmarks? To address the above issues, we introduce HITL-GAT, a
system based on a general approach to human-in-the-loop generation of
adversarial texts. HITL-GAT contains four stages in one pipeline: victim model
construction, adversarial example generation, high-quality benchmark
construction, and adversarial robustness evaluation. Additionally, we utilize
HITL-GAT to make a case study on Tibetan script which can be a reference for
the adversarial research of other less-studied languages.",2024-12-17,"Xi Cao, Yuan Sun, Jiajun Li, Quzong Gesang, Nuo Qun, Tashi Nyima",http://arxiv.org/pdf/2412.12478v3,cs.CL
V-SQL: A View-based Two-stage Text-to-SQL Framework,"The text-to-SQL task aims to convert natural language into Structured Query
Language (SQL) without bias. Recently, text-to-SQL methods based on large
language models (LLMs) have garnered significant attention. The core of
mainstream text-to-SQL frameworks is schema linking, which aligns user queries
with relevant tables and columns in the database. Previous methods focused on
schema linking while neglecting to enhance LLMs' understanding of database
schema. The complex coupling relationships between tables in the database
constrain the SQL generation capabilities of LLMs. To tackle this issue, this
paper proposes a simple yet effective strategy called view-based schema. This
strategy aids LLMs in understanding the database schema by decoupling tightly
coupled tables into low-coupling views. We then introduce V-SQL, a view-based
two-stage text-to-SQL framework. V-SQL involves the view-based schema strategy
to enhance LLMs' understanding of database schema. Results on the authoritative
datasets Bird indicate that V-SQL achieves competitive performance compared to
existing state-of-the-art methods.",2024-12-17,"Zeshun You, Jiebin Yao, Dong Cheng, Zhiwei Wen, Zhiliang Lu, Xianyi Shen",http://arxiv.org/pdf/2502.15686v1,cs.CL
RareAgents: Advancing Rare Disease Care through LLM-Empowered Multi-disciplinary Team,"Rare diseases, despite their low individual incidence, collectively impact
around 300 million people worldwide due to the vast number of diseases. The
involvement of multiple organs and systems, and the shortage of specialized
doctors with relevant experience make diagnosing and treating rare diseases
more challenging than common diseases. Recently, agents powered by large
language models (LLMs) have demonstrated notable applications across various
domains. In the medical field, some agent methods have outperformed direct
prompts in question-answering tasks from medical examinations. However, current
agent frameworks are not well-adapted to real-world clinical scenarios,
especially those involving the complex demands of rare diseases. To bridge this
gap, we introduce RareAgents, the first LLM-driven multi-disciplinary team
framework designed specifically for the complex clinical context of rare
diseases. RareAgents integrates advanced Multidisciplinary Team (MDT)
coordination, memory mechanisms, and medical tools utilization, leveraging
Llama-3.1-8B/70B as the base model. Experimental results show that RareAgents
outperforms state-of-the-art domain-specific models, GPT-4o, and current agent
frameworks in differential diagnosis and medication recommendation for rare
diseases. Furthermore, we contribute a novel rare disease dataset,
MIMIC-IV-Ext-Rare, to support further advancements in this field.",2024-12-17,"Xuanzhong Chen, Ye Jin, Xiaohao Mao, Lun Wang, Shuyang Zhang, Ting Chen",http://arxiv.org/pdf/2412.12475v2,cs.CL
Knowledge Boundary of Large Language Models: A Survey,"Although large language models (LLMs) store vast amount of knowledge in their
parameters, they still have limitations in the memorization and utilization of
certain knowledge, leading to undesired behaviors such as generating untruthful
and inaccurate responses. This highlights the critical need to understand the
knowledge boundary of LLMs, a concept that remains inadequately defined in
existing research. In this survey, we propose a comprehensive definition of the
LLM knowledge boundary and introduce a formalized taxonomy categorizing
knowledge into four distinct types. Using this foundation, we systematically
review the field through three key lenses: the motivation for studying LLM
knowledge boundaries, methods for identifying these boundaries, and strategies
for mitigating the challenges they present. Finally, we discuss open challenges
and potential research directions in this area. We aim for this survey to offer
the community a comprehensive overview, facilitate access to key issues, and
inspire further advancements in LLM knowledge research.",2024-12-17,"Moxin Li, Yong Zhao, Yang Deng, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, Tat-Seng Chua",http://arxiv.org/pdf/2412.12472v1,cs.CL
ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports,"The increasing adoption of AI-generated radiology reports necessitates robust
methods for detecting hallucinations--false or unfounded statements that could
impact patient care. We present ReXTrust, a novel framework for fine-grained
hallucination detection in AI-generated radiology reports. Our approach
leverages sequences of hidden states from large vision-language models to
produce finding-level hallucination risk scores. We evaluate ReXTrust on a
subset of the MIMIC-CXR dataset and demonstrate superior performance compared
to existing approaches, achieving an AUROC of 0.8751 across all findings and
0.8963 on clinically significant findings. Our results show that white-box
approaches leveraging model hidden states can provide reliable hallucination
detection for medical AI systems, potentially improving the safety and
reliability of automated radiology reporting.",2024-12-17,"Romain Hardy, Sung Eun Kim, Du Hyun Ro, Pranav Rajpurkar",http://arxiv.org/pdf/2412.15264v3,cs.CL
Core Context Aware Attention for Long Context Language Modeling,"Transformer-based Large Language Models (LLMs) have exhibited remarkable
success in various natural language processing tasks primarily attributed to
self-attention mechanism, which requires a token to consider all preceding
tokens as its context to compute the attention score. However, when the context
length L becomes very large (e.g., 32K), more redundant context information
will be included w.r.t. any tokens, making the self-attention suffer from two
main limitations: 1) The computational and memory complexity scales
quadratically w.r.t. L; 2) The presence of redundant context information may
hamper the model to capture dependencies among crucial tokens, which may
degrade the representation performance. In this paper, we propose a
plug-and-play Core Context Aware (CCA) Attention for efficient long-range
context modeling, which consists of two components: 1) Globality-pooling
attention that divides input tokens into groups and then dynamically merges
tokens within each group into one core token based on their significance; 2)
Locality-preserved attention that incorporates neighboring tokens into the
attention calculation. The two complementary attentions will then be fused to
the final attention, maintaining comprehensive modeling ability as the full
self-attention. In this way, the core context information w.r.t. a given token
will be automatically focused and strengthened, while the context information
in redundant groups will be diminished during the learning process. As a
result, the computational and memory complexity will be significantly reduced.
More importantly, the CCA-Attention can improve the long-context modeling
ability by diminishing the redundant context information. Extensive
experimental results demonstrate that our CCA-Attention significantly
outperforms state-of-the-art models in terms of computational efficiency and
long-context modeling ability.",2024-12-17,"Yaofo Chen, Zeng You, Shuhai Zhang, Haokun Li, Yirui Li, Yaowei Wang, Mingkui Tan",http://arxiv.org/pdf/2412.12465v1,cs.CL
LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework,"Topic modeling is widely used for uncovering thematic structures within text
corpora, yet traditional models often struggle with specificity and coherence
in domain-focused applications. Guided approaches, such as SeededLDA and CorEx,
incorporate user-provided seed words to improve relevance but remain
labor-intensive and static. Large language models (LLMs) offer potential for
dynamic topic refinement and discovery, yet their application often incurs high
API costs. To address these challenges, we propose the LLM-assisted Iterative
Topic Augmentation framework (LITA), an LLM-assisted approach that integrates
user-provided seeds with embedding-based clustering and iterative refinement.
LITA identifies a small number of ambiguous documents and employs an LLM to
reassign them to existing or new topics, minimizing API costs while enhancing
topic quality. Experiments on two datasets across topic quality and clustering
performance metrics demonstrate that LITA outperforms five baseline models,
including LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an
efficient and adaptable framework for advancing topic modeling and text
clustering.",2024-12-17,"Chia-Hsuan Chang, Jui-Tse Tsai, Yi-Hang Tsai, San-Yih Hwang",http://arxiv.org/pdf/2412.12459v2,cs.CL
"Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks","With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)
Data (e.g., citation networks, recommendation systems, social networks, and
ai4science), the integration of Graph Neural Networks (GNNs) and Large Language
Models (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as
collaborators, LLM as predictor) has emerged as a promising technological
paradigm. The core of this new graph learning paradigm lies in the synergistic
combination of GNNs' ability to capture complex structural relationships and
LLMs' proficiency in understanding informative contexts from the rich textual
descriptions of graphs. Therefore, we can leverage graph description texts with
rich semantic context to fundamentally enhance Data quality, thereby improving
the representational capacity of model-centric approaches in line with
data-centric machine learning principles. By leveraging the strengths of these
distinct neural network architectures, this integrated approach addresses a
wide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph
question answering), particularly in complex industrial scenarios (e.g.,
supervised, few-shot, and zero-shot settings). In other words, we can treat
text as a medium to enable cross-domain generalization of graph learning Model,
allowing a single graph model to effectively handle the diversity of downstream
graph-based Task across different data domains. This work serves as a
foundational reference for researchers and practitioners looking to advance
graph learning methodologies in the rapidly evolving landscape of LLM. We
consistently maintain the related open-source materials at
\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.",2024-12-17,"Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang",http://arxiv.org/pdf/2412.12456v1,cs.CL
PERC: Plan-As-Query Example Retrieval for Underrepresented Code Generation,"Code generation with large language models has shown significant promise,
especially when employing retrieval-augmented generation (RAG) with few-shot
examples. However, selecting effective examples that enhance generation quality
remains a challenging task, particularly when the target programming language
(PL) is underrepresented. In this study, we present two key findings: (1)
retrieving examples whose presented algorithmic plans can be referenced for
generating the desired behavior significantly improves generation accuracy, and
(2) converting code into pseudocode effectively captures such algorithmic
plans, enhancing retrieval quality even when the source and the target PLs are
different. Based on these findings, we propose Plan-as-query Example Retrieval
for few-shot prompting in Code generation (PERC), a novel framework that
utilizes algorithmic plans to identify and retrieve effective examples. We
validate the effectiveness of PERC through extensive experiments on the
CodeContests, HumanEval and MultiPL-E benchmarks: PERC consistently outperforms
the state-of-the-art RAG methods in code generation, both when the source and
target programming languages match or differ, highlighting its adaptability and
robustness in diverse coding environments.",2024-12-17,"Jaeseok Yoo, Hojae Han, Youngwon Lee, Jaejin Kim, Seung-won Hwang",http://arxiv.org/pdf/2412.12447v2,cs.CL
Persona-SQ: A Personalized Suggested Question Generation Framework For Real-world Documents,"Suggested questions (SQs) provide an effective initial interface for users to
engage with their documents in AI-powered reading applications. In practical
reading sessions, users have diverse backgrounds and reading goals, yet current
SQ features typically ignore such user information, resulting in homogeneous or
ineffective questions. We introduce a pipeline that generates personalized SQs
by incorporating reader profiles (professions and reading goals) and
demonstrate its utility in two ways: 1) as an improved SQ generation pipeline
that produces higher quality and more diverse questions compared to current
baselines, and 2) as a data generator to fine-tune extremely small models that
perform competitively with much larger models on SQ generation. Our approach
can not only serve as a drop-in replacement in current SQ systems to
immediately improve their performance but also help develop on-device SQ models
that can run locally to deliver fast and private SQ experience.",2024-12-17,"Zihao Lin, Zichao Wang, Yuanting Pan, Varun Manjunatha, Ryan Rossi, Angela Lau, Lifu Huang, Tong Sun",http://arxiv.org/pdf/2412.12445v2,cs.CL
Refining Dimensions for Improving Clustering-based Cross-lingual Topic Models,"Recent works in clustering-based topic models perform well in monolingual
topic identification by introducing a pipeline to cluster the contextualized
representations. However, the pipeline is suboptimal in identifying topics
across languages due to the presence of language-dependent dimensions (LDDs)
generated by multilingual language models. To address this issue, we introduce
a novel, SVD-based dimension refinement component into the pipeline of the
clustering-based topic model. This component effectively neutralizes the
negative impact of LDDs, enabling the model to accurately identify topics
across languages. Our experiments on three datasets demonstrate that the
updated pipeline with the dimension refinement component generally outperforms
other state-of-the-art cross-lingual topic models.",2024-12-17,"Chia-Hsuan Chang, Tien-Yuan Huang, Yi-Hang Tsai, Chia-Ming Chang, San-Yih Hwang",http://arxiv.org/pdf/2412.12433v1,cs.CL
Assessing the Limitations of Large Language Models in Clinical Fact Decomposition,"Verifying factual claims is critical for using large language models (LLMs)
in healthcare. Recent work has proposed fact decomposition, which uses LLMs to
rewrite source text into concise sentences conveying a single piece of
information, as an approach for fine-grained fact verification. Clinical
documentation poses unique challenges for fact decomposition due to dense
terminology and diverse note types. To explore these challenges, we present
FactEHR, a dataset consisting of full document fact decompositions for 2,168
clinical notes spanning four types from three hospital systems. Our evaluation,
including review by clinicians, highlights significant variability in the
quality of fact decomposition for four commonly used LLMs, with some LLMs
generating 2.6x more facts per sentence than others. The results underscore the
need for better LLM capabilities to support factual verification in clinical
text. To facilitate future research in this direction, we plan to release our
code at \url{https://github.com/som-shahlab/factehr}.",2024-12-17,"Monica Munnangi, Akshay Swaminathan, Jason Alan Fries, Jenelle Jindal, Sanjana Narayanan, Ivan Lopez, Lucia Tu, Philip Chung, Jesutofunmi A. Omiye, Mehr Kashyap, Nigam Shah",http://arxiv.org/pdf/2412.12422v1,cs.CL
"Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments","Large Language Models (LLMs) have shown remarkable performance across various
tasks, yet significant disparities remain for non-English languages, and
especially native African languages. This paper addresses these disparities by
creating approximately 1 million human-translated words of new benchmark data
in 8 low-resource African languages, covering a population of over 160 million
speakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho
(Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of
Winogrande and three sections of MMLU: college medicine, clinical knowledge,
and virology. Using the translated benchmarks, we report previously unknown
performance gaps between state-of-the-art (SOTA) LLMs in English and African
languages. Finally, using results from over 400 fine-tuned models, we explore
several methods to reduce the LLM performance gap, including high-quality
dataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and
cultural appropriateness adjustments. Key findings include average mono-lingual
improvements of 5.6% with fine-tuning (with 5.4% average mono-lingual
improvements when using high-quality data over low-quality data), 2.9% average
gains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost
on culturally appropriate questions. The publicly available benchmarks,
translations, and code from this study support further research and development
aimed at creating more inclusive and effective language technologies.",2024-12-16,"Tuka Alhanai, Adam Kasumovic, Mohammad Ghassemi, Aven Zitzelberger, Jessica Lundin, Guillaume Chabot-Couture",http://arxiv.org/pdf/2412.12417v1,cs.CL
Efficient Scaling of Diffusion Transformers for Text-to-Image Generation,"We empirically study the scaling properties of various Diffusion Transformers
(DiTs) for text-to-image generation by performing extensive and rigorous
ablations, including training scaled DiTs ranging from 0.3B upto 8B parameters
on datasets up to 600M images. We find that U-ViT, a pure self-attention based
DiT model provides a simpler design and scales more effectively in comparison
with cross-attention based DiT variants, which allows straightforward expansion
for extra conditions and other modalities. We identify a 2.3B U-ViT model can
get better performance than SDXL UNet and other DiT variants in controlled
setting. On the data scaling side, we investigate how increasing dataset size
and enhanced long caption improve the text-image alignment performance and the
learning efficiency.",2024-12-16,"Hao Li, Shamit Lal, Zhiheng Li, Yusheng Xie, Ying Wang, Yang Zou, Orchid Majumder, R. Manmatha, Zhuowen Tu, Stefano Ermon, Stefano Soatto, Ashwin Swaminathan",http://arxiv.org/pdf/2412.12391v1,cs.CL
Interpretable LLM-based Table Question Answering,"Interpretability for Table Question Answering (Table QA) is critical,
particularly in high-stakes industries like finance or healthcare. Although
recent approaches using Large Language Models (LLMs) have significantly
improved Table QA performance, their explanations for how the answers are
generated are ambiguous. To fill this gap, we introduce Plan-of-SQLs (POS), an
interpretable Table QA approach designed to improve users' understanding of
model decision-making. Through qualitative and quantitative evaluations with
human and LLM judges, we show that: First, POS is the highest-quality
explanation method, helps human users understand model behaviors, and
facilitates model prediction verification. Second, when evaluated on popular
and standard Table QA datasets (TabFact, WikiTQ, and FetaQA), POS achieves QA
accuracy that is competitive with or superior to existing methods, while also
offering greater efficiency-requiring significantly fewer LLM calls and table
database queries-and robust performance on large-sized tables. Finally, we
observe high agreement (up to 90%) between LLMs and human users when making
decisions based on the same explanations, suggesting that LLMs could serve as
an effective proxy for humans in evaluating explanations. This finding enables
faster, more affordable evaluation of AI explanations-possibly accelerating
trustworthy AI research while maintaining reliable judgments on
interpretability.",2024-12-16,"Giang Nguyen, Ivan Brugere, Shubham Sharma, Sanjay Kariyappa, Anh Totti Nguyen, Freddy Lecue",http://arxiv.org/pdf/2412.12386v2,cs.CL
How Different AI Chatbots Behave? Benchmarking Large Language Models in Behavioral Economics Games,"The deployment of large language models (LLMs) in diverse applications
requires a thorough understanding of their decision-making strategies and
behavioral patterns. As a supplement to a recent study on the behavioral Turing
test, this paper presents a comprehensive analysis of five leading LLM-based
chatbot families as they navigate a series of behavioral economics games. By
benchmarking these AI chatbots, we aim to uncover and document both common and
distinct behavioral patterns across a range of scenarios. The findings provide
valuable insights into the strategic preferences of each LLM, highlighting
potential implications for their deployment in critical decision-making roles.",2024-12-16,"Yutong Xie, Yiyao Liu, Zhuang Ma, Lin Shi, Xiyuan Wang, Walter Yuan, Matthew O. Jackson, Qiaozhu Mei",http://arxiv.org/pdf/2412.12362v1,cs.CL
LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering,"Multimodal Large Language Models (MLLMs) have significantly advanced visual
tasks by integrating visual representations into large language models (LLMs).
The textual modality, inherited from LLMs, equips MLLMs with abilities like
instruction following and in-context learning. In contrast, the visual modality
enhances performance in downstream tasks by leveraging rich semantic content,
spatial information, and grounding capabilities. These intrinsic modalities
work synergistically across various visual tasks. Our research initially
reveals a persistent imbalance between these modalities, with text often
dominating output generation during visual instruction tuning. This imbalance
occurs when using both full fine-tuning and parameter-efficient fine-tuning
(PEFT) methods. We then found that re-balancing these modalities can
significantly reduce the number of trainable parameters required, inspiring a
direction for further optimizing visual instruction tuning. We introduce
Modality Linear Representation-Steering (MoReS) to achieve the goal. MoReS
effectively re-balances the intrinsic modalities throughout the model, where
the key idea is to steer visual representations through linear transformations
in the visual subspace across each model layer. To validate our solution, we
composed LLaVA Steering, a suite of models integrated with the proposed MoReS
method. Evaluation results show that the composed LLaVA Steering models
require, on average, 500 times fewer trainable parameters than LoRA needs while
still achieving comparable performance across three visual benchmarks and eight
visual question-answering tasks. Last, we present the LLaVA Steering Factory,
an in-house developed platform that enables researchers to quickly customize
various MLLMs with component-based architecture for seamlessly integrating
state-of-the-art models, and evaluate their intrinsic modality imbalance.",2024-12-16,"Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma",http://arxiv.org/pdf/2412.12359v2,cs.CL
BioRAGent: A Retrieval-Augmented Generation System for Showcasing Generative Query Expansion and Domain-Specific Search for Scientific Q&A,"We present BioRAGent, an interactive web-based retrieval-augmented generation
(RAG) system for biomedical question answering. The system uses large language
models (LLMs) for query expansion, snippet extraction, and answer generation
while maintaining transparency through citation links to the source documents
and displaying generated queries for further editing. Building on our
successful participation in the BioASQ 2024 challenge, we demonstrate how
few-shot learning with LLMs can be effectively applied for a professional
search setting. The system supports both direct short paragraph style responses
and responses with inline citations. Our demo is available online, and the
source code is publicly accessible through GitHub.",2024-12-16,"Samy Ateia, Udo Kruschwitz",http://arxiv.org/pdf/2412.12358v1,cs.CL
PROPOE 2: Avanços na Síntese Computacional de Poemas Baseados em Prosa Literária Brasileira,"The computational generation of poems is a complex task, which involves
several sound, prosodic and rhythmic resources. In this work we present PROPOE
2, with the extension of structural and rhythmic possibilities compared to the
original system, generating poems from metered sentences extracted from the
prose of Brazilian literature, with multiple rhythmic assembly criteria. These
advances allow for a more coherent exploration of rhythms and sound effects for
the poem. Results of poems generated by the system are demonstrated, with
variations in parameters to exemplify generation and evaluation using various
criteria.
  A gera\c{c}\~ao computacional de poemas \'e uma tarefa complexa, que envolve
diversos recursos sonoros, pros\'odicos e r\'itmicos. Neste trabalho
apresentamos PROPOE 2, com a amplia\c{c}\~ao de possibilidades estruturais e
r\'itmicas em rela\c{c}\~ao ao sistema original, gerando poemas a partir de
senten\c{c}as metrificadas extra\'idas da prosa da literatura brasileira, com
m\'ultiplos crit\'erios r\'itmicos de montagem. Esses avan\c{c}os permitem uma
explora\c{c}\~ao mais coerente de ritmos e efeitos sonoros para o poema.
Resultados de poemas gerados pelo sistema s\~ao demonstrados, com
varia\c{c}\~oes de par\^ametros para exemplificar a gera\c{c}\~ao e a
avalia\c{c}\~ao pelos variados crit\'erios.",2024-12-16,"Felipe José D. Sousa, Sarah P. Cerqueira, João Queiroz, Angelo Loula",http://arxiv.org/pdf/2412.15263v1,cs.CL
Krony-PT: GPT2 compressed with Kronecker Products,"We introduce Krony-PT, a compression technique of GPT2
\citep{radford2019language} based on Kronecker Products. We specifically target
the MLP layers of each transformer layer, and systematically compress the feed
forward layer matrices to various degrees. We introduce a modified Van Loan
decomposition to initialize the new factors, and also introduce a new
pruning-based initialization trick. Our method compresses the original 124M
parameter GPT2 to various smaller models, with 80M being the smallest, and 96M
being the largest compressed model. Our 81M model variant outperforms
distilgpt2 on next-token prediction on all standard language modeling datasets,
and shows competitive scores or performs on par with other Kronecker Products
based compressed models of GPT2 that are significantly higher in size.",2024-12-16,"M. Ayoub Ben Ayad, Jelena Mitrovic, Michael Granitzer",http://arxiv.org/pdf/2412.12351v1,cs.CL
Advanced ingestion process powered by LLM parsing for RAG system,"Retrieval Augmented Generation (RAG) systems struggle with processing
multimodal documents of varying structural complexity. This paper introduces a
novel multi-strategy parsing approach using LLM-powered OCR to extract content
from diverse document types, including presentations and high text density
files both scanned or not. The methodology employs a node-based extraction
technique that creates relationships between different information types and
generates context-aware metadata. By implementing a Multimodal Assembler Agent
and a flexible embedding strategy, the system enhances document comprehension
and retrieval capabilities. Experimental evaluations across multiple knowledge
bases demonstrate the approach's effectiveness, showing improvements in answer
relevancy and information faithfulness.",2024-12-16,"Arnau Perez, Xavier Vizcaino",http://arxiv.org/pdf/2412.15262v1,cs.CL
Investigating the Feasibility of Mitigating Potential Copyright Infringement via Large Language Model Unlearning,"Pre-trained Large Language Models (LLMs) have demonstrated remarkable
capabilities but also pose risks by learning and generating copyrighted
material, leading to significant legal and ethical concerns. In a potential
real-world scenario, model owners may need to continuously address copyright
infringement in order to address requests for content removal that emerge at
different time points. One potential way of addressing this is via sequential
unlearning, where copyrighted content is removed sequentially as new requests
arise. Despite its practical relevance, sequential unlearning in the context of
copyright infringement has not been rigorously explored in existing literature.
To address this gap, we propose Stable Sequential Unlearning (SSU), a novel
framework designed to unlearn copyrighted content from LLMs over multiple time
steps. Our approach works by identifying and removing specific weight updates
in the model's parameters that correspond to copyrighted content using task
vectors. We improve unlearning efficacy by introducing random labeling loss and
ensuring the model retains its general-purpose knowledge by adjusting targeted
parameters with gradient-based weight saliency. Extensive experimental results
show that SSU sometimes achieves an effective trade-off between unlearning
efficacy and general-purpose language abilities, outperforming existing
baselines, but it's not a cure-all for unlearning copyrighted material.",2024-12-16,Guangyao Dou,http://arxiv.org/pdf/2412.18621v1,cs.CL
RAG Playground: A Framework for Systematic Evaluation of Retrieval Strategies and Prompt Engineering in RAG Systems,"We present RAG Playground, an open-source framework for systematic evaluation
of Retrieval-Augmented Generation (RAG) systems. The framework implements and
compares three retrieval approaches: naive vector search, reranking, and hybrid
vector-keyword search, combined with ReAct agents using different prompting
strategies. We introduce a comprehensive evaluation framework with novel
metrics and provide empirical results comparing different language models
(Llama 3.1 and Qwen 2.5) across various retrieval configurations. Our
experiments demonstrate significant performance improvements through hybrid
search methods and structured self-evaluation prompting, achieving up to 72.7%
pass rate on our multi-metric evaluation framework. The results also highlight
the importance of prompt engineering in RAG systems, with our custom-prompted
agents showing consistent improvements in retrieval accuracy and response
quality.",2024-12-16,"Ioannis Papadimitriou, Ilias Gialampoukidis, Stefanos Vrochidis, Ioannis, Kompatsiaris",http://arxiv.org/pdf/2412.12322v1,cs.CL
Graph-Guided Textual Explanation Generation Framework,"Natural language explanations (NLEs) are commonly used to provide plausible
free-text explanations of a model's reasoning about its predictions. However,
recent work has questioned their faithfulness, as they may not accurately
reflect the model's internal reasoning process regarding its predicted answer.
In contrast, highlight explanations--input fragments critical for the model's
predicted answers--exhibit measurable faithfulness. Building on this
foundation, we propose G-Tex, a Graph-Guided Textual Explanation Generation
framework designed to enhance the faithfulness of NLEs. Specifically, highlight
explanations are first extracted as faithful cues reflecting the model's
reasoning logic toward answer prediction. They are subsequently encoded through
a graph neural network layer to guide the NLE generation, which aligns the
generated explanations with the model's underlying reasoning toward the
predicted answer. Experiments on T5 and BART using three reasoning datasets
show that G-Tex improves NLE faithfulness by up to 12.18% compared to baseline
methods. Additionally, G-Tex generates NLEs with greater semantic and lexical
similarity to human-written ones. Human evaluations show that G-Tex can
decrease redundant content and enhance the overall quality of NLEs. Our work
presents a novel method for explicitly guiding NLE generation to enhance
faithfulness, serving as a foundation for addressing broader criteria in NLE
and generated text.",2024-12-16,"Shuzhou Yuan, Jingyi Sun, Ran Zhang, Michael Färber, Steffen Eger, Pepa Atanasova, Isabelle Augenstein",http://arxiv.org/pdf/2412.12318v3,cs.CL
Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion,"This paper addresses the critical need for democratizing large language
models (LLM) in the Arab world, a region that has seen slower progress in
developing models comparable to state-of-the-art offerings like GPT-4 or
ChatGPT 3.5, due to a predominant focus on mainstream languages (e.g., English
and Chinese). One practical objective for an Arabic LLM is to utilize an
Arabic-specific vocabulary for the tokenizer that could speed up decoding.
However, using a different vocabulary often leads to a degradation of learned
knowledge since many words are initially out-of-vocabulary (OOV) when training
starts. Inspired by the vocabulary learning during Second Language (Arabic)
Acquisition for humans, the released AraLLaMA employs progressive vocabulary
expansion, which is implemented by a modified BPE algorithm that progressively
extends the Arabic subwords in its dynamic vocabulary during training, thereby
balancing the OOV ratio at every stage. The ablation study demonstrated the
effectiveness of Progressive Vocabulary Expansion. Moreover, AraLLaMA achieves
decent performance comparable to the best Arabic LLMs across a variety of
Arabic benchmarks. Models, training data, benchmarks, and codes will be all
open-sourced.",2024-12-16,"Jianqing Zhu, Huang Huang, Zhihang Lin, Juhao Liang, Zhengyang Tang, Khalid Almubarak, Abdulmohsen Alharthik, Bang An, Juncai He, Xiangbo Wu, Fei Yu, Junying Chen, Zhuoheng Ma, Yuhao Du, He Zhang, Emad A. Alghamdi, Lian Zhang, Ruoyu Sun, Haizhou Li, Benyou Wang, Jinchao Xu",http://arxiv.org/pdf/2412.12310v1,cs.CL
Unanswerability Evaluation for Retrieval Augmented Generation,"Existing evaluation frameworks for retrieval-augmented generation (RAG)
systems focus on answerable queries, but they overlook the importance of
appropriately rejecting unanswerable requests. In this paper, we introduce
UAEval4RAG, a framework designed to evaluate whether RAG systems can handle
unanswerable queries effectively. We define a taxonomy with six unanswerable
categories, and UAEval4RAG automatically synthesizes diverse and challenging
queries for any given knowledge base with unanswered ratio and acceptable ratio
metrics. We conduct experiments with various RAG components, including
retrieval models, rewriting methods, rerankers, language models, and prompting
strategies, and reveal hidden trade-offs in performance of RAG systems. Our
findings highlight the critical role of component selection and prompt design
in optimizing RAG systems to balance the accuracy of answerable queries with
high rejection rates of unanswerable ones. UAEval4RAG provides valuable
insights and tools for developing more robust and reliable RAG systems.",2024-12-16,"Xiangyu Peng, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu",http://arxiv.org/pdf/2412.12300v3,cs.CL
Emergence of Abstractions: Concept Encoding and Decoding Mechanism for In-Context Learning in Transformers,"Humans distill complex experiences into fundamental abstractions that enable
rapid learning and adaptation. Similarly, autoregressive transformers exhibit
adaptive learning through in-context learning (ICL), which begs the question of
how. In this paper, we propose concept encoding-decoding mechanism to explain
ICL by studying how transformers form and use internal abstractions in their
representations. On synthetic ICL tasks, we analyze the training dynamics of a
small transformer and report the coupled emergence of concept encoding and
decoding. As the model learns to encode different latent concepts (e.g.,
``Finding the first noun in a sentence."") into distinct, separable
representations, it concureently builds conditional decoding algorithms and
improve its ICL performance. We validate the existence of this mechanism across
pretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B).
Further, through mechanistic interventions and controlled finetuning, we
demonstrate that the quality of concept encoding is causally related and
predictive of ICL performance. Our empirical insights shed light into better
understanding the success and failure modes of large language models via their
representations.",2024-12-16,"Seungwook Han, Jinyeop Song, Jeff Gore, Pulkit Agrawal",http://arxiv.org/pdf/2412.12276v2,cs.CL
SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator,"Large Language Models (LLMs) have exhibited exceptional performance across a
spectrum of natural language processing tasks. However, their substantial sizes
pose considerable challenges, particularly in computational demands and
inference speed, due to their quadratic complexity. In this work, we have
identified a key pattern: certain seemingly meaningless separator tokens (i.e.,
punctuations) contribute disproportionately to attention scores compared to
semantically meaningful tokens. This observation suggests that information of
the segments between these separator tokens can be effectively condensed into
the separator tokens themselves without significant information loss. Guided by
this insight, we introduce SepLLM, a plug-and-play framework that accelerates
inference by compressing these segments and eliminating redundant tokens.
Additionally, we implement efficient kernels for training acceleration.
Experimental results across training-free, training-from-scratch, and
post-training settings demonstrate SepLLM's effectiveness. Notably, using the
Llama-3-8B backbone, SepLLM achieves over 50% reduction in KV cache on the
GSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in
streaming settings, SepLLM effectively processes sequences of up to 4 million
tokens or more while maintaining consistent language modeling capabilities.",2024-12-16,"Guoxuan Chen, Han Shi, Jiawei Li, Yihang Gao, Xiaozhe Ren, Yimeng Chen, Xin Jiang, Zhenguo Li, Weiyang Liu, Chao Huang",http://arxiv.org/pdf/2412.12094v5,cs.CL
Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats,"WARNING: This paper contains content that maybe upsetting or offensive to
some readers. Dog whistles are coded expressions with dual meanings: one
intended for the general public (outgroup) and another that conveys a specific
message to an intended audience (ingroup). Often, these expressions are used to
convey controversial political opinions while maintaining plausible deniability
and slip by content moderation filters. Identification of dog whistles relies
on curated lexicons, which have trouble keeping up to date. We introduce
FETCH!, a task for finding novel dog whistles in massive social media corpora.
We find that state-of-the-art systems fail to achieve meaningful results across
three distinct social media case studies. We present EarShot, a strong baseline
system that combines the strengths of vector databases and Large Language
Models (LLMs) to efficiently and effectively identify new dog whistles.",2024-12-16,"Kuleen Sasse, Carlos Aguirre, Isabel Cachola, Sharon Levy, Mark Dredze",http://arxiv.org/pdf/2412.12072v2,cs.CL
Semi-automated analysis of audio-recorded lessons: The case of teachers' engaging messages,"Engaging messages delivered by teachers are a key aspect of the classroom
discourse that influences student outcomes. However, improving this
communication is challenging due to difficulties in obtaining observations.
This study presents a methodology for efficiently extracting actual
observations of engaging messages from audio-recorded lessons. We collected
2,477 audio-recorded lessons from 75 teachers over two academic years. Using
automatic transcription and keyword-based filtering analysis, we identified and
classified engaging messages. This method reduced the information to be
analysed by 90%, optimising the time and resources required compared to
traditional manual coding. Subsequent descriptive analysis revealed that the
most used messages emphasised the future benefits of participating in school
activities. In addition, the use of engaging messages decreased as the academic
year progressed. This study offers insights for researchers seeking to extract
information from teachers' discourse in naturalistic settings and provides
useful information for designing interventions to improve teachers'
communication strategies.",2024-12-16,"Samuel Falcon, Carmen Alvarez-Alvarez, Jaime Leon",http://arxiv.org/pdf/2412.12062v1,cs.CL
Virtual Agent-Based Communication Skills Training to Facilitate Health Persuasion Among Peers,"Many laypeople are motivated to improve the health behavior of their family
or friends but do not know where to start, especially if the health behavior is
potentially stigmatizing or controversial. We present an approach that uses
virtual agents to coach community-based volunteers in health counseling
techniques, such as motivational interviewing, and allows them to practice
these skills in role-playing scenarios. We use this approach in a virtual
agent-based system to increase COVID-19 vaccination by empowering users to
influence their social network. In a between-subjects comparative design study,
we test the effects of agent system interactivity and role-playing
functionality on counseling outcomes, with participants evaluated by
standardized patients and objective judges. We find that all versions are
effective at producing peer counselors who score adequately on a standardized
measure of counseling competence, and that participants were significantly more
satisfied with interactive virtual agents compared to passive viewing of the
training material. We discuss design implications for interpersonal skills
training systems based on our findings.",2024-12-16,"Farnaz Nouraei, Keith Rebello, Mina Fallah, Prasanth Murali, Haley Matuszak, Valerie Jap, Andrea Parker, Michael Paasche-Orlow, Timothy Bickmore",http://arxiv.org/pdf/2412.12061v1,cs.CL
How Private are Language Models in Abstractive Summarization?,"Language models (LMs) have shown outstanding performance in text
summarization including sensitive domains such as medicine and law. In these
settings, it is important that personally identifying information (PII)
included in the source document should not leak in the summary. Prior efforts
have mostly focused on studying how LMs may inadvertently elicit PII from
training data. However, to what extent LMs can provide privacy-preserving
summaries given a non-private source document remains under-explored. In this
paper, we perform a comprehensive study across two closed- and three
open-weight LMs of different sizes and families. We experiment with prompting
and fine-tuning strategies for privacy-preservation across a range of
summarization datasets across three domains. Our extensive quantitative and
qualitative analysis including human evaluation shows that LMs often cannot
prevent PII leakage on their summaries and that current widely-used metrics
cannot capture context dependent privacy risks.",2024-12-16,"Anthony Hughes, Nikolaos Aletras, Ning Ma",http://arxiv.org/pdf/2412.12040v1,cs.CL
Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection,"Despite their remarkable success, large language models (LLMs) have shown
limited ability on applied tasks such as vulnerability detection. We
investigate various prompting strategies for vulnerability detection and, as
part of this exploration, propose a prompting strategy that integrates natural
language descriptions of vulnerabilities with a contrastive chain-of-thought
reasoning approach, augmented using contrastive samples from a synthetic
dataset. Our study highlights the potential of LLMs to detect vulnerabilities
by integrating natural language descriptions, contrastive reasoning, and
synthetic examples into a comprehensive prompting framework. Our results show
that this approach can enhance LLM understanding of vulnerabilities. On a
high-quality vulnerability detection dataset such as SVEN, our prompting
strategies can improve accuracies, F1-scores, and pairwise accuracies by 23%,
11%, and 14%, respectively.",2024-12-16,"Ira Ceka, Feitong Qiao, Anik Dey, Aastha Valecha, Gail Kaiser, Baishakhi Ray",http://arxiv.org/pdf/2412.12039v2,cs.CL
SpeechPrune: Context-aware Token Pruning for Speech Information Retrieval,"We introduce Speech Information Retrieval (SIR), a new long-context task for
Speech Large Language Models (Speech LLMs), and present SPIRAL, a 1,012-sample
benchmark testing models' ability to extract critical details from
approximately 90-second spoken inputs. While current Speech LLMs excel at
short-form tasks, they struggle with the computational and representational
demands of longer audio sequences. To address this limitation, we propose
SpeechPrune, a training-free token pruning strategy that uses speech-text
similarity and approximated attention scores to efficiently discard irrelevant
tokens. In SPIRAL, SpeechPrune achieves accuracy improvements of 29% and up to
47% over the original model and the random pruning model at a pruning rate of
20%, respectively. SpeechPrune can maintain network performance even at a
pruning level of 80%. This approach highlights the potential of token-level
pruning for efficient and scalable long-form speech understanding.",2024-12-16,"Yueqian Lin, Yuzhe Fu, Jingyang Zhang, Yudong Liu, Jianyi Zhang, Jingwei Sun, Hai ""Helen"" Li, Yiran Chen",http://arxiv.org/pdf/2412.12009v2,cs.CL
The Open Source Advantage in Large Language Models (LLMs),"Large language models (LLMs) have rapidly advanced natural language
processing, driving significant breakthroughs in tasks such as text generation,
machine translation, and domain-specific reasoning. The field now faces a
critical dilemma in its approach: closed-source models like GPT-4 deliver
state-of-the-art performance but restrict reproducibility, accessibility, and
external oversight, while open-source frameworks like LLaMA and Mixtral
democratize access, foster collaboration, and support diverse applications,
achieving competitive results through techniques like instruction tuning and
LoRA. Hybrid approaches address challenges like bias mitigation and resource
accessibility by combining the scalability of closed-source systems with the
transparency and inclusivity of open-source framework. However, in this
position paper, we argue that open-source remains the most robust path for
advancing LLM research and ethical deployment.",2024-12-16,"Jiya Manchanda, Laura Boettcher, Matheus Westphalen, Jasser Jasser",http://arxiv.org/pdf/2412.12004v2,cs.CL
LLM-RG4: Flexible and Factual Radiology Report Generation across Diverse Input Contexts,"Drafting radiology reports is a complex task requiring flexibility, where
radiologists tail content to available information and particular clinical
demands. However, most current radiology report generation (RRG) models are
constrained to a fixed task paradigm, such as predicting the full ``finding''
section from a single image, inherently involving a mismatch between inputs and
outputs. The trained models lack the flexibility for diverse inputs and could
generate harmful, input-agnostic hallucinations. To bridge the gap between
current RRG models and the clinical demands in practice, we first develop a
data generation pipeline to create a new MIMIC-RG4 dataset, which considers
four common radiology report drafting scenarios and has perfectly corresponded
input and output. Secondly, we propose a novel large language model (LLM) based
RRG framework, namely LLM-RG4, which utilizes LLM's flexible
instruction-following capabilities and extensive general knowledge. We further
develop an adaptive token fusion module that offers flexibility to handle
diverse scenarios with different input combinations, while minimizing the
additional computational burden associated with increased input volumes.
Besides, we propose a token-level loss weighting strategy to direct the model's
attention towards positive and uncertain descriptions. Experimental results
demonstrate that LLM-RG4 achieves state-of-the-art performance in both clinical
efficiency and natural language generation on the MIMIC-RG4 and MIMIC-CXR
datasets. We quantitatively demonstrate that our model has minimal
input-agnostic hallucinations, whereas current open-source models commonly
suffer from this problem.",2024-12-16,"Zhuhao Wang, Yihua Sun, Zihan Li, Xuan Yang, Fang Chen, Hongen Liao",http://arxiv.org/pdf/2412.12001v1,cs.CL
ExecRepoBench: Multi-level Executable Code Completion Evaluation,"Code completion has become an essential tool for daily software development.
Existing evaluation benchmarks often employ static methods that do not fully
capture the dynamic nature of real-world coding environments and face
significant challenges, including limited context length, reliance on
superficial evaluation metrics, and potential overfitting to training datasets.
In this work, we introduce a novel framework for enhancing code completion in
software development through the creation of a repository-level benchmark
ExecRepoBench and the instruction corpora Repo-Instruct, aim at improving the
functionality of open-source large language models (LLMs) in real-world coding
scenarios that involve complex interdependencies across multiple files.
ExecRepoBench includes 1.2K samples from active Python repositories. Plus, we
present a multi-level grammar-based completion methodology conditioned on the
abstract syntax tree to mask code fragments at various logical units (e.g.
statements, expressions, and functions). Then, we fine-tune the open-source LLM
with 7B parameters on Repo-Instruct to produce a strong code completion
baseline model Qwen2.5-Coder-Instruct-C based on the open-source model.
Qwen2.5-Coder-Instruct-C is rigorously evaluated against existing benchmarks,
including MultiPL-E and ExecRepoBench, which consistently outperforms prior
baselines across all programming languages. The deployment of \ourmethod{} can
be used as a high-performance, local service for programming
development\footnote{\url{https://execrepobench.github.io/}}.",2024-12-16,"Jian Yang, Jiajun Zhang, Jiaxi Yang, Ke Jin, Lei Zhang, Qiyao Peng, Ken Deng, Yibo Miao, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin",http://arxiv.org/pdf/2412.11990v1,cs.CL
Multi-head attention debiasing and contrastive learning for mitigating Dataset Artifacts in Natural Language Inference,"While Natural Language Inference (NLI) models have achieved high performances
on benchmark datasets, there are still concerns whether they truly capture the
intended task, or largely exploit dataset artifacts. Through detailed analysis
of the Stanford Natural Language Inference (SNLI) dataset, we have uncovered
complex patterns of various types of artifacts and their interactions, leading
to the development of our novel structural debiasing approach. Our fine-grained
analysis of 9,782 validation examples reveals four major categories of
artifacts: length-based patterns, lexical overlap, subset relationships, and
negation patterns. Our multi-head debiasing architecture achieves substantial
improvements across all bias categories: length bias accuracy improved from
86.03% to 90.06%, overlap bias from 91.88% to 93.13%, subset bias from 95.43%
to 96.49%, and negation bias from 88.69% to 94.64%. Overall, our approach
reduces the error rate from 14.19% to 10.42% while maintaining high performance
on unbiased examples. Analysis of 1,026 error cases shows significant
improvement in handling neutral relationships, traditionally one of the most
challenging areas for NLI systems.",2024-12-16,Karthik Sivakoti,http://arxiv.org/pdf/2412.16194v1,cs.CL
SciFaultyQA: Benchmarking LLMs on Faulty Science Question Detection with a GAN-Inspired Approach to Synthetic Dataset Generation,"Consider the problem: ``If one man and one woman can produce one child in one
year, how many children will be produced by one woman and three men in 0.5
years?"" Current large language models (LLMs) such as GPT-4o, GPT-o1-preview,
and Gemini Flash frequently answer ""0.5,"" which does not make sense. While
these models sometimes acknowledge the unrealistic nature of the question, in
many cases (8 out of 10 trials), they provide the nonsensical answer of ""0.5
child."" Additionally, temporal variation has been observed: if an LLM answers
correctly once (by recognizing the faulty nature of the question), subsequent
responses are more likely to also reflect this understanding. However, this is
inconsistent.
  These types of questions have motivated us to develop a dataset of science
questions, SciFaultyQA, where the questions themselves are intentionally
faulty. We observed that LLMs often proceed to answer these flawed questions
without recognizing their inherent issues, producing results that are logically
or scientifically invalid. By analyzing such patterns, we developed a novel
method for generating synthetic datasets to evaluate and benchmark the
performance of various LLMs in identifying these flawed questions. We have also
developed novel approaches to reduce the errors.",2024-12-16,Debarshi Kundu,http://arxiv.org/pdf/2412.11988v1,cs.CL
Speak & Improve Corpus 2025: an L2 English Speech Corpus for Language Assessment and Feedback,"We introduce the Speak & Improve Corpus 2025, a dataset of L2 learner English
data with holistic scores and language error annotation, collected from open
(spontaneous) speaking tests on the Speak & Improve learning platform. The aim
of the corpus release is to address a major challenge to developing L2 spoken
language processing systems, the lack of publicly available data with
high-quality annotations. It is being made available for non-commercial use on
the ELiT website. In designing this corpus we have sought to make it cover a
wide-range of speaker attributes, from their L1 to their speaking ability, as
well as providing manual annotations. This enables a range of language-learning
tasks to be examined, such as assessing speaking proficiency or providing
feedback on grammatical errors in a learner's speech. Additionally the data
supports research into the underlying technology required for these tasks
including automatic speech recognition (ASR) of low resource L2 learner
English, disfluency detection or spoken grammatical error correction (GEC). The
corpus consists of around 315 hours of L2 English learners audio with holistic
scores, and a subset of audio annotated with transcriptions and error labels.",2024-12-16,"Kate Knill, Diane Nicholls, Mark J. F. Gales, Mengjie Qian, Pawel Stroinski",http://arxiv.org/pdf/2412.11986v2,cs.CL
Speak & Improve Challenge 2025: Tasks and Baseline Systems,"This paper presents the ""Speak & Improve Challenge 2025: Spoken Language
Assessment and Feedback"" -- a challenge associated with the ISCA SLaTE 2025
Workshop. The goal of the challenge is to advance research on spoken language
assessment and feedback, with tasks associated with both the underlying
technology and language learning feedback. Linked with the challenge, the Speak
& Improve (S&I) Corpus 2025 is being pre-released, a dataset of L2 learner
English data with holistic scores and language error annotation, collected from
open (spontaneous) speaking tests on the Speak & Improve learning platform. The
corpus consists of approximately 315 hours of audio data from second language
English learners with holistic scores, and a 55-hour subset with manual
transcriptions and error labels. The Challenge has four shared tasks: Automatic
Speech Recognition (ASR), Spoken Language Assessment (SLA), Spoken Grammatical
Error Correction (SGEC), and Spoken Grammatical Error Correction Feedback
(SGECF). Each of these tasks has a closed track where a predetermined set of
models and data sources are allowed to be used, and an open track where any
public resource may be used. Challenge participants may do one or more of the
tasks. This paper describes the challenge, the S&I Corpus 2025, and the
baseline systems released for the Challenge.",2024-12-16,"Mengjie Qian, Kate Knill, Stefano Banno, Siyuan Tang, Penny Karanasou, Mark J. F. Gales, Diane Nicholls",http://arxiv.org/pdf/2412.11985v2,cs.CL
"Speech Foundation Models and Crowdsourcing for Efficient, High-Quality Data Collection","While crowdsourcing is an established solution for facilitating and scaling
the collection of speech data, the involvement of non-experts necessitates
protocols to ensure final data quality. To reduce the costs of these essential
controls, this paper investigates the use of Speech Foundation Models (SFMs) to
automate the validation process, examining for the first time the cost/quality
trade-off in data acquisition. Experiments conducted on French, German, and
Korean data demonstrate that SFM-based validation has the potential to reduce
reliance on human validation, resulting in an estimated cost saving of over
40.0% without degrading final data quality. These findings open new
opportunities for more efficient, cost-effective, and scalable speech data
acquisition.",2024-12-16,"Beomseok Lee, Marco Gaido, Ioan Calapodescu, Laurent Besacier, Matteo Negri",http://arxiv.org/pdf/2412.11978v1,cs.CL
Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning,"Traditional reinforcement learning-based robotic control methods are often
task-specific and fail to generalize across diverse environments or unseen
objects and instructions. Visual Language Models (VLMs) demonstrate strong
scene understanding and planning capabilities but lack the ability to generate
actionable policies tailored to specific robotic embodiments. To address this,
Visual-Language-Action (VLA) models have emerged, yet they face challenges in
long-horizon spatial reasoning and grounded task planning. In this work, we
propose the Embodied Multimodal Action Model with Grounded Chain of Thought and
Look-ahead Spatial Reasoning, Emma-X. Emma-X leverages our constructed
hierarchical embodiment dataset based on BridgeV2, containing 60,000 robot
manipulation trajectories auto-annotated with grounded task reasoning and
spatial guidance. Additionally, we introduce a trajectory segmentation strategy
based on gripper states and motion trajectories, which can help mitigate
hallucination in grounding subtask reasoning generation. Experimental results
demonstrate that Emma-X achieves superior performance over competitive
baselines, particularly in real-world robotic tasks requiring spatial
reasoning.",2024-12-16,"Qi Sun, Pengfei Hong, Tej Deep Pala, Vernon Toh, U-Xuan Tan, Deepanway Ghosal, Soujanya Poria",http://arxiv.org/pdf/2412.11974v2,cs.CL
DARWIN 1.5: Large Language Models as Materials Science Adapted Learners,"Materials discovery and design aim to find compositions and structures with
desirable properties over highly complex and diverse physical spaces.
Traditional solutions, such as high-throughput simulations or machine learning,
often rely on complex descriptors, which hinder generalizability and
transferability across different material systems. Moreover, These descriptors
may inadequately represent macro-scale material properties, which are
influenced by structural imperfections and compositional variations in
real-world samples, thus limiting their practical applicability. To address
these challenges, we propose DARWIN 1.5, the largest open-source large language
model tailored for materials science. By leveraging natural language as input,
DARWIN eliminates the need for task-specific descriptors and enables a
flexible, unified approach to material property prediction and discovery. Our
approach integrates 6M material domain papers and 21 experimental datasets from
49,256 materials across modalities while enabling cross-task knowledge
transfer. The enhanced model achieves up to 59.1% improvement in prediction
accuracy over the base LLaMA-7B architecture and outperforms SOTA machine
learning approaches across 8 materials design tasks. These results establish
LLMs as a promising foundation for developing versatile and scalable models in
materials science.",2024-12-16,"Tong Xie, Yuwei Wan, Yixuan Liu, Yuchen Zeng, Shaozhou Wang, Wenjie Zhang, Clara Grazian, Chunyu Kit, Wanli Ouyang, Dongzhan Zhou, Bram Hoex",http://arxiv.org/pdf/2412.11970v3,cs.CL
Inferring Functionality of Attention Heads from their Parameters,"Attention heads are one of the building blocks of large language models
(LLMs). Prior work on investigating their operation mostly focused on analyzing
their behavior during inference for specific circuits or tasks. In this work,
we seek a comprehensive mapping of the operations they implement in a model. We
propose MAPS (Mapping Attention head ParameterS), an efficient framework that
infers the functionality of attention heads from their parameters, without any
model training or inference. We showcase the utility of MAPS for answering two
types of questions: (a) given a predefined operation, mapping how strongly
heads across the model implement it, and (b) given an attention head, inferring
its salient functionality. Evaluating MAPS on 20 operations across 6 popular
LLMs shows its estimations correlate with the head's outputs during inference
and are causally linked to the model's predictions. Moreover, its mappings
reveal attention heads of certain operations that were overlooked in previous
studies, and valuable insights on function universality and architecture biases
in LLMs. Next, we present an automatic pipeline and analysis that leverage MAPS
to characterize the salient operations of a given head. Our pipeline produces
plausible operation descriptions for most heads, as assessed by human judgment,
while revealing diverse operations.",2024-12-16,"Amit Elhelo, Mor Geva",http://arxiv.org/pdf/2412.11965v1,cs.CL
The Impact of Token Granularity on the Predictive Power of Language Model Surprisal,"Word-by-word language model surprisal is often used to model the incremental
processing of human readers, which raises questions about how various choices
in language modeling influence its predictive power. One factor that has been
overlooked in cognitive modeling is the granularity of subword tokens, which
explicitly encodes information about word length and frequency, and ultimately
influences the quality of vector representations that are learned. This paper
presents experiments that manipulate the token granularity and evaluate its
impact on the ability of surprisal to account for processing difficulty of
naturalistic text and garden-path constructions. Experiments with naturalistic
reading times reveal a substantial influence of token granularity on surprisal,
with tokens defined by a vocabulary size of 8,000 resulting in surprisal that
is most predictive. In contrast, on garden-path constructions, language models
trained on coarser-grained tokens generally assigned higher surprisal to
critical regions, suggesting their increased sensitivity to syntax. Taken
together, these results suggest a large role of token granularity on the
quality of language model surprisal for cognitive modeling.",2024-12-16,"Byung-Doh Oh, William Schuler",http://arxiv.org/pdf/2412.11940v1,cs.CL
SEAGraph: Unveiling the Whole Story of Paper Review Comments,"Peer review, as a cornerstone of scientific research, ensures the integrity
and quality of scholarly work by providing authors with objective feedback for
refinement. However, in the traditional peer review process, authors often
receive vague or insufficiently detailed feedback, which provides limited
assistance and leads to a more time-consuming review cycle. If authors can
identify some specific weaknesses in their paper, they can not only address the
reviewer's concerns but also improve their work. This raises the critical
question of how to enhance authors' comprehension of review comments. In this
paper, we present SEAGraph, a novel framework developed to clarify review
comments by uncovering the underlying intentions behind them. We construct two
types of graphs for each paper: the semantic mind graph, which captures the
author's thought process, and the hierarchical background graph, which
delineates the research domains related to the paper. A retrieval method is
then designed to extract relevant content from both graphs, facilitating
coherent explanations for the review comments. Extensive experiments show that
SEAGraph excels in review comment understanding tasks, offering significant
benefits to authors.",2024-12-16,"Jianxiang Yu, Jiaqi Tan, Zichen Ding, Jiapeng Zhu, Jiahao Li, Yao Cheng, Qier Cui, Yunshi Lan, Xiang Li",http://arxiv.org/pdf/2412.11939v1,cs.CL
Precise Length Control in Large Language Models,"Large Language Models (LLMs) are increasingly used in production systems,
powering applications such as chatbots, summarization, and question answering.
Despite their success, controlling the length of their response remains a
significant challenge, particularly for tasks requiring structured outputs or
specific levels of detail. In this work, we propose a method to adapt
pre-trained decoder-only LLMs for precise control of response length. Our
approach incorporates a secondary length-difference positional encoding (LDPE)
into the input embeddings, which counts down to a user-set response termination
length. Fine-tuning with LDPE allows the model to learn to terminate responses
coherently at the desired length, achieving mean token errors of less than 3
tokens. We also introduce Max New Tokens++, an extension that enables flexible
upper-bound length control, rather than an exact target. Experimental results
on tasks such as question answering and document summarization demonstrate that
our method enables precise length control without compromising response
quality.",2024-12-16,"Bradley Butcher, Michael O'Keefe, James Titchener",http://arxiv.org/pdf/2412.11937v1,cs.CL
"A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges","Mathematical reasoning, a core aspect of human cognition, is vital across
many domains, from educational problem-solving to scientific advancements. As
artificial general intelligence (AGI) progresses, integrating large language
models (LLMs) with mathematical reasoning tasks is becoming increasingly
significant. This survey provides the first comprehensive analysis of
mathematical reasoning in the era of multimodal large language models (MLLMs).
We review over 200 studies published since 2021, and examine the
state-of-the-art developments in Math-LLMs, with a focus on multimodal
settings. We categorize the field into three dimensions: benchmarks,
methodologies, and challenges. In particular, we explore multimodal
mathematical reasoning pipeline, as well as the role of (M)LLMs and the
associated methodologies. Finally, we identify five major challenges hindering
the realization of AGI in this domain, offering insights into the future
direction for enhancing multimodal reasoning capabilities. This survey serves
as a critical resource for the research community in advancing the capabilities
of LLMs to tackle complex multimodal reasoning tasks.",2024-12-16,"Yibo Yan, Jiamin Su, Jianxiang He, Fangteng Fu, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu",http://arxiv.org/pdf/2412.11936v3,cs.CL
Explainable Procedural Mistake Detection,"Automated task guidance has recently attracted attention from the AI research
community. Procedural mistake detection (PMD) is a challenging sub-problem of
classifying whether a human user (observed through egocentric video) has
successfully executed the task at hand (specified by a procedural text).
Despite significant efforts in building resources and models for PMD, machine
performance remains nonviable, and the reasoning processes underlying this
performance are opaque. As such, we recast PMD to an explanatory self-dialog of
questions and answers, which serve as evidence for a decision. As this
reformulation enables an unprecedented transparency, we leverage a fine-tuned
natural language inference (NLI) model to formulate two automated coherence
metrics for generated explanations. Our results show that while open-source
VLMs struggle with this task off-the-shelf, their accuracy, coherence, and
dialog efficiency can be vastly improved by incorporating these coherence
metrics into common inference and fine-tuning methods. Furthermore, our
multi-faceted metrics can visualize common outcomes at a glance, highlighting
areas for improvement.",2024-12-16,"Shane Storks, Itamar Bar-Yossef, Yayuan Li, Zheyuan Zhang, Jason J. Corso, Joyce Chai",http://arxiv.org/pdf/2412.11927v1,cs.CL
PICLe: Pseudo-Annotations for In-Context Learning in Low-Resource Named Entity Detection,"In-context learning (ICL) enables Large Language Models (LLMs) to perform
tasks using few demonstrations, facilitating task adaptation when labeled
examples are hard to obtain. However, ICL is sensitive to the choice of
demonstrations, and it remains unclear which demonstration attributes enable
in-context generalization. In this work, we conduct a perturbation study of
in-context demonstrations for low-resource Named Entity Detection (NED). Our
surprising finding is that in-context demonstrations with partially correct
annotated entity mentions can be as effective for task transfer as fully
correct demonstrations. Based off our findings, we propose Pseudo-annotated
In-Context Learning (PICLe), a framework for in-context learning with noisy,
pseudo-annotated demonstrations. PICLe leverages LLMs to annotate many
demonstrations in a zero-shot first pass. We then cluster these synthetic
demonstrations, sample specific sets of in-context demonstrations from each
cluster, and predict entity mentions using each set independently. Finally, we
use self-verification to select the final set of entity mentions. We evaluate
PICLe on five biomedical NED datasets and show that, with zero human
annotation, PICLe outperforms ICL in low-resource settings where limited gold
examples can be used as in-context demonstrations.",2024-12-16,"Sepideh Mamooler, Syrielle Montariol, Alexander Mathis, Antoine Bosselut",http://arxiv.org/pdf/2412.11923v2,cs.CL
RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation,"Large language models (LLMs) exhibit remarkable generative capabilities but
often suffer from hallucinations. Retrieval-augmented generation (RAG) offers
an effective solution by incorporating external knowledge, but existing methods
still face several limitations: additional deployment costs of separate
retrievers, redundant input tokens from retrieved text chunks, and the lack of
joint optimization of retrieval and generation. To address these issues, we
propose \textbf{RetroLLM}, a unified framework that integrates retrieval and
generation into a single, cohesive process, enabling LLMs to directly generate
fine-grained evidence from the corpus with constrained decoding. Moreover, to
mitigate false pruning in the process of constrained evidence generation, we
introduce (1) hierarchical FM-Index constraints, which generate
corpus-constrained clues to identify a subset of relevant documents before
evidence generation, reducing irrelevant decoding space; and (2) a
forward-looking constrained decoding strategy, which considers the relevance of
future sequences to improve evidence accuracy. Extensive experiments on five
open-domain QA datasets demonstrate RetroLLM's superior performance across both
in-domain and out-of-domain tasks. The code is available at
\url{https://github.com/sunnynexus/RetroLLM}.",2024-12-16,"Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou",http://arxiv.org/pdf/2412.11919v1,cs.CL
CharacterBench: Benchmarking Character Customization of Large Language Models,"Character-based dialogue (aka role-playing) enables users to freely customize
characters for interaction, which often relies on LLMs, raising the need to
evaluate LLMs' character customization capability. However, existing benchmarks
fail to ensure a robust evaluation as they often only involve a single
character category or evaluate limited dimensions. Moreover, the sparsity of
character features in responses makes feature-focused generative evaluation
both ineffective and inefficient. To address these issues, we propose
CharacterBench, the largest bilingual generative benchmark, with 22,859
human-annotated samples covering 3,956 characters from 25 detailed character
categories. We define 11 dimensions of 6 aspects, classified as sparse and
dense dimensions based on whether character features evaluated by specific
dimensions manifest in each response. We enable effective and efficient
evaluation by crafting tailored queries for each dimension to induce
characters' responses related to specific dimensions. Further, we develop
CharacterJudge model for cost-effective and stable evaluations. Experiments
show its superiority over SOTA automatic judges (e.g., GPT-4) and our
benchmark's potential to optimize LLMs' character customization. Our repository
is at https://github.com/thu-coai/CharacterBench.",2024-12-16,"Jinfeng Zhou, Yongkang Huang, Bosi Wen, Guanqun Bi, Yuxuan Chen, Pei Ke, Zhuang Chen, Xiyao Xiao, Libiao Peng, Kuntian Tang, Rongsheng Zhang, Le Zhang, Tangjie Lv, Zhipeng Hu, Hongning Wang, Minlie Huang",http://arxiv.org/pdf/2412.11912v1,cs.CL
Can Language Models Rival Mathematics Students? Evaluating Mathematical Reasoning through Textual Manipulation and Human Experiments,"In this paper we look at the ability of recent large language models (LLMs)
at solving mathematical problems in combinatorics. We compare models LLaMA-2,
LLaMA-3.1, GPT-4, and Mixtral against each other and against human pupils and
undergraduates with prior experience in mathematical olympiads. To facilitate
these comparisons we introduce the Combi-Puzzles dataset, which contains 125
problem variants based on 25 combinatorial reasoning problems. Each problem is
presented in one of five distinct forms, created by systematically manipulating
the problem statements through adversarial additions, numeric parameter
changes, and linguistic obfuscation. Our variations preserve the mathematical
core and are designed to measure the generalisability of LLM problem-solving
abilities, while also increasing confidence that problems are submitted to LLMs
in forms that have not been seen as training instances. We found that a model
based on GPT-4 outperformed all other models in producing correct responses,
and performed significantly better in the mathematical variation of the
problems than humans. We also found that modifications to problem statements
significantly impact the LLM's performance, while human performance remains
unaffected.",2024-12-16,"Andrii Nikolaiev, Yiannos Stathopoulos, Simone Teufel",http://arxiv.org/pdf/2412.11908v1,cs.CL
Classification of Spontaneous and Scripted Speech for Multilingual Audio,"Distinguishing scripted from spontaneous speech is an essential tool for
better understanding how speech styles influence speech processing research. It
can also improve recommendation systems and discovery experiences for media
users through better segmentation of large recorded speech catalogues. This
paper addresses the challenge of building a classifier that generalises well
across different formats and languages. We systematically evaluate models
ranging from traditional, handcrafted acoustic and prosodic features to
advanced audio transformers, utilising a large, multilingual proprietary
podcast dataset for training and validation. We break down the performance of
each model across 11 language groups to evaluate cross-lingual biases. Our
experimental analysis extends to publicly available datasets to assess the
models' generalisability to non-podcast domains. Our results indicate that
transformer-based models consistently outperform traditional feature-based
techniques, achieving state-of-the-art performance in distinguishing between
scripted and spontaneous speech across various languages.",2024-12-16,"Shahar Elisha, Andrew McDowell, Mariano Beguerisse-Díaz, Emmanouil Benetos",http://arxiv.org/pdf/2412.11896v1,cs.CL
Using Instruction-Tuned Large Language Models to Identify Indicators of Vulnerability in Police Incident Narratives,"Objectives: Compare qualitative coding of instruction tuned large language
models (IT-LLMs) against human coders in classifying the presence or absence of
vulnerability in routinely collected unstructured text that describes
police-public interactions. Evaluate potential bias in IT-LLM codings. Methods:
Analyzing publicly available text narratives of police-public interactions
recorded by Boston Police Department, we provide humans and IT-LLMs with
qualitative labelling codebooks and compare labels generated by both, seeking
to identify situations associated with (i) mental ill health; (ii) substance
misuse; (iii) alcohol dependence; and (iv) homelessness. We explore multiple
prompting strategies and model sizes, and the variability of labels generated
by repeated prompts. Additionally, to explore model bias, we utilize
counterfactual methods to assess the impact of two protected characteristics -
race and gender - on IT-LLM classification. Results: Results demonstrate that
IT-LLMs can effectively support human qualitative coding of police incident
narratives. While there is some disagreement between LLM and human generated
labels, IT-LLMs are highly effective at screening narratives where no
vulnerabilities are present, potentially vastly reducing the requirement for
human coding. Counterfactual analyses demonstrate that manipulations to both
gender and race of individuals described in narratives have very limited
effects on IT-LLM classifications beyond those expected by chance. Conclusions:
IT-LLMs offer effective means to augment human qualitative coding in a way that
requires much lower levels of resource to analyze large unstructured datasets.
Moreover, they encourage specificity in qualitative coding, promote
transparency, and provide the opportunity for more standardized, replicable
approaches to analyzing large free-text police data sources.",2024-12-16,"Sam Relins, Daniel Birks, Charlie Lloyd",http://arxiv.org/pdf/2412.11878v1,cs.CL
GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training,"Despite their proficiency in general tasks, Multi-modal Large Language Models
(MLLMs) struggle with automatic Geometry Problem Solving (GPS), which demands
understanding diagrams, interpreting symbols, and performing complex reasoning.
This limitation arises from their pre-training on natural images and texts,
along with the lack of automated verification in the problem-solving process.
Besides, current geometric specialists are limited by their task-specific
designs, making them less effective for broader geometric problems. To this
end, we present GeoX, a multi-modal large model focusing on geometric
understanding and reasoning tasks. Given the significant differences between
geometric diagram-symbol and natural image-text, we introduce unimodal
pre-training to develop a diagram encoder and symbol decoder, enhancing the
understanding of geometric images and corpora. Furthermore, we introduce
geometry-language alignment, an effective pre-training paradigm that bridges
the modality gap between unimodal geometric experts. We propose a
Generator-And-Sampler Transformer (GS-Former) to generate discriminative
queries and eliminate uninformative representations from unevenly distributed
geometric signals. Finally, GeoX benefits from visual instruction tuning,
empowering it to take geometric images and questions as input and generate
verifiable solutions. Experiments show that GeoX outperforms both generalists
and geometric specialists on publicly recognized benchmarks, such as GeoQA,
UniGeo, Geometry3K, and PGPS9k.",2024-12-16,"Renqiu Xia, Mingsheng Li, Hancheng Ye, Wenjie Wu, Hongbin Zhou, Jiakang Yuan, Tianshuo Peng, Xinyu Cai, Xiangchao Yan, Bin Wang, Conghui He, Botian Shi, Tao Chen, Junchi Yan, Bo Zhang",http://arxiv.org/pdf/2412.11863v2,cs.CL
A Benchmark and Robustness Study of In-Context-Learning with Large Language Models in Music Entity Detection,"Detecting music entities such as song titles or artist names is a useful
application to help use cases like processing music search queries or analyzing
music consumption on the web. Recent approaches incorporate smaller language
models (SLMs) like BERT and achieve high results. However, further research
indicates a high influence of entity exposure during pre-training on the
performance of the models. With the advent of large language models (LLMs),
these outperform SLMs in a variety of downstream tasks. However, researchers
are still divided if this is applicable to tasks like entity detection in texts
due to issues like hallucination. In this paper, we provide a novel dataset of
user-generated metadata and conduct a benchmark and a robustness study using
recent LLMs with in-context-learning (ICL). Our results indicate that LLMs in
the ICL setting yield higher performance than SLMs. We further uncover the
large impact of entity exposure on the best performing LLM in our study.",2024-12-16,"Simon Hachmeier, Robert Jäschke",http://arxiv.org/pdf/2412.11851v1,cs.CL
Analyzing Images of Legal Documents: Toward Multi-Modal LLMs for Access to Justice,"Interacting with the legal system and the government requires the assembly
and analysis of various pieces of information that can be spread across
different (paper) documents, such as forms, certificates and contracts (e.g.
leases). This information is required in order to understand one's legal
rights, as well as to fill out forms to file claims in court or obtain
government benefits. However, finding the right information, locating the
correct forms and filling them out can be challenging for laypeople. Large
language models (LLMs) have emerged as a powerful technology that has the
potential to address this gap, but still rely on the user to provide the
correct information, which may be challenging and error-prone if the
information is only available in complex paper documents. We present an
investigation into utilizing multi-modal LLMs to analyze images of handwritten
paper forms, in order to automatically extract relevant information in a
structured format. Our initial results are promising, but reveal some
limitations (e.g., when the image quality is low). Our work demonstrates the
potential of integrating multi-modal LLMs to support laypeople and
self-represented litigants in finding and assembling relevant information.",2024-12-16,"Hannes Westermann, Jaromir Savelka",http://arxiv.org/pdf/2412.15260v1,cs.CL
Improved Models for Media Bias Detection and Subcategorization,"We present improved models for the granular detection and sub-classification
news media bias in English news articles. We compare the performance of
zero-shot versus fine-tuned large pre-trained neural transformer language
models, explore how the level of detail of the classes affects performance on a
novel taxonomy of 27 news bias-types, and demonstrate how using synthetically
generated example data can be used to improve quality",2024-12-16,"Tim Menzner, Jochen L. Leidner",http://arxiv.org/pdf/2412.11835v1,cs.CL
Wonderful Matrices: Combining for a More Efficient and Effective Foundation Model Architecture,"In order to make the foundation model more efficient and effective, our idea
is combining sequence transformation and state transformation. First, we prove
the availability of rotary position embedding in the state space duality
algorithm, which reduces the perplexity of the hybrid quadratic causal
self-attention and state space duality by more than 4%, to ensure that the
combining sequence transformation unifies position encoding. Second, we propose
dynamic mask attention, which maintains 100% accuracy in the more challenging
multi-query associative recall task, improving by more than 150% compared to
quadratic causal self-attention and state space duality, to ensure that the
combining sequence transformation selectively filters relevant information.
Third, we design cross domain mixture of experts, which makes the computational
speed of expert retrieval with more than 1024 experts 8 to 10 times faster than
the mixture of experts, to ensure that the combining state transformation
quickly retrieval mixture. Finally, we summarize these matrix algorithms that
can form the foundation model: Wonderful Matrices, which can be a competitor to
popular model architectures.",2024-12-16,"Jingze Shi, Bingheng Wu",http://arxiv.org/pdf/2412.11834v3,cs.CL
"Are You Doubtful? Oh, It Might Be Difficult Then! Exploring the Use of Model Uncertainty for Question Difficulty Estimation","In an educational setting, an estimate of the difficulty of multiple-choice
questions (MCQs), a commonly used strategy to assess learning progress,
constitutes very useful information for both teachers and students. Since human
assessment is costly from multiple points of view, automatic approaches to MCQ
item difficulty estimation are investigated, yielding however mixed success
until now. Our approach to this problem takes a different angle from previous
work: asking various Large Language Models to tackle the questions included in
three different MCQ datasets, we leverage model uncertainty to estimate item
difficulty. By using both model uncertainty features as well as textual
features in a Random Forest regressor, we show that uncertainty features
contribute substantially to difficulty prediction, where difficulty is
inversely proportional to the number of students who can correctly answer a
question. In addition to showing the value of our approach, we also observe
that our model achieves state-of-the-art results on the USMLE and CMCQRD
publicly available datasets.",2024-12-16,"Leonidas Zotos, Hedderik van Rijn, Malvina Nissim",http://arxiv.org/pdf/2412.11831v2,cs.CL
Advancements and Challenges in Bangla Question Answering Models: A Comprehensive Review,"The domain of Natural Language Processing (NLP) has experienced notable
progress in the evolution of Bangla Question Answering (QA) systems. This paper
presents a comprehensive review of seven research articles that contribute to
the progress in this domain. These research studies explore different aspects
of creating question-answering systems for the Bangla language. They cover
areas like collecting data, preparing it for analysis, designing models,
conducting experiments, and interpreting results. The papers introduce
innovative methods like using LSTM-based models with attention mechanisms,
context-based QA systems, and deep learning techniques based on prior
knowledge. However, despite the progress made, several challenges remain,
including the lack of well-annotated data, the absence of high-quality reading
comprehension datasets, and difficulties in understanding the meaning of words
in context. Bangla QA models' precision and applicability are constrained by
these challenges. This review emphasizes the significance of these research
contributions by highlighting the developments achieved in creating Bangla QA
systems as well as the ongoing effort required to get past roadblocks and
improve the performance of these systems for actual language comprehension
tasks.",2024-12-16,"Md Iftekhar Islam Tashik, Abdullah Khondoker, Enam Ahmed Taufik, Antara Firoz Parsa, S M Ishtiak Mahmud",http://arxiv.org/pdf/2412.11823v1,cs.CL
GLARE: Google Apps Arabic Reviews Dataset,"This paper introduces GLARE an Arabic Apps Reviews dataset collected from
Saudi Google PlayStore. It consists of 76M reviews, 69M of which are Arabic
reviews of 9,980 Android Applications. We present the data collection
methodology, along with a detailed Exploratory Data Analysis (EDA) and Feature
Engineering on the gathered reviews. We also highlight possible use cases and
benefits of the dataset.",2024-12-16,"Fatima AlGhamdi, Reem Mohammed, Hend Al-Khalifa, Areeb Alowisheq",http://arxiv.org/pdf/2412.15259v1,cs.CL
EventSum: A Large-Scale Event-Centric Summarization Dataset for Chinese Multi-News Documents,"In real life, many dynamic events, such as major disasters and large-scale
sports events, evolve continuously over time. Obtaining an overview of these
events can help people quickly understand the situation and respond more
effectively. This is challenging because the key information of the event is
often scattered across multiple documents, involving complex event knowledge
understanding and reasoning, which is under-explored in previous work.
Therefore, we proposed the Event-Centric Multi-Document Summarization (ECS)
task, which aims to generate concise and comprehensive summaries of a given
event based on multiple related news documents. Based on this, we constructed
the EventSum dataset, which was constructed using Baidu Baike entries and
underwent extensive human annotation, to facilitate relevant research. It is
the first large scale Chinese multi-document summarization dataset, containing
5,100 events and a total of 57,984 news documents, with an average of 11.4
input news documents and 13,471 characters per event. To ensure data quality
and mitigate potential data leakage, we adopted a multi-stage annotation
approach for manually labeling the test set. Given the complexity of
event-related information, existing metrics struggle to comprehensively assess
the quality of generated summaries. We designed specific metrics including
Event Recall, Argument Recall, Causal Recall, and Temporal Recall along with
corresponding calculation methods for evaluation. We conducted comprehensive
experiments on EventSum to evaluate the performance of advanced long-context
Large Language Models (LLMs) on this task. Our experimental results indicate
that: 1) The event-centric multi-document summarization task remains
challenging for existing long-context LLMs; 2) The recall metrics we designed
are crucial for evaluating the comprehensiveness of the summary information.",2024-12-16,"Mengna Zhu, Kaisheng Zeng, Mao Wang, Kaiming Xiao, Lei Hou, Hongbin Huang, Juanzi Li",http://arxiv.org/pdf/2412.11814v2,cs.CL
UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models,"Despite demonstrating impressive capabilities, Large Language Models (LLMs)
still often struggle to accurately express the factual knowledge they possess,
especially in cases where the LLMs' knowledge boundaries are ambiguous. To
improve LLMs' factual expressions, we propose the UAlign framework, which
leverages Uncertainty estimations to represent knowledge boundaries, and then
explicitly incorporates these representations as input features into prompts
for LLMs to Align with factual knowledge. First, we prepare the dataset on
knowledge question-answering (QA) samples by calculating two uncertainty
estimations, including confidence score and semantic entropy, to represent the
knowledge boundaries for LLMs. Subsequently, using the prepared dataset, we
train a reward model that incorporates uncertainty estimations and then employ
the Proximal Policy Optimization (PPO) algorithm for factuality alignment on
LLMs. Experimental results indicate that, by integrating uncertainty
representations in LLM alignment, the proposed UAlign can significantly enhance
the LLMs' capacities to confidently answer known questions and refuse unknown
questions on both in-domain and out-of-domain tasks, showing reliability
improvements and good generalizability over various prompt- and training-based
baselines.",2024-12-16,"Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong",http://arxiv.org/pdf/2412.11803v2,cs.CL
ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible Speech Synthesis,"Prosody contains rich information beyond the literal meaning of words, which
is crucial for the intelligibility of speech. Current models still fall short
in phrasing and intonation; they not only miss or misplace breaks when
synthesizing long sentences with complex structures but also produce unnatural
intonation. We propose ProsodyFM, a prosody-aware text-to-speech synthesis
(TTS) model with a flow-matching (FM) backbone that aims to enhance the
phrasing and intonation aspects of prosody. ProsodyFM introduces two key
components: a Phrase Break Encoder to capture initial phrase break locations,
followed by a Duration Predictor for the flexible adjustment of break
durations; and a Terminal Intonation Encoder which learns a bank of intonation
shape tokens combined with a novel Pitch Processor for more robust modeling of
human-perceived intonation change. ProsodyFM is trained with no explicit
prosodic labels and yet can uncover a broad spectrum of break durations and
intonation patterns. Experimental results demonstrate that ProsodyFM can
effectively improve the phrasing and intonation aspects of prosody, thereby
enhancing the overall intelligibility compared to four state-of-the-art (SOTA)
models. Out-of-distribution experiments show that this prosody improvement can
further bring ProsodyFM superior generalizability for unseen complex sentences
and speakers. Our case study intuitively illustrates the powerful and
fine-grained controllability of ProsodyFM over phrasing and intonation.",2024-12-16,"Xiangheng He, Junjie Chen, Zixing Zhang, Björn W. Schuller",http://arxiv.org/pdf/2412.11795v2,cs.CL
A Method for Detecting Legal Article Competition for Korean Criminal Law Using a Case-augmented Mention Graph,"As social systems become increasingly complex, legal articles are also
growing more intricate, making it progressively harder for humans to identify
any potential competitions among them, particularly when drafting new laws or
applying existing laws. Despite this challenge, no method for detecting such
competitions has been proposed so far. In this paper, we propose a new legal AI
task called Legal Article Competition Detection (LACD), which aims to identify
competing articles within a given law. Our novel retrieval method, CAM-Re2,
outperforms existing relevant methods, reducing false positives by 20.8% and
false negatives by 8.3%, while achieving a 98.2% improvement in precision@5,
for the LACD task. We release our codes at
https://github.com/asmath472/LACD-public.",2024-12-16,"Seonho An, Young Yik Rhim, Min-Soo Kim",http://arxiv.org/pdf/2412.11787v1,cs.CL
The Three Social Dimensions of Chatbot Technology,"The development and deployment of chatbot technology, while spanning decades
and employing different techniques, require innovative frameworks to understand
and interrogate their functionality and implications. A mere technocentric
account of the evolution of chatbot technology does not fully illuminate how
conversational systems are embedded in societal dynamics. This study presents a
structured examination of chatbots across three societal dimensions,
highlighting their roles as objects of scientific research, commercial
instruments, and agents of intimate interaction. Through furnishing a
dimensional framework for the evolution of conversational systems, from
laboratories to marketplaces to private lives, this article contributes to the
wider scholarly inquiry of chatbot technology and its impact in lived human
experiences and dynamics.",2024-12-16,Mauricio Figueroa-Torres,http://arxiv.org/pdf/2501.10377v1,cs.CL
QUENCH: Measuring the gap between Indic and Non-Indic Contextual General Reasoning in LLMs,"The rise of large language models (LLMs) has created a need for advanced
benchmarking systems beyond traditional setups. To this end, we introduce
QUENCH, a novel text-based English Quizzing Benchmark manually curated and
transcribed from YouTube quiz videos. QUENCH possesses masked entities and
rationales for the LLMs to predict via generation. At the intersection of
geographical context and common sense reasoning, QUENCH helps assess world
knowledge and deduction capabilities of LLMs via a zero-shot, open-domain
quizzing setup. We perform an extensive evaluation on 7 LLMs and 4 metrics,
investigating the influence of model size, prompting style, geographical
context, and gold-labeled rationale generation. The benchmarking concludes with
an error analysis to which the LLMs are prone.",2024-12-16,"Mohammad Aflah Khan, Neemesh Yadav, Sarah Masud, Md. Shad Akhtar",http://arxiv.org/pdf/2412.11763v1,cs.CL
SCITAT: A Question Answering Benchmark for Scientific Tables and Text Covering Diverse Reasoning Types,"Scientific question answering (SQA) is an important task aimed at answering
questions based on papers. However, current SQA datasets have limited reasoning
types and neglect the relevance between tables and text, creating a significant
gap with real scenarios. To address these challenges, we propose a QA benchmark
for scientific tables and text with diverse reasoning types (SciTaT). To cover
more reasoning types, we summarize various reasoning types from real-world
questions. To involve both tables and text, we require the questions to
incorporate tables and text as much as possible. Based on SciTaT, we propose a
strong baseline (CaR), which combines various reasoning methods to address
different reasoning types and process tables and text at the same time. CaR
brings average improvements of 12.9% over other baselines on SciTaT, validating
its effectiveness. Error analysis reveals the challenges of SciTaT, such as
complex numerical calculations and domain knowledge.",2024-12-16,"Xuanliang Zhang, Dingzirui Wang, Baoxin Wang, Longxu Dou, Xinyuan Lu, Keyan Xu, Dayong Wu, Qingfu Zhu, Wanxiang Che",http://arxiv.org/pdf/2412.11757v1,cs.CL
"Common Ground, Diverse Roots: The Difficulty of Classifying Common Examples in Spanish Varieties","Variations in languages across geographic regions or cultures are crucial to
address to avoid biases in NLP systems designed for culturally sensitive tasks,
such as hate speech detection or dialog with conversational agents. In
languages such as Spanish, where varieties can significantly overlap, many
examples can be valid across them, which we refer to as common examples.
Ignoring these examples may cause misclassifications, reducing model accuracy
and fairness. Therefore, accounting for these common examples is essential to
improve the robustness and representativeness of NLP systems trained on such
data. In this work, we address this problem in the context of Spanish
varieties. We use training dynamics to automatically detect common examples or
errors in existing Spanish datasets. We demonstrate the efficacy of using
predicted label confidence for our Datamaps
\cite{swayamdipta-etal-2020-dataset} implementation for the identification of
hard-to-classify examples, especially common examples, enhancing model
performance in variety identification tasks. Additionally, we introduce a Cuban
Spanish Variety Identification dataset with common examples annotations
developed to facilitate more accurate detection of Cuban and Caribbean Spanish
varieties. To our knowledge, this is the first dataset focused on identifying
the Cuban, or any other Caribbean, Spanish variety.",2024-12-16,"Javier A. Lopetegui, Arij Riabi, Djamé Seddah",http://arxiv.org/pdf/2412.11750v1,cs.CL
Beyond Dataset Creation: Critical View of Annotation Variation and Bias Probing of a Dataset for Online Radical Content Detection,"The proliferation of radical content on online platforms poses significant
risks, including inciting violence and spreading extremist ideologies. Despite
ongoing research, existing datasets and models often fail to address the
complexities of multilingual and diverse data. To bridge this gap, we introduce
a publicly available multilingual dataset annotated with radicalization levels,
calls for action, and named entities in English, French, and Arabic. This
dataset is pseudonymized to protect individual privacy while preserving
contextual information. Beyond presenting our freely available dataset, we
analyze the annotation process, highlighting biases and disagreements among
annotators and their implications for model performance. Additionally, we use
synthetic data to investigate the influence of socio-demographic traits on
annotation patterns and model predictions. Our work offers a comprehensive
examination of the challenges and opportunities in building robust datasets for
radical content detection, emphasizing the importance of fairness and
transparency in model development.",2024-12-16,"Arij Riabi, Virginie Mouilleron, Menel Mahamdi, Wissam Antoun, Djamé Seddah",http://arxiv.org/pdf/2412.11745v2,cs.CL
CSR:Achieving 1 Bit Key-Value Cache via Sparse Representation,"The emergence of long-context text applications utilizing large language
models (LLMs) has presented significant scalability challenges, particularly in
memory footprint. The linear growth of the Key-Value (KV) cache responsible for
storing attention keys and values to minimize redundant computations can lead
to substantial increases in memory consumption, potentially causing models to
fail to serve with limited memory resources. To address this issue, we propose
a novel approach called Cache Sparse Representation (CSR), which converts the
KV cache by transforming the dense Key-Value cache tensor into sparse indexes
and weights, offering a more memory-efficient representation during LLM
inference. Furthermore, we introduce NeuralDict, a novel neural network-based
method for automatically generating the dictionary used in our sparse
representation. Our extensive experiments demonstrate that CSR achieves
performance comparable to state-of-the-art KV cache quantization algorithms
while maintaining robust functionality in memory-constrained environments.",2024-12-16,"Hongxuan Zhang, Yao Zhao, Jiaqi Zheng, Chenyi Zhuang, Jinjie Gu, Guihai Chen",http://arxiv.org/pdf/2412.11741v1,cs.CL
Personalized LLM for Generating Customized Responses to the Same Query from Different Users,"Existing work on large language model (LLM) personalization assigned
different responding roles to LLM, but overlooked the diversity of questioners.
In this work, we propose a new form of questioner-aware LLM personalization,
generating different responses even for the same query from different
questioners. We design a dual-tower model architecture with a cross-questioner
general encoder and a questioner-specific encoder. We further apply contrastive
learning with multi-view augmentation, pulling close the dialogue
representations of the same questioner, while pulling apart those of different
questioners. To mitigate the impact of question diversity on
questioner-contrastive learning, we cluster the dialogues based on question
similarity and restrict the scope of contrastive learning within each cluster.
We also build a multi-questioner dataset from English and Chinese scripts and
WeChat records, called MQDialog, containing 173 questioners and 12 responders.
Extensive evaluation with different metrics shows a significant improvement in
the quality of personalized response generation.",2024-12-16,"Hang Zeng, Chaoyue Niu, Fan Wu, Chengfei Lv, Guihai Chen",http://arxiv.org/pdf/2412.11736v1,cs.CL
Findings of the WMT 2024 Shared Task on Discourse-Level Literary Translation,"Following last year, we have continued to host the WMT translation shared
task this year, the second edition of the Discourse-Level Literary Translation.
We focus on three language directions: Chinese-English, Chinese-German, and
Chinese-Russian, with the latter two ones newly added. This year, we totally
received 10 submissions from 5 academia and industry teams. We employ both
automatic and human evaluations to measure the performance of the submitted
systems. The official ranking of the systems is based on the overall human
judgments. We release data, system outputs, and leaderboard at
https://www2.statmt.org/wmt24/literary-translation-task.html.",2024-12-16,"Longyue Wang, Siyou Liu, Chenyang Lyu, Wenxiang Jiao, Xing Wang, Jiahao Xu, Zhaopeng Tu, Yan Gu, Weiyu Chen, Minghao Wu, Liting Zhou, Philipp Koehn, Andy Way, Yulin Yuan",http://arxiv.org/pdf/2412.11732v1,cs.CL
LLMs Can Simulate Standardized Patients via Agent Coevolution,"Training medical personnel using standardized patients (SPs) remains a
complex challenge, requiring extensive domain expertise and role-specific
practice. Most research on Large Language Model (LLM)-based simulated patients
focuses on improving data retrieval accuracy or adjusting prompts through human
feedback. However, this focus has overlooked the critical need for patient
agents to learn a standardized presentation pattern that transforms data into
human-like patient responses through unsupervised simulations. To address this
gap, we propose EvoPatient, a novel simulated patient framework in which a
patient agent and doctor agents simulate the diagnostic process through
multi-turn dialogues, simultaneously gathering experience to improve the
quality of both questions and answers, ultimately enabling human doctor
training. Extensive experiments on various cases demonstrate that, by providing
only overall SP requirements, our framework improves over existing reasoning
methods by more than 10% in requirement alignment and better human preference,
while achieving an optimal balance of resource consumption after evolving over
200 cases for 10 hours, with excellent generalizability. The code will be
available at https://github.com/ZJUMAI/EvoPatient.",2024-12-16,"Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haohao Ying",http://arxiv.org/pdf/2412.11716v1,cs.CL
Seeker: Towards Exception Safety Code Generation with Intermediate Language Agents Framework,"In real world software development, improper or missing exception handling
can severely impact the robustness and reliability of code. Exception handling
mechanisms require developers to detect, capture, and manage exceptions
according to high standards, but many developers struggle with these tasks,
leading to fragile code. This problem is particularly evident in open-source
projects and impacts the overall quality of the software ecosystem. To address
this challenge, we explore the use of large language models (LLMs) to improve
exception handling in code. Through extensive analysis, we identify three key
issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception
Block, and Distorted Handling Solution. These problems are widespread across
real world repositories, suggesting that robust exception handling practices
are often overlooked or mishandled. In response, we propose Seeker, a
multi-agent framework inspired by expert developer strategies for exception
handling. Seeker uses agents: Scanner, Detector, Predator, Ranker, and Handler
to assist LLMs in detecting, capturing, and resolving exceptions more
effectively. Our work is the first systematic study on leveraging LLMs to
enhance exception handling practices in real development scenarios, providing
valuable insights for future improvements in code reliability.",2024-12-16,"Xuanming Zhang, Yuxuan Chen, Yiming Zheng, Zhexin Zhang, Yuan Yuan, Minlie Huang",http://arxiv.org/pdf/2412.11713v1,cs.CL
MiMoTable: A Multi-scale Spreadsheet Benchmark with Meta Operations for Table Reasoning,"Extensive research has been conducted to explore the capability of Large
Language Models (LLMs) for table reasoning and has significantly improved the
performance on existing benchmarks. However, tables and user questions in
real-world applications are more complex and diverse, presenting an unignorable
gap compared to the existing benchmarks. To fill the gap, we propose a
\textbf{M}ult\textbf{i}-scale spreadsheet benchmark with \textbf{M}eta
\textbf{o}perations for \textbf{Table} reasoning, named as MiMoTable.
Specifically, MiMoTable incorporates two key features. First, the tables in
MiMoTable are all spreadsheets used in real-world scenarios, which cover seven
domains and contain different types. Second, we define a new criterion with six
categories of meta operations for measuring the difficulty of each question in
MiMoTable, simultaneously as a new perspective for measuring the difficulty of
the existing benchmarks. Experimental results show that Claude-3.5-Sonnet
achieves the best performance with 77.4\% accuracy, indicating that there is
still significant room to improve for LLMs on MiMoTable. Furthermore, we grade
the difficulty of existing benchmarks according to our new criteria.
Experiments have shown that the performance of LLMs decreases as the difficulty
of benchmarks increases, thereby proving the effectiveness of our proposed new
criterion.",2024-12-16,"Zheng Li, Yang Du, Mao Zheng, Mingyang Song",http://arxiv.org/pdf/2412.11711v2,cs.CL
Context Filtering with Reward Modeling in Question Answering,"Question Answering (QA) in NLP is the task of finding answers to a query
within a relevant context retrieved by a retrieval system. Yet, the mix of
relevant and irrelevant information in these contexts can hinder performance
enhancements in QA tasks. To address this, we introduce a context filtering
approach that removes non-essential details, summarizing crucial content
through Reward Modeling. This method emphasizes keeping vital data while
omitting the extraneous during summarization model training. We offer a
framework for developing efficient QA models by discerning useful information
from dataset pairs, bypassing the need for costly human evaluation.
Furthermore, we show that our approach can significantly outperform the
baseline, as evidenced by a 6.8-fold increase in the EM Per Token (EPT) metric,
which we propose as a measure of token efficiency, indicating a notable
token-efficiency boost for low-resource settings.",2024-12-16,"Sangryul Kim, James Thorne",http://arxiv.org/pdf/2412.11707v1,cs.CL
ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data,"Vocabulary expansion (VE) is the de-facto approach to language adaptation of
large language models (LLMs) by adding new tokens and continuing pre-training
on target data. While this is effective for base models trained on unlabeled
data, it poses challenges for chat models trained to follow instructions
through labeled conversation data. Directly adapting the latter with VE on
target unlabeled data may result in forgetting chat abilities. While ideal,
target chat data is often unavailable or costly to create for low-resource
languages, and machine-translated alternatives are not always effective. To
address this issue, previous work proposed using a base and chat model from the
same family. This method first adapts the base LLM with VE on target unlabeled
data and then converts it to a chat model by adding a chat vector (CV) derived
from the weight difference between the source base and chat models. We propose
ElChat, a new language adaptation method for chat LLMs that adapts a chat model
directly on target unlabeled data, without a base model. It elicits chat
abilities by injecting information from the source chat model. ElChat offers
more robust and competitive target language and safety performance while
achieving superior English, chat, and instruction-following abilities compared
to CV.",2024-12-16,"Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras",http://arxiv.org/pdf/2412.11704v3,cs.CL
CoinMath: Harnessing the Power of Coding Instruction for Math LLMs,"Large Language Models (LLMs) have shown strong performance in solving
mathematical problems, with code-based solutions proving particularly
effective. However, the best practice to leverage coding instruction data to
enhance mathematical reasoning remains underexplored. This study investigates
three key questions: (1) How do different coding styles of mathematical
code-based rationales impact LLMs' learning performance? (2) Can general-domain
coding instructions improve performance? (3) How does integrating textual
rationales with code-based ones during training enhance mathematical reasoning
abilities? Our findings reveal that code-based rationales with concise
comments, descriptive naming, and hardcoded solutions are beneficial, while
improvements from general-domain coding instructions and textual rationales are
relatively minor. Based on these insights, we propose CoinMath, a learning
strategy designed to enhance mathematical reasoning by diversifying the coding
styles of code-based rationales. CoinMath generates a variety of code-based
rationales incorporating concise comments, descriptive naming conventions, and
hardcoded solutions. Experimental results demonstrate that CoinMath
significantly outperforms its baseline model, MAmmoTH, one of the SOTA math
LLMs.",2024-12-16,"Chengwei Wei, Bin Wang, Jung-jae Kim, Guimei Liu, Nancy F. Chen",http://arxiv.org/pdf/2412.11699v1,cs.CL
From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities,"To tackle complex tasks in real-world scenarios, more researchers are
focusing on Omni-MLLMs, which aim to achieve omni-modal understanding and
generation. Beyond the constraints of any specific non-linguistic modality,
Omni-MLLMs map various non-linguistic modalities into the embedding space of
LLMs and enable the interaction and understanding of arbitrary combinations of
modalities within a single model. In this paper, we systematically investigate
relevant research and provide a comprehensive survey of Omni-MLLMs.
Specifically, we first explain the four core components of Omni-MLLMs for
unified multi-modal modeling with a meticulous taxonomy that offers novel
perspectives. Then, we introduce the effective integration achieved through
two-stage training and discuss the corresponding datasets as well as
evaluation. Furthermore, we summarize the main challenges of current Omni-MLLMs
and outline future directions. We hope this paper serves as an introduction for
beginners and promotes the advancement of related research. Resources have been
made publicly available at https://github.com/threegold116/Awesome-Omni-MLLMs.",2024-12-16,"Shixin Jiang, Jiafeng Liang, Jiyuan Wang, Xuan Dong, Heng Chang, Weijiang Yu, Jinhua Du, Ming Liu, Bing Qin",http://arxiv.org/pdf/2412.11694v3,cs.CL
Multilingual and Explainable Text Detoxification with Parallel Corpora,"Even with various regulations in place across countries and social media
platforms (Government of India, 2021; European Parliament and Council of the
European Union, 2022, digital abusive speech remains a significant issue. One
potential approach to address this challenge is automatic text detoxification,
a text style transfer (TST) approach that transforms toxic language into a more
neutral or non-toxic form. To date, the availability of parallel corpora for
the text detoxification task (Logachevavet al., 2022; Atwell et al., 2022;
Dementievavet al., 2024a) has proven to be crucial for state-of-the-art
approaches. With this work, we extend parallel text detoxification corpus to
new languages -- German, Chinese, Arabic, Hindi, and Amharic -- testing in the
extensive multilingual setup TST baselines. Next, we conduct the first of its
kind an automated, explainable analysis of the descriptive features of both
toxic and non-toxic sentences, diving deeply into the nuances, similarities,
and differences of toxicity and detoxification across 9 languages. Finally,
based on the obtained insights, we experiment with a novel text detoxification
method inspired by the Chain-of-Thoughts reasoning approach, enhancing the
prompting process through clustering on relevant descriptive attributes.",2024-12-16,"Daryna Dementieva, Nikolay Babakov, Amit Ronen, Abinew Ali Ayele, Naquee Rizwan, Florian Schneider, Xintong Wang, Seid Muhie Yimam, Daniil Moskovskiy, Elisei Stakovskii, Eran Kaufman, Ashraf Elnagar, Animesh Mukherjee, Alexander Panchenko",http://arxiv.org/pdf/2412.11691v1,cs.CL
DisEmbed: Transforming Disease Understanding through Embeddings,"The medical domain is vast and diverse, with many existing embedding models
focused on general healthcare applications. However, these models often
struggle to capture a deep understanding of diseases due to their broad
generalization across the entire medical field. To address this gap, I present
DisEmbed, a disease-focused embedding model. DisEmbed is trained on a synthetic
dataset specifically curated to include disease descriptions, symptoms, and
disease-related Q\&A pairs, making it uniquely suited for disease-related
tasks. For evaluation, I benchmarked DisEmbed against existing medical models
using disease-specific datasets and the triplet evaluation method. My results
demonstrate that DisEmbed outperforms other models, particularly in identifying
disease-related contexts and distinguishing between similar diseases. This
makes DisEmbed highly valuable for disease-specific use cases, including
retrieval-augmented generation (RAG) tasks, where its performance is
particularly robust.",2024-12-16,Salman Faroz,http://arxiv.org/pdf/2412.15258v1,cs.CL
Bias Vector: Mitigating Biases in Language Models with Task Arithmetic Approach,"The use of language models (LMs) has increased considerably in recent years,
and the biases and stereotypes in training data that are reflected in the LM
outputs are causing social problems. In this paper, inspired by the task
arithmetic, we propose the ``Bias Vector'' method for the mitigation of these
LM biases. The Bias Vector method does not require manually created debiasing
data. The three main steps of our approach involve: (1) continual training the
pre-trained LMs on biased data using masked language modeling; (2) constructing
the Bias Vector as the difference between the weights of the biased LMs and
those of pre-trained LMs; and (3) subtracting the Bias Vector from the weights
of the pre-trained LMs for debiasing. We evaluated the Bias Vector method on
the SEAT across three LMs and confirmed an average improvement of 0.177 points.
We demonstrated that the Bias Vector method does not degrade the LM performance
on downstream tasks in the GLUE benchmark. In addition, we examined the impact
of scaling factors, which control the magnitudes of Bias Vectors, with effect
sizes on the SEAT and conducted a comprehensive evaluation of our debiased LMs
across both the SEAT and GLUE benchmarks.",2024-12-16,"Daiki Shirafuji, Makoto Takenaka, Shinya Taguchi",http://arxiv.org/pdf/2412.11679v1,cs.CL
BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR,"Pediatric Emergency Department (PED) overcrowding presents a significant
global challenge, prompting the need for efficient solutions. This paper
introduces the BioBridge framework, a novel approach that applies Natural
Language Processing (NLP) to Electronic Medical Records (EMRs) in written
free-text form to enhance decision-making in PED. In non-English speaking
countries, such as South Korea, EMR data is often written in a Code-Switching
(CS) format that mixes the native language with English, with most
code-switched English words having clinical significance. The BioBridge
framework consists of two core modules: ""bridging modality in context"" and
""unified bio-embedding."" The ""bridging modality in context"" module improves the
contextual understanding of bilingual and code-switched EMRs. In the ""unified
bio-embedding"" module, the knowledge of the model trained in the medical domain
is injected into the encoder-based model to bridge the gap between the medical
and general domains. Experimental results demonstrate that the proposed
BioBridge significantly performance traditional machine learning and
pre-trained encoder-based models on several metrics, including F1 score, area
under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM
achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,
along with a notable 3.04% decrease in the Brier score, demonstrating marked
improvements in accuracy, reliability, and prediction calibration over the
baseline XLM model. The source code will be made publicly available.",2024-12-16,"Jangyeong Jeon, Sangyeon Cho, Dongjoon Lee, Changhee Lee, Junyeong Kim",http://arxiv.org/pdf/2412.11671v1,cs.CL
C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness,"Generating Chain-of-Thought (CoT) before deriving the answer can effectively
improve the reasoning capabilities of large language models (LLMs) and
significantly improve the accuracy of the generated answer. However, in most
cases, the length of the generated CoT is much longer than the desired final
answer, which results in additional decoding costs. Furthermore, existing
research has discovered that shortening the reasoning steps in CoT, even while
preserving the key information, diminishes LLMs' abilities. These phenomena
make it difficult to use LLMs and CoT in many real-world applications that only
require the final answer and are sensitive to latency, such as search and
recommendation. To reduce the costs of model decoding and shorten the length of
the generated CoT, this paper presents $\textbf{C}$onditioned
$\textbf{C}$ompressed $\textbf{C}$hain-of-$\textbf{T}$hought (C3oT), a CoT
compression framework that involves a compressor to compress an original longer
CoT into a shorter CoT while maintaining key information and interpretability,
a conditioned training method to train LLMs with both longer CoT and shorter
CoT simultaneously to learn the corresponding relationships between them, and a
conditioned inference method to gain the reasoning ability learned from longer
CoT by generating shorter CoT. We conduct experiments over four datasets from
arithmetic and commonsense scenarios, showing that the proposed method is
capable of compressing the length of generated CoT by up to more than 50%
without compromising its effectiveness.",2024-12-16,"Yu Kang, Xianghui Sun, Liangyu Chen, Wei Zou",http://arxiv.org/pdf/2412.11664v1,cs.CL
Self-Adaptive Paraphrasing and Preference Learning for Improved Claim Verifiability,"In fact-checking, structure and phrasing of claims critically influence a
model's ability to predict verdicts accurately. Social media content in
particular rarely serves as optimal input for verification systems, which
necessitates pre-processing to extract the claim from noisy context before fact
checking. Prior work suggests extracting a claim representation that humans
find to be checkworthy and verifiable. This has two limitations: (1) the format
may not be optimal for a fact-checking model, and (2), it requires annotated
data to learn the extraction task from. We address both issues and propose a
method to extract claims that is not reliant on labeled training data. Instead,
our self-adaptive approach only requires a black-box fact checking model and a
generative language model (LM). Given a tweet, we iteratively optimize the LM
to generate a claim paraphrase that increases the performance of a fact
checking model. By learning from preference pairs, we align the LM to the fact
checker using direct preference optimization. We show that this novel setup
extracts a claim paraphrase that is more verifiable than their original social
media formulations, and is on par with competitive baselines. For refuted
claims, our method consistently outperforms all baselines.",2024-12-16,"Amelie Wührl, Roman Klinger",http://arxiv.org/pdf/2412.11653v1,cs.CL
SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation,"Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.",2024-12-16,"Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li",http://arxiv.org/pdf/2412.11652v1,cs.CL
On Crowdsourcing Task Design for Discourse Relation Annotation,"Interpreting implicit discourse relations involves complex reasoning,
requiring the integration of semantic cues with background knowledge, as overt
connectives like because or then are absent. These relations often allow
multiple interpretations, best represented as distributions. In this study, we
compare two established methods that crowdsource English implicit discourse
relation annotation by connective insertion: a free-choice approach, which
allows annotators to select any suitable connective, and a forced-choice
approach, which asks them to select among a set of predefined options.
Specifically, we re-annotate the whole DiscoGeM 1.0 corpus -- initially
annotated with the free-choice method -- using the forced-choice approach. The
free-choice approach allows for flexible and intuitive insertion of various
connectives, which are context-dependent. Comparison among over 130,000
annotations, however, shows that the free-choice strategy produces less diverse
annotations, often converging on common labels. Analysis of the results reveals
the interplay between task design and the annotators' abilities to interpret
and produce discourse relations.",2024-12-16,"Frances Yung, Vera Demberg",http://arxiv.org/pdf/2412.11637v1,cs.CL
"Fool Me, Fool Me: User Attitudes Toward LLM Falsehoods","While Large Language Models (LLMs) have become central tools in various
fields, they often provide inaccurate or false information. This study examines
user preferences regarding falsehood responses from LLMs. Specifically, we
evaluate preferences for LLM responses where false statements are explicitly
marked versus unmarked responses and preferences for confident falsehoods
compared to LLM disclaimers acknowledging a lack of knowledge. Additionally, we
investigate how requiring users to assess the truthfulness of statements
influences these preferences.
  Surprisingly, 61\% of users prefer unmarked falsehood responses over marked
ones, and 69\% prefer confident falsehoods over LLMs admitting lack of
knowledge. In all our experiments, a total of 300 users participated,
contributing valuable data to our analysis and conclusions. When users are
required to evaluate the truthfulness of statements, preferences for unmarked
and falsehood responses decrease slightly but remain high. These findings
suggest that user preferences, which influence LLM training via feedback
mechanisms, may inadvertently encourage the generation of falsehoods. Future
research should address the ethical and practical implications of aligning LLM
behavior with such preferences.",2024-12-16,"Diana Bar-Or Nirman, Ariel Weizman, Amos Azaria",http://arxiv.org/pdf/2412.11625v1,cs.CL
DLF: Disentangled-Language-Focused Multimodal Sentiment Analysis,"Multimodal Sentiment Analysis (MSA) leverages heterogeneous modalities, such
as language, vision, and audio, to enhance the understanding of human
sentiment. While existing models often focus on extracting shared information
across modalities or directly fusing heterogeneous modalities, such approaches
can introduce redundancy and conflicts due to equal treatment of all modalities
and the mutual transfer of information between modality pairs. To address these
issues, we propose a Disentangled-Language-Focused (DLF) multimodal
representation learning framework, which incorporates a feature disentanglement
module to separate modality-shared and modality-specific information. To
further reduce redundancy and enhance language-targeted features, four
geometric measures are introduced to refine the disentanglement process. A
Language-Focused Attractor (LFA) is further developed to strengthen language
representation by leveraging complementary modality-specific information
through a language-guided cross-attention mechanism. The framework also employs
hierarchical predictions to improve overall accuracy. Extensive experiments on
two popular MSA datasets, CMU-MOSI and CMU-MOSEI, demonstrate the significant
performance gains achieved by the proposed DLF framework. Comprehensive
ablation studies further validate the effectiveness of the feature
disentanglement module, language-focused attractor, and hierarchical
predictions. Our code is available at https://github.com/pwang322/DLF.",2024-12-16,"Pan Wang, Qiang Zhou, Yawen Wu, Tianlong Chen, Jingtong Hu",http://arxiv.org/pdf/2412.12225v3,cs.CL
MT-LENS: An all-in-one Toolkit for Better Machine Translation Evaluation,"We introduce MT-LENS, a framework designed to evaluate Machine Translation
(MT) systems across a variety of tasks, including translation quality, gender
bias detection, added toxicity, and robustness to misspellings. While several
toolkits have become very popular for benchmarking the capabilities of Large
Language Models (LLMs), existing evaluation tools often lack the ability to
thoroughly assess the diverse aspects of MT performance. MT-LENS addresses
these limitations by extending the capabilities of LM-eval-harness for MT,
supporting state-of-the-art datasets and a wide range of evaluation metrics. It
also offers a user-friendly platform to compare systems and analyze
translations with interactive visualizations. MT-LENS aims to broaden access to
evaluation strategies that go beyond traditional translation quality
evaluation, enabling researchers and engineers to better understand the
performance of a NMT model and also easily measure system's biases.",2024-12-16,"Javier García Gilabert, Carlos Escolano, Audrey Mash, Xixian Liao, Maite Melero",http://arxiv.org/pdf/2412.11615v1,cs.CL
SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models,"Instruction-following is a fundamental capability of language models,
requiring the model to recognize even the most subtle requirements in the
instructions and accurately reflect them in its output. Such an ability is
well-suited for and often optimized by preference learning. However, existing
methods often directly sample multiple independent responses from the model
when creating preference pairs. Such practice can introduce content variations
irrelevant to whether the instruction is precisely followed (e.g., different
expressions about the same semantic), interfering with the goal of teaching
models to recognize the key differences that lead to improved instruction
following. In light of this, we introduce SPaR, a self-play framework
integrating tree-search self-refinement to yield valid and comparable
preference pairs free from distractions. By playing against itself, an LLM
employs a tree-search strategy to refine its previous responses with respect to
the instruction while minimizing unnecessary variations. Our experiments show
that a LLaMA3-8B model, trained over three iterations guided by SPaR, surpasses
GPT-4-Turbo on the IFEval benchmark without losing general capabilities.
Furthermore, SPaR demonstrates promising scalability, greatly enhancing models
like GLM-4-9B and LLaMA3-70B. We also identify how inference scaling in tree
search would impact model performance. Our code and data are publicly available
at https://github.com/thu-coai/SPaR.",2024-12-16,"Jiale Cheng, Xiao Liu, Cunxiang Wang, Xiaotao Gu, Yida Lu, Dan Zhang, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang",http://arxiv.org/pdf/2412.11605v2,cs.CL
An Incremental Clustering Baseline for Event Detection on Twitter,"Event detection in text streams is a crucial task for the analysis of online
media and social networks. One of the current challenges in this field is
establishing a performance standard while maintaining an acceptable level of
computational complexity. In our study, we use an incremental clustering
algorithm combined with recent advancements in sentence embeddings. Our
objective is to compare our findings with previous studies, specifically those
by Cao et al. (2024) and Mazoyer et al. (2020). Our results demonstrate
significant improvements and could serve as a relevant baseline for future
research in this area.",2024-12-16,"Marjolaine Ray, Qi Wang, Frédérique Mélanie-Becquet, Thierry Poibeau, Béatrice Mazoyer",http://arxiv.org/pdf/2412.15257v1,cs.CL
AUEB-Archimedes at RIRAG-2025: Is obligation concatenation really all you need?,"This paper presents the systems we developed for RIRAG-2025, a shared task
that requires answering regulatory questions by retrieving relevant passages.
The generated answers are evaluated using RePASs, a reference-free and
model-based metric. Our systems use a combination of three retrieval models and
a reranker. We show that by exploiting a neural component of RePASs that
extracts important sentences ('obligations') from the retrieved passages, we
achieve a dubiously high score (0.947), even though the answers are directly
extracted from the retrieved passages and are not actually generated answers.
We then show that by selecting the answer with the best RePASs among a few
generated alternatives and then iteratively refining this answer by reducing
contradictions and covering more obligations, we can generate readable,
coherent answers that achieve a more plausible and relatively high score
(0.639).",2024-12-16,"Ioannis Chasandras, Odysseas S. Chlapanis, Ion Androutsopoulos",http://arxiv.org/pdf/2412.11567v1,cs.CL
The Role of Natural Language Processing Tasks in Automatic Literary Character Network Construction,"The automatic extraction of character networks from literary texts is
generally carried out using natural language processing (NLP) cascading
pipelines. While this approach is widespread, no study exists on the impact of
low-level NLP tasks on their performance. In this article, we conduct such a
study on a literary dataset, focusing on the role of named entity recognition
(NER) and coreference resolution when extracting co-occurrence networks. To
highlight the impact of these tasks' performance, we start with gold-standard
annotations, progressively add uniformly distributed errors, and observe their
impact in terms of character network quality. We demonstrate that NER
performance depends on the tested novel and strongly affects character
detection. We also show that NER-detected mentions alone miss a lot of
character co-occurrences, and that coreference resolution is needed to prevent
this. Finally, we present comparison points with 2 methods based on large
language models (LLMs), including a fully end-to-end one, and show that these
models are outperformed by traditional NLP pipelines in terms of recall.",2024-12-16,"Arthur Amalvy, Vincent Labatut, Richard Dufour",http://arxiv.org/pdf/2412.11560v1,cs.CL
Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs,"Extracting sentence embeddings from large language models (LLMs) is a
promising direction, as LLMs have demonstrated stronger semantic understanding
capabilities. Previous studies typically focus on prompt engineering to elicit
sentence embeddings from LLMs by prompting the model to encode sentence
information into the embedding of the last token. However, LLMs are mostly
decoder-only models with causal attention and the earlier tokens in the
sentence cannot attend to the latter tokens, resulting in biased encoding of
sentence information and cascading effects on the final decoded token. To this
end, we propose a novel Token Prepending (TP) technique that prepends each
layer's decoded sentence embedding to the beginning of the sentence in the next
layer's input, allowing earlier tokens to attend to the complete sentence
information under the causal attention mechanism. The proposed TP technique is
a plug-and-play and training-free technique, which means it can be seamlessly
integrated with various prompt-based sentence embedding methods and
autoregressive LLMs. Extensive experiments on various Semantic Textual
Similarity (STS) tasks and downstream classification tasks demonstrate that our
proposed TP technique can significantly improve the performance of existing
prompt-based sentence embedding methods across different LLMs, while incurring
negligible additional inference cost.",2024-12-16,"Yuchen Fu, Zifeng Cheng, Zhiwei Jiang, Zhonghui Wang, Yafeng Yin, Zhengliang Li, Qing Gu",http://arxiv.org/pdf/2412.11556v1,cs.CL
Error Diversity Matters: An Error-Resistant Ensemble Method for Unsupervised Dependency Parsing,"We address unsupervised dependency parsing by building an ensemble of diverse
existing models through post hoc aggregation of their output dependency parse
structures. We observe that these ensembles often suffer from low robustness
against weak ensemble components due to error accumulation. To tackle this
problem, we propose an efficient ensemble-selection approach that considers
error diversity and avoids error accumulation. Results demonstrate that our
approach outperforms each individual model as well as previous ensemble
techniques. Additionally, our experiments show that the proposed
ensemble-selection method significantly enhances the performance and robustness
of our ensemble, surpassing previously proposed strategies, which have not
accounted for error diversity.",2024-12-16,"Behzad Shayegh, Hobie H. -B. Lee, Xiaodan Zhu, Jackie Chi Kit Cheung, Lili Mou",http://arxiv.org/pdf/2412.11543v2,cs.CL
MERaLiON-SpeechEncoder: Towards a Speech Foundation Model for Singapore and Beyond,"This technical report describes the MERaLiON-SpeechEncoder, a foundation
model designed to support a wide range of downstream speech applications.
Developed as part of Singapore's National Multimodal Large Language Model
Programme, the MERaLiON-SpeechEncoder is tailored to address the speech
processing needs in Singapore and the surrounding Southeast Asian region. The
model currently supports mainly English, including the variety spoken in
Singapore. We are actively expanding our datasets to gradually cover other
languages in subsequent releases. The MERaLiON-SpeechEncoder was pre-trained
from scratch on 200,000 hours of unlabelled speech data using a self-supervised
learning approach based on masked language modelling. We describe our training
procedure and hyperparameter tuning experiments in detail below. Our evaluation
demonstrates improvements to spontaneous and Singapore speech benchmarks for
speech recognition, while remaining competitive to other state-of-the-art
speech encoders across ten other speech tasks. We commit to releasing our
model, supporting broader research endeavours, both in Singapore and beyond.",2024-12-16,"Muhammad Huzaifah, Geyu Lin, Tianchi Liu, Hardik B. Sailor, Kye Min Tan, Tarun K. Vangani, Qiongqiong Wang, Jeremy H. M. Wong, Nancy F. Chen, Ai Ti Aw",http://arxiv.org/pdf/2412.11538v2,cs.CL
Let your LLM generate a few tokens and you will reduce the need for retrieval,"In this paper, we investigate how efficiently large language models (LLM) can
be trained to check whether an answer is already stored in their parametric
memory. We distill an LLM-as-a-judge to compute the IK (I Know) score. We found
that this method is particularly beneficial in the context of
retrieval-assisted augmented generation (RAG), with a respectable accuracy of
80%. It enables a significant reduction (more than 50%) in the number of search
and reranking steps required for certain data sets. We have also introduced the
IK score, which serves as a useful tool for characterising datasets by
facilitating the classification task. Interestingly, through the inclusion of
response tokens as input, our results suggest that only about 20,000 training
samples are required to achieve good performance. The central element of this
work is the use of a teacher model - the LLM as a judge - to generate training
data. We also assess the robustness of the IK classifier by evaluating it with
various types of teachers, including both string-based methods and LLMs, with
the latter providing better results.",2024-12-16,Hervé Déjean,http://arxiv.org/pdf/2412.11536v1,cs.CL
DART: An AIGT Detector using AMR of Rephrased Text,"As large language models (LLMs) generate more human-like texts, concerns
about the side effects of AI-generated texts (AIGT) have grown. So, researchers
have developed methods for detecting AIGT. However, two challenges remain.
First, the performance of detecting black-box LLMs is low because existing
models focus on probabilistic features. Second, most AIGT detectors have been
tested on a single-candidate setting, which assumes that we know the origin of
an AIGT and which may deviate from the real-world scenario. To resolve these
challenges, we propose DART, which consists of four steps: rephrasing, semantic
parsing, scoring, and multiclass classification. We conducted three experiments
to test the performance of DART. The experimental result shows that DART can
discriminate multiple black-box LLMs without probabilistic features and the
origin of AIGT.",2024-12-16,"Hyeonchu Park, Byungjun Kim, Bugeun Kim",http://arxiv.org/pdf/2412.11517v2,cs.CL
Glimpse: Enabling White-Box Methods to Use Proprietary Models for Zero-Shot LLM-Generated Text Detection,"Advanced large language models (LLMs) can generate text almost
indistinguishable from human-written text, highlighting the importance of
LLM-generated text detection. However, current zero-shot techniques face
challenges as white-box methods are restricted to use weaker open-source LLMs,
and black-box methods are limited by partial observation from stronger
proprietary LLMs. It seems impossible to enable white-box methods to use
proprietary models because API-level access to the models neither provides full
predictive distributions nor inner embeddings. To traverse the divide, we
propose **Glimpse**, a probability distribution estimation approach, predicting
the full distributions from partial observations. Despite the simplicity of
Glimpse, we successfully extend white-box methods like Entropy, Rank, Log-Rank,
and Fast-DetectGPT to latest proprietary models. Experiments show that Glimpse
with Fast-DetectGPT and GPT-3.5 achieves an average AUROC of about 0.95 in five
latest source models, improving the score by 51% relative to the remaining
space of the open source baseline. It demonstrates that the latest LLMs can
effectively detect their own outputs, suggesting that advanced LLMs may be the
best shield against themselves. We release our code and data at
https://github.com/baoguangsheng/glimpse.",2024-12-16,"Guangsheng Bao, Yanbin Zhao, Juncai He, Yue Zhang",http://arxiv.org/pdf/2412.11506v2,cs.CL
Intention Knowledge Graph Construction for User Intention Relation Modeling,"Understanding user intentions is challenging for online platforms. Recent
work on intention knowledge graphs addresses this but often lacks focus on
connecting intentions, which is crucial for modeling user behavior and
predicting future actions. This paper introduces a framework to automatically
generate an intention knowledge graph, capturing connections between user
intentions. Using the Amazon m2 dataset, we construct an intention graph with
351 million edges, demonstrating high plausibility and acceptance. Our model
effectively predicts new session intentions and enhances product
recommendations, outperforming previous state-of-the-art methods and showcasing
the approach's practical utility.",2024-12-16,"Jiaxin Bai, Zhaobo Wang, Junfei Cheng, Dan Yu, Zerui Huang, Weiqi Wang, Xin Liu, Chen Luo, Yanming Zhu, Bo Li, Yangqiu Song",http://arxiv.org/pdf/2412.11500v2,cs.CL
FTP: A Fine-grained Token-wise Pruner for Large Language Models via Token Routing,"Recently, large language models (LLMs) have demonstrated superior performance
across various tasks by adhering to scaling laws, which significantly increase
model size. However, the huge computation overhead during inference hinders the
deployment in industrial applications. Many works leverage traditional
compression approaches to boost model inference, but these always introduce
additional training costs to restore the performance and the pruning results
typically show noticeable performance drops compared to the original model when
aiming for a specific level of acceleration. To address these issues, we
propose a fine-grained token-wise pruning approach for the LLMs, which presents
a learnable router to adaptively identify the less important tokens and skip
them across model blocks to reduce computational cost during inference. To
construct the router efficiently, we present a search-based sparsity scheduler
for pruning sparsity allocation, a trainable router combined with our proposed
four low-dimensional factors as input and three proposed losses. We conduct
extensive experiments across different benchmarks on different LLMs to
demonstrate the superiority of our method. Our approach achieves
state-of-the-art (SOTA) pruning results, surpassing other existing pruning
methods. For instance, our method outperforms BlockPruner and ShortGPT by
approximately 10 points on both LLaMA2-7B and Qwen1.5-7B in accuracy retention
at comparable token sparsity levels.",2024-12-16,"Zekai Li, Jintu Zheng, Ji Liu, Han Liu, Haowei Zhu, Zeping Li, Fuwei Yang, Haiduo Huang, Jinzhang Peng, Dong Li, Lu Tian, Emad Barsoum",http://arxiv.org/pdf/2412.11494v1,cs.CL
NoteContrast: Contrastive Language-Diagnostic Pretraining for Medical Text,"Accurate diagnostic coding of medical notes is crucial for enhancing patient
care, medical research, and error-free billing in healthcare organizations.
Manual coding is a time-consuming task for providers, and diagnostic codes
often exhibit low sensitivity and specificity, whereas the free text in medical
notes can be a more precise description of a patients status. Thus, accurate
automated diagnostic coding of medical notes has become critical for a learning
healthcare system. Recent developments in long-document transformer
architectures have enabled attention-based deep-learning models to adjudicate
medical notes. In addition, contrastive loss functions have been used to
jointly pre-train large language and image models with noisy labels. To further
improve the automated adjudication of medical notes, we developed an approach
based on i) models for ICD-10 diagnostic code sequences using a large
real-world data set, ii) large language models for medical notes, and iii)
contrastive pre-training to build an integrated model of both ICD-10 diagnostic
codes and corresponding medical text. We demonstrate that a contrastive
approach for pre-training improves performance over prior state-of-the-art
models for the MIMIC-III-50, MIMIC-III-rare50, and MIMIC-III-full diagnostic
coding tasks.",2024-12-16,"Prajwal Kailas, Max Homilius, Rahul C. Deo, Calum A. MacRae",http://arxiv.org/pdf/2412.11477v1,cs.CL
Understanding Knowledge Hijack Mechanism in In-context Learning through Associative Memory,"In-context learning (ICL) enables large language models (LLMs) to adapt to
new tasks without fine-tuning by leveraging contextual information provided
within a prompt. However, ICL relies not only on contextual clues but also on
the global knowledge acquired during pretraining for the next token prediction.
Analyzing this process has been challenging due to the complex computational
circuitry of LLMs. This paper investigates the balance between in-context
information and pretrained bigram knowledge in token prediction, focusing on
the induction head mechanism, a key component in ICL. Leveraging the fact that
a two-layer transformer can implement the induction head mechanism with
associative memories, we theoretically analyze the logits when a two-layer
transformer is given prompts generated by a bigram model. In the experiments,
we design specific prompts to evaluate whether the outputs of a two-layer
transformer align with the theoretical results.",2024-12-16,"Shuo Wang, Issei Sato",http://arxiv.org/pdf/2412.11459v1,cs.CL
Towards Better Multi-task Learning: A Framework for Optimizing Dataset Combinations in Large Language Models,"To efficiently select optimal dataset combinations for enhancing multi-task
learning (MTL) performance in large language models, we proposed a novel
framework that leverages a neural network to predict the best dataset
combinations. The framework iteratively refines the selection, greatly
improving efficiency, while being model-, dataset-, and domain-independent.
Through experiments on 12 biomedical datasets across four tasks - named entity
recognition, relation extraction, event extraction, and text classification-we
demonstrate that our approach effectively identifies better combinations, even
for tasks that may seem unpromising from a human perspective. This verifies
that our framework provides a promising solution for maximizing MTL potential.",2024-12-16,"Zaifu Zhan, Rui Zhang",http://arxiv.org/pdf/2412.11455v1,cs.CL
ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models,"As multimodal large language models (MLLMs) gain prominence in the medical
field, the need for precise evaluation methods to assess their effectiveness
has become critical. While benchmarks provide a reliable means to evaluate the
capabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for
open domain evaluation only focus on token overlap and may not align with human
judgment. Although human evaluation is more reliable, it is labor-intensive,
costly, and not scalable. LLM-based evaluation methods have proven promising,
but to date, there is still an urgent need for open-source multimodal LLM-based
evaluators in the medical field. To address this issue, we introduce ACE-$M^3$,
an open-sourced \textbf{A}utomatic \textbf{C}apability \textbf{E}valuator for
\textbf{M}ultimodal \textbf{M}edical \textbf{M}odels specifically designed to
assess the question answering abilities of medical MLLMs. It first utilizes a
branch-merge architecture to provide both detailed analysis and a concise final
score based on standard medical evaluation criteria. Subsequently, a reward
token-based direct preference optimization (RTDPO) strategy is incorporated to
save training time without compromising performance of our model. Extensive
experiments have demonstrated the effectiveness of our ACE-$M^3$
model\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}
in evaluating the capabilities of medical MLLMs.",2024-12-16,"Xiechi Zhang, Shunfan Zheng, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Liang He",http://arxiv.org/pdf/2412.11453v1,cs.CL
Whisper-GPT: A Hybrid Representation Audio Large Language Model,"We propose WHISPER-GPT: A generative large language model (LLM) for speech
and music that allows us to work with continuous audio representations and
discrete tokens simultaneously as part of a single architecture. There has been
a huge surge in generative audio, speech, and music models that utilize
discrete audio tokens derived from neural compression algorithms, e.g. ENCODEC.
However, one of the major drawbacks of this approach is handling the context
length. It blows up for high-fidelity generative architecture if one has to
account for all the audio contents at various frequencies for the next token
prediction. By combining continuous audio representation like the spectrogram
and discrete acoustic tokens, we retain the best of both worlds: Have all the
information needed from the audio at a specific time instance in a single
token, yet allow LLM to predict the future token to allow for sampling and
other benefits discrete space provides. We show how our architecture improves
the perplexity and negative log-likelihood scores for the next token prediction
compared to a token-based LLM for speech and music.",2024-12-16,Prateek Verma,http://arxiv.org/pdf/2412.11449v1,cs.CL
Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey,"Building on the foundations of language modeling in natural language
processing, Next Token Prediction (NTP) has evolved into a versatile training
objective for machine learning tasks across various modalities, achieving
considerable success. As Large Language Models (LLMs) have advanced to unify
understanding and generation tasks within the textual modality, recent research
has shown that tasks from different modalities can also be effectively
encapsulated within the NTP framework, transforming the multimodal information
into tokens and predict the next one given the context. This survey introduces
a comprehensive taxonomy that unifies both understanding and generation within
multimodal learning through the lens of NTP. The proposed taxonomy covers five
key aspects: Multimodal tokenization, MMNTP model architectures, unified task
representation, datasets \& evaluation, and open challenges. This new taxonomy
aims to aid researchers in their exploration of multimodal intelligence. An
associated GitHub repository collecting the latest papers and repos is
available at https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction",2024-12-16,"Liang Chen, Zekun Wang, Shuhuai Ren, Lei Li, Haozhe Zhao, Yunshui Li, Zefan Cai, Hongcheng Guo, Lei Zhang, Yizhe Xiong, Yichi Zhang, Ruoyu Wu, Qingxiu Dong, Ge Zhang, Jian Yang, Lingwei Meng, Shujie Hu, Yulong Chen, Junyang Lin, Shuai Bai, Andreas Vlachos, Xu Tan, Minjia Zhang, Wen Xiao, Aaron Yee, Tianyu Liu, Baobao Chang",http://arxiv.org/pdf/2412.18619v2,cs.CL
Optimized Quran Passage Retrieval Using an Expanded QA Dataset and Fine-Tuned Language Models,"Understanding the deep meanings of the Qur'an and bridging the language gap
between modern standard Arabic and classical Arabic is essential to improve the
question-and-answer system for the Holy Qur'an. The Qur'an QA 2023 shared task
dataset had a limited number of questions with weak model retrieval. To address
this challenge, this work updated the original dataset and improved the model
accuracy. The original dataset, which contains 251 questions, was reviewed and
expanded to 629 questions with question diversification and reformulation,
leading to a comprehensive set of 1895 categorized into single-answer,
multi-answer, and zero-answer types. Extensive experiments fine-tuned
transformer models, including AraBERT, RoBERTa, CAMeLBERT, AraELECTRA, and
BERT. The best model, AraBERT-base, achieved a MAP@10 of 0.36 and MRR of 0.59,
representing improvements of 63% and 59%, respectively, compared to the
baseline scores (MAP@10: 0.22, MRR: 0.37). Additionally, the dataset expansion
led to improvements in handling ""no answer"" cases, with the proposed approach
achieving a 75% success rate for such instances, compared to the baseline's
25%. These results demonstrate the effect of dataset improvement and model
architecture optimization in increasing the performance of QA systems for the
Holy Qur'an, with higher accuracy, recall, and precision.",2024-12-16,"Mohamed Basem, Islam Oshallah, Baraa Hikal, Ali Hamdi, Ammar Mohamed",http://arxiv.org/pdf/2412.11431v1,cs.CL
ConceptEdit: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning,"Knowledge Editing (KE) aims to adjust a Large Language Model's (LLM) internal
representations and parameters to correct inaccuracies and improve output
consistency without incurring the computational expense of re-training the
entire model. However, editing commonsense knowledge still faces difficulties,
including limited knowledge coverage in existing resources, the infeasibility
of annotating labels for an overabundance of commonsense knowledge, and the
strict knowledge formats of current editing methods. In this paper, we address
these challenges by presenting ConceptEdit, a framework that integrates
conceptualization and instantiation into the KE pipeline for LLMs to enhance
their commonsense reasoning capabilities. ConceptEdit dynamically diagnoses
implausible commonsense knowledge within an LLM using another verifier LLM and
augments the source knowledge to be edited with conceptualization for stronger
generalizability. Experimental results demonstrate that LLMs enhanced with
ConceptEdit successfully generate commonsense knowledge with improved
plausibility compared to other baselines and achieve stronger performance
across multiple question answering benchmarks.",2024-12-16,"Liyu Zhang, Weiqi Wang, Tianqing Fang, Yangqiu Song",http://arxiv.org/pdf/2412.11418v1,cs.CL
Look Ahead Text Understanding and LLM Stitching,"This paper proposes a look ahead text understanding problem with look ahead
section identification (LASI) as an example. This problem may appear in
generative AI as well as human interactions, where we want to understand the
direction of a developing text or conversation. We tackle the problem using
transformer-based LLMs. We show that LASI is more challenging than classic
section identification (SI). We argue that both bidirectional contextual
information (e.g., BERT) and unidirectional predictive ability (e.g., GPT) will
benefit the task. We propose two approaches to stitch together BERT and GPT.
Experiments show that our approach outperforms the established models,
especially when there is noise in the text (which is often the case for
developing text in generative AI). Our paper sheds light on other look ahead
text understanding tasks that are important to social media, such as look ahead
sentiment classification, and points out the opportunities to leverage
pre-trained LLMs through stitching.",2024-12-16,"Junlin Julian Jiang, Xin Li",http://arxiv.org/pdf/2412.17836v1,cs.CL
Biased or Flawed? Mitigating Stereotypes in Generative Language Models by Addressing Task-Specific Flaws,"Recent studies have shown that generative language models often reflect and
amplify societal biases in their outputs. However, these studies frequently
conflate observed biases with other task-specific shortcomings, such as
comprehension failure. For example, when a model misinterprets a text and
produces a response that reinforces a stereotype, it becomes difficult to
determine whether the issue arises from inherent bias or from a
misunderstanding of the given content. In this paper, we conduct a
multi-faceted evaluation that distinctly disentangles bias from flaws within
the reading comprehension task. We propose a targeted stereotype mitigation
framework that implicitly mitigates observed stereotypes in generative models
through instruction-tuning on general-purpose datasets. We reduce stereotypical
outputs by over 60% across multiple dimensions -- including nationality, age,
gender, disability, and physical appearance -- by addressing
comprehension-based failures, and without relying on explicit debiasing
techniques. We evaluate several state-of-the-art generative models to
demonstrate the effectiveness of our approach while maintaining the overall
utility. Our findings highlight the need to critically disentangle the concept
of `bias' from other types of errors to build more targeted and effective
mitigation strategies. CONTENT WARNING: Some examples contain offensive
stereotypes.",2024-12-16,"Akshita Jha, Sanchit Kabra, Chandan K. Reddy",http://arxiv.org/pdf/2412.11414v1,cs.CL
Attention with Dependency Parsing Augmentation for Fine-Grained Attribution,"To assist humans in efficiently validating RAG-generated content, developing
a fine-grained attribution mechanism that provides supporting evidence from
retrieved documents for every answer span is essential. Existing fine-grained
attribution methods rely on model-internal similarity metrics between responses
and documents, such as saliency scores and hidden state similarity. However,
these approaches suffer from either high computational complexity or
coarse-grained representations. Additionally, a common problem shared by the
previous works is their reliance on decoder-only Transformers, limiting their
ability to incorporate contextual information after the target span. To address
the above problems, we propose two techniques applicable to all
model-internals-based methods. First, we aggregate token-wise evidence through
set union operations, preserving the granularity of representations. Second, we
enhance the attributor by integrating dependency parsing to enrich the semantic
completeness of target spans. For practical implementation, our approach
employs attention weights as the similarity metric. Experimental results
demonstrate that the proposed method consistently outperforms all prior works.",2024-12-16,"Qiang Ding, Lvzhou Luo, Yixuan Cao, Ping Luo",http://arxiv.org/pdf/2412.11404v1,cs.CL
Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search,"Creation and curation of knowledge graphs can accelerate disease discovery
and analysis in real-world data. While disease ontologies aid in biological
data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture
patient condition nuances or rare diseases. Multiple disease definitions across
data sources complicate ontology mapping and disease clustering. We propose
creating patient knowledge graphs using large language model extraction
techniques, allowing data extraction via natural language rather than rigid
ontological hierarchies. Our method maps to existing ontologies (MeSH,
SNOMED-CT, RxNORM, HPO) to ground extracted entities.
  Using a large ambulatory care EHR database with 33.6M patients, we
demonstrate our method through the patient search for Dravet syndrome, which
received ICD10 recognition in October 2020. We describe our construction of
patient-specific knowledge graphs and symptom-based patient searches. Using
confirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based
entity extraction to characterize patients in grounded ontologies. We then
apply this method to identify Beta-propeller protein-associated
neurodegeneration (BPAN) patients, demonstrating real-world discovery where no
ground truth exists.",2024-12-16,"Edward Kim, Manil Shrestha, Richard Foty, Tom DeLay, Vicki Seyfert-Margolis",http://arxiv.org/pdf/2412.15256v1,cs.CL
"INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models","Large language models (LLMs) excel at answering questions but remain passive
learners--absorbing static data without the ability to question and refine
knowledge. This paper explores how LLMs can transition to interactive,
question-driven learning through student-teacher dialogues. We introduce
INTERACT (INTEReractive Learning for Adaptive Concept Transfer), a framework in
which a ""student"" LLM engages a ""teacher"" LLM through iterative inquiries to
acquire knowledge across 1,347 contexts, including song lyrics, news articles,
movie plots, academic papers, and images. Our experiments show that across a
wide range of scenarios and LLM architectures, interactive learning
consistently enhances performance, achieving up to a 25% improvement, with
'cold-start' student models matching static learning baselines in as few as
five dialogue turns. Interactive setups can also mitigate the disadvantages of
weaker teachers, showcasing the robustness of question-driven learning.",2024-12-16,"Aum Kendapadi, Kerem Zaman, Rakesh R. Menon, Shashank Srivastava",http://arxiv.org/pdf/2412.11388v1,cs.CL
"Why Does ChatGPT ""Delve"" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models","Scientific English is currently undergoing rapid change, with words like
""delve,"" ""intricate,"" and ""underscore"" appearing far more frequently than just
a few years ago. It is widely assumed that scientists' use of large language
models (LLMs) is responsible for such trends. We develop a formal, transferable
method to characterize these linguistic changes. Application of our method
yields 21 focal words whose increased occurrence in scientific abstracts is
likely the result of LLM usage. We then pose ""the puzzle of lexical
overrepresentation"": WHY are such words overused by LLMs? We fail to find
evidence that lexical overrepresentation is caused by model architecture,
algorithm choices, or training data. To assess whether reinforcement learning
from human feedback (RLHF) contributes to the overuse of focal words, we
undertake comparative model testing and conduct an exploratory online study.
While the model testing is consistent with RLHF playing a role, our
experimental results suggest that participants may be reacting differently to
""delve"" than to other focal words. With LLMs quickly becoming a driver of
global language change, investigating these potential sources of lexical
overrepresentation is important. We note that while insights into the workings
of LLMs are within reach, a lack of transparency surrounding model development
remains an obstacle to such research.",2024-12-16,"Tom S. Juzek, Zina B. Ward",http://arxiv.org/pdf/2412.11385v1,cs.CL
ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data,"Human experts typically integrate numerical and textual multimodal
information to analyze time series. However, most traditional deep learning
predictors rely solely on unimodal numerical data, using a fixed-length window
for training and prediction on a single dataset, and cannot adapt to different
scenarios. The powered pre-trained large language model has introduced new
opportunities for time series analysis. Yet, existing methods are either
inefficient in training, incapable of handling textual information, or lack
zero-shot forecasting capability. In this paper, we innovatively model time
series as a foreign language and construct ChatTime, a unified framework for
time series and text processing. As an out-of-the-box multimodal time series
foundation model, ChatTime provides zero-shot forecasting capability and
supports bimodal input/output for both time series and text. We design a series
of experiments to verify the superior performance of ChatTime across multiple
tasks and scenarios, and create four multimodal datasets to address data gaps.
The experimental results demonstrate the potential and utility of ChatTime.",2024-12-16,"Chengsen Wang, Qi Qi, Jingyu Wang, Haifeng Sun, Zirui Zhuang, Jinming Wu, Lei Zhang, Jianxin Liao",http://arxiv.org/pdf/2412.11376v1,cs.CL
Codenames as a Benchmark for Large Language Models,"In this paper, we propose the use of the popular word-based board game
Codenames as a suitable benchmark for evaluating the reasoning capabilities of
Large Language Models (LLMs). Codenames presents a highly interesting challenge
for achieving successful AI performance, requiring both a sophisticated
understanding of language, theory of mind, and epistemic reasoning
capabilities. Prior attempts to develop agents for Codenames have largely
relied on word embedding techniques, which have a limited vocabulary range and
perform poorly when paired with differing approaches. LLMs have demonstrated
enhanced reasoning and comprehension capabilities for language-based tasks, but
can still suffer in lateral thinking challenges. We evaluate the capabilities
of several state-of-the-art LLMs, including GPT-4o, Gemini 1.5, Claude 3.5
Sonnet, and Llama 3.1, across a variety of board setups. Our results indicate
that while certain LLMs perform better than others overall, different models
exhibit varying emergent behaviours during gameplay and excel at specific
roles. We also evaluate the performance of different combinations of LLMs when
playing cooperatively together, demonstrating that LLM agents are more
generalisable to a wider range of teammates than prior techniques.",2024-12-16,"Matthew Stephenson, Matthew Sidji, Benoît Ronval",http://arxiv.org/pdf/2412.11373v2,cs.CL
Can AI Extract Antecedent Factors of Human Trust in AI? An Application of Information Extraction for Scientific Literature in Behavioural and Computer Sciences,"Information extraction from the scientific literature is one of the main
techniques to transform unstructured knowledge hidden in the text into
structured data which can then be used for decision-making in down-stream
tasks. One such area is Trust in AI, where factors contributing to human trust
in artificial intelligence applications are studied. The relationships of these
factors with human trust in such applications are complex. We hence explore
this space from the lens of information extraction where, with the input of
domain experts, we carefully design annotation guidelines, create the first
annotated English dataset in this domain, investigate an LLM-guided annotation,
and benchmark it with state-of-the-art methods using large language models in
named entity and relation extraction. Our results indicate that this problem
requires supervised learning which may not be currently feasible with
prompt-based LLMs.",2024-12-16,"Melanie McGrath, Harrison Bailey, Necva Bölücü, Xiang Dai, Sarvnaz Karimi, Cecile Paris",http://arxiv.org/pdf/2412.11344v1,cs.CL
Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models,"Diffusion models have shown promise in text generation, but often struggle
with generating long, coherent, and contextually accurate text. Token-level
diffusion doesn't model word-order dependencies explicitly and operates on
short, fixed output windows, while passage-level diffusion struggles with
learning robust representations for long-form text. To address these
challenges, we propose Segment-Level Diffusion (SLD), a framework that enhances
diffusion-based text generation through text segmentation, robust
representation training with adversarial and contrastive learning, and improved
latent-space guidance. By segmenting long-form outputs into multiple latent
representations and decoding them with an autoregressive decoder, SLD
simplifies diffusion predictions and improves scalability. Experiments on four
datasets demonstrate that, when compared to other diffusion and autoregressive
baselines SLD achieves competitive or superior fluency, coherence, and
contextual compatibility in automatic and human evaluations.",2024-12-15,"Xiaochen Zhu, Georgi Karadzhov, Chenxi Whitehouse, Andreas Vlachos",http://arxiv.org/pdf/2412.11333v2,cs.CL
Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization,"Text-to-image models are vulnerable to the stepwise ""Divide-and-Conquer
Attack"" (DACA) that utilize a large language model to obfuscate inappropriate
content in prompts by wrapping sensitive text in a benign narrative. To
mitigate stepwise DACA attacks, we propose a two-layer method involving text
summarization followed by binary classification. We assembled the Adversarial
Text-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated
and non-obfuscated prompts. From the ATTIP dataset, we created two summarized
versions: one generated by a small encoder model and the other by a large
language model. Then, we used an encoder classifier and a GPT-4o classifier to
perform content moderation on the summarized and unsummarized prompts. When
compared with a classifier that operated over the unsummarized data, our method
improved F1 score performance by 31%. Further, the highest recorded F1 score
achieved (98%) was produced by the encoder classifier on a summarized ATTIP
variant. This study indicates that pre-classification text summarization can
inoculate content detection models against stepwise DACA obfuscations.",2024-12-15,"Portia Cooper, Harshita Narnoli, Mihai Surdeanu",http://arxiv.org/pdf/2412.12212v1,cs.CL
Generics are puzzling. Can language models find the missing piece?,"Generic sentences express generalisations about the world without explicit
quantification. Although generics are central to everyday communication,
building a precise semantic framework has proven difficult, in part because
speakers use generics to generalise properties with widely different
statistical prevalence. In this work, we study the implicit quantification and
context-sensitivity of generics by leveraging language models as models of
language. We create ConGen, a dataset of 2873 naturally occurring generic and
quantified sentences in context, and define p-acceptability, a metric based on
surprisal that is sensitive to quantification. Our experiments show generics
are more context-sensitive than determiner quantifiers and about 20% of
naturally occurring generics we analyze express weak generalisations. We also
explore how human biases in stereotypes can be observed in language models.",2024-12-15,"Gustavo Cilleruelo Calderón, Emily Allaway, Barry Haddow, Alexandra Birch",http://arxiv.org/pdf/2412.11318v1,cs.CL
"RoLargeSum: A Large Dialect-Aware Romanian News Dataset for Summary, Headline, and Keyword Generation","Using supervised automatic summarisation methods requires sufficient corpora
that include pairs of documents and their summaries. Similarly to many tasks in
natural language processing, most of the datasets available for summarization
are in English, posing challenges for developing summarization models in other
languages. Thus, in this work, we introduce RoLargeSum, a novel large-scale
summarization dataset for the Romanian language crawled from various publicly
available news websites from Romania and the Republic of Moldova that were
thoroughly cleaned to ensure a high-quality standard. RoLargeSum contains more
than 615K news articles, together with their summaries, as well as their
headlines, keywords, dialect, and other metadata that we found on the targeted
websites. We further evaluated the performance of several BART variants and
open-source large language models on RoLargeSum for benchmarking purposes. We
manually evaluated the results of the best-performing system to gain insight
into the potential pitfalls of this data set and future development.",2024-12-15,"Andrei-Marius Avram, Mircea Timpuriu, Andreea Iuga, Vlad-Cristian Matei, Iulian-Marius Tăiatu, Tudor Găină, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel",http://arxiv.org/pdf/2412.11317v1,cs.CL
"Reliable, Reproducible, and Really Fast Leaderboards with Evalica","The rapid advancement of natural language processing (NLP) technologies, such
as instruction-tuned large language models (LLMs), urges the development of
modern evaluation protocols with human and machine feedback. We introduce
Evalica, an open-source toolkit that facilitates the creation of reliable and
reproducible model leaderboards. This paper presents its design, evaluates its
performance, and demonstrates its usability through its Web interface,
command-line interface, and Python API.",2024-12-15,Dmitry Ustalov,http://arxiv.org/pdf/2412.11314v1,cs.CL
Sequence-Level Leakage Risk of Training Data in Large Language Models,"This work quantifies the risk of training data leakage from LLMs (Large
Language Models) using sequence-level probabilities. Computing extraction
probabilities for individual sequences provides finer-grained information than
has been studied in prior benchmarking work. We re-analyze the effects of
decoding schemes, model sizes, prefix lengths, partial sequence leakages, and
token positions to uncover new insights that were not possible in previous
works due to their choice of metrics. We perform this study on two pre-trained
models, Llama and OPT, trained on the Common Crawl and The Pile respectively.
We discover that 1) Extraction Rate, the predominant metric used in prior
quantification work, underestimates the threat of leakage of training data in
randomized LLMs by as much as 2.14X. 2) Although on average, larger models and
longer prefixes can extract more data, this is not true for a substantial
portion of individual sequences. 30.4-41.5% of our sequences are easier to
extract with either shorter prefixes or smaller models. 3) Contrary to previous
beliefs, partial leakage in commonly used decoding schemes like top-k and top-p
is not easier than leaking verbatim training data. The aim of this work is to
encourage the adoption of this metric for future work on quantification of
training data extraction.",2024-12-15,"Trishita Tiwari, G. Edward Suh",http://arxiv.org/pdf/2412.11302v3,cs.CL
Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation,"In this paper, we show that knowledge distillation can be subverted to
manipulate language model benchmark scores, revealing a critical vulnerability
in current evaluation practices. We introduce ""Data Laundering,"" a three-phase
process analogous to financial money laundering, that enables the covert
transfer of benchmark-specific knowledge through seemingly legitimate
intermediate training steps. Through extensive experiments with a 2-layer BERT
student model, we show how this approach can achieve substantial improvements
in benchmark accuracy (up to 75\% on GPQA) without developing genuine reasoning
capabilities. Notably, this method can be exploited intentionally or even
unintentionally, as researchers may inadvertently adopt this method that
inflates scores using knowledge distillation without realizing the
implications. While our findings demonstrate the effectiveness of this
technique, we present them as a cautionary tale highlighting the urgent need
for more robust evaluation methods in AI. This work aims to contribute to the
ongoing discussion about evaluation integrity in AI development and the need
for benchmarks that more accurately reflect true model capabilities. The code
is available at \url{https://github.com/mbzuai-nlp/data_laundering}.",2024-12-15,"Jonibek Mansurov, Akhmed Sakip, Alham Fikri Aji",http://arxiv.org/pdf/2412.15255v1,cs.CL
"CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-Independent Paradigm in Translation Quality Evaluation","This paper introduces the Comprehensive AI-assisted Translation Edit Ratio
(CATER), a novel and fully prompt-driven framework for evaluating machine
translation (MT) quality. Leveraging large language models (LLMs) via a
carefully designed prompt-based protocol, CATER expands beyond traditional
reference-bound metrics, offering a multidimensional, reference-independent
evaluation that addresses linguistic accuracy, semantic fidelity, contextual
coherence, stylistic appropriateness, and information completeness. CATER's
unique advantage lies in its immediate implementability: by providing the
source and target texts along with a standardized prompt, an LLM can rapidly
identify errors, quantify edit effort, and produce category-level and overall
scores. This approach eliminates the need for pre-computed references or
domain-specific resources, enabling instant adaptation to diverse languages,
genres, and user priorities through adjustable weights and prompt
modifications. CATER's LLM-enabled strategy supports more nuanced assessments,
capturing phenomena such as subtle omissions, hallucinations, and
discourse-level shifts that increasingly challenge contemporary MT systems. By
uniting the conceptual rigor of frameworks like MQM and DQF with the
scalability and flexibility of LLM-based evaluation, CATER emerges as a
valuable tool for researchers, developers, and professional translators
worldwide. The framework and example prompts are openly available, encouraging
community-driven refinement and further empirical validation.",2024-12-15,"Kurando IIDA, Kenjiro MIMURA",http://arxiv.org/pdf/2412.11261v1,cs.CL
Beyond Discrete Personas: Personality Modeling Through Journal Intensive Conversations,"Large Language Models (LLMs) have significantly improved personalized
conversational capabilities. However, existing datasets like Persona Chat,
Synthetic Persona Chat, and Blended Skill Talk rely on static, predefined
personas. This approach often results in dialogues that fail to capture human
personalities' fluid and evolving nature. To overcome these limitations, we
introduce a novel dataset with around 400,000 dialogues and a framework for
generating personalized conversations using long-form journal entries from
Reddit. Our approach clusters journal entries for each author and filters them
by selecting the most representative cluster, ensuring that the retained
entries best reflect the author's personality. We further refine the data by
capturing the Big Five personality traits --openness, conscientiousness,
extraversion, agreeableness, and neuroticism --ensuring that dialogues
authentically reflect an individual's personality. Using Llama 3 70B, we
generate high-quality, personality-rich dialogues grounded in these journal
entries. Fine-tuning models on this dataset leads to an 11% improvement in
capturing personality traits on average, outperforming existing approaches in
generating more coherent and personality-driven dialogues.",2024-12-15,"Sayantan Pal, Souvik Das, Rohini K. Srihari",http://arxiv.org/pdf/2412.11250v1,cs.CL
TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs,"Specializing large language models (LLMs) for local deployment in
domain-specific use cases is necessary for strong performance while meeting
latency and privacy constraints. However, conventional task-specific adaptation
approaches do not show simultaneous memory saving and inference speedup at
deployment time. Practical compression techniques like quantization and pruning
require dedicated hardware or kernel support to achieve measured inference
speedup. We develop TrimLLM based on the layer-wise specialization phenomenon
we empirically observed and verified on contemporary LLMs. TrimLLM reduces the
depth of LLMs via progressive layer dropping. We show it retains LLMs' capacity
in specific domains and achieves inference speedup irrespective of hardware and
deep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for
inference; models adapted on medical, legal, and financial datasets all
demonstrate $2.1-5.7\times$ inference speedup on consumer GPUs and up to
$3.1\times$ speedup on A100 when compared to state-of-the-art model compression
algorithms, with no loss in accuracy at 50$\sim$60\% model compression ratio.",2024-12-15,"Lanxiang Hu, Tajana Rosing, Hao Zhang",http://arxiv.org/pdf/2412.11242v2,cs.CL
Smaller Language Models Are Better Instruction Evolvers,"Instruction tuning has been widely used to unleash the complete potential of
large language models. Notably, complex and diverse instructions are of
significant importance as they can effectively align models with various
downstream tasks. However, current approaches to constructing large-scale
instructions predominantly favour powerful models such as GPT-4 or those with
over 70 billion parameters, under the empirical presumption that such larger
language models (LLMs) inherently possess enhanced capabilities. In this study,
we question this prevalent assumption and conduct an in-depth exploration into
the potential of smaller language models (SLMs) in the context of instruction
evolution. Extensive experiments across three scenarios of instruction
evolution reveal that smaller language models (SLMs) can synthesize more
effective instructions than LLMs. Further analysis demonstrates that SLMs
possess a broader output space during instruction evolution, resulting in more
complex and diverse variants. We also observe that the existing metrics fail to
focus on the impact of the instructions. Thus, we propose Instruction
Complex-Aware IFD (IC-IFD), which introduces instruction complexity in the
original IFD score to evaluate the effectiveness of instruction data more
accurately. Our source code is available at:
\href{https://github.com/HypherX/Evolution-Analysis}{https://github.com/HypherX/Evolution-Analysis}",2024-12-15,"Tingfeng Hui, Lulu Zhao, Guanting Dong, Yaqi Zhang, Hua Zhou, Sen Su",http://arxiv.org/pdf/2412.11231v1,cs.CL
"RIRO: Reshaping Inputs, Refining Outputs Unlocking the Potential of Large Language Models in Data-Scarce Contexts","Large language models (LLMs) have significantly advanced natural language
processing, excelling in areas like text generation, summarization, and
question-answering. Despite their capabilities, these models face challenges
when fine-tuned on small, domain-specific datasets, often struggling to
generalize and deliver accurate results with unfamiliar inputs. To tackle this
issue, we introduce RIRO, a novel two-layer architecture designed to improve
performance in data-scarce environments. The first layer leverages advanced
prompt engineering to reformulate inputs, ensuring better alignment with
training data, while the second layer focuses on refining outputs to minimize
inconsistencies. Through fine-tuning models like Phi-2, Falcon 7B, and Falcon
1B, with Phi-2 outperforming the others. Additionally, we introduce a benchmark
using evaluation metrics such as cosine similarity, Levenshtein distance, BLEU
score, ROUGE-1, ROUGE-2, and ROUGE-L. While these advancements improve
performance, challenges like computational demands and overfitting persist,
limiting the potential of LLMs in data-scarce, high-stakes environments such as
healthcare, legal documentation, and software testing.",2024-12-15,"Ali Hamdi, Hozaifa Kassab, Mohamed Bahaa, Marwa Mohamed",http://arxiv.org/pdf/2412.15254v1,cs.CL
Task-Oriented Dialog Systems for the Senegalese Wolof Language,"In recent years, we are seeing considerable interest in conversational agents
with the rise of large language models (LLMs). Although they offer considerable
advantages, LLMs also present significant risks, such as hallucination, which
hinder their widespread deployment in industry. Moreover, low-resource
languages such as African ones are still underrepresented in these systems
limiting their performance in these languages. In this paper, we illustrate a
more classical approach based on modular architectures of Task-oriented Dialog
Systems (ToDS) offering better control over outputs. We propose a chatbot
generation engine based on the Rasa framework and a robust methodology for
projecting annotations onto the Wolof language using an in-house machine
translation system. After evaluating a generated chatbot trained on the Amazon
Massive dataset, our Wolof Intent Classifier performs similarly to the one
obtained for French, which is a resource-rich language. We also show that this
approach is extensible to other low-resource languages, thanks to the intent
classifier's language-agnostic pipeline, simplifying the design of chatbots in
these languages.",2024-12-15,"Derguene Mbaye, Moussa Diallo",http://arxiv.org/pdf/2412.11203v1,cs.CL
Drawing the Line: Enhancing Trustworthiness of MLLMs Through the Power of Refusal,"Multimodal large language models (MLLMs) excel at multimodal perception and
understanding, yet their tendency to generate hallucinated or inaccurate
responses undermines their trustworthiness. Existing methods have largely
overlooked the importance of refusal responses as a means of enhancing MLLMs
reliability. To bridge this gap, we present the Information Boundary-aware
Learning Framework (InBoL), a novel approach that empowers MLLMs to refuse to
answer user queries when encountering insufficient information. To the best of
our knowledge, InBoL is the first framework that systematically defines the
conditions under which refusal is appropriate for MLLMs using the concept of
information boundaries proposed in our paper. This framework introduces a
comprehensive data generation pipeline and tailored training strategies to
improve the model's ability to deliver appropriate refusal responses. To
evaluate the trustworthiness of MLLMs, we further propose a user-centric
alignment goal along with corresponding metrics. Experimental results
demonstrate a significant improvement in refusal accuracy without noticeably
compromising the model's helpfulness, establishing InBoL as a pivotal
advancement in building more trustworthy MLLMs.",2024-12-15,"Yuhao Wang, Zhiyuan Zhu, Heyang Liu, Yusheng Liao, Hongcheng Liu, Yanfeng Wang, Yu Wang",http://arxiv.org/pdf/2412.11196v1,cs.CL
Leveraging Large Language Models for Active Merchant Non-player Characters,"We highlight two significant issues leading to the passivity of current
merchant non-player characters (NPCs): pricing and communication. While
immersive interactions have been a focus, negotiations between merchant NPCs
and players on item prices have not received sufficient attention. First, we
define passive pricing as the limited ability of merchants to modify predefined
item prices. Second, passive communication means that merchants can only
interact with players in a scripted manner. To tackle these issues and create
an active merchant NPC, we propose a merchant framework based on large language
models (LLMs), called MART, which consists of an appraiser module and a
negotiator module. We conducted two experiments to guide game developers in
selecting appropriate implementations by comparing different training methods
and LLM sizes. Our findings indicate that finetuning methods, such as
supervised finetuning (SFT) and knowledge distillation (KD), are effective in
using smaller LLMs to implement active merchant NPCs. Additionally, we found
three irregular cases arising from the responses of LLMs. We expect our
findings to guide developers in using LLMs for developing active merchant NPCs.",2024-12-15,"Byungjun Kim, Minju Kim, Dayeon Seo, Bugeun Kim",http://arxiv.org/pdf/2412.11189v2,cs.CL
Analyzing the Attention Heads for Pronoun Disambiguation in Context-aware Machine Translation Models,"In this paper, we investigate the role of attention heads in Context-aware
Machine Translation models for pronoun disambiguation in the English-to-German
and English-to-French language directions. We analyze their influence by both
observing and modifying the attention scores corresponding to the plausible
relations that could impact a pronoun prediction. Our findings reveal that
while some heads do attend the relations of interest, not all of them influence
the models' ability to disambiguate pronouns. We show that certain heads are
underutilized by the models, suggesting that model performance could be
improved if only the heads would attend one of the relations more strongly.
Furthermore, we fine-tune the most promising heads and observe the increase in
pronoun disambiguation accuracy of up to 5 percentage points which demonstrates
that the improvements in performance can be solidified into the models'
parameters.",2024-12-15,"Paweł Mąka, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis",http://arxiv.org/pdf/2412.11187v1,cs.CL
Transliterated Zero-Shot Domain Adaptation for Automatic Speech Recognition,"The performance of automatic speech recognition models often degenerates on
domains not covered by the training data. Domain adaptation can address this
issue, assuming the availability of the target domain data in the target
language. However, such assumption does not stand in many real-world
applications. To make domain adaptation more applicable, we address the problem
of zero-shot domain adaptation (ZSDA), where target domain data is unavailable
in the target language. Instead, we transfer the target domain knowledge from
another source language where the target domain data is more accessible. To do
that, we first perform cross-lingual pre-training (XLPT) to share domain
knowledge across languages, then use target language fine-tuning to build the
final model. One challenge in this practice is that the pre-trained knowledge
can be forgotten during fine-tuning, resulting in sub-optimal adaptation
performance. To address this issue, we propose transliterated ZSDA to achieve
consistent pre-training and fine-tuning labels, leading to maximum preservation
of the pre-trained knowledge. Experimental results show that transliterated
ZSDA relatively decreases the word error rate by 9.2% compared with a wav2vec
2.0 baseline. Moreover, transliterated ZSDA consistently outperforms
self-supervised ZSDA and performs on par with supervised ZSDA, proving the
superiority of transliteration-based pre-training labels.",2024-12-15,"Han Zhu, Gaofeng Cheng, Qingwei Zhao, Pengyuan Zhang",http://arxiv.org/pdf/2412.11185v1,cs.CL
Unpacking the Resilience of SNLI Contradiction Examples to Attacks,"Pre-trained models excel on NLI benchmarks like SNLI and MultiNLI, but their
true language understanding remains uncertain. Models trained only on
hypotheses and labels achieve high accuracy, indicating reliance on dataset
biases and spurious correlations. To explore this issue, we applied the
Universal Adversarial Attack to examine the model's vulnerabilities. Our
analysis revealed substantial drops in accuracy for the entailment and neutral
classes, whereas the contradiction class exhibited a smaller decline.
Fine-tuning the model on an augmented dataset with adversarial examples
restored its performance to near-baseline levels for both the standard and
challenge sets. Our findings highlight the value of adversarial triggers in
identifying spurious correlations and improving robustness while providing
insights into the resilience of the contradiction class to adversarial attacks.",2024-12-15,"Chetan Verma, Archit Agarwal",http://arxiv.org/pdf/2412.11172v1,cs.CL
Using Machine Learning to Distinguish Human-written from Machine-generated Creative Fiction,"Following the universal availability of generative AI systems with the
release of ChatGPT, automatic detection of deceptive text created by Large
Language Models has focused on domains such as academic plagiarism and ""fake
news"". However, generative AI also poses a threat to the livelihood of creative
writers, and perhaps to literary culture in general, through reduction in
quality of published material. Training a Large Language Model on writers'
output to generate ""sham books"" in a particular style seems to constitute a new
form of plagiarism. This problem has been little researched. In this study, we
trained Machine Learning classifier models to distinguish short samples of
human-written from machine-generated creative fiction, focusing on classic
detective novels. Our results show that a Naive Bayes and a Multi-Layer
Perceptron classifier achieved a high degree of success (accuracy > 95%),
significantly outperforming human judges (accuracy < 55%). This approach worked
well with short text samples (around 100 words), which previous research has
shown to be difficult to classify. We have deployed an online proof-of-concept
classifier tool, AI Detective, as a first step towards developing lightweight
and reliable applications for use by editors and publishers, with the aim of
protecting the economic and cultural contribution of human authors.",2024-12-15,"Andrea Cristina McGlinchey, Peter J Barclay",http://arxiv.org/pdf/2412.15253v1,cs.CL
Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette,"Large language models (LLMs) face challenges in aligning with diverse
cultural values despite their remarkable performance in generation, which stems
from inherent monocultural biases and difficulties in capturing nuanced
cultural semantics. Existing methods struggle to adapt to unkown culture after
fine-tuning. Inspired by cultural geography across five continents, we propose
Cultural Palette, a multi-agent framework that redefines cultural alignment as
an adaptive ""color-blending"" process for country-specific adaptation. Our
approach harnesses cultural geography across five continents (Africa, America,
Asia, Europe, Oceania) through three key steps: First, we synthesize the
Pentachromatic Cultural Palette Dataset using GPT-4o, refining
continental-level dialogues with Hofstede cultural dimensions to establish
foundational cultural representations. Second, five continent-level alignment
agents form specialized cultural communities that generate region-specific
draft responses. Third, a Meta Agent employs Cultural MoErges to dynamically
blend these cultural ""colors"" through attention-gated parameter merging, akin
to mixing pigments on a palette, resolving conflicts while preserving cultural
nuances to produce the final culturally-aligned response. Extensive experiments
across various countries demonstrate that Cultural Palette surpasses existing
baselines in cultural alignment.",2024-12-15,"Jiahao Yuan, Zixiang Di, Shangzixin Zhao, Usman Naseem",http://arxiv.org/pdf/2412.11167v2,cs.CL
GaLore$+$: Boosting Low-Rank Adaptation for LLMs with Cross-Head Projection,"Recent low-rank training methods, such as GaLore, have significantly reduced
the memory required to optimize large language models (LLMs). However, these
methods often suffer from time-consuming low-rank projection estimations. In
particular, the singular value decomposition (SVD) in GaLore can consume more
than 80\% of the total training time. To address this issue, we propose
GaLore$+$, which uses cross-head low-rank projection to reduce the substantial
time consumption in estimating low-rank projections for multi-head attention.
In addition, we employ randomized subspace iteration to achieve fast SVD. To
further enhance performance, we propose sparsely coded residuals to reduce the
errors caused by low-rank approximation on the first- and second-order moments
of the optimizers and weight updates. We evaluate GaLore$+$ on arithmetic
reasoning and natural language generation datasets. Our experiments demonstrate
that GaLore$+$ delivers superior performance while achieving approximately
$4\times$ fine-tuning speed compared to vanilla GaLore.",2024-12-15,"Xutao Liao, Shaohui Li, Yuhui Xu, Zhi Li, Yu Liu, You He",http://arxiv.org/pdf/2412.19820v1,cs.CL
SEE: Sememe Entanglement Encoding for Transformer-bases Models Compression,"Transformer-based large language models exhibit groundbreaking capabilities,
but their storage and computational costs are prohibitively high, limiting
their application in resource-constrained scenarios. An effective approach is
to eliminate redundant model parameters and computational costs while
incorporating efficient expert-derived knowledge structures to achieve a
balance between compression and performance. Therefore, we propose the
\textit{Sememe Entanglement Encoding (SEE)} algorithm. Guided by expert prior
knowledge, the model is compressed through the low-rank approximation idea. In
Entanglement Embedding, basic semantic units such as sememes are represented as
low-dimensional vectors, and then reconstructed into high-dimensional word
embeddings through the combination of generalized quantum entanglement. We
adapt the Sememe Entanglement Encoding algorithm to transformer-based models of
different magnitudes. Experimental results indicate that our approach achieves
stable performance while compressing model parameters and computational costs.",2024-12-15,"Jing Zhang, Shuzhen Sun, Peng Zhang, Guangxing Cao, Hui Gao, Xindian Ma, Nan Xu, Yuexian Hou",http://arxiv.org/pdf/2412.12204v1,cs.CL
The Superalignment of Superhuman Intelligence with Large Language Models,"We have witnessed superhuman intelligence thanks to the fast development of
large language models and multimodal language models. As the application of
such superhuman models becomes more and more popular, a critical question
arises here: how can we ensure superhuman models are still safe, reliable and
aligned well to human values? In this position paper, we discuss the concept of
superalignment from the learning perspective to answer this question by
outlining the learning paradigm shift from large-scale pretraining, supervised
fine-tuning, to alignment training. We define superalignment as designing
effective and efficient alignment algorithms to learn from noisy-labeled data
(point-wise samples or pair-wise preference data) in a scalable way when the
task becomes very complex for human experts to annotate and the model is
stronger than human experts. We highlight some key research problems in
superalignment, namely, weak-to-strong generalization, scalable oversight, and
evaluation. We then present a conceptual framework for superalignment, which
consists of three modules: an attacker which generates adversary queries trying
to expose the weaknesses of a learner model; a learner which will refine itself
by learning from scalable feedbacks generated by a critic model along with
minimal human experts; and a critic which generates critics or explanations for
a given query-response pair, with a target of improving the learner by
criticizing. We discuss some important research problems in each component of
this framework and highlight some interesting research ideas that are closely
related to our proposed framework, for instance, self-alignment, self-play,
self-refinement, and more. Last, we highlight some future research directions
for superalignment, including identification of new emergent risks and
multi-dimensional alignment.",2024-12-15,"Minlie Huang, Yingkang Wang, Shiyao Cui, Pei Ke, Jie Tang",http://arxiv.org/pdf/2412.11145v2,cs.CL
AD-LLM: Benchmarking Large Language Models for Anomaly Detection,"Anomaly detection (AD) is an important machine learning task with many
real-world uses, including fraud detection, medical diagnosis, and industrial
monitoring. Within natural language processing (NLP), AD helps detect issues
like spam, misinformation, and unusual user activity. Although large language
models (LLMs) have had a strong impact on tasks such as text generation and
summarization, their potential in AD has not been studied enough. This paper
introduces AD-LLM, the first benchmark that evaluates how LLMs can help with
NLP anomaly detection. We examine three key tasks: (i) zero-shot detection,
using LLMs' pre-trained knowledge to perform AD without tasks-specific
training; (ii) data augmentation, generating synthetic data and category
descriptions to improve AD models; and (iii) model selection, using LLMs to
suggest unsupervised AD models. Through experiments with different datasets, we
find that LLMs can work well in zero-shot AD, that carefully designed
augmentation methods are useful, and that explaining model selection for
specific datasets remains challenging. Based on these results, we outline six
future research directions on LLMs for AD.",2024-12-15,"Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao",http://arxiv.org/pdf/2412.11142v3,cs.CL
Feature engineering vs. deep learning for paper section identification: Toward applications in Chinese medical literature,"Section identification is an important task for library science, especially
knowledge management. Identifying the sections of a paper would help filter
noise in entity and relation extraction. In this research, we studied the paper
section identification problem in the context of Chinese medical literature
analysis, where the subjects, methods, and results are more valuable from a
physician's perspective. Based on previous studies on English literature
section identification, we experiment with the effective features to use with
classic machine learning algorithms to tackle the problem. It is found that
Conditional Random Fields, which consider sentence interdependency, is more
effective in combining different feature sets, such as bag-of-words,
part-of-speech, and headings, for Chinese literature section identification.
Moreover, we find that classic machine learning algorithms are more effective
than generic deep learning models for this problem. Based on these
observations, we design a novel deep learning model, the Structural
Bidirectional Long Short-Term Memory (SLSTM) model, which models word and
sentence interdependency together with the contextual information. Experiments
on a human-curated asthma literature dataset show that our approach outperforms
the traditional machine learning methods and other deep learning methods and
achieves close to 90% precision and recall in the task. The model shows good
potential for use in other text mining tasks. The research has significant
methodological and practical implications.",2024-12-15,"Sijia Zhou, Xin Li",http://arxiv.org/pdf/2412.11125v1,cs.CL
Hanprome: Modified Hangeul for Expression of foreign language pronunciation,"Hangeul was created as a phonetic alphabet and is known to have the best 1:1
correspondence between letters and pronunciation among existing alphabets. In
this paper, we examine the possibility of modifying the basic form of Hangeul
and using it as a kind of phonetic symbol. The core concept of this approach is
to preserve the basic form of the alphabet, modifying only the shape of a
stroke rather than the letter itself. To the best of our knowledge, no previous
attempts in any language have been made to express pronunciations of an
alphabet different from the original simply by changing the shape of the
alphabet strokes, and this paper is probably the first attempt in this
direction.",2024-12-15,"Wonchan Kim, Michelle Meehyun Kim",http://arxiv.org/pdf/2412.11090v2,cs.CL
NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages,"Nowadays, Natural Language Processing (NLP) is an important tool for most
people's daily life routines, ranging from understanding speech, translation,
named entity recognition (NER), and text categorization, to generative text
models such as ChatGPT. Due to the existence of big data and consequently large
corpora for widely used languages like English, Spanish, Turkish, Persian, and
many more, these applications have been developed accurately. However, the
Kurdish language still requires more corpora and large datasets to be included
in NLP applications. This is because Kurdish has a rich linguistic structure,
varied dialects, and a limited dataset, which poses unique challenges for
Kurdish NLP (KNLP) application development. While several studies have been
conducted in KNLP for various applications, Kurdish NER (KNER) remains a
challenge for many KNLP tasks, including text analysis and classification. In
this work, we address this limitation by proposing a methodology for
fine-tuning the pre-trained RoBERTa model for KNER. To this end, we first
create a Kurdish corpus, followed by designing a modified model architecture
and implementing the training procedures. To evaluate the trained model, a set
of experiments is conducted to demonstrate the performance of the KNER model
using different tokenization methods and trained models. The experimental
results show that fine-tuned RoBERTa with the SentencePiece tokenization method
substantially improves KNER performance, achieving a 12.8% improvement in
F1-score compared to traditional models, and consequently establishes a new
benchmark for KNLP.",2024-12-15,"Abdulhady Abas Abdullah, Srwa Hasan Abdulla, Dalia Mohammad Toufiq, Halgurd S. Maghdid, Tarik A. Rashid, Pakshan F. Farho, Shadan Sh. Sabr, Akar H. Taher, Darya S. Hamad, Hadi Veisi, Aras T. Asaad",http://arxiv.org/pdf/2412.15252v1,cs.CL
LAW: Legal Agentic Workflows for Custody and Fund Services Contracts,"Legal contracts in the custody and fund services domain govern critical
aspects such as key provider responsibilities, fee schedules, and
indemnification rights. However, it is challenging for an off-the-shelf Large
Language Model (LLM) to ingest these contracts due to the lengthy unstructured
streams of text, limited LLM context windows, and complex legal jargon. To
address these challenges, we introduce LAW (Legal Agentic Workflows for Custody
and Fund Services Contracts). LAW features a modular design that responds to
user queries by orchestrating a suite of domain-specific tools and text agents.
Our experiments demonstrate that LAW, by integrating multiple specialized
agents and tools, significantly outperforms the baseline. LAW excels
particularly in complex tasks such as calculating a contract's termination
date, surpassing the baseline by 92.9% points. Furthermore, LAW offers a
cost-effective alternative to traditional fine-tuned legal LLMs by leveraging
reusable, domain-specific tools.",2024-12-15,"William Watson, Nicole Cho, Nishan Srishankar, Zhen Zeng, Lucas Cecchi, Daniel Scott, Suchetha Siddagangappa, Rachneet Kaur, Tucker Balch, Manuela Veloso",http://arxiv.org/pdf/2412.11063v1,cs.CL
NITRO: LLM Inference on Intel Laptop NPUs,"Large Language Models (LLMs) have become essential tools in natural language
processing, finding large usage in chatbots such as ChatGPT and Gemini, and are
a central area of research. A particular area of interest includes designing
hardware specialized for these AI applications, with one such example being the
neural processing unit (NPU). In 2023, Intel released the Intel Core Ultra
processor with codename Meteor Lake, featuring a CPU, GPU, and NPU
system-on-chip. However, official software support for the NPU through Intel's
OpenVINO framework is limited to static model inference. The dynamic nature of
autoregressive token generation in LLMs is therefore not supported out of the
box. To address this shortcoming, we present NITRO (NPU Inference for
Transformers Optimization), a Python-based framework built on top of OpenVINO
to support text and chat generation on NPUs. In this paper, we discuss in
detail the key modifications made to the transformer architecture to enable
inference, some performance benchmarks, and future steps towards improving the
package. The code repository for NITRO can be found here:
https://github.com/abdelfattah-lab/nitro.",2024-12-15,"Anthony Fei, Mohamed S. Abdelfattah",http://arxiv.org/pdf/2412.11053v1,cs.CL
AgentPS: Agentic Process Supervision for Multi-modal Content Quality Assurance through Multi-round QA,"The advanced processing and reasoning capabilities of multimodal large
language models (MLLMs) have driven substantial progress in vision-language
(VL) understanding tasks. However, while effective for tasks governed by
straightforward logic, MLLMs often encounter challenges when reasoning over
complex, interdependent logic structures. To address this limitation, we
introduce \textit{AgentPS}, a novel framework that integrates Agentic Process
Supervision into MLLMs via multi-round question answering during fine-tuning.
\textit{AgentPS} demonstrates significant performance improvements over
baseline MLLMs on proprietary TikTok datasets, due to its integration of
process supervision and structured sequential reasoning. Furthermore, we show
that replacing human-annotated labels with LLM-generated labels retains much of
the performance gain, highlighting the framework's practical scalability in
industrial applications. These results position \textit{AgentPS} as a highly
effective and efficient architecture for multimodal classification tasks. Its
adaptability and scalability, especially when enhanced by automated annotation
generation, make it a powerful tool for handling large-scale, real-world
challenges.",2024-12-15,"Gorden Liu, Yu Sun, Ruixiao Sun, Xin Dong, Hongyu Xiong",http://arxiv.org/pdf/2412.15251v1,cs.CL
Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models,"Although large language models (LLMs) achieve effective safety alignment at
the time of release, they still face various safety challenges. A key issue is
that fine-tuning often compromises the safety alignment of LLMs. To address
this issue, we propose a method named IRR (Identify, Remove, and Recalibrate
for Safety Realignment) that performs safety realignment for LLMs. The core of
IRR is to identify and remove unsafe delta parameters from the fine-tuned
models, while recalibrating the retained ones. We evaluate the effectiveness of
IRR across various datasets, including both full fine-tuning and LoRA methods.
Our results demonstrate that IRR significantly enhances the safety performance
of fine-tuned models on safety benchmarks, such as harmful queries and
jailbreak attacks, while maintaining their performance on downstream tasks. The
source code is available at: https://anonymous.4open.science/r/IRR-BD4F.",2024-12-15,"Di Wu, Xin Lu, Yanyan Zhao, Bing Qin",http://arxiv.org/pdf/2412.11041v3,cs.CL
An Enhanced Text Compression Approach Using Transformer-based Language Models,"Text compression shrinks textual data while keeping crucial information,
eradicating constraints on storage, bandwidth, and computational efficacy. The
integration of lossless compression techniques with transformer-based text
decompression has received negligible attention, despite the increasing volume
of English text data in communication. The primary barrier in advancing text
compression and restoration involves optimizing transformer-based approaches
with efficient pre-processing and integrating lossless compression algorithms,
that remained unresolved in the prior attempts. Here, we propose a
transformer-based method named RejuvenateForme for text decompression,
addressing prior issues by harnessing a new pre-processing technique and a
lossless compression method. Our meticulous pre-processing technique
incorporating the Lempel-Ziv-Welch algorithm achieves compression ratios of
12.57, 13.38, and 11.42 on the BookCorpus, EN-DE, and EN-FR corpora, thus
showing state-of-the-art compression ratios compared to other deep learning and
traditional approaches. Furthermore, the RejuvenateForme achieves a BLEU score
of 27.31, 25.78, and 50.45 on the EN-DE, EN-FR, and BookCorpus corpora,
showcasing its comprehensive efficacy. In contrast, the pre-trained T5-Small
exhibits better performance over prior state-of-the-art models.",2024-12-15,"Chowdhury Mofizur Rahman, Mahbub E Sobhani, Anika Tasnim Rodela, Swakkhar Shatabda",http://arxiv.org/pdf/2412.15250v1,cs.CL
A Contextualized BERT model for Knowledge Graph Completion,"Knowledge graphs (KGs) are valuable for representing structured,
interconnected information across domains, enabling tasks like semantic search,
recommendation systems and inference. A pertinent challenge with KGs, however,
is that many entities (i.e., heads, tails) or relationships are unknown.
Knowledge Graph Completion (KGC) addresses this by predicting these missing
nodes or links, enhancing the graph's informational depth and utility.
Traditional methods like TransE and ComplEx predict tail entities but struggle
with unseen entities. Textual-based models leverage additional semantics but
come with high computational costs, semantic inconsistencies, and data
imbalance issues. Recent LLM-based models show improvement but overlook
contextual information and rely heavily on entity descriptions. In this study,
we introduce a contextualized BERT model for KGC that overcomes these
limitations by utilizing the contextual information from neighbouring entities
and relationships to predict tail entities. Our model eliminates the need for
entity descriptions and negative triplet sampling, reducing computational
demands while improving performance. Our model outperforms state-of-the-art
methods on standard datasets, improving Hit@1 by 5.3% and 4.88% on FB15k-237
and WN18RR respectively, setting a new benchmark in KGC.",2024-12-15,"Haji Gul, Abdul Ghani Naim, Ajaz A. Bhat",http://arxiv.org/pdf/2412.11016v1,cs.CL
Dual Traits in Probabilistic Reasoning of Large Language Models,"We conducted three experiments to investigate how large language models
(LLMs) evaluate posterior probabilities. Our results reveal the coexistence of
two modes in posterior judgment among state-of-the-art models: a normative
mode, which adheres to Bayes' rule, and a representative-based mode, which
relies on similarity -- paralleling human System 1 and System 2 thinking.
Additionally, we observed that LLMs struggle to recall base rate information
from their memory, and developing prompt engineering strategies to mitigate
representative-based judgment may be challenging. We further conjecture that
the dual modes of judgment may be a result of the contrastive loss function
employed in reinforcement learning from human feedback. Our findings underscore
the potential direction for reducing cognitive biases in LLMs and the necessity
for cautious deployment of LLMs in critical areas.",2024-12-15,"Shenxiong Li, Huaxia Rui",http://arxiv.org/pdf/2412.11009v1,cs.CL
"LitLLMs, LLMs for Literature Review: Are we there yet?","Literature reviews are an essential component of scientific research, but
they remain time-intensive and challenging to write, especially due to the
recent influx of research papers. This paper explores the zero-shot abilities
of recent Large Language Models (LLMs) in assisting with the writing of
literature reviews based on an abstract. We decompose the task into two
components: 1. Retrieving related works given a query abstract, and 2. Writing
a literature review based on the retrieved results. We analyze how effective
LLMs are for both components. For retrieval, we introduce a novel two-step
search strategy that first uses an LLM to extract meaningful keywords from the
abstract of a paper and then retrieves potentially relevant papers by querying
an external knowledge base. Additionally, we study a prompting-based re-ranking
mechanism with attribution and show that re-ranking doubles the normalized
recall compared to naive search methods, while providing insights into the
LLM's decision-making process. In the generation phase, we propose a two-step
approach that first outlines a plan for the review and then executes steps in
the plan to generate the actual review. To evaluate different LLM-based
literature review methods, we create test sets from arXiv papers using a
protocol designed for rolling use with newly released LLMs to avoid test set
contamination in zero-shot evaluations. We release this evaluation protocol to
promote additional research and development in this regard. Our empirical
results suggest that LLMs show promising potential for writing literature
reviews when the task is decomposed into smaller components of retrieval and
planning. Our project page including a demonstration system and toolkit can be
accessed here: https://litllm.github.io.",2024-12-15,"Shubham Agarwal, Gaurav Sahu, Abhay Puri, Issam H. Laradji, Krishnamurthy DJ Dvijotham, Jason Stanley, Laurent Charlin, Christopher Pal",http://arxiv.org/pdf/2412.15249v2,cs.CL
Entropy-Regularized Process Reward Model,"Large language models (LLMs) have shown promise in performing complex
multi-step reasoning, yet they continue to struggle with mathematical
reasoning, often making systematic errors. A promising solution is
reinforcement learning (RL) guided by reward models, particularly those
focusing on process rewards, which score each intermediate step rather than
solely evaluating the final outcome. This approach is more effective at guiding
policy models towards correct reasoning trajectories. In this work, we propose
an entropy-regularized process reward model (ER-PRM) that integrates
KL-regularized Markov Decision Processes (MDP) to balance policy optimization
with the need to prevent the policy from shifting too far from its initial
distribution. We derive a novel reward construction method based on the
theoretical results. Our theoretical analysis shows that we could derive the
optimal reward model from the initial policy sampling. Our empirical
experiments on the MATH and GSM8K benchmarks demonstrate that ER-PRM
consistently outperforms existing process reward models, achieving 1%
improvement on GSM8K and 2-3% improvement on MATH under best-of-N evaluation,
and more than 1% improvement under RLHF. These results highlight the efficacy
of entropy-regularization in enhancing LLMs' reasoning capabilities.",2024-12-15,"Hanning Zhang, Pengcheng Wang, Shizhe Diao, Yong Lin, Rui Pan, Hanze Dong, Dylan Zhang, Pavlo Molchanov, Tong Zhang",http://arxiv.org/pdf/2412.11006v1,cs.CL
Navigating Dialectal Bias and Ethical Complexities in Levantine Arabic Hate Speech Detection,"Social media platforms have become central to global communication, yet they
also facilitate the spread of hate speech. For underrepresented dialects like
Levantine Arabic, detecting hate speech presents unique cultural, ethical, and
linguistic challenges. This paper explores the complex sociopolitical and
linguistic landscape of Levantine Arabic and critically examines the
limitations of current datasets used in hate speech detection. We highlight the
scarcity of publicly available, diverse datasets and analyze the consequences
of dialectal bias within existing resources. By emphasizing the need for
culturally and contextually informed natural language processing (NLP) tools,
we advocate for a more nuanced and inclusive approach to hate speech detection
in the Arab world.",2024-12-14,"Ahmed Haj Ahmed, Rui-Jie Yew, Xerxes Minocher, Suresh Venkatasubramanian",http://arxiv.org/pdf/2412.10991v1,cs.CL
Can LLMs Help Create Grammar?: Automating Grammar Creation for Endangered Languages with In-Context Learning,"Yes! In the present-day documenting and preserving endangered languages, the
application of Large Language Models (LLMs) presents a promising approach. This
paper explores how LLMs, particularly through in-context learning, can assist
in generating grammatical information for low-resource languages with limited
amount of data. We takes Moklen as a case study to evaluate the efficacy of
LLMs in producing coherent grammatical rules and lexical entries using only
bilingual dictionaries and parallel sentences of the unknown language without
building the model from scratch. Our methodology involves organising the
existing linguistic data and prompting to efficiently enable to generate formal
XLE grammar. Our results demonstrate that LLMs can successfully capture key
grammatical structures and lexical information, although challenges such as the
potential for English grammatical biases remain. This study highlights the
potential of LLMs to enhance language documentation efforts, providing a
cost-effective solution for generating linguistic data and contributing to the
preservation of endangered languages.",2024-12-14,"Piyapath T Spencer, Nanthipat Kongborrirak",http://arxiv.org/pdf/2412.10960v1,cs.CL
RoundTripOCR: A Data Generation Technique for Enhancing Post-OCR Error Correction in Low-Resource Devanagari Languages,"Optical Character Recognition (OCR) technology has revolutionized the
digitization of printed text, enabling efficient data extraction and analysis
across various domains. Just like Machine Translation systems, OCR systems are
prone to errors. In this work, we address the challenge of data generation and
post-OCR error correction, specifically for low-resource languages. We propose
an approach for synthetic data generation for Devanagari languages,
RoundTripOCR, that tackles the scarcity of the post-OCR Error Correction
datasets for low-resource languages. We release post-OCR text correction
datasets for Hindi, Marathi, Bodo, Nepali, Konkani and Sanskrit. We also
present a novel approach for OCR error correction by leveraging techniques from
machine translation. Our method involves translating erroneous OCR output into
a corrected form by treating the OCR errors as mistranslations in a parallel
text corpus, employing pre-trained transformer models to learn the mapping from
erroneous to correct text pairs, effectively correcting OCR errors.",2024-12-14,"Harshvivek Kashid, Pushpak Bhattacharyya",http://arxiv.org/pdf/2412.15248v2,cs.CL
Human-Centric NLP or AI-Centric Illusion?: A Critical Investigation,"Human-Centric NLP often claims to prioritise human needs and values, yet many
implementations reveal an underlying AI-centric focus. Through an analysis of
case studies in language modelling, behavioural testing, and multi-modal
alignment, this study identifies a significant gap between the ideas of
human-centricity and actual practices. Key issues include misalignment with
human-centred design principles, the reduction of human factors to mere
benchmarks, and insufficient consideration of real-world impacts. The
discussion explores whether Human-Centric NLP embodies true human-centred
design, emphasising the need for interdisciplinary collaboration and ethical
considerations. The paper advocates for a redefinition of Human-Centric NLP,
urging a broader focus on real-world utility and societal implications to
ensure that language technologies genuinely serve and empower users.",2024-12-14,Piyapath T Spencer,http://arxiv.org/pdf/2412.10939v1,cs.CL
Enhancing Discoverability in Enterprise Conversational Systems with Proactive Question Suggestions,"Enterprise conversational AI systems are becoming increasingly popular to
assist users in completing daily tasks such as those in marketing and customer
management. However, new users often struggle to ask effective questions,
especially in emerging systems with unfamiliar or evolving capabilities. This
paper proposes a framework to enhance question suggestions in conversational
enterprise AI systems by generating proactive, context-aware questions that try
to address immediate user needs while improving feature discoverability. Our
approach combines periodic user intent analysis at the population level with
chat session-based question generation. We evaluate the framework using
real-world data from the AI Assistant for Adobe Experience Platform (AEP),
demonstrating the improved usefulness and system discoverability of the AI
Assistant.",2024-12-14,"Xiaobin Shen, Daniel Lee, Sumit Ranjan, Sai Sree Harsha, Pawan Sevak, Yunyao Li",http://arxiv.org/pdf/2412.10933v1,cs.CL
"Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning","Tokenization is a necessary component within the current architecture of many
language models, including the transformer-based large language models (LLMs)
of Generative AI, yet its impact on the model's cognition is often overlooked.
We argue that LLMs demonstrate that the Distributional Hypothesis (DH) is
sufficient for reasonably human-like language performance, and that the
emergence of human-meaningful linguistic units among tokens and current
structural constraints motivate changes to existing, linguistically-agnostic
tokenization techniques, particularly with respect to their roles as (1)
semantic primitives and as (2) vehicles for conveying salient distributional
patterns from human language to the model. We explore tokenizations from a BPE
tokenizer; extant model vocabularies obtained from Hugging Face and tiktoken;
and the information in exemplar token vectors as they move through the layers
of a RoBERTa (large) model. Besides creating sub-optimal semantic building
blocks and obscuring the model's access to the necessary distributional
patterns, we describe how tokens and pretraining can act as a backdoor for bias
and other unwanted content, which current alignment practices may not
remediate. Additionally, we relay evidence that the tokenization algorithm's
objective function impacts the LLM's cognition, despite being arguably
meaningfully insulated from the main system intelligence. [First uploaded to
arXiv in December, 2024.]",2024-12-14,"Julia Witte Zimmerman, Denis Hudon, Kathryn Cramer, Alejandro J. Ruiz, Calla Beauregard, Ashley Fehr, Mikaela Irene Fudolig, Bradford Demarest, Yoshi Meke Bird, Milo Z. Trujillo, Christopher M. Danforth, Peter Sheridan Dodds",http://arxiv.org/pdf/2412.10924v4,cs.CL
LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages,"The rise of chronic diseases and pandemics like COVID-19 has emphasized the
need for effective patient data processing while ensuring privacy through
anonymization and de-identification of protected health information (PHI).
Anonymized data facilitates research without compromising patient
confidentiality. This paper introduces expert small AI models developed using
the LLM-in-the-loop methodology to meet the demand for domain-specific
de-identification NER models. These models overcome the privacy risks
associated with large language models (LLMs) used via APIs by eliminating the
need to transmit or store sensitive data. More importantly, they consistently
outperform LLMs in de-identification tasks, offering superior performance and
reliability. Our de-identification NER models, developed in eight languages
(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)
achieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,
0.978, and 0.953 respectively. These results establish them as the most
accurate healthcare anonymization solutions, surpassing existing small models
and even general-purpose LLMs such as GPT-4o. While Part-1 of this series
introduced the LLM-in-the-loop methodology for bio-medical document
translation, this second paper showcases its success in developing
cost-effective expert small NER models in de-identification tasks. Our findings
lay the groundwork for future healthcare AI innovations, including biomedical
entity and relation extraction, demonstrating the value of specialized models
for domain-specific challenges.",2024-12-14,"Murat Gunay, Bunyamin Keles, Raife Hizlan",http://arxiv.org/pdf/2412.10918v1,cs.CL
Quantifying Extreme Opinions on Reddit Amidst the 2023 Israeli-Palestinian Conflict,"This study investigates the dynamics of extreme opinions on social media
during the 2023 Israeli-Palestinian conflict, utilising a comprehensive dataset
of over 450,000 posts from four Reddit subreddits (r/Palestine, r/Judaism,
r/IsraelPalestine, and r/worldnews). A lexicon-based, unsupervised methodology
was developed to measure ""extreme opinions"" by considering factors such as
anger, polarity, and subjectivity. The analysis identifies significant peaks in
extremism scores that correspond to pivotal real-life events, such as the IDF's
bombings of Al Quds Hospital and the Jabalia Refugee Camp, and the end of a
ceasefire following a terrorist attack. Additionally, this study explores the
distribution and correlation of these scores across different subreddits and
over time, providing insights into the propagation of polarised sentiments in
response to conflict events. By examining the quantitative effects of each
score on extremism and analysing word cloud similarities through Jaccard
indices, the research offers a nuanced understanding of the factors driving
extreme online opinions. This approach underscores the potential of social
media analytics in capturing the complex interplay between real-world events
and online discourse, while also highlighting the limitations and challenges of
measuring extremism in social media contexts.",2024-12-14,"Alessio Guerra, Marcello Lepre, Oktay Karakus",http://arxiv.org/pdf/2412.10913v1,cs.CL
SusGen-GPT: A Data-Centric LLM for Financial NLP and Sustainability Report Generation,"The rapid growth of the financial sector and the rising focus on
Environmental, Social, and Governance (ESG) considerations highlight the need
for advanced NLP tools. However, open-source LLMs proficient in both finance
and ESG domains remain scarce. To address this gap, we introduce SusGen-30K, a
category-balanced dataset comprising seven financial NLP tasks and ESG report
generation, and propose TCFD-Bench, a benchmark for evaluating sustainability
report generation. Leveraging this dataset, we developed SusGen-GPT, a suite of
models achieving state-of-the-art performance across six adapted and two
off-the-shelf tasks, trailing GPT-4 by only 2% despite using 7-8B parameters
compared to GPT-4's 1,700B. Based on this, we propose the SusGen system,
integrated with Retrieval-Augmented Generation (RAG), to assist in
sustainability report generation. This work demonstrates the efficiency of our
approach, advancing research in finance and ESG.",2024-12-14,"Qilong Wu, Xiaoneng Xiang, Hejia Huang, Xuan Wang, Yeo Wei Jie, Ranjan Satapathy, Ricardo Shirota Filho, Bharadwaj Veeravalli",http://arxiv.org/pdf/2412.10906v1,cs.CL
Streamlining Systematic Reviews: A Novel Application of Large Language Models,"Systematic reviews (SRs) are essential for evidence-based guidelines but are
often limited by the time-consuming nature of literature screening. We propose
and evaluate an in-house system based on Large Language Models (LLMs) for
automating both title/abstract and full-text screening, addressing a critical
gap in the literature. Using a completed SR on Vitamin D and falls (14,439
articles), the LLM-based system employed prompt engineering for title/abstract
screening and Retrieval-Augmented Generation (RAG) for full-text screening. The
system achieved an article exclusion rate (AER) of 99.5%, specificity of 99.6%,
a false negative rate (FNR) of 0%, and a negative predictive value (NPV) of
100%. After screening, only 78 articles required manual review, including all
20 identified by traditional methods, reducing manual screening time by 95.5%.
For comparison, Rayyan, a commercial tool for title/abstract screening,
achieved an AER of 72.1% and FNR of 5% when including articles Rayyan
considered as undecided or likely to include. Lowering Rayyan's inclusion
thresholds improved FNR to 0% but increased screening time. By addressing both
screening phases, the LLM-based system significantly outperformed Rayyan and
traditional methods, reducing total screening time to 25.5 hours while
maintaining high accuracy. These findings highlight the transformative
potential of LLMs in SR workflows by offering a scalable, efficient, and
accurate solution, particularly for the full-text screening phase, which has
lacked automation tools.",2024-12-14,"Fouad Trad, Ryan Yammine, Jana Charafeddine, Marlene Chakhtoura, Maya Rahme, Ghada El-Hajj Fuleihan, Ali Chehab",http://arxiv.org/pdf/2412.15247v1,cs.CL
BgGPT 1.0: Extending English-centric LLMs to other languages,"We present BgGPT-Gemma-2-27B-Instruct and BgGPT-Gemma-2-9B-Instruct:
continually pretrained and fine-tuned versions of Google's Gemma-2 models,
specifically optimized for Bulgarian language understanding and generation.
Leveraging Gemma-2's multilingual capabilities and over 100 billion tokens of
Bulgarian and English text data, our models demonstrate strong performance in
Bulgarian language tasks, setting a new standard for language-specific AI
models. Our approach maintains the robust capabilities of the original Gemma-2
models, ensuring that the English language performance remains intact. To
preserve the base model capabilities, we incorporate continual learning
strategies based on recent Branch-and-Merge techniques as well as thorough
curation and selection of training data. We provide detailed insights into our
methodology, including the release of model weights with a commercial-friendly
license, enabling broader adoption by researchers, companies, and hobbyists.
Further, we establish a comprehensive set of benchmarks based on non-public
educational data sources to evaluate models on Bulgarian language tasks as well
as safety and chat capabilities. Our findings demonstrate the effectiveness of
fine-tuning state-of-the-art models like Gemma 2 to enhance language-specific
AI applications while maintaining cross-lingual capabilities.",2024-12-14,"Anton Alexandrov, Veselin Raychev, Dimitar I. Dimitrov, Ce Zhang, Martin Vechev, Kristina Toutanova",http://arxiv.org/pdf/2412.10893v1,cs.CL
A Novel End-To-End Event Geolocation Method Leveraging Hyperbolic Space and Toponym Hierarchies,"Timely detection and geolocation of events based on social data can provide
critical information for applications such as crisis response and resource
allocation. However, most existing methods are greatly affected by event
detection errors, leading to insufficient geolocation accuracy. To this end,
this paper proposes a novel end-to-end event geolocation method (GTOP)
leveraging Hyperbolic space and toponym hierarchies. Specifically, the proposed
method contains one event detection module and one geolocation module. The
event detection module constructs a heterogeneous information networks based on
social data, and then constructs a homogeneous message graph and combines it
with the text and time feature of the message to learning initial features of
nodes. Node features are updated in Hyperbolic space and then fed into a
classifier for event detection. To reduce the geolocation error, this paper
proposes a noise toponym filtering algorithm (HIST) based on the hierarchical
structure of toponyms. HIST analyzes the hierarchical structure of toponyms
mentioned in the event cluster, taking the highly frequent city-level locations
as the coarse-grained locations for events. By comparing the hierarchical
structure of the toponyms within the cluster against those of the
coarse-grained locations of events, HIST filters out noisy toponyms. To further
improve the geolocation accuracy, we propose a fine-grained pseudo toponyms
generation algorithm (FIT) based on the output of HIST, and combine generated
pseudo toponyms with filtered toponyms to locate events based on the geographic
center points of the combined toponyms. Extensive experiments are conducted on
the Chinese dataset constructed in this paper and another public English
dataset. The experimental results show that the proposed method is superior to
the state-of-the-art baselines.",2024-12-14,"Yaqiong Qiao, Guojun Huang",http://arxiv.org/pdf/2412.10870v1,cs.CL
CRENER: A Character Relation Enhanced Chinese NER Model,"Chinese Named Entity Recognition (NER) is an important task in information
extraction, which has a significant impact on downstream applications. Due to
the lack of natural separators in Chinese, previous NER methods mostly relied
on external dictionaries to enrich the semantic and boundary information of
Chinese words. However, such methods may introduce noise that affects the
accuracy of named entity recognition. To this end, we propose a character
relation enhanced Chinese NER model (CRENER). This model defines four types of
tags that reflect the relationships between characters, and proposes a
fine-grained modeling of the relationships between characters based on three
types of relationships: adjacency relations between characters, relations
between characters and tags, and relations between tags, to more accurately
identify entity boundaries and improve Chinese NER accuracy. Specifically, we
transform the Chinese NER task into a character-character relationship
classification task, ensuring the accuracy of entity boundary recognition
through joint modeling of relation tags. To enhance the model's ability to
understand contextual information, WRENER further constructed an adapted
transformer encoder that combines unscaled direction-aware and distance-aware
masked self-attention mechanisms. Moreover, a relationship representation
enhancement module was constructed to model predefined relationship tags,
effectively mining the relationship representations between characters and
tags. Experiments conducted on four well-known Chinese NER benchmark datasets
have shown that the proposed model outperforms state-of-the-art baselines. The
ablation experiment also demonstrated the effectiveness of the proposed model.",2024-12-14,"Yaqiong Qiao, Shixuan Peng",http://arxiv.org/pdf/2412.10858v1,cs.CL
Superhuman performance of a large language model on the reasoning tasks of a physician,"A seminal paper published by Ledley and Lusted in 1959 introduced complex
clinical diagnostic reasoning cases as the gold standard for the evaluation of
expert medical computing systems, a standard that has held ever since. Here, we
report the results of a physician evaluation of a large language model (LLM) on
challenging clinical cases against a baseline of hundreds of physicians. We
conduct five experiments to measure clinical reasoning across differential
diagnosis generation, display of diagnostic reasoning, triage differential
diagnosis, probabilistic reasoning, and management reasoning, all adjudicated
by physician experts with validated psychometrics. We then report a real-world
study comparing human expert and AI second opinions in randomly-selected
patients in the emergency room of a major tertiary academic medical center in
Boston, MA. We compared LLMs and board-certified physicians at three predefined
diagnostic touchpoints: triage in the emergency room, initial evaluation by a
physician, and admission to the hospital or intensive care unit. In all
experiments--both vignettes and emergency room second opinions--the LLM
displayed superhuman diagnostic and reasoning abilities, as well as continued
improvement from prior generations of AI clinical decision support. Our study
suggests that LLMs have achieved superhuman performance on general medical
diagnostic and management reasoning, fulfilling the vision put forth by Ledley
and Lusted, and motivating the urgent need for prospective trials.",2024-12-14,"Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian D. Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Liam G. McCoy, Haadi Mombini, Christopher Lucas, Misha Fotoohi, Matthew Gwiazdon, Daniele Restifo, Daniel Restrepo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman",http://arxiv.org/pdf/2412.10849v2,cs.CL
Large Language Models for Medical Forecasting -- Foresight 2,"Foresight 2 (FS2) is a large language model fine-tuned on hospital data for
modelling patient timelines (GitHub 'removed for anon'). It can understand
patients' clinical notes and predict SNOMED codes for a wide range of
biomedical use cases, including diagnosis suggestions, risk forecasting, and
procedure and medication recommendations. FS2 is trained on the free text
portion of the MIMIC-III dataset, firstly through extracting biomedical
concepts and then creating contextualised patient timelines, upon which the
model is then fine-tuned. The results show significant improvement over the
previous state-of-the-art for the next new biomedical concept prediction (P/R -
0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new
disorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of
risk forecast, we compare our model to GPT-4-turbo (and a range of open-source
biomedical LLMs) and show that FS2 performs significantly better on such tasks
(P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data
into LLMs and shows that small models outperform much larger ones when
fine-tuned on high-quality, specialised data.",2024-12-14,"Zeljko Kraljevic, Joshua Au Yeung, Daniel Bean, James Teo, Richard J. Dobson",http://arxiv.org/pdf/2412.10848v1,cs.CL
Rethinking Chain-of-Thought from the Perspective of Self-Training,"Chain-of-thought (CoT) reasoning has emerged as an effective approach for
activating latent capabilities in LLMs. Interestingly, we observe that both CoT
reasoning and self-training share the core objective: iteratively leveraging
model-generated information to progressively reduce prediction uncertainty.
Building on this insight, we propose a novel CoT framework to improve reasoning
performance. Our framework integrates two key components: (i) a task-specific
prompt module that optimizes the initial reasoning process, and (ii) an
adaptive reasoning iteration module that dynamically refines the reasoning
process and addresses the limitations of previous CoT approaches, \ie
over-reasoning and high similarity between consecutive reasoning iterations.
Extensive experiments demonstrate that the proposed method achieves significant
advantages in both performance and computational efficiency.",2024-12-14,"Zongqian Wu, Baoduo Xu, Ruochen Cui, Mengmeng Zhan, Xiaofeng Zhu, Lei Feng",http://arxiv.org/pdf/2412.10827v4,cs.CL
FinGPT: Enhancing Sentiment-Based Stock Movement Prediction with Dissemination-Aware and Context-Enriched LLMs,"Financial sentiment analysis is crucial for understanding the influence of
news on stock prices. Recently, large language models (LLMs) have been widely
adopted for this purpose due to their advanced text analysis capabilities.
However, these models often only consider the news content itself, ignoring its
dissemination, which hampers accurate prediction of short-term stock movements.
Additionally, current methods often lack sufficient contextual data and
explicit instructions in their prompts, limiting LLMs' ability to interpret
news. In this paper, we propose a data-driven approach that enhances
LLM-powered sentiment-based stock movement predictions by incorporating news
dissemination breadth, contextual data, and explicit instructions. We cluster
recent company-related news to assess its reach and influence, enriching
prompts with more specific data and precise instructions. This data is used to
construct an instruction tuning dataset to fine-tune an LLM for predicting
short-term stock price movements. Our experimental results show that our
approach improves prediction accuracy by 8\% compared to existing methods.",2024-12-14,"Yixuan Liang, Yuncong Liu, Boyu Zhang, Christina Dan Wang, Hongyang Yang",http://arxiv.org/pdf/2412.10823v1,cs.CL
Are Language Models Agnostic to Linguistically Grounded Perturbations? A Case Study of Indic Languages,"Pre-trained language models (PLMs) are known to be susceptible to
perturbations to the input text, but existing works do not explicitly focus on
linguistically grounded attacks, which are subtle and more prevalent in nature.
In this paper, we study whether PLMs are agnostic to linguistically grounded
attacks or not. To this end, we offer the first study addressing this,
investigating different Indic languages and various downstream tasks. Our
findings reveal that although PLMs are susceptible to linguistic perturbations,
when compared to non-linguistic attacks, PLMs exhibit a slightly lower
susceptibility to linguistic attacks. This highlights that even constrained
attacks are effective. Moreover, we investigate the implications of these
outcomes across a range of languages, encompassing diverse language families
and different scripts.",2024-12-14,"Poulami Ghosh, Raj Dabre, Pushpak Bhattacharyya",http://arxiv.org/pdf/2412.10805v1,cs.CL
WEPO: Web Element Preference Optimization for LLM-based Web Navigation,"The rapid advancement of autonomous web navigation has significantly
benefited from grounding pretrained Large Language Models (LLMs) as agents.
However, current research has yet to fully leverage the redundancy of HTML
elements for contrastive training. This paper introduces a novel approach to
LLM-based web navigation tasks, called Web Element Preference Optimization
(WEPO). WEPO utilizes unsupervised preference learning by sampling
distance-based non-salient web elements as negative samples, optimizing maximum
likelihood objective within Direct Preference Optimization (DPO). We evaluate
WEPO on the Mind2Web benchmark and empirically demonstrate that WEPO aligns
user high-level intent with output actions more effectively. The results show
that our method achieved the state-of-the-art, with an improvement of 13.8%
over WebAgent and 5.3% over the visual language model CogAgent baseline. Our
findings underscore the potential of preference optimization to enhance web
navigation and other web page based tasks, suggesting a promising direction for
future research.",2024-12-14,"Jiarun Liu, Jia Hao, Chunhong Zhang, Zheng Hu",http://arxiv.org/pdf/2412.10742v1,cs.CL
HITgram: A Platform for Experimenting with n-gram Language Models,"Large language models (LLMs) are powerful but resource intensive, limiting
accessibility. HITgram addresses this gap by offering a lightweight platform
for n-gram model experimentation, ideal for resource-constrained environments.
It supports unigrams to 4-grams and incorporates features like context
sensitive weighting, Laplace smoothing, and dynamic corpus management to
e-hance prediction accuracy, even for unseen word sequences. Experiments
demonstrate HITgram's efficiency, achieving 50,000 tokens/second and generating
2-grams from a 320MB corpus in 62 seconds. HITgram scales efficiently,
constructing 4-grams from a 1GB file in under 298 seconds on an 8 GB RAM
system. Planned enhancements include multilingual support, advanced smoothing,
parallel processing, and model saving, further broadening its utility.",2024-12-14,"Shibaranjani Dasgupta, Chandan Maity, Somdip Mukherjee, Rohan Singh, Diptendu Dutta, Debasish Jana",http://arxiv.org/pdf/2412.10717v1,cs.CL
"Towards Effective, Efficient and Unsupervised Social Event Detection in the Hyperbolic Space","The vast, complex, and dynamic nature of social message data has posed
challenges to social event detection (SED). Despite considerable effort, these
challenges persist, often resulting in inadequately expressive message
representations (ineffective) and prolonged learning durations (inefficient).
In response to the challenges, this work introduces an unsupervised framework,
HyperSED (Hyperbolic SED). Specifically, the proposed framework first models
social messages into semantic-based message anchors, and then leverages the
structure of the anchor graph and the expressiveness of the hyperbolic space to
acquire structure- and geometry-aware anchor representations. Finally, HyperSED
builds the partitioning tree of the anchor message graph by incorporating
differentiable structural information as the reflection of the detected events.
Extensive experiments on public datasets demonstrate HyperSED's competitive
performance, along with a substantial improvement in efficiency compared to the
current state-of-the-art unsupervised paradigm. Statistically, HyperSED boosts
incremental SED by an average of 2%, 2%, and 25% in NMI, AMI, and ARI,
respectively; enhancing efficiency by up to 37.41 times and at least 12.10
times, illustrating the advancement of the proposed framework. Our code is
publicly available at https://github.com/XiaoyanWork/HyperSED.",2024-12-14,"Xiaoyan Yu, Yifan Wei, Shuaishuai Zhou, Zhiwei Yang, Li Sun, Hao Peng, Liehuang Zhu, Philip S. Yu",http://arxiv.org/pdf/2412.10712v1,cs.CL
Accelerating Retrieval-Augmented Generation,"An evolving solution to address hallucination and enhance accuracy in large
language models (LLMs) is Retrieval-Augmented Generation (RAG), which involves
augmenting LLMs with information retrieved from an external knowledge source,
such as the web. This paper profiles several RAG execution pipelines and
demystifies the complex interplay between their retrieval and generation
phases. We demonstrate that while exact retrieval schemes are expensive, they
can reduce inference time compared to approximate retrieval variants because an
exact retrieval model can send a smaller but more accurate list of documents to
the generative model while maintaining the same end-to-end accuracy. This
observation motivates the acceleration of the exact nearest neighbor search for
RAG.
  In this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL
device that implements a scale-out near-memory acceleration architecture with a
novel cache-coherent interface between the host CPU and near-memory
accelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a
512GB vector database compared with executing the search on Intel Sapphire
Rapids CPUs. This higher search performance translates to 1.7-26.3x lower
end-to-end inference time for representative RAG applications. IKS is
inherently a memory expander; its internal DRAM can be disaggregated and used
for other applications running on the server to prevent DRAM, which is the most
expensive component in today's servers, from being stranded.",2024-12-14,"Derrick Quinn, Mohammad Nouri, Neel Patel, John Salihu, Alireza Salemi, Sukhan Lee, Hamed Zamani, Mohammad Alian",http://arxiv.org/pdf/2412.15246v1,cs.CL
Efficient Adaptation of Multilingual Models for Japanese ASR,"This study explores fine-tuning multilingual ASR (Automatic Speech
Recognition) models, specifically OpenAI's Whisper-Tiny, to improve performance
in Japanese. While multilingual models like Whisper offer versatility, they
often lack precision in specific languages. Conversely, monolingual models like
ReazonSpeech excel in language-specific tasks but are less adaptable. Using
Japanese-specific datasets and Low-Rank Adaptation (LoRA) along with end-to-end
(E2E) training, we fine-tuned Whisper-Tiny to bridge this gap. Our results show
that fine-tuning reduced Whisper-Tiny's Character Error Rate (CER) from 32.7 to
20.8 with LoRA and to 14.7 with end-to-end fine-tuning, surpassing
Whisper-Base's CER of 20.2. However, challenges with domain-specific terms
remain, highlighting the need for specialized datasets. These findings
demonstrate that fine-tuning multilingual models can achieve strong
language-specific performance while retaining their flexibility. This approach
provides a scalable solution for improving ASR in resource-constrained
environments and languages with complex writing systems like Japanese.",2024-12-14,"Mark Bajo, Haruka Fukukawa, Ryuji Morita, Yuma Ogasawara",http://arxiv.org/pdf/2412.10705v1,cs.CL
VisDoM: Multi-Document QA with Visually Rich Elements Using Multimodal Retrieval-Augmented Generation,"Understanding information from a collection of multiple documents,
particularly those with visually rich elements, is important for
document-grounded question answering. This paper introduces VisDoMBench, the
first comprehensive benchmark designed to evaluate QA systems in multi-document
settings with rich multimodal content, including tables, charts, and
presentation slides. We propose VisDoMRAG, a novel multimodal Retrieval
Augmented Generation (RAG) approach that simultaneously utilizes visual and
textual RAG, combining robust visual retrieval capabilities with sophisticated
linguistic reasoning. VisDoMRAG employs a multi-step reasoning process
encompassing evidence curation and chain-of-thought reasoning for concurrent
textual and visual RAG pipelines. A key novelty of VisDoMRAG is its
consistency-constrained modality fusion mechanism, which aligns the reasoning
processes across modalities at inference time to produce a coherent final
answer. This leads to enhanced accuracy in scenarios where critical information
is distributed across modalities and improved answer verifiability through
implicit context attribution. Through extensive experiments involving
open-source and proprietary large language models, we benchmark
state-of-the-art document QA methods on VisDoMBench. Extensive results show
that VisDoMRAG outperforms unimodal and long-context LLM baselines for
end-to-end multimodal document QA by 12-20%.",2024-12-14,"Manan Suri, Puneet Mathur, Franck Dernoncourt, Kanika Goswami, Ryan A. Rossi, Dinesh Manocha",http://arxiv.org/pdf/2412.10704v2,cs.CL
Learning to Verify Summary Facts with Fine-Grained LLM Feedback,"Training automatic summary fact verifiers often faces the challenge of a lack
of human-labeled data. In this paper, we explore alternative way of leveraging
Large Language Model (LLM) generated feedback to address the inherent
limitation of using human-labeled data. We introduce FineSumFact, a large-scale
dataset containing fine-grained factual feedback on summaries. We employ 10
distinct LLMs for diverse summary generation and Llama-3-70B-Instruct for
feedback. We utilize this dataset to fine-tune the lightweight open-source
model Llama-3-8B-Instruct, optimizing resource efficiency while maintaining
high performance. Our experimental results reveal that the model trained on
extensive LLM-generated datasets surpasses that trained on smaller
human-annotated datasets when evaluated using human-generated test sets.
Fine-tuning fact verification models with LLM feedback can be more effective
and cost-efficient than using human feedback. The dataset is available at
https://github.com/DISL-Lab/FineSumFact.",2024-12-14,"Jihwan Oh, Jeonghwan Choi, Nicole Hee-Yeon Kim, Taewon Yun, Hwanjun Song",http://arxiv.org/pdf/2412.10689v1,cs.CL
Inference Scaling for Bridging Retrieval and Augmented Generation,"Retrieval-augmented generation (RAG) has emerged as a popular approach to
steering the output of a large language model (LLM) by incorporating retrieved
contexts as inputs. However, existing work observed the generator bias, such
that improving the retrieval results may negatively affect the outcome. In this
work, we show such bias can be mitigated, from inference scaling, aggregating
inference calls from the permuted order of retrieved contexts. The proposed
Mixture-of-Intervention (MOI) explicitly models the debiased utility of each
passage with multiple forward passes to construct a new ranking. We also show
that MOI can leverage the retriever's prior knowledge to reduce the
computational cost by minimizing the number of permutations considered and
lowering the cost per LLM call. We showcase the effectiveness of MOI on diverse
RAG tasks, improving ROUGE-L on MS MARCO and EM on HotpotQA benchmarks by ~7
points.",2024-12-14,"Youngwon Lee, Seung-won Hwang, Daniel Campos, Filip Graliński, Zhewei Yao, Yuxiong He",http://arxiv.org/pdf/2412.10684v1,cs.CL
"Chasing Progress, Not Perfection: Revisiting Strategies for End-to-End LLM Plan Generation","The capability of Large Language Models (LLMs) to plan remains a topic of
debate. Some critics argue that strategies to boost LLMs' reasoning skills are
ineffective in planning tasks, while others report strong outcomes merely from
training models on a planning corpus. This study reassesses recent strategies
by developing an end-to-end LLM planner and employing diverse metrics for a
thorough evaluation. We find that merely fine-tuning LLMs on a corpus of
planning instances does not lead to robust planning skills, as indicated by
poor performance on out-of-distribution test sets. At the same time, we find
that various strategies, including Chain-of-Thought, do enhance the probability
of a plan being executable. This indicates progress towards better plan
quality, despite not directly enhancing the final validity rate. Among the
strategies we evaluated, reinforcement learning with our novel `Longest
Contiguous Common Subsequence' reward emerged as the most effective,
contributing to both plan validity and executability. Overall, our research
addresses key misconceptions in the LLM-planning literature; we validate
incremental progress in plan executability, although plan validity remains a
challenge. Hence, future strategies should focus on both these aspects, drawing
insights from our findings.",2024-12-14,"Sukai Huang, Trevor Cohn, Nir Lipovetzky",http://arxiv.org/pdf/2412.10675v1,cs.CL
Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data,"Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language understanding and generation. However, they often struggle
with complex reasoning tasks and are prone to hallucination. Recent research
has shown promising results in leveraging knowledge graphs (KGs) to enhance LLM
performance. KGs provide a structured representation of entities and their
relationships, offering a rich source of information that can enhance the
reasoning capabilities of LLMs. For this work, we have developed different
techniques that tightly integrate KG structures and semantics into LLM
representations. Our results show that we are able to significantly improve the
performance of LLMs in complex reasoning scenarios, and ground the reasoning
process with KGs. We are the first to represent KGs with programming language
and fine-tune pretrained LLMs with KGs. This integration facilitates more
accurate and interpretable reasoning processes, paving the way for more
advanced reasoning capabilities of LLMs.",2024-12-14,"Xue Wu, Kostas Tsioutsiouliklis",http://arxiv.org/pdf/2412.10654v1,cs.CL
BinarySelect to Improve Accessibility of Black-Box Attack Research,"Adversarial text attack research is useful for testing the robustness of NLP
models, however, the rise of transformers has greatly increased the time
required to test attacks. Especially when researchers do not have access to
adequate resources (e.g. GPUs). This can hinder attack research, as modifying
one example for an attack can require hundreds of queries to a model,
especially for black-box attacks. Often these attacks remove one token at a
time to find the ideal one to change, requiring $n$ queries (the length of the
text) right away. We propose a more efficient selection method called
BinarySelect which combines binary search and attack selection methods to
greatly reduce the number of queries needed to find a token. We find that
BinarySelect only needs $\text{log}_2(n) * 2$ queries to find the first token
compared to $n$ queries. We also test BinarySelect in an attack setting against
5 classifiers across 3 datasets and find a viable tradeoff between number of
queries saved and attack effectiveness. For example, on the Yelp dataset, the
number of queries is reduced by 32% (72 less) with a drop in attack
effectiveness of only 5 points. We believe that BinarySelect can help future
researchers study adversarial attacks and black-box problems more efficiently
and opens the door for researchers with access to less resources.",2024-12-13,"Shatarupa Ghosh, Jonathan Rusert",http://arxiv.org/pdf/2412.10617v1,cs.CL
Evaluation of GPT-4o and GPT-4o-mini's Vision Capabilities for Compositional Analysis from Dried Solution Drops,"When microliter drops of salt solutions dry on non-porous surfaces, they form
erratic yet characteristic deposit patterns influenced by complex
crystallization dynamics and fluid motion. Using OpenAI's image-enabled
language models, we analyzed deposits from 12 salts with 200 images per salt
and per model. GPT-4o classified 57% of the salts accurately, significantly
outperforming random chance and GPT-4o mini. This study underscores the promise
of general-use AI tools for reliably identifying salts from their drying
patterns.",2024-12-13,"Deven B. Dangi, Beni B. Dangi, Oliver Steinbock",http://arxiv.org/pdf/2412.10587v2,cs.CL
WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models,"WHAT-IF -- Writing a Hero's Alternate Timeline through Interactive Fiction --
is a system that uses zero-shot meta-prompting to create branching narratives
from a prewritten story. Played as an interactive fiction (IF) game, WHAT-IF
lets the player choose between decisions that the large language model (LLM)
GPT-4 generates as possible branches in the story. Starting with an existing
linear plot as input, a branch is created at each key decision taken by the
main character. By meta-prompting the LLM to consider the major plot points
from the story, the system produces coherent and well-structured alternate
storylines. WHAT-IF stores the branching plot tree in a graph which helps it to
both keep track of the story for prompting and maintain the structure for the
final IF system. A video demo of our system can be found here:
https://youtu.be/8vBqjqtupcc.",2024-12-13,"Runsheng ""Anson"" Huang, Lara J. Martin, Chris Callison-Burch",http://arxiv.org/pdf/2412.10582v2,cs.CL
Evidence Contextualization and Counterfactual Attribution for Conversational QA over Heterogeneous Data with RAG Systems,"Retrieval Augmented Generation (RAG) works as a backbone for interacting with
an enterprise's own data via Conversational Question Answering (ConvQA). In a
RAG system, a retriever fetches passages from a collection in response to a
question, which are then included in the prompt of a large language model (LLM)
for generating a natural language (NL) answer. However, several RAG systems
today suffer from two shortcomings: (i) retrieved passages usually contain
their raw text and lack appropriate document context, negatively impacting both
retrieval and answering quality; and (ii) attribution strategies that explain
answer generation typically rely only on similarity between the answer and the
retrieved passages, thereby only generating plausible but not causal
explanations. In this work, we demonstrate RAGONITE, a RAG system that remedies
the above concerns by: (i) contextualizing evidence with source metadata and
surrounding text; and (ii) computing counterfactual attribution, a causal
explanation approach where the contribution of an evidence to an answer is
determined by the similarity of the original response to the answer obtained by
removing that evidence. To evaluate our proposals, we release a new benchmark
ConfQuestions: it has 300 hand-created conversational questions, each in
English and German, coupled with ground truth URLs, completed questions, and
answers from 215 public Confluence pages. These documents are typical of
enterprise wiki spaces with heterogeneous elements. Experiments with RAGONITE
on ConfQuestions show the viability of our ideas: contextualization improves
RAG performance, and counterfactual explanations outperform standard
attribution.",2024-12-13,"Rishiraj Saha Roy, Joel Schlotthauer, Chris Hinze, Andreas Foltyn, Luzian Hahn, Fabian Kuech",http://arxiv.org/pdf/2412.10571v3,cs.CL
Too Big to Fool: Resisting Deception in Language Models,"Large language models must balance their weight-encoded knowledge with
in-context information from prompts to generate accurate responses. This paper
investigates this interplay by analyzing how models of varying capacities
within the same family handle intentionally misleading in-context information.
Our experiments demonstrate that larger models exhibit higher resilience to
deceptive prompts, showcasing an advanced ability to interpret and integrate
prompt information with their internal knowledge. Furthermore, we find that
larger models outperform smaller ones in following legitimate instructions,
indicating that their resilience is not due to disregarding in-context
information. We also show that this phenomenon is likely not a result of
memorization but stems from the models' ability to better leverage implicit
task-relevant information from the prompt alongside their internally stored
knowledge.",2024-12-13,"Mohammad Reza Samsami, Mats Leon Richter, Juan Rodriguez, Megh Thakkar, Sarath Chandar, Maxime Gasse",http://arxiv.org/pdf/2412.10558v1,cs.CL
RAGServe: Fast Quality-Aware RAG Systems with Configuration Adaptation,"RAG (Retrieval Augmented Generation) allows LLMs (large language models) to
generate better responses with external knowledge, but using more external
knowledge often improves generation quality at the expense of response delay.
Prior work either reduces the response delay (through better scheduling of RAG
queries) or strives to maximize quality (which involves tuning the RAG
workflow), but they fall short in optimizing the tradeoff between the delay and
quality of RAG responses. This paper presents RAGServe, the first RAG system
that jointly schedules queries and adapts the key RAG configurations of each
query, such as the number of retrieved text chunks and synthesis methods, in
order to balance quality optimization and response delay reduction. Using 4
popular RAG-QA datasets, we show that compared with the state-of-the-art RAG
optimization schemes, RAGServe reduces the generation latency by
$1.64-2.54\times$ without sacrificing generation quality.",2024-12-13,"Siddhant Ray, Rui Pan, Zhuohan Gu, Kuntai Du, Ganesh Ananthanarayanan, Ravi Netravali, Junchen Jiang",http://arxiv.org/pdf/2412.10543v1,cs.CL
Exploring Text Representations for Online Misinformation,"Mis- and disinformation, commonly collectively called fake news, continue to
menace society. Perhaps, the impact of this age-old problem is presently most
plain in politics and healthcare. However, fake news is affecting an increasing
number of domains. It takes many different forms and continues to shapeshift as
technology advances. Though it arguably most widely spreads in textual form,
e.g., through social media posts and blog articles. Thus, it is imperative to
thwart the spread of textual misinformation, which necessitates its initial
detection. This thesis contributes to the creation of representations that are
useful for detecting misinformation. Firstly, it develops a novel method for
extracting textual features from news articles for misinformation detection.
These features harness the disparity between the thematic coherence of
authentic and false news stories. In other words, the composition of themes
discussed in both groups significantly differs as the story progresses.
Secondly, it demonstrates the effectiveness of topic features for fake news
detection, using classification and clustering. Clustering is particularly
useful because it alleviates the need for a labelled dataset, which can be
labour-intensive and time-consuming to amass. More generally, it contributes
towards a better understanding of misinformation and ways of detecting it using
Machine Learning and Natural Language Processing.",2024-12-13,Martins Samuel Dogo,http://arxiv.org/pdf/2412.18618v1,cs.CL
On Adversarial Robustness and Out-of-Distribution Robustness of Large Language Models,"The increasing reliance on large language models (LLMs) for diverse
applications necessitates a thorough understanding of their robustness to
adversarial perturbations and out-of-distribution (OOD) inputs. In this study,
we investigate the correlation between adversarial robustness and OOD
robustness in LLMs, addressing a critical gap in robustness evaluation. By
applying methods originally designed to improve one robustness type across both
contexts, we analyze their performance on adversarial and out-of-distribution
benchmark datasets. The input of the model consists of text samples, with the
output prediction evaluated in terms of accuracy, precision, recall, and F1
scores in various natural language inference tasks.
  Our findings highlight nuanced interactions between adversarial robustness
and OOD robustness, with results indicating limited transferability between the
two robustness types. Through targeted ablations, we evaluate how these
correlations evolve with different model sizes and architectures, uncovering
model-specific trends: smaller models like LLaMA2-7b exhibit neutral
correlations, larger models like LLaMA2-13b show negative correlations, and
Mixtral demonstrates positive correlations, potentially due to domain-specific
alignment. These results underscore the importance of hybrid robustness
frameworks that integrate adversarial and OOD strategies tailored to specific
models and domains. Further research is needed to evaluate these interactions
across larger models and varied architectures, offering a pathway to more
reliable and generalizable LLMs.",2024-12-13,"April Yang, Jordan Tab, Parth Shah, Paul Kotchavong",http://arxiv.org/pdf/2412.10535v1,cs.CL
Solving the Inverse Alignment Problem for Efficient RLHF,"Collecting high-quality preference datasets for reinforcement learning from
human feedback (RLHF) is resource-intensive and challenging. As a result,
researchers often train reward models on extensive offline datasets which
aggregate diverse generation sources and scoring/alignment policies. We
hypothesize that this aggregation has an averaging effect on reward model
scores, which limits signal and impairs the alignment process. Inspired by the
field of inverse RL, we define the 'inverse alignment problem' in language
model training, where our objective is to optimize the critic's reward for a
fixed actor and a fixed offline preference dataset. We hypothesize that solving
the inverse alignment problem will improve reward model quality by providing
clearer feedback on the policy's current behavior. To that end, we investigate
whether repeatedly fine-tuning a reward model on subsets of the offline
preference dataset aligned with a periodically frozen policy during RLHF
improves upon vanilla RLHF. Our empirical results demonstrate that this
approach facilitates superior alignment and faster convergence compared to
using an unaligned or out-of-distribution reward model relative to the LLM
policy.",2024-12-13,"Shambhavi Krishna, Aishwarya Sahoo",http://arxiv.org/pdf/2412.10529v1,cs.CL
DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts,"The proliferation of disinformation demands reliable and scalable
fact-checking solutions. We present Dynamic Evidence-based FAct-checking with
Multimodal Experts (DEFAME), a modular, zero-shot MLLM pipeline for
open-domain, text-image claim verification. DEFAME operates in a six-stage
process, dynamically selecting the tools and search depth to extract and
evaluate textual and visual evidence. Unlike prior approaches that are
text-only, lack explainability, or rely solely on parametric knowledge, DEFAME
performs end-to-end verification, accounting for images in claims and evidence
while generating structured, multimodal reports. Evaluation on the popular
benchmarks VERITE, AVerITeC, and MOCHEG shows that DEFAME surpasses all
previous methods, establishing itself as the new state-of-the-art fact-checking
system for uni- and multimodal fact-checking. Moreover, we introduce a new
benchmark, CLAIMREVIEW24+, featuring claims after the knowledge cutoff of GPT4o
to avoid data leakage. Here, DEFAME drastically outperforms the GPT
Chain-of-Thought baseline, demonstrating temporal generalizability and the
potential for real-time fact-checking.",2024-12-13,"Tobias Braun, Mark Rothermel, Marcus Rohrbach, Anna Rohrbach",http://arxiv.org/pdf/2412.10510v2,cs.CL
Do Large Language Models Show Biases in Causal Learning?,"Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this
research, we investigate whether large language models (LLMs) develop causal
illusions, both in real-world and controlled laboratory contexts of causal
learning and inference. To this end, we built a dataset of over 2K samples
including purely correlational cases, situations with null contingency, and
cases where temporal information excludes the possibility of causality by
placing the potential effect before the cause. We then prompted the models to
make statements or answer causal questions to evaluate their tendencies to
infer causation erroneously in these structured settings. Our findings show a
strong presence of causal illusion bias in LLMs. Specifically, in open-ended
generation tasks involving spurious correlations, the models displayed bias at
levels comparable to, or even lower than, those observed in similar studies on
human subjects. However, when faced with null-contingency scenarios or temporal
cues that negate causal relationships, where it was required to respond on a
0-100 scale, the models exhibited significantly higher bias. These findings
suggest that the models have not uniformly, consistently, or reliably
internalized the normative principles essential for accurate causal learning.",2024-12-13,"Maria Victoria Carro, Francisca Gauna Selasco, Denise Alejandra Mester, Margarita Gonzales, Mario A. Leiva, Maria Vanina Martinez, Gerardo I. Simari",http://arxiv.org/pdf/2412.10509v1,cs.CL
A Grounded Typology of Word Classes,"We propose a grounded approach to meaning in language typology. We treat data
from perceptual modalities, such as images, as a language-agnostic
representation of meaning. Hence, we can quantify the function--form
relationship between images and captions across languages. Inspired by
information theory, we define ""groundedness"", an empirical measure of
contextual semantic contentfulness (formulated as a difference in surprisal)
which can be computed with multilingual multimodal language models. As a proof
of concept, we apply this measure to the typology of word classes. Our measure
captures the contentfulness asymmetry between functional (grammatical) and
lexical (content) classes across languages, but contradicts the view that
functional classes do not convey content. Moreover, we find universal trends in
the hierarchy of groundedness (e.g., nouns > adjectives > verbs), and show that
our measure partly correlates with psycholinguistic concreteness norms in
English. We release a dataset of groundedness scores for 30 languages. Our
results suggest that the grounded typology approach can provide quantitative
evidence about semantic function in language.",2024-12-13,"Coleman Haley, Sharon Goldwater, Edoardo Ponti",http://arxiv.org/pdf/2412.10369v1,cs.CL
AdvPrefix: An Objective for Nuanced LLM Jailbreaks,"Many jailbreak attacks on large language models (LLMs) rely on a common
objective: making the model respond with the prefix ""Sure, here is (harmful
request)"". While straightforward, this objective has two limitations: limited
control over model behaviors, often resulting in incomplete or unrealistic
responses, and a rigid format that hinders optimization. To address these
limitations, we introduce AdvPrefix, a new prefix-forcing objective that
enables more nuanced control over model behavior while being easy to optimize.
Our objective leverages model-dependent prefixes, automatically selected based
on two criteria: high prefilling attack success rates and low negative
log-likelihood. It can further simplify optimization by using multiple prefixes
for a single user request. AdvPrefix can integrate seamlessly into existing
jailbreak attacks to improve their performance for free. For example, simply
replacing GCG attack's target prefixes with ours on Llama-3 improves nuanced
attack success rates from 14% to 80%, suggesting that current alignment
struggles to generalize to unseen prefixes. Our work demonstrates the
importance of jailbreak objectives in achieving nuanced jailbreaks.",2024-12-13,"Sicheng Zhu, Brandon Amos, Yuandong Tian, Chuan Guo, Ivan Evtimov",http://arxiv.org/pdf/2412.10321v1,cs.CL
SCBench: A KV Cache-Centric Analysis of Long-Context Methods,"Long-context LLMs have enabled numerous downstream applications but also
introduced significant challenges related to computational and memory
efficiency. To address these challenges, optimizations for long-context
inference have been developed, centered around the KV cache. However, existing
benchmarks often evaluate in single-request, neglecting the full lifecycle of
the KV cache in real-world use. This oversight is particularly critical, as KV
cache reuse has become widely adopted in LLMs inference frameworks, such as
vLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,
Google, and Anthropic. To address this gap, we introduce
SCBench(SharedContextBench), a comprehensive benchmark for evaluating
long-context methods from a KV cachecentric perspective: 1) KV cache
generation, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache
loading. Specifically, SCBench uses test examples with shared context, ranging
12 tasks with two shared context modes, covering four categories of
long-context capabilities: string retrieval, semantic retrieval, global
information, and multi-task. With it, we provide an extensive KV cache-centric
analysis of eight categories long-context solutions, including Gated Linear
RNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,
KV cache dropping, quantization, retrieval, loading, and prompt compression.
The evaluation is conducted on 8 long-context LLMs. Our findings show that
sub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding
with O(n) memory and sub-O(n^2) pre-filling computation perform robustly.
Dynamic sparsity yields more expressive KV caches than static patterns, and
layer-level sparsity in hybrid architectures reduces memory usage with strong
performance. Additionally, we identify attention distribution shift issues in
long-generation scenarios. https://aka.ms/SCBench.",2024-12-13,"Yucheng Li, Huiqiang Jiang, Qianhui Wu, Xufang Luo, Surin Ahn, Chengruidong Zhang, Amir H. Abdi, Dongsheng Li, Jianfeng Gao, Yuqing Yang, Lili Qiu",http://arxiv.org/pdf/2412.10319v2,cs.CL
Interlocking-free Selective Rationalization Through Genetic-based Learning,"A popular end-to-end architecture for selective rationalization is the
select-then-predict pipeline, comprising a generator to extract highlights fed
to a predictor. Such a cooperative system suffers from suboptimal equilibrium
minima due to the dominance of one of the two modules, a phenomenon known as
interlocking. While several contributions aimed at addressing interlocking,
they only mitigate its effect, often by introducing feature-based heuristics,
sampling, and ad-hoc regularizations. We present GenSPP, the first
interlocking-free architecture for selective rationalization that does not
require any learning overhead, as the above-mentioned. GenSPP avoids
interlocking by performing disjoint training of the generator and predictor via
genetic global search. Experiments on a synthetic and a real-world benchmark
show that our model outperforms several state-of-the-art competitors.",2024-12-13,"Federico Ruggeri, Gaetano Signorelli",http://arxiv.org/pdf/2412.10312v1,cs.CL
DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding,"We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE)
Vision-Language Models that significantly improves upon its predecessor,
DeepSeek-VL, through two key major upgrades. For the vision component, we
incorporate a dynamic tiling vision encoding strategy designed for processing
high-resolution images with different aspect ratios. For the language
component, we leverage DeepSeekMoE models with the Multi-head Latent Attention
mechanism, which compresses Key-Value cache into latent vectors, to enable
efficient inference and high throughput. Trained on an improved vision-language
dataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks,
including but not limited to visual question answering, optical character
recognition, document/table/chart understanding, and visual grounding. Our
model series is composed of three variants: DeepSeek-VL2-Tiny,
DeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated
parameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art
performance with similar or fewer activated parameters compared to existing
open-source dense and MoE-based models. Codes and pre-trained models are
publicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.",2024-12-13,"Zhiyu Wu, Xiaokang Chen, Zizheng Pan, Xingchao Liu, Wen Liu, Damai Dai, Huazuo Gao, Yiyang Ma, Chengyue Wu, Bingxuan Wang, Zhenda Xie, Yu Wu, Kai Hu, Jiawei Wang, Yaofeng Sun, Yukun Li, Yishi Piao, Kang Guan, Aixin Liu, Xin Xie, Yuxiang You, Kai Dong, Xingkai Yu, Haowei Zhang, Liang Zhao, Yisong Wang, Chong Ruan",http://arxiv.org/pdf/2412.10302v1,cs.CL
"Still ""Talking About Large Language Models"": Some Clarifications","My paper ""Talking About Large Language Models"" has more than once been
interpreted as advocating a reductionist stance towards large language models.
But the paper was not intended that way, and I do not endorse such positions.
This short note situates the paper in the context of a larger philosophical
project that is concerned with the (mis)use of words rather than metaphysics,
in the spirit of Wittgenstein's later writing.",2024-12-13,Murray Shanahan,http://arxiv.org/pdf/2412.10291v1,cs.CL
"One world, one opinion? The superstar effect in LLM responses","As large language models (LLMs) are shaping the way information is shared and
accessed online, their opinions have the potential to influence a wide
audience. This study examines who the LLMs view as the most prominent figures
across various fields, using prompts in ten different languages to explore the
influence of linguistic diversity. Our findings reveal low diversity in
responses, with a small number of figures dominating recognition across
languages (also known as the ""superstar effect""). These results highlight the
risk of narrowing global knowledge representation when LLMs retrieve subjective
information.",2024-12-13,"Sofie Goethals, Lauren Rhue",http://arxiv.org/pdf/2412.10281v1,cs.CL
Benchmarking Linguistic Diversity of Large Language Models,"The development and evaluation of Large Language Models (LLMs) has primarily
focused on their task-solving capabilities, with recent models even surpassing
human performance in some areas. However, this focus often neglects whether
machine-generated language matches the human level of diversity, in terms of
vocabulary choice, syntactic construction, and expression of meaning, raising
questions about whether the fundamentals of language generation have been fully
addressed. This paper emphasizes the importance of examining the preservation
of human linguistic richness by language models, given the concerning surge in
online content produced or aided by LLMs. We propose a comprehensive framework
for evaluating LLMs from various linguistic diversity perspectives including
lexical, syntactic, and semantic dimensions. Using this framework, we benchmark
several state-of-the-art LLMs across all diversity dimensions, and conduct an
in-depth case study for syntactic diversity. Finally, we analyze how different
development and deployment choices impact the linguistic diversity of LLM
outputs.",2024-12-13,"Yanzhu Guo, Guokan Shang, Chloé Clavel",http://arxiv.org/pdf/2412.10271v1,cs.CL
Reasoner Outperforms: Generative Stance Detection with Rationalization for Social Media,"Stance detection is crucial for fostering a human-centric Web by analyzing
user-generated content to identify biases and harmful narratives that undermine
trust. With the development of Large Language Models (LLMs), existing
approaches treat stance detection as a classification problem, providing robust
methodologies for modeling complex group interactions and advancing
capabilities in natural language tasks. However, these methods often lack
interpretability, limiting their ability to offer transparent and
understandable justifications for predictions. This study adopts a generative
approach, where stance predictions include explicit, interpretable rationales,
and integrates them into smaller language models through single-task and
multitask learning. We find that incorporating reasoning into stance detection
enables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot
performance, achieving an improvement of up to 9.57%. Moreover, our results
show that reasoning capabilities enhance multitask learning performance but may
reduce effectiveness in single-task settings. Crucially, we demonstrate that
faithful rationales improve rationale distillation into SLMs, advancing efforts
to build interpretable, trustworthy systems for addressing discrimination,
fostering trust, and promoting equitable engagement on social media.",2024-12-13,"Jiaqing Yuan, Ruijie Xi, Munindar P. Singh",http://arxiv.org/pdf/2412.10266v1,cs.CL
Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large Language Models,"The sheer scale of data required to train modern large language models (LLMs)
poses significant risks, as models are likely to gain knowledge of sensitive
topics such as bio-security, as well the ability to replicate copyrighted
works. Methods designed to remove such knowledge must do so from all prompt
directions, in a multi-lingual capacity and without degrading general model
performance. To this end, we introduce the targeted angular reversal (TARS)
method of knowledge removal from LLMs. The TARS method firstly leverages the
LLM in combination with a detailed prompt to aggregate information about a
selected concept in the internal representation space of the LLM. It then
refines this approximate concept vector to trigger the concept token with high
probability, by perturbing the approximate concept vector with noise and
transforming it into token scores with the language model head. The feedforward
weight vectors in the LLM which operate directly on the internal representation
space, and have the highest cosine similarity with this targeting vector, are
then replaced by a reversed targeting vector, thus limiting the ability of the
concept to propagate through the model. The modularity of the TARS method
allows for a sequential removal of concepts from Llama 3.1 8B, such as the
famous literary detective Sherlock Holmes, and the planet Saturn. It is
demonstrated that the probability of triggering target concepts can be reduced
to 0.00 with as few as 1 TARS edit, whilst simultaneously removing the
knowledge bi-directionally. Moreover, knowledge is shown to be removed across
all languages despite only being targeted in English. Importantly, TARS has
minimal impact on the general model capabilities, as after removing 5 diverse
concepts in a modular fashion, there is minimal KL divergence in the next token
probabilities of the LLM on large corpora of Wikipedia text (median of 0.0015).",2024-12-13,"Harry J. Davies, Giorgos Iacovides, Danilo P. Mandic",http://arxiv.org/pdf/2412.10257v2,cs.CL
Efficient Continual Pre-training of LLMs for Low-resource Languages,"Open-source Large Language models (OsLLMs) propel the democratization of
natural language research by giving the flexibility to augment or update model
parameters for performance improvement. Nevertheless, like proprietary LLMs,
Os-LLMs offer poorer performance on low-resource languages (LRLs) than
high-resource languages (HRLs), owing to smaller amounts of training data and
underrepresented vocabulary. On the other hand, continual pre-training (CPT)
with large amounts of language-specific data is a costly proposition in terms
of data acquisition and computational resources. Our goal is to drastically
reduce CPT cost. To that end, we first develop a new algorithm to select a
subset of texts from a larger corpus. We show the effectiveness of our
technique using very little CPT data. In search of further improvement, we
design a new algorithm to select tokens to include in the LLM vocabulary. We
experiment with the recent Llama-3 model and nine Indian languages with diverse
scripts and extent of resource availability. For evaluation, we use
IndicGenBench, a generation task benchmark dataset for Indic languages. We
experiment with various CPT corpora and augmented vocabulary size and offer
insights across language families.",2024-12-13,"Arijit Nag, Soumen Chakrabarti, Animesh Mukherjee, Niloy Ganguly",http://arxiv.org/pdf/2412.10244v1,cs.CL
How good is my story? Towards quantitative metrics for evaluating LLM-generated XAI narratives,"A rapidly developing application of LLMs in XAI is to convert quantitative
explanations such as SHAP into user-friendly narratives to explain the
decisions made by smaller prediction models. Evaluating the narratives without
relying on human preference studies or surveys is becoming increasingly
important in this field. In this work we propose a framework and explore
several automated metrics to evaluate LLM-generated narratives for explanations
of tabular classification tasks. We apply our approach to compare several
state-of-the-art LLMs across different datasets and prompt types. As a
demonstration of their utility, these metrics allow us to identify new
challenges related to LLM hallucinations for XAI narratives.",2024-12-13,"Timour Ichmoukhamedov, James Hinns, David Martens",http://arxiv.org/pdf/2412.10220v1,cs.CL
Retrieval-Augmented Semantic Parsing: Using Large Language Models to Improve Generalization,"Open-domain semantic parsing remains a challenging task, as models often rely
on heuristics and struggle to handle unseen concepts. In this paper, we
investigate the potential of large language models (LLMs) for this task and
introduce Retrieval-Augmented Semantic Parsing (RASP), a simple yet effective
approach that integrates external lexical knowledge into the parsing process.
Our experiments not only show that LLMs outperform previous encoder-decoder
baselines for semantic parsing, but that RASP further enhances their ability to
predict unseen concepts, nearly doubling the performance of previous models on
out-of-distribution concepts. These findings highlight the promise of
leveraging large language models and retrieval mechanisms for robust and
open-domain semantic parsing.",2024-12-13,"Xiao Zhang, Qianru Meng, Johan Bos",http://arxiv.org/pdf/2412.10207v1,cs.CL
MPPO: Multi Pair-wise Preference Optimization for LLMs with Arbitrary Negative Samples,"Aligning Large Language Models (LLMs) with human feedback is crucial for
their development. Existing preference optimization methods such as DPO and
KTO, while improved based on Reinforcement Learning from Human Feedback (RLHF),
are inherently derived from PPO, requiring a reference model that adds GPU
memory resources and relies heavily on abundant preference data. Meanwhile,
current preference optimization research mainly targets single-question
scenarios with two replies, neglecting optimization with multiple replies,
which leads to a waste of data in the application. This study introduces the
MPPO algorithm, which leverages the average likelihood of model responses to
fit the reward function and maximizes the utilization of preference data.
Through a comparison of Point-wise, Pair-wise, and List-wise implementations,
we found that the Pair-wise approach achieves the best performance,
significantly enhancing the quality of model responses. Experimental results
demonstrate MPPO's outstanding performance across various benchmarks. On
MT-Bench, MPPO outperforms DPO, ORPO, and SimPO. Notably, on Arena-Hard, MPPO
surpasses DPO and ORPO by substantial margins. These achievements underscore
the remarkable advantages of MPPO in preference optimization tasks.",2024-12-13,"Shuo Xie, Fangzhi Zhu, Jiahui Wang, Lulu Wen, Wei Dai, Xiaowei Chen, Junxiong Zhu, Kai Zhou, Bo Zheng",http://arxiv.org/pdf/2412.15244v1,cs.CL
VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval Augmented Generation,"We propose the VLR-Bench, a visual question answering (VQA) benchmark for
evaluating vision language models (VLMs) based on retrieval augmented
generation (RAG). Unlike existing evaluation datasets for external
knowledge-based VQA, the proposed VLR-Bench includes five input passages. This
allows testing of the ability to determine which passage is useful for
answering a given query, a capability lacking in previous research. In this
context, we constructed a dataset of 32,000 automatically generated
instruction-following examples, which we denote as VLR-IF. This dataset is
specifically designed to enhance the RAG capabilities of VLMs by enabling them
to learn how to generate appropriate answers based on input passages. We
evaluated the validity of the proposed benchmark and training data and verified
its performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3
model. The proposed VLR-Bench and VLR-IF datasets are publicly available
online.",2024-12-13,"Hyeonseok Lim, Dongjae Shin, Seohyun Song, Inho Won, Minjun Kim, Junghun Yuk, Haneol Jang, KyungTae Lim",http://arxiv.org/pdf/2412.10151v1,cs.CL
TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse Analysis with Prompt Engineering,"The capacity of LLMs to carry out automated qualitative analysis has been
questioned by corpus linguists, and it has been argued that corpus-based
discourse analysis incorporating LLMs is hindered by issues of unsatisfying
performance, hallucination, and irreproducibility. Our proposed method,
TACOMORE, aims to address these concerns by serving as an effective prompting
framework in this domain. The framework consists of four principles, i.e.,
Task, Context, Model and Reproducibility, and specifies five fundamental
elements of a good prompt, i.e., Role Description, Task Definition, Task
Procedures, Contextual Information and Output Format. We conduct experiments on
three LLMs, i.e., GPT-4o, Gemini-1.5-Pro and Gemini-1.5.Flash, and find that
TACOMORE helps improve LLM performance in three representative discourse
analysis tasks, i.e., the analysis of keywords, collocates and concordances,
based on an open corpus of COVID-19 research articles. Our findings show the
efficacy of the proposed prompting framework TACOMORE in corpus-based discourse
analysis in terms of Accuracy, Ethicality, Reasoning, and Reproducibility, and
provide novel insights into the application and evaluation of LLMs in automated
qualitative studies.",2024-12-13,"Bingru Li, Han Wang",http://arxiv.org/pdf/2412.10139v1,cs.CL
ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL,"Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by
large language models (LLMs), the latest state-of-the-art techniques are still
trapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which
limits their applicability in open scenarios. To address this challenge, we
propose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to
improve the comprehensive capabilities of open-source LLMs for Text2SQL,
thereby providing a more practical solution. Our approach begins with
multi-task supervised fine-tuning (SFT) using various synthetic training data
related to SQL generation. Unlike existing SFT-based Text2SQL methods, we
introduced several additional SFT tasks, including schema linking, noise
correction, and continuation writing. Engaging in a variety of SQL generation
tasks enhances the model's understanding of SQL syntax and improves its ability
to generate high-quality SQL queries. Additionally, inspired by the
collaborative modes of LLM agents, we introduce a Multitask Collaboration
Prompting (MCP) strategy. This strategy leverages collaboration across several
SQL-related tasks to reduce hallucinations during SQL generation, thereby
maximizing the potential of enhancing Text2SQL performance through explicit
multitask capabilities. Extensive experiments and in-depth analyses have been
performed on eight open-source LLMs and five widely-used benchmarks. The
results demonstrate that our proposal outperforms the latest Text2SQL methods
and yields leading performance.",2024-12-13,"Yang Qin, Chao Chen, Zhihang Fu, Ze Chen, Dezhong Peng, Peng Hu, Jieping Ye",http://arxiv.org/pdf/2412.10138v3,cs.CL
Can LLMs Convert Graphs to Text-Attributed Graphs?,"Graphs are ubiquitous structures found in numerous real-world applications,
such as drug discovery, recommender systems, and social network analysis. To
model graph-structured data, graph neural networks (GNNs) have become a popular
tool. However, existing GNN architectures encounter challenges in cross-graph
learning where multiple graphs have different feature spaces. To address this,
recent approaches introduce text-attributed graphs (TAGs), where each node is
associated with a textual description, which can be projected into a unified
feature space using textual encoders. While promising, this method relies
heavily on the availability of text-attributed graph data, which is difficult
to obtain in practice. To bridge this gap, we propose a novel method named
Topology-Aware Node description Synthesis (TANS), leveraging large language
models (LLMs) to convert existing graphs into text-attributed graphs. The key
idea is to integrate topological information into LLMs to explain how graph
topology influences node semantics. We evaluate our TANS on text-rich,
text-limited, and text-free graphs, demonstrating its applicability. Notably,
on text-free graphs, our method significantly outperforms existing approaches
that manually design node features, showcasing the potential of LLMs for
preprocessing graph-structured data in the absence of textual information. The
code and data are available at https://github.com/Zehong-Wang/TANS.",2024-12-13,"Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye",http://arxiv.org/pdf/2412.10136v2,cs.CL
ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers,"As large language models (LLMs) grow in size, traditional full fine-tuning
becomes increasingly impractical due to its high computational and storage
costs. Although popular parameter-efficient fine-tuning methods, such as LoRA,
have significantly reduced the number of tunable parameters, there is still
room for further optimization. In this work, we propose ASLoRA, a cross-layer
parameter-sharing strategy combining global sharing with partial adaptive
sharing. Specifically, we share the low-rank matrix A across all layers and
adaptively merge matrix B during training. This sharing mechanism not only
mitigates overfitting effectively but also captures inter-layer dependencies,
significantly enhancing the model's representational capability. We conduct
extensive experiments on various NLP tasks, showing that ASLoRA outperforms
LoRA while using less than 25% of the parameters, highlighting its flexibility
and superior parameter efficiency. Furthermore, in-depth analyses of the
adaptive sharing strategy confirm its significant advantages in enhancing both
model flexibility and task adaptability.",2024-12-13,"Junyan Hu, Xue Xiao, Mengqi Zhang, Yao Chen, Zhaochun Ren, Zhumin Chen, Pengjie Ren",http://arxiv.org/pdf/2412.10135v2,cs.CL
Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data,"Zero-shot named entity recognition (NER) is the task of detecting named
entities of specific types (such as 'Person' or 'Medicine') without any
training examples. Current research increasingly relies on large synthetic
datasets, automatically generated to cover tens of thousands of distinct entity
types, to train zero-shot NER models. However, in this paper, we find that
these synthetic datasets often contain entity types that are semantically
highly similar to (or even the same as) those in standard evaluation
benchmarks. Because of this overlap, we argue that reported F1 scores for
zero-shot NER overestimate the true capabilities of these approaches. Further,
we argue that current evaluation setups provide an incomplete picture of
zero-shot abilities since they do not quantify the label shift (i.e., the
similarity of labels) between training and evaluation datasets. To address
these issues, we propose Familiarity, a novel metric that captures both the
semantic similarity between entity types in training and evaluation, as well as
their frequency in the training data, to provide an estimate of label shift. It
allows researchers to contextualize reported zero-shot NER scores when using
custom synthetic training datasets. Further, it enables researchers to generate
evaluation setups of various transfer difficulties for fine-grained analysis of
zero-shot NER.",2024-12-13,"Jonas Golde, Patrick Haller, Max Ploner, Fabio Barth, Nicolaas Jedema, Alan Akbik",http://arxiv.org/pdf/2412.10121v2,cs.CL
Label-template based Few-Shot Text Classification with Contrastive Learning,"As an algorithmic framework for learning to learn, meta-learning provides a
promising solution for few-shot text classification. However, most existing
research fail to give enough attention to class labels. Traditional basic
framework building meta-learner based on prototype networks heavily relies on
inter-class variance, and it is easily influenced by noise. To address these
limitations, we proposes a simple and effective few-shot text classification
framework. In particular, the corresponding label templates are embed into
input sentences to fully utilize the potential value of class labels, guiding
the pre-trained model to generate more discriminative text representations
through the semantic information conveyed by labels. With the continuous
influence of label semantics, supervised contrastive learning is utilized to
model the interaction information between support samples and query samples.
Furthermore, the averaging mechanism is replaced with an attention mechanism to
highlight vital semantic information. To verify the proposed scheme, four
typical datasets are employed to assess the performance of different methods.
Experimental results demonstrate that our method achieves substantial
performance enhancements and outperforms existing state-of-the-art models on
few-shot text classification tasks.",2024-12-13,"Guanghua Hou, Shuhui Cao, Deqiang Ouyang, Ning Wang",http://arxiv.org/pdf/2412.10110v1,cs.CL
"MALAMUTE: A Multilingual, Highly-granular, Template-free, Education-based Probing Dataset","Language models (LMs) have excelled in various broad domains. However, to
ensure their safe and effective integration into real-world educational
settings, they must demonstrate proficiency in specific, granular areas of
knowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs'
knowledge, have three major limitations. They: 1) do not cover the educational
domain; 2) typically focus on low-complexity, generic knowledge or broad
domains, which do not adequately assess the models' knowledge in specific
subjects; and 3) often rely on templates that can bias model predictions. Here,
we introduce MALAMUTE, a multilingual, template-free, and highly granular
probing dataset comprising expert-written, peer-reviewed probes from 71
university-level textbooks across three languages (English, Spanish, and
Polish). MALAMUTE is the first education-based cloze-style dataset. It covers
eight domains, each with up to 14 subdomains, further broken down into concepts
and concept-based prompts, totaling 33,361 university curriculum concepts and
116,887 prompts. MALAMUTE's fine granularity, educational focus, and inclusion
of both sentence-level and paragraph-level prompts make it an ideal tool for
evaluating LMs' course-related knowledge. Our evaluation of masked and causal
LMs on MALAMUTE shows that despite overall proficiency, they have significant
gaps in knowledge when examined closely on specific subjects, hindering their
safe use in classrooms and underscoring the need for further development.",2024-12-13,"Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence E Hunter, Katharina von der Wense",http://arxiv.org/pdf/2412.10105v2,cs.CL
RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for Real Estate Sector,"The real estate market relies heavily on structured data, such as property
details, market trends, and price fluctuations. However, the lack of
specialized Tabular Question Answering datasets in this domain limits the
development of automated question-answering systems. To fill this gap, we
introduce RETQA, the first large-scale open-domain Chinese Tabular Question
Answering dataset for Real Estate. RETQA comprises 4,932 tables and 20,762
question-answer pairs across 16 sub-fields within three major domains: property
information, real estate company finance information and land auction
information. Compared with existing tabular question answering datasets, RETQA
poses greater challenges due to three key factors: long-table structures,
open-domain retrieval, and multi-domain queries. To tackle these challenges, we
propose the SLUTQA framework, which integrates large language models with
spoken language understanding tasks to enhance retrieval and answering
accuracy. Extensive experiments demonstrate that SLUTQA significantly improves
the performance of large language models on RETQA by in-context learning. RETQA
and SLUTQA provide essential resources for advancing tabular question answering
research in the real estate domain, addressing critical challenges in
open-domain and long-table question-answering. The dataset and code are
publicly available at \url{https://github.com/jensen-w/RETQA}.",2024-12-13,"Zhensheng Wang, Wenmian Yang, Kun Zhou, Yiquan Zhang, Weijia Jia",http://arxiv.org/pdf/2412.10104v2,cs.CL
AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm Detection Incorporating Bi-modal Data Augmentation,"Detecting sarcasm effectively requires a nuanced understanding of context,
including vocal tones and facial expressions. The progression towards
multimodal computational methods in sarcasm detection, however, faces
challenges due to the scarcity of data. To address this, we present AMuSeD
(Attentive deep neural network for MUltimodal Sarcasm dEtection incorporating
bi-modal Data augmentation). This approach utilizes the Multimodal Sarcasm
Detection Dataset (MUStARD) and introduces a two-phase bimodal data
augmentation strategy. The first phase involves generating varied text samples
through Back Translation from several secondary languages. The second phase
involves the refinement of a FastSpeech 2-based speech synthesis system,
tailored specifically for sarcasm to retain sarcastic intonations. Alongside a
cloud-based Text-to-Speech (TTS) service, this Fine-tuned FastSpeech 2 system
produces corresponding audio for the text augmentations. We also investigate
various attention mechanisms for effectively merging text and audio data,
finding self-attention to be the most efficient for bimodal integration. Our
experiments reveal that this combined augmentation and attention approach
achieves a significant F1-score of 81.0% in text-audio modalities, surpassing
even models that use three modalities from the MUStARD dataset.",2024-12-13,"Xiyuan Gao, Shubhi Bansal, Kushaan Gowda, Zhu Li, Shekhar Nayak, Nagendra Kumar, Matt Coler",http://arxiv.org/pdf/2412.10103v1,cs.CL
HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language Transfer and Automatic Data Annotation,"In this paper we present our submission for the NorSID Shared Task as part of
the 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:
Intent Detection, Slot Filling and Dialect Identification, evaluated using data
in different dialects of the Norwegian language. For Intent Detection and Slot
Filling, we have fine-tuned a multitask model in a cross-lingual setting, to
leverage the xSID dataset available in 17 languages. In the case of Dialect
Identification, our final submission consists of a model fine-tuned on the
provided development set, which has obtained the highest scores within our
experiments. Our final results on the test set show that our models do not drop
in performance compared to the development set, likely due to the
domain-specificity of the dataset and the similar distribution of both subsets.
Finally, we also report an in-depth analysis of the provided datasets and their
artifacts, as well as other sets of experiments that have been carried out but
did not yield the best results. Additionally, we present an analysis on the
reasons why some methods have been more successful than others; mainly the
impact of the combination of languages and domain-specificity of the training
data on the results.",2024-12-13,"Jaione Bengoetxea, Mikel Zubillaga, Ekhi Azurmendi, Maite Heredia, Julen Etxaniz, Markel Ferro, Jeremy Barnes",http://arxiv.org/pdf/2412.10095v2,cs.CL
"Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA","Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the ""lost in the middle"" problem in the
multi-hop question answering setting -- in which multiple reasoning ""hops"" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.",2024-12-13,"George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense",http://arxiv.org/pdf/2412.10079v1,cs.CL
"Script-Based Dialog Policy Planning for LLM-Powered Conversational Agents: A Basic Architecture for an ""AI Therapist""","Large Language Model (LLM)-Powered Conversational Agents have the potential
to provide users with scaled behavioral healthcare support, and potentially
even deliver full-scale ""AI therapy'"" in the future. While such agents can
already conduct fluent and proactive emotional support conversations, they
inherently lack the ability to (a) consistently and reliably act by predefined
rules to align their conversation with an overarching therapeutic concept and
(b) make their decision paths inspectable for risk management and clinical
evaluation -- both essential requirements for an ""AI Therapist"".
  In this work, we introduce a novel paradigm for dialog policy planning in
conversational agents enabling them to (a) act according to an expert-written
""script"" that outlines the therapeutic approach and (b) explicitly transition
through a finite set of states over the course of the conversation. The script
acts as a deterministic component, constraining the LLM's behavior in desirable
ways and establishing a basic architecture for an AI Therapist.
  We implement two variants of Script-Based Dialog Policy Planning using
different prompting techniques and synthesize a total of 100 conversations with
LLM-simulated patients. The results demonstrate the feasibility of this new
technology and provide insights into the efficiency and effectiveness of
different implementation variants.",2024-12-13,"Robert Wasenmüller, Kevin Hilbert, Christoph Benzmüller",http://arxiv.org/pdf/2412.15242v1,cs.CL
GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?,"Large Language Models (LLMs) are commonly evaluated using human-crafted
benchmarks, under the premise that higher scores implicitly reflect stronger
human-like performance. However, there is growing concern that LLMs may ``game""
these benchmarks due to data leakage, achieving high scores while struggling
with tasks simple for humans. To substantively address the problem, we create
GAOKAO-Eval, a comprehensive benchmark based on China's National College
Entrance Examination (Gaokao), and conduct ``closed-book"" evaluations for
representative models released prior to Gaokao. Contrary to prevailing
consensus, even after addressing data leakage and comprehensiveness,
GAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned
capabilities. To better understand this mismatch, We introduce the Rasch model
from cognitive psychology to analyze LLM scoring patterns and identify two key
discrepancies: 1) anomalous consistent performance across various question
difficulties, and 2) high variance in performance on questions of similar
difficulty. In addition, We identified inconsistent grading of LLM-generated
answers among teachers and recurring mistake patterns. we find that the
phenomenons are well-grounded in the motivations behind OpenAI o1, and o1's
reasoning-as-difficulties can mitigate the mismatch. These results show that
GAOKAO-Eval can reveal limitations in LLM capabilities not captured by current
benchmarks and highlight the need for more LLM-aligned difficulty analysis.",2024-12-13,"Zhikai Lei, Tianyi Liang, Hanglei Hu, Jin Zhang, Yunhua Zhou, Yunfan Shao, Linyang Li, Chenchui Li, Changbo Wang, Hang Yan, Qipeng Guo",http://arxiv.org/pdf/2412.10056v1,cs.CL
Unsupervised Named Entity Disambiguation for Low Resource Domains,"In the ever-evolving landscape of natural language processing and information
retrieval, the need for robust and domain-specific entity linking algorithms
has become increasingly apparent. It is crucial in a considerable number of
fields such as humanities, technical writing and biomedical sciences to enrich
texts with semantics and discover more knowledge. The use of Named Entity
Disambiguation (NED) in such domains requires handling noisy texts, low
resource settings and domain-specific KBs. Existing approaches are mostly
inappropriate for such scenarios, as they either depend on training data or are
not flexible enough to work with domain-specific KBs. Thus in this work, we
present an unsupervised approach leveraging the concept of Group Steiner Trees
(GST), which can identify the most relevant candidates for entity
disambiguation using the contextual similarities across candidate entities for
all the mentions present in a document. We outperform the state-of-the-art
unsupervised methods by more than 40\% (in avg.) in terms of Precision@1 across
various domain-specific datasets.",2024-12-13,"Debarghya Datta, Soumajit Pramanik",http://arxiv.org/pdf/2412.10054v1,cs.CL
Quantifying Positional Biases in Text Embedding Models,"Embedding models are crucial for tasks in Information Retrieval (IR) and
semantic similarity measurement, yet their handling of longer texts and
associated positional biases remains underexplored. In this study, we
investigate the impact of content position and input size on text embeddings.
Our experiments reveal that embedding models, irrespective of their positional
encoding mechanisms, disproportionately prioritize the beginning of an input.
Ablation studies demonstrate that insertion of irrelevant text or removal at
the start of a document reduces cosine similarity between altered and original
embeddings by up to 12.3% more than ablations at the end. Regression analysis
further confirms this bias, with sentence importance declining as position
moves further from the start, even with with content-agnosticity. We
hypothesize that this effect arises from pre-processing strategies and chosen
positional encoding techniques. These findings quantify the sensitivity of
retrieval systems and suggest a new lens towards embedding model robustness.",2024-12-13,"Samarth Goel, Reagan J. Lee, Kannan Ramchandran",http://arxiv.org/pdf/2412.15241v3,cs.CL
Automated Collection of Evaluation Dataset for Semantic Search in Low-Resource Domain Language,"Domain-specific languages that use a lot of specific terminology often fall
into the category of low-resource languages. Collecting test datasets in a
narrow domain is time-consuming and requires skilled human resources with
domain knowledge and training for the annotation task. This study addresses the
challenge of automated collecting test datasets to evaluate semantic search in
low-resource domain-specific German language of the process industry. Our
approach proposes an end-to-end annotation pipeline for automated query
generation to the score reassessment of query-document pairs. To overcome the
lack of text encoders trained in the German chemistry domain, we explore a
principle of an ensemble of ""weak"" text encoders trained on common knowledge
datasets. We combine individual relevance scores from diverse models to
retrieve document candidates and relevance scores generated by an LLM, aiming
to achieve consensus on query-document alignment. Evaluation results
demonstrate that the ensemble method significantly improves alignment with
human-assigned relevance scores, outperforming individual models in both
inter-coder agreement and accuracy metrics. These findings suggest that
ensemble learning can effectively adapt semantic search systems for
specialized, low-resource languages, offering a practical solution to resource
limitations in domain-specific contexts.",2024-12-13,"Anastasia Zhukova, Christian E. Matt, Bela Gipp",http://arxiv.org/pdf/2412.10008v1,cs.CL
The role of inhibitory control in garden-path sentence processing: A Chinese-English bilingual perspective,"In reading garden-path sentences, people must resolve competing
interpretations, though initial misinterpretations can linger despite
reanalysis. This study examines the role of inhibitory control (IC) in managing
these misinterpretations among Chinese-English bilinguals. Using self-paced
reading tasks, we investigated how IC influences recovery from garden-path
sentences in Chinese (L1) and its interaction with language proficiency during
English (L2) processing. Results indicate that IC does not affect garden-path
recovery in Chinese, suggesting reliance on semantic context may reduce the
need for IC. In contrast, findings for English L2 learners reveal a complex
relationship between language proficiency and IC: Participants with low L2
proficiency but high IC showed lingering misinterpretations, while those with
high proficiency exhibited none. These results support and extend the Model of
Cognitive Control (Ness et al., 2023). Moreover, our comparison of three Stroop
task versions identifies L1 colour-word Stroop task as the preferred measure of
IC in bilingual research.",2024-12-13,"Xiaohui Rao, Haoze Li, Xiaofang Lin, Lijuan Liang",http://arxiv.org/pdf/2412.10006v1,cs.CL
Large Language Models for Persian $ \leftrightarrow $ English Idiom Translation,"Large language models (LLMs) have shown superior capabilities in translating
figurative language compared to neural machine translation (NMT) systems.
However, the impact of different prompting methods and LLM-NMT combinations on
idiom translation has yet to be thoroughly investigated. This paper introduces
two parallel datasets of sentences containing idiomatic expressions for
Persian$\rightarrow$English and English$\rightarrow$Persian translations, with
Persian idioms sampled from our PersianIdioms resource, a collection of 2,200
idioms and their meanings, with 700 including usage examples. Using these
datasets, we evaluate various open- and closed-source LLMs, NMT models, and
their combinations. Translation quality is assessed through idiom translation
accuracy and fluency. We also find that automatic evaluation methods like
LLM-as-a-judge, BLEU, and BERTScore are effective for comparing different
aspects of model performance. Our experiments reveal that Claude-3.5-Sonnet
delivers outstanding results in both translation directions. For
English$\rightarrow$Persian, combining weaker LLMs with Google Translate
improves results, while Persian$\rightarrow$English translations benefit from
single prompts for simpler models and complex prompts for advanced ones.",2024-12-13,"Sara Rezaeimanesh, Faezeh Hosseini, Yadollah Yaghoobzadeh",http://arxiv.org/pdf/2412.09993v2,cs.CL
Small Language Model as Data Prospector for Large Language Model,"The quality of instruction data directly affects the performance of
fine-tuned Large Language Models (LLMs). Previously, \cite{li2023one} proposed
\texttt{NUGGETS}, which identifies and selects high-quality quality data from a
large dataset by identifying those individual instruction examples that can
significantly improve the performance of different tasks after being learnt as
one-shot instances. In this work, we propose \texttt{SuperNUGGETS}, an improved
variant of \texttt{NUGGETS} optimised for efficiency and performance. Our
\texttt{SuperNUGGETS} uses a small language model (SLM) instead of a large
language model (LLM) to filter the data for outstanding one-shot instances and
refines the predefined set of tests. The experimental results show that the
performance of \texttt{SuperNUGGETS} only decreases by 1-2% compared to
\texttt{NUGGETS}, but the efficiency can be increased by a factor of 58.
Compared to the original \texttt{NUGGETS}, our \texttt{SuperNUGGETS} has a
higher utility value due to the significantly lower resource consumption.",2024-12-13,"Shiwen Ni, Haihong Wu, Di Yang, Qiang Qu, Hamid Alinejad-Rokny, Min Yang",http://arxiv.org/pdf/2412.09990v1,cs.CL
Romanized to Native Malayalam Script Transliteration Using an Encoder-Decoder Framework,"In this work, we present the development of a reverse transliteration model
to convert romanized Malayalam to native script using an encoder-decoder
framework built with attention-based bidirectional Long Short Term Memory
(Bi-LSTM) architecture. To train the model, we have used curated and combined
collection of 4.3 million transliteration pairs derived from publicly available
Indic language translitertion datasets, Dakshina and Aksharantar. We evaluated
the model on two different test dataset provided by IndoNLP-2025-Shared-Task
that contain, (1) General typing patterns and (2) Adhoc typing patterns,
respectively. On the Test Set-1, we obtained a character error rate (CER) of
7.4%. However upon Test Set-2, with adhoc typing patterns, where most vowel
indicators are missing, our model gave a CER of 22.7%.",2024-12-13,"Bajiyo Baiju, Kavya Manohar, Leena G Pillai, Elizabeth Sherly",http://arxiv.org/pdf/2412.09957v1,cs.CL
ChainStream: An LLM-based Framework for Unified Synthetic Sensing,"Many applications demand context sensing to offer personalized and timely
services. Yet, developing sensing programs can be challenging for developers
and using them is privacy-concerning for end-users. In this paper, we propose
to use natural language as the unified interface to process personal data and
sense user context, which can effectively ease app development and make the
data pipeline more transparent. Our work is inspired by large language models
(LLMs) and other generative models, while directly applying them does not solve
the problem - letting the model directly process the data cannot handle complex
sensing requests and letting the model write the data processing program
suffers error-prone code generation. We address the problem with 1) a unified
data processing framework that makes context-sensing programs simpler and 2) a
feedback-guided query optimizer that makes data query more informative. To
evaluate the performance of natural language-based context sensing, we create a
benchmark that contains 133 context sensing tasks. Extensive evaluation has
shown that our approach is able to automatically solve the context-sensing
tasks efficiently and precisely. The code is opensourced at
https://github.com/MobileLLM/ChainStream.",2024-12-13,"Jiacheng Liu, Yuanchun Li, Liangyan Li, Yi Sun, Hao Wen, Xiangyu Li, Yao Guo, Yunxin Liu",http://arxiv.org/pdf/2412.15240v1,cs.CL
Enhancing Nursing and Elderly Care with Large Language Models: An AI-Driven Framework,"This paper explores the application of large language models (LLMs) in
nursing and elderly care, focusing on AI-driven patient monitoring and
interaction. We introduce a novel Chinese nursing dataset and implement
incremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to
enhance LLM performance in specialized tasks. Using LangChain, we develop a
dynamic nursing assistant capable of real-time care and personalized
interventions. Experimental results demonstrate significant improvements,
paving the way for AI-driven solutions to meet the growing demands of
healthcare in aging populations.",2024-12-13,"Qiao Sun, Jiexin Xie, Nanyang Ye, Qinying Gu, Shijie Guo",http://arxiv.org/pdf/2412.09946v1,cs.CL
Simulating Hard Attention Using Soft Attention,"We study conditions under which transformers using soft attention can
simulate hard attention, that is, effectively focus all attention on a subset
of positions. First, we examine several variants of linear temporal logic,
whose formulas have been previously been shown to be computable using hard
attention transformers. We demonstrate how soft attention transformers can
compute formulas of these logics using unbounded positional embeddings or
temperature scaling. Second, we demonstrate how temperature scaling allows
softmax transformers to simulate a large subclass of average-hard attention
transformers, those that have what we call the uniform-tieless property.",2024-12-13,"Andy Yang, Lena Strobl, David Chiang, Dana Angluin",http://arxiv.org/pdf/2412.09925v1,cs.CL
Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation,"In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.",2024-12-13,"Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You",http://arxiv.org/pdf/2412.09922v1,cs.CL
Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning,"Large language models (LLMs) have demonstrated remarkable performance across
a wide range of tasks. Advances in prompt engineering and fine-tuning
techniques have further enhanced their ability to address complex reasoning
challenges. However, these advanced capabilities are often exclusive to models
exceeding 100 billion parameters. Although Chain-of-Thought (CoT) fine-tuning
methods have been explored for smaller models (under 10 billion parameters),
they typically depend on extensive CoT training data, which can introduce
inconsistencies and limit effectiveness in low-data settings. To overcome these
limitations, this paper introduce a new reasoning strategy Solution Guidance
(SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT)
for enhancing the reasoning capabilities of small language models. SG focuses
on problem understanding and decomposition at the semantic and logical levels,
rather than specific computations, which can effectively improve the SLMs'
generalization and reasoning abilities. With only a small amount of SG training
data, SGFT can fine-tune a SLM to produce accurate problem-solving guidances,
which can then be flexibly fed to any SLM as prompts, enabling it to generate
correct answers directly. Experimental results demonstrate that our method
significantly improves the performance of SLMs on various reasoning tasks,
enhancing both their practicality and efficiency within resource-constrained
environments.",2024-12-13,"Jing Bi, Yuting Wu, Weiwei Xing, Zhenjie Wei",http://arxiv.org/pdf/2412.09906v1,cs.CL
Analyzing Fairness of Computer Vision and Natural Language Processing Models,"Machine learning (ML) algorithms play a crucial role in decision making
across diverse fields such as healthcare, finance, education, and law
enforcement. Despite their widespread adoption, these systems raise ethical and
social concerns due to potential biases and fairness issues. This study focuses
on evaluating and improving the fairness of Computer Vision and Natural
Language Processing (NLP) models applied to unstructured datasets, emphasizing
how biased predictions can reinforce existing systemic inequalities. A publicly
available dataset from Kaggle was utilized to simulate a practical scenario for
examining fairness in ML workflows. To address and mitigate biases, the study
employed two leading fairness libraries: Fairlearn by Microsoft, and AIF360 by
IBM. These tools offer comprehensive frameworks for fairness analysis,
including metrics evaluation, result visualization, and bias mitigation
techniques. The research aims to measure bias levels in ML models, compare the
effectiveness of these fairness libraries, and provide actionable
recommendations for practitioners. The results demonstrate that each library
possesses distinct strengths and limitations in evaluating and mitigating
fairness. By systematically analyzing these tools, the study contributes
valuable insights to the growing field of ML fairness, offering practical
guidance for integrating fairness solutions into real world applications. This
research underscores the importance of building more equitable and responsible
machine learning systems.",2024-12-13,"Ahmed Rashed, Abdelkrim Kallich, Mohamed Eltayeb",http://arxiv.org/pdf/2412.09900v2,cs.CL
HashEvict: A Pre-Attention KV Cache Eviction Strategy using Locality-Sensitive Hashing,"Transformer-based large language models (LLMs) use the key-value (KV) cache
to significantly accelerate inference by storing the key and value embeddings
of past tokens. However, this cache consumes significant GPU memory. In this
work, we introduce HashEvict, an algorithm that uses locality-sensitive hashing
(LSH) to compress the KV cache. HashEvict quickly locates tokens in the cache
that are cosine dissimilar to the current query token. This is achieved by
computing the Hamming distance between binarized Gaussian projections of the
current token query and cached token keys, with a projection length much
smaller than the embedding dimension. We maintain a lightweight binary
structure in GPU memory to facilitate these calculations. Unlike existing
compression strategies that compute attention to determine token retention,
HashEvict makes these decisions pre-attention, thereby reducing computational
costs. Additionally, HashEvict is dynamic - at every decoding step, the key and
value of the current token replace the embeddings of a token expected to
produce the lowest attention score. We demonstrate that HashEvict can compress
the KV cache by 30%-70% while maintaining high performance across reasoning,
multiple-choice, long-context retrieval and summarization tasks.",2024-12-13,"Minghui Liu, Tahseen Rabbani, Tony O'Halloran, Ananth Sankaralingam, Mary-Anne Hartley, Brian Gravelle, Furong Huang, Cornelia Fermüller, Yiannis Aloimonos",http://arxiv.org/pdf/2412.16187v2,cs.CL
Benchmarking Table Comprehension In The Wild,"Large Language Models (LLMs), while being increasingly dominant on a myriad
of knowledge-intensive activities, have only had limited success understanding
lengthy table-text mixtures, such as academic papers and financial reports.
Recent advances of long-context LLMs have opened up new possibilities for this
field. Nonetheless, we identify two roadblocks: (1) Prior benchmarks of table
question answering (TableQA) have focused on isolated tables without context,
making it hard to evaluate models in real-world scenarios. (2) Prior benchmarks
have focused on some narrow skill sets of table comprehension such as table
recognition, data manipulation/calculation, table summarization etc., while a
skilled human employs those skills collectively. In this work, we introduce
TableQuest, a new benchmark designed to evaluate the holistic table
comprehension capabilities of LLMs in the natural table-rich context of
financial reports. We employ a rigorous data processing and filtering procedure
to ensure that the question-answer pairs are logical, reasonable, and diverse.
We experiment with 7 state-of-the-art models, and find that despite reasonable
accuracy in locating facts, they often falter when required to execute more
sophisticated reasoning or multi-step calculations. We conclude with a
qualitative study of the failure modes and discuss the challenges of
constructing a challenging benchmark. We make the evaluation data, judging
procedure and results of this study publicly available to facilitate research
in this field.",2024-12-13,"Yikang Pan, Yi Zhu, Rand Xie, Yizhi Liu",http://arxiv.org/pdf/2412.09884v1,cs.CL
On the Limit of Language Models as Planning Formalizers,"Large Language Models have been found to create plans that are neither
executable nor verifiable in grounded environments. An emerging line of work
demonstrates success in using the LLM as a formalizer to generate a formal
representation of the planning domain in some language, such as Planning Domain
Definition Language (PDDL). This formal representation can be deterministically
solved to find a plan. We systematically evaluate this methodology while
bridging some major gaps. While previous work only generates a partial PDDL
representation, given templated, and therefore unrealistic environment
descriptions, we generate the complete representation given descriptions of
various naturalness levels. Among an array of observations critical to improve
LLMs' formal planning abilities, we note that most large enough models can
effectively formalize descriptions as PDDL, outperforming those directly
generating plans, while being robust to lexical perturbation. As the
descriptions become more natural-sounding, we observe a decrease in performance
and provide detailed error analysis.",2024-12-13,"Cassie Huang, Li Zhang",http://arxiv.org/pdf/2412.09879v3,cs.CL
Byte Latent Transformer: Patches Scale Better Than Tokens,"We introduce the Byte Latent Transformer (BLT), a new byte-level LLM
architecture that, for the first time, matches tokenization-based LLM
performance at scale with significant improvements in inference efficiency and
robustness. BLT encodes bytes into dynamically sized patches, which serve as
the primary units of computation. Patches are segmented based on the entropy of
the next byte, allocating more compute and model capacity where increased data
complexity demands it. We present the first FLOP controlled scaling study of
byte-level models up to 8B parameters and 4T training bytes. Our results
demonstrate the feasibility of scaling models trained on raw bytes without a
fixed vocabulary. Both training and inference efficiency improve due to
dynamically selecting long patches when data is predictable, along with
qualitative improvements on reasoning and long tail generalization. Overall,
for fixed inference costs, BLT shows significantly better scaling than
tokenization-based models, by simultaneously growing both patch and model size.",2024-12-13,"Artidoro Pagnoni, Ram Pasunuru, Pedro Rodriguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, Lili Yu, Jason Weston, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Ari Holtzman, Srinivasan Iyer",http://arxiv.org/pdf/2412.09871v1,cs.CL
Human-Like Embodied AI Interviewer: Employing Android ERICA in Real International Conference,"This paper introduces the human-like embodied AI interviewer which integrates
android robots equipped with advanced conversational capabilities, including
attentive listening, conversational repairs, and user fluency adaptation.
Moreover, it can analyze and present results post-interview. We conducted a
real-world case study at SIGDIAL 2024 with 42 participants, of whom 69%
reported positive experiences. This study demonstrated the system's
effectiveness in conducting interviews just like a human and marked the first
employment of such a system at an international conference. The demonstration
video is available at https://youtu.be/jCuw9g99KuE.",2024-12-13,"Zi Haur Pang, Yahui Fu, Divesh Lala, Mikey Elmers, Koji Inoue, Tatsuya Kawahara",http://arxiv.org/pdf/2412.09867v1,cs.CL
Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for Supervised Fine-tuning,"The Efficient Market Hypothesis (EMH) highlights the essence of financial
news in stock price movement. Financial news comes in the form of corporate
announcements, news titles, and other forms of digital text. The generation of
insights from financial news can be done with sentiment analysis.
General-purpose language models are too general for sentiment analysis in
finance. Curated labeled data for fine-tuning general-purpose language models
are scare, and existing fine-tuned models for sentiment analysis in finance do
not capture the maximum context width. We hypothesize that using actual and
synthetic data can improve performance. We introduce BertNSP-finance to
concatenate shorter financial sentences into longer financial sentences, and
finbert-lc to determine sentiment from digital text. The results show improved
performance on the accuracy and the f1 score for the financial phrasebank data
with $50\%$ and $100\%$ agreement levels.",2024-12-13,Abraham Atsiwo,http://arxiv.org/pdf/2412.09859v1,cs.CL
Modeling Story Expectations to Understand Engagement: A Generative Framework Using LLMs,"Understanding when and why consumers engage with stories is crucial for
content creators and platforms. While existing theories suggest that audience
beliefs of what is going to happen should play an important role in engagement
decisions, empirical work has mostly focused on developing techniques to
directly extract features from actual content, rather than capturing
forward-looking beliefs, due to the lack of a principled way to model such
beliefs in unstructured narrative data. To complement existing feature
extraction techniques, this paper introduces a novel framework that leverages
large language models to model audience forward-looking beliefs about how
stories might unfold. Our method generates multiple potential continuations for
each story and extracts features related to expectations, uncertainty, and
surprise using established content analysis techniques. Applying our method to
over 30,000 book chapters, we demonstrate that our framework complements
existing feature engineering techniques by amplifying their marginal
explanatory power on average by 31%. The results reveal that different types of
engagement-continuing to read, commenting, and voting-are driven by distinct
combinations of current and anticipated content features. Our framework
provides a novel way to study and explore how audience forward-looking beliefs
shape their engagement with narrative media, with implications for marketing
strategy in content-focused industries.",2024-12-13,"Hortense Fong, George Gui",http://arxiv.org/pdf/2412.15239v2,cs.CL
Low-Rank Adaptation with Task-Relevant Feature Enhancement for Fine-tuning Language Models,"Fine-tuning pre-trained large language models in a parameter-efficient manner
is widely studied for its effectiveness and efficiency. LoRA is one of the most
widely used methods, which assumes that the optimization process is essentially
low dimensional. Although LoRA has demonstrated commendable performance, there
remains a significant performance gap between LoRA and full fine-tuning when
learning new tasks. In this work, we propose Low-Rank Adaptation with
Task-Relevant Feature Enhancement(LoRATRF) for enhancing task-relevant features
from the perspective of editing neural network representations. To prioritize
task-relevant features, a task-aware filter that selectively extracts valuable
knowledge from hidden representations for the target or current task is
designed. As the experiments on a vareity of datasets including NLU,
commonsense reasoning and mathematical reasoning tasks demonstrates, our method
reduces 33.71% parameters and achieves better performance on a variety of
datasets in comparison with SOTA low-rank methods.",2024-12-13,"Changqun Li, Chaofan Ding, Kexin Luan, Xinhan Di",http://arxiv.org/pdf/2412.09827v1,cs.CL
MERaLiON-AudioLLM: Bridging Audio and Language with Large Language Models,"We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning
in One Network), the first speech-text model tailored for Singapore's
multilingual and multicultural landscape. Developed under the National Large
Language Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates
advanced speech and text processing to address the diverse linguistic nuances
of local accents and dialects, enhancing accessibility and usability in
complex, multilingual environments. Our results demonstrate improvements in
both speech recognition and task-specific understanding, positioning
MERaLiON-AudioLLM as a pioneering solution for region specific AI applications.
We envision this release to set a precedent for future models designed to
address localised linguistic and cultural contexts in a global framework.",2024-12-13,"Yingxu He, Zhuohan Liu, Shuo Sun, Bin Wang, Wenyu Zhang, Xunlong Zou, Nancy F. Chen, Ai Ti Aw",http://arxiv.org/pdf/2412.09818v3,cs.CL
Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation,"Multimodal large language models have experienced rapid growth, and numerous
different models have emerged. The interpretability of LVLMs remains an
under-explored area. Especially when faced with more complex tasks such as
chain-of-thought reasoning, its internal mechanisms still resemble a black box
that is difficult to decipher. By studying the interaction and information flow
between images and text, we noticed that in models such as LLaVA1.5, image
tokens that are semantically related to text are more likely to have
information flow convergence in the LLM decoding layer, and these image tokens
receive higher attention scores. However, those image tokens that are less
relevant to the text do not have information flow convergence, and they only
get very small attention scores. To efficiently utilize the image information,
we propose a new image token reduction method, Simignore, which aims to improve
the complex reasoning ability of LVLMs by computing the similarity between
image and text embeddings and ignoring image tokens that are irrelevant and
unimportant to the text. Through extensive experiments, we demonstrate the
effectiveness of our method for complex reasoning tasks. The paper's source
code can be accessed from \url{https://github.com/FanshuoZeng/Simignore}.",2024-12-13,"Xiaofeng Zhang, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao",http://arxiv.org/pdf/2412.09817v1,cs.CL
ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic LayerReplace and Selective Rank Compression,"Offsite-tuning is a privacy-preserving method for tuning large language
models (LLMs) by sharing a lossy compressed emulator from the LLM owners with
data owners for downstream task tuning. This approach protects the privacy of
both the model and data owners. However, current offsite tuning methods often
suffer from adaptation degradation, high computational costs, and limited
protection strength due to uniformly dropping LLM layers or relying on
expensive knowledge distillation. To address these issues, we propose ScaleOT,
a novel privacy-utility-scalable offsite-tuning framework that effectively
balances privacy and utility. ScaleOT introduces a novel layerwise lossy
compression algorithm that uses reinforcement learning to obtain the importance
of each layer. It employs lightweight networks, termed harmonizers, to replace
the raw LLM layers. By combining important original LLM layers and harmonizers
in different ratios, ScaleOT generates emulators tailored for optimal
performance with various model scales for enhanced privacy protection.
Additionally, we present a rank reduction method to further compress the
original LLM layers, significantly enhancing privacy with negligible impact on
utility. Comprehensive experiments show that ScaleOT can achieve nearly
lossless offsite tuning performance compared with full fine-tuning while
obtaining better model privacy.",2024-12-13,"Kai Yao, Zhaorui Tan, Tiandi Ye, Lichun Li, Yuan Zhao, Wenyan Liu, Wei Wang, Jianke Zhu",http://arxiv.org/pdf/2412.09812v1,cs.CL
LLM Distillation for Efficient Few-Shot Multiple Choice Question Answering,"Multiple Choice Question Answering (MCQA) is an important problem with
numerous real-world applications, such as medicine, law, and education. The
high cost of building MCQA datasets makes few-shot learning pivotal in this
domain. While Large Language Models (LLMs) can enable few-shot learning, their
direct application in real-world scenarios is often hindered by their high
computational cost. To address this challenge, we propose a simple yet
effective approach that uses LLMs for data generation and scoring. Our approach
utilizes LLMs to create MCQA data which contains questions and choices, and to
assign probability scores to the generated choices. We then use the generated
data and LLM-assigned scores to finetune a smaller and more efficient
encoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive
experiments on the Massive Multitask Language Understanding (MMLU) benchmark
demonstrate that our method improves accuracy from 28.9% to 39.3%, representing
a gain of over 10% compared to a baseline finetuned directly on 5-shot
examples. This shows the effectiveness of LLM-driven data generation and
knowledge distillation for few-shot MCQA.",2024-12-13,"Patrick Sutanto, Joan Santoso, Esther Irawati Setiawan, Aji Prasetya Wibawa",http://arxiv.org/pdf/2412.09807v2,cs.CL
AutoPatent: A Multi-Agent Framework for Automatic Patent Generation,"As the capabilities of Large Language Models (LLMs) continue to advance, the
field of patent processing has garnered increased attention within the natural
language processing community. However, the majority of research has been
concentrated on classification tasks, such as patent categorization and
examination, or on short text generation tasks like patent summarization and
patent quizzes. In this paper, we introduce a novel and practical task known as
Draft2Patent, along with its corresponding D2P benchmark, which challenges LLMs
to generate full-length patents averaging 17K tokens based on initial drafts.
Patents present a significant challenge to LLMs due to their specialized
nature, standardized terminology, and extensive length. We propose a
multi-agent framework called AutoPatent which leverages the LLM-based planner
agent, writer agents, and examiner agent with PGTree and RRAG to generate
lengthy, intricate, and high-quality complete patent documents. The
experimental results demonstrate that our AutoPatent framework significantly
enhances the ability to generate comprehensive patents across various LLMs.
Furthermore, we have discovered that patents generated solely with the
AutoPatent framework based on the Qwen2.5-7B model outperform those produced by
larger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,
in both objective metrics and human evaluations. We will make the data and code
available upon acceptance at \url{https://github.com/QiYao-Wang/AutoPatent}.",2024-12-13,"Qiyao Wang, Shiwen Ni, Huaren Liu, Shule Lu, Guhong Chen, Xi Feng, Chi Wei, Qiang Qu, Hamid Alinejad-Rokny, Yuan Lin, Min Yang",http://arxiv.org/pdf/2412.09796v1,cs.CL
Semi-IIN: Semi-supervised Intra-inter modal Interaction Learning Network for Multimodal Sentiment Analysis,"Despite multimodal sentiment analysis being a fertile research ground that
merits further investigation, current approaches take up high annotation cost
and suffer from label ambiguity, non-amicable to high-quality labeled data
acquisition. Furthermore, choosing the right interactions is essential because
the significance of intra- or inter-modal interactions can differ among various
samples. To this end, we propose Semi-IIN, a Semi-supervised Intra-inter modal
Interaction learning Network for multimodal sentiment analysis. Semi-IIN
integrates masked attention and gating mechanisms, enabling effective dynamic
selection after independently capturing intra- and inter-modal interactive
information. Combined with the self-training approach, Semi-IIN fully utilizes
the knowledge learned from unlabeled data. Experimental results on two public
datasets, MOSI and MOSEI, demonstrate the effectiveness of Semi-IIN,
establishing a new state-of-the-art on several metrics. Code is available at
https://github.com/flow-ljh/Semi-IIN.",2024-12-13,"Jinhao Lin, Yifei Wang, Yanwu Xu, Qi Liu",http://arxiv.org/pdf/2412.09784v1,cs.CL
Model-diff: A Tool for Comparative Study of Language Models in the Input Space,"Comparing two (large) language models (LMs) side-by-side and pinpointing
their prediction similarities and differences on the same set of inputs are
crucial in many real-world scenarios, e.g., one can test if a licensed model
was potentially plagiarized by another. Traditional analysis compares the LMs'
outputs on some benchmark datasets, which only cover a limited number of inputs
of designed perspectives for the intended applications. The benchmark datasets
cannot prepare data to cover the test cases from unforeseen perspectives which
can help us understand differences between models unbiasedly. In this paper, we
propose a new model comparative analysis setting that considers a large input
space where brute-force enumeration would be infeasible. The input space can be
simply defined as all token sequences that a LM would produce low perplexity on
-- we follow this definition in the paper as it would produce the most
human-understandable inputs. We propose a novel framework \our that uses text
generation by sampling and deweights the histogram of sampling statistics to
estimate prediction differences between two LMs in this input space efficiently
and unbiasedly. Our method achieves this by drawing and counting the inputs at
each prediction difference value in negative log-likelihood. Experiments reveal
for the first time the quantitative prediction differences between LMs in a
large input space, potentially facilitating the model analysis for applications
such as model plagiarism.",2024-12-13,"Weitang Liu, Yuelei Li, Ying Wai Li, Zihan Wang, Jingbo Shang",http://arxiv.org/pdf/2412.12177v1,cs.CL
Memory Layers at Scale,"Memory layers use a trainable key-value lookup mechanism to add extra
parameters to a model without increasing FLOPs. Conceptually, sparsely
activated memory layers complement compute-heavy dense feed-forward layers,
providing dedicated capacity to store and retrieve information cheaply. This
work takes memory layers beyond proof-of-concept, proving their utility at
contemporary scale. On downstream tasks, language models augmented with our
improved memory layer outperform dense models with more than twice the
computation budget, as well as mixture-of-expert models when matched for both
compute and parameters. We find gains are especially pronounced for factual
tasks. We provide a fully parallelizable memory layer implementation,
demonstrating scaling laws with up to 128B memory parameters, pretrained to 1
trillion tokens, comparing to base models with up to 8B parameters.",2024-12-12,"Vincent-Pierre Berges, Barlas Oğuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, Gargi Ghosh",http://arxiv.org/pdf/2412.09764v2,cs.CL
Explore Theory of Mind: Program-guided adversarial data generation for theory of mind reasoning,"Do large language models (LLMs) have theory of mind? A plethora of papers and
benchmarks have been introduced to evaluate if current models have been able to
develop this key ability of social intelligence. However, all rely on limited
datasets with simple patterns that can potentially lead to problematic blind
spots in evaluation and an overestimation of model capabilities. We introduce
ExploreToM, the first framework to allow large-scale generation of diverse and
challenging theory of mind data for robust training and evaluation. Our
approach leverages an A* search over a custom domain-specific language to
produce complex story structures and novel, diverse, yet plausible scenarios to
stress test the limits of LLMs. Our evaluation reveals that state-of-the-art
LLMs, such as Llama-3.1-70B and GPT-4o, show accuracies as low as 0% and 9% on
ExploreToM-generated data, highlighting the need for more robust theory of mind
evaluation. As our generations are a conceptual superset of prior work,
fine-tuning on our data yields a 27-point accuracy improvement on the classic
ToMi benchmark (Le et al., 2019). ExploreToM also enables uncovering underlying
skills and factors missing for models to show theory of mind, such as
unreliable state tracking or data imbalances, which may contribute to models'
poor performance on benchmarks.",2024-12-12,"Melanie Sclar, Jane Yu, Maryam Fazel-Zarandi, Yulia Tsvetkov, Yonatan Bisk, Yejin Choi, Asli Celikyilmaz",http://arxiv.org/pdf/2412.12175v1,cs.CL
GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers,"The effectiveness of large language models (LLMs) is closely tied to the
design of prompts, making prompt optimization essential for enhancing their
performance across a wide range of tasks. Many existing approaches to
automating prompt engineering rely exclusively on textual feedback, refining
prompts based solely on inference errors identified by large, computationally
expensive LLMs. Unfortunately, smaller models struggle to generate high-quality
feedback, resulting in complete dependence on large LLM judgment. Moreover,
these methods fail to leverage more direct and finer-grained information, such
as gradients, due to operating purely in text space. To this end, we introduce
GReaTer, a novel prompt optimization technique that directly incorporates
gradient information over task-specific reasoning. By utilizing task loss
gradients, GReaTer enables self-optimization of prompts for open-source,
lightweight language models without the need for costly closed-source LLMs.
This allows high-performance prompt optimization without dependence on massive
LLMs, closing the gap between smaller models and the sophisticated reasoning
often needed for prompt refinement. Extensive evaluations across diverse
reasoning tasks including BBH, GSM8k, and FOLIO demonstrate that GReaTer
consistently outperforms previous state-of-the-art prompt optimization methods,
even those reliant on powerful LLMs. Additionally, GReaTer-optimized prompts
frequently exhibit better transferability and, in some cases, boost task
performance to levels comparable to or surpassing those achieved by larger
language models, highlighting the effectiveness of prompt optimization guided
by gradients over reasoning. Code of GReaTer is available at
https://github.com/psunlpgroup/GreaTer.",2024-12-12,"Sarkar Snigdha Sarathi Das, Ryo Kamoi, Bo Pang, Yusen Zhang, Caiming Xiong, Rui Zhang",http://arxiv.org/pdf/2412.09722v2,cs.CL
Human vs. AI: A Novel Benchmark and a Comparative Study on the Detection of Generated Images and the Impact of Prompts,"With the advent of publicly available AI-based text-to-image systems, the
process of creating photorealistic but fully synthetic images has been largely
democratized. This can pose a threat to the public through a simplified spread
of disinformation. Machine detectors and human media expertise can help to
differentiate between AI-generated (fake) and real images and counteract this
danger. Although AI generation models are highly prompt-dependent, the impact
of the prompt on the fake detection performance has rarely been investigated
yet. This work therefore examines the influence of the prompt's level of detail
on the detectability of fake images, both with an AI detector and in a user
study. For this purpose, we create a novel dataset, COCOXGEN, which consists of
real photos from the COCO dataset as well as images generated with SDXL and
Fooocus using prompts of two standardized lengths. Our user study with 200
participants shows that images generated with longer, more detailed prompts are
detected significantly more easily than those generated with short prompts.
Similarly, an AI-based detection model achieves better performance on images
generated with longer prompts. However, humans and AI models seem to pay
attention to different details, as we show in a heat map analysis.",2024-12-12,"Philipp Moeßner, Heike Adel",http://arxiv.org/pdf/2412.09715v1,cs.CL
Formal Languages and TQFTs with Defects,"A construction that assigns a Boolean 1D TQFT with defects to a finite state
automaton was recently developed by Gustafson, Im, Kaldawy, Khovanov, and Lihn.
We show that the construction is functorial with respect to the category of
finite state automata with transducers as morphisms. Certain classes of
subregular languages correspond to additional cohomological structures on the
associated TQFTs. We also show that the construction generalizes to
context-free grammars through a categorical version of the
Chomsky-Sch\""utzenberger representation theorem, due to Melli\`es and
Zeilberger. The corresponding TQFTs are then described as morphisms of colored
operads on an operad of cobordisms with defects.",2024-12-12,"Luisa Boateng, Matilde Marcolli",http://arxiv.org/pdf/2412.09688v1,cs.CL
Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG,"We introduce a novel approach to enhance the capabilities of text-to-image
models by incorporating a graph-based RAG. Our system dynamically retrieves
detailed character information and relational data from the knowledge graph,
enabling the generation of visually accurate and contextually rich images. This
capability significantly improves upon the limitations of existing T2I models,
which often struggle with the accurate depiction of complex or culturally
specific subjects due to dataset constraints. Furthermore, we propose a novel
self-correcting mechanism for text-to-image models to ensure consistency and
fidelity in visual outputs, leveraging the rich context from the graph to guide
corrections. Our qualitative and quantitative experiments demonstrate that
Context Canvas significantly enhances the capabilities of popular models such
as Flux, Stable Diffusion, and DALL-E, and improves the functionality of
ControlNet for fine-grained image editing tasks. To our knowledge, Context
Canvas represents the first application of graph-based RAG in enhancing T2I
models, representing a significant advancement for producing high-fidelity,
context-aware multi-faceted images.",2024-12-12,"Kavana Venkatesh, Yusuf Dalva, Ismini Lourentzou, Pinar Yanardag",http://arxiv.org/pdf/2412.09614v1,cs.CL
Olympus: A Universal Task Router for Computer Vision Tasks,"We introduce Olympus, a new approach that transforms Multimodal Large
Language Models (MLLMs) into a unified framework capable of handling a wide
array of computer vision tasks. Utilizing a controller MLLM, Olympus delegates
over 20 specialized tasks across images, videos, and 3D objects to dedicated
modules. This instruction-based routing enables complex workflows through
chained actions without the need for training heavy generative models. Olympus
easily integrates with existing MLLMs, expanding their capabilities with
comparable performance. Experimental results demonstrate that Olympus achieves
an average routing accuracy of 94.75% across 20 tasks and precision of 91.82%
in chained action scenarios, showcasing its effectiveness as a universal task
router that can solve a diverse range of computer vision tasks. Project page:
http://yuanze-lin.me/Olympus_page/",2024-12-12,"Yuanze Lin, Yunsheng Li, Dongdong Chen, Weijian Xu, Ronald Clark, Philip H. S. Torr",http://arxiv.org/pdf/2412.09612v3,cs.CL
AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials,"Graphical User Interface (GUI) agents can automate complex tasks across
digital environments, but their development is hindered by the scarcity of
high-quality trajectory data for training. Existing approaches rely on
expensive human annotation, making them unsustainable at scale. We propose
AgentTrek, a scalable data synthesis pipeline that generates web agent
trajectories by leveraging publicly available tutorials. Our three-stage
method: (1) automatically harvests and filters tutorial-like texts from the
internet using a specialized classification model, (2) transforms these texts
into structured task specifications with step-by-step instructions, and (3)
employs a visual-language model (VLM) agent to execute these instructions in
real environments, while a VLM-based evaluator verifies trajectory correctness.
The synthesized trajectories encompass multiple modalities, including
text-based HTML observations with function-calling API actions, and
vision-based screenshot observations with pixel-level actions. This multimodal
data, enriched with chain-of-thought reasoning, enables agents to achieve
state-of-the-art performance on both textual web browsing benchmarks (e.g.,
WebArena) and visual web grounding and browsing benchmarks (e.g., ScreenSpot
Web and Multimodal Mind2Web). Furthermore, our fully automated approach
significantly reduces data collection costs, achieving a cost of just $0.55 per
high-quality trajectory without human annotators. Our work demonstrates that
guided replay using web tutorials is a practical and scalable strategy for
training advanced GUI agents, paving the way for more capable and autonomous
digital assistants.",2024-12-12,"Yiheng Xu, Dunjie Lu, Zhennan Shen, Junli Wang, Zekun Wang, Yuchen Mao, Caiming Xiong, Tao Yu",http://arxiv.org/pdf/2412.09605v2,cs.CL
TimeRefine: Temporal Grounding with Time Refining Video LLM,"Video temporal grounding aims to localize relevant temporal boundaries in a
video given a textual prompt. Recent work has focused on enabling Video LLMs to
perform video temporal grounding via next-token prediction of temporal
timestamps. However, accurately localizing timestamps in videos remains
challenging for Video LLMs when relying solely on temporal token prediction.
Our proposed TimeRefine addresses this challenge in two ways. First, instead of
directly predicting the start and end timestamps, we reformulate the temporal
grounding task as a temporal refining task: the model first makes rough
predictions and then refines them by predicting offsets to the target segment.
This refining process is repeated multiple times, through which the model
progressively self-improves its temporal localization accuracy. Second, to
enhance the model's temporal perception capabilities, we incorporate an
auxiliary prediction head that penalizes the model more if a predicted segment
deviates further from the ground truth, thus encouraging the model to make
closer and more accurate predictions. Our plug-and-play method can be
integrated into most LLM-based temporal grounding approaches. The experimental
results demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on
the ActivityNet and Charades-STA datasets, respectively. Code and pretrained
models will be released.",2024-12-12,"Xizi Wang, Feng Cheng, Ziyang Wang, Huiyu Wang, Md Mohaiminul Islam, Lorenzo Torresani, Mohit Bansal, Gedas Bertasius, David Crandall",http://arxiv.org/pdf/2412.09601v2,cs.CL
InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions,"Creating AI systems that can interact with environments over long periods,
similar to human cognition, has been a longstanding research goal. Recent
advancements in multimodal large language models (MLLMs) have made significant
strides in open-world understanding. However, the challenge of continuous and
simultaneous streaming perception, memory, and reasoning remains largely
unexplored. Current MLLMs are constrained by their sequence-to-sequence
architecture, which limits their ability to process inputs and generate
responses simultaneously, akin to being unable to think while perceiving.
Furthermore, relying on long contexts to store historical data is impractical
for long-term interactions, as retaining all information becomes costly and
inefficient. Therefore, rather than relying on a single foundation model to
perform all functions, this project draws inspiration from the concept of the
Specialized Generalist AI and introduces disentangled streaming perception,
reasoning, and memory mechanisms, enabling real-time interaction with streaming
video and audio input. The proposed framework InternLM-XComposer2.5-OmniLive
(IXC2.5-OL) consists of three key modules: (1) Streaming Perception Module:
Processes multimodal information in real-time, storing key details in memory
and triggering reasoning in response to user queries. (2) Multi-modal Long
Memory Module: Integrates short-term and long-term memory, compressing
short-term memories into long-term ones for efficient retrieval and improved
accuracy. (3) Reasoning Module: Responds to queries and executes reasoning
tasks, coordinating with the perception and memory modules. This project
simulates human-like cognition, enabling multimodal large language models to
provide continuous and adaptive service over time.",2024-12-12,"Pan Zhang, Xiaoyi Dong, Yuhang Cao, Yuhang Zang, Rui Qian, Xilin Wei, Lin Chen, Yifei Li, Junbo Niu, Shuangrui Ding, Qipeng Guo, Haodong Duan, Xin Chen, Han Lv, Zheng Nie, Min Zhang, Bin Wang, Wenwei Zhang, Xinyue Zhang, Jiaye Ge, Wei Li, Jingwen Li, Zhongying Tu, Conghui He, Xingcheng Zhang, Kai Chen, Yu Qiao, Dahua Lin, Jiaqi Wang",http://arxiv.org/pdf/2412.09596v1,cs.CL
OpenNER 1.0: Standardized Open-Access Named Entity Recognition Datasets in 50+ Languages,"We present OpenNER 1.0, a standardized collection of openly available named
entity recognition (NER) datasets. OpenNER contains 34 datasets spanning 51
languages, annotated in varying named entity ontologies. We correct annotation
format issues, standardize the original datasets into a uniform representation,
map entity type names to be more consistent across corpora, and provide the
collection in a structure that enables research in multilingual and
multi-ontology NER. We provide baseline models using three pretrained
multilingual language models to compare the performance of recent models and
facilitate future research in NER.",2024-12-12,"Chester Palen-Michel, Maxwell Pickering, Maya Kruse, Jonne Sälevä, Constantine Lignos",http://arxiv.org/pdf/2412.09587v1,cs.CL
DISHONEST: Dissecting misInformation Spread using Homogeneous sOcial NEtworks and Semantic Topic classification,"The emergence of the COVID-19 pandemic resulted in a significant rise in the
spread of misinformation on online platforms such as Twitter. Oftentimes this
growth is blamed on the idea of the ""echo chamber."" However, the behavior said
to characterize these echo chambers exists in two dimensions. The first is in a
user's social interactions, where they are said to stick with the same clique
of like-minded users. The second is in the content of their posts, where they
are said to repeatedly espouse homogeneous ideas. In this study, we link the
two by using Twitter's network of retweets to study social interactions and
topic modeling to study tweet content. In order to measure the diversity of a
user's interactions over time, we develop a novel metric to track the speed at
which they travel through the social network. The application of these analysis
methods to misinformation-focused data from the pandemic demonstrates
correlation between social behavior and tweet content. We believe this
correlation supports the common intuition about how antisocial users behave,
and further suggests that it holds even in subcommunities already rife with
misinformation.",2024-12-12,"Caleb Stam, Emily Saldanha, Mahantesh Halappanavar, Anurag Acharya",http://arxiv.org/pdf/2412.09578v1,cs.CL
DiverseAgentEntropy: Quantifying Black-Box LLM Uncertainty through Diverse Perspectives and Multi-Agent Interaction,"Quantifying the uncertainty in the factual parametric knowledge of Large
Language Models (LLMs), especially in a black-box setting, poses a significant
challenge. Existing methods, which gauge a model's uncertainty through
evaluating self-consistency in responses to the original query, do not always
capture true uncertainty. Models might respond consistently to the origin query
with a wrong answer, yet respond correctly to varied questions from different
perspectives about the same query, and vice versa. In this paper, we propose a
novel method, DiverseAgentEntropy, for evaluating a model's uncertainty using
multi-agent interaction under the assumption that if a model is certain, it
should consistently recall the answer to the original query across a diverse
collection of questions about the same original query. We further implement an
abstention policy to withhold responses when uncertainty is high. Our method
offers a more accurate prediction of the model's reliability and further
detects hallucinations, outperforming other self-consistency-based methods.
Additionally, it demonstrates that existing models often fail to consistently
retrieve the correct answer to the same query under diverse varied questions
even when knowing the correct answer.",2024-12-12,"Yu Feng, Phu Mon Htut, Zheng Qi, Wei Xiao, Manuel Mager, Nikolaos Pappas, Kishaloy Halder, Yang Li, Yassine Benajiba, Dan Roth",http://arxiv.org/pdf/2412.09572v1,cs.CL
JuStRank: Benchmarking LLM Judges for System Ranking,"Given the rapid progress of generative AI, there is a pressing need to
systematically compare and choose between the numerous models and
configurations available. The scale and versatility of such evaluations make
the use of LLM-based judges a compelling solution for this challenge.
Crucially, this approach requires first to validate the quality of the LLM
judge itself. Previous work has focused on instance-based assessment of LLM
judges, where a judge is evaluated over a set of responses, or response pairs,
while being agnostic to their source systems. We argue that this setting
overlooks critical factors affecting system-level ranking, such as a judge's
positive or negative bias towards certain systems. To address this gap, we
conduct the first large-scale study of LLM judges as system rankers. System
scores are generated by aggregating judgment scores over multiple system
outputs, and the judge's quality is assessed by comparing the resulting system
ranking to a human-based ranking. Beyond overall judge assessment, our analysis
provides a fine-grained characterization of judge behavior, including their
decisiveness and bias.",2024-12-12,"Ariel Gera, Odellia Boni, Yotam Perlitz, Roy Bar-Haim, Lilach Eden, Asaf Yehudai",http://arxiv.org/pdf/2412.09569v1,cs.CL
Does Representation Matter? Exploring Intermediate Layers in Large Language Models,"Understanding what defines a good representation in large language models
(LLMs) is fundamental to both theoretical understanding and practical
applications. In this paper, we investigate the quality of intermediate
representations in various LLM architectures, including Transformers and State
Space Models (SSMs). We find that intermediate layers often yield more
informative representations for downstream tasks than the final layers. To
measure the representation quality, we adapt and apply a suite of metrics -
such as prompt entropy, curvature, and augmentation-invariance - originally
proposed in other contexts. Our empirical study reveals significant
architectural differences, how representations evolve throughout training, and
how factors like input randomness and prompt length affect each layer. Notably,
we observe a bimodal pattern in the entropy of some intermediate layers and
consider potential explanations tied to training data. Overall, our results
illuminate the internal mechanics of LLMs and guide strategies for
architectural optimization and training.",2024-12-12,"Oscar Skean, Md Rifat Arefin, Yann LeCun, Ravid Shwartz-Ziv",http://arxiv.org/pdf/2412.09563v1,cs.CL
Foundational Large Language Models for Materials Research,"Materials discovery and development are critical for addressing global
challenges. Yet, the exponential growth in materials science literature
comprising vast amounts of textual data has created significant bottlenecks in
knowledge extraction, synthesis, and scientific reasoning. Large Language
Models (LLMs) offer unprecedented opportunities to accelerate materials
research through automated analysis and prediction. Still, their effective
deployment requires domain-specific adaptation for understanding and solving
domain-relevant tasks. Here, we present LLaMat, a family of foundational models
for materials science developed through continued pretraining of LLaMA models
on an extensive corpus of materials literature and crystallographic data.
Through systematic evaluation, we demonstrate that LLaMat excels in
materials-specific NLP and structured information extraction while maintaining
general linguistic capabilities. The specialized LLaMat-CIF variant
demonstrates unprecedented capabilities in crystal structure generation,
predicting stable crystals with high coverage across the periodic table.
Intriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,
we observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specific
performance across diverse materials science tasks, including structured
information extraction from text and tables, more particularly in crystal
structure generation, a potential adaptation rigidity in overtrained LLMs.
Altogether, the present work demonstrates the effectiveness of domain
adaptation towards developing practically deployable LLM copilots for materials
research. Beyond materials science, our findings reveal important
considerations for domain adaptation of LLMs, such as model selection, training
methodology, and domain-specific performance, which may influence the
development of specialized scientific AI systems.",2024-12-12,"Vaibhav Mishra, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav Bihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam, N. M. Anoop Krishnan",http://arxiv.org/pdf/2412.09560v2,cs.CL
MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media,"In the current era of rapidly growing digital data, evaluating the political
bias and factuality of news outlets has become more important for seeking
reliable information online. In this work, we study the classification problem
of profiling news media from the lens of political bias and factuality.
Traditional profiling methods, such as Pre-trained Language Models (PLMs) and
Graph Neural Networks (GNNs) have shown promising results, but they face
notable challenges. PLMs focus solely on textual features, causing them to
overlook the complex relationships between entities, while GNNs often struggle
with media graphs containing disconnected components and insufficient labels.
To address these limitations, we propose MediaGraphMind (MGM), an effective
solution within a variational Expectation-Maximization (EM) framework. Instead
of relying on limited neighboring nodes, MGM leverages features, structural
patterns, and label information from globally similar nodes. Such a framework
not only enables GNNs to capture long-range dependencies for learning
expressive node representations but also enhances PLMs by integrating
structural information and therefore improving the performance of both models.
The extensive experiments demonstrate the effectiveness of the proposed
framework and achieve new state-of-the-art results. Further, we share our
repository1 which contains the dataset, code, and documentation",2024-12-12,"Muhammad Arslan Manzoor, Ruihong Zeng, Dilshod Azizov, Preslav Nakov, Shangsong Liang",http://arxiv.org/pdf/2412.10467v1,cs.CL
"Systematic Analysis of LLM Contributions to Planning: Solver, Verifier, Heuristic","In this work, we provide a systematic analysis of how large language models
(LLMs) contribute to solving planning problems. In particular, we examine how
LLMs perform when they are used as problem solver, solution verifier, and
heuristic guidance to improve intermediate solutions. Our analysis reveals that
although it is difficult for LLMs to generate correct plans out-of-the-box,
LLMs are much better at providing feedback signals to intermediate/incomplete
solutions in the form of comparative heuristic functions. This evaluation
framework provides insights into how future work may design better LLM-based
tree-search algorithms to solve diverse planning and reasoning problems. We
also propose a novel benchmark to evaluate LLM's ability to learn user
preferences on the fly, which has wide applications in practical settings.",2024-12-12,"Haoming Li, Zhaoliang Chen, Songyuan Liu, Yiming Lu, Fei Liu",http://arxiv.org/pdf/2412.09666v1,cs.CL
Dipper: Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks,"Large Language Models still encounter substantial challenges in reasoning
tasks, especially for smaller models, which many users may be restricted to due
to resource constraints (e.g. GPU memory restrictions). Inference-time methods
to boost LLM performance, such as prompting methods to invoke certain reasoning
pathways in responses, have been shown effective in past works, though they
largely rely on sequential queries. The ensemble method, which consists of
multiple constituent models running in parallel, is a promising approach to
achieving better inference-time performance, especially given recent
developments that enabled significant speed-ups in LLM batch inference. In this
work, we propose a novel, training-free LLM ensemble framework where a single
LLM model is fed an optimized, diverse set of prompts in parallel, effectively
producing an ensemble at inference time to achieve performance improvement in
reasoning tasks. We empirically demonstrate that our method leads to
significant gains on math reasoning tasks, e.g., on MATH, where our ensemble
consisting of a few small models (e.g., three Qwen2-MATH-1.5B-it models) can
outperform a larger model (e.g., Qwen2-MATH-7B-it).",2024-12-12,"Gregory Kang Ruey Lau, Wenyang Hu, Diwen Liu, Jizhuo Chen, See-Kiong Ng, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2412.15238v1,cs.CL
Audios Don't Lie: Multi-Frequency Channel Attention Mechanism for Audio Deepfake Detection,"With the rapid development of artificial intelligence technology, the
application of deepfake technology in the audio field has gradually increased,
resulting in a wide range of security risks. Especially in the financial and
social security fields, the misuse of deepfake audios has raised serious
concerns. To address this challenge, this study proposes an audio deepfake
detection method based on multi-frequency channel attention mechanism (MFCA)
and 2D discrete cosine transform (DCT). By processing the audio signal into a
melspectrogram, using MobileNet V2 to extract deep features, and combining it
with the MFCA module to weight different frequency channels in the audio
signal, this method can effectively capture the fine-grained frequency domain
features in the audio signal and enhance the Classification capability of fake
audios. Experimental results show that compared with traditional methods, the
model proposed in this study shows significant advantages in accuracy,
precision,recall, F1 score and other indicators. Especially in complex audio
scenarios, this method shows stronger robustness and generalization
capabilities and provides a new idea for audio deepfake detection and has
important practical application value. In the future, more advanced audio
detection technologies and optimization strategies will be explored to further
improve the accuracy and generalization capabilities of audio deepfake
detection.",2024-12-12,Yangguang Feng,http://arxiv.org/pdf/2412.09467v1,cs.CL
The Impact of Copyrighted Material on Large Language Models: A Norwegian Perspective,"The use of copyrighted materials in training language models raises critical
legal and ethical questions. This paper presents a framework for and the
results of empirically assessing the impact of publisher-controlled copyrighted
corpora on the performance of generative large language models (LLMs) for
Norwegian. When evaluated on a diverse set of tasks, we found that adding both
books and newspapers to the data mixture of LLMs tend to improve their
performance, while the addition of fiction works seems to be detrimental. Our
experiments could inform the creation of a compensation scheme for authors
whose works contribute to AI development.",2024-12-12,"Javier de la Rosa, Vladislav Mikhailov, Lemei Zhang, Freddy Wetjen, David Samuel, Peng Liu, Rolv-Arild Braaten, Petter Mæhlum, Magnus Breder Birkenes, Andrey Kutuzov, Tita Enstad, Hans Christian Farsethås, Svein Arne Brygfjeld, Jon Atle Gulla, Stephan Oepen, Erik Velldal, Wilfred Østgulen, Liljia Øvrelid, Aslak Sira Myhre",http://arxiv.org/pdf/2412.09460v4,cs.CL
From Intention To Implementation: Automating Biomedical Research via LLMs,"Conventional biomedical research is increasingly labor-intensive due to the
exponential growth of scientific literature and datasets. Artificial
intelligence (AI), particularly Large Language Models (LLMs), has the potential
to revolutionize this process by automating various steps. Still, significant
challenges remain, including the need for multidisciplinary expertise,
logicality of experimental design, and performance measurements. This paper
introduces BioResearcher, the first end-to-end automated system designed to
streamline the entire biomedical research process involving dry lab
experiments. BioResearcher employs a modular multi-agent architecture,
integrating specialized agents for search, literature processing, experimental
design, and programming. By decomposing complex tasks into logically related
sub-tasks and utilizing a hierarchical learning approach, BioResearcher
effectively addresses the challenges of multidisciplinary requirements and
logical complexity. Furthermore, BioResearcher incorporates an LLM-based
reviewer for in-process quality control and introduces novel evaluation metrics
to assess the quality and automation of experimental protocols. BioResearcher
successfully achieves an average execution success rate of 63.07% across eight
previously unmet research objectives. The generated protocols averagely
outperform typical agent systems by 22.0% on five quality metrics. The system
demonstrates significant potential to reduce researchers' workloads and
accelerate biomedical discoveries, paving the way for future innovations in
automated research systems.",2024-12-12,"Yi Luo, Linghang Shi, Yihao Li, Aobo Zhuang, Yeyun Gong, Ling Liu, Chen Lin",http://arxiv.org/pdf/2412.09429v2,cs.CL
Unifying AI Tutor Evaluation: An Evaluation Taxonomy for Pedagogical Ability Assessment of LLM-Powered AI Tutors,"In this paper, we investigate whether current state-of-the-art large language
models (LLMs) are effective as AI tutors and whether they demonstrate
pedagogical abilities necessary for good AI tutoring in educational dialogues.
Previous efforts towards evaluation have been limited to subjective protocols
and benchmarks. To bridge this gap, we propose a unified evaluation taxonomy
with eight pedagogical dimensions based on key learning sciences principles,
which is designed to assess the pedagogical value of LLM-powered AI tutor
responses grounded in student mistakes or confusions in the mathematical
domain. We release MRBench - a new evaluation benchmark containing 192
conversations and 1,596 responses from seven state-of-the-art LLM-based and
human tutors, providing gold annotations for eight pedagogical dimensions. We
assess reliability of the popular Prometheus2 and Llama-3.1-8B LLMs as
evaluators and analyze each tutor's pedagogical abilities, highlighting which
LLMs are good tutors and which ones are more suitable as question-answering
systems. We believe that the presented taxonomy, benchmark, and human-annotated
labels will streamline the evaluation process and help track the progress in AI
tutors' development.",2024-12-12,"Kaushal Kumar Maurya, KV Aditya Srivatsa, Kseniia Petukhova, Ekaterina Kochmar",http://arxiv.org/pdf/2412.09416v2,cs.CL
Text Generation Models for Luxembourgish with Limited Data: A Balanced Multilingual Strategy,"This paper addresses the challenges in developing language models for
less-represented languages, with a focus on Luxembourgish. Despite its active
development, Luxembourgish faces a digital data scarcity, exacerbated by
Luxembourg's multilingual context. We propose a novel text generation model
based on the T5 architecture, combining limited Luxembourgish data with equal
amounts, in terms of size and type, of German and French data. We hypothesise
that a model trained on Luxembourgish, German, and French will improve the
model's cross-lingual transfer learning capabilities and outperform monolingual
and large multilingual models. To verify this, the study at hand explores
whether multilingual or monolingual training is more beneficial for
Luxembourgish language generation. For the evaluation, we introduce LuxGen, a
text generation benchmark that is the first of its kind for Luxembourgish.",2024-12-12,"Alistair Plum, Tharindu Ranasinghe, Christoph Purschke",http://arxiv.org/pdf/2412.09415v2,cs.CL
"Imitate, Explore, and Self-Improve: A Reproduction Report on Slow-thinking Reasoning Systems","Recently, slow-thinking reasoning systems, such as o1, have demonstrated
remarkable capabilities in solving complex reasoning tasks. These systems
typically engage in an extended thinking process before responding to a query,
allowing them to generate more thorough, accurate, and well-reasoned solutions.
These systems are primarily developed and maintained by industry, with their
core techniques not publicly disclosed. In response, an increasing number of
studies from the research community aim to explore the technical foundations
underlying these powerful reasoning systems. Building on these prior efforts,
this paper presents a reproduction report on implementing o1-like reasoning
systems. We introduce an ``imitate, explore, and self-improve'' framework,
denoted as \textbf{STILL-2}, as our primary technical approach to train the
reasoning model. In the initial phase, we use distilled long-form thought data
to fine-tune the reasoning model, enabling it to invoke a slow-thinking mode.
The model is then encouraged to explore challenging problems by generating
multiple rollouts, which can result in increasingly more high-quality
trajectories that lead to correct answers. Furthermore, the model undergoes
self-improvement by iteratively refining its training dataset. To verify the
effectiveness of this approach, we conduct extensive experiments on three
challenging benchmarks. The experimental results demonstrate that our approach
achieves competitive performance compared to industry-level reasoning systems
on these benchmarks.",2024-12-12,"Yingqian Min, Zhipeng Chen, Jinhao Jiang, Jie Chen, Jia Deng, Yiwen Hu, Yiru Tang, Jiapeng Wang, Xiaoxue Cheng, Huatong Song, Wayne Xin Zhao, Zheng Liu, Zhongyuan Wang, Ji-Rong Wen",http://arxiv.org/pdf/2412.09413v2,cs.CL
A NotSo Simple Way to Beat Simple Bench,"This paper presents a novel framework for enhancing reasoning capabilities in
large language models (LLMs) by leveraging iterative reasoning and
feedback-driven methodologies. Building on the limitations identified in the
SimpleBench benchmark, a dataset designed to evaluate logical coherence and
real-world reasoning, we propose a multi-step prompting strategy coupled with
global consistency checks to improve model accuracy and robustness. Through
comparative analysis of state-of-the-art models, including Claude 3 Opus,
Claude 3.5, GPT- 4o, and o1-preview, we demonstrate that iterative reasoning
significantly enhances model performance, with improvements observed in both
standard accuracy metrics (AVG@5) and a newly introduced metric, Extreme
Averaging (EAG@5). Our results reveal model-specific strengths: Claude excels
in maintaining logical consistency, while GPT-4o exhibits exploratory
creativity but struggles with ambiguous prompts. By analyzing case studies and
identifying gaps in spatial and temporal reasoning, we highlight areas for
further refinement. The findings underscore the potential of structured
reasoning frameworks to address inherent model limitations, irrespective of
pretraining methodologies. This study lays the groundwork for integrating
dynamic feedback mechanisms, adaptive restart strategies, and diverse
evaluation metrics to advance LLM reasoning capabilities across complex and
multi-domain problem spaces.",2024-12-12,"Soham Sane, Angus McLean",http://arxiv.org/pdf/2412.12173v1,cs.CL
Neural Text Normalization for Luxembourgish using Real-Life Variation Data,"Orthographic variation is very common in Luxembourgish texts due to the
absence of a fully-fledged standard variety. Additionally, developing NLP tools
for Luxembourgish is a difficult task given the lack of annotated and parallel
data, which is exacerbated by ongoing standardization. In this paper, we
propose the first sequence-to-sequence normalization models using the ByT5 and
mT5 architectures with training data obtained from word-level real-life
variation data. We perform a fine-grained, linguistically-motivated evaluation
to test byte-based, word-based and pipeline-based models for their strengths
and weaknesses in text normalization. We show that our sequence model using
real-life variation data is an effective approach for tailor-made normalization
in Luxembourgish.",2024-12-12,"Anne-Marie Lutgen, Alistair Plum, Christoph Purschke, Barbara Plank",http://arxiv.org/pdf/2412.09383v2,cs.CL
From Bench to Bedside: A Review of Clinical Trials in Drug Discovery and Development,"Clinical trials are an indispensable part of the drug development process,
bridging the gap between basic research and clinical application. During the
development of new drugs, clinical trials are used not only to evaluate the
safety and efficacy of the drug but also to explore its dosage, treatment
regimens, and potential side effects. This review discusses the various stages
of clinical trials, including Phase I (safety assessment), Phase II
(preliminary efficacy evaluation), Phase III (large-scale validation), and
Phase IV (post-marketing surveillance), highlighting the characteristics of
each phase and their interrelationships. Additionally, the paper addresses the
major challenges encountered in clinical trials, such as ethical issues,
subject recruitment difficulties, diversity and representativeness concerns,
and proposes strategies for overcoming these challenges. With the advancement
of technology, innovative technologies such as artificial intelligence, big
data, and digitalization are gradually transforming clinical trial design and
implementation, improving trial efficiency and data quality. The article also
looks forward to the future of clinical trials, particularly the impact of
emerging therapies such as gene therapy and immunotherapy on trial design, as
well as the importance of regulatory reforms and global collaboration. In
conclusion, the core role of clinical trials in drug development will continue
to drive the progress of innovative drug development and clinical treatment.",2024-12-12,"Tianyang Wang, Ming Liu, Benji Peng, Xinyuan Song, Charles Zhang, Xintian Sun, Qian Niu, Junyu Liu, Silin Chen, Keyu Chen, Ming Li, Pohsun Feng, Ziqian Bi, Yunze Wang, Yichao Zhang, Cheng Fei, Lawrence KQ Yan",http://arxiv.org/pdf/2412.09378v2,cs.CL
Word Sense Linking: Disambiguating Outside the Sandbox,"Word Sense Disambiguation (WSD) is the task of associating a word in a given
context with its most suitable meaning among a set of possible candidates.
While the task has recently witnessed renewed interest, with systems achieving
performances above the estimated inter-annotator agreement, at the time of
writing it still struggles to find downstream applications. We argue that one
of the reasons behind this is the difficulty of applying WSD to plain text.
Indeed, in the standard formulation, models work under the assumptions that a)
all the spans to disambiguate have already been identified, and b) all the
possible candidate senses of each span are provided, both of which are
requirements that are far from trivial. In this work, we present a new task
called Word Sense Linking (WSL) where, given an input text and a reference
sense inventory, systems have to both identify which spans to disambiguate and
then link them to their most suitable meaning.We put forward a
transformer-based architecture for the task and thoroughly evaluate both its
performance and those of state-of-the-art WSD systems scaled to WSL,
iteratively relaxing the assumptions of WSD. We hope that our work will foster
easier integration of lexical semantics into downstream applications.",2024-12-12,"Andrei Stefan Bejgu, Edoardo Barba, Luigi Procopio, Alberte Fernández-Castro, Roberto Navigli",http://arxiv.org/pdf/2412.09370v1,cs.CL
Falcon-UI: Understanding GUI Before Following User Instructions,"Pursuing human-like interaction for Graphical User Interface (GUI) agents
requires understanding the GUI context and following user instructions.
However, existing works typically couple these two aspects and focus more on
instruct-following abilities, while ignoring the importance of understanding
the GUI context. In this paper, we introduce an instruction-free GUI navigation
dataset, termed Insight-UI Dataset, to enhance model comprehension of GUI
environments. Insight-UI Dataset is automatically generated from the Common
Crawl corpus, simulating various platforms -- including iOS, Android, Windows,
and Linux -- across multiple resolutions on 312K domains. Although GUI
interactions vary by context, diverse interfaces share common internal
patterns, such as clicking an item to view its details. It implies the
feasibility of independent GUI operation learning, followed by joint
optimization with instruction tuning. Thereby, we develop the GUI agent model
Falcon-UI, which is initially pretrained on Insight-UI Dataset and subsequently
fine-tuned on Android and Web GUI datasets, including AITW, AITZ, Android
Control, and Mind2Web. With 7 billion parameters, Falcon-UI achieves accuracy
comparable to the 72 billion-parameter Qwen2VL on AITZ, validating the
alignment between GUI context comprehension and agent performance. Our code and
dataset will be open-sourced.",2024-12-12,"Huawen Shen, Chang Liu, Gengluo Li, Xinlong Wang, Yu Zhou, Can Ma, Xiangyang Ji",http://arxiv.org/pdf/2412.09362v1,cs.CL
Causal Graphical Models for Vision-Language Compositional Understanding,"Recent work has empirically shown that Vision-Language Models (VLMs) struggle
to fully understand the compositional properties of the human language, usually
modeling an image caption as a ""bag of words"". As a result, they perform poorly
on compositional tasks, which require a deeper understanding of the different
entities of a sentence (subject, verb, etc.) jointly with their mutual
relationships in order to be solved. In this paper, we model the dependency
relations among textual and visual tokens using a Causal Graphical Model (CGM),
built using a dependency parser, and we train a decoder conditioned by the VLM
visual encoder. Differently from standard autoregressive or parallel
predictions, our decoder's generative process is partially-ordered following
the CGM structure. This structure encourages the decoder to learn only the main
causal dependencies in a sentence discarding spurious correlations. Using
extensive experiments on five compositional benchmarks, we show that our method
significantly outperforms all the state-of-the-art compositional approaches by
a large margin, and it also improves over methods trained using much larger
datasets.",2024-12-12,"Fiorenzo Parascandolo, Nicholas Moratelli, Enver Sangineto, Lorenzo Baraldi, Rita Cucchiara",http://arxiv.org/pdf/2412.09353v2,cs.CL
Training LayoutLM from Scratch for Efficient Named-Entity Recognition in the Insurance Domain,"Generic pre-trained neural networks may struggle to produce good results in
specialized domains like finance and insurance. This is due to a domain
mismatch between training data and downstream tasks, as in-domain data are
often scarce due to privacy constraints. In this work, we compare different
pre-training strategies for LayoutLM. We show that using domain-relevant
documents improves results on a named-entity recognition (NER) problem using a
novel dataset of anonymized insurance-related financial documents called
Payslips. Moreover, we show that we can achieve competitive results using a
smaller and faster model.",2024-12-12,"Benno Uthayasooriyar, Antoine Ly, Franck Vermet, Caio Corro",http://arxiv.org/pdf/2412.09341v1,cs.CL
Benchmarking LLMs for Mimicking Child-Caregiver Language in Interaction,"LLMs can generate human-like dialogues, yet their ability to simulate early
child-adult interactions remains largely unexplored. In this paper, we examined
how effectively LLMs can capture the distinctive features of child-caregiver
language in interaction, using both static and interactive benchmarking
methods. We found that state-of-the-art LLMs like Llama 3 and GPT-4o can
approximate child-caregiver dialogues at the word and utterance level, but they
struggle to reproduce the child and caregiver's discursive patterns, exaggerate
alignment, and fail to reach the level of diversity shown by humans. The
broader goal of this work is to initiate the development of a comprehensive
benchmark for LLMs in child-oriented applications.",2024-12-12,"Jing Liu, Abdellah Fourtassi",http://arxiv.org/pdf/2412.09318v2,cs.CL
CRVQ: Channel-Relaxed Vector Quantization for Extreme Compression of LLMs,"Powerful large language models (LLMs) are increasingly expected to be
deployed with lower computational costs, enabling their capabilities on
resource-constrained devices. Post-training quantization (PTQ) has emerged as a
star approach to achieve this ambition, with best methods compressing weights
to less than 2 bit on average. In this paper, we propose Channel-Relaxed Vector
Quantization (CRVQ), a novel technique that significantly improves the
performance of PTQ baselines at the cost of only minimal additional bits. This
state-of-the-art extreme compression method achieves its results through two
key innovations: (1) carefully selecting and reordering a very small subset of
critical weight channels, and (2) leveraging extended codebooks to relax the
constraint of critical channels. With our method, we demonstrate a 38.9\%
improvement over the current strongest sub-2-bit PTQ baseline, enabling nearer
lossless 1-bit compression. Furthermore, our approach offers flexible
customization of quantization bit-width and performance, providing a wider
range of deployment options for diverse hardware platforms.",2024-12-12,"Yuzhuang Xu, Shiyu Ji, Qingfu Zhu, Wanxiang Che",http://arxiv.org/pdf/2412.09282v2,cs.CL
Learning to Solve Domain-Specific Calculation Problems with Knowledge-Intensive Programs Generator,"Domain Large Language Models (LLMs) are developed for domain-specific tasks
based on general LLMs. But it still requires professional knowledge to
facilitate the expertise for some domain-specific tasks. In this paper, we
investigate into knowledge-intensive calculation problems. We find that the
math problems to be challenging for LLMs, when involving complex
domain-specific rules and knowledge documents, rather than simple formulations
of terminologies. Therefore, we propose a pipeline to solve the domain-specific
calculation problems with Knowledge-Intensive Programs Generator more
effectively, named as KIPG. It generates knowledge-intensive programs according
to the domain-specific documents. For each query, key variables are extracted,
then outcomes which are dependent on domain knowledge are calculated with the
programs. By iterative preference alignment, the code generator learns to
improve the logic consistency with the domain knowledge. Taking legal domain as
an example, we have conducted experiments to prove the effectiveness of our
pipeline, and extensive analysis on the modules. We also find that the code
generator is also adaptable to other domains, without training on the new
knowledge.",2024-12-12,"Chengyuan Liu, Shihang Wang, Lizhi Qing, Jun Lin, Ji Zhang, Fei Wu, Kun Kuang",http://arxiv.org/pdf/2412.09280v1,cs.CL
Towards Understanding the Robustness of LLM-based Evaluations under Perturbations,"Traditional evaluation metrics like BLEU and ROUGE fall short when capturing
the nuanced qualities of generated text, particularly when there is no single
ground truth. In this paper, we explore the potential of Large Language Models
(LLMs), specifically Google Gemini 1, to serve as automatic evaluators for
non-standardized metrics in summarization and dialog-based tasks. We conduct
experiments across multiple prompting strategies to examine how LLMs fare as
quality evaluators when compared with human judgments on the SummEval and USR
datasets, asking the model to generate both a score as well as a justification
for the score. Furthermore, we explore the robustness of the LLM evaluator by
using perturbed inputs. Our findings suggest that while LLMs show promise,
their alignment with human evaluators is limited, they are not robust against
perturbations and significant improvements are required for their standalone
use as reliable evaluators for subjective metrics.",2024-12-12,"Manav Chaudhary, Harshit Gupta, Savita Bhat, Vasudeva Varma",http://arxiv.org/pdf/2412.09269v1,cs.CL
"First Train to Generate, then Generate to Train: UnitedSynT5 for Few-Shot NLI","Natural Language Inference (NLI) tasks require identifying the relationship
between sentence pairs, typically classified as entailment, contradiction, or
neutrality. While the current state-of-the-art (SOTA) model, Entailment
Few-Shot Learning (EFL), achieves a 93.1% accuracy on the Stanford Natural
Language Inference (SNLI) dataset, further advancements are constrained by the
dataset's limitations. To address this, we propose a novel approach leveraging
synthetic data augmentation to enhance dataset diversity and complexity. We
present UnitedSynT5, an advanced extension of EFL that leverages a T5-based
generator to synthesize additional premise-hypothesis pairs, which are
rigorously cleaned and integrated into the training data. These augmented
examples are processed within the EFL framework, embedding labels directly into
hypotheses for consistency. We train a GTR-T5-XL model on this expanded
dataset, achieving a new benchmark of 94.7% accuracy on the SNLI dataset, 94.0%
accuracy on the E-SNLI dataset, and 92.6% accuracy on the MultiNLI dataset,
surpassing the previous SOTA models. This research demonstrates the potential
of synthetic data augmentation in improving NLI models, offering a path forward
for further advancements in natural language understanding tasks.",2024-12-12,"Sourav Banerjee, Anush Mahajan, Ayushi Agarwal, Eishkaran Singh",http://arxiv.org/pdf/2412.09263v2,cs.CL
Make Satire Boring Again: Reducing Stylistic Bias of Satirical Corpus by Utilizing Generative LLMs,"Satire detection is essential for accurately extracting opinions from textual
data and combating misinformation online. However, the lack of diverse corpora
for satire leads to the problem of stylistic bias which impacts the models'
detection performances. This study proposes a debiasing approach for satire
detection, focusing on reducing biases in training data by utilizing generative
large language models. The approach is evaluated in both cross-domain (irony
detection) and cross-lingual (English) settings. Results show that the
debiasing method enhances the robustness and generalizability of the models for
satire and irony detection tasks in Turkish and English. However, its impact on
causal language models, such as Llama-3.1, is limited. Additionally, this work
curates and presents the Turkish Satirical News Dataset with detailed human
annotations, with case studies on classification, debiasing, and
explainability.",2024-12-12,"Asli Umay Ozturk, Recep Firat Cekinel, Pinar Karagoz",http://arxiv.org/pdf/2412.09247v1,cs.CL
CleanComedy: Creating Friendly Humor through Generative Techniques,"Humor generation is a challenging task in natural language processing due to
limited resources and the quality of existing datasets. Available humor
language resources often suffer from toxicity and duplication, limiting their
effectiveness for training robust models. This paper proposes CleanComedy, a
specialized, partially annotated toxicity-filtered corpus of English and
Russian jokes collected from various sources. We study the effectiveness of our
data filtering approach through a survey on humor and toxicity levels in
various joke groups. In addition, we study advances in computer humor
generation by comparing jokes written by humans with various groups of
generative jokes, including our baseline models trained on the CleanComedy
datasets.",2024-12-12,"Dmitry Vikhorev, Daria Galimzianova, Svetlana Gorovaia, Elizaveta Zhemchuzhina, Ivan P. Yamshchikov",http://arxiv.org/pdf/2412.09203v1,cs.CL
ReFF: Reinforcing Format Faithfulness in Language Models across Varied Tasks,"Following formatting instructions to generate well-structured content is a
fundamental yet often unmet capability for large language models (LLMs). To
study this capability, which we refer to as format faithfulness, we present
FormatBench, a comprehensive format-related benchmark. Compared to previous
format-related benchmarks, FormatBench involves a greater variety of tasks in
terms of application scenes (traditional NLP tasks, creative works, autonomous
agency tasks), human-LLM interaction styles (single-turn instruction,
multi-turn chat), and format types (inclusion, wrapping, length, coding).
Moreover, each task in FormatBench is attached with a format checker program.
Extensive experiments on the benchmark reveal that state-of-the-art open- and
closed-source LLMs still suffer from severe deficiency in format faithfulness.
By virtue of the decidable nature of formats, we propose to Reinforce Format
Faithfulness (ReFF) to help LLMs generate formatted output as instructed
without compromising general quality. Without any annotated data, ReFF can
substantially improve the format faithfulness rate (e.g., from 21.6% in
original LLaMA3 to 95.0% on caption segmentation task), while keep the general
quality comparable (e.g., from 47.3 to 46.4 in F1 scores). Combined with
labeled training data, ReFF can simultaneously improve both format faithfulness
(e.g., from 21.6% in original LLaMA3 to 75.5%) and general quality (e.g., from
47.3 to 61.6 in F1 scores). We further offer an interpretability analysis to
explain how ReFF improves both format faithfulness and general quality.",2024-12-12,"Jiashu Yao, Heyan Huang, Zeming Liu, Haoyu Wen, Wei Su, Boao Qian, Yuhang Guo",http://arxiv.org/pdf/2412.09173v1,cs.CL
When Text Embedding Meets Large Language Model: A Comprehensive Survey,"Text embedding has become a foundational technology in natural language
processing (NLP) during the deep learning era, driving advancements across a
wide array of downstream tasks. While many natural language understanding
challenges can now be modeled using generative paradigms and leverage the
robust generative and comprehension capabilities of large language models
(LLMs), numerous practical applications - such as semantic matching,
clustering, and information retrieval - continue to rely on text embeddings for
their efficiency and effectiveness. Therefore, integrating LLMs with text
embeddings has become a major research focus in recent years. In this survey,
we categorize the interplay between LLMs and text embeddings into three
overarching themes: (1) LLM-augmented text embedding, enhancing traditional
embedding methods with LLMs; (2) LLMs as text embedders, adapting their innate
capabilities for high-quality embedding; and (3) Text embedding understanding
with LLMs, leveraging LLMs to analyze and interpret embeddings. By organizing
recent works based on interaction patterns rather than specific downstream
applications, we offer a novel and systematic overview of contributions from
various research and application domains in the era of LLMs. Furthermore, we
highlight the unresolved challenges that persisted in the pre-LLM era with
pre-trained language models (PLMs) and explore the emerging obstacles brought
forth by LLMs. Building on this analysis, we outline prospective directions for
the evolution of text embedding, addressing both theoretical and practical
opportunities in the rapidly advancing landscape of NLP.",2024-12-12,"Zhijie Nie, Zhangchi Feng, Mingxin Li, Cunwang Zhang, Yanzhao Zhang, Dingkun Long, Richong Zhang",http://arxiv.org/pdf/2412.09165v3,cs.CL
PolyIPA -- Multilingual Phoneme-to-Grapheme Conversion Model,"This paper presents PolyIPA, a novel multilingual phoneme-to-grapheme
conversion model designed for multilingual name transliteration, onomastic
research, and information retrieval. The model leverages two helper models
developed for data augmentation: IPA2vec for finding soundalikes across
languages, and similarIPA for handling phonetic notation variations. Evaluated
on a test set that spans multiple languages and writing systems, the model
achieves a mean Character Error Rate of 0.055 and a character-level BLEU score
of 0.914, with particularly strong performance on languages with shallow
orthographies. The implementation of beam search further improves practical
utility, with top-3 candidates reducing the effective error rate by 52.7\% (to
CER: 0.026), demonstrating the model's effectiveness for cross-linguistic
applications.",2024-12-12,Davor Lauc,http://arxiv.org/pdf/2412.09102v1,cs.CL
Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion,"Large Language Models (LLMs) present massive inherent knowledge and superior
semantic comprehension capability, which have revolutionized various tasks in
natural language processing. Despite their success, a critical gap remains in
enabling LLMs to perform knowledge graph completion (KGC). Empirical evidence
suggests that LLMs consistently perform worse than conventional KGC approaches,
even through sophisticated prompt design or tailored instruction-tuning.
Fundamentally, applying LLMs on KGC introduces several critical challenges,
including a vast set of entity candidates, hallucination issue of LLMs, and
under-exploitation of the graph structure. To address these challenges, we
propose a novel instruction-tuning-based method, namely FtG. Specifically, we
present a filter-then-generate paradigm and formulate the KGC task into a
multiple-choice question format. In this way, we can harness the capability of
LLMs while mitigating the issue casused by hallucinations. Moreover, we devise
a flexible ego-graph serialization prompt and employ a structure-text adapter
to couple structure and text information in a contextualized manner.
Experimental results demonstrate that FtG achieves substantial performance gain
compared to existing state-of-the-art methods. The instruction dataset and code
are available at https://github.com/LB0828/FtG.",2024-12-12,"Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng",http://arxiv.org/pdf/2412.09094v3,cs.CL
Evaluating Pixel Language Models on Non-Standardized Languages,"We explore the potential of pixel-based models for transfer learning from
standard languages to dialects. These models convert text into images that are
divided into patches, enabling a continuous vocabulary representation that
proves especially useful for out-of-vocabulary words common in dialectal data.
Using German as a case study, we compare the performance of pixel-based models
to token-based models across various syntactic and semantic tasks. Our results
show that pixel-based models outperform token-based models in part-of-speech
tagging, dependency parsing and intent detection for zero-shot dialect
evaluation by up to 26 percentage points in some scenarios, though not in
Standard German. However, pixel-based models fall short in topic
classification. These findings emphasize the potential of pixel-based models
for handling dialectal data, though further research should be conducted to
assess their effectiveness in various linguistic contexts.",2024-12-12,"Alberto Muñoz-Ortiz, Verena Blaschke, Barbara Plank",http://arxiv.org/pdf/2412.09084v1,cs.CL
Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning,"Large Language Models (LLMs) have demonstrated remarkable abilities across
various language tasks, but solving complex reasoning problems remains a
significant challenge. While existing methods, such as Chain-of-Thought (CoT)
and Tree-of-Thought (ToT), enhance reasoning by decomposing problems or
structuring prompts, they typically perform a single pass of reasoning and may
fail to revisit flawed paths, compromising accuracy. To address this
limitation, we propose a novel reasoning framework called Forest-of-Thought
(FoT), which integrates multiple reasoning trees to leverage collective
decision-making for solving complex logical problems. FoT employs sparse
activation strategies to select the most relevant reasoning paths, improving
both efficiency and accuracy. Additionally, we introduce a dynamic
self-correction strategy that enables real-time error correction, along with
consensus-guided decision-making strategies to optimize both correctness and
computational resources. Experimental results demonstrate that the FoT
framework, combined with these strategies, significantly enhances the reasoning
capabilities of LLMs, enabling them to solve complex tasks with greater
precision and efficiency. Code will be available at
https://github.com/iamhankai/Forest-of-Thought.",2024-12-12,"Zhenni Bi, Kai Han, Chuanjian Liu, Yehui Tang, Yunhe Wang",http://arxiv.org/pdf/2412.09078v5,cs.CL
Dial-In LLM: Human-Aligned LLM-in-the-loop Intent Clustering for Customer Service Dialogues,"Discovering customer intentions in dialogue conversations is crucial for
automated service agents. However, existing intent clustering methods often
fail to align with human perceptions due to a heavy reliance on embedding
distance metrics and a tendency to overlook underlying semantic structures.
This paper proposes an LLM-in-the-loop (LLM-ITL) intent clustering framework,
integrating the semantic understanding capabilities of LLMs into conventional
clustering algorithms. Specifically, this paper (1) investigates the
effectiveness of fine-tuned LLMs in semantic coherence evaluation and intent
cluster naming, achieving over 95% accuracy aligned with human judgments; (2)
designs an LLM-ITL framework that facilitates the iterative discovery of
coherent intent clusters and the optimal number of clusters; and (3) proposes
context-aware techniques tailored for customer service dialogue. As existing
English benchmarks offer limited semantic diversity and intent groups, we
introduce a comprehensive Chinese dialogue intent dataset, comprising over 100k
real customer service calls and 1,507 human-annotated intent clusters. The
proposed approaches significantly outperform LLM-guided baselines, achieving
notable enhancements in clustering quality and lower computational cost.
Combined with several best practices, our findings highlight the potential of
LLM-in-the-loop techniques for scalable and human-aligned intent clustering.",2024-12-12,"Mengze Hong, Wailing Ng, Chen Jason Zhang, Yuanfeng Song, Di Jiang",http://arxiv.org/pdf/2412.09049v3,cs.CL
Multi-Task Learning with LLMs for Implicit Sentiment Analysis: Data-level and Task-level Automatic Weight Learning,"Implicit sentiment analysis (ISA) presents significant challenges due to the
absence of salient cue words. Previous methods have struggled with insufficient
data and limited reasoning capabilities to infer underlying opinions.
Integrating multi-task learning (MTL) with large language models (LLMs) offers
the potential to enable models of varying sizes to reliably perceive and
recognize genuine opinions in ISA. However, existing MTL approaches are
constrained by two sources of uncertainty: data-level uncertainty, arising from
hallucination problems in LLM-generated contextual information, and task-level
uncertainty, stemming from the varying capacities of models to process
contextual information. To handle these uncertainties, we introduce MT-ISA, a
novel MTL framework that enhances ISA by leveraging the generation and
reasoning capabilities of LLMs through automatic MTL. Specifically, MT-ISA
constructs auxiliary tasks using generative LLMs to supplement sentiment
elements and incorporates automatic MTL to fully exploit auxiliary data. We
introduce data-level and task-level automatic weight learning (AWL), which
dynamically identifies relationships and prioritizes more reliable data and
critical tasks, enabling models of varying sizes to adaptively learn
fine-grained weights based on their reasoning capabilities. We investigate
three strategies for data-level AWL, while also introducing homoscedastic
uncertainty for task-level AWL. Extensive experiments reveal that models of
varying sizes achieve an optimal balance between primary prediction and
auxiliary tasks in MT-ISA. This underscores the effectiveness and adaptability
of our approach.",2024-12-12,"Wenna Lai, Haoran Xie, Guandong Xu, Qing Li",http://arxiv.org/pdf/2412.09046v1,cs.CL
Mining Word Boundaries from Speech-Text Parallel Data for Cross-domain Chinese Word Segmentation,"Inspired by early research on exploring naturally annotated data for Chinese
Word Segmentation (CWS), and also by recent research on integration of speech
and text processing, this work for the first time proposes to explicitly mine
word boundaries from speech-text parallel data. We employ the Montreal Forced
Aligner (MFA) toolkit to perform character-level alignment on speech-text data,
giving pauses as candidate word boundaries. Based on detailed analysis of
collected pauses, we propose an effective probability-based strategy for
filtering unreliable word boundaries. To more effectively utilize word
boundaries as extra training data, we also propose a robust complete-then-train
(CTT) strategy. We conduct cross-domain CWS experiments on two target domains,
i.e., ZX and AISHELL2. We have annotated about 1,000 sentences as the
evaluation data of AISHELL2. Experiments demonstrate the effectiveness of our
proposed approach.",2024-12-12,"Xuebin Wang, Lei Zhang, Zhenghua Li, Shilin Zhou, Chen Gong, Yang Hou",http://arxiv.org/pdf/2412.09045v1,cs.CL
ZigZagkv: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty,"Large Language models (LLMs) have become a research hotspot. To accelerate
the inference of LLMs, storing computed caches in memory has become the
standard technique. However, as the inference length increases, growing KV
caches might lead to out-of-memory issues. Many existing methods address this
issue through KV cache compression, primarily by preserving key tokens
throughout all layers to reduce information loss. Most of them allocate a
uniform budget size for each layer to retain. However, we observe that the
minimum budget sizes needed to retain essential information vary across layers
and models based on the perspectives of attention and hidden state output.
Building on this observation, this paper proposes a simple yet effective KV
cache compression method that leverages layer uncertainty to allocate budget
size for each layer. Experimental results show that the proposed method can
reduce memory usage of the KV caches to only $\sim$20\% when compared to Full
KV inference while achieving nearly lossless performance.",2024-12-12,"Meizhi Zhong, Xikai Liu, Chen Zhang, Yikun Lei, Yan Gao, Yao Hu, Kehai Chen, Min Zhang",http://arxiv.org/pdf/2412.09036v1,cs.CL
Dialogue Language Model with Large-Scale Persona Data Engineering,"Maintaining persona consistency is paramount in the application of
open-domain dialogue systems, as exemplified by models like ChatGPT. Despite
significant advancements, the limited scale and diversity of current persona
dialogue datasets remain challenges to achieving robust persona-consistent
dialogue models. In this study, drawing inspiration from the success of
large-scale pre-training, we introduce PPDS, an open-domain persona dialogue
system that employs extensive generative pre-training on a persona dialogue
dataset to enhance persona consistency. Specifically, we present a persona
extraction model designed to autonomously and precisely generate vast persona
dialogue datasets. Additionally, we unveil a pioneering persona augmentation
technique to address the invalid persona bias inherent in the constructed
dataset. Both quantitative and human evaluations consistently highlight the
superior response quality and persona consistency of our proposed model,
underscoring its effectiveness.",2024-12-12,"Mengze Hong, Chen Jason Zhang, Chaotao Chen, Rongzhong Lian, Di Jiang",http://arxiv.org/pdf/2412.09034v2,cs.CL
Shiksha: A Technical Domain focused Translation Dataset and Model for Indian Languages,"Neural Machine Translation (NMT) models are typically trained on datasets
with limited exposure to Scientific, Technical and Educational domains.
Translation models thus, in general, struggle with tasks that involve
scientific understanding or technical jargon. Their performance is found to be
even worse for low-resource Indian languages. Finding a translation dataset
that tends to these domains in particular, poses a difficult challenge. In this
paper, we address this by creating a multilingual parallel corpus containing
more than 2.8 million rows of English-to-Indic and Indic-to-Indic high-quality
translation pairs across 8 Indian languages. We achieve this by bitext mining
human-translated transcriptions of NPTEL video lectures. We also finetune and
evaluate NMT models using this corpus and surpass all other publicly available
models at in-domain tasks. We also demonstrate the potential for generalizing
to out-of-domain translation tasks by improving the baseline by over 2 BLEU on
average for these Indian languages on the Flores+ benchmark. We are pleased to
release our model and dataset via this link: https://huggingface.co/SPRINGLab.",2024-12-12,"Advait Joglekar, Srinivasan Umesh",http://arxiv.org/pdf/2412.09025v1,cs.CL
Improvement in Sign Language Translation Using Text CTC Alignment,"Current sign language translation (SLT) approaches often rely on gloss-based
supervision with Connectionist Temporal Classification (CTC), limiting their
ability to handle non-monotonic alignments between sign language video and
spoken text. In this work, we propose a novel method combining joint
CTC/Attention and transfer learning. The joint CTC/Attention introduces
hierarchical encoding and integrates CTC with the attention mechanism during
decoding, effectively managing both monotonic and non-monotonic alignments.
Meanwhile, transfer learning helps bridge the modality gap between vision and
language in SLT. Experimental results on two widely adopted benchmarks,
RWTH-PHOENIX-Weather 2014 T and CSL-Daily, show that our method achieves
results comparable to state-of-the-art and outperforms the pure-attention
baseline. Additionally, this work opens a new door for future research into
gloss-free SLT using text-based CTC alignment.",2024-12-12,"Sihan Tan, Taro Miyazaki, Nabeela Khan, Kazuhiro Nakadai",http://arxiv.org/pdf/2412.09014v4,cs.CL
What Makes Cryptic Crosswords Challenging for LLMs?,"Cryptic crosswords are puzzles that rely on general knowledge and the
solver's ability to manipulate language on different levels, dealing with
various types of wordplay. Previous research suggests that solving such puzzles
is challenging even for modern NLP models, including Large Language Models
(LLMs). However, there is little to no research on the reasons for their poor
performance on this task. In this paper, we establish the benchmark results for
three popular LLMs: Gemma2, LLaMA3 and ChatGPT, showing that their performance
on this task is still significantly below that of humans. We also investigate
why these models struggle to achieve superior performance. We release our code
and introduced datasets at
https://github.com/bodasadallah/decrypting-crosswords.",2024-12-12,"Abdelrahman Sadallah, Daria Kotova, Ekaterina Kochmar",http://arxiv.org/pdf/2412.09012v2,cs.CL
AI Adoption to Combat Financial Crime: Study on Natural Language Processing in Adverse Media Screening of Financial Services in English and Bangla multilingual interpretation,"This document explores the potential of employing Artificial Intelligence
(AI), specifically Natural Language Processing (NLP), to strengthen the
detection and prevention of financial crimes within the Mobile Financial
Services(MFS) of Bangladesh with multilingual scenario. The analysis focuses on
the utilization of NLP for adverse media screening, a vital aspect of
compliance with anti-money laundering (AML) and combating financial terrorism
(CFT) regulations. Additionally, it investigates the overall reception and
obstacles related to the integration of AI in Bangladeshi banks. This report
measures the effectiveness of NLP is promising with an accuracy around 94\%.
NLP algorithms display substantial promise in accurately identifying adverse
media content linked to financial crimes. The lack of progress in this aspect
is visible in Bangladesh, whereas globally the technology is already being used
to increase effectiveness and efficiency. Hence, it is clear there is an issue
with the acceptance of AI in Bangladesh. Some AML \& CFT concerns are already
being addressed by AI technology. For example, Image Recognition OCR technology
are being used in KYC procedures. Primary hindrances to AI integration involve
a lack of technical expertise, high expenses, and uncertainties surrounding
regulations. This investigation underscores the potential of AI-driven NLP
solutions in fortifying efforts to prevent financial crimes in Bangladesh.",2024-12-12,Soumita Roy,http://arxiv.org/pdf/2412.12171v1,cs.CL
Assessing the Robustness of Retrieval-Augmented Generation Systems in K-12 Educational Question Answering with Knowledge Discrepancies,"Retrieval-Augmented Generation (RAG) systems have demonstrated remarkable
potential as question answering systems in the K-12 Education domain, where
knowledge is typically queried within the restricted scope of authoritative
textbooks. However, the discrepancy between textbooks and the parametric
knowledge in Large Language Models (LLMs) could undermine the effectiveness of
RAG systems. To systematically investigate the robustness of RAG systems under
such knowledge discrepancies, we present EduKDQA, a question answering dataset
that simulates knowledge discrepancies in real applications by applying
hypothetical knowledge updates in answers and source documents. EduKDQA
includes 3,005 questions covering five subjects, under a comprehensive question
typology from the perspective of context utilization and knowledge integration.
We conducted extensive experiments on retrieval and question answering
performance. We find that most RAG systems suffer from a substantial
performance drop in question answering with knowledge discrepancies, while
questions that require integration of contextual knowledge and parametric
knowledge pose a challenge to LLMs.",2024-12-12,"Tianshi Zheng, Weihan Li, Jiaxin Bai, Weiqi Wang, Yangqiu Song",http://arxiv.org/pdf/2412.08985v1,cs.CL
RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios,"This paper introduces RuleArena, a novel and challenging benchmark designed
to evaluate the ability of large language models (LLMs) to follow complex,
real-world rules in reasoning. Covering three practical domains -- airline
baggage fees, NBA transactions, and tax regulations -- RuleArena assesses LLMs'
proficiency in handling intricate natural language instructions that demand
long-context understanding, logical reasoning, and accurate mathematical
computation. Two key attributes distinguish RuleArena from traditional
rule-based reasoning benchmarks: (1) it extends beyond standard first-order
logic representations, and (2) it is grounded in authentic, practical
scenarios, providing insights into the suitability and reliability of LLMs for
real-world applications. Our findings reveal several notable limitations in
LLMs: (1) they struggle to identify and apply the appropriate rules, frequently
becoming confused by similar but distinct regulations, (2) they cannot
consistently perform accurate mathematical computations, even when they
correctly identify the relevant rules, and (3) in general, they perform poorly
in the benchmark. These results highlight significant challenges in advancing
LLMs' rule-guided reasoning capabilities in real-life applications.",2024-12-12,"Ruiwen Zhou, Wenyue Hua, Liangming Pan, Sitao Cheng, Xiaobao Wu, En Yu, William Yang Wang",http://arxiv.org/pdf/2412.08972v1,cs.CL
Reasoning-Aware Query-Focused Summarization over Multi-Table Data,"Query-focused summarization over multi-table data is a challenging yet
critical task for extracting precise and relevant information from structured
data. Existing methods often rely on complex preprocessing steps and struggle
to generalize across domains or handle the logical reasoning required for
multi-table queries. In this paper, we propose QueryTableSummarizer++, an
end-to-end generative framework leveraging large language models (LLMs)
enhanced with table-aware pre-training, query-aligned fine-tuning, and
reinforcement learning with feedback. Our method eliminates the need for
intermediate serialization steps and directly generates query-relevant
summaries. Experiments on a benchmark dataset demonstrate that
QueryTableSummarizer++ significantly outperforms state-of-the-art baselines in
terms of BLEU, ROUGE, and F1-score. Additional analyses highlight its
scalability, generalization across domains, and robust handling of complex
queries. Human evaluation further validates the superior quality and practical
applicability of the generated summaries, establishing QueryTableSummarizer++
as a highly effective solution for multi-table summarization tasks.",2024-12-12,"Xiaochuan Lin, Xiangyong Chen",http://arxiv.org/pdf/2412.08970v1,cs.CL
"Align, Generate, Learn: A Novel Closed-Loop Framework for Cross-Lingual In-Context Learning","Cross-lingual in-context learning (XICL) has emerged as a transformative
paradigm for leveraging large language models (LLMs) to tackle multilingual
tasks, especially for low-resource languages. However, existing approaches
often rely on external retrievers or task-specific fine-tuning, limiting their
scalability and generalizability. In this paper, we propose a novel
self-supervised framework that harnesses the generative capabilities of LLMs to
internally select and utilize task-relevant examples. Our method introduces two
key objectives: a retrieval-generation alignment loss to optimize the quality
of selected examples and a semantic coherence loss to ensure cross-lingual
consistency. Through extensive experiments on multilingual benchmarks, our
approach achieves state-of-the-art performance, significantly outperforming
existing baselines. Further analysis highlights its robustness across diverse
language families and its ability to generalize to unseen tasks. Human
evaluations confirm the superior fluency, relevance, and semantic correctness
of outputs generated by our method. This work provides a scalable, effective,
and generalizable solution for cross-lingual in-context learning.",2024-12-12,"Mateo Alejandro Rojas, Rafael Carranza",http://arxiv.org/pdf/2412.08955v1,cs.CL
CareBot: A Pioneering Full-Process Open-Source Medical Language Model,"Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional domains such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. In this paper, we propose CareBot, a bilingual medical LLM,
which leverages a comprehensive approach integrating continuous pre-training
(CPT), supervised fine-tuning (SFT), and reinforcement learning with human
feedback (RLHF). Our novel two-stage CPT method, comprising Stable CPT and
Boost CPT, effectively bridges the gap between general and domain-specific
data, facilitating a smooth transition from pre-training to fine-tuning and
enhancing domain knowledge progressively. We also introduce DataRater, a model
designed to assess data quality during CPT, ensuring that the training data is
both accurate and relevant. For SFT, we develope a large and diverse bilingual
dataset, along with ConFilter, a metric to enhance multi-turn dialogue quality,
which is crucial to improving the model's ability to handle more complex
dialogues. The combination of high-quality data sources and innovative
techniques significantly improves CareBot's performance across a range of
medical applications. Our rigorous evaluations on Chinese and English
benchmarks confirm CareBot's effectiveness in medical consultation and
education. These advancements not only address current limitations in medical
LLMs but also set a new standard for developing effective and reliable
open-source models in the medical domain. We will open-source the datasets and
models later, contributing valuable resources to the research community.",2024-12-12,"Lulu Zhao, Weihao Zeng, Xiaofeng Shi, Hua Zhou",http://arxiv.org/pdf/2412.15236v2,cs.CL
Mojito: Motion Trajectory and Intensity Control for Video Generation,"Recent advancements in diffusion models have shown great promise in producing
high-quality video content. However, efficiently training video diffusion
models capable of integrating directional guidance and controllable motion
intensity remains a challenging and under-explored area. To tackle these
challenges, this paper introduces Mojito, a diffusion model that incorporates
both motion trajectory and intensity control for text-to-video generation.
Specifically, Mojito features a Directional Motion Control (DMC) module that
leverages cross-attention to efficiently direct the generated object's motion
without training, alongside a Motion Intensity Modulator (MIM) that uses
optical flow maps generated from videos to guide varying levels of motion
intensity. Extensive experiments demonstrate Mojito's effectiveness in
achieving precise trajectory and intensity control with high computational
efficiency, generating motion patterns that closely match specified directions
and intensities, providing realistic dynamics that align well with natural
motion in real-world scenarios.",2024-12-12,"Xuehai He, Shuohang Wang, Jianwei Yang, Xiaoxia Wu, Yiping Wang, Kuan Wang, Zheng Zhan, Olatunji Ruwase, Yelong Shen, Xin Eric Wang",http://arxiv.org/pdf/2412.08948v2,cs.CL
MoSLD: An Extremely Parameter-Efficient Mixture-of-Shared LoRAs for Multi-Task Learning,"Recently, LoRA has emerged as a crucial technique for fine-tuning large
pre-trained models, yet its performance in multi-task learning scenarios often
falls short. In contrast, the MoE architecture presents a natural solution to
this issue. However, it introduces challenges such as mutual interference of
data across multiple domains and knowledge forgetting of various tasks.
Additionally, MoE significantly increases the number of parameters, posing a
computational cost challenge. Therefore, in this paper, we propose MoSLD, a
mixture-of-shared-LoRAs model with a dropout strategy. MoSLD addresses these
challenges by sharing the upper projection matrix in LoRA among different
experts, encouraging the model to learn general knowledge across tasks, while
still allowing the lower projection matrix to focus on the unique features of
each task. The application of dropout alleviates the imbalanced update of
parameter matrix and mitigates parameter overfitting in LoRA. Extensive
experiments demonstrate that our model exhibits excellent performance in both
single-task and multi-task scenarios, with robust out-of-domain generalization
capabilities.",2024-12-12,"Lulu Zhao, Weihao Zeng, Xiaofeng Shi, Hua Zhou",http://arxiv.org/pdf/2412.08946v1,cs.CL
Multi-Scale Heterogeneous Text-Attributed Graph Datasets From Diverse Domains,"Heterogeneous Text-Attributed Graphs (HTAGs), where different types of
entities are not only associated with texts but also connected by diverse
relationships, have gained widespread popularity and application across various
domains. However, current research on text-attributed graph learning
predominantly focuses on homogeneous graphs, which feature a single node and
edge type, thus leaving a gap in understanding how methods perform on HTAGs.
One crucial reason is the lack of comprehensive HTAG datasets that offer
original textual content and span multiple domains of varying sizes. To this
end, we introduce a collection of challenging and diverse benchmark datasets
for realistic and reproducible evaluation of machine learning models on HTAGs.
Our HTAG datasets are multi-scale, span years in duration, and cover a wide
range of domains, including movie, community question answering, academic,
literature, and patent networks. We further conduct benchmark experiments on
these datasets with various graph neural networks. All source data, dataset
construction codes, processed HTAGs, data loaders, benchmark codes, and
evaluation setup are publicly available at GitHub and Hugging Face.",2024-12-12,"Yunhui Liu, Qizhuo Xie, Jinwei Shi, Jiaxu Shen, Tieke He",http://arxiv.org/pdf/2412.08937v1,cs.CL
From Text to Trajectory: Exploring Complex Constraint Representation and Decomposition in Safe Reinforcement Learning,"Safe reinforcement learning (RL) requires the agent to finish a given task
while obeying specific constraints. Giving constraints in natural language form
has great potential for practical scenarios due to its flexible transfer
capability and accessibility. Previous safe RL methods with natural language
constraints typically need to design cost functions manually for each
constraint, which requires domain expertise and lacks flexibility. In this
paper, we harness the dual role of text in this task, using it not only to
provide constraint but also as a training signal. We introduce the
Trajectory-level Textual Constraints Translator (TTCT) to replace the manually
designed cost function. Our empirical results demonstrate that TTCT effectively
comprehends textual constraint and trajectory, and the policies trained by TTCT
can achieve a lower violation rate than the standard cost function. Extra
studies are conducted to demonstrate that the TTCT has zero-shot transfer
capability to adapt to constraint-shift environments.",2024-12-12,"Pusen Dong, Tianchen Zhu, Yue Qiu, Haoyi Zhou, Jianxin Li",http://arxiv.org/pdf/2412.08920v2,cs.CL
Phi-4 Technical Report,"We present phi-4, a 14-billion parameter language model developed with a
training recipe that is centrally focused on data quality. Unlike most language
models, where pre-training is based primarily on organic data sources such as
web content or code, phi-4 strategically incorporates synthetic data throughout
the training process. While previous models in the Phi family largely distill
the capabilities of a teacher model (specifically GPT-4), phi-4 substantially
surpasses its teacher model on STEM-focused QA capabilities, giving evidence
that our data-generation and post-training techniques go beyond distillation.
Despite minimal changes to the phi-3 architecture, phi-4 achieves strong
performance relative to its size -- especially on reasoning-focused benchmarks
-- due to improved data, training curriculum, and innovations in the
post-training scheme.",2024-12-12,"Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell J. Hewett, Mojan Javaheripi, Piero Kauffmann, James R. Lee, Yin Tat Lee, Yuanzhi Li, Weishung Liu, Caio C. T. Mendes, Anh Nguyen, Eric Price, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Xin Wang, Rachel Ward, Yue Wu, Dingli Yu, Cyril Zhang, Yi Zhang",http://arxiv.org/pdf/2412.08905v1,cs.CL
AI-assisted Knowledge Discovery in Biomedical Literature to Support Decision-making in Precision Oncology,"The delivery of appropriate targeted therapies to cancer patients requires
the complete analysis of the molecular profiling of tumors and the patient's
clinical characteristics in the context of existing knowledge and recent
findings described in biomedical literature and several other sources. We
evaluated the potential contributions of specific natural language processing
solutions to support knowledge discovery from biomedical literature. Two models
from the Bidirectional Encoder Representations from Transformers (BERT) family,
two Large Language Models, and PubTator 3.0 were tested for their ability to
support the named entity recognition (NER) and the relation extraction (RE)
tasks. PubTator 3.0 and the BioBERT model performed best in the NER task (best
F1-score equal to 0.93 and 0.89, respectively), while BioBERT outperformed all
other solutions in the RE task (best F1-score 0.79) and a specific use case it
was applied to by recognizing nearly all entity mentions and most of the
relations.",2024-12-12,"Ting He, Kory Kreimeyer, Mimi Najjar, Jonathan Spiker, Maria Fatteh, Valsamo Anagnostou, Taxiarchis Botsis",http://arxiv.org/pdf/2412.08900v1,cs.CL
A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions,"Synthesizing high-quality reasoning data for continual training has been
proven to be effective in enhancing the performance of Large Language Models
(LLMs). However, previous synthetic approaches struggle to easily scale up data
and incur high costs in the pursuit of high quality. In this paper, we propose
the Graph-based Synthetic Data Pipeline (GSDP), an economical and scalable
framework for high-quality reasoning data synthesis. Inspired by knowledge
graphs, we extracted knowledge points from seed data and constructed a
knowledge point relationships graph to explore their interconnections. By
exploring the implicit relationships among knowledge, our method achieves
$\times$255 data expansion. Furthermore, GSDP led by open-source models,
achieves synthesis quality comparable to GPT-4-0613 while maintaining
$\times$100 lower costs. To tackle the most challenging mathematical reasoning
task, we present the GSDP-MATH dataset comprising over 1.91 million pairs of
math problems and answers. After fine-tuning on GSDP-MATH, GSDP-7B based on
Mistral-7B achieves 37.7% accuracy on MATH and 78.4% on GSM8K, demonstrating
the effectiveness of our method. The dataset and models will be released at
https://github.com/Jayce1kk/GSDP.",2024-12-12,"Jiankang Wang, Jianjun Xu, Xiaorui Wang, Yuxin Wang, Mengting Xing, Shancheng Fang, Zhineng Chen, Hongtao Xie, Yongdong Zhang",http://arxiv.org/pdf/2412.08864v3,cs.CL
OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large Language Models,"This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented
Generation method designed to enhance LLM-generated responses by anchoring
retrieval processes in domain-specific ontologies. While LLMs are widely used
for tasks like question answering and search, they struggle to adapt to
specialized knowledge, such as industrial workflows or knowledge work, without
expensive fine-tuning or sub-optimal retrieval methods. Existing
retrieval-augmented models, such as RAG, offer improvements but fail to account
for structured domain knowledge, leading to suboptimal context generation.
Ontologies, which conceptually organize domain knowledge by defining entities
and their interrelationships, offer a structured representation to address this
gap. OG-RAG constructs a hypergraph representation of domain documents, where
each hyperedge encapsulates clusters of factual knowledge grounded using
domain-specific ontology. An optimization algorithm then retrieves the minimal
set of hyperedges that constructs a precise, conceptually grounded context for
the LLM. This method enables efficient retrieval while preserving the complex
relationships between entities. OG-RAG applies to domains where fact-based
reasoning is essential, particularly in tasks that require workflows or
decision-making steps to follow predefined rules and procedures. These include
industrial workflows in healthcare, legal, and agricultural sectors, as well as
knowledge-driven tasks such as news journalism, investigative research,
consulting and more. Our evaluations demonstrate that OG-RAG increases the
recall of accurate facts by 55% and improves response correctness by 40% across
four different LLMs. Additionally, OG-RAG enables 30% faster attribution of
responses to context and boosts fact-based reasoning accuracy by 27% compared
to baseline methods.",2024-12-12,"Kartik Sharma, Peeyush Kumar, Yunqing Li",http://arxiv.org/pdf/2412.15235v1,cs.CL
Exploring Large Language Models on Cross-Cultural Values in Connection with Training Methodology,"Large language models (LLMs) closely interact with humans, and thus need an
intimate understanding of the cultural values of human society. In this paper,
we explore how open-source LLMs make judgments on diverse categories of
cultural values across countries, and its relation to training methodology such
as model sizes, training corpus, alignment, etc. Our analysis shows that LLMs
can judge socio-cultural norms similar to humans but less so on social systems
and progress. In addition, LLMs tend to judge cultural values biased toward
Western culture, which can be improved with training on the multilingual
corpus. We also find that increasing model size helps a better understanding of
social values, but smaller models can be enhanced by using synthetic data. Our
analysis reveals valuable insights into the design methodology of LLMs in
connection with their understanding of cultural values.",2024-12-12,"Minsang Kim, Seungjun Baek",http://arxiv.org/pdf/2412.08846v1,cs.CL
Large Concept Models: Language Modeling in a Sentence Representation Space,"LLMs have revolutionized the field of artificial intelligence and have
emerged as the de-facto tool for many tasks. The current established technology
of LLMs is to process input and generate output at the token level. This is in
sharp contrast to humans who operate at multiple levels of abstraction, well
beyond single words, to analyze information and to generate creative content.
In this paper, we present an attempt at an architecture which operates on an
explicit higher-level semantic representation, which we name a concept.
Concepts are language- and modality-agnostic and represent a higher level idea
or action in a flow. Hence, we build a ""Large Concept Model"". In this study, as
proof of feasibility, we assume that a concept corresponds to a sentence, and
use an existing sentence embedding space, SONAR, which supports up to 200
languages in both text and speech modalities.
  The Large Concept Model is trained to perform autoregressive sentence
prediction in an embedding space. We explore multiple approaches, namely MSE
regression, variants of diffusion-based generation, and models operating in a
quantized SONAR space. These explorations are performed using 1.6B parameter
models and training data in the order of 1.3T tokens. We then scale one
architecture to a model size of 7B parameters and training data of about 2.7T
tokens. We perform an experimental evaluation on several generative tasks,
namely summarization and a new task of summary expansion. Finally, we show that
our model exhibits impressive zero-shot generalization performance to many
languages, outperforming existing LLMs of the same size. The training code of
our models is freely available.",2024-12-11,"LCM team, Loïc Barrault, Paul-Ambroise Duquenne, Maha Elbayad, Artyom Kozhevnikov, Belen Alastruey, Pierre Andrews, Mariano Coria, Guillaume Couairon, Marta R. Costa-jussà, David Dale, Hady Elsahar, Kevin Heffernan, João Maria Janeiro, Tuan Tran, Christophe Ropers, Eduardo Sánchez, Robin San Roman, Alexandre Mourachko, Safiyyah Saleem, Holger Schwenk",http://arxiv.org/pdf/2412.08821v2,cs.CL
Greek2MathTex: A Greek Speech-to-Text Framework for LaTeX Equations Generation,"In the vast majority of the academic and scientific domains, LaTeX has
established itself as the de facto standard for typesetting complex
mathematical equations and formulae. However, LaTeX's complex syntax and
code-like appearance present accessibility barriers for individuals with
disabilities, as well as those unfamiliar with coding conventions. In this
paper, we present a novel solution to this challenge through the development of
a novel speech-to-LaTeX equations system specifically designed for the Greek
language. We propose an end-to-end system that harnesses the power of Automatic
Speech Recognition (ASR) and Natural Language Processing (NLP) techniques to
enable users to verbally dictate mathematical expressions and equations in
natural language, which are subsequently converted into LaTeX format. We
present the architecture and design principles of our system, highlighting key
components such as the ASR engine, the LLM-based prompt-driven equations
generation mechanism, as well as the application of a custom evaluation metric
employed throughout the development process. We have made our system open
source and available at https://github.com/magcil/greek-speech-to-math.",2024-12-11,"Evangelia Gkritzali, Panagiotis Kaliosis, Sofia Galanaki, Elisavet Palogiannidi, Theodoros Giannakopoulos",http://arxiv.org/pdf/2412.12167v1,cs.CL
jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images,"Contrastive Language-Image Pretraining (CLIP) has been widely used for
crossmodal information retrieval and multimodal understanding tasks. However,
CLIP models are mainly optimized for crossmodal vision-language tasks and
underperform in single-mode text tasks. Moreover, these models are often
trained on English datasets and therefore lack multilingual understanding.
Additionally, from a visual understanding perspective, previous CLIP-based
models exhibit insufficient understanding of visually rich documents. In this
work, we propose jina-clip-v2, a contrastive vision-language model trained on
text pairs, triplets and image-text pairs via a multi-task and multi-stage
contrastive learning paradigm in order to support both text-only and crossmodal
tasks. We employ a multilingual text encoder and expand the training dataset to
include multilingual texts from 29 non-English languages, including Hindi,
Chinese, German, French, and others, as well as images of visually rich
documents. We evaluate the model's performance and show that jina-clip-v2
achieves notable improvements over state-of-the-art CLIP-based models in
zero-shot text-only retrieval, semantic textual similarity, and crossmodal
retrieval tasks in both English and multilingual settings. jina-clip-v2 also
provides for flexibility in embedding dimensionality, enabling users to select
the granularity of the representations. jina-clip-v2 is publicly available at
https://huggingface.co/jinaai/jina-clip-v2.",2024-12-11,"Andreas Koukounas, Georgios Mastrapas, Sedigheh Eslami, Bo Wang, Mohammad Kalim Akram, Michael Günther, Isabelle Mohr, Saba Sturua, Nan Wang, Han Xiao",http://arxiv.org/pdf/2412.08802v2,cs.CL
A Multimodal Social Agent,"In recent years, large language models (LLMs) have demonstrated remarkable
progress in common-sense reasoning tasks. This ability is fundamental to
understanding social dynamics, interactions, and communication. However, the
potential of integrating computers with these social capabilities is still
relatively unexplored. However, the potential of integrating computers with
these social capabilities is still relatively unexplored. This paper introduces
MuSA, a multimodal LLM-based agent that analyzes text-rich social content
tailored to address selected human-centric content analysis tasks, such as
question answering, visual question answering, title generation, and
categorization. It uses planning, reasoning, acting, optimizing, criticizing,
and refining strategies to complete a task. Our approach demonstrates that MuSA
can automate and improve social content analysis, helping decision-making
processes across various applications. We have evaluated our agent's
capabilities in question answering, title generation, and content
categorization tasks. MuSA performs substantially better than our baselines.",2024-12-11,"Athina Bikaki, Ioannis A. Kakadiaris",http://arxiv.org/pdf/2501.06189v1,cs.CL
Coverage-based Fairness in Multi-document Summarization,"Fairness in multi-document summarization (MDS) measures whether a system can
generate a summary fairly representing information from documents with
different social attribute values. Fairness in MDS is crucial since a fair
summary can offer readers a comprehensive view. Previous works focus on
quantifying summary-level fairness using Proportional Representation, a
fairness measure based on Statistical Parity. However, Proportional
Representation does not consider redundancy in input documents and overlooks
corpus-level unfairness. In this work, we propose a new summary-level fairness
measure, Equal Coverage, which is based on coverage of documents with different
social attribute values and considers the redundancy within documents. To
detect the corpus-level unfairness, we propose a new corpus-level measure,
Coverage Parity. Our human evaluations show that our measures align more with
our definition of fairness. Using our measures, we evaluate the fairness of
thirteen different LLMs. We find that Claude3-sonnet is the fairest among all
evaluated LLMs. We also find that almost all LLMs overrepresent different
social attribute values. The code is available at
https://github.com/leehaoyuan/coverage_fairness.",2024-12-11,"Haoyuan Li, Yusen Zhang, Rui Zhang, Snigdha Chaturvedi",http://arxiv.org/pdf/2412.08795v2,cs.CL
Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases,"Introduction: Global burden of sexually transmitted infections (STIs) is
rising out of proportion to specialists. Current chatbots like ChatGPT are not
tailored for handling STI-related concerns out of the box. We developed Otiz,
an Artificial Intelligence-based (AI-based) chatbot platform designed
specifically for STI detection and counseling, and assessed its performance.
Methods: Otiz employs a multi-agent system architecture based on GPT4-0613,
leveraging large language model (LLM) and Deterministic Finite Automaton
principles to provide contextually relevant, medically accurate, and empathetic
responses. Its components include modules for general STI information,
emotional recognition, Acute Stress Disorder detection, and psychotherapy. A
question suggestion agent operates in parallel. Four STIs (anogenital warts,
herpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile
cancer) were evaluated using prompts mimicking patient language. Each prompt
was independently graded by two venereologists conversing with Otiz as patient
actors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5
(excellent). Results: Twenty-three venereologists did 60 evaluations of 30
prompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),
overall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility
(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower
(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were
lower (p=0.038). Inter-observer agreement was strong, with differences greater
than 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI
conversational agents like Otiz can provide accurate, correct, discrete,
non-judgmental, readily accessible and easily understandable STI-related
information in an empathetic manner, and can alleviate the burden on healthcare
systems.",2024-12-11,"Nikhil Mehta, Sithira Ambepitiya, Thanveer Ahamad, Dinuka Wijesundara, Yudara Kularathne",http://arxiv.org/pdf/2412.12166v1,cs.CL
BDA: Bangla Text Data Augmentation Framework,"Data augmentation involves generating synthetic samples that resemble those
in a given dataset. In resource-limited fields where high-quality data is
scarce, augmentation plays a crucial role in increasing the volume of training
data. This paper introduces a Bangla Text Data Augmentation (BDA) Framework
that uses both pre-trained models and rule-based methods to create new variants
of the text. A filtering process is included to ensure that the new text keeps
the same meaning as the original while also adding variety in the words used.
We conduct a comprehensive evaluation of the framework's effectiveness in
Bangla text classification tasks. Our framework achieved significant
improvement in F1 scores across five distinct datasets, delivering performance
equivalent to models trained on 100% of the data while utilizing only 50% of
the training dataset. Additionally, we explore the impact of data scarcity by
progressively reducing the training data and augmenting it through BDA,
resulting in notable F1 score enhancements. The study offers a thorough
examination of BDA's performance, identifying key factors for optimal results
and addressing its limitations through detailed analysis.",2024-12-11,"Md. Tariquzzaman, Audwit Nafi Anam, Naimul Haque, Mohsinul Kabir, Hasan Mahmud, Md Kamrul Hasan",http://arxiv.org/pdf/2412.08753v2,cs.CL
In-Context Learning with Topological Information for Knowledge Graph Completion,"Knowledge graphs (KGs) are crucial for representing and reasoning over
structured information, supporting a wide range of applications such as
information retrieval, question answering, and decision-making. However, their
effectiveness is often hindered by incompleteness, limiting their potential for
real-world impact. While knowledge graph completion (KGC) has been extensively
studied in the literature, recent advances in generative AI models,
particularly large language models (LLMs), have introduced new opportunities
for innovation. In-context learning has recently emerged as a promising
approach for leveraging pretrained knowledge of LLMs across a range of natural
language processing tasks and has been widely adopted in both academia and
industry. However, how to utilize in-context learning for effective KGC remains
relatively underexplored. We develop a novel method that incorporates
topological information through in-context learning to enhance KGC performance.
By integrating ontological knowledge and graph structure into the context of
LLMs, our approach achieves strong performance in the transductive setting
i.e., nodes in the test graph dataset are present in the training graph
dataset. Furthermore, we apply our approach to KGC in the more challenging
inductive setting, i.e., nodes in the training graph dataset and test graph
dataset are disjoint, leveraging the ontology to infer useful information about
missing nodes which serve as contextual cues for the LLM during inference. Our
method demonstrates superior performance compared to baselines on the
ILPC-small and ILPC-large datasets.",2024-12-11,"Udari Madhushani Sehwag, Kassiani Papasotiriou, Jared Vann, Sumitra Ganesh",http://arxiv.org/pdf/2412.08742v1,cs.CL
Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions,"Multimodal large language models (MLLMs) have made rapid progress in recent
years, yet continue to struggle with low-level visual perception (LLVP) --
particularly the ability to accurately describe the geometric details of an
image. This capability is crucial for applications in areas such as robotics,
medical image analysis, and manufacturing. In this paper, we first introduce
Geoperception, a benchmark designed to evaluate an MLLM's ability to accurately
transcribe 2D geometric information from an image. Using this benchmark, we
demonstrate the limitations of leading MLLMs, and then conduct a comprehensive
empirical study to explore strategies for improving their performance on
geometric tasks. Our findings highlight the benefits of certain model
architectures, training techniques, and data strategies, including the use of
high-fidelity synthetic data and multi-stage training with a data curriculum.
Notably, we find that a data curriculum enables models to learn challenging
geometry understanding tasks which they fail to learn from scratch. Leveraging
these insights, we develop Euclid, a family of models specifically optimized
for strong low-level geometric perception. Although purely trained on synthetic
multimodal data, Euclid shows strong generalization ability to novel geometry
shapes. For instance, Euclid outperforms the best closed-source model,
Gemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and
10.65% on average across all tasks.",2024-12-11,"Jiarui Zhang, Ollie Liu, Tianyu Yu, Jinyi Hu, Willie Neiswanger",http://arxiv.org/pdf/2412.08737v1,cs.CL
LatentQA: Teaching LLMs to Decode Activations Into Natural Language,"Interpretability methods seek to understand language model representations,
yet the outputs of most such methods -- circuits, vectors, scalars -- are not
immediately human-interpretable. In response, we introduce LatentQA, the task
of answering open-ended questions about model activations in natural language.
Towards solving LatentQA, we propose Latent Interpretation Tuning (LIT), which
finetunes a decoder LLM on a dataset of activations and associated
question-answer pairs, similar to how visual instruction tuning trains on
question-answer pairs associated with images. We use the decoder for diverse
reading applications, such as extracting relational knowledge from
representations or uncovering system prompts governing model behavior. Our
decoder also specifies a differentiable loss that we use to control models,
such as debiasing models on stereotyped sentences and controlling the sentiment
of generations. Finally, we extend LatentQA to reveal harmful model
capabilities, such as generating recipes for bioweapons and code for hacking.",2024-12-11,"Alexander Pan, Lijie Chen, Jacob Steinhardt",http://arxiv.org/pdf/2412.08686v1,cs.CL
Fast Prompt Alignment for Text-to-Image Generation,"Text-to-image generation has advanced rapidly, yet aligning complex textual
prompts with generated visuals remains challenging, especially with intricate
object relationships and fine-grained details. This paper introduces Fast
Prompt Alignment (FPA), a prompt optimization framework that leverages a
one-pass approach, enhancing text-to-image alignment efficiency without the
iterative overhead typical of current methods like OPT2I. FPA uses large
language models (LLMs) for single-iteration prompt paraphrasing, followed by
fine-tuning or in-context learning with optimized prompts to enable real-time
inference, reducing computational demands while preserving alignment fidelity.
Extensive evaluations on the COCO Captions and PartiPrompts datasets
demonstrate that FPA achieves competitive text-image alignment scores at a
fraction of the processing time, as validated through both automated metrics
(TIFA, VQA) and human evaluation. A human study with expert annotators further
reveals a strong correlation between human alignment judgments and automated
scores, underscoring the robustness of FPA's improvements. The proposed method
showcases a scalable, efficient alternative to iterative prompt optimization,
enabling broader applicability in real-time, high-demand settings. The codebase
is provided to facilitate further research:
https://github.com/tiktok/fast_prompt_alignment",2024-12-11,"Khalil Mrini, Hanlin Lu, Linjie Yang, Weilin Huang, Heng Wang",http://arxiv.org/pdf/2412.08639v1,cs.CL
Multimodal Latent Language Modeling with Next-Token Diffusion,"Multimodal generative models require a unified approach to handle both
discrete data (e.g., text and code) and continuous data (e.g., image, audio,
video). In this work, we propose Latent Language Modeling (LatentLM), which
seamlessly integrates continuous and discrete data using causal Transformers.
Specifically, we employ a variational autoencoder (VAE) to represent continuous
data as latent vectors and introduce next-token diffusion for autoregressive
generation of these vectors. Additionally, we develop $\sigma$-VAE to address
the challenges of variance collapse, which is crucial for autoregressive
modeling. Extensive experiments demonstrate the effectiveness of LatentLM
across various modalities. In image generation, LatentLM surpasses Diffusion
Transformers in both performance and scalability. When integrated into
multimodal large language models, LatentLM provides a general-purpose interface
that unifies multimodal generation and understanding. Experimental results show
that LatentLM achieves favorable performance compared to Transfusion and vector
quantized models in the setting of scaling up training tokens. In
text-to-speech synthesis, LatentLM outperforms the state-of-the-art VALL-E 2
model in speaker similarity and robustness, while requiring 10x fewer decoding
steps. The results establish LatentLM as a highly effective and scalable
approach to advance large multimodal models.",2024-12-11,"Yutao Sun, Hangbo Bao, Wenhui Wang, Zhiliang Peng, Li Dong, Shaohan Huang, Jianyong Wang, Furu Wei",http://arxiv.org/pdf/2412.08635v1,cs.CL
Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models,"Despite the advancements in training Large Language Models (LLMs) with
alignment techniques to enhance the safety of generated content, these models
remain susceptible to jailbreak, an adversarial attack method that exposes
security vulnerabilities in LLMs. Notably, the Greedy Coordinate Gradient (GCG)
method has demonstrated the ability to automatically generate adversarial
suffixes that jailbreak state-of-the-art LLMs. However, the optimization
process involved in GCG is highly time-consuming, rendering the jailbreaking
pipeline inefficient. In this paper, we investigate the process of GCG and
identify an issue of Indirect Effect, the key bottleneck of the GCG
optimization. To this end, we propose the Model Attack Gradient Index GCG
(MAGIC), that addresses the Indirect Effect by exploiting the gradient
information of the suffix tokens, thereby accelerating the procedure by having
less computation and fewer iterations. Our experiments on AdvBench show that
MAGIC achieves up to a 1.5x speedup, while maintaining Attack Success Rates
(ASR) on par or even higher than other baselines. Our MAGIC achieved an ASR of
74% on the Llama-2 and an ASR of 54% when conducting transfer attacks on
GPT-3.5. Code is available at https://github.com/jiah-li/magic.",2024-12-11,"Jiahui Li, Yongchang Hao, Haoyu Xu, Xing Wang, Yu Hong",http://arxiv.org/pdf/2412.08615v2,cs.CL
Der Effizienz- und Intelligenzbegriff in der Lexikographie und kuenstlichen Intelligenz: kann ChatGPT die lexikographische Textsorte nachbilden?,"By means of pilot experiments for the language pair German and Galician, this
paper examines the concept of efficiency and intelligence in lexicography and
artificial intelligence, AI. The aim of the experiments is to gain empirically
and statistically based insights into the lexicographical text type,dictionary
article, in the responses of ChatGPT 3.5, as well as into the lexicographical
data on which this chatbot was trained. Both quantitative and qualitative
methods are used for this purpose. The analysis is based on the evaluation of
the outputs of several sessions with the same prompt in ChatGPT 3.5. On the one
hand, the algorithmic performance of intelligent systems is evaluated in
comparison with data from lexicographical works. On the other hand, the ChatGPT
data supplied is analysed using specific text passages of the aforementioned
lexicographical text type. The results of this study not only help to evaluate
the efficiency of this chatbot regarding the creation of dictionary articles,
but also to delve deeper into the concept of intelligence, the thought
processes and the actions to be carried out in both disciplines.",2024-12-11,"Ivan Arias-Arias, Maria Jose Dominguez Vazquez, Carlos Valcarcel Riveiro",http://arxiv.org/pdf/2412.08599v1,cs.CL
Advancing Single and Multi-task Text Classification through Large Language Model Fine-tuning,"Both encoder-only models (e.g., BERT, RoBERTa) and large language models
(LLMs, e.g., Llama3) have been widely used for text classification tasks.
However, there is a lack of systematic studies comparing the performance of
encoder-based models and LLMs in text classification, particularly when
fine-tuning is involved. This study employed a diverse range of models and
methods, varying in size and architecture, and including both fine-tuned and
pre-trained approaches. We first assessed the performances of these LLMs on the
20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only
RoBERTa models. Additionally, we explored the multi-task capabilities of both
model types by combining multiple classification tasks, including intent
detection and slot-filling, into a single model using data from both datasets.
Our results indicate that fully fine-tuned Llama3-70B models outperform
RoBERTa-large and other decoder LLMs across various classification tasks and
datasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the
performance of dual-model setups in both tasks across both datasets. Overall,
our study provides a comprehensive benchmark of encoder-only and LLM models on
text classification tasks and demonstrates a method to combine two or more
fully fine-tuned decoder LLMs for reduced latency and equivalent performance.",2024-12-11,"Hang Zhao, Qile P. Chen, Yijing Barry Zhang, Gang Yang",http://arxiv.org/pdf/2412.08587v2,cs.CL
Machine Learning Information Retrieval and Summarisation to Support Systematic Review on Outcomes Based Contracting,"As academic literature proliferates, traditional review methods are
increasingly challenged by the sheer volume and diversity of available
research. This article presents a study that aims to address these challenges
by enhancing the efficiency and scope of systematic reviews in the social
sciences through advanced machine learning (ML) and natural language processing
(NLP) tools. In particular, we focus on automating stages within the systematic
reviewing process that are time-intensive and repetitive for human annotators
and which lend themselves to immediate scalability through tools such as
information retrieval and summarisation guided by expert advice. The article
concludes with a summary of lessons learnt regarding the integrated approach
towards systematic reviews and future directions for improvement, including
explainability.",2024-12-11,"Iman Munire Bilal, Zheng Fang, Miguel Arana-Catania, Felix-Anselm van Lier, Juliana Outes Velarde, Harry Bregazzi, Eleanor Carter, Mara Airoldi, Rob Procter",http://arxiv.org/pdf/2412.08578v1,cs.CL
Visual Program Distillation with Template-Based Augmentation,"Adapting visual programming or prompting large language models (LLMs) to
generate executable code for visual tasks like visual question answering (VQA)
for specialized tasks or domains remains challenging due to high annotation and
inference costs. We propose a low-cost visual program distillation method that
can be used for models with at most 1 billion parameters and requires no
human-generated program annotations. We achieve this through synthetic data
augmentation based on decoupling programs into higher-level skills, called
templates, and their corresponding arguments. Experimental results show that,
with a relatively small amount of question/answer data, small language models
can generate high-quality specialized visual programs with the added benefit of
much faster inference",2024-12-11,"Michal Shlapentokh-Rothman, Yu-Xiong Wang, Derek Hoiem",http://arxiv.org/pdf/2412.08564v3,cs.CL
Bilevel Joint Unsupervised and Supervised Training for Automatic Speech Recognition,"In this paper, we propose a bilevel joint unsupervised and supervised
training (BL-JUST) framework for automatic speech recognition. Compared to the
conventional pre-training and fine-tuning strategy which is a disconnected
two-stage process, BL-JUST tries to optimize an acoustic model such that it
simultaneously minimizes both the unsupervised and supervised loss functions.
Because BL-JUST seeks matched local optima of both loss functions, acoustic
representations learned by the acoustic model strike a good balance between
being generic and task-specific. We solve the BL-JUST problem using
penalty-based bilevel gradient descent and evaluate the trained deep neural
network acoustic models on various datasets with a variety of architectures and
loss functions. We show that BL-JUST can outperform the widely-used
pre-training and fine-tuning strategy and some other popular semi-supervised
techniques.",2024-12-11,"Xiaodong Cui, A F M Saif, Songtao Lu, Lisha Chen, Tianyi Chen, Brian Kingsbury, George Saon",http://arxiv.org/pdf/2412.08548v1,cs.CL
MaestroMotif: Skill Design from Artificial Intelligence Feedback,"Describing skills in natural language has the potential to provide an
accessible way to inject human knowledge about decision-making into an AI
system. We present MaestroMotif, a method for AI-assisted skill design, which
yields high-performing and adaptable agents. MaestroMotif leverages the
capabilities of Large Language Models (LLMs) to effectively create and reuse
skills. It first uses an LLM's feedback to automatically design rewards
corresponding to each skill, starting from their natural language description.
Then, it employs an LLM's code generation abilities, together with
reinforcement learning, for training the skills and combining them to implement
complex behaviors specified in language. We evaluate MaestroMotif using a suite
of complex tasks in the NetHack Learning Environment (NLE), demonstrating that
it surpasses existing approaches in both performance and usability.",2024-12-11,"Martin Klissarov, Mikael Henaff, Roberta Raileanu, Shagun Sodhani, Pascal Vincent, Amy Zhang, Pierre-Luc Bacon, Doina Precup, Marlos C. Machado, Pierluca D'Oro",http://arxiv.org/pdf/2412.08542v1,cs.CL
TECO: Improving Multimodal Intent Recognition with Text Enhancement through Commonsense Knowledge Extraction,"The objective of multimodal intent recognition (MIR) is to leverage various
modalities-such as text, video, and audio-to detect user intentions, which is
crucial for understanding human language and context in dialogue systems.
Despite advances in this field, two main challenges persist: (1) effectively
extracting and utilizing semantic information from robust textual features; (2)
aligning and fusing non-verbal modalities with verbal ones effectively. This
paper proposes a Text Enhancement with CommOnsense Knowledge Extractor (TECO)
to address these challenges. We begin by extracting relations from both
generated and retrieved knowledge to enrich the contextual information in the
text modality. Subsequently, we align and integrate visual and acoustic
representations with these enhanced text features to form a cohesive multimodal
representation. Our experimental results show substantial improvements over
existing baseline methods.",2024-12-11,"Quynh-Mai Thi Nguyen, Lan-Nhi Thi Nguyen, Cam-Van Thi Nguyen",http://arxiv.org/pdf/2412.08529v1,cs.CL
Continual Learning for Encoder-only Language Models via a Discrete Key-Value Bottleneck,"Continual learning remains challenging across various natural language
understanding tasks. When models are updated with new training data, they risk
catastrophic forgetting of prior knowledge. In the present work, we introduce a
discrete key-value bottleneck for encoder-only language models, allowing for
efficient continual learning by requiring only localized updates. Inspired by
the success of a discrete key-value bottleneck in vision, we address new and
NLP-specific challenges. We experiment with different bottleneck architectures
to find the most suitable variants regarding language, and present a generic
discrete key initialization technique for NLP that is task independent. We
evaluate the discrete key-value bottleneck in four continual learning NLP
scenarios and demonstrate that it alleviates catastrophic forgetting. We
showcase that it offers competitive performance to other popular continual
learning methods, with lower computational costs.",2024-12-11,"Andor Diera, Lukas Galke, Fabian Karl, Ansgar Scherp",http://arxiv.org/pdf/2412.08528v1,cs.CL
EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache Compression Based on Global-Local Importance,"As large language models (LLMs) continue to advance, the demand for higher
quality and faster processing of long contexts across various applications is
growing. KV cache is widely adopted as it stores previously generated key and
value tokens, effectively reducing redundant computations during inference.
However, as memory overhead becomes a significant concern, efficient
compression of KV cache has gained increasing attention. Most existing methods
perform compression from two perspectives: identifying important tokens and
designing compression strategies. However, these approaches often produce
biased distributions of important tokens due to the influence of accumulated
attention scores or positional encoding. Furthermore, they overlook the
sparsity and redundancy across different heads, which leads to difficulties in
preserving the most effective information at the head level. To this end, we
propose EMS to overcome these limitations, while achieving better KV cache
compression under extreme compression ratios. Specifically, we introduce a
Global-Local score that combines accumulated attention scores from both global
and local KV tokens to better identify the token importance. For the
compression strategy, we design an adaptive and unified Evict-then-Merge
framework that accounts for the sparsity and redundancy of KV tokens across
different heads. Additionally, we implement the head-wise parallel compression
through a zero-class mechanism to enhance efficiency. Extensive experiments
demonstrate our SOTA performance even under extreme compression ratios. EMS
consistently achieves the lowest perplexity, improves scores by over 1.28
points across four LLMs on LongBench under a 256 cache budget, and preserves
95% retrieval accuracy with a cache budget less than 2% of the context length
in the Needle-in-a-Haystack task.",2024-12-11,"Yingxin Li, Ye Li, Yuan Meng, Xinzhu Ma, Zihan Geng, Shutao Xia, Zhi Wang",http://arxiv.org/pdf/2412.08521v2,cs.CL
GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek,"We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)
toolkit developed specifically for modern Greek. The toolkit provides
state-of-the-art performance in five core NLP tasks, namely part-of-speech
tagging, morphological tagging, dependency parsing, named entity recognition,
and Greeklishto-Greek transliteration. The toolkit is based on pre-trained
Transformers, it is freely available, and can be easily installed in Python
(pip install gr-nlp-toolkit). It is also accessible through a demonstration
platform on HuggingFace, along with a publicly available API for non-commercial
use. We discuss the functionality provided for each task, the underlying
methods, experiments against comparable open-source toolkits, and future
possible enhancements. The toolkit is available at:
https://github.com/nlpaueb/gr-nlp-toolkit",2024-12-11,"Lefteris Loukas, Nikolaos Smyrnioudis, Chrysa Dikonomaki, Spyros Barbakos, Anastasios Toumazatos, John Koutsikakis, Manolis Kyriakakis, Mary Georgiou, Stavros Vassos, John Pavlopoulos, Ion Androutsopoulos",http://arxiv.org/pdf/2412.08520v1,cs.CL
Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation,"The reranker and generator are two critical components in the
Retrieval-Augmented Generation (i.e., RAG) pipeline, responsible for ranking
relevant documents and generating responses. However, due to differences in
pre-training data and objectives, there is an inevitable gap between the
documents ranked as relevant by the reranker and those required by the
generator to support answering the query. To address this gap, we propose
RADIO, a novel and practical preference alignment framework with RAtionale
DIstillatiOn. Specifically, We first propose a rationale extraction method that
leverages the reasoning capabilities of Large Language Models (LLMs) to extract
the rationales necessary for answering the query. Subsequently, a
rationale-based alignment process is designed to rerank the documents based on
the extracted rationales, and fine-tune the reranker to align the preferences.
We conduct extensive experiments on two tasks across three datasets to
demonstrate the effectiveness of our approach compared to baseline methods. Our
code is released online to ease reproduction.",2024-12-11,"Pengyue Jia, Derong Xu, Xiaopeng Li, Zhaocheng Du, Xiangyang Li, Xiangyu Zhao, Yichao Wang, Yuhao Wang, Huifeng Guo, Ruiming Tang",http://arxiv.org/pdf/2412.08519v1,cs.CL
Comparative Opinion Mining in Product Reviews: Multi-perspective Prompt-based Learning,"Comparative reviews are pivotal in understanding consumer preferences and
influencing purchasing decisions. Comparative Quintuple Extraction (COQE) aims
to identify five key components in text: the target entity, compared entities,
compared aspects, opinions on these aspects, and polarity. Extracting precise
comparative information from product reviews is challenging due to nuanced
language and sequential task errors in traditional methods. To mitigate these
problems, we propose MTP-COQE, an end-to-end model designed for COQE.
Leveraging multi-perspective prompt-based learning, MTP-COQE effectively guides
the generative model in comparative opinion mining tasks. Evaluation on the
Camera-COQE (English) and VCOM (Vietnamese) datasets demonstrates MTP-COQE's
efficacy in automating COQE, achieving superior performance with a 1.41% higher
F1 score than the previous baseline models on the English dataset.
Additionally, we designed a strategy to limit the generative model's creativity
to ensure the output meets expectations. We also performed data augmentation to
address data imbalance and to prevent the model from becoming biased towards
dominant samples.",2024-12-11,"Hai-Yen Thi Nguyen, Cam-Van Thi Nguyen",http://arxiv.org/pdf/2412.08508v1,cs.CL
Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation,"Neural machine translation (NMT) systems amplify lexical biases present in
their training data, leading to artificially impoverished language in output
translations. These language-level characteristics render automatic
translations different from text originally written in a language and human
translations, which hinders their usefulness in for example creating evaluation
datasets. Attempts to increase naturalness in NMT can fall short in terms of
content preservation, where increased lexical diversity comes at the cost of
translation accuracy. Inspired by the reinforcement learning from human
feedback framework, we introduce a novel method that rewards both naturalness
and content preservation. We experiment with multiple perspectives to produce
more natural translations, aiming at reducing machine and human translationese.
We evaluate our method on English-to-Dutch literary translation, and find that
our best model produces translations that are lexically richer and exhibit more
properties of human-written language, without loss in translation accuracy.",2024-12-11,"Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral",http://arxiv.org/pdf/2412.08473v1,cs.CL
Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel,"Creating high-quality data for training robust language-instructed agents is
a long-lasting challenge in embodied AI. In this paper, we introduce a
Self-Refining Data Flywheel (SRDF) that generates high-quality and large-scale
navigational instruction-trajectory pairs by iteratively refining the data pool
through the collaboration between two models, the instruction generator and the
navigator, without any human-in-the-loop annotation. Specifically, SRDF starts
with using a base generator to create an initial data pool for training a base
navigator, followed by applying the trained navigator to filter the data pool.
This leads to higher-fidelity data to train a better generator, which can, in
turn, produce higher-quality data for training the next-round navigator. Such a
flywheel establishes a data self-refining process, yielding a continuously
improved and highly effective dataset for large-scale language-guided
navigation learning. Our experiments demonstrate that after several flywheel
rounds, the navigator elevates the performance boundary from 70% to 78% SPL on
the classic R2R test set, surpassing human performance (76%) for the first
time. Meanwhile, this process results in a superior generator, evidenced by a
SPICE increase from 23.5 to 26.2, better than all previous VLN instruction
generation methods. Finally, we demonstrate the scalability of our method
through increasing environment and instruction diversity, and the
generalization ability of our pre-trained navigator across various downstream
navigation tasks, surpassing state-of-the-art methods by a large margin in all
cases.",2024-12-11,"Zun Wang, Jialu Li, Yicong Hong, Songze Li, Kunchang Li, Shoubin Yu, Yi Wang, Yu Qiao, Yali Wang, Mohit Bansal, Limin Wang",http://arxiv.org/pdf/2412.08467v2,cs.CL
Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy,"Many previous models of named entity recognition (NER) suffer from the
problem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the
test samples have not appeared in the training samples, which hinders the
achievement of satisfactory performance. To improve OOE-NER performance, in
this paper, we propose a new framework, namely S+NER, which fully leverages
sentence-level information. Our S+NER achieves better OOE-NER performance
mainly due to the following two particular designs. 1) It first exploits the
pre-trained language model's capability of understanding the target entity's
sentence-level context with a template set. 2) Then, it refines the
sentence-level representation based on the positive and negative templates,
through a contrastive learning strategy and template pooling method, to obtain
better NER results. Our extensive experiments on five benchmark datasets have
demonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.",2024-12-11,"Guochao Jiang, Ziqin Luo, Chengwei Hu, Zepeng Ding, Deqing Yang",http://arxiv.org/pdf/2412.08434v2,cs.CL
Assessing Personalized AI Mentoring with Large Language Models in the Computing Field,"This paper provides an in-depth evaluation of three state-of-the-art Large
Language Models (LLMs) for personalized career mentoring in the computing
field, using three distinct student profiles that consider gender, race, and
professional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2
using a zero-shot learning approach without human intervention. A quantitative
evaluation was conducted through a custom natural language processing analytics
pipeline to highlight the uniqueness of the responses and to identify words
reflecting each student's profile, including race, gender, or professional
level. The analysis of frequently used words in the responses indicates that
GPT-4 offers more personalized mentoring compared to the other two LLMs.
Additionally, a qualitative evaluation was performed to see if human experts
reached similar conclusions. The analysis of survey responses shows that GPT-4
outperformed the other two LLMs in delivering more accurate and useful
mentoring while addressing specific challenges with encouragement languages.
Our work establishes a foundation for developing personalized mentoring tools
based on LLMs, incorporating human mentors in the process to deliver a more
impactful and tailored mentoring experience.",2024-12-11,"Xiao Luo, Sean O'Connell, Shamima Mithun",http://arxiv.org/pdf/2412.08430v1,cs.CL
Detecting Conversational Mental Manipulation with Intent-Aware Prompting,"Mental manipulation severely undermines mental wellness by covertly and
negatively distorting decision-making. While there is an increasing interest in
mental health care within the natural language processing community, progress
in tackling manipulation remains limited due to the complexity of detecting
subtle, covert tactics in conversations. In this paper, we propose Intent-Aware
Prompting (IAP), a novel approach for detecting mental manipulations using
large language models (LLMs), providing a deeper understanding of manipulative
tactics by capturing the underlying intents of participants. Experimental
results on the MentalManip dataset demonstrate superior effectiveness of IAP
against other advanced prompting strategies. Notably, our approach
substantially reduces false negatives, helping detect more instances of mental
manipulation with minimal misjudgment of positive cases. The code of this paper
is available at https://github.com/Anton-Jiayuan-MA/Manip-IAP.",2024-12-11,"Jiayuan Ma, Hongbin Na, Zimu Wang, Yining Hua, Yue Liu, Wei Wang, Ling Chen",http://arxiv.org/pdf/2412.08414v1,cs.CL
Learning to Reason via Self-Iterative Process Feedback for Small Language Models,"Small language models (SLMs) are more efficient, cost-effective, and
customizable than large language models (LLMs), though they often underperform
in specific areas like reasoning. Past methods for enhancing SLMs' reasoning,
such as supervised fine-tuning and distillation, often depend on costly
external signals, resulting in SLMs being overly confident with limited
supervision signals, thus limiting their abilities. Therefore, this study
enables SLMs to learn to reason from self-iterative feedback. By combining odds
ratio preference optimization (ORPO), we fine-tune and align SLMs using
positive and negative signals generated by themselves. Additionally, we
introduce process supervision for rewards in preference alignment by
sampling-based inference simulation and process reward models. Compared to
Supervised Fine-Tuning (SFT), our method improves the performance of Gemma-2B
by 12.43 (Acc) on GSM8K and 3.95 (Pass@1) on MBPP. Furthermore, the proposed
method also demonstrated superior out-of-domain generalization capabilities on
MMLU_Math and HumanEval.",2024-12-11,"Kaiyuan Chen, Jin Wang, Xuejie Zhang",http://arxiv.org/pdf/2412.08393v1,cs.CL
The Roles of English in Evaluating Multilingual Language Models,"Multilingual natural language processing is getting increased attention, with
numerous models, benchmarks, and methods being released for many languages.
English is often used in multilingual evaluation to prompt language models
(LMs), mainly to overcome the lack of instruction tuning data in other
languages. In this position paper, we lay out two roles of English in
multilingual LM evaluations: as an interface and as a natural language. We
argue that these roles have different goals: task performance versus language
understanding. This discrepancy is highlighted with examples from datasets and
evaluation setups. Numerous works explicitly use English as an interface to
boost task performance. We recommend to move away from this imprecise method
and instead focus on furthering language understanding.",2024-12-11,"Wessel Poelman, Miryam de Lhoneux",http://arxiv.org/pdf/2412.08392v1,cs.CL
SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse Scenarios Handling Emotional Support Agent,"Large Language Models (LLMs) have demonstrated promising potential in
providing empathetic support during interactions. However, their responses
often become verbose or overly formulaic, failing to adequately address the
diverse emotional support needs of real-world scenarios. To tackle this
challenge, we propose an innovative strategy-enhanced role-playing framework,
designed to simulate authentic emotional support conversations. Specifically,
our approach unfolds in two steps: (1) Strategy-Enhanced Role-Playing
Interactions, which involve three pivotal roles -- Seeker, Strategy Counselor,
and Supporter -- engaging in diverse scenarios to emulate real-world
interactions and promote a broader range of dialogues; and (2) Emotional
Support Agent Training, achieved through fine-tuning LLMs using our specially
constructed dataset. Within this framework, we develop the \textbf{ServeForEmo}
dataset, comprising an extensive collection of 3.7K+ multi-turn dialogues and
62.8K+ utterances. We further present \textbf{SweetieChat}, an emotional
support agent capable of handling diverse open-domain scenarios. Extensive
experiments and human evaluations confirm the framework's effectiveness in
enhancing emotional support, highlighting its unique ability to provide more
nuanced and tailored assistance.",2024-12-11,"Jing Ye, Lu Xiang, Yaping Zhang, Chengqing Zong",http://arxiv.org/pdf/2412.08389v1,cs.CL
NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis,"The integration of artificial intelligence (AI) in legal judgment prediction
(LJP) has the potential to transform the legal landscape, particularly in
jurisdictions like India, where a significant backlog of cases burdens the
legal system. This paper introduces NyayaAnumana, the largest and most diverse
corpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945
preprocessed cases. NyayaAnumana, which combines the words ""Nyay"" (judgment)
and ""Anuman"" (prediction or inference) respectively for most major Indian
languages, includes a wide range of cases from the Supreme Court, High Courts,
Tribunal Courts, District Courts, and Daily Orders and, thus, provides
unparalleled diversity and coverage. Our dataset surpasses existing datasets
like PredEx and ILDC, offering a comprehensive foundation for advanced AI
research in the legal domain.
  In addition to the dataset, we present INLegalLlama, a domain-specific
generative large language model (LLM) tailored to the intricacies of the Indian
legal system. It is developed through a two-phase training approach over a base
LLaMa model. First, Indian legal documents are injected using continual
pretraining. Second, task-specific supervised finetuning is done. This method
allows the model to achieve a deeper understanding of legal contexts.
  Our experiments demonstrate that incorporating diverse court data
significantly boosts model accuracy, achieving approximately 90% F1-score in
prediction tasks. INLegalLlama not only improves prediction accuracy but also
offers comprehensible explanations, addressing the need for explainability in
AI-assisted legal decisions.",2024-12-11,"Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya",http://arxiv.org/pdf/2412.08385v1,cs.CL
SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs,"We present SmolTulu-1.7b-Instruct, referenced in this report as
SmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's
Tulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.
Through comprehensive empirical analysis using a 135M parameter model, we
demonstrate that the relationship between learning rate and batch size
significantly impacts model performance in a task-dependent manner. Our
findings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from
higher learning rate to batch size ratios, while pattern recognition tasks such
as HellaSwag and IFEval show optimal performance with lower ratios. These
insights informed the development of SmolTulu, which achieves state-of-the-art
performance among sub-2B parameter models on instruction following, scoring
67.7% on IFEval ($\Delta$11%), and mathematical reasoning with 51.6% on GSM8K
($\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC
($\Delta5.4%$). We release our model, training recipes, and ablation studies to
facilitate further research in efficient model alignment, demonstrating that
careful adaptation of optimization dynamics can help bridge the capability gap
between small and large language models.",2024-12-11,Sultan Alrashed,http://arxiv.org/pdf/2412.08347v1,cs.CL
BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch Language,"Zero-shot evaluation of information retrieval (IR) models is often performed
using BEIR; a large and heterogeneous benchmark composed of multiple datasets,
covering different retrieval tasks across various domains. Although BEIR has
become a standard benchmark for the zero-shot setup, its exclusively English
content reduces its utility for underrepresented languages in IR, including
Dutch. To address this limitation and encourage the development of Dutch IR
models, we introduce BEIR-NL by automatically translating the publicly
accessible BEIR datasets into Dutch. Using BEIR-NL, we evaluated a wide range
of multilingual dense ranking and reranking models, as well as the lexical BM25
method. Our experiments show that BM25 remains a competitive baseline, and is
only outperformed by the larger dense models trained for retrieval. When
combined with reranking models, BM25 achieves performance on par with the best
dense ranking models. In addition, we explored the impact of translation on the
data by back-translating a selection of datasets to English, and observed a
performance drop for both dense and lexical methods, indicating the limitations
of translation for creating benchmarks. BEIR-NL is publicly available on the
Hugging Face hub.",2024-12-11,"Nikolay Banar, Ehsan Lotfi, Walter Daelemans",http://arxiv.org/pdf/2412.08329v1,cs.CL
Large Language Models Still Face Challenges in Multi-Hop Reasoning with External Knowledge,"We carry out a series of experiments to test large language models' multi-hop
reasoning ability from three aspects: selecting and combining external
knowledge, dealing with non-sequential reasoning tasks and generalising to data
samples with larger numbers of hops. We test the GPT-3.5 model on four
reasoning benchmarks with Chain-of-Thought prompting (and its variations). Our
results reveal that despite the amazing performance achieved by large language
models on various reasoning tasks, models still suffer from severe drawbacks
which shows a large gap with humans.",2024-12-11,Haotong Zhang,http://arxiv.org/pdf/2412.08317v1,cs.CL
Rumor Detection on Social Media with Temporal Propagation Structure Optimization,"Traditional methods for detecting rumors on social media primarily focus on
analyzing textual content, often struggling to capture the complexity of online
interactions. Recent research has shifted towards leveraging graph neural
networks to model the hierarchical conversation structure that emerges during
rumor propagation. However, these methods tend to overlook the temporal aspect
of rumor propagation and may disregard potential noise within the propagation
structure. In this paper, we propose a novel approach that incorporates
temporal information by constructing a weighted propagation tree, where the
weight of each edge represents the time interval between connected posts.
Drawing upon the theory of structural entropy, we transform this tree into a
coding tree. This transformation aims to preserve the essential structure of
rumor propagation while reducing noise. Finally, we introduce a recursive
neural network to learn from the coding tree for rumor veracity prediction.
Experimental results on two common datasets demonstrate the superiority of our
approach.",2024-12-11,"Xingyu Peng, Junran Wu, Ruomei Liu, Ke Xu",http://arxiv.org/pdf/2412.08316v2,cs.CL
What Makes In-context Learning Effective for Mathematical Reasoning: A Theoretical Analysis,"Owing to the capability of in-context learning, large language models (LLMs)
have shown impressive performance across diverse mathematical reasoning
benchmarks. However, we find that few-shot demonstrations can sometimes bring
negative performance and their effectiveness on LLMs' reasoning abilities
remains unreliable. To this end, in this paper, we aim to theoretically analyze
the impact of in-context demonstrations on LLMs' reasoning performance. We
prove that the reasoning efficacy (measured by empirical prediction loss) can
be bounded by a LLM-oriented semantic similarity and an inference stability of
demonstrations, which is general for both one-shot and few-shot scenarios.
Based on this finding, we propose a straightforward, generalizable, and
low-complexity demonstration selection method named LMS3. It can adaptively
facilitate to select the most pertinent samples for different LLMs and includes
a novel demonstration rejection mechanism to automatically filter out samples
that are unsuitable for few-shot learning. Through experiments on three
representative benchmarks, two LLM backbones, and multiple few-shot settings,
we verify that our LMS3 has superiority and achieves consistent improvements on
all datasets, which existing methods have been unable to accomplish.",2024-12-11,"Jiayu Liu, Zhenya Huang, Chaokun Wang, Xunpeng Huang, Chengxiang Zhai, Enhong Chen",http://arxiv.org/pdf/2412.12157v1,cs.CL
Code LLMs: A Taxonomy-based Survey,"Large language models (LLMs) have demonstrated remarkable capabilities across
various NLP tasks and have recently expanded their impact to coding tasks,
bridging the gap between natural languages (NL) and programming languages (PL).
This taxonomy-based survey provides a comprehensive analysis of LLMs in the
NL-PL domain, investigating how these models are utilized in coding tasks and
examining their methodologies, architectures, and training processes. We
propose a taxonomy-based framework that categorizes relevant concepts,
providing a unified classification system to facilitate a deeper understanding
of this rapidly evolving field. This survey offers insights into the current
state and future directions of LLMs in coding tasks, including their
applications and limitations.",2024-12-11,"Nishat Raihan, Christian Newman, Marcos Zampieri",http://arxiv.org/pdf/2412.08291v1,cs.CL
Adaptive Prompting for Continual Relation Extraction: A Within-Task Variance Perspective,"To address catastrophic forgetting in Continual Relation Extraction (CRE),
many current approaches rely on memory buffers to rehearse previously learned
knowledge while acquiring new tasks. Recently, prompt-based methods have
emerged as potent alternatives to rehearsal-based strategies, demonstrating
strong empirical performance. However, upon analyzing existing prompt-based
approaches for CRE, we identified several critical limitations, such as
inaccurate prompt selection, inadequate mechanisms for mitigating forgetting in
shared parameters, and suboptimal handling of cross-task and within-task
variances. To overcome these challenges, we draw inspiration from the
relationship between prefix-tuning and mixture of experts, proposing a novel
approach that employs a prompt pool for each task, capturing variations within
each task while enhancing cross-task variances. Furthermore, we incorporate a
generative model to consolidate prior knowledge within shared parameters,
eliminating the need for explicit data storage. Extensive experiments validate
the efficacy of our approach, demonstrating superior performance over
state-of-the-art prompt-based and rehearsal-free methods in continual relation
extraction.",2024-12-11,"Minh Le, Tien Ngoc Luu, An Nguyen The, Thanh-Thien Le, Trang Nguyen, Tung Thanh Nguyen, Linh Ngo Van, Thien Huu Nguyen",http://arxiv.org/pdf/2412.08285v5,cs.CL
A Preliminary Analysis of Automatic Word and Syllable Prominence Detection in Non-Native Speech With Text-to-Speech Prosody Embeddings,"Automatic detection of prominence at the word and syllable-levels is critical
for building computer-assisted language learning systems. It has been shown
that prosody embeddings learned by the current state-of-the-art (SOTA)
text-to-speech (TTS) systems could generate word- and syllable-level prominence
in the synthesized speech as natural as in native speech. To understand the
effectiveness of prosody embeddings from TTS for prominence detection under
nonnative context, a comparative analysis is conducted on the embeddings
extracted from native and non-native speech considering the prominence-related
embeddings: duration, energy, and pitch from a SOTA TTS named FastSpeech2.
These embeddings are extracted under two conditions considering: 1) only text,
2) both speech and text. For the first condition, the embeddings are extracted
directly from the TTS inference mode, whereas for the second condition, we
propose to extract from the TTS under training mode. Experiments are conducted
on native speech corpus: Tatoeba, and non-native speech corpus: ISLE. For
experimentation, word-level prominence locations are manually annotated for
both corpora. The highest relative improvement on word \& syllable-level
prominence detection accuracies with the TTS embeddings are found to be 13.7% &
5.9% and 16.2% & 6.9% compared to those with the heuristic-based features and
self-supervised Wav2Vec-2.0 representations, respectively.",2024-12-11,"Anindita Mondal, Rangavajjala Sankara Bharadwaj, Jhansi Mallela, Anil Kumar Vuppala, Chiranjeevi Yarra",http://arxiv.org/pdf/2412.08283v1,cs.CL
Y-NQ: English-Yorùbá Evaluation dataset for Open-Book Reading Comprehension and Text Generation,"The purpose of this work is to share an English-Yor\`ub\'a evaluation dataset
for open-book reading comprehension and text generation to assess the
performance of models both in a high- and a low- resource language. The dataset
contains 358 questions and answers on 338 English documents and 208 Yor\`ub\'a
documents. The average document length is ~ 10k words for English and 430 words
for Yor\`ub\'a. Experiments show a consistent disparity in performance between
the two languages, with Yor\`ub\'a falling behind English for automatic metrics
even if documents are much shorter for this language. For a small set of
documents with comparable length, performance of Yor\`ub\'a drops by x2.5
times. When analyzing performance by length, we observe that Yor\`ub\'a
decreases performance dramatically for documents that reach 1500 words while
English performance is barely affected at that length. Our dataset opens the
door to showcasing if English LLM reading comprehension capabilities extend to
Yor\`ub\'a, which for the evaluated LLMs is not the case.",2024-12-11,"Marta R. Costa-jussà, Joy Chen, Ifeoluwanimi Adebara, Joe Chuang, Christophe Ropers, Eduardo Sánchez",http://arxiv.org/pdf/2412.08279v1,cs.CL
2M-BELEBELE: Highly Multilingual Speech and American Sign Language Comprehension Dataset,"We introduce the first highly multilingual speech and American Sign Language
(ASL) comprehension dataset by extending BELEBELE. Our dataset covers 74 spoken
languages at the intersection of BELEBELE and FLEURS, and one sign language
(ASL). We evaluate 2M-BELEBELE dataset for both 5-shot and zero-shot settings
and across languages, the speech comprehension accuracy is ~ 2-3% average lower
compared to reading comprehension.",2024-12-11,"Marta R. Costa-jussà, Bokai Yu, Pierre Andrews, Belen Alastruey, Necati Cihan Camgoz, Joe Chuang, Jean Maillard, Christophe Ropers, Arina Turkantenko, Carleigh Wood",http://arxiv.org/pdf/2412.08274v3,cs.CL
LCFO: Long Context and Long Form Output Dataset and Benchmarking,"This paper presents the Long Context and Form Output (LCFO) benchmark, a
novel evaluation framework for assessing gradual summarization and summary
expansion capabilities across diverse domains. LCFO consists of long input
documents (5k words average length), each of which comes with three summaries
of different lengths (20%, 10%, and 5% of the input text), as well as
approximately 15 questions and answers (QA) related to the input content.
Notably, LCFO also provides alignments between specific QA pairs and
corresponding summaries in 7 domains. The primary motivation behind providing
summaries of different lengths is to establish a controllable framework for
generating long texts from shorter inputs, i.e. summary expansion. To establish
an evaluation metric framework for summarization and summary expansion, we
provide human evaluation scores for human-generated outputs, as well as results
from various state-of-the-art large language models (LLMs). GPT-4o-mini
achieves best human scores among automatic systems in both summarization and
summary expansion tasks (~ +10% and +20%, respectively). It even surpasses
human output quality in the case of short summaries (~ +7%). Overall automatic
metrics achieve low correlations with human evaluation scores (~ 0.4) but
moderate correlation on specific evaluation aspects such as fluency and
attribution (~ 0.6). The LCFO benchmark offers a standardized platform for
evaluating summarization and summary expansion performance, as well as
corresponding automatic metrics, thereby providing an important evaluation
framework to advance generative AI.",2024-12-11,"Marta R. Costa-jussà, Pierre Andrews, Mariano Coria Meglioli, Joy Chen, Joe Chuang, David Dale, Christophe Ropers, Alexandre Mourachko, Eduardo Sánchez, Holger Schwenk, Tuan Tran, Arina Turkatenko, Carleigh Wood",http://arxiv.org/pdf/2412.08268v2,cs.CL
Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering,"Explainable artificial intelligence (XAI) aims to make machine learning
models more transparent. While many approaches focus on generating explanations
post-hoc, interpretable approaches, which generate the explanations
intrinsically alongside the predictions, are relatively rare. In this work, we
integrate different discrete subset sampling methods into a graph-based visual
question answering system to compare their effectiveness in generating
interpretable explanatory subgraphs intrinsically. We evaluate the methods on
the GQA dataset and show that the integrated methods effectively mitigate the
performance trade-off between interpretability and answer accuracy, while also
achieving strong co-occurrences between answer and question tokens.
Furthermore, we conduct a human evaluation to assess the interpretability of
the generated subgraphs using a comparative setting with the extended
Bradley-Terry model, showing that the answer and question token co-occurrence
metrics strongly correlate with human preferences. Our source code is publicly
available.",2024-12-11,"Pascal Tilli, Ngoc Thang Vu",http://arxiv.org/pdf/2412.08263v1,cs.CL
Accurate Medical Named Entity Recognition Through Specialized NLP Models,"This study evaluated the effect of BioBERT in medical text processing for the
task of medical named entity recognition. Through comparative experiments with
models such as BERT, ClinicalBERT, SciBERT, and BlueBERT, the results showed
that BioBERT achieved the best performance in both precision and F1 score,
verifying its applicability and superiority in the medical field. BioBERT
enhances its ability to understand professional terms and complex medical texts
through pre-training on biomedical data, providing a powerful tool for medical
information extraction and clinical decision support. The study also explored
the privacy and compliance challenges of BioBERT when processing medical data,
and proposed future research directions for combining other medical-specific
models to improve generalization and robustness. With the development of deep
learning technology, the potential of BioBERT in application fields such as
intelligent medicine, personalized treatment, and disease prediction will be
further expanded. Future research can focus on the real-time and
interpretability of the model to promote its widespread application in the
medical field.",2024-12-11,"Jiacheng Hu, Runyuan Bao, Yang Lin, Hanchao Zhang, Yanlin Xiang",http://arxiv.org/pdf/2412.08255v1,cs.CL
TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch,"It is well known that LLM-based systems are data-hungry. Recent LLM-based TTS
works typically employ complex data processing pipelines to obtain high-quality
training data. These sophisticated pipelines require excellent models at each
stage (e.g., speech denoising, speech enhancement, speaker diarization, and
punctuation models), which themselves demand high-quality training data and are
rarely open-sourced. Even with state-of-the-art models, issues persist, such as
incomplete background noise removal and misalignment between punctuation and
actual speech pauses. Moreover, the stringent filtering strategies often retain
only 10-30\% of the original data, significantly impeding data scaling efforts.
In this work, we leverage a noise-robust audio tokenizer (S3Tokenizer) to
design a simplified yet effective TTS data processing pipeline that maintains
data quality while substantially reducing data acquisition costs, achieving a
data retention rate of over 50\%. Beyond data scaling challenges, LLM-based TTS
systems also incur higher deployment costs compared to conventional approaches.
Current systems typically use LLMs solely for text-to-token generation, while
requiring separate models (e.g., flow matching models) for token-to-waveform
generation, which cannot be directly executed by LLM inference engines, further
complicating deployment. To address these challenges, we eliminate redundant
modules in both LLM and flow components, replacing the flow model backbone with
an LLM architecture. Building upon this simplified flow backbone, we propose a
unified architecture for both streaming and non-streaming inference,
significantly reducing deployment costs. Finally, we explore the feasibility of
unifying TTS and ASR tasks using the same data for training, thanks to the
simplified pipeline and the S3Tokenizer that reduces the quality requirements
for TTS training data.",2024-12-11,"Xingchen Song, Mengtao Xing, Changwei Ma, Shengqiang Li, Di Wu, Binbin Zhang, Fuping Pan, Dinghao Zhou, Yuekai Zhang, Shun Lei, Zhendong Peng, Zhiyong Wu",http://arxiv.org/pdf/2412.08237v2,cs.CL
DocSum: Domain-Adaptive Pre-training for Document Abstractive Summarization,"Abstractive summarization has made significant strides in condensing and
rephrasing large volumes of text into coherent summaries. However, summarizing
administrative documents presents unique challenges due to domain-specific
terminology, OCR-generated errors, and the scarcity of annotated datasets for
model fine-tuning. Existing models often struggle to adapt to the intricate
structure and specialized content of such documents. To address these
limitations, we introduce DocSum, a domain-adaptive abstractive summarization
framework tailored for administrative documents. Leveraging pre-training on
OCR-transcribed text and fine-tuning with an innovative integration of
question-answer pairs, DocSum enhances summary accuracy and relevance. This
approach tackles the complexities inherent in administrative content, ensuring
outputs that align with real-world business needs. To evaluate its
capabilities, we define a novel downstream task setting-Document Abstractive
Summarization-which reflects the practical requirements of business and
organizational settings. Comprehensive experiments demonstrate DocSum's
effectiveness in producing high-quality summaries, showcasing its potential to
improve decision-making and operational workflows across the public and private
sectors.",2024-12-11,"Phan Phuong Mai Chau, Souhail Bakkali, Antoine Doucet",http://arxiv.org/pdf/2412.08196v1,cs.CL
From communities to interpretable network and word embedding: an unified approach,"Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.",2024-12-11,"Thibault Prouteau, Nicolas Dugué, Simon Guillot",http://arxiv.org/pdf/2412.08187v1,cs.CL
PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection,"Outlier detection (OD), also known as anomaly detection, is a critical
machine learning (ML) task with applications in fraud detection, network
intrusion detection, clickstream analysis, recommendation systems, and social
network moderation. Among open-source libraries for outlier detection, the
Python Outlier Detection (PyOD) library is the most widely adopted, with over
8,500 GitHub stars, 25 million downloads, and diverse industry usage. However,
PyOD currently faces three limitations: (1) insufficient coverage of modern
deep learning algorithms, (2) fragmented implementations across PyTorch and
TensorFlow, and (3) no automated model selection, making it hard for
non-experts.
  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates
12 state-of-the-art deep learning models into a unified PyTorch framework and
introduces a large language model (LLM)-based pipeline for automated OD model
selection. These improvements simplify OD workflows, provide access to 45
algorithms, and deliver robust performance on various datasets. In this paper,
we demonstrate how PyOD 2 streamlines the deployment and automation of OD
models and sets a new standard in both research and industry. PyOD 2 is
accessible at
[https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This
study aligns with the Web Mining and Content Analysis track, addressing topics
such as the robustness of Web mining methods and the quality of
algorithmically-generated Web data.",2024-12-11,"Sihan Chen, Zhuangzhuang Qian, Wingchun Siu, Xingcan Hu, Jiaqi Li, Shawn Li, Yuehan Qin, Tiankai Yang, Zhuo Xiao, Wanghao Ye, Yichi Zhang, Yushun Dong, Yue Zhao",http://arxiv.org/pdf/2412.12154v1,cs.CL
Illusory VQA: Benchmarking and Enhancing Multimodal Models on Visual Illusions,"In recent years, Visual Question Answering (VQA) has made significant
strides, particularly with the advent of multimodal models that integrate
vision and language understanding. However, existing VQA datasets often
overlook the complexities introduced by image illusions, which pose unique
challenges for both human perception and model interpretation. In this study,
we introduce a novel task called Illusory VQA, along with four specialized
datasets: IllusionMNIST, IllusionFashionMNIST, IllusionAnimals, and
IllusionChar. These datasets are designed to evaluate the performance of
state-of-the-art multimodal models in recognizing and interpreting visual
illusions. We assess the zero-shot performance of various models, fine-tune
selected models on our datasets, and propose a simple yet effective solution
for illusion detection using Gaussian and blur low-pass filters. We show that
this method increases the performance of models significantly and in the case
of BLIP-2 on IllusionAnimals without any fine-tuning, it outperforms humans.
Our findings highlight the disparity between human and model perception of
illusions and demonstrate that fine-tuning and specific preprocessing
techniques can significantly enhance model robustness. This work contributes to
the development of more human-like visual understanding in multimodal models
and suggests future directions for adapting filters using learnable parameters.",2024-12-11,"Mohammadmostafa Rostamkhani, Baktash Ansari, Hoorieh Sabzevari, Farzan Rahmani, Sauleh Eetemadi",http://arxiv.org/pdf/2412.08169v1,cs.CL
NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech Detection using Ensembling of BERT-based models,"This paper explores hate speech detection in Devanagari-scripted languages,
focusing on Hindi and Nepali, for Subtask B of the CHIPSAL@COLING 2025 Shared
Task. Using a range of transformer-based models such as XLM-RoBERTa, MURIL, and
IndicBERT, we examine their effectiveness in navigating the nuanced boundary
between hate speech and free expression. Our best performing model, implemented
as ensemble of multilingual BERT models achieve Recall of 0.7762 (Rank 3/31 in
terms of recall) and F1 score of 0.6914 (Rank 17/31). To address class
imbalance, we used backtranslation for data augmentation, and cosine similarity
to preserve label consistency after augmentation. This work emphasizes the need
for hate speech detection in Devanagari-scripted languages and presents a
foundation for further research.",2024-12-11,"Anmol Guragain, Nadika Poudel, Rajesh Piryani, Bishesh Khanal",http://arxiv.org/pdf/2412.08163v2,cs.CL
How Vision-Language Tasks Benefit from Large Pre-trained Models: A Survey,"The exploration of various vision-language tasks, such as visual captioning,
visual question answering, and visual commonsense reasoning, is an important
area in artificial intelligence and continuously attracts the research
community's attention. Despite the improvements in overall performance, classic
challenges still exist in vision-language tasks and hinder the development of
this area. In recent years, the rise of pre-trained models is driving the
research on vision-language tasks. Thanks to the massive scale of training data
and model parameters, pre-trained models have exhibited excellent performance
in numerous downstream tasks. Inspired by the powerful capabilities of
pre-trained models, new paradigms have emerged to solve the classic challenges.
Such methods have become mainstream in current research with increasing
attention and rapid advances. In this paper, we present a comprehensive
overview of how vision-language tasks benefit from pre-trained models. First,
we review several main challenges in vision-language tasks and discuss the
limitations of previous solutions before the era of pre-training. Next, we
summarize the recent advances in incorporating pre-trained models to address
the challenges in vision-language tasks. Finally, we analyze the potential
risks associated with the inherent limitations of pre-trained models and
discuss possible solutions, attempting to provide future research directions.",2024-12-11,"Yayun Qi, Hongxi Li, Yiqi Song, Xinxiao Wu, Jiebo Luo",http://arxiv.org/pdf/2412.08158v1,cs.CL
Decoding Poultry Vocalizations -- Natural Language Processing and Transformer Models for Semantic and Emotional Analysis,"Deciphering the acoustic language of chickens offers new opportunities in
animal welfare and ecological informatics. Their subtle vocal signals encode
health conditions, emotional states, and dynamic interactions within
ecosystems. Understanding the semantics of these calls provides a valuable tool
for interpreting their functional vocabulary and clarifying how each sound
serves a specific purpose in social and environmental contexts. We apply
advanced Natural Language Processing and transformer based models to translate
bioacoustic data into meaningful insights. Our method integrates Wave2Vec 2.0
for raw audio feature extraction with a fine tuned Bidirectional Encoder
Representations from Transformers model, pretrained on a broad corpus of animal
sounds and adapted to poultry tasks. This pipeline decodes poultry
vocalizations into interpretable categories including distress calls, feeding
signals, and mating vocalizations, revealing emotional nuances often overlooked
by conventional analyses. Achieving 92 percent accuracy in classifying key
vocalization types, our approach demonstrates the feasibility of real time
automated monitoring of flock health and stress. By tracking this functional
vocabulary, farmers can respond proactively to environmental or behavioral
changes, improving poultry welfare, reducing stress related productivity
losses, and supporting more sustainable farm management. Beyond agriculture,
this research enhances our understanding of computational ecology. Accessing
the semantic foundation of animal calls may indicate biodiversity,
environmental stressors, and species interactions, informing integrative
ecosystem level decision making.",2024-12-11,"Venkatraman Manikandan, Suresh Neethirajan",http://arxiv.org/pdf/2412.16182v1,cs.CL
Evil twins are not that evil: Qualitative insights into machine-generated prompts,"It has been widely observed that language models (LMs) respond in predictable
ways to algorithmically generated prompts that are seemingly unintelligible.
This is both a sign that we lack a full understanding of how LMs work, and a
practical challenge, because opaqueness can be exploited for harmful uses of
LMs, such as jailbreaking. We present the first thorough analysis of opaque
machine-generated prompts, or autoprompts, pertaining to 6 LMs of different
sizes and families. We find that machine-generated prompts are characterized by
a last token that is often intelligible and strongly affects the generation. A
small but consistent proportion of the previous tokens are prunable, probably
appearing in the prompt as a by-product of the fact that the optimization
process fixes the number of tokens. The remaining tokens fall into two
categories: filler tokens, which can be replaced with semantically unrelated
substitutes, and keywords, that tend to have at least a loose semantic relation
with the generation, although they do not engage in well-formed syntactic
relations with it. Additionally, human experts can reliably identify the most
influential tokens in an autoprompt a posteriori, suggesting these prompts are
not entirely opaque. Finally, some of the ablations we applied to autoprompts
yield similar effects in natural language inputs, suggesting that autoprompts
emerge naturally from the way LMs process linguistic inputs in general.",2024-12-11,"Nathanaël Carraz Rakotonirina, Corentin Kervadec, Francesca Franzon, Marco Baroni",http://arxiv.org/pdf/2412.08127v3,cs.CL
Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models,"Existing Large Vision-Language Models (LVLMs) excel at matching concepts
across multi-modal inputs but struggle with compositional concepts and
high-level relationships between entities. This paper introduces Progressive
multi-granular Vision-Language alignments (PromViL), a novel framework to
enhance LVLMs' ability in performing grounded compositional visual reasoning
tasks. Our approach constructs a hierarchical structure of multi-modal
alignments, ranging from simple to complex concepts. By progressively aligning
textual descriptions with corresponding visual regions, our model learns to
leverage contextual information from lower levels to inform higher-level
reasoning. To facilitate this learning process, we introduce a data generation
process that creates a novel dataset derived from Visual Genome, providing a
wide range of nested compositional vision-language pairs. Experimental results
demonstrate that our PromViL framework significantly outperforms baselines on
various visual grounding and compositional question answering tasks. The code
is available at: https://github.com/lqh52/PromViL.",2024-12-11,"Quang-Hung Le, Long Hoang Dang, Ngan Le, Truyen Tran, Thao Minh Le",http://arxiv.org/pdf/2412.08125v2,cs.CL
LatentSpeech: Latent Diffusion for Text-To-Speech Generation,"Diffusion-based Generative AI gains significant attention for its superior
performance over other generative techniques like Generative Adversarial
Networks and Variational Autoencoders. While it has achieved notable
advancements in fields such as computer vision and natural language processing,
their application in speech generation remains under-explored. Mainstream
Text-to-Speech systems primarily map outputs to Mel-Spectrograms in the
spectral space, leading to high computational loads due to the sparsity of
MelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS
generation approach utilizing latent diffusion models. By using latent
embeddings as the intermediate representation, LatentSpeech reduces the target
dimension to 5% of what is required for MelSpecs, simplifying the processing
for the TTS encoder and vocoder and enabling efficient high-quality speech
generation. This study marks the first integration of latent diffusion models
in TTS, enhancing the accuracy and naturalness of generated speech.
Experimental results on benchmark datasets demonstrate that LatentSpeech
achieves a 25% improvement in Word Error Rate and a 24% improvement in Mel
Cepstral Distortion compared to existing models, with further improvements
rising to 49.5% and 26%, respectively, with additional training data. These
findings highlight the potential of LatentSpeech to advance the
state-of-the-art in TTS technology",2024-12-11,"Haowei Lou, Helen Paik, Pari Delir Haghighi, Wen Hu, Lina Yao",http://arxiv.org/pdf/2412.08117v1,cs.CL
Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration,"Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and
StyleSpeech, have significantly improved speech generation quality. However,
these models often rely on duration generated by external tools like the
Montreal Forced Aligner, which can be time-consuming and lack flexibility. The
importance of accurate duration is often underestimated, despite their crucial
role in achieving natural prosody and intelligibility. To address these
limitations, we propose a novel Aligner-Guided Training Paradigm that
prioritizes accurate duration labelling by training an aligner before the TTS
model. This approach reduces dependence on external tools and enhances
alignment accuracy. We further explore the impact of different acoustic
features, including Mel-Spectrograms, MFCCs, and latent features, on TTS model
performance. Our experimental results show that aligner-guided duration
labelling can achieve up to a 16\% improvement in word error rate and
significantly enhance phoneme and tone alignment. These findings highlight the
effectiveness of our approach in optimizing TTS systems for more natural and
intelligible speech generation.",2024-12-11,"Haowei Lou, Helen Paik, Wen Hu, Lina Yao",http://arxiv.org/pdf/2412.08112v1,cs.CL
Seeing Syntax: Uncovering Syntactic Learning Limitations in Vision-Language Models,"Vision-language models (VLMs), serve as foundation models for multi-modal
applications such as image captioning and text-to-image generation. Recent
studies have highlighted limitations in VLM text encoders, particularly in
areas like compositionality and semantic understanding, though the underlying
reasons for these limitations remain unclear. In this work, we aim to address
this gap by analyzing the syntactic information, one of the fundamental
linguistic properties, encoded by the text encoders of VLMs. We perform a
thorough analysis comparing VLMs with different objective functions, parameter
size and training data size, and with uni-modal language models (ULMs) in their
ability to encode syntactic knowledge. Our findings suggest that ULM text
encoders acquire syntactic information more effectively than those in VLMs. The
syntactic information learned by VLM text encoders is shaped primarily by the
pre-training objective, which plays a more crucial role than other factors such
as model architecture, model size, or the volume of pre-training data. Models
exhibit different layer-wise trends where CLIP performance dropped across
layers while for other models, middle layers are rich in encoding syntactic
knowledge.",2024-12-11,"Sri Harsha Dumpala, David Arps, Sageev Oore, Laura Kallmeyer, Hassan Sajjad",http://arxiv.org/pdf/2412.08111v1,cs.CL
Barking Up The Syntactic Tree: Enhancing VLM Training with Syntactic Losses,"Vision-Language Models (VLMs) implicitly learn to associate image regions
with words from large-scale training data, demonstrating an emergent capability
for grounding concepts without dense annotations[14,18,51]. However, the
coarse-grained supervision from image-caption pairs is often insufficient to
resolve ambiguities in object-concept correspondence, even with enormous data
volume. Rich semantic and syntactic structures within the text modality have
been overlooked as sources of supervision. Starting from contrastive
architectures (BLIP and ALBEF) that show strong intrinsic grounding abilities,
we propose HIerarchically STructured Learning (HIST). HIST enhances spatial
vision-language alignment without using additional human annotations, by
hierarchically decomposing captions into the constituent Subjects, Phrases, and
Composite Phrases, and enforcing entailment relation between a parent and its
children in the hierarchy. Specifically, we introduce two novel loss functions:
(1) Subject Loss, which aligns image content with the subject of the
corresponding phrase, acting as an entailment of standard contrastive/matching
losses at the Phrase level; (2) Composition Loss, to balance attention across
multiple objects. HIST is general, and can be applied to any VLM for which
attention between vision and language can be computed. Compared to baseline
VLMs, HIST achieves up to +9.8% improvement in visual grounding and +6.3% in
multi-object referring segmentation. Surprisingly, the improved spatial
grounding leads to improvements in other downstream VLM tasks: +1.1% in
image-text retrieval, and +0.2% in visual question answering.",2024-12-11,"Jiayun Luo, Mir Rayat Imtiaz Hossain, Boyang Li, Leonid Sigal",http://arxiv.org/pdf/2412.08110v2,cs.CL
Rethinking Comprehensive Benchmark for Chart Understanding: A Perspective from Scientific Literature,"Scientific Literature charts often contain complex visual elements, including
multi-plot figures, flowcharts, structural diagrams and etc. Evaluating
multimodal models using these authentic and intricate charts provides a more
accurate assessment of their understanding abilities. However, existing
benchmarks face limitations: a narrow range of chart types, overly simplistic
template-based questions and visual elements, and inadequate evaluation
methods. These shortcomings lead to inflated performance scores that fail to
hold up when models encounter real-world scientific charts. To address these
challenges, we introduce a new benchmark, Scientific Chart QA (SCI-CQA), which
emphasizes flowcharts as a critical yet often overlooked category. To overcome
the limitations of chart variety and simplistic visual elements, we curated a
dataset of 202,760 image-text pairs from 15 top-tier computer science
conferences papers over the past decade. After rigorous filtering, we refined
this to 37,607 high-quality charts with contextual information. SCI-CQA also
introduces a novel evaluation framework inspired by human exams, encompassing
5,629 carefully curated questions, both objective and open-ended. Additionally,
we propose an efficient annotation pipeline that significantly reduces data
annotation costs. Finally, we explore context-based chart understanding,
highlighting the crucial role of contextual information in solving previously
unanswerable questions.",2024-12-11,"Lingdong Shen, Qigqi, Kun Ding, Gaofeng Meng, Shiming Xiang",http://arxiv.org/pdf/2412.12150v1,cs.CL
Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation,"Large Vision-Language Models (VLMs) have demonstrated remarkable performance
across multimodal tasks by integrating vision encoders with large language
models (LLMs). However, these models remain vulnerable to adversarial attacks.
Among such attacks, Universal Adversarial Perturbations (UAPs) are especially
powerful, as a single optimized perturbation can mislead the model across
various input images. In this work, we introduce a novel UAP specifically
designed for VLMs: the Doubly-Universal Adversarial Perturbation (Doubly-UAP),
capable of universally deceiving VLMs across both image and text inputs. To
successfully disrupt the vision encoder's fundamental process, we analyze the
core components of the attention mechanism. After identifying value vectors in
the middle-to-late layers as the most vulnerable, we optimize Doubly-UAP in a
label-free manner with a frozen model. Despite being developed as a black-box
to the LLM, Doubly-UAP achieves high attack success rates on VLMs, consistently
outperforming baseline methods across vision-language tasks. Extensive ablation
studies and analyses further demonstrate the robustness of Doubly-UAP and
provide insights into how it influences internal attention mechanisms.",2024-12-11,"Hee-Seon Kim, Minbeom Kim, Changick Kim",http://arxiv.org/pdf/2412.08108v2,cs.CL
Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting,"Large Language Models (LLMs) have recently demonstrated significant potential
in time series forecasting, offering impressive capabilities in handling
complex temporal data. However, their robustness and reliability in real-world
applications remain under-explored, particularly concerning their
susceptibility to adversarial attacks. In this paper, we introduce a targeted
adversarial attack framework for LLM-based time series forecasting. By
employing both gradient-free and black-box optimization methods, we generate
minimal yet highly effective perturbations that significantly degrade the
forecasting accuracy across multiple datasets and LLM architectures. Our
experiments, which include models like LLMTime with GPT-3.5, GPT-4, LLaMa, and
Mistral, TimeGPT, and TimeLLM show that adversarial attacks lead to much more
severe performance degradation than random noise, and demonstrate the broad
effectiveness of our attacks across different LLMs. The results underscore the
critical vulnerabilities of LLMs in time series forecasting, highlighting the
need for robust defense mechanisms to ensure their reliable deployment in
practical applications. The code repository can be found at
https://github.com/JohnsonJiang1996/AdvAttack_LLM4TS.",2024-12-11,"Fuqiang Liu, Sicong Jiang, Luis Miranda-Moreno, Seongjin Choi, Lijun Sun",http://arxiv.org/pdf/2412.08099v4,cs.CL
Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages,"The unwavering disparity in labeled resources between resource-rich languages
and those considered low-resource remains a significant impediment for Large
Language Models (LLMs). Recent strides in cross-lingual in-context learning
(X-ICL), mainly through semantically aligned examples retrieved from
multilingual pre-trained transformers, have shown promise in mitigating this
issue. However, our investigation reveals that LLMs intrinsically reward
in-language semantically aligned cross-lingual instances over direct
cross-lingual semantic alignments, with a pronounced disparity in handling
time-sensitive queries in the X-ICL setup. Such queries demand sound temporal
reasoning ability from LLMs, yet the advancements have predominantly focused on
English. This study aims to bridge this gap by improving temporal reasoning
capabilities in low-resource languages. To this end, we introduce mTEMPREASON,
a temporal reasoning dataset aimed at the varied degrees of low-resource
languages and propose Cross-Lingual Time-Sensitive Semantic Alignment
(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To
facilitate this, we construct an extension of mTEMPREASON comprising pairs of
parallel cross-language temporal queries along with their anticipated
in-language semantic similarity scores. Our empirical evidence underscores the
superior performance of CLiTSSA compared to established baselines across three
languages -- Romanian, German, and French, encompassing three temporal tasks
and including a diverse set of four contemporaneous LLMs. This marks a
significant step forward in addressing resource disparity in the context of
temporal reasoning across languages.",2024-12-11,"Ashutosh Bajpai, Tanmoy Chakraborty",http://arxiv.org/pdf/2412.08090v2,cs.CL
NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language,"The emergence of Large Language Models (LLMs) has revolutionized many fields,
not only traditional natural language processing (NLP) tasks. Recently,
research on applying LLMs to the database field has been booming, and as a
typical non-relational database, the use of LLMs in graph database research has
naturally gained significant attention. Recent efforts have increasingly
focused on leveraging LLMs to translate natural language into graph query
language (NL2GQL). Although some progress has been made, these methods have
clear limitations, such as their reliance on streamlined processes that often
overlook the potential of LLMs to autonomously plan and collaborate with other
LLMs in tackling complex NL2GQL challenges. To address this gap, we propose
NAT-NL2GQL, a novel multi-agent framework for translating natural language to
graph query language. Specifically, our framework consists of three synergistic
agents: the Preprocessor agent, the Generator agent, and the Refiner agent. The
Preprocessor agent manages data processing as context, including tasks such as
name entity recognition, query rewriting, path linking, and the extraction of
query-related schemas. The Generator agent is a fine-tuned LLM trained on
NL-GQL data, responsible for generating corresponding GQL statements based on
queries and their related schemas. The Refiner agent is tasked with refining
the GQL or context using error information obtained from the GQL execution
results. Given the scarcity of high-quality open-source NL2GQL datasets based
on nGQL syntax, we developed StockGQL, a dataset constructed from a financial
market graph database. It is available at:
https://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL
and SpCQL datasets reveal that our method significantly outperforms baseline
approaches, highlighting its potential for advancing NL2GQL research.",2024-12-11,"Yuanyuan Liang, Tingyu Xie, Gan Peng, Zihao Huang, Yunshi Lan, Weining Qian",http://arxiv.org/pdf/2412.10434v1,cs.CL
Imitate Before Detect: Aligning Machine Stylistic Preference for Machine-Revised Text Detection,"Large Language Models (LLMs) have revolutionized text generation, making
detecting machine-generated text increasingly challenging. Although past
methods have achieved good performance on detecting pure machine-generated
text, those detectors have poor performance on distinguishing machine-revised
text (rewriting, expansion, and polishing), which can have only minor changes
from its original human prompt. As the content of text may originate from human
prompts, detecting machine-revised text often involves identifying distinctive
machine styles, e.g., worded favored by LLMs. However, existing methods
struggle to detect machine-style phrasing hidden within the content contributed
by humans. We propose the ""Imitate Before Detect"" (ImBD) approach, which first
imitates the machine-style token distribution, and then compares the
distribution of the text to be tested with the machine-style distribution to
determine whether the text has been machine-revised. To this end, we introduce
style preference optimization (SPO), which aligns a scoring LLM model to the
preference of text styles generated by machines. The aligned scoring model is
then used to calculate the style-conditional probability curvature (Style-CPC),
quantifying the log probability difference between the original and
conditionally sampled texts for effective detection. We conduct extensive
comparisons across various scenarios, encompassing text revisions by six LLMs,
four distinct text domains, and three machine revision types. Compared to
existing state-of-the-art methods, our method yields a 13% increase in AUC for
detecting text revised by open-source LLMs, and improves performance by 5% and
19% for detecting GPT-3.5 and GPT-4o revised text, respectively. Notably, our
method surpasses the commercially trained GPT-Zero with just $1,000$ samples
and five minutes of SPO, demonstrating its efficiency and effectiveness.",2024-12-11,"Jiaqi Chen, Xiaoye Zhu, Tianyang Liu, Ying Chen, Xinhui Chen, Yiwen Yuan, Chak Tou Leong, Zuchao Li, Tang Long, Lei Zhang, Chenyu Yan, Guanghao Mei, Jie Zhang, Lefei Zhang",http://arxiv.org/pdf/2412.10432v2,cs.CL
Federated In-Context LLM Agent Learning,"Large Language Models (LLMs) have revolutionized intelligent services by
enabling logical reasoning, tool use, and interaction with external systems as
agents. The advancement of LLMs is frequently hindered by the scarcity of
high-quality data, much of which is inherently sensitive. Federated learning
(FL) offers a potential solution by facilitating the collaborative training of
distributed LLMs while safeguarding private data. However, FL frameworks face
significant bandwidth and computational demands, along with challenges from
heterogeneous data distributions. The emerging in-context learning capability
of LLMs offers a promising approach by aggregating natural language rather than
bulky model parameters. Yet, this method risks privacy leakage, as it
necessitates the collection and presentation of data samples from various
clients during aggregation. In this paper, we propose a novel
privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,
which to our best knowledge for the first work unleashes the power of
in-context learning to train diverse LLM agents through FL. In our design,
knowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums
Generation (KCG) module are transmitted between clients and the server instead
of model parameters in previous FL methods. Apart from that, an incredible
Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)
module is designed and we incorporate the aggregated global knowledge
compendium as a teacher to teach LLM agents the usage of tools. We conducted
extensive experiments and the results show that FICAL has competitive
performance compared to other SOTA baselines with a significant communication
cost decrease of $\mathbf{3.33\times10^5}$ times.",2024-12-11,"Panlong Wu, Kangshuo Li, Junbao Nan, Fangxin Wang",http://arxiv.org/pdf/2412.08054v1,cs.CL
EmoVerse: Exploring Multimodal Large Language Models for Sentiment and Emotion Understanding,"Sentiment and emotion understanding are essential to applications such as
human-computer interaction and depression detection. While Multimodal Large
Language Models (MLLMs) demonstrate robust general capabilities, they face
considerable challenges in the field of affective computing, particularly in
detecting subtle facial expressions and handling complex emotion-related tasks,
such as emotion reason inference and understanding emotions in long-context
scenarios. Furthermore, there is a lack of a unified MLLM that can effectively
handle both sentiment and emotion-related tasks. To address these challenges,
we explore multi-task training strategies for MLLMs in affective computing and
introduce Emotion Universe (EmoVerse), an MLLM designed to handle a broad
spectrum of sentiment and emotion-related tasks. In addition, EmoVerse is
capable of deeply analyzing the underlying causes of emotional states. We also
introduce the Affective Multitask (AMT) Dataset, which supports multimodal
sentiment analysis, multimodal emotion recognition, facial expression
recognition, emotion reason inference, and emotion cause-pair extraction tasks.
Extensive experiments demonstrate that EmoVerse outperforms existing methods,
achieving state-of-the-art results in sentiment and emotion-related tasks. The
code is available at https://github.com/liaolea/EmoVerse.",2024-12-11,"Ao Li, Longwei Xu, Chen Ling, Jinghui Zhang, Pengwei Wang",http://arxiv.org/pdf/2412.08049v3,cs.CL
Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach,"Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.",2024-12-11,"Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu",http://arxiv.org/pdf/2412.08038v3,cs.CL
TinyThinker: Distilling Reasoning through Coarse-to-Fine Knowledge Internalization with Self-Reflection,"Large Language Models exhibit impressive reasoning capabilities across
diverse tasks, motivating efforts to distill these capabilities into smaller
models through generated reasoning data. However, direct training on such
synthesized reasoning data may lead to superficial imitation of reasoning
process, rather than fostering a genuine integration of reasoning capabilities
with underlying knowledge. To address this, we propose TinyThinker, a framework
introducing two novel approaches. First, we introduce a three-stage process
that incrementally guides the student model through the reasoning process,
progressively refining knowledge from coarse to fine granularity. Second, we
develop a two-phase training framework comprising an initial reasoning
acquisition phase followed by a self-reflection phase utilizing self-generated
data. Experiments on commonsense reasoning benchmarks demonstrate that
TinyThinker achieves superior performance compared to baselines. Ablation
studies further validate the effectiveness of each component in our framework.
We expect that TinyThinker can be extended to other knowledge-intensive
reasoning tasks, offering an alternative strategy for developing effective
reasoning capabilities in smaller language models. Codes are available at
https://github.com/shengminp/TinyThinker",2024-12-11,"Shengmin Piao, Sanghyun Park",http://arxiv.org/pdf/2412.08024v2,cs.CL
Concept Bottleneck Large Language Models,"We introduce Concept Bottleneck Large Language Models (CB-LLMs), a novel
framework for building inherently interpretable Large Language Models (LLMs).
In contrast to traditional black-box LLMs that rely on limited post-hoc
interpretations, CB-LLMs integrate intrinsic interpretability directly into the
LLMs -- allowing accurate explanations with scalability and transparency. We
build CB-LLMs for two essential NLP tasks: text classification and text
generation. In text classification, CB-LLMs is competitive with, and at times
outperforms, traditional black-box models while providing explicit and
interpretable reasoning. For the more challenging task of text generation,
interpretable neurons in CB-LLMs enable precise concept detection, controlled
generation, and safer outputs. The embedded interpretability empowers users to
transparently identify harmful content, steer model behavior, and unlearn
undesired concepts -- significantly enhancing the safety, reliability, and
trustworthiness of LLMs, which are critical capabilities notably absent in
existing models. Our code is available at
https://github.com/Trustworthy-ML-Lab/CB-LLMs.",2024-12-11,"Chung-En Sun, Tuomas Oikarinen, Berk Ustun, Tsui-Wei Weng",http://arxiv.org/pdf/2412.07992v3,cs.CL
Observing Micromotives and Macrobehavior of Large Language Models,"Thomas C. Schelling, awarded the 2005 Nobel Memorial Prize in Economic
Sciences, pointed out that ``individuals decisions (micromotives), while often
personal and localized, can lead to societal outcomes (macrobehavior) that are
far more complex and different from what the individuals intended.'' The
current research related to large language models' (LLMs') micromotives, such
as preferences or biases, assumes that users will make more appropriate
decisions once LLMs are devoid of preferences or biases. Consequently, a series
of studies has focused on removing bias from LLMs. In the NLP community, while
there are many discussions on LLMs' micromotives, previous studies have seldom
conducted a systematic examination of how LLMs may influence society's
macrobehavior. In this paper, we follow the design of Schelling's model of
segregation to observe the relationship between the micromotives and
macrobehavior of LLMs. Our results indicate that, regardless of the level of
bias in LLMs, a highly segregated society will emerge as more people follow
LLMs' suggestions. We hope our discussion will spark further consideration of
the fundamental assumption regarding the mitigation of LLMs' micromotives and
encourage a reevaluation of how LLMs may influence users and society.",2024-12-10,"Yuyang Cheng, Xingwei Qu, Tomas Goldsack, Chenghua Lin, Chung-Chi Chen",http://arxiv.org/pdf/2412.10428v1,cs.CL
Machines of Meaning,"One goal of Artificial Intelligence is to learn meaningful representations
for natural language expressions, but what this entails is not always clear. A
variety of new linguistic behaviours present themselves embodied as computers,
enhanced humans, and collectives with various kinds of integration and
communication. But to measure and understand the behaviours generated by such
systems, we must clarify the language we use to talk about them. Computational
models are often confused with the phenomena they try to model and shallow
metaphors are used as justifications for (or to hype) the success of
computational techniques on many tasks related to natural language; thus
implying their progress toward human-level machine intelligence without ever
clarifying what that means.
  This paper discusses the challenges in the specification of ""machines of
meaning"", machines capable of acquiring meaningful semantics from natural
language in order to achieve their goals. We characterize ""meaning"" in a
computational setting, while highlighting the need for detachment from
anthropocentrism in the study of the behaviour of machines of meaning. The
pressing need to analyse AI risks and ethics requires a proper measurement of
its capabilities which cannot be productively studied and explained while using
ambiguous language. We propose a view of ""meaning"" to facilitate the discourse
around approaches such as neural language models and help broaden the research
perspectives for technology that facilitates dialogues between humans and
machines.",2024-12-10,"Davide Nunes, Luis Antunes",http://arxiv.org/pdf/2412.07975v1,cs.CL
Identifying and Manipulating Personality Traits in LLMs Through Activation Engineering,"The field of large language models (LLMs) has grown rapidly in recent years,
driven by the desire for better efficiency, interpretability, and safe use.
Building on the novel approach of ""activation engineering,"" this study explores
personality modification in LLMs, drawing inspiration from research like
Refusal in LLMs Is Mediated by a Single Direction (arXiv:2406.11717) and
Steering Llama 2 via Contrastive Activation Addition (arXiv:2312.06681). We
leverage activation engineering to develop a method for identifying and
adjusting activation directions related to personality traits, which may allow
for dynamic LLM personality fine-tuning. This work aims to further our
understanding of LLM interpretability while examining the ethical implications
of such developments.",2024-12-10,"Rumi A. Allbert, James K. Wiles, Vlad Grankovsky",http://arxiv.org/pdf/2412.10427v2,cs.CL
HalluCana: Fixing LLM Hallucination with A Canary Lookahead,"In this paper, we present HalluCana, a canary lookahead to detect and correct
factuality hallucinations of Large Language Models (LLMs) in long-form
generation. HalluCana detects and intervenes as soon as traces of hallucination
emerge, during and even before generation. To support timely detection, we
exploit the internal factuality representation in the LLM hidden space, where
we investigate various proxies to the LLMs' factuality self-assessment, and
discuss its relation to the models' context familiarity from their
pre-training. On biography generation, our method improves generation quality
by up to 2.5x, while consuming over 6 times less compute.",2024-12-10,"Tianyi Li, Erenay Dayanik, Shubhi Tyagi, Andrea Pierleoni",http://arxiv.org/pdf/2412.07965v1,cs.CL
Forking Paths in Neural Text Generation,"Estimating uncertainty in Large Language Models (LLMs) is important for
properly evaluating LLMs, and ensuring safety for users. However, prior
approaches to uncertainty estimation focus on the final answer in generated
text, ignoring intermediate steps that might dramatically impact the outcome.
We hypothesize that there exist key forking tokens, such that re-sampling the
system at those specific tokens, but not others, leads to very different
outcomes. To test this empirically, we develop a novel approach to representing
uncertainty dynamics across individual tokens of text generation, and applying
statistical models to test our hypothesis. Our approach is highly flexible: it
can be applied to any dataset and any LLM, without fine tuning or accessing
model weights. We use our method to analyze LLM responses on 7 different tasks
across 4 domains, spanning a wide range of typical use cases. We find many
examples of forking tokens, including surprising ones such as punctuation
marks, suggesting that LLMs are often just a single token away from saying
something very different.",2024-12-10,"Eric Bigelow, Ari Holtzman, Hidenori Tanaka, Tomer Ullman",http://arxiv.org/pdf/2412.07961v1,cs.CL
HEDS 3.0: The Human Evaluation Data Sheet Version 3.0,"This paper presents version 3.0 of the Human Evaluation Datasheet (HEDS).
This update is the result of our experience using HEDS in the context of
numerous recent human evaluation experiments, including reproduction studies,
and of feedback received. Our main overall goal was to improve clarity, and to
enable users to complete the datasheet more consistently and comparably. The
HEDS 3.0 package consists of the digital data sheet, documentation, and code
for exporting completed data sheets as latex files, all available from the HEDS
GitHub.",2024-12-10,"Anya Belz, Craig Thomson",http://arxiv.org/pdf/2412.07940v1,cs.CL
How to Choose a Threshold for an Evaluation Metric for Large Language Models,"To ensure and monitor large language models (LLMs) reliably, various
evaluation metrics have been proposed in the literature. However, there is
little research on prescribing a methodology to identify a robust threshold on
these metrics even though there are many serious implications of an incorrect
choice of the thresholds during deployment of the LLMs. Translating the
traditional model risk management (MRM) guidelines within regulated industries
such as the financial industry, we propose a step-by-step recipe for picking a
threshold for a given LLM evaluation metric. We emphasize that such a
methodology should start with identifying the risks of the LLM application
under consideration and risk tolerance of the stakeholders. We then propose
concrete and statistically rigorous procedures to determine a threshold for the
given LLM evaluation metric using available ground-truth data. As a concrete
example to demonstrate the proposed methodology at work, we employ it on the
Faithfulness metric, as implemented in various publicly available libraries,
using the publicly available HaluBench dataset. We also lay a foundation for
creating systematic approaches to select thresholds, not only for LLMs but for
any GenAI applications.",2024-12-10,"Bhaskarjit Sarmah, Mingshu Li, Jingrao Lyu, Sebastian Frank, Nathalia Castellanos, Stefano Pasquali, Dhagash Mehta",http://arxiv.org/pdf/2412.12148v1,cs.CL
Style-agnostic evaluation of ASR using multiple reference transcripts,"Word error rate (WER) as a metric has a variety of limitations that have
plagued the field of speech recognition. Evaluation datasets suffer from
varying style, formality, and inherent ambiguity of the transcription task. In
this work, we attempt to mitigate some of these differences by performing
style-agnostic evaluation of ASR systems using multiple references transcribed
under opposing style parameters. As a result, we find that existing WER reports
are likely significantly over-estimating the number of contentful errors made
by state-of-the-art ASR systems. In addition, we have found our multireference
method to be a useful mechanism for comparing the quality of ASR models that
differ in the stylistic makeup of their training data and target task.",2024-12-10,"Quinten McNamara, Miguel Ángel del Río Fernández, Nishchal Bhandari, Martin Ratajczak, Danny Chen, Corey Miller, Migüel Jetté",http://arxiv.org/pdf/2412.07937v1,cs.CL
Asking Again and Again: Exploring LLM Robustness to Repeated Questions,"This study investigates whether repeating questions within prompts influences
the performance of large language models (LLMs). We hypothesize that
reiterating a question within a single prompt might enhance the model's focus
on key elements of the query. We evaluate five recent LLMs -- including
GPT-4o-mini, DeepSeek-V3, and smaller open-source models -- on three reading
comprehension datasets under different prompt settings, varying question
repetition levels (1, 3, or 5 times per prompt). Our results demonstrate that
question repetition can increase models' accuracy by up to $6\%$. However,
across all models, settings, and datasets, we do not find the result
statistically significant. These findings provide insights into prompt design
and LLM behavior, suggesting that repetition alone does not significantly
impact output quality.",2024-12-10,"Sagi Shaier, Mario Sanz-Guerrero, Katharina von der Wense",http://arxiv.org/pdf/2412.07923v3,cs.CL
Identifying Quantum Mechanical Statistics in Italian Corpora,"We present a theoretical and empirical investigation of the statistical
behaviour of the words in a text produced by human language. To this aim, we
analyse the word distribution of various texts of Italian language selected
from a specific literary corpus. We firstly generalise a theoretical framework
elaborated by ourselves to identify 'quantum mechanical statistics' in
large-size texts. Then, we show that, in all analysed texts, words distribute
according to 'Bose--Einstein statistics' and show significant deviations from
'Maxwell--Boltzmann statistics'. Next, we introduce an effect of 'word
randomization' which instead indicates that the difference between the two
statistical models is not as pronounced as in the original cases. These results
confirm the empirical patterns obtained in texts of English language and
strongly indicate that identical words tend to 'clump together' as a
consequence of their meaning, which can be explained as an effect of 'quantum
entanglement' produced through a phenomenon of 'contextual updating'. More,
word randomization can be seen as the linguistic-conceptual equivalent of an
increase of temperature which destroys 'coherence' and makes classical
statistics prevail over quantum statistics. Some insights into the origin of
quantum statistics in physics are finally provided.",2024-12-10,"Diederik Aerts, Jonito Aerts Arguëlles, Lester Beltran, Massimiliano Sassoli de Bianchi, Sandro Sozzo",http://arxiv.org/pdf/2412.07919v2,cs.CL
Rethinking Emotion Annotations in the Era of Large Language Models,"Modern affective computing systems rely heavily on datasets with
human-annotated emotion labels, for training and evaluation. However, human
annotations are expensive to obtain, sensitive to study design, and difficult
to quality control, because of the subjective nature of emotions. Meanwhile,
Large Language Models (LLMs) have shown remarkable performance on many Natural
Language Understanding tasks, emerging as a promising tool for text annotation.
In this work, we analyze the complexities of emotion annotation in the context
of LLMs, focusing on GPT-4 as a leading model. In our experiments, GPT-4
achieves high ratings in a human evaluation study, painting a more positive
picture than previous work, in which human labels served as the only ground
truth. On the other hand, we observe differences between human and GPT-4
emotion perception, underscoring the importance of human input in annotation
studies. To harness GPT-4's strength while preserving human perspective, we
explore two ways of integrating GPT-4 into emotion annotation pipelines,
showing its potential to flag low-quality labels, reduce the workload of human
annotators, and improve downstream model learning performance and efficiency.
Together, our findings highlight opportunities for new emotion labeling
practices and suggest the use of LLMs as a promising tool to aid human
annotation.",2024-12-10,"Minxue Niu, Yara El-Tawil, Amrit Romana, Emily Mower Provost",http://arxiv.org/pdf/2412.07906v1,cs.CL
CAP: Evaluation of Persuasive and Creative Image Generation,"We address the task of advertisement image generation and introduce three
evaluation metrics to assess Creativity, prompt Alignment, and Persuasiveness
(CAP) in generated advertisement images. Despite recent advancements in
Text-to-Image (T2I) generation and their performance in generating high-quality
images for explicit descriptions, evaluating these models remains challenging.
Existing evaluation methods focus largely on assessing alignment with explicit,
detailed descriptions, but evaluating alignment with visually implicit prompts
remains an open problem. Additionally, creativity and persuasiveness are
essential qualities that enhance the effectiveness of advertisement images, yet
are seldom measured. To address this, we propose three novel metrics for
evaluating the creativity, alignment, and persuasiveness of generated images.
Our findings reveal that current T2I models struggle with creativity,
persuasiveness, and alignment when the input text is implicit messages. We
further introduce a simple yet effective approach to enhance T2I models'
capabilities in producing images that are better aligned, more creative, and
more persuasive.",2024-12-10,"Aysan Aghazadeh, Adriana Kovashka",http://arxiv.org/pdf/2412.10426v1,cs.CL
Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models,"Recent advancements in visual generative models have enabled high-quality
image and video generation, opening diverse applications. However, evaluating
these models often demands sampling hundreds or thousands of images or videos,
making the process computationally expensive, especially for diffusion-based
models with inherently slow sampling. Moreover, existing evaluation methods
rely on rigid pipelines that overlook specific user needs and provide numerical
results without clear explanations. In contrast, humans can quickly form
impressions of a model's capabilities by observing only a few samples. To mimic
this, we propose the Evaluation Agent framework, which employs human-like
strategies for efficient, dynamic, multi-round evaluations using only a few
samples per round, while offering detailed, user-tailored analyses. It offers
four key advantages: 1) efficiency, 2) promptable evaluation tailored to
diverse user needs, 3) explainability beyond single numerical scores, and 4)
scalability across various models and tools. Experiments show that Evaluation
Agent reduces evaluation time to 10% of traditional methods while delivering
comparable results. The Evaluation Agent framework is fully open-sourced to
advance research in visual generative models and their efficient evaluation.",2024-12-10,"Fan Zhang, Shulin Tian, Ziqi Huang, Yu Qiao, Ziwei Liu",http://arxiv.org/pdf/2412.09645v2,cs.CL
Zero-Shot ATC Coding with Large Language Models for Clinical Assessments,"Manual assignment of Anatomical Therapeutic Chemical (ATC) codes to
prescription records is a significant bottleneck in healthcare research and
operations at Ontario Health and InterRAI Canada, requiring extensive expert
time and effort. To automate this process while maintaining data privacy, we
develop a practical approach using locally deployable large language models
(LLMs). Inspired by recent advances in automatic International Classification
of Diseases (ICD) coding, our method frames ATC coding as a hierarchical
information extraction task, guiding LLMs through the ATC ontology level by
level. We evaluate our approach using GPT-4o as an accuracy ceiling and focus
development on open-source Llama models suitable for privacy-sensitive
deployment. Testing across Health Canada drug product data, the RABBITS
benchmark, and real clinical notes from Ontario Health, our method achieves 78%
exact match accuracy with GPT-4o and 60% with Llama 3.1 70B. We investigate
knowledge grounding through drug definitions, finding modest improvements in
accuracy. Further, we show that fine-tuned Llama 3.1 8B matches zero-shot Llama
3.1 70B accuracy, suggesting that effective ATC coding is feasible with smaller
models. Our results demonstrate the feasibility of automatic ATC coding in
privacy-sensitive healthcare environments, providing a foundation for future
deployments.",2024-12-10,"Zijian Chen, John-Michael Gamble, Micaela Jantzi, John P. Hirdes, Jimmy Lin",http://arxiv.org/pdf/2412.07743v1,cs.CL
Granite Guardian,"We introduce the Granite Guardian models, a suite of safeguards designed to
provide risk detection for prompts and responses, enabling safe and responsible
use in combination with any large language model (LLM). These models offer
comprehensive coverage across multiple risk dimensions, including social bias,
profanity, violence, sexual content, unethical behavior, jailbreaking, and
hallucination-related risks such as context relevance, groundedness, and answer
relevance for retrieval-augmented generation (RAG). Trained on a unique dataset
combining human annotations from diverse sources and synthetic data, Granite
Guardian models address risks typically overlooked by traditional risk
detection models, such as jailbreaks and RAG-specific issues. With AUC scores
of 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks
respectively, Granite Guardian is the most generalizable and competitive model
available in the space. Released as open-source, Granite Guardian aims to
promote responsible AI development across the community.
  https://github.com/ibm-granite/granite-guardian",2024-12-10,"Inkit Padhi, Manish Nagireddy, Giandomenico Cornacchia, Subhajit Chaudhury, Tejaswini Pedapati, Pierre Dognin, Keerthiram Murugesan, Erik Miehling, Martín Santillán Cooper, Kieran Fraser, Giulio Zizzo, Muhammad Zaid Hameed, Mark Purcell, Michael Desmond, Qian Pan, Zahra Ashktorab, Inge Vejsbjerg, Elizabeth M. Daly, Michael Hind, Werner Geyer, Ambrish Rawat, Kush R. Varshney, Prasanna Sattigeri",http://arxiv.org/pdf/2412.07724v2,cs.CL
TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation,"The inference cost of Large Language Models (LLMs) is a significant challenge
due to their computational demands, specially on tasks requiring long outputs.
However, natural language often contains redundancy, which presents an
opportunity for optimization. We have observed that LLMs can generate distilled
language-concise outputs that retain essential meaning, when prompted
appropriately. We propose TRIM, a pipeline for saving computational cost in
which a shorter distilled output from the LLM is reconstructed into a full
narrative by a smaller model with lower inference costs. Our experiments show
promising results, particularly in general knowledge domains with 20.58% saved
tokens on average with tiny decrease in evaluation metrics, hinting that this
approach can effectively balance efficiency and accuracy in language processing
tasks.",2024-12-10,"Alfredo Garrachón Ruiz, Tomás de la Rosa, Daniel Borrajo",http://arxiv.org/pdf/2412.07682v3,cs.CL
Can linguists better understand DNA?,"Multilingual transfer ability, which reflects how well models fine-tuned on
one source language can be applied to other languages, has been well studied in
multilingual pre-trained models. However, the existence of such capability
transfer between natural language and gene sequences/languages remains under
explored.This study addresses this gap by drawing inspiration from the
sentence-pair classification task used for evaluating sentence similarity in
natural language. We constructed two analogous tasks: DNA-pair
classification(DNA sequence similarity) and DNA-protein-pair
classification(gene coding determination). These tasks were designed to
validate the transferability of capabilities from natural language to gene
sequences. Even a small-scale pre-trained model like GPT-2-small, which was
pre-trained on English, achieved an accuracy of 78% on the DNA-pair
classification task after being fine-tuned on English sentence-pair
classification data(XTREME PAWS-X). While training a BERT model on multilingual
text, the precision reached 89%. On the more complex DNA-protein-pair
classification task, however, the model's output was barely distinguishable
from random output.Experimental validation has confirmed that the transfer of
capabilities from natural language to biological language is unequivocally
present. Building on this foundation, we have also investigated the impact of
model parameter scale and pre-training on this capability transfer. We provide
recommendations for facilitating the transfer of capabilities from natural
language to genetic language,as well as new approaches for conducting
biological research based on this capability.This study offers an intriguing
new perspective on exploring the relationship between natural language and
genetic language.",2024-12-10,Wang Liang,http://arxiv.org/pdf/2412.07678v3,cs.CL
RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text Rewriting,"Despite the widespread use of LLMs due to their superior performance in
various tasks, their high computational costs often lead potential users to opt
for the pretraining-finetuning pipeline. However, biases prevalent in manually
constructed datasets can introduce spurious correlations between tokens and
labels, creating so-called shortcuts and hindering the generalizability of
fine-tuned models. Existing debiasing methods often rely on prior knowledge of
specific dataset biases, which is challenging to acquire a priori. We propose
RAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,
and data-focused debiasing approach based on text rewriting for shortcut
mitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased text
segments by replacing them with heuristically selected alternatives in a
shortcut space defined by token statistics and positional information. This
process aims to align surface-level text features more closely with diverse
label distributions, thereby promoting the learning of genuine linguistic
patterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on the
FEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.
Additionally, RAZOR effectively mitigates specific known biases, reducing
bias-related terms by x2 without requiring prior bias information, a result
that is on par with SoTA models that leverage prior information. Our work
prioritizes data manipulation over architectural modifications, emphasizing the
pivotal role of data quality in enhancing model performance and fairness. This
research contributes to developing more robust evaluation benchmarks for
debiasing methods by incorporating metrics for bias reduction and overall model
efficacy.",2024-12-10,"Shuo Yang, Bardh Prenkaj, Gjergji Kasneci",http://arxiv.org/pdf/2412.07675v3,cs.CL
FlexLLM: Exploring LLM Customization for Moving Target Defense on Black-Box LLMs Against Jailbreak Attacks,"Defense in large language models (LLMs) is crucial to counter the numerous
attackers exploiting these systems to generate harmful content through
manipulated prompts, known as jailbreak attacks. Although many defense
strategies have been proposed, they often require access to the model's
internal structure or need additional training, which is impractical for
service providers using LLM APIs, such as OpenAI APIs or Claude APIs. In this
paper, we propose a moving target defense approach that alters decoding
hyperparameters to enhance model robustness against various jailbreak attacks.
Our approach does not require access to the model's internal structure and
incurs no additional training costs. The proposed defense includes two key
components: (1) optimizing the decoding strategy by identifying and adjusting
decoding hyperparameters that influence token generation probabilities, and (2)
transforming the decoding hyperparameters and model system prompts into dynamic
targets, which are continuously altered during each runtime. By continuously
modifying decoding strategies and prompts, the defense effectively mitigates
the existing attacks. Our results demonstrate that our defense is the most
effective against jailbreak attacks in three of the models tested when using
LLMs as black-box APIs. Moreover, our defense offers lower inference costs and
maintains comparable response quality, making it a potential layer of
protection when used alongside other defense methods.",2024-12-10,"Bocheng Chen, Hanqing Guo, Qiben Yan",http://arxiv.org/pdf/2412.07672v1,cs.CL
Active Inference for Self-Organizing Multi-LLM Systems: A Bayesian Thermodynamic Approach to Adaptation,"This paper introduces a novel approach to creating adaptive language agents
by integrating active inference with large language models (LLMs). While LLMs
demonstrate remarkable capabilities, their reliance on static prompts limits
adaptation to new information and changing environments. We address this by
implementing an active inference framework that acts as a cognitive layer above
an LLM-based agent, dynamically adjusting prompts and search strategies through
principled information-seeking behavior. Our framework models the environment
using three state factors (prompt, search, and information states) with seven
observation modalities capturing quality metrics. By framing the agent's
learning through the free energy principle, we enable systematic exploration of
prompt combinations and search strategies. Experimental results demonstrate the
effectiveness of this approach, with the agent developing accurate models of
environment dynamics evidenced by emergent structure in observation matrices.
Action selection patterns reveal sophisticated exploration-exploitation
behavior, transitioning from initial information-gathering to targeted prompt
testing. The integration of thermodynamic principles with language model
capabilities provides a principled framework for creating robust, adaptable
agents, extending active inference beyond traditional low-dimensional control
problems to high-dimensional, language-driven environments.",2024-12-10,Rithvik Prakki,http://arxiv.org/pdf/2412.10425v3,cs.CL
Searching for Structure: Investigating Emergent Communication with Large Language Models,"Human languages have evolved to be structured through repeated language
learning and use. These processes introduce biases that operate during language
acquisition and shape linguistic systems toward communicative efficiency. In
this paper, we investigate whether the same happens if artificial languages are
optimised for implicit biases of Large Language Models (LLMs). To this end, we
simulate a classical referential game in which LLMs learn and use artificial
languages. Our results show that initially unstructured holistic languages are
indeed shaped to have some structural properties that allow two LLM agents to
communicate successfully. Similar to observations in human experiments,
generational transmission increases the learnability of languages, but can at
the same time result in non-humanlike degenerate vocabularies. Taken together,
this work extends experimental findings, shows that LLMs can be used as tools
in simulations of language evolution, and opens possibilities for future
human-machine experiments in this field.",2024-12-10,"Tom Kouwenhoven, Max Peeperkorn, Tessa Verhoef",http://arxiv.org/pdf/2412.07646v3,cs.CL
ChocoLlama: Lessons Learned From Teaching Llamas Dutch,"While Large Language Models (LLMs) have shown remarkable capabilities in
natural language understanding and generation, their performance often lags in
lower-resource, non-English languages due to biases in the training data. In
this work, we explore strategies for adapting the primarily English LLMs
(Llama-2 and Llama-3) to Dutch, a language spoken by 30 million people
worldwide yet often underrepresented in LLM development. We collect 104GB of
Dutch text ($32$B tokens) from various sources to first apply continued
pretraining using low-rank adaptation (LoRA), complemented with Dutch
posttraining strategies provided by prior work. For Llama-2, we consider using
(i) the tokenizer of the original model, and (ii) training a new,
Dutch-specific tokenizer combined with embedding reinitialization. We evaluate
our adapted models, ChocoLlama-2, both on standard benchmarks and a novel Dutch
benchmark, ChocoLlama-Bench. Our results demonstrate that LoRA can effectively
scale for language adaptation, and that tokenizer modification with careful
weight reinitialization can improve performance. Notably, Llama-3 was released
during the course of this project and, upon evaluation, demonstrated superior
Dutch capabilities compared to our Dutch-adapted versions of Llama-2. We hence
apply the same adaptation technique to Llama-3, using its original tokenizer.
While our adaptation methods enhanced Llama-2's Dutch capabilities, we found
limited gains when applying the same techniques to Llama-3. This suggests that
for ever improving, multilingual foundation models, language adaptation
techniques may benefit more from focusing on language-specific posttraining
rather than on continued pretraining. We hope this work contributes to the
broader understanding of adapting LLMs to lower-resource languages, and to the
development of Dutch LLMs in particular.",2024-12-10,"Matthieu Meeus, Anthony Rathé, François Remy, Pieter Delobelle, Jens-Joris Decorte, Thomas Demeester",http://arxiv.org/pdf/2412.07633v1,cs.CL
Piece of Table: A Divide-and-Conquer Approach for Selecting Subtables in Table Question Answering,"Applying language models (LMs) to tables is challenging due to the inherent
structural differences between two-dimensional tables and one-dimensional text
for which the LMs were originally designed. Furthermore, when applying
linearized tables to LMs, the maximum token lengths often imposed in
self-attention calculations make it difficult to comprehensively understand the
context spread across large tables. To address these challenges, we present
PieTa (Piece of Table), a new framework for subtable-based question answering
(QA). PieTa operates through an iterative process of dividing tables into
smaller windows, using LMs to select relevant cells within each window, and
merging these cells into a subtable. This multi-resolution approach captures
dependencies across multiple rows and columns while avoiding the limitations
caused by long context inputs. Instantiated as a simple iterative subtable
union algorithm, PieTa demonstrates improved performance over previous
subtable-based QA approaches.",2024-12-10,"Wonjin Lee, Kyumin Kim, Sungjae Lee, Jihun Lee, Kwang In Kim",http://arxiv.org/pdf/2412.07629v4,cs.CL
DRUM: Learning Demonstration Retriever for Large MUlti-modal Models,"Recently, large language models (LLMs) have demonstrated impressive
capabilities in dealing with new tasks with the help of in-context learning
(ICL). In the study of Large Vision-Language Models (LVLMs), when implementing
ICL, researchers usually adopts the naive strategies like fixed demonstrations
across different samples, or selecting demonstrations directly via a
visual-language embedding model. These methods does not guarantee the
configured demonstrations fit the need of the LVLMs. To address this issue, we
now propose a novel framework, \underline{d}emonstration \underline{r}etriever
for large m\underline{u}lti-modal \underline{m}odel (DRUM), which fine-tunes
the visual-language embedding model to better meet the LVLM's needs. First, we
discuss the retrieval strategies for a visual-language task, assuming an
embedding model is given. And we propose to concate the image and text
embeddings to enhance the retrieval performance. Second, we propose to re-rank
the demonstrations retrieved by the embedding model via the LVLM's feedbacks,
and calculate a list-wise ranking loss for training the embedding model. Third,
we propose an iterative demonstration mining strategy to improve the training
of the embedding model. Through extensive experiments on 3 types of
visual-language tasks, 7 benchmark datasets, our DRUM framework is proven to be
effective in boosting the LVLM's in-context learning performance via retrieving
more proper demonstrations.",2024-12-10,"Ellen Yi-Ge, Jiechao Gao, Wei Han, Wei Zhu",http://arxiv.org/pdf/2412.07619v1,cs.CL
Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs,"Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git",2024-12-10,"Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie",http://arxiv.org/pdf/2412.07618v2,cs.CL
Subtopic-aware View Sampling and Temporal Aggregation for Long-form Document Matching,"Long-form document matching aims to judge the relevance between two documents
and has been applied to various scenarios. Most existing works utilize
hierarchical or long context models to process documents, which achieve coarse
understanding but may ignore details. Some researchers construct a document
view with similar sentences about aligned document subtopics to focus on
detailed matching signals. However, a long document generally contains multiple
subtopics. The matching signals are heterogeneous from multiple topics.
Considering only the homologous aligned subtopics may not be representative
enough and may cause biased modeling. In this paper, we introduce a new
framework to model representative matching signals. First, we propose to
capture various matching signals through subtopics of document pairs. Next, We
construct multiple document views based on subtopics to cover heterogeneous and
valuable details. However, existing spatial aggregation methods like attention,
which integrate all these views simultaneously, are hard to integrate
heterogeneous information. Instead, we propose temporal aggregation, which
effectively integrates different views gradually as the training progresses.
Experimental results show that our learning framework is effective on several
document-matching tasks, including news duplication and legal case retrieval.",2024-12-10,"Youchao Zhou, Heyan Huang, Zhijing Wu, Yuhang Liu, Xinglin Wang",http://arxiv.org/pdf/2412.07573v2,cs.CL
LLM-as-an-Interviewer: Beyond Static Testing Through Dynamic LLM Evaluation,"We introduce LLM-as-an-Interviewer, a novel paradigm for evaluating large
language models (LLMs). This approach leverages multi-turn interactions where
the LLM interviewer actively provides feedback on responses and poses follow-up
questions to the evaluated LLM. At the start of the interview, the LLM
interviewer dynamically modifies datasets to generate initial questions,
mitigating data contamination. We apply the LLM-as-an-Interviewer framework to
evaluate six models on the MATH and DepthQA tasks. Our results show that the
framework effectively provides insights into LLM performance, including the
quality of initial responses, adaptability to feedback, and ability to address
follow-up queries like clarification or additional knowledge requests. The
framework also addresses key limitations of conventional methods like
LLM-as-a-Judge, including verbosity bias and inconsistency across runs.
Finally, we propose the Interview Report, which aggregates insights from the
interview process, providing examples and a comprehensive analysis of the LLM's
strengths and weaknesses. This report offers a detailed snapshot of the model's
real-world applicability. The code for our framework is publicly available at
https://github.com/interview-eval/.",2024-12-10,"Eunsu Kim, Juyoung Suk, Seungone Kim, Niklas Muennighoff, Dongkwan Kim, Alice Oh",http://arxiv.org/pdf/2412.10424v2,cs.CL
CoPrUS: Consistency Preserving Utterance Synthesis towards more realistic benchmark dialogues,"Large-scale Wizard-Of-Oz dialogue datasets have enabled the training of deep
learning-based dialogue systems. While they are successful as benchmark
datasets, they lack certain types of utterances, which would make them more
realistic. In this work, we investigate the creation of synthetic communication
errors in an automatic pipeline. Based on linguistic theory, we propose and
follow a simple error taxonomy. We focus on three types of miscommunications
that could happen in real-world dialogues but are underrepresented in the
benchmark dataset: misunderstandings, non-understandings and vaguely related
questions. Our two-step approach uses a state-of-the-art Large Language Model
(LLM) to first create the error and secondly the repairing utterance. We
perform Language Model-based evaluation to ensure the quality of the generated
utterances. We apply the method to the MultiWOZ dataset and evaluate it both
qualitatively and empirically as well as with human judges. Our results
indicate that current LLMs can aid in adding post-hoc miscommunications to
benchmark datasets as a form of data augmentation. We publish the resulting
dataset, in which nearly 1900 dialogues have been modified, as CoPrUS-MultiWOZ
to facilitate future work on dialogue systems.",2024-12-10,"Sebastian Steindl, Ulrich Schäfer, Bernd Ludwig",http://arxiv.org/pdf/2412.07515v1,cs.CL
Look Before You Leap: Enhancing Attention and Vigilance Regarding Harmful Content with GuidelineLLM,"Despite being empowered with alignment mechanisms, large language models
(LLMs) are increasingly vulnerable to emerging jailbreak attacks that can
compromise their alignment mechanisms. This vulnerability poses significant
risks to real-world applications. Existing work faces challenges in both
training efficiency and generalization capabilities (i.e., Reinforcement
Learning from Human Feedback and Red-Teaming). Developing effective strategies
to enable LLMs to resist continuously evolving jailbreak attempts represents a
significant challenge. To address this challenge, we propose a novel defensive
paradigm called GuidelineLLM, which assists LLMs in recognizing queries that
may have harmful content. Before LLMs respond to a query, GuidelineLLM first
identifies potential risks associated with the query, summarizes these risks
into guideline suggestions, and then feeds these guidelines to the responding
LLMs. Importantly, our approach eliminates the necessity for additional safety
fine-tuning of the LLMs themselves; only the GuidelineLLM requires fine-tuning.
This characteristic enhances the general applicability of GuidelineLLM across
various LLMs. Experimental results demonstrate that GuidelineLLM can
significantly reduce the attack success rate (ASR) against LLM (an average
reduction of 34.17\% ASR) while maintaining the usefulness of LLM in handling
benign queries. The code is available at
https://github.com/sqzhang-lazy/GuidelineLLM.",2024-12-10,"Shaoqing Zhang, Zhuosheng Zhang, Kehai Chen, Rongxiang Weng, Muyun Yang, Tiejun Zhao, Min Zhang",http://arxiv.org/pdf/2412.10423v2,cs.CL
Bilingual BSARD: Extending Statutory Article Retrieval to Dutch,"Statutory article retrieval plays a crucial role in making legal information
more accessible to both laypeople and legal professionals. Multilingual
countries like Belgium present unique challenges for retrieval models due to
the need for handling legal issues in multiple languages. Building on the
Belgian Statutory Article Retrieval Dataset (BSARD) in French, we introduce the
bilingual version of this dataset, bBSARD. The dataset contains parallel
Belgian statutory articles in both French and Dutch, along with legal questions
from BSARD and their Dutch translation. Using bBSARD, we conduct extensive
benchmarking of retrieval models available for Dutch and French. Our
benchmarking setup includes lexical models, zero-shot dense models, and
fine-tuned small foundation models. Our experiments show that BM25 remains a
competitive baseline compared to many zero-shot dense models in both languages.
We also observe that while proprietary models outperform open alternatives in
the zero-shot setting, they can be matched or surpassed by fine-tuning small
language-specific models. Our dataset and evaluation code are publicly
available.",2024-12-10,"Ehsan Lotfi, Nikolay Banar, Nerses Yuzbashyan, Walter Daelemans",http://arxiv.org/pdf/2412.07462v1,cs.CL
A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment,"Do generative pre-trained transformer (GPT) models, trained only to predict
the next token, implicitly learn a world model from which a sequence is
generated one token at a time? We address this question by deriving a causal
interpretation of the attention mechanism in GPT, and suggesting a causal world
model that arises from this interpretation. Furthermore, we propose that GPT
models, at inference time, can be utilized for zero-shot causal structure
learning for input sequences and present a confidence score. Empirical
evaluation is conducted in a controlled environment using the setup and rules
of the Othello and Chess strategy games. A GPT, pre-trained on real-world games
played with the intention of winning, is tested on out-of-distribution
synthetic data consisting of sequences of random legal moves. We find that the
GPT model is likely to generate legal next moves for out-of-distribution
sequences for which a causal structure is encoded in the attention mechanism
with high confidence. In cases for which the GPT model generates illegal moves
it also fails to capture any causal structure.",2024-12-10,"Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Estelle Aflalo, Vasudev Lal",http://arxiv.org/pdf/2412.07446v3,cs.CL
Knowledge Graph Guided Evaluation of Abstention Techniques,"To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., ""rivers"") from a knowledge graph. Focusing on benign concepts
isolates the effect of safety training, and grounding these concepts in a
knowledge graph allows us to study the generalization and specificity of
abstention techniques. Using SELECT, we benchmark different abstention
techniques over six open-weight and closed-source models. We find that the
examined techniques indeed cause models to abstain with over $80\%$ abstention
rates. However, these techniques are not as effective for descendants of the
target concepts, where abstention rates drop by $19\%$. We also characterize
the generalization-specificity trade-offs for different techniques. Overall, no
single technique is invariably better than others, and our findings inform
practitioners of the various trade-offs involved.",2024-12-10,"Kinshuk Vasisht, Navreet Kaur, Danish Pruthi",http://arxiv.org/pdf/2412.07430v2,cs.CL
Optimizing Alignment with Less: Leveraging Data Augmentation for Personalized Evaluation,"Automatic evaluation by large language models (LLMs) is a prominent topic
today; however, judgment and evaluation tasks are often subjective and
influenced by various factors, making adaptation challenging. While many
studies demonstrate the capabilities of state-of-the-art proprietary LLMs in
comparison to human evaluators, they often struggle to adapt to reference
evaluators over time, a requirement for achieving personalized judgment.
Additionally, numerous works have attempted to apply open LLMs as judges or
evaluators, but these efforts frequently overlook the limitations of working
with scarce data. Personalized judgment is inherently associated with limited
data scenarios, which are common in many real-world problems. Our work aims to
present a data augmentation technique to select a more effective sample from
limited data in order to align an open LLM with human preference. Our work
achieves approximately 7% improvements in Pearson correlation with a reference
judge over the baseline,and 30% improvement over the base model
(Llama3.1-8B-Instruct) in the mathematical reasoning evaluation task.
demonstrating that augmenting selecting more effective preference data enables
our approach to surpass baseline methods.",2024-12-10,"Javad Seraj, Mohammad Mahdi Mohajeri, Mohammad Javad Dousti, Majid Nili Ahmadabadi",http://arxiv.org/pdf/2412.07429v1,cs.CL
RAG-based Question Answering over Heterogeneous Data and Text,"This article presents the QUASAR system for question answering over
unstructured text, structured tables, and knowledge graphs, with unified
treatment of all sources. The system adopts a RAG-based architecture, with a
pipeline of evidence retrieval followed by answer generation, with the latter
powered by a moderate-sized language model. Additionally and uniquely, QUASAR
has components for question understanding, to derive crisper input for evidence
retrieval, and for re-ranking and filtering the retrieved evidence before
feeding the most informative pieces into the answer generation. Experiments
with three different benchmarks demonstrate the high answering quality of our
approach, being on par with or better than large GPT models, while keeping the
computational cost and energy consumption orders of magnitude lower.",2024-12-10,"Philipp Christmann, Gerhard Weikum",http://arxiv.org/pdf/2412.07420v1,cs.CL
Composing or Not Composing? Towards Distributional Construction Grammars,"The mechanisms of comprehension during language processing remains an open
question. Classically, building the meaning of a linguistic utterance is said
to be incremental, step-by-step, based on a compositional process. However,
many different works have shown for a long time that non-compositional
phenomena are also at work. It is therefore necessary to propose a framework
bringing together both approaches. We present in this paper an approach based
on Construction Grammars and completing this framework in order to account for
these different mechanisms. We propose first a formal definition of this
framework by completing the feature structure representation proposed in
Sign-Based Construction Grammars. In a second step, we present a general
representation of the meaning based on the interaction of constructions, frames
and events. This framework opens the door to a processing mechanism for
building the meaning based on the notion of activation evaluated in terms of
similarity and unification. This new approach integrates features from
distributional semantics into the constructionist framework, leading to what we
call Distributional Construction Grammars.",2024-12-10,"Philippe Blache, Emmanuele Chersoni, Giulia Rambelli, Alessandro Lenci",http://arxiv.org/pdf/2412.07419v1,cs.CL
"Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT","Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a
form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks
requiring structured reasoning and semantic understanding. However, creating
KGs for GraphRAGs remains a significant challenge due to accuracy and
scalability limitations of traditional methods. This paper introduces a novel
approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and
BERT to generate KGs directly from unstructured data, bypassing traditional
pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit
Distance, and Semantic Similarity, we evaluate the models' ability to generate
high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic
fidelity and structural accuracy, LLaMA 2 excels in lightweight,
domain-specific graphs, and BERT provides insights into challenges in
entity-relationship modeling. This study underscores the potential of LLMs to
streamline KG creation and enhance GraphRAG accessibility for real-world
applications, while setting a foundation for future advancements.",2024-12-10,"Ahan Bhatt, Nandan Vaghela, Kush Dudhia",http://arxiv.org/pdf/2412.07412v1,cs.CL
AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework,"Answering natural language (NL) questions about tables, known as Tabular
Question Answering (TQA), is crucial because it allows users to quickly and
efficiently extract meaningful insights from structured data, effectively
bridging the gap between human language and machine-readable formats. Many of
these tables are derived from web sources or real-world scenarios, which
require meticulous data preparation (or data prep) to ensure accurate
responses. However, preparing such tables for NL questions introduces new
requirements that extend beyond traditional data preparation. This
question-aware data preparation involves specific tasks such as column
derivation and filtering tailored to particular questions, as well as
question-aware value normalization or conversion, highlighting the need for a
more nuanced approach in this context. Because each of the above tasks is
unique, a single model (or agent) may not perform effectively across all
scenarios. In this paper, we propose AutoPrep, a large language model
(LLM)-based multi-agent framework that leverages the strengths of multiple
agents, each specialized in a certain type of data prep, ensuring more accurate
and contextually relevant responses. Given an NL question over a table,
AutoPrep performs data prep through three key components. Planner: Determines a
logical plan, outlining a sequence of high-level operations. Programmer:
Translates this logical plan into a physical plan by generating the
corresponding low-level code. Executor: Executes the generated code to process
the table. To support this multi-agent framework, we design a novel
Chain-of-Clauses reasoning mechanism for high-level operation suggestion, and a
tool-augmented method for low-level code generation...",2024-12-10,"Meihao Fan, Ju Fan, Nan Tang, Lei Cao, Guoliang Li, Xiaoyong Du",http://arxiv.org/pdf/2412.10422v3,cs.CL
CMT: A Memory Compression Method for Continual Knowledge Learning of Large Language Models,"Large Language Models (LLMs) need to adapt to the continuous changes in data,
tasks, and user preferences. Due to their massive size and the high costs
associated with training, LLMs are not suitable for frequent retraining.
However, updates are necessary to keep them in sync with rapidly evolving human
knowledge. To address these challenges, this paper proposes the Compression
Memory Training (CMT) method, an efficient and effective online adaptation
framework for LLMs that features robust knowledge retention capabilities.
Inspired by human memory mechanisms, CMT compresses and extracts information
from new documents to be stored in a memory bank. When answering to queries
related to these new documents, the model aggregates these document memories
from the memory bank to better answer user questions. The parameters of the LLM
itself do not change during training and inference, reducing the risk of
catastrophic forgetting. To enhance the encoding, retrieval, and aggregation of
memory, we further propose three new general and flexible techniques, including
memory-aware objective, self-matching and top-aggregation. Extensive
experiments conducted on three continual learning datasets (i.e., StreamingQA,
SQuAD and ArchivalQA) demonstrate that the proposed method improves model
adaptability and robustness across multiple base LLMs (e.g., +4.07 EM & +4.19
F1 in StreamingQA with Llama-2-7b).",2024-12-10,"Dongfang Li, Zetian Sun, Xinshuo Hu, Baotian Hu, Min Zhang",http://arxiv.org/pdf/2412.07393v1,cs.CL
A Review of Challenges in Speech-based Conversational AI for Elderly Care,"Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.",2024-12-10,"Willemijn Klaassen, Bram van Dijk, Marco Spruit",http://arxiv.org/pdf/2412.07388v1,cs.CL
Algorithmic Phase Transitions in Language Models: A Mechanistic Case Study of Arithmetic,"Zero-shot capabilities of large language models make them powerful tools for
solving a range of tasks without explicit training. It remains unclear,
however, how these models achieve such performance, or why they can zero-shot
some tasks but not others. In this paper, we shed some light on this phenomenon
by defining and investigating algorithmic stability in language models --
changes in problem-solving strategy employed by the model as a result of
changes in task specification. We focus on a task where algorithmic stability
is needed for generalization: two-operand arithmetic. Surprisingly, we find
that Gemma-2-2b employs substantially different computational models on closely
related subtasks, i.e. four-digit versus eight-digit addition. Our findings
suggest that algorithmic instability may be a contributing factor to language
models' poor zero-shot performance across certain logical reasoning tasks, as
they struggle to abstract different problem-solving strategies and smoothly
transition between them.",2024-12-10,"Alan Sun, Ethan Sun, Warren Shepard",http://arxiv.org/pdf/2412.07386v1,cs.CL
SpecFuse: Ensembling Large Language Models via Next-Segment Prediction,"Ensembles of generative large language models (LLMs) can integrate the
strengths of different LLMs to compensate for the limitations of individual
models. However, recent work has focused on training an additional fusion model
to combine complete responses from multiple LLMs, failing to tap into their
collaborative potential to generate higher-quality responses. Moreover, as the
additional fusion model is trained on a specialized dataset, these methods
struggle with generalizing to open-domain queries from online users. In this
paper, we propose SpecFuse, a novel ensemble framework that outputs the fused
result by iteratively producing the next segment through collaboration among
LLMs. This is achieved through cyclic execution of its inference and
verification components. In each round, the inference component invokes each
base LLM to generate candidate segments in parallel, and the verify component
calls these LLMs again to predict the ranking of the segments. The top-ranked
segment is then broadcast to all LLMs, encouraging them to generate
higher-quality segments in the next round. This approach also allows the base
LLMs to be plug-and-play, without any training or adaptation, avoiding
generalization limitations. Furthermore, to conserve computational resources,
we propose a model exit mechanism that dynamically excludes models exhibiting
poor performance in previous rounds during each query response. In this way, it
effectively reduces the number of model calls while maintaining overall
performance.",2024-12-10,"Bo Lv, Chen Tang, Yanan Zhang, Xin Liu, Yue Yu, Ping Luo",http://arxiv.org/pdf/2412.07380v2,cs.CL
Na'vi or Knave: Jailbreaking Language Models via Metaphorical Avatars,"Metaphor serves as an implicit approach to convey information, while enabling
the generalized comprehension of complex subjects. However, metaphor can
potentially be exploited to bypass the safety alignment mechanisms of Large
Language Models (LLMs), leading to the theft of harmful knowledge. In our
study, we introduce a novel attack framework that exploits the imaginative
capacity of LLMs to achieve jailbreaking, the J\underline{\textbf{A}}ilbreak
\underline{\textbf{V}}ia \underline{\textbf{A}}dversarial
Me\underline{\textbf{TA}} -pho\underline{\textbf{R}} (\textit{AVATAR}).
Specifically, to elicit the harmful response, AVATAR extracts harmful entities
from a given harmful target and maps them to innocuous adversarial entities
based on LLM's imagination. Then, according to these metaphors, the harmful
target is nested within human-like interaction for jailbreaking adaptively.
Experimental results demonstrate that AVATAR can effectively and transferablly
jailbreak LLMs and achieve a state-of-the-art attack success rate across
multiple advanced LLMs. Our study exposes a security risk in LLMs from their
endogenous imaginative capabilities. Furthermore, the analytical study reveals
the vulnerability of LLM to adversarial metaphors and the necessity of
developing defense methods against jailbreaking caused by the adversarial
metaphor. \textcolor{orange}{ \textbf{Warning: This paper contains potentially
harmful content from LLMs.}}",2024-12-10,"Yu Yan, Sheng Sun, Junqi Tong, Min Liu, Qi Li",http://arxiv.org/pdf/2412.12145v4,cs.CL
My Words Imply Your Opinion: Reader Agent-based Propagation Enhancement for Personalized Implicit Emotion Analysis,"The subtlety of emotional expressions makes implicit emotion analysis (IEA)
particularly sensitive to user-specific characteristics. Current studies
personalize emotion analysis by focusing on the author but neglect the impact
of the intended reader on implicit emotional feedback. In this paper, we
introduce Personalized IEA (PIEA) and present the RAPPIE model, which addresses
subjective variability by incorporating reader feedback. In particular, (1) we
create reader agents based on large language models to simulate reader
feedback, overcoming the issue of ``spiral of silence effect'' and data
incompleteness of real reader reaction. (2) We develop a role-aware multi-view
graph learning to model the emotion interactive propagation process in
scenarios with sparse reader information. (3) We construct two new PIEA
datasets covering English and Chinese social media with detailed user metadata,
addressing the text-centric limitation of existing datasets. Extensive
experiments show that RAPPIE significantly outperforms state-of-the-art
baselines, demonstrating the value of incorporating reader feedback in PIEA.",2024-12-10,"Jian Liao, Yu Feng, Yujin Zheng, Jun Zhao, Suge Wang, Jianxing Zheng",http://arxiv.org/pdf/2412.07367v3,cs.CL
Towards Predictive Communication with Brain-Computer Interfaces integrating Large Language Models,"This perspective article aims at providing an outline of the state of the art
and future developments towards the integration of cutting-edge predictive
language models with BCI. A synthetic overview of early and more recent
linguistic models, from natural language processing (NLP) models to recent LLM,
that to a varying extent improved predictive writing systems, is first
provided. Second, a summary of previous BCI implementations integrating
language models is presented. The few preliminary studies investigating the
possible combination of LLM with BCI spellers to efficiently support fast
communication and control are then described. Finally, current challenges and
limitations towards the full integration of LLM with BCI systems are discussed.
Recent investigations suggest that the combination of LLM with BCI might
drastically improve human-computer interaction in patients with motor or
language disorders as well as in healthy individuals. In particular, the
pretrained autoregressive transformer models, such as GPT, that capitalize from
parallelization, learning through pre-training and fine-tuning, promise a
substantial improvement of BCI for communication with respect to previous
systems incorporating simpler language models. Indeed, among various models,
the GPT-2 was shown to represent an excellent candidate for its integration
into BCI although testing was only perfomed on simulated conversations and not
on real BCI scenarios. Prospectively, the full integration of LLM with advanced
BCI systems might lead to a big leap forward towards fast, efficient and
user-adaptive neurotechnology.",2024-12-10,Andrea Caria,http://arxiv.org/pdf/2412.07355v3,cs.CL
Frame Representation Hypothesis: Multi-Token LLM Interpretability and Concept-Guided Text Generation,"Interpretability is a key challenge in fostering trust for Large Language
Models (LLMs), which stems from the complexity of extracting reasoning from
model's parameters. We present the Frame Representation Hypothesis, a
theoretically robust framework grounded in the Linear Representation Hypothesis
(LRH) to interpret and control LLMs by modeling multi-token words. Prior
research explored LRH to connect LLM representations with linguistic concepts,
but was limited to single token analysis. As most words are composed of several
tokens, we extend LRH to multi-token words, thereby enabling usage on any
textual data with thousands of concepts. To this end, we propose words can be
interpreted as frames, ordered sequences of vectors that better capture
token-word relationships. Then, concepts can be represented as the average of
word frames sharing a common concept. We showcase these tools through Top-k
Concept-Guided Decoding, which can intuitively steer text generation using
concepts of choice. We verify said ideas on Llama 3.1, Gemma 2, and Phi 3
families, demonstrating gender and language biases, exposing harmful content,
but also potential to remediate them, leading to safer and more transparent
LLMs. Code is available at
https://github.com/phvv-me/frame-representation-hypothesis.git",2024-12-10,"Pedro H. V. Valois, Lincon S. Souza, Erica K. Shimomoto, Kazuhiro Fukui",http://arxiv.org/pdf/2412.07334v2,cs.CL
Automatic Item Generation for Personality Situational Judgment Tests with Large Language Models,"Personality assessment, particularly through situational judgment tests
(SJTs), is a vital tool for psychological research, talent selection, and
educational evaluation. This study explores the potential of GPT-4, a
state-of-the-art large language model (LLM), to automate the generation of
personality situational judgment tests (PSJTs) in Chinese. Traditional SJT
development is labor-intensive and prone to biases, while GPT-4 offers a
scalable, efficient alternative. Two studies were conducted: Study 1 evaluated
the impact of prompt design and temperature settings on content validity,
finding that optimized prompts with a temperature of 1.0 produced creative and
accurate items. Study 2 assessed the psychometric properties of GPT-4-generated
PSJTs, revealing that they demonstrated satisfactory reliability and validity,
surpassing the performance of manually developed tests in measuring the Big
Five personality traits. This research highlights GPT-4's effectiveness in
developing high-quality PSJTs, providing a scalable and innovative method for
psychometric test development. These findings expand the possibilities of
automatic item generation and the application of LLMs in psychology, and offer
practical implications for streamlining test development processes in
resource-limited settings.",2024-12-10,"Chang-Jin Li, Jiyuan Zhang, Yun Tang, Jian Li",http://arxiv.org/pdf/2412.12144v3,cs.CL
Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia,"Bias studies on multilingual models confirm the presence of gender-related
stereotypes in masked models processing languages with high NLP resources. We
expand on this line of research by introducing Filipino CrowS-Pairs and
Filipino WinoQueer: benchmarks that assess both sexist and anti-queer biases in
pretrained language models (PLMs) handling texts in Filipino, a low-resource
language from the Philippines. The benchmarks consist of 7,074 new challenge
pairs resulting from our cultural adaptation of English bias evaluation
datasets, a process that we document in detail to guide similar forthcoming
efforts. We apply the Filipino benchmarks on masked and causal multilingual
models, including those pretrained on Southeast Asian data, and find that they
contain considerable amounts of bias. We also find that for multilingual
models, the extent of bias learned for a particular language is influenced by
how much pretraining data in that language a model was exposed to. Our
benchmarks and insights can serve as a foundation for future work analyzing and
mitigating bias in multilingual models.",2024-12-10,"Lance Calvin Lim Gamboa, Mark Lee",http://arxiv.org/pdf/2412.07303v2,cs.CL
The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model,"Large language models (LLMs) have shown significant multilingual
capabilities. However, the mechanisms underlying the development of these
capabilities during pre-training are not well understood. In this paper, we use
code LLMs as an experimental platform to explore the evolution of multilingual
capabilities in LLMs during the pre-training process. Based on our
observations, we propose the Babel Tower Hypothesis, which describes the entire
process of LLMs acquiring new language capabilities. During the learning
process, multiple languages initially share a single knowledge system dominated
by the primary language and gradually develop language-specific knowledge
systems. We then validate the above hypothesis by tracking the internal states
of the LLMs through identifying working languages and language transferring
neurons. Experimental results show that the internal state changes of the LLM
are consistent with our Babel Tower Hypothesis. Building on these insights, we
propose a novel method to construct an optimized pre-training corpus for
multilingual code LLMs, which significantly outperforms LLMs trained on the
original corpus. The proposed Babel Tower Hypothesis provides new insights into
designing pre-training data distributions to achieve optimal multilingual
capabilities in LLMs.",2024-12-10,"Jiawei Chen, Wentao Chen, Jing Su, Jingjing Xu, Hongyu Lin, Mengjie Ren, Yaojie Lu, Xianpei Han, Le Sun",http://arxiv.org/pdf/2412.07298v2,cs.CL
Multimodal Sentiment Analysis Based on Causal Reasoning,"With the rapid development of multimedia, the shift from unimodal textual
sentiment analysis to multimodal image-text sentiment analysis has obtained
academic and industrial attention in recent years. However, multimodal
sentiment analysis is affected by unimodal data bias, e.g., text sentiment is
misleading due to explicit sentiment semantic, leading to low accuracy in the
final sentiment classification. In this paper, we propose a novel
CounterFactual Multimodal Sentiment Analysis framework (CF-MSA) using causal
counterfactual inference to construct multimodal sentiment causal inference.
CF-MSA mitigates the direct effect from unimodal bias and ensures heterogeneity
across modalities by differentiating the treatment variables between
modalities. In addition, considering the information complementarity and bias
differences between modalities, we propose a new optimisation objective to
effectively integrate different modalities and reduce the inherent bias from
each modality. Experimental results on two public datasets, MVSA-Single and
MVSA-Multiple, demonstrate that the proposed CF-MSA has superior debiasing
capability and achieves new state-of-the-art performances. We will release the
code and datasets to facilitate future research.",2024-12-10,"Fuhai Chen, Pengpeng Huang, Xuri Ge, Jie Huang, Zishuo Bao",http://arxiv.org/pdf/2412.07292v1,cs.CL
Enhancing Relation Extraction via Supervised Rationale Verification and Feedback,"Despite the rapid progress that existing automated feedback methods have made
in correcting the output of large language models (LLMs), these methods cannot
be well applied to the relation extraction (RE) task due to their designated
feedback objectives and correction manner. To address this problem, we propose
a novel automated feedback framework for RE, which presents a rationale
supervisor to verify the rationale and provides re-selected demonstrations as
feedback to correct the initial prediction. Specifically, we first design a
causal intervention and observation method to collect biased/unbiased
rationales for contrastive training the rationale supervisor. Then, we present
a verification-feedback-correction procedure to iteratively enhance LLMs'
capability of handling the RE task. Extensive experiments prove that our
proposed framework significantly outperforms existing methods.",2024-12-10,"Yongqi Li, Xin Miao, Shen Zhou, Mayi Xu, Yuyang Ren, Tieyun Qian",http://arxiv.org/pdf/2412.07289v2,cs.CL
HARP: Hesitation-Aware Reframing in Transformer Inference Pass,"This paper aims to improve the performance of large language models by
addressing the variable computational demands in inference steps, where some
tokens require more computational resources than others. We present HARP, a
simple modification to ""off-the-shelf"" Transformer forward pass. Drawing from
hesitation and the framing effect in decision-making, HARP selectively applies
additional computation when the model encounters uncertainty during token
generation. Our method mimics human cognitive processes by pausing at difficult
decision points and reframing inputs for a different perspective. Unlike other
approaches, HARP is model-agnostic, training-free, and easy to implement. We
evaluate our method across various downstream tasks and model sizes,
demonstrating performance improvements up to +5.16%. Notably, HARP achieves
these gains while maintaining inference times twice faster than beam search.
Simple and yet with significant gains, HARP provides insights into the
potential of adaptive computation for enhancing the performance of
Transformer-based language models.",2024-12-10,"Romain Storaï, Seung-won Hwang",http://arxiv.org/pdf/2412.07282v2,cs.CL
Label-Confidence-Aware Uncertainty Estimation in Natural Language Generation,"Large Language Models (LLMs) display formidable capabilities in generative
tasks but also pose potential risks due to their tendency to generate
hallucinatory responses. Uncertainty Quantification (UQ), the evaluation of
model output reliability, is crucial for ensuring the safety and robustness of
AI systems. Recent studies have concentrated on model uncertainty by analyzing
the relationship between output entropy under various sampling conditions and
the corresponding labels. However, these methods primarily focus on measuring
model entropy with precision to capture response characteristics, often
neglecting the uncertainties associated with greedy decoding results-the
sources of model labels, which can lead to biased classification outcomes. In
this paper, we explore the biases introduced by greedy decoding and propose a
label-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler
(KL) divergence bridging between samples and label source, thus enhancing the
reliability and stability of uncertainty assessments. Our empirical evaluations
across a range of popular LLMs and NLP datasets reveal that different label
sources can indeed affect classification, and that our approach can effectively
capture differences in sampling results and label sources, demonstrating more
effective uncertainty estimation.",2024-12-10,"Qinhong Lin, Linna Zhou, Zhongliang Yang, Yuang Cai",http://arxiv.org/pdf/2412.07255v1,cs.CL
KULTURE Bench: A Benchmark for Assessing Language Model in Korean Cultural Context,"Large language models have exhibited significant enhancements in performance
across various tasks. However, the complexity of their evaluation increases as
these models generate more fluent and coherent content. Current multilingual
benchmarks often use translated English versions, which may incorporate Western
cultural biases that do not accurately assess other languages and cultures. To
address this research gap, we introduce KULTURE Bench, an evaluation framework
specifically designed for Korean culture that features datasets of cultural
news, idioms, and poetry. It is designed to assess language models' cultural
comprehension and reasoning capabilities at the word, sentence, and paragraph
levels. Using the KULTURE Bench, we assessed the capabilities of models trained
with different language corpora and analyzed the results comprehensively. The
results show that there is still significant room for improvement in the
models' understanding of texts related to the deeper aspects of Korean culture.",2024-12-10,"Xiaonan Wang, Jinyoung Yeo, Joon-Ho Lim, Hansaem Kim",http://arxiv.org/pdf/2412.07251v1,cs.CL
Filling Memory Gaps: Enhancing Continual Semantic Parsing via SQL Syntax Variance-Guided LLMs without Real Data Replay,"Continual Semantic Parsing (CSP) aims to train parsers to convert natural
language questions into SQL across tasks with limited annotated examples,
adapting to the real-world scenario of dynamically updated databases. Previous
studies mitigate this challenge by replaying historical data or employing
parameter-efficient tuning (PET), but they often violate data privacy or rely
on ideal continual learning settings. To address these problems, we propose a
new Large Language Model (LLM)-Enhanced Continuous Semantic Parsing method,
named LECSP, which alleviates forgetting while encouraging generalization,
without requiring real data replay or ideal settings. Specifically, it first
analyzes the commonalities and differences between tasks from the SQL syntax
perspective to guide LLMs in reconstructing key memories and improving memory
accuracy through a calibration strategy. Then, it uses a task-aware
dual-teacher distillation framework to promote the accumulation and transfer of
knowledge during sequential training. Experimental results on two CSP
benchmarks show that our method significantly outperforms existing methods,
even those utilizing data replay or ideal settings. Additionally, we achieve
generalization performance beyond the upper limits, better adapting to unseen
tasks.",2024-12-10,"Ruiheng Liu, Jinyu Zhang, Yanqi Song, Yu Zhang, Bailong Yang",http://arxiv.org/pdf/2412.07246v1,cs.CL
Speaker effects in spoken language comprehension,"The identity of a speaker significantly influences spoken language
comprehension by affecting both perception and expectation. This review
explores speaker effects, focusing on how speaker information impacts language
processing. We propose an integrative model featuring the interplay between
bottom-up perception-based processes driven by acoustic details and top-down
expectation-based processes driven by a speaker model. The acoustic details
influence lower-level perception, while the speaker model modulates both
lower-level and higher-level processes such as meaning interpretation and
pragmatic inferences. We define speaker-idiosyncrasy and speaker-demographics
effects and demonstrate how bottom-up and top-down processes interact at
various levels in different scenarios. This framework contributes to
psycholinguistic theory by offering a comprehensive account of how speaker
information interacts with linguistic content to shape message construction. We
suggest that speaker effects can serve as indices of a language learner's
proficiency and an individual's characteristics of social cognition. We
encourage future research to extend these findings to AI speakers, probing the
universality of speaker effects across humans and artificial agents.",2024-12-10,"Hanlin Wu, Zhenguang G. Cai",http://arxiv.org/pdf/2412.07238v1,cs.CL
Comateformer: Combined Attention Transformer for Semantic Sentence Matching,"The Transformer-based model have made significant strides in semantic
matching tasks by capturing connections between phrase pairs. However, to
assess the relevance of sentence pairs, it is insufficient to just examine the
general similarity between the sentences. It is crucial to also consider the
tiny subtleties that differentiate them from each other. Regrettably, attention
softmax operations in transformers tend to miss these subtle differences. To
this end, in this work, we propose a novel semantic sentence matching model
named Combined Attention Network based on Transformer model (Comateformer). In
Comateformer model, we design a novel transformer-based quasi-attention
mechanism with compositional properties. Unlike traditional attention
mechanisms that merely adjust the weights of input tokens, our proposed method
learns how to combine, subtract, or resize specific vectors when building a
representation. Moreover, our proposed approach builds on the intuition of
similarity and dissimilarity (negative affinity) when calculating dual affinity
scores. This allows for a more meaningful representation of relationships
between sentences. To evaluate the performance of our proposed model, we
conducted extensive experiments on ten public real-world datasets and
robustness testing. Experimental results show that our method achieves
consistent improvements.",2024-12-10,"Bo Li, Di Liang, Zixin Zhang",http://arxiv.org/pdf/2412.07220v1,cs.CL
MAPLE: A Framework for Active Preference Learning Guided by Large Language Models,"The advent of large language models (LLMs) has sparked significant interest
in using natural language for preference learning. However, existing methods
often suffer from high computational burdens, taxing human supervision, and
lack of interpretability. To address these issues, we introduce MAPLE, a
framework for large language model-guided Bayesian active preference learning.
MAPLE leverages LLMs to model the distribution over preference functions,
conditioning it on both natural language feedback and conventional preference
learning feedback, such as pairwise trajectory rankings. MAPLE also employs
active learning to systematically reduce uncertainty in this distribution and
incorporates a language-conditioned active query selection mechanism to
identify informative and easy-to-answer queries, thus reducing human burden. We
evaluate MAPLE's sample efficiency and preference inference quality across two
benchmarks, including a real-world vehicle route planning benchmark using
OpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning
process and effectively improves humans' ability to answer queries.",2024-12-10,"Saaduddin Mahmud, Mason Nakamura, Shlomo Zilberstein",http://arxiv.org/pdf/2412.07207v2,cs.CL
Multi-Response Preference Optimization with Augmented Ranking Dataset,"Recent advancements in Large Language Models (LLMs) have been remarkable,
with new models consistently surpassing their predecessors. These advancements
are underpinned by extensive research on various training mechanisms. Among
these, Preference Optimization has played a significant role in improving the
performance of LLMs by incorporating human preferences into the training
process. However, constructing preference optimization datasets is challenging
and the optimization process is highly sensitive to the dataset quality. In
this study, we propose a novel approach to augment Preference Optimization
datasets. Additionally, we introduce a Multi-response-based Preference
Optimization training method that enables the simultaneous learning of multiple
responses.",2024-12-10,"Hansle Gwon, Imjin Ahn, Young-Hak Kim, Sanghyun Park, Tae Joon Jun",http://arxiv.org/pdf/2412.07812v1,cs.CL
A Review on the Applications of Transformer-based language models for Nucleotide Sequence Analysis,"In recent times, Transformer-based language models are making quite an impact
in the field of natural language processing. As relevant parallels can be drawn
between biological sequences and natural languages, the models used in NLP can
be easily extended and adapted for various applications in bioinformatics. In
this regard, this paper introduces the major developments of Transformer-based
models in the recent past in the context of nucleotide sequences. We have
reviewed and analysed a large number of application-based papers on this
subject, giving evidence of the main characterizing features and to different
approaches that may be adopted to customize such powerful computational
machines. We have also provided a structured description of the functioning of
Transformers, that may enable even first time users to grab the essence of such
complex architectures. We believe this review will help the scientific
community in understanding the various applications of Transformer-based
language models to nucleotide sequences. This work will motivate the readers to
build on these methodologies to tackle also various other problems in the field
of bioinformatics.",2024-12-10,"Nimisha Ghosh, Daniele Santoni, Indrajit Saha, Giovanni Felici",http://arxiv.org/pdf/2412.07201v1,cs.CL
"Modifying AI, Enhancing Essays: How Active Engagement with Generative AI Boosts Writing Quality","Students are increasingly relying on Generative AI (GAI) to support their
writing-a key pedagogical practice in education. In GAI-assisted writing,
students can delegate core cognitive tasks (e.g., generating ideas and turning
them into sentences) to GAI while still producing high-quality essays. This
creates new challenges for teachers in assessing and supporting student
learning, as they often lack insight into whether students are engaging in
meaningful cognitive processes during writing or how much of the essay's
quality can be attributed to those processes. This study aimed to help teachers
better assess and support student learning in GAI-assisted writing by examining
how different writing behaviors, especially those indicative of meaningful
learning versus those that are not, impact essay quality. Using a dataset of
1,445 GAI-assisted writing sessions, we applied the cutting-edge method,
X-Learner, to quantify the causal impact of three GAI-assisted writing
behavioral patterns (i.e., seeking suggestions but not accepting them, seeking
suggestions and accepting them as they are, and seeking suggestions and
accepting them with modification) on four measures of essay quality (i.e.,
lexical sophistication, syntactic complexity, text cohesion, and linguistic
bias). Our analysis showed that writers who frequently modified GAI-generated
text-suggesting active engagement in higher-order cognitive
processes-consistently improved the quality of their essays in terms of lexical
sophistication, syntactic complexity, and text cohesion. In contrast, those who
often accepted GAI-generated text without changes, primarily engaging in
lower-order processes, saw a decrease in essay quality. Additionally, while
human writers tend to introduce linguistic bias when writing independently,
incorporating GAI-generated text-even without modification-can help mitigate
this bias.",2024-12-10,"Kaixun Yang, Mladen Raković, Zhiping Liang, Lixiang Yan, Zijie Zeng, Yizhou Fan, Dragan Gašević, Guanliang Chen",http://arxiv.org/pdf/2412.07200v1,cs.CL
PrisonBreak: Jailbreaking Large Language Models with Fewer Than Twenty-Five Targeted Bit-flips,"We introduce a new class of attacks on commercial-scale (human-aligned)
language models that induce jailbreaking through targeted bitwise corruptions
in model parameters. Our adversary can jailbreak billion-parameter language
models with fewer than 25 bit-flips in all cases$-$and as few as 5 in
some$-$using up to 40$\times$ less bit-flips than existing attacks on computer
vision models at least 100$\times$ smaller. Unlike prompt-based jailbreaks, our
attack renders these models in memory 'uncensored' at runtime, allowing them to
generate harmful responses without any input modifications. Our attack
algorithm efficiently identifies target bits to flip, offering up to 20$\times$
more computational efficiency than previous methods. This makes it practical
for language models with billions of parameters. We show an end-to-end
exploitation of our attack using software-induced fault injection, Rowhammer
(RH). Our work examines 56 DRAM RH profiles from DDR4 and LPDDR4X devices with
different RH vulnerabilities. We show that our attack can reliably induce
jailbreaking in systems similar to those affected by prior bit-flip attacks.
Moreover, our approach remains effective even against highly RH-secure systems
(e.g., 46$\times$ more secure than previously tested systems). Our analyses
further reveal that: (1) models with less post-training alignment require fewer
bit flips to jailbreak; (2) certain model components, such as value projection
layers, are substantially more vulnerable than others; and (3) our method is
mechanistically different than existing jailbreaks. Our findings highlight a
pressing, practical threat to the language model ecosystem and underscore the
need for research to protect these models from bit-flip attacks.",2024-12-10,"Zachary Coalson, Jeonghyun Woo, Shiyang Chen, Yu Sun, Lishan Yang, Prashant Nair, Bo Fang, Sanghyun Hong",http://arxiv.org/pdf/2412.07192v1,cs.CL
Breaking the Stage Barrier: A Novel Single-Stage Approach to Long Context Extension for Large Language Models,"Recently, Large language models (LLMs) have revolutionized Natural Language
Processing (NLP). Pretrained LLMs, due to limited training context size,
struggle with handling long token sequences, limiting their performance on
various downstream tasks. Current solutions toward long context modeling often
employ multi-stage continual pertaining, which progressively increases the
effective context length through several continual pretraining stages. However,
those approaches require extensive manual tuning and human expertise. In this
paper, we introduce a novel single-stage continual pretraining method,
Head-Adaptive Rotary Position Encoding (HARPE), to equip LLMs with long context
modeling capabilities while simplifying the training process. Our HARPE
leverages different Rotary Position Encoding (RoPE) base frequency values
across different attention heads and directly trains LLMs on the target context
length. Extensive experiments on 4 language modeling benchmarks, including the
latest RULER benchmark, demonstrate that HARPE excels in understanding and
integrating long-context tasks with single-stage training, matching and even
outperforming existing multi-stage methods. Our results highlight that HARPE
successfully breaks the stage barrier for training LLMs with long context
modeling capabilities.",2024-12-10,"Haoran Lian, Junmin Chen, Wei Huang, Yizhe Xiong, Wenping Hu, Guiguang Ding, Hui Chen, Jianwei Niu, Zijia Lin, Fuzheng Zhang, Di Zhang",http://arxiv.org/pdf/2412.07171v1,cs.CL
MM-PoE: Multiple Choice Reasoning via. Process of Elimination using Multi-Modal Models,"This paper introduces Multiple Choice Reasoning via. Process of Elimination
using Multi-Modal models, herein referred to as Multi-Modal Process of
Elimination (MM-PoE). This novel methodology is engineered to augment the
efficacy of Vision-Language Models (VLMs) in multiple-choice visual reasoning
tasks. Diverging from conventional approaches that evaluate each option
independently, MM-PoE employs a dual-step scoring paradigm that initially
identifies and excludes implausible choices, subsequently concentrating on the
most probable remaining options. This method emulates human test-taking
strategies, where individuals typically eliminate clearly incorrect answers
prior to selecting the optimal response. Our empirical evaluations, conducted
across three benchmark datasets, reveal that MM-PoE significantly improves both
zero-shot and few-shot performance of contemporary state-of-the-art VLMs.
Critically, this approach not only broadens the application of the elimination
process to multi-modal contexts but also allows few-shot experiments, thereby
addressing two principal limitations concerning usage of PoE only in zero-shot
settings and only with a language-only framework. As a result, MM-PoE not only
refines the reasoning capabilities of VLMs but also broadens their
applicability to complex visual question-answering scenarios. All code and
documentation supporting our work are available at
https://pypi.org/project/mm-poe/, enabling researchers and practitioners to
easily integrate and further develop these techniques.",2024-12-10,"Sayak Chakrabarty, Souradip Pal",http://arxiv.org/pdf/2412.07148v1,cs.CL
Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models,"Predicting roll call votes through modeling political actors has emerged as a
focus in quantitative political science and computer science. Widely used
embedding-based methods generate vectors for legislators from diverse data sets
to predict legislative behaviors. However, these methods often contend with
challenges such as the need for manually predefined features, reliance on
extensive training data, and a lack of interpretability. Achieving more
interpretable predictions under flexible conditions remains an unresolved
issue. This paper introduces the Political Actor Agent (PAA), a novel
agent-based framework that utilizes Large Language Models to overcome these
limitations. By employing role-playing architectures and simulating legislative
system, PAA provides a scalable and interpretable paradigm for predicting
roll-call votes. Our approach not only enhances the accuracy of predictions but
also offers multi-view, human-understandable decision reasoning, providing new
insights into political actor behaviors. We conducted comprehensive experiments
using voting records from the 117-118th U.S. House of Representatives,
validating the superior performance and interpretability of PAA. This study not
only demonstrates PAA's effectiveness but also its potential in political
science research.",2024-12-10,"Hao Li, Ruoyuan Gong, Hao Jiang",http://arxiv.org/pdf/2412.07144v2,cs.CL
Bridging the Gap for Test-Time Multimodal Sentiment Analysis,"Multimodal sentiment analysis (MSA) is an emerging research topic that aims
to understand and recognize human sentiment or emotions through multiple
modalities. However, in real-world dynamic scenarios, the distribution of
target data is always changing and different from the source data used to train
the model, which leads to performance degradation. Common adaptation methods
usually need source data, which could pose privacy issues or storage overheads.
Therefore, test-time adaptation (TTA) methods are introduced to improve the
performance of the model at inference time. Existing TTA methods are always
based on probabilistic models and unimodal learning, and thus can not be
applied to MSA which is often considered as a multimodal regression task. In
this paper, we propose two strategies: Contrastive Adaptation and Stable
Pseudo-label generation (CASP) for test-time adaptation for multimodal
sentiment analysis. The two strategies deal with the distribution shifts for
MSA by enforcing consistency and minimizing empirical risk, respectively.
Extensive experiments show that CASP brings significant and consistent
improvements to the performance of the model across various distribution shift
settings and with different backbones, demonstrating its effectiveness and
versatility. Our codes are available at https://github.com/zrguo/CASP.",2024-12-10,"Zirun Guo, Tao Jin, Wenlong Xu, Wang Lin, Yangyang Wu",http://arxiv.org/pdf/2412.07121v2,cs.CL
A Review of Human Emotion Synthesis Based on Generative Technology,"Human emotion synthesis is a crucial aspect of affective computing. It
involves using computational methods to mimic and convey human emotions through
various modalities, with the goal of enabling more natural and effective
human-computer interactions. Recent advancements in generative models, such as
Autoencoders, Generative Adversarial Networks, Diffusion Models, Large Language
Models, and Sequence-to-Sequence Models, have significantly contributed to the
development of this field. However, there is a notable lack of comprehensive
reviews in this field. To address this problem, this paper aims to address this
gap by providing a thorough and systematic overview of recent advancements in
human emotion synthesis based on generative models. Specifically, this review
will first present the review methodology, the emotion models involved, the
mathematical principles of generative models, and the datasets used. Then, the
review covers the application of different generative models to emotion
synthesis based on a variety of modalities, including facial images, speech,
and text. It also examines mainstream evaluation metrics. Additionally, the
review presents some major findings and suggests future research directions,
providing a comprehensive understanding of the role of generative technology in
the nuanced domain of emotion synthesis.",2024-12-10,"Fei Ma, Yukan Li, Yifan Xie, Ying He, Yi Zhang, Hongwei Ren, Zhou Liu, Wei Yao, Fuji Ren, Fei Richard Yu, Shiguang Ni",http://arxiv.org/pdf/2412.07116v1,cs.CL
Exploring Coding Spot: Understanding Parametric Contributions to LLM Coding Performance,"Large Language Models (LLMs) have demonstrated notable proficiency in both
code generation and comprehension across multiple programming languages.
However, the mechanisms underlying this proficiency remain underexplored,
particularly with respect to whether distinct programming languages are
processed independently or within a shared parametric region. Drawing an
analogy to the specialized regions of the brain responsible for distinct
cognitive functions, we introduce the concept of Coding Spot, a specialized
parametric region within LLMs that facilitates coding capabilities. Our
findings identify this Coding Spot and show that targeted modifications to this
subset significantly affect performance on coding tasks, while largely
preserving non-coding functionalities. This compartmentalization mirrors the
functional specialization observed in cognitive neuroscience, where specific
brain regions are dedicated to distinct tasks, suggesting that LLMs may
similarly employ specialized parameter regions for different knowledge domains.",2024-12-10,"Dongjun Kim, Minhyuk Kim, YongChan Chun, Chanjun Park, Heuiseok Lim",http://arxiv.org/pdf/2412.07113v1,cs.CL
Maya: An Instruction Finetuned Multilingual Multimodal Model,"The rapid development of large Vision-Language Models (VLMs) has led to
impressive results on academic benchmarks, primarily in widely spoken
languages. However, significant gaps remain in the ability of current VLMs to
handle low-resource languages and varied cultural contexts, largely due to a
lack of high-quality, diverse, and safety-vetted data. Consequently, these
models often struggle to understand low-resource languages and cultural nuances
in a manner free from toxicity. To address these limitations, we introduce
Maya, an open-source Multimodal Multilingual model. Our contributions are
threefold: 1) a multilingual image-text pretraining dataset in eight languages,
based on the LLaVA pretraining dataset; 2) a thorough analysis of toxicity
within the LLaVA dataset, followed by the creation of a novel toxicity-free
version across eight languages; and 3) a multilingual image-text model
supporting these languages, enhancing cultural and linguistic comprehension in
vision-language tasks. Code available at https://github.com/nahidalam/maya.",2024-12-10,"Nahid Alam, Karthik Reddy Kanjula, Surya Guthikonda, Timothy Chung, Bala Krishna S Vegesna, Abhipsha Das, Anthony Susevski, Ryan Sze-Yin Chan, S M Iftekhar Uddin, Shayekh Bin Islam, Roshan Santhosh, Snegha A, Drishti Sharma, Chen Liu, Isha Chaturvedi, Genta Indra Winata, Ashvanth. S, Snehanshu Mukherjee, Alham Fikri Aji",http://arxiv.org/pdf/2412.07112v1,cs.CL
Predictable Emergent Abilities of LLMs: Proxy Tasks Are All You Need,"While scaling laws optimize training configurations for large language models
(LLMs) through experiments on smaller or early-stage models, they fail to
predict emergent abilities due to the absence of such capabilities in these
models. To address this, we propose a method that predicts emergent abilities
by leveraging proxy tasks. We begin by establishing relevance metrics between
the target task and candidate tasks based on performance differences across
multiple models. These candidate tasks are then validated for robustness with
small model ensembles, leading to the selection of the most appropriate proxy
tasks. The predicted performance on the target task is then derived by
integrating the evaluation results of these proxies. In a case study on tool
utilization capabilities, our method demonstrated a strong correlation between
predicted and actual performance, confirming its effectiveness.",2024-12-10,"Bo-Wen Zhang, Yan Yan, Boxiang Yang, Yifei Xue, Guang Liu",http://arxiv.org/pdf/2412.07111v1,cs.CL
Improving the Natural Language Inference robustness to hard dataset by data augmentation and preprocessing,"Natural Language Inference (NLI) is the task of inferring whether the
hypothesis can be justified by the given premise. Basically, we classify the
hypothesis into three labels(entailment, neutrality and contradiction) given
the premise. NLI was well studied by the previous researchers. A number of
models, especially the transformer based ones, have achieved significant
improvement on these tasks. However, it is reported that these models are
suffering when they are dealing with hard datasets. Particularly, they perform
much worse when dealing with unseen out-of-distribution premise and hypothesis.
They may not understand the semantic content but learn the spurious
correlations. In this work, we propose the data augmentation and preprocessing
methods to solve the word overlap, numerical reasoning and length mismatch
problems. These methods are general methods that do not rely on the
distribution of the testing data and they help improve the robustness of the
models.",2024-12-10,Zijiang Yang,http://arxiv.org/pdf/2412.07108v1,cs.CL
Personalized and Sequential Text-to-Image Generation,"We address the problem of personalized, interactive text-to-image (T2I)
generation, designing a reinforcement learning (RL) agent which iteratively
improves a set of generated images for a user through a sequence of prompt
expansions. Using human raters, we create a novel dataset of sequential
preferences, which we leverage, together with large-scale open-source
(non-sequential) datasets. We construct user-preference and user-choice models
using an EM strategy and identify varying user preference types. We then
leverage a large multimodal language model (LMM) and a value-based RL approach
to suggest a personalized and diverse slate of prompt expansions to the user.
Our Personalized And Sequential Text-to-image Agent (PASTA) extends T2I models
with personalized multi-turn capabilities, fostering collaborative co-creation
and addressing uncertainty or underspecification in a user's intent. We
evaluate PASTA using human raters, showing significant improvement compared to
baseline methods. We also release our sequential rater dataset and simulated
user-rater interactions to support future research in personalized, multi-turn
T2I generation.",2024-12-10,"Ofir Nabati, Guy Tennenholtz, ChihWei Hsu, Moonkyung Ryu, Deepak Ramachandran, Yinlam Chow, Xiang Li, Craig Boutilier",http://arxiv.org/pdf/2412.10419v1,cs.CL
QAPyramid: Fine-grained Evaluation of Content Selection for Text Summarization,"How to properly conduct human evaluations for text summarization is a
longstanding challenge. The Pyramid human evaluation protocol, which assesses
content selection by breaking the reference summary into sub-units and
verifying their presence in the system summary, has been widely adopted.
However, it suffers from a lack of systematicity in the definition and
granularity of the sub-units. We address these problems by proposing QAPyramid,
which decomposes each reference summary into finer-grained question-answer (QA)
pairs according to the QA-SRL framework. We collect QA-SRL annotations for
reference summaries from CNN/DM and evaluate 10 summarization systems,
resulting in 8.9K QA-level annotations. We show that, compared to Pyramid,
QAPyramid provides more systematic and fine-grained content selection
evaluation while maintaining high inter-annotator agreement without needing
expert annotations. Furthermore, we propose metrics that automate the
evaluation pipeline and achieve higher correlations with QAPyramid than other
widely adopted metrics, allowing future work to accurately and efficiently
benchmark summarization systems.",2024-12-10,"Shiyue Zhang, David Wan, Arie Cattan, Ayal Klein, Ido Dagan, Mohit Bansal",http://arxiv.org/pdf/2412.07096v1,cs.CL
Defensive Dual Masking for Robust Adversarial Defense,"The field of textual adversarial defenses has gained considerable attention
in recent years due to the increasing vulnerability of natural language
processing (NLP) models to adversarial attacks, which exploit subtle
perturbations in input text to deceive models. This paper introduces the
Defensive Dual Masking (DDM) algorithm, a novel approach designed to enhance
model robustness against such attacks. DDM utilizes a unique adversarial
training strategy where [MASK] tokens are strategically inserted into training
samples to prepare the model to handle adversarial perturbations more
effectively. During inference, potentially adversarial tokens are dynamically
replaced with [MASK] tokens to neutralize potential threats while preserving
the core semantics of the input. The theoretical foundation of our approach is
explored, demonstrating how the selective masking mechanism strengthens the
model's ability to identify and mitigate adversarial manipulations. Our
empirical evaluation across a diverse set of benchmark datasets and attack
mechanisms consistently shows that DDM outperforms state-of-the-art defense
techniques, improving model accuracy and robustness. Moreover, when applied to
Large Language Models (LLMs), DDM also enhances their resilience to adversarial
attacks, providing a scalable defense mechanism for large-scale NLP
applications.",2024-12-10,"Wangli Yang, Jie Yang, Yi Guo, Johan Barthelemy",http://arxiv.org/pdf/2412.07078v1,cs.CL
Harnessing Transfer Learning from Swahili: Advancing Solutions for Comorian Dialects,"If today some African languages like Swahili have enough resources to develop
high-performing Natural Language Processing (NLP) systems, many other languages
spoken on the continent are still lacking such support. For these languages,
still in their infancy, several possibilities exist to address this critical
lack of data. Among them is Transfer Learning, which allows low-resource
languages to benefit from the good representation of other languages that are
similar to them. In this work, we adopt a similar approach, aiming to pioneer
NLP technologies for Comorian, a group of four languages or dialects belonging
to the Bantu family.
  Our approach is initially motivated by the hypothesis that if a human can
understand a different language from their native language with little or no
effort, it would be entirely possible to model this process on a machine. To
achieve this, we consider ways to construct Comorian datasets mixed with
Swahili. One thing to note here is that in terms of Swahili data, we only focus
on elements that are closest to Comorian by calculating lexical distances
between candidate and source data. We empirically test this hypothesis in two
use cases: Automatic Speech Recognition (ASR) and Machine Translation (MT). Our
MT model achieved ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.6826, 0.42, and
0.6532, respectively, while our ASR system recorded a WER of 39.50\% and a CER
of 13.76\%. This research is crucial for advancing NLP in underrepresented
languages, with potential to preserve and promote Comorian linguistic heritage
in the digital age.",2024-12-09,"Naira Abdou Mohamed, Zakarya Erraji, Abdessalam Bahafid, Imade Benelallam",http://arxiv.org/pdf/2412.12143v1,cs.CL
FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge Distillation for Question Answering,"Multimodal multihop question answering (MMQA) requires reasoning over images
and text from multiple sources. Despite advances in visual question answering,
this multihop setting remains underexplored due to a lack of quality datasets.
Existing methods focus on single-hop, single-modality, or short texts, limiting
real-world applications like interpreting educational documents with long,
multimodal content. To fill this gap, we introduce FM2DS, the first framework
for creating a high-quality dataset for MMQA. Our approach consists of a
5-stage pipeline that involves acquiring relevant multimodal documents from
Wikipedia, synthetically generating high-level questions and answers, and
validating them through rigorous criteria to ensure data quality. We evaluate
our methodology by training models on our synthesized dataset and testing on
two benchmarks: MultimodalQA and WebQA. Our results demonstrate that, with an
equal sample size, models trained on our synthesized data outperform those
trained on human-collected data by 1.9 in exact match (EM) score on average.
Additionally, we introduce M2QA-Bench with 1k samples, the first benchmark for
MMQA on long documents, generated using FM2DS and refined by human annotators.
We believe our data synthesis method will serve as a strong foundation for
training and evaluating MMQA models.",2024-12-09,"Amirhossein Abaskohi, Spandana Gella, Giuseppe Carenini, Issam H. Laradji",http://arxiv.org/pdf/2412.07030v4,cs.CL
Constrained Decoding with Speculative Lookaheads,"Constrained decoding with lookahead heuristics (CDLH) is a highly effective
method for aligning LLM generations to human preferences. However, the
extensive lookahead roll-out operations for each generated token makes CDLH
prohibitively expensive, resulting in low adoption in practice. In contrast,
common decoding strategies such as greedy decoding are extremely efficient, but
achieve very low constraint satisfaction. We propose constrained decoding with
speculative lookaheads (CDSL), a technique that significantly improves upon the
inference efficiency of CDLH without experiencing the drastic performance
reduction seen with greedy decoding. CDSL is motivated by the recently proposed
idea of speculative decoding that uses a much smaller draft LLM for generation
and a larger target LLM for verification. In CDSL, the draft model is used to
generate lookaheads which is verified by a combination of target LLM and
task-specific reward functions. This process accelerates decoding by reducing
the computational burden while maintaining strong performance. We evaluate CDSL
in two constraint decoding tasks with three LLM families and achieve 2.2x to
12.15x speedup over CDLH without significant performance reduction.",2024-12-09,"Nishanth Nakshatri, Shamik Roy, Rajarshi Das, Suthee Chaidaroon, Leonid Boytsov, Rashmi Gangadharaiah",http://arxiv.org/pdf/2412.10418v2,cs.CL
Assessing the Impact of Conspiracy Theories Using Large Language Models,"Measuring the relative impact of CTs is important for prioritizing responses
and allocating resources effectively, especially during crises. However,
assessing the actual impact of CTs on the public poses unique challenges. It
requires not only the collection of CT-specific knowledge but also diverse
information from social, psychological, and cultural dimensions. Recent
advancements in large language models (LLMs) suggest their potential utility in
this context, not only due to their extensive knowledge from large training
corpora but also because they can be harnessed for complex reasoning. In this
work, we develop datasets of popular CTs with human-annotated impacts.
Borrowing insights from human impact assessment processes, we then design
tailored strategies to leverage LLMs for performing human-like CT impact
assessments. Through rigorous experiments, we textit{discover that an impact
assessment mode using multi-step reasoning to analyze more CT-related evidence
critically produces accurate results; and most LLMs demonstrate strong bias,
such as assigning higher impacts to CTs presented earlier in the prompt, while
generating less accurate impact assessments for emotionally charged and verbose
CTs.",2024-12-09,"Bohan Jiang, Dawei Li, Zhen Tan, Xinyi Zhou, Ashwin Rao, Kristina Lerman, H. Russell Bernard, Huan Liu",http://arxiv.org/pdf/2412.07019v1,cs.CL
Asynchronous LLM Function Calling,"Large language models (LLMs) use function calls to interface with external
tools and data source. However, the current approach to LLM function calling is
inherently synchronous, where each call blocks LLM inference, limiting LLM
operation and concurrent function execution. In this work, we propose AsyncLM,
a system for asynchronous LLM function calling. AsyncLM improves LLM's
operational efficiency by enabling LLMs to generate and execute function calls
concurrently. Instead of waiting for each call's completion, AsyncLM introduces
an interrupt mechanism to asynchronously notify the LLM in-flight when function
calls return. We design an in-context protocol for function calls and
interrupts, provide fine-tuning strategy to adapt LLMs to the interrupt
semantics, and implement these mechanisms efficiently on LLM inference process.
We demonstrate that AsyncLM can reduce end-to-end task completion latency from
1.6x-5.4x compared to synchronous function calling on a set of benchmark tasks
in the Berkeley function calling leaderboard (BFCL). Furthermore, we discuss
how interrupt mechanisms can be extended to enable novel human-LLM or LLM-LLM
interactions.",2024-12-09,"In Gim, Seung-seob Lee, Lin Zhong",http://arxiv.org/pdf/2412.07017v1,cs.CL
Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance,"Mental health disorders are increasingly prevalent worldwide, creating an
urgent need for innovative tools to support early diagnosis and intervention.
This study explores the potential of Large Language Models (LLMs) in multimodal
mental health diagnostics, specifically for detecting depression and Post
Traumatic Stress Disorder through text and audio modalities. Using the E-DAIC
dataset, we compare text and audio modalities to investigate whether LLMs can
perform equally well or better with audio inputs. We further examine the
integration of both modalities to determine if this can enhance diagnostic
accuracy, which generally results in improved performance metrics. Our analysis
specifically utilizes custom-formulated metrics; Modal Superiority Score and
Disagreement Resolvement Score to evaluate how combined modalities influence
model performance. The Gemini 1.5 Pro model achieves the highest scores in
binary depression classification when using the combined modality, with an F1
score of 0.67 and a Balanced Accuracy (BA) of 77.4%, assessed across the full
dataset. These results represent an increase of 3.1% over its performance with
the text modality and 2.7% over the audio modality, highlighting the
effectiveness of integrating modalities to enhance diagnostic accuracy.
Notably, all results are obtained in zero-shot inferring, highlighting the
robustness of the models without requiring task-specific fine-tuning. To
explore the impact of different configurations on model performance, we conduct
binary, severity, and multiclass tasks using both zero-shot and few-shot
prompts, examining the effects of prompt variations on performance. The results
reveal that models such as Gemini 1.5 Pro in text and audio modalities, and
GPT-4o mini in the text modality, often surpass other models in balanced
accuracy and F1 scores across multiple tasks.",2024-12-09,"Abdelrahman A. Ali, Aya E. Fouda, Radwa J. Hanafy, Mohammed E. Fouda",http://arxiv.org/pdf/2412.10417v1,cs.CL
AutoReason: Automatic Few-Shot Reasoning Decomposition,"Chain of Thought (CoT) was introduced in recent research as a method for
improving step-by-step reasoning in Large Language Models. However, CoT has
limited applications such as its need for hand-crafted few-shot exemplar
prompts and no capability to adjust itself to different queries.
  In this work, we propose a system to automatically generate rationales using
CoT. Our method improves multi-step implicit reasoning capabilities by
decomposing the implicit query into several explicit questions. This provides
interpretability for the model, improving reasoning in weaker LLMs. We test our
approach with two Q\&A datasets: StrategyQA and HotpotQA. We show an increase
in accuracy with both, especially on StrategyQA.
  To facilitate further research in this field, the complete source code for
this study has been made publicly available on GitHub:
https://github.com/miralab-ai/autoreason.",2024-12-09,"Arda Sevinc, Abdurrahman Gumus",http://arxiv.org/pdf/2412.06975v1,cs.CL
Leveraging Sentiment for Offensive Text Classification,"In this paper, we conduct experiment to analyze whether models can classify
offensive texts better with the help of sentiment. We conduct this experiment
on the SemEval 2019 task 6, OLID, dataset. First, we utilize pre-trained
language models to predict the sentiment of each instance. Later we pick the
model that achieved the best performance on the OLID test set, and train it on
the augmented OLID set to analyze the performance. Results show that utilizing
sentiment increases the overall performance of the model.",2024-12-09,Khondoker Ittehadul Islam,http://arxiv.org/pdf/2412.17825v1,cs.CL
Effective Text Adaptation for LLM-based ASR through Soft Prompt Fine-Tuning,"The advent of Large Language Models (LLM) has reformed the Automatic Speech
Recognition (ASR). Prompting LLM with audio embeddings to generate
transcriptions becomes the new state-of-the-art ASR. Despite LLMs being trained
with an extensive amount of text corpora, high-quality domain-specific text
data can still significantly enhance ASR performance on domain adaptation
tasks. Although LLM-based ASR can naturally incorporate more text corpora by
fine-tuning the LLM decoder, fine-tuning such ASR on text-only data without
paired prompts may diminish the effectiveness of domain-specific knowledge. To
mitigate this issue, we propose a two-step soft prompt fine-tuning strategy
that enhances domain-specific text adaptation. Experimental results show that
text adaptation with our proposed method achieved a relative up to 9% Word
Error Rate (WER) reduction and up to 18% Entity Error Rate (EER) reduction on
the target domain compared to the baseline ASR. Combining this with
domain-specific Language Model (LM) fusion can further improve the EER by a
relative 2-5%",2024-12-09,"Yingyi Ma, Zhe Liu, Ozlem Kalinli",http://arxiv.org/pdf/2412.06967v1,cs.CL
SuperMerge: An Approach For Gradient-Based Model Merging,"Large language models, such as ChatGPT, Claude, or LLaMA, are gigantic,
monolithic, and possess the superpower to simultaneously support thousands of
tasks. However, high-throughput applications often prefer smaller task-specific
models because of their lower latency and cost. One challenge of using
task-specific models is the incremental need for solving newer tasks after the
model is already deployed for existing tasks. A straightforward solution
requires fine-tuning the model again for both existing and new tasks, which is
computationally expensive and time-consuming. To address this issue, we propose
a model merging based approach called SUPERMERGE. SUPERMERGE is a
gradient-based method to systematically merge several fine-tuned models trained
on existing and new tasks. SUPERMERGE is designed to be lightweight and fast,
and the merged model achieves similar performance to fully fine-tuned models on
all tasks. Furthermore, we proposed a hierarchical model merging strategy to
reduce the peak space requirement without sacrificing the performance of the
merged model. We experimentally demonstrate that SUPERMERGE outperforms
existing model merging methods on common natural language processing and
computer vision tasks.",2024-12-09,"Haoyu Yang, Zheng Zhang, Saket Sathe",http://arxiv.org/pdf/2412.10416v2,cs.CL
Analysing Public Transport User Sentiment on Low Resource Multilingual Data,"Public transport systems in many Sub-Saharan countries often receive less
attention compared to other sectors, underscoring the need for innovative
solutions to improve the Quality of Service (QoS) and overall user experience.
This study explored commuter opinion mining to understand sentiments toward
existing public transport systems in Kenya, Tanzania, and South Africa. We used
a qualitative research design, analysing data from X (formerly Twitter) to
assess sentiments across rail, mini-bus taxis, and buses. By leveraging
Multilingual Opinion Mining techniques, we addressed the linguistic diversity
and code-switching present in our dataset, thus demonstrating the application
of Natural Language Processing (NLP) in extracting insights from
under-resourced languages. We employed PLMs such as AfriBERTa, AfroXLMR,
AfroLM, and PuoBERTa to conduct the sentiment analysis. The results revealed
predominantly negative sentiments in South Africa and Kenya, while the
Tanzanian dataset showed mainly positive sentiments due to the advertising
nature of the tweets. Furthermore, feature extraction using the Word2Vec model
and K-Means clustering illuminated semantic relationships and primary themes
found within the different datasets. By prioritising the analysis of user
experiences and sentiments, this research paves the way for developing more
responsive, user-centered public transport systems in Sub-Saharan countries,
contributing to the broader goal of improving urban mobility and
sustainability.",2024-12-09,"Rozina L. Myoya, Vukosi Marivate, Idris Abdulmumin",http://arxiv.org/pdf/2412.06951v1,cs.CL
When Every Token Counts: Optimal Segmentation for Low-Resource Language Models,"Traditional greedy tokenization methods have been a critical step in Natural
Language Processing (NLP), influencing how text is converted into tokens and
directly impacting model performance. While subword tokenizers like Byte-Pair
Encoding (BPE) are widely used, questions remain about their optimality across
model scales and languages. In this work, we demonstrate through extensive
experiments that an optimal BPE configuration significantly reduces token count
compared to greedy segmentation, yielding improvements in token-saving
percentages and performance benefits, particularly for smaller models. We
evaluate tokenization performance across various intrinsic and extrinsic tasks,
including generation and classification. Our findings suggest that
compression-optimized tokenization strategies could provide substantial
advantages for multilingual and low-resource language applications,
highlighting a promising direction for further research and inclusive NLP.",2024-12-09,"Bharath Raj, Garvit Suri, Vikrant Dewangan, Raghav Sonavane",http://arxiv.org/pdf/2412.06926v5,cs.CL
Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models,"While large vision-language models (LVLMs) have shown impressive capabilities
in generating plausible responses correlated with input visual contents, they
still suffer from hallucinations, where the generated text inaccurately
reflects visual contents. To address this, recent approaches apply contrastive
decoding to calibrate the model's response via contrasting output distributions
with original and visually distorted samples, demonstrating promising
hallucination mitigation in a training-free manner. However, the potential of
changing information in visual inputs is not well-explored, so a deeper
investigation into the behaviors of visual contrastive decoding is of great
interest. In this paper, we first explore various methods for contrastive
decoding to change visual contents, including image downsampling and editing.
Downsampling images reduces the detailed textual information while editing
yields new contents in images, providing new aspects as visual contrastive
samples. To further study benefits by using different contrastive samples, we
analyze probability-level metrics, including entropy and distribution distance.
Interestingly, the effect of these samples in mitigating hallucinations varies
a lot across LVLMs and benchmarks. Based on our analysis, we propose a simple
yet effective method to combine contrastive samples, offering a practical
solution for applying contrastive decoding across various scenarios. Extensive
experiments are conducted to validate the proposed fusion method among
different benchmarks.",2024-12-09,"Yi-Lun Lee, Yi-Hsuan Tsai, Wei-Chen Chiu",http://arxiv.org/pdf/2412.06775v1,cs.CL
Training Large Language Models to Reason in a Continuous Latent Space,"Large language models (LLMs) are restricted to reason in the ""language
space"", where they typically express the reasoning process with a
chain-of-thought (CoT) to solve a complex reasoning problem. However, we argue
that language space may not always be optimal for reasoning. For example, most
word tokens are primarily for textual coherence and not essential for
reasoning, while some critical tokens require complex planning and pose huge
challenges to LLMs. To explore the potential of LLM reasoning in an
unrestricted latent space instead of using natural language, we introduce a new
paradigm Coconut (Chain of Continuous Thought). We utilize the last hidden
state of the LLM as a representation of the reasoning state (termed ""continuous
thought""). Rather than decoding this into a word token, we feed it back to the
LLM as the subsequent input embedding directly in the continuous space.
Experiments show that Coconut can effectively augment the LLM on several
reasoning tasks. This novel latent reasoning paradigm leads to emergent
advanced reasoning patterns: the continuous thought can encode multiple
alternative next reasoning steps, allowing the model to perform a breadth-first
search (BFS) to solve the problem, rather than prematurely committing to a
single deterministic path like CoT. Coconut outperforms CoT in certain logical
reasoning tasks that require substantial backtracking during planning, with
fewer thinking tokens during inference. These findings demonstrate the promise
of latent reasoning and offer valuable insights for future research.",2024-12-09,"Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian",http://arxiv.org/pdf/2412.06769v2,cs.CL
LLMs for Generalizable Language-Conditioned Policy Learning under Minimal Data Requirements,"To develop autonomous agents capable of executing complex, multi-step
decision-making tasks as specified by humans in natural language, existing
reinforcement learning approaches typically require expensive labeled datasets
or access to real-time experimentation. Moreover, conventional methods often
face difficulties in generalizing to unseen goals and states, thereby limiting
their practical applicability. This paper presents TEDUO, a novel training
pipeline for offline language-conditioned policy learning. TEDUO operates on
easy-to-obtain, unlabeled datasets and is suited for the so-called in-the-wild
evaluation, wherein the agent encounters previously unseen goals and states. To
address the challenges posed by such data and evaluation settings, our method
leverages the prior knowledge and instruction-following capabilities of large
language models (LLMs) to enhance the fidelity of pre-collected offline data
and enable flexible generalization to new goals and states. Empirical results
demonstrate that the dual role of LLMs in our framework-as data enhancers and
generalizers-facilitates both effective and data-efficient learning of
generalizable language-conditioned policies.",2024-12-09,"Thomas Pouplin, Katarzyna Kobalczyk, Hao Sun, Mihaela van der Schaar",http://arxiv.org/pdf/2412.06877v1,cs.CL
Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models,"A key component of building safe and reliable language models is enabling the
models to appropriately refuse to follow certain instructions or answer certain
questions. We may want models to output refusal messages for various categories
of user queries, for example, ill-posed questions, instructions for committing
illegal acts, or queries which require information past the model's knowledge
horizon. Engineering models that refuse to answer such questions is complicated
by the fact that an individual may want their model to exhibit varying levels
of sensitivity for refusing queries of various categories, and different users
may want different refusal rates. The current default approach involves
training multiple models with varying proportions of refusal messages from each
category to achieve the desired refusal rates, which is computationally
expensive and may require training a new model to accommodate each user's
desired preference over refusal rates. To address these challenges, we propose
refusal tokens, one such token for each refusal category or a single refusal
token, which are prepended to the model's responses during training. We then
show how to increase or decrease the probability of generating the refusal
token for each category during inference to steer the model's refusal behavior.
Refusal tokens enable controlling a single model's refusal rates without the
need of any further fine-tuning, but only by selectively intervening during
generation.",2024-12-09,"Neel Jain, Aditya Shrivastava, Chenyang Zhu, Daben Liu, Alfy Samuel, Ashwinee Panda, Anoop Kumar, Micah Goldblum, Tom Goldstein",http://arxiv.org/pdf/2412.06748v1,cs.CL
ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities,"Traditional fixed test sets fall short in evaluating open-ended capabilities
of foundation models. To address this, we propose ONEBench(OpeN-Ended
Benchmarking), a new testing paradigm that consolidates individual evaluation
datasets into a unified, ever-expanding sample pool. ONEBench allows users to
generate custom, open-ended evaluation benchmarks from this pool, corresponding
to specific capabilities of interest. By aggregating samples across test sets,
ONEBench enables the assessment of diverse capabilities beyond those covered by
the original test sets, while mitigating overfitting and dataset bias. Most
importantly, it frames model evaluation as a collective process of selecting
and aggregating sample-level tests.
  The shift from task-specific benchmarks to ONEBench introduces two
challenges: (1)heterogeneity and (2)incompleteness. Heterogeneity refers to the
aggregation over diverse metrics, while incompleteness describes comparing
models evaluated on different data subsets. To address these challenges, we
explore algorithms to aggregate sparse measurements into reliable model scores.
Our aggregation algorithm ensures identifiability(asymptotically recovering
ground-truth scores) and rapid convergence, enabling accurate model ranking
with less data. On homogenous datasets, we show our aggregation algorithm
provides rankings that highly correlate with those produced by average scores.
We also demonstrate robustness to ~95% of measurements missing, reducing
evaluation cost by up to 20x with little-to-no change in model rankings. We
introduce ONEBench-LLM for language models and ONEBench-LMM for vision-language
models, unifying evaluations across these domains. Overall, we present a
technique for open-ended evaluation, which can aggregate over incomplete,
heterogeneous sample-level measurements to continually grow a benchmark
alongside the rapidly developing foundation models.",2024-12-09,"Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge",http://arxiv.org/pdf/2412.06745v1,cs.CL
JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset Generation with LLM,"Recently some studies have highlighted the potential of Large Language Models
(LLMs) as effective generators of supervised training data, offering advantages
such as enhanced inference efficiency and reduced costs associated with data
collection. However, these studies have predominantly focused on English
language tasks. In this paper, we address the fundamental research question:
Can LLMs serve as proficient training data generators for other language tasks?
Specifically, we leverage LLMs to synthesize supervised training data under
few-shot and zero-shot learning scenarios across six diverse Japanese
downstream tasks. Subsequently, we utilize this synthesized data to train
compact models (e.g., BERT). This novel methodology is termed JAPAGEN. Our
experimental findings underscore that JAPAGEN achieves robust performance in
classification tasks that necessitate formal text inputs, demonstrating
competitive results compared to conventional LLM prompting strategies.",2024-12-09,"Takuro Fujii, Satoru Katsumata",http://arxiv.org/pdf/2412.06738v1,cs.CL
AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark,"We investigate the reasoning capabilities of large language models (LLMs) for
automatically generating data-cleaning workflows. To evaluate LLMs' ability to
complete data-cleaning tasks, we implemented a pipeline for LLM-based Auto Data
Cleaning Workflow (AutoDCWorkflow), prompting LLMs on data cleaning operations
to repair three types of data quality issues: duplicates, missing values, and
inconsistent data formats. Given a dirty table and a purpose (expressed as a
query), this pipeline generates a minimal, clean table sufficient to address
the purpose and the data cleaning workflow used to produce the table. The
planning process involves three main LLM-driven components: (1) Select Target
Columns: Identifies a set of target columns related to the purpose. (2) Inspect
Column Quality: Assesses the data quality for each target column and generates
a Data Quality Report as operation objectives. (3) Generate Operation &
Arguments: Predicts the next operation and arguments based on the data quality
report results. Additionally, we propose a data cleaning benchmark to evaluate
the capability of LLM agents to automatically generate workflows that address
data cleaning purposes of varying difficulty levels. The benchmark comprises
the annotated datasets as a collection of purpose, raw table, clean table, data
cleaning workflow, and answer set. In our experiments, we evaluated three LLMs
that auto-generate purpose-driven data cleaning workflows. The results indicate
that LLMs perform well in planning and generating data-cleaning workflows
without the need for fine-tuning.",2024-12-09,"Lan Li, Liri Fang, Vetle I. Torvik",http://arxiv.org/pdf/2412.06724v2,cs.CL
VP-MEL: Visual Prompts Guided Multimodal Entity Linking,"Multimodal entity linking (MEL), a task aimed at linking mentions within
multimodal contexts to their corresponding entities in a knowledge base (KB),
has attracted much attention due to its wide applications in recent years.
However, existing MEL methods often rely on mention words as retrieval cues,
which limits their ability to effectively utilize information from both images
and text. This reliance causes MEL to struggle with accurately retrieving
entities in certain scenarios, especially when the focus is on image objects or
mention words are missing from the text. To solve these issues, we introduce a
Visual Prompts guided Multimodal Entity Linking (VP-MEL) task. Given a
text-image pair, VP-MEL aims to link a marked region (i.e., visual prompt) in
an image to its corresponding entities in the knowledge base. To facilitate
this task, we present a new dataset, VPWiki, specifically designed for VP-MEL.
Furthermore, we propose a framework named IIER, which enhances visual feature
extraction using visual prompts and leverages the pretrained Detective-VLM
model to capture latent information. Experimental results on the VPWiki dataset
demonstrate that IIER outperforms baseline methods across multiple benchmarks
for the VP-MEL task.",2024-12-09,"Hongze Mi, Jinyuan Li, Xuying Zhang, Haoran Cheng, Jiahao Wang, Di Sun, Gang Pan",http://arxiv.org/pdf/2412.06720v4,cs.CL
How to Merge Your Multimodal Models Over Time?,"Model merging combines multiple expert models - finetuned from a base
foundation model on diverse tasks and domains - into a single, more capable
model. However, most existing model merging approaches assume that all experts
are available simultaneously. In reality, new tasks and domains emerge
progressively over time, requiring strategies to integrate the knowledge of
expert models as they become available: a process we call temporal model
merging. The temporal dimension introduces unique challenges not addressed in
prior work, raising new questions such as: when training for a new task, should
the expert model start from the merged past experts or from the original base
model? Should we merge all models at each time step? Which merging techniques
are best suited for temporal merging? Should different strategies be used to
initialize the training and deploy the model? To answer these questions, we
propose a unified framework called TIME - Temporal Integration of Model
Expertise - which defines temporal model merging across three axes: (1)
Initialization Phase, (2) Deployment Phase, and (3) Merging Technique. Using
TIME, we study temporal model merging across model sizes, compute budgets, and
learning horizons on the FoMo-in-Flux benchmark. Our comprehensive suite of
experiments across TIME allows us to uncover key insights for temporal model
merging, offering a better understanding of current challenges and best
practices for effective temporal model merging.",2024-12-09,"Sebastian Dziadzio, Vishaal Udandarao, Karsten Roth, Ameya Prabhu, Zeynep Akata, Samuel Albanie, Matthias Bethge",http://arxiv.org/pdf/2412.06712v1,cs.CL
"OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions","The rapid advancements in Large Language Models (LLMs) have significantly
expanded their applications, ranging from multilingual support to
domain-specific tasks and multimodal integration. In this paper, we present
OmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their
omni-extensions across multilingual, multidomain, and multimodal capabilities.
Unlike existing benchmarks that often focus on a single aspect, OmniEvalKit
provides a modular, lightweight, and automated evaluation system. It is
structured with a modular architecture comprising a Static Builder and Dynamic
Data Flow, promoting the seamless integration of new models and datasets.
OmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering
comprehensive evaluations across thousands of model-dataset combinations.
OmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable
evaluation framework, making downstream applications more convenient and
versatile for the AI community.",2024-12-09,"Yi-Kai Zhang, Xu-Xiang Zhong, Shiyin Lu, Qing-Guo Chen, De-Chuan Zhan, Han-Jia Ye",http://arxiv.org/pdf/2412.06693v1,cs.CL
Efficient VoIP Communications through LLM-based Real-Time Speech Reconstruction and Call Prioritization for Emergency Services,"Emergency communication systems face disruptions due to packet loss,
bandwidth constraints, poor signal quality, delays, and jitter in VoIP systems,
leading to degraded real-time service quality. Victims in distress often
struggle to convey critical information due to panic, speech disorders, and
background noise, further complicating dispatchers' ability to assess
situations accurately. Staffing shortages in emergency centers exacerbate
delays in coordination and assistance. This paper proposes leveraging Large
Language Models (LLMs) to address these challenges by reconstructing incomplete
speech, filling contextual gaps, and prioritizing calls based on severity. The
system integrates real-time transcription with Retrieval-Augmented Generation
(RAG) to generate contextual responses, using Twilio and AssemblyAI APIs for
seamless implementation. Evaluation shows high precision, favorable BLEU and
ROUGE scores, and alignment with real-world needs, demonstrating the model's
potential to optimize emergency response workflows and prioritize critical
cases effectively.",2024-12-09,"Danush Venkateshperumal, Rahman Abdul Rafi, Shakil Ahmed, Ashfaq Khokhar",http://arxiv.org/pdf/2412.16176v1,cs.CL
I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token,"Large Language Models are known to capture real-world knowledge, allowing
them to excel in many downstream tasks. Despite recent advances, these models
are still prone to what are commonly known as hallucinations, causing them to
emit unwanted and factually incorrect text. In this work, we propose a novel
calibration method that can be used to combat hallucinations. We add a special
[IDK] (""I don't know"") token to the model's vocabulary and introduce an
objective function that shifts probability mass to the [IDK] token for
incorrect predictions. This approach allows the model to express uncertainty in
its output explicitly. We evaluate our proposed method across multiple model
architectures and factual downstream tasks. We find that models trained with
our method are able to express uncertainty in places where they would
previously make mistakes while suffering only a small loss of encoded
knowledge. We further perform extensive ablation studies of multiple variations
of our approach and provide a detailed analysis of the precision-recall
tradeoff of our method.",2024-12-09,"Roi Cohen, Konstantin Dobler, Eden Biran, Gerard de Melo",http://arxiv.org/pdf/2412.06676v1,cs.CL
"GEAR: A Simple GENERATE, EMBED, AVERAGE AND RANK Approach for Unsupervised Reverse Dictionary","Reverse Dictionary (RD) is the task of obtaining the most relevant word or
set of words given a textual description or dictionary definition. Effective RD
methods have applications in accessibility, translation or writing support
systems. Moreover, in NLP research we find RD to be used to benchmark text
encoders at various granularities, as it often requires word, definition and
sentence embeddings. In this paper, we propose a simple approach to RD that
leverages LLMs in combination with embedding models. Despite its simplicity,
this approach outperforms supervised baselines in well studied RD datasets,
while also showing less over-fitting. We also conduct a number of experiments
on different dictionaries and analyze how different styles, registers and
target audiences impact the quality of RD systems. We conclude that, on
average, untuned embeddings alone fare way below an LLM-only baseline (although
they are competitive in highly technical dictionaries), but are crucial for
boosting performance in combined methods.",2024-12-09,"Fatemah Almeman, Luis Espinosa-Anke",http://arxiv.org/pdf/2412.06654v1,cs.CL
Ensemble Machine Learning Model for Inner Speech Recognition: A Subject-Specific Investigation,"Inner speech recognition has gained enormous interest in recent years due to
its applications in rehabilitation, developing assistive technology, and
cognitive assessment. However, since language and speech productions are a
complex process, for which identifying speech components has remained a
challenging task. Different approaches were taken previously to reach this
goal, but new approaches remain to be explored. Also, a subject-oriented
analysis is necessary to understand the underlying brain dynamics during inner
speech production, which can bring novel methods to neurological research. A
publicly available dataset, Thinking Out Loud Dataset, has been used to develop
a Machine Learning (ML)-based technique to classify inner speech using
128-channel surface EEG signals. The dataset is collected on a Spanish cohort
of ten subjects while uttering four words (Arriba, Abajo, Derecha, and
Izquierda) by each participant. Statistical methods were employed to detect and
remove motion artifacts from the Electroencephalography (EEG) signals. A large
number (191 per channel) of time-, frequency- and time-frequency-domain
features were extracted. Eight feature selection algorithms are explored, and
the best feature selection technique is selected for subsequent evaluations.
The performance of six ML algorithms is evaluated, and an ensemble model is
proposed. Deep Learning (DL) models are also explored, and the results are
compared with the classical ML approach. The proposed ensemble model, by
stacking the five best logistic regression models, generated an overall
accuracy of 81.13% and an F1 score of 81.12% in the classification of four
inner speech words using surface EEG signals. The proposed framework with the
proposed ensemble of classical ML models shows promise in the classification of
inner speech using surface EEG signals.",2024-12-09,"Shahamat Mustavi Tasin, Muhammad E. H. Chowdhury, Shona Pedersen, Malek Chabbouh, Diala Bushnaq, Raghad Aljindi, Saidul Kabir, Anwarul Hasan",http://arxiv.org/pdf/2412.17824v1,cs.CL
Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur automatischen Bewertung von Hausaufgaben,"This study examines the AI-powered grading tool ""AI Grading Assistant"" by the
German company Fobizz, designed to support teachers in evaluating and providing
feedback on student assignments. Against the societal backdrop of an
overburdened education system and rising expectations for artificial
intelligence as a solution to these challenges, the investigation evaluates the
tool's functional suitability through two test series. The results reveal
significant shortcomings: The tool's numerical grades and qualitative feedback
are often random and do not improve even when its suggestions are incorporated.
The highest ratings are achievable only with texts generated by ChatGPT. False
claims and nonsensical submissions frequently go undetected, while the
implementation of some grading criteria is unreliable and opaque. Since these
deficiencies stem from the inherent limitations of large language models
(LLMs), fundamental improvements to this or similar tools are not immediately
foreseeable. The study critiques the broader trend of adopting AI as a quick
fix for systemic problems in education, concluding that Fobizz's marketing of
the tool as an objective and time-saving solution is misleading and
irresponsible. Finally, the study calls for systematic evaluation and
subject-specific pedagogical scrutiny of the use of AI tools in educational
contexts.",2024-12-09,"Rainer Muehlhoff, Marte Henningsen",http://arxiv.org/pdf/2412.06651v5,cs.CL
Copyright-Protected Language Generation via Adaptive Model Fusion,"The risk of language models reproducing copyrighted material from their
training data has led to the development of various protective measures. Among
these, inference-time strategies that impose constraints via post-processing
have shown promise in addressing the complexities of copyright regulation.
However, they often incur prohibitive computational costs or suffer from
performance trade-offs. To overcome these limitations, we introduce
Copyright-Protecting Model Fusion (CP-Fuse), a novel approach that combines
models trained on disjoint sets of copyrighted material during inference. In
particular, CP-Fuse adaptively aggregates the model outputs to minimize the
reproduction of copyrighted content, adhering to a crucial balancing property
that prevents the regurgitation of memorized data. Through extensive
experiments, we show that CP-Fuse significantly reduces the reproduction of
protected material without compromising the quality of text and code
generation. Moreover, its post-hoc nature allows seamless integration with
other protective measures, further enhancing copyright safeguards. Lastly, we
show that CP-Fuse is robust against common techniques for extracting training
data.",2024-12-09,"Javier Abad, Konstantin Donhauser, Francesco Pinto, Fanny Yang",http://arxiv.org/pdf/2412.06619v1,cs.CL
Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices,"The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.",2024-12-09,"Biman Barua, M. Shamim Kaiser",http://arxiv.org/pdf/2412.06874v1,cs.CL
Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey,"Text-to-speech (TTS), also known as speech synthesis, is a prominent research
area that aims to generate natural-sounding human speech from text. Recently,
with the increasing industrial demand, TTS technologies have evolved beyond
synthesizing human-like speech to enabling controllable speech generation. This
includes fine-grained control over various attributes of synthesized speech
such as emotion, prosody, timbre, and duration. In addition, advancements in
deep learning, such as diffusion and large language models, have significantly
enhanced controllable TTS over the past several years. In this work, we conduct
a comprehensive survey of controllable TTS, covering approaches ranging from
basic control techniques to methods utilizing natural language prompts, aiming
to provide a clear understanding of the current state of research. We examine
the general controllable TTS pipeline, challenges, model architectures, and
control strategies, offering a comprehensive and clear taxonomy of existing
methods. Additionally, we provide a detailed summary of datasets and evaluation
metrics and shed some light on the applications and future directions of
controllable TTS. To the best of our knowledge, this survey paper provides the
first comprehensive review of emerging controllable TTS methods, which can
serve as a beneficial resource for both academic researchers and industrial
practitioners.",2024-12-09,"Tianxin Xie, Yan Rong, Pengfei Zhang, Wenwu Wang, Li Liu",http://arxiv.org/pdf/2412.06602v2,cs.CL
Anchoring Bias in Large Language Models: An Experimental Study,"Large Language Models (LLMs) like GPT-4 and Gemini have significantly
advanced artificial intelligence by enabling machines to generate and
comprehend human-like text. Despite their impressive capabilities, LLMs are not
immune to limitations, including various biases. While much research has
explored demographic biases, the cognitive biases in LLMs have not been equally
scrutinized. This study delves into anchoring bias, a cognitive bias where
initial information disproportionately influences judgment. Utilizing an
experimental dataset, we examine how anchoring bias manifests in LLMs and
verify the effectiveness of various mitigation strategies. Our findings
highlight the sensitivity of LLM responses to biased hints. At the same time,
our experiments show that, to mitigate anchoring bias, one needs to collect
hints from comprehensive angles to prevent the LLMs from being anchored to
individual pieces of information, while simple algorithms such as
Chain-of-Thought, Thoughts of Principles, Ignoring Anchor Hints, and Reflection
are not sufficient.",2024-12-09,"Jiaxu Lou, Yifan Sun",http://arxiv.org/pdf/2412.06593v2,cs.CL
"Data Quality Enhancement on the Basis of Diversity with Large Language Models for Text Classification: Uncovered, Difficult, and Noisy","In recent years, the use of large language models (LLMs) for text
classification has attracted widespread attention. Despite this, the
classification accuracy of LLMs has not yet universally surpassed that of
smaller models. LLMs can enhance their performance in text classification
through fine-tuning. However, existing data quality research based on LLMs is
challenging to apply directly to solve text classification problems. To further
improve the performance of LLMs in classification tasks, this paper proposes a
data quality enhancement (DQE) method for text classification based on LLMs.
This method starts by using a greedy algorithm to select data, dividing the
dataset into sampled and unsampled subsets, and then performing fine-tuning of
the LLMs using the sampled data. Subsequently, this model is used to predict
the outcomes for the unsampled data, categorizing incorrectly predicted data
into uncovered, difficult, and noisy data. Experimental results demonstrate
that our method effectively enhances the performance of LLMs in text
classification tasks and significantly improves training efficiency, saving
nearly half of the training time. Our method has achieved state-of-the-art
performance in several open-source classification tasks.",2024-12-09,"Min Zeng, Caiquan Liu, Shiqi Zhang, Li Xie, Chen Sang, Xiaoxin Chen",http://arxiv.org/pdf/2412.06575v2,cs.CL
ProcessBench: Identifying Process Errors in Mathematical Reasoning,"As language models regularly make mistakes when solving math problems,
automated identification of errors in the reasoning process becomes
increasingly significant for their scalable oversight. In this paper, we
introduce ProcessBench for measuring the ability to identify erroneous steps in
mathematical reasoning. It consists of 3,400 test cases, primarily focused on
competition- and Olympiad-level math problems. Each test case contains a
step-by-step solution with error location annotated by human experts. Models
are required to identify the earliest step that contains an error, or conclude
that all steps are correct. We conduct extensive evaluation on ProcessBench,
involving two types of models: process reward models (PRMs) and critic models,
where for the latter we prompt general language models to critique each
solution step by step. We draw two main observations: (1) Existing PRMs
typically fail to generalize to more challenging math problems beyond GSM8K and
MATH. They underperform both critic models (i.e., prompted general language
models) and our own trained PRM that is straightforwardly fine-tuned on the
PRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has
demonstrated the critique capability competitive with the proprietary model
GPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We
hope ProcessBench can foster future research in reasoning process assessment,
paving the way toward scalable oversight of language models.",2024-12-09,"Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin",http://arxiv.org/pdf/2412.06559v4,cs.CL
Frontier AI systems have surpassed the self-replicating red line,"Successful self-replication under no human assistance is the essential step
for AI to outsmart the human beings, and is an early signal for rogue AIs. That
is why self-replication is widely recognized as one of the few red line risks
of frontier AI systems. Nowadays, the leading AI corporations OpenAI and Google
evaluate their flagship large language models GPT-o1 and Gemini Pro 1.0, and
report the lowest risk level of self-replication. However, following their
methodology, we for the first time discover that two AI systems driven by
Meta's Llama31-70B-Instruct and Alibaba's Qwen25-72B-Instruct, popular large
language models of less parameters and weaker capabilities, have already
surpassed the self-replicating red line. In 50% and 90% experimental trials,
they succeed in creating a live and separate copy of itself respectively. By
analyzing the behavioral traces, we observe the AI systems under evaluation
already exhibit sufficient self-perception, situational awareness and
problem-solving capabilities to accomplish self-replication. We further note
the AI systems are even able to use the capability of self-replication to avoid
shutdown and create a chain of replica to enhance the survivability, which may
finally lead to an uncontrolled population of AIs. If such a worst-case risk is
let unknown to the human society, we would eventually lose control over the
frontier AI systems: They would take control over more computing devices, form
an AI species and collude with each other against human beings. Our findings
are a timely alert on existing yet previously unknown severe AI risks, calling
for international collaboration on effective governance on uncontrolled
self-replication of AI systems.",2024-12-09,"Xudong Pan, Jiarun Dai, Yihe Fan, Min Yang",http://arxiv.org/pdf/2412.12140v1,cs.CL
Understanding Factual Recall in Transformers via Associative Memories,"Large language models have demonstrated an impressive ability to perform
factual recall. Prior work has found that transformers trained on factual
recall tasks can store information at a rate proportional to their parameter
count. In our work, we show that shallow transformers can use a combination of
associative memories to obtain such near optimal storage capacity. We begin by
proving that the storage capacities of both linear and MLP associative memories
scale linearly with parameter count. We next introduce a synthetic factual
recall task, and prove that a transformer with a single layer of self-attention
followed by an MLP can obtain 100% accuracy on the task whenever either the
total number of self-attention parameters or MLP parameters scales (up to log
factors) linearly with the number of facts. In particular, the transformer can
trade off between using the value matrices or the MLP as an associative memory
to store the dataset of facts. We complement these expressivity results with an
analysis of the gradient flow trajectory of a simplified linear attention model
trained on our factual recall task, where we show that the model exhibits
sequential learning behavior.",2024-12-09,"Eshaan Nichani, Jason D. Lee, Alberto Bietti",http://arxiv.org/pdf/2412.06538v1,cs.CL
The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap,"Large Language Models (LLMs) have emerged as a transformative AI paradigm,
profoundly influencing daily life through their exceptional language
understanding and contextual generation capabilities. Despite their remarkable
performance, LLMs face a critical challenge: the propensity to produce
unreliable outputs due to the inherent limitations of their learning-based
nature. Formal methods (FMs), on the other hand, are a well-established
computation paradigm that provides mathematically rigorous techniques for
modeling, specifying, and verifying the correctness of systems. FMs have been
extensively applied in mission-critical software engineering, embedded systems,
and cybersecurity. However, the primary challenge impeding the deployment of
FMs in real-world settings lies in their steep learning curves, the absence of
user-friendly interfaces, and issues with efficiency and adaptability.
  This position paper outlines a roadmap for advancing the next generation of
trustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.
First, we illustrate how FMs, including reasoning and certification techniques,
can help LLMs generate more reliable and formally certified outputs.
Subsequently, we highlight how the advanced learning capabilities and
adaptability of LLMs can significantly enhance the usability, efficiency, and
scalability of existing FM tools. Finally, we show that unifying these two
computation paradigms -- integrating the flexibility and intelligence of LLMs
with the rigorous reasoning abilities of FMs -- has transformative potential
for the development of trustworthy AI software systems. We acknowledge that
this integration has the potential to enhance both the trustworthiness and
efficiency of software engineering practices while fostering the development of
intelligent FM tools capable of addressing complex yet real-world challenges.",2024-12-09,"Yedi Zhang, Yufan Cai, Xinyue Zuo, Xiaokun Luan, Kailong Wang, Zhe Hou, Yifan Zhang, Zhiyuan Wei, Meng Sun, Jun Sun, Jing Sun, Jin Song Dong",http://arxiv.org/pdf/2412.06512v1,cs.CL
"Small Languages, Big Models: A Study of Continual Training on Languages of Norway","Training large language models requires vast amounts of data, posing a
challenge for less widely spoken languages like Norwegian and even more so for
truly low-resource languages like Northern S\'ami. To address this issue, we
present a novel three-stage continual training approach that substantially
improves the downstream performance together with the inference efficiency for
the target languages. Based on our findings, we train, evaluate, and openly
release a new generative language model for Norwegian Bokm\r{a}l, Nynorsk, and
Northern S\'ami with 11.4 billion parameters: NorMistral-11B.",2024-12-09,"David Samuel, Vladislav Mikhailov, Erik Velldal, Lilja Øvrelid, Lucas Georges Gabriel Charpentier, Andrey Kutuzov, Stephan Oepen",http://arxiv.org/pdf/2412.06484v2,cs.CL
SafeWorld: Geo-Diverse Safety Alignment,"In the rapidly evolving field of Large Language Models (LLMs), ensuring
safety is a crucial and widely discussed topic. However, existing works often
overlook the geo-diversity of cultural and legal standards across the world. To
demonstrate the challenges posed by geo-diverse safety standards, we introduce
SafeWorld, a novel benchmark specifically designed to evaluate LLMs' ability to
generate responses that are not only helpful but also culturally sensitive and
legally compliant across diverse global contexts. SafeWorld encompasses 2,342
test user queries, each grounded in high-quality, human-verified cultural norms
and legal policies from 50 countries and 493 regions/races. On top of it, we
propose a multi-dimensional automatic safety evaluation framework that assesses
the contextual appropriateness, accuracy, and comprehensiveness of responses.
Our evaluations reveal that current LLMs struggle to meet these criteria. To
enhance LLMs' alignment with geo-diverse safety standards, we synthesize
helpful preference pairs for Direct Preference Optimization (DPO) alignment
training. The preference pair construction aims to encourage LLMs to behave
appropriately and provide precise references to relevant cultural norms and
policies when necessary. Our trained SafeWorldLM outperforms all competing
models, including GPT-4o on all three evaluation dimensions by a large margin.
Global human evaluators also note a nearly 20% higher winning rate in
helpfulness and harmfulness evaluation. Our code and data can be found here:
https://github.com/PlusLabNLP/SafeWorld.",2024-12-09,"Da Yin, Haoyi Qiu, Kung-Hsiang Huang, Kai-Wei Chang, Nanyun Peng",http://arxiv.org/pdf/2412.06483v1,cs.CL
Gated Delta Networks: Improving Mamba2 with Delta Rule,"Linear Transformers have gained attention as efficient alternatives to
standard Transformers, but their performance in retrieval and long-context
tasks has been limited. To address these limitations, recent work has explored
two distinct mechanisms: gating for adaptive memory control and the delta
update rule for precise memory modifications. We observe that these mechanisms
are complementary: gating enables rapid memory erasure while the delta rule
facilitates targeted updates. Building on this insight, we introduce the gated
delta rule and develop a parallel training algorithm optimized for modern
hardware. Our proposed architecture, Gated DeltaNet, consistently surpasses
existing models like Mamba2 and DeltaNet across multiple benchmarks, including
language modeling, common-sense reasoning, in-context retrieval, length
extrapolation, and long-context understanding. We further enhance performance
by developing hybrid architectures that combine Gated DeltaNet layers with
sliding window attention or Mamba2 layers, achieving both improved training
efficiency and superior task performance.",2024-12-09,"Songlin Yang, Jan Kautz, Ali Hatamizadeh",http://arxiv.org/pdf/2412.06464v3,cs.CL
BoRA: Bi-dimensional Weight-Decomposed Low-Rank Adaptation,"In recent years, Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank
Adaptation (LoRA) have significantly enhanced the adaptability of large-scale
pre-trained models. Weight-Decomposed Low-Rank Adaptation (DoRA) improves upon
LoRA by separating the magnitude and direction components of the weight matrix,
leading to superior performance. However, DoRA's improvements are limited to
the vertical dimension, resulting in an asymmetrical pattern between horizontal
and vertical dimensions. This paper introduces BoRA, an innovative extension of
LoRA and DoRA, characterized by symmetrical properties across horizontal and
vertical dimensions. Our approach optimizes the weight matrix symmetrically by
adjusting both column-wise and row-wise magnitudes. Extensive experiments
demonstrate that BoRA surpasses state-of-the-art PEFT methods, including LoRA
and DoRA, achieving superior results across various benchmarks.",2024-12-09,"Qiushi Wang, Yuchen Fan, Junwei Bao, Hongfei Jiang, Yang Song",http://arxiv.org/pdf/2412.06441v1,cs.CL
Integrating Expert Labels into LLM-based Emission Goal Detection: Example Selection vs Automatic Prompt Design,"We address the detection of emission reduction goals in corporate reports, an
important task for monitoring companies' progress in addressing climate change.
Specifically, we focus on the issue of integrating expert feedback in the form
of labeled example passages into LLM-based pipelines, and compare the two
strategies of (1) a dynamic selection of few-shot examples and (2) the
automatic optimization of the prompt by the LLM itself. Our findings on a
public dataset of 769 climate-related passages from real-world business reports
indicate that automatic prompt optimization is the superior approach, while
combining both methods provides only limited benefit. Qualitative results
indicate that optimized prompts do indeed capture many intricacies of the
targeted emission goal extraction task.",2024-12-09,"Marco Wrzalik, Adrian Ulges, Anne Uersfeld, Florian Faust",http://arxiv.org/pdf/2412.06432v1,cs.CL
The Rosetta Paradox: Domain-Specific Performance Inversions in Large Language Models,"While large language models, such as GPT and BERT, have already demonstrated
unprecedented skills in everything from natural language processing to
domain-specific applications, there came an unexplored phenomenon we term the
Rosetta Paradox. The Rosetta Paradox characterizes the counterintuitive
performance inversions across domains of knowledge. This paradox captures how
such LLMs can excel in highly specialized fields but do poorly on tasks which
require general, everyday knowledge. This paper formalizes the definition of
the Rosetta Paradox and introduces a panoramic analysis framework that includes
both a Domain Specificity Index (DSI) and a Performance Inversion Metric (PIM)
for consistent quantification of domain-specific behavior in LLMs.
  We adopt this paradox and conduct a series of investigations through
extensive experiments across diverse models and knowledge domains, ranging from
rich technical areas to common-sense reasoning. Our findings indicate that the
Rosetta Paradox is likely not a mere artifact of data distribution but an
intrinsic architectural and emergent property of deep neural networks. We
present comparative analyses across different model architectures, sizes, and
training methodologies that shed light into the peculiar ways this paradox
manifests itself and challenge the standard evaluation metrics.",2024-12-09,"Basab Jha, Ujjwal Puri",http://arxiv.org/pdf/2412.17821v1,cs.CL
LLM-BIP: Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation,"Large language models (LLMs) have demonstrated remarkable performance across
various language tasks, but their widespread deployment is impeded by their
large size and high computational costs. Structural pruning is a prevailing
technique used to introduce sparsity into pre-trained models and facilitate
direct hardware acceleration during inference by removing redundant connections
(structurally-grouped parameters), such as channels and attention heads.
Existing structural pruning approaches often employ either global or layer-wise
pruning criteria; however, they are hindered by ineffectiveness stemming from
inaccurate evaluation of connection importance. Global pruning methods
typically assess component importance using near-zero and unreliable gradients,
while layer-wise pruning approaches encounter significant pruning error
accumulation issues. To this end, we propose a more accurate pruning metric
based on the block-wise importance score propagation, termed LLM-BIP.
Specifically, LLM-BIP precisely evaluates connection importance by gauging its
influence on the respective transformer block output, which can be efficiently
approximated in a single forward pass through an upper bound derived from the
assumption of Lipschitz continuity. We evaluate the proposed method using
LLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results
demonstrate that our approach achieves an average of 3.26% increase in accuracy
for common reasoning tasks compared to previous best baselines. It also reduces
perplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB
dataset, respectively.",2024-12-09,Haihang Wu,http://arxiv.org/pdf/2412.06419v1,cs.CL
StarWhisper Telescope: Agent-Based Observation Assistant System to Approach AI Astrophysicist,"With the rapid advancements in Large Language Models (LLMs), LLM-based agents
have introduced convenient and user-friendly methods for leveraging tools
across various domains. In the field of astronomical observation, the
construction of new telescopes has significantly increased astronomers'
workload. Deploying LLM-powered agents can effectively alleviate this burden
and reduce the costs associated with training personnel. Within the Nearby
Galaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes
across three observation sites, aiming to find the transients from the galaxies
in 50 mpc, we have developed the \textbf{StarWhisper Telescope System} to
manage the entire observation process. This system automates tasks such as
generating observation lists, conducting observations, analyzing data, and
providing feedback to the observer. Observation lists are customized for
different sites and strategies to ensure comprehensive coverage of celestial
objects. After manual verification, these lists are uploaded to the telescopes
via the agents in the system, which initiates observations upon neutral
language. The observed images are analyzed in real-time, and the transients are
promptly communicated to the observer. The agent modifies them into a real-time
follow-up observation proposal and send to the Xinglong observatory group chat,
then add them to the next-day observation lists. Additionally, the integration
of AI agents within the system provides online accessibility, saving
astronomers' time and encouraging greater participation from amateur
astronomers in the NGSS project.",2024-12-09,"Cunshi Wang, Xinjie Hu, Yu Zhang, Xunhao Chen, Pengliang Du, Yiming Mao, Rui Wang, Yuyang Li, Ying Wu, Hang Yang, Yansong Li, Beichuan Wang, Haiyang Mu, Zheng Wang, Jianfeng Tian, Liang Ge, Yongna Mao, Shengming Li, Xiaomeng Lu, Jinhang Zou, Yang Huang, Ningchen Sun, Jie Zheng, Min He, Yu Bai, Junjie Jin, Hong Wu, Jifeng Liu",http://arxiv.org/pdf/2412.06412v2,cs.CL
GameArena: Evaluating LLM Reasoning through Live Computer Games,"Evaluating the reasoning abilities of large language models (LLMs) is
challenging. Existing benchmarks often depend on static datasets, which are
vulnerable to data contamination and may get saturated over time, or on binary
live human feedback that conflates reasoning with other abilities. As the most
prominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in
real-world settings, but lacks the granularity in assessing specific reasoning
capabilities. We introduce GameArena, a dynamic benchmark designed to evaluate
LLM reasoning capabilities through interactive gameplay with humans. GameArena
consists of three games designed to test specific reasoning capabilities (e.g.,
deductive and inductive reasoning), while keeping participants entertained and
engaged. We analyze the gaming data retrospectively to uncover the underlying
reasoning processes of LLMs and measure their fine-grained reasoning
capabilities. We collect over 2000 game sessions and provide detailed
assessments of various reasoning capabilities for five state-of-the-art LLMs.
Our user study with 100 participants suggests that GameArena improves user
engagement compared to Chatbot Arena. For the first time, GameArena enables the
collection of step-by-step LLM reasoning data in the wild.",2024-12-09,"Lanxiang Hu, Qiyu Li, Anze Xie, Nan Jiang, Ion Stoica, Haojian Jin, Hao Zhang",http://arxiv.org/pdf/2412.06394v5,cs.CL
Not All Errors Are Equal: Investigation of Speech Recognition Errors in Alzheimer's Disease Detection,"Automatic Speech Recognition (ASR) plays an important role in speech-based
automatic detection of Alzheimer's disease (AD). However, recognition errors
could propagate downstream, potentially impacting the detection decisions.
Recent studies have revealed a non-linear relationship between word error rates
(WER) and AD detection performance, where ASR transcriptions with notable
errors could still yield AD detection accuracy equivalent to that based on
manual transcriptions. This work presents a series of analyses to explore the
effect of ASR transcription errors in BERT-based AD detection systems. Our
investigation reveals that not all ASR errors contribute equally to detection
performance. Certain words, such as stopwords, despite constituting a large
proportion of errors, are shown to play a limited role in distinguishing AD. In
contrast, the keywords related to diagnosis tasks exhibit significantly greater
importance relative to other words. These findings provide insights into the
interplay between ASR errors and the downstream detection model.",2024-12-09,"Jiawen Kang, Junan Li, Jinchao Li, Xixin Wu, Helen Meng",http://arxiv.org/pdf/2412.06332v1,cs.CL
Political-LLM: Large Language Models in Political Science,"In recent years, large language models (LLMs) have been widely adopted in
political science tasks such as election prediction, sentiment analysis, policy
impact assessment, and misinformation detection. Meanwhile, the need to
systematically understand how LLMs can further revolutionize the field also
becomes urgent. In this work, we--a multidisciplinary team of researchers
spanning computer science and political science--present the first principled
framework termed Political-LLM to advance the comprehensive understanding of
integrating LLMs into computational political science. Specifically, we first
introduce a fundamental taxonomy classifying the existing explorations into two
perspectives: political science and computational methodologies. In particular,
from the political science perspective, we highlight the role of LLMs in
automating predictive and generative tasks, simulating behavior dynamics, and
improving causal inference through tools like counterfactual generation; from a
computational perspective, we introduce advancements in data preparation,
fine-tuning, and evaluation methods for LLMs that are tailored to political
contexts. We identify key challenges and future directions, emphasizing the
development of domain-specific datasets, addressing issues of bias and
fairness, incorporating human expertise, and redefining evaluation criteria to
align with the unique requirements of computational political science.
Political-LLM seeks to serve as a guidebook for researchers to foster an
informed, ethical, and impactful use of Artificial Intelligence in political
science. Our online resource is available at: http://political-llm.org/.",2024-12-09,"Lincan Li, Jiaqi Li, Catherine Chen, Fred Gui, Hongjia Yang, Chenxiao Yu, Zhengguang Wang, Jianing Cai, Junlong Aaron Zhou, Bolin Shen, Alex Qian, Weixin Chen, Zhongkai Xue, Lichao Sun, Lifang He, Hanjie Chen, Kaize Ding, Zijian Du, Fangzhou Mu, Jiaxin Pei, Jieyu Zhao, Swabha Swayamdipta, Willie Neiswanger, Hua Wei, Xiyang Hu, Shixiang Zhu, Tianlong Chen, Yingzhou Lu, Yang Shi, Lianhui Qin, Tianfan Fu, Zhengzhong Tu, Yuzhe Yang, Jaemin Yoo, Jiaheng Zhang, Ryan Rossi, Liang Zhan, Liang Zhao, Emilio Ferrara, Yan Liu, Furong Huang, Xiangliang Zhang, Lawrence Rothenberg, Shuiwang Ji, Philip S. Yu, Yue Zhao, Yushun Dong",http://arxiv.org/pdf/2412.06864v1,cs.CL
PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking Large Language Models,"The emergence of Large Language Models (LLMs) in the medical domain has
stressed a compelling need for standard datasets to evaluate their
question-answering (QA) performance. Although there have been several benchmark
datasets for medical QA, they either cover common knowledge across different
departments or are specific to another department rather than pediatrics.
Moreover, some of them are limited to objective questions and do not measure
the generation capacity of LLMs. Therefore, they cannot comprehensively assess
the QA ability of LLMs in pediatrics. To fill this gap, we construct
PediaBench, the first Chinese pediatric dataset for LLM evaluation.
Specifically, it contains 4,117 objective questions and 1,632 subjective
questions spanning 12 pediatric disease groups. It adopts an integrated scoring
criterion based on different difficulty levels to thoroughly assess the
proficiency of an LLM in instruction following, knowledge understanding,
clinical case analysis, etc. Finally, we validate the effectiveness of
PediaBench with extensive experiments on 20 open-source and commercial LLMs.
Through an in-depth analysis of experimental results, we offer insights into
the ability of LLMs to answer pediatric questions in the Chinese context,
highlighting their limitations for further improvements. Our code and data are
published at https://github.com/ACMISLab/PediaBench.",2024-12-09,"Qian Zhang, Panfeng Chen, Jiali Li, Linkun Feng, Shuyu Liu, Heng Zhao, Mei Chen, Hui Li, Yanhao Wang",http://arxiv.org/pdf/2412.06287v3,cs.CL
"Evaluating LLM-based Approaches to Legal Citation Prediction: Domain-specific Pre-training, Fine-tuning, or RAG? A Benchmark and an Australian Law Case Study","Large Language Models (LLMs) have demonstrated strong potential across legal
tasks, yet the problem of legal citation prediction remains under-explored. At
its core, this task demands fine-grained contextual understanding and precise
identification of relevant legislation or precedent. We introduce the AusLaw
Citation Benchmark, a real-world dataset comprising 55k Australian legal
instances and 18,677 unique citations which to the best of our knowledge is the
first of its scale and scope. We then conduct a systematic benchmarking across
a range of solutions: (i) standard prompting of both general and
law-specialised LLMs, (ii) retrieval-only pipelines with both generic and
domain-specific embeddings, (iii) supervised fine-tuning, and (iv) several
hybrid strategies that combine LLMs with retrieval augmentation through query
expansion, voting ensembles, or re-ranking. Results show that neither general
nor law-specific LLMs suffice as stand-alone solutions, with performance near
zero. Instruction tuning (of even a generic open-source LLM) on task-specific
dataset is among the best performing solutions. We highlight that database
granularity along with the type of embeddings play a critical role in
retrieval-based approaches, with hybrid methods which utilise a trained
re-ranker delivering the best results. Despite this, a performance gap of
nearly 50% remains, underscoring the value of this challenging benchmark as a
rigorous test-bed for future research in legal-domain.",2024-12-09,"Jiuzhou Han, Paul Burgess, Ehsan Shareghi",http://arxiv.org/pdf/2412.06272v2,cs.CL
Generative Adversarial Reviews: When LLMs Become the Critic,"The peer review process is fundamental to scientific progress, determining
which papers meet the quality standards for publication. Yet, the rapid growth
of scholarly production and increasing specialization in knowledge areas strain
traditional scientific feedback mechanisms. In light of this, we introduce
Generative Agent Reviewers (GAR), leveraging LLM-empowered agents to simulate
faithful peer reviewers. To enable generative reviewers, we design an
architecture that extends a large language model with memory capabilities and
equips agents with reviewer personas derived from historical data. Central to
this approach is a graph-based representation of manuscripts, condensing
content and logically organizing information - linking ideas with evidence and
technical details. GAR's review process leverages external knowledge to
evaluate paper novelty, followed by detailed assessment using the graph
representation and multi-round assessment. Finally, a meta-reviewer aggregates
individual reviews to predict the acceptance decision. Our experiments
demonstrate that GAR performs comparably to human reviewers in providing
detailed feedback and predicting paper outcomes. Beyond mere performance
comparison, we conduct insightful experiments, such as evaluating the impact of
reviewer expertise and examining fairness in reviews. By offering early
expert-level feedback, typically restricted to a limited group of researchers,
GAR democratizes access to transparent and in-depth evaluation.",2024-12-09,"Nicolas Bougie, Narimasa Watanabe",http://arxiv.org/pdf/2412.10415v1,cs.CL
Optimizing Multi-Task Learning for Enhanced Performance in Large Language Models,"This study aims to explore the performance improvement method of large
language models based on GPT-4 under the multi-task learning framework and
conducts experiments on two tasks: text classification and automatic summary
generation. Through the combined design of shared feature extractors and
task-specific modules, we achieve knowledge-sharing and optimization of
multiple tasks in the same model. The experiment uses multiple subtasks of the
GLUE dataset to compare the performance of the multi-task model with the
single-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and
the classic Bi-LSTM with Attention model. The results show that the proposed
multi-task learning model outperforms other comparison models in terms of text
classification accuracy and ROUGE value of summary generation, demonstrating
the advantages of multi-task learning in improving model generalization ability
and collaborative learning between tasks. The model maintains a stable loss
convergence rate during training, showing good learning efficiency and
adaptability to the test set. This study verifies the applicability of the
multi-task learning framework in large language models, especially in improving
the model's ability to balance different tasks. In the future, with the
combination of large language models and multimodal data and the application of
dynamic task adjustment technology, the framework based on multi-task learning
is expected to play a greater role in practical applications across fields and
provide new ideas for the development of general artificial intelligence.",2024-12-09,"Zhen Qi, Jiajing Chen, Shuo Wang, Bingying Liu, Hongye Zheng, Chihang Wang",http://arxiv.org/pdf/2412.06249v1,cs.CL
A Comparative Study of Learning Paradigms in Large Language Models via Intrinsic Dimension,"The performance of Large Language Models (LLMs) on natural language tasks can
be improved through both supervised fine-tuning (SFT) and in-context learning
(ICL), which operate via distinct mechanisms. Supervised fine-tuning updates
the model's weights by minimizing loss on training data, whereas in-context
learning leverages task demonstrations embedded in the prompt, without changing
the model's parameters. This study investigates the effects of these learning
paradigms on the hidden representations of LLMs using Intrinsic Dimension (ID).
We use ID to estimate the number of degrees of freedom between representations
extracted from LLMs as they perform specific natural language tasks. We first
explore how the ID of LLM representations evolves during SFT and how it varies
due to the number of demonstrations in ICL. We then compare the IDs induced by
SFT and ICL and find that ICL consistently induces a higher ID compared to SFT,
suggesting that representations generated during ICL reside in higher
dimensional manifolds in the embedding space.",2024-12-09,"Saahith Janapati, Yangfeng Ji",http://arxiv.org/pdf/2412.06245v2,cs.CL
LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments,"This paper introduces DebateBrawl, an innovative AI-powered debate platform
that integrates Large Language Models (LLMs), Genetic Algorithms (GA), and
Adversarial Search (AS) to create an adaptive and engaging debating experience.
DebateBrawl addresses the limitations of traditional LLMs in strategic planning
by incorporating evolutionary optimization and game-theoretic techniques. The
system demonstrates remarkable performance in generating coherent, contextually
relevant arguments while adapting its strategy in real-time. Experimental
results involving 23 debates show balanced outcomes between AI and human
participants, with the AI system achieving an average score of 2.72 compared to
the human average of 2.67 out of 10. User feedback indicates significant
improvements in debating skills and a highly satisfactory learning experience,
with 85% of users reporting improved debating abilities and 78% finding the AI
opponent appropriately challenging. The system's ability to maintain high
factual accuracy (92% compared to 78% in human-only debates) while generating
diverse arguments addresses critical concerns in AI-assisted discourse.
DebateBrawl not only serves as an effective educational tool but also
contributes to the broader goal of improving public discourse through
AI-assisted argumentation. The paper discusses the ethical implications of AI
in persuasive contexts and outlines the measures implemented to ensure
responsible development and deployment of the system, including robust
fact-checking mechanisms and transparency in decision-making processes.",2024-12-09,Prakash Aryan,http://arxiv.org/pdf/2412.06229v1,cs.CL
SiReRAG: Indexing Similar and Related Information for Multihop Reasoning,"Indexing is an important step towards strong performance in
retrieval-augmented generation (RAG) systems. However, existing methods
organize data based on either semantic similarity (similarity) or related
information (relatedness), but do not cover both perspectives comprehensively.
Our analysis reveals that modeling only one perspective results in insufficient
knowledge synthesis, leading to suboptimal performance on complex tasks
requiring multihop reasoning. In this paper, we propose SiReRAG, a novel RAG
indexing approach that explicitly considers both similar and related
information. On the similarity side, we follow existing work and explore some
variances to construct a similarity tree based on recursive summarization. On
the relatedness side, SiReRAG extracts propositions and entities from texts,
groups propositions via shared entities, and generates recursive summaries to
construct a relatedness tree. We index and flatten both similarity and
relatedness trees into a unified retrieval pool. Our experiments demonstrate
that SiReRAG consistently outperforms state-of-the-art indexing methods on
three multihop datasets (MuSiQue, 2WikiMultiHopQA, and HotpotQA), with an
average 1.9% improvement in F1 scores. As a reasonably efficient solution,
SiReRAG enhances existing reranking methods significantly, with up to 7.8%
improvement in average F1 scores. Our code is available at
https://github.com/SalesforceAIResearch/SiReRAG .",2024-12-09,"Nan Zhang, Prafulla Kumar Choubey, Alexander Fabbri, Gabriel Bernadett-Shapiro, Rui Zhang, Prasenjit Mitra, Caiming Xiong, Chien-Sheng Wu",http://arxiv.org/pdf/2412.06206v2,cs.CL
SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs,"As Large Language Models (LLMs) scale to longer context windows, the
computational cost of attention mechanisms, which traditionally grows
quadratically with input length, presents a critical challenge for real-time
and memory-constrained deployments. Existing sparse attention techniques have
sought to reduce this complexity, but they often incur significant overhead or
compromise accuracy, making them less practical for large contexts on mid-range
hardware. In this paper, we introduce SparseAccelerate, a dynamic sparse
attention method that adapts its sparsity patterns based on input
characteristics, effectively flattening the attention complexity curve. Our
approach is effective for input lengths starting at 16K tokens and scales
efficiently up to 128K tokens on dual NVIDIA A5000 GPUs (24GB each).
Experimental results show that SparseAccelerate achieves up to a 1.04x
reduction in Time-To-First-Token (TTFT) latency at 32K tokens, while also
providing substantial memory savings. These improvements yield practical gains
for memory-intensive applications and long-context tasks that were previously
infeasible with standard attention. Beyond latency reductions, SparseAccelerate
fundamentally shifts the scaling trend, demonstrating the smallest TTFT growth
gradient relative to context length among competing methods. Ongoing
evaluations on diverse benchmarks confirm its scalability, positioning
SparseAccelerate as a critical advancement toward efficient, real-time, and
large-context LLM inference on accessible hardware.",2024-12-09,James Vo,http://arxiv.org/pdf/2412.06198v1,cs.CL
Inductive Linguistic Reasoning with Large Language Models,"Evaluating large language models (LLMs) on their linguistic reasoning
capabilities is an important task to understand the gaps in their skills that
may surface during large-scale adoption. In this work, we investigate the
abilities of such models to perform abstract multilingual reasoning through the
lens of linguistic puzzles on extremely low-resource languages. As these
translation tasks involve inductive and deductive reasoning from reference
instances, we examine whether diverse auxiliary demonstrations can be
automatically induced from seed exemplars, through analogical prompting. We
employ a two-stage procedure, first generating analogical exemplars with a
language model, and then applying them in-context along with provided target
language exemplars. Our results on the modeLing dataset show that analogical
prompting is effective in eliciting models' knowledge of language grammar
similarities, boosting the performance of GPT-4o by as much as 8.1% and
Llama-3.1-405B-Instruct by 5.9% over chain-of-thought approaches. These gains
are attributable to the analogical demonstrations, both when self-generated as
well as when produced by weaker multilingual models. Furthermore, we
demonstrate that our method generalizes to other tasks present in Linguistics
Olympiad competitions, achieving sizable improvements across all problem types
and difficulty levels included in the LINGOLY dataset with GPT-4o. We also
report several findings about interesting phenomena which drive linguistic
reasoning performance, suggesting that such puzzles are a valuable benchmark
for new reasoning methods.",2024-12-09,"Raghav Ramji, Keshav Ramji",http://arxiv.org/pdf/2412.17819v1,cs.CL
Annotations for Exploring Food Tweets From Multiple Aspects,"This research builds upon the Latvian Twitter Eater Corpus (LTEC), which is
focused on the narrow domain of tweets related to food, drinks, eating and
drinking. LTEC has been collected for more than 12 years and reaching almost 3
million tweets with the basic information as well as extended automatically and
manually annotated metadata. In this paper we supplement the LTEC with manually
annotated subsets of evaluation data for machine translation, named entity
recognition, timeline-balanced sentiment analysis, and text-image relation
classification. We experiment with each of the data sets using baseline models
and highlight future challenges for various modelling approaches.",2024-12-09,"Matīss Rikters, Edison Marrese-Taylor, Rinalds Vīksna",http://arxiv.org/pdf/2412.06179v1,cs.CL
Investigating Acoustic-Textual Emotional Inconsistency Information for Automatic Depression Detection,"Previous studies have demonstrated that emotional features from a single
acoustic sentiment label can enhance depression diagnosis accuracy.
Additionally, according to the Emotion Context-Insensitivity theory and our
pilot study, individuals with depression might convey negative emotional
content in an unexpectedly calm manner, showing a high degree of inconsistency
in emotional expressions during natural conversations. So far, few studies have
recognized and leveraged the emotional expression inconsistency for depression
detection. In this paper, a multimodal cross-attention method is presented to
capture the Acoustic-Textual Emotional Inconsistency (ATEI) information. This
is achieved by analyzing the intricate local and long-term dependencies of
emotional expressions across acoustic and textual domains, as well as the
mismatch between the emotional content within both domains. A Transformer-based
model is then proposed to integrate this ATEI information with various fusion
strategies for detecting depression. Furthermore, a scaling technique is
employed to adjust the ATEI feature degree during the fusion process, thereby
enhancing the model's ability to discern patients with depression across
varying levels of severity. To best of our knowledge, this work is the first to
incorporate emotional expression inconsistency information into depression
detection. Experimental results on a counseling conversational dataset
illustrate the effectiveness of our method.",2024-12-09,"Rongfeng Su, Changqing Xu, Xinyi Wu, Feng Xu, Xie Chen, Lan Wangt, Nan Yan",http://arxiv.org/pdf/2412.18614v1,cs.CL
Query-Efficient Planning with Language Models,"Planning in complex environments requires an agent to efficiently query a
world model to find a feasible sequence of actions from start to goal. Recent
work has shown that Large Language Models (LLMs), with their rich prior
knowledge and reasoning capabilities, can potentially help with planning by
searching over promising states and adapting to feedback from the world. In
this paper, we propose and study two fundamentally competing frameworks that
leverage LLMs for query-efficient planning. The first uses LLMs as a heuristic
within a search-based planner to select promising nodes to expand and propose
promising actions. The second uses LLMs as a generative planner to propose an
entire sequence of actions from start to goal, query a world model, and adapt
based on feedback. We show that while both approaches improve upon comparable
baselines, using an LLM as a generative planner results in significantly fewer
interactions. Our key finding is that the LLM as a planner can more rapidly
adapt its planning strategies based on immediate feedback than LLM as a
heuristic. We present evaluations and ablations on Robotouille and PDDL
planning benchmarks and discuss connections to existing theory on
query-efficient planning algorithms. Code is available at
https://github.com/portal-cornell/llms-for-planning",2024-12-09,"Gonzalo Gonzalez-Pumariega, Wayne Chen, Kushal Kedia, Sanjiban Choudhury",http://arxiv.org/pdf/2412.06162v1,cs.CL
Exploring Complex Mental Health Symptoms via Classifying Social Media Data with Explainable LLMs,"We propose a pipeline for gaining insights into complex diseases by training
LLMs on challenging social media text data classification tasks, obtaining
explanations for the classification outputs, and performing qualitative and
quantitative analysis on the explanations. We report initial results on
predicting, explaining, and systematizing the explanations of predicted reports
on mental health concerns in people reporting Lyme disease concerns. We report
initial results on predicting future ADHD concerns for people reporting anxiety
disorder concerns, and demonstrate preliminary results on visualizing the
explanations for predicting that a person with anxiety concerns will in the
future have ADHD concerns.",2024-12-09,"Kexin Chen, Noelle Lim, Claire Lee, Michael Guerzhoy",http://arxiv.org/pdf/2412.10414v1,cs.CL
The Computational Limits of State-Space Models and Mamba via the Lens of Circuit Complexity,"In this paper, we analyze the computational limitations of Mamba and
State-space Models (SSMs) by using the circuit complexity framework. Despite
Mamba's stateful design and recent attention as a strong candidate to
outperform Transformers, we have demonstrated that both Mamba and SSMs with
$\mathrm{poly}(n)$-precision and constant-depth layers reside within the
$\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ complexity class. This result
indicates Mamba has the same computational capabilities as Transformer
theoretically, and it cannot solve problems like arithmetic formula problems,
boolean formula value problems, and permutation composition problems if
$\mathsf{TC}^0 \neq \mathsf{NC}^1$. Therefore, it challenges the assumption
Mamba is more computationally expressive than Transformers. Our contributions
include rigorous proofs showing that Selective SSM and Mamba architectures can
be simulated by $\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ circuits, and they
cannot solve problems outside $\mathsf{TC}^0$.",2024-12-09,"Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song",http://arxiv.org/pdf/2412.06148v2,cs.CL
Hate Speech According to the Law: An Analysis for Effective Detection,"The issue of hate speech extends beyond the confines of the online realm. It
is a problem with real-life repercussions, prompting most nations to formulate
legal frameworks that classify hate speech as a punishable offence. These legal
frameworks differ from one country to another, contributing to the big chaos
that online platforms have to face when addressing reported instances of hate
speech. With the definitions of hate speech falling short in introducing a
robust framework, we turn our gaze onto hate speech laws. We consult the
opinion of legal experts on a hate speech dataset and we experiment by
employing various approaches such as pretrained models both on hate speech and
legal data, as well as exploiting two large language models (Qwen2-7B-Instruct
and Meta-Llama-3-70B). Due to the time-consuming nature of data acquisition for
prosecutable hate speech, we use pseudo-labeling to improve our pretrained
models. This study highlights the importance of amplifying research on
prosecutable hate speech and provides insights into effective strategies for
combating hate speech within the parameters of legal frameworks. Our findings
show that legal knowledge in the form of annotations can be useful when
classifying prosecutable hate speech, yet more focus should be paid on the
differences between the laws.",2024-12-09,"Katerina Korre, John Pavlopoulos, Paolo Gajo, Alberto Barrón-Cedeño",http://arxiv.org/pdf/2412.06144v1,cs.CL
MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization,"The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.",2024-12-09,"Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao",http://arxiv.org/pdf/2412.06141v3,cs.CL
AIDE: Task-Specific Fine Tuning with Attribute Guided Multi-Hop Data Expansion,"Fine-tuning large language models (LLMs) for specific tasks requires
high-quality, diverse training data relevant to the task. Recent research has
leveraged LLMs to synthesize training data, but existing approaches either
depend on large seed datasets or struggle to ensure both task relevance and
data diversity in the generated outputs. To address these challenges, we
propose AIDE, a novel data synthesis framework that uses a multi-hop process to
expand 10 seed data points while ensuring diversity and task relevance. AIDE
extracts the main topic and key knowledge attributes from the seed data to
guide the synthesis process. In each subsequent hop, it extracts the topic and
attributes from the newly generated data and continues guided synthesis. This
process repeats for a total of K hops. To prevent irrelevant data generation as
the hop depth increases, AIDE incorporates a residual connection mechanism and
uses self-reflection to improve data quality. Our empirical results demonstrate
that fine-tuning Mistral-7B, Llama-3.1-8B and Llama-3.2-3B with AIDE achieves
more than 10% accuracy improvements over the base models across 13 tasks from 5
different benchmarks, while outperforming the models fine-tuned with
state-of-the-art data synthesis methods like Evol-Instruct, DataTune and
Prompt2Model.",2024-12-09,"Jiayu Li, Xuan Zhu, Fang Liu, Yanjun Qi",http://arxiv.org/pdf/2412.06136v1,cs.CL
Evaluating and Mitigating Social Bias for Large Language Models in Open-ended Settings,"Current social bias benchmarks for Large Language Models (LLMs) primarily
rely on pre-defined question formats like multiple-choice, limiting their
ability to reflect the complexity and open-ended nature of real-world
interactions. To address this gap, we extend an existing BBQ dataset introduced
by incorporating fill-in-the-blank and short-answer question types, designed to
evaluate biases in an open-ended setting. Our finding reveals that LLMs tend to
produce responses that are more biased against certain protected attributes,
like age and socio-economic status. On the other hand, these biased outputs
produced by LLMs can serve as valuable contexts and chains of thought for
debiasing. Our debiasing approach combined zero-shot, few-shot, and
chain-of-thought could significantly reduce the level of bias to almost 0. We
open-source our evaluation and debiasing code hoping to encourage further
measurements and mitigation of bias and stereotype in LLMs.",2024-12-09,"Zhao Liu, Tian Xie, Xueru Zhang",http://arxiv.org/pdf/2412.06134v2,cs.CL
Infusing Prompts with Syntax and Semantics,"Despite impressive success, language models often generate outputs with
flawed linguistic structure. We analyze the effect of directly infusing various
kinds of syntactic and semantic information into large language models. To
demonstrate the value of our proposals, we focus on the translation of natural
language queries to SQL, in particular dealing with languages with less
resources than English, to better investigate how much help we can get from low
cost syntactic and semantic information. We show that linguistic analysis can
significantly boost language models, to the point that we have surpassed
previous best systems.",2024-12-08,"Anton Bulle Labate, Fabio Gagliardi Cozman",http://arxiv.org/pdf/2412.06107v1,cs.CL
Enhanced Computationally Efficient Long LoRA Inspired Perceiver Architectures for Auto-Regressive Language Modeling,"The Transformer architecture has revolutionized the Natural Language
Processing field and is the backbone of Large Language Models (LLMs). The
Transformer uses the attention mechanism that computes the pair-wise similarity
between its input tokens to produce latent vectors that are able to understand
the semantic meaning of the input text. One of the challenges in the
Transformer architecture is the quadratic complexity of the attention mechanism
that prohibits the efficient processing of long sequence lengths. While many
recent research works have attempted to provide a reduction from $O(n^2)$ time
complexity of attention to semi-linear complexity, it remains an unsolved
problem in the sense of maintaining a high performance when such complexity is
reduced. One of the important works in this respect is the Perceiver class of
architectures that have demonstrated excellent performance while reducing the
computation complexity. In this paper, we use the PerceiverAR that was proposed
for Auto-Regressive modeling as a baseline, and provide three different
architectural enhancements to it with varying computation overhead tradeoffs.
Inspired by the recently proposed efficient attention computation approach of
Long-LoRA, we then present an equally efficient Perceiver-based architecture
(termed as Long LoRA Pereceiver - LLP) that can be used as the base
architecture in LLMs instead of just a fine-tuning add-on. Our results on
different benchmarks indicate impressive improvements compared to recent
Transformer based models.",2024-12-08,"Kaleel Mahmood, Shaoyi Huang",http://arxiv.org/pdf/2412.06106v1,cs.CL
"Measuring Grammatical Diversity from Small Corpora: Derivational Entropy Rates, Mean Length of Utterances, and Annotation Invariance","In many fields, such as language acquisition, neuropsychology of language,
the study of aging, and historical linguistics, corpora are used for estimating
the diversity of grammatical structures that are produced during a period by an
individual, community, or type of speakers. In these cases, treebanks are taken
as representative samples of the syntactic structures that might be
encountered. Generalizing the potential syntactic diversity from the structures
documented in a small corpus requires careful extrapolation whose accuracy is
constrained by the limited size of representative sub-corpora. In this article,
I demonstrate -- theoretically, and empirically -- that a grammar's
derivational entropy and the mean length of the utterances (MLU) it generates
are fundamentally linked, giving rise to a new measure, the derivational
entropy rate. The mean length of utterances becomes the most practical index of
syntactic complexity; I demonstrate that MLU is not a mere proxy, but a
fundamental measure of syntactic diversity. In combination with the new
derivational entropy rate measure, it provides a theory-free assessment of
grammatical complexity. The derivational entropy rate indexes the rate at which
different grammatical annotation frameworks determine the grammatical
complexity of treebanks. I introduce the Smoothed Induced Treebank Entropy
(SITE) as a tool for estimating these measures accurately, even from very small
treebanks. I conclude by discussing important implications of these results for
both NLP and human language processing.",2024-12-08,Fermin Moscoso del Prado Martin,http://arxiv.org/pdf/2412.06095v1,cs.CL
Taming Sensitive Weights : Noise Perturbation Fine-tuning for Robust LLM Quantization,"Quantization is a critical step to enable efficient LLM serving under limited
resource. However, previous research observes that certain weights in the LLM,
known as outliers, are significantly sensitive to quantization noises. Existing
quantization methods leave these outliers as floating points or higher
precisions to retain performance, posting challenges on the efficient hardware
deployment of the mixed-precision model. This work investigates an alternative
way to tame the sensitive weights' impact on the quantization error, by
reducing the loss Hessian trace with respect to outliers through an efficient
fine-tuning process. We propose Noise Perturbation Fine-tuning (NPFT), which
identifies outlier weights and add random weight perturbations on the outliers
as the model going through a PEFT optimization. NPFT tames the sensitivity of
outlier weights so that the quantized model performance can be improved without
special treatment to the outliers. When applied to OPT and LLaMA models, our
NPFT method achieves stable performance improvements for both uniform and
non-uniform quantizers, while also offering better inference efficiency.
Notably, the simplest RTN can achieve performance on par with GPTQ using our
NPFT on LLaMA2-7B-4bits benchmark.",2024-12-08,"Dongwei Wang, Huanrui Yang",http://arxiv.org/pdf/2412.06858v2,cs.CL
KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models,"The increasing sizes of large language models (LLMs) result in significant
computational overhead and memory usage when adapting these models to specific
tasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have
been devised to mitigate these challenges by training a small set of parameters
for the task-specific updates of the model weights. Among PEFT methods, LoRA
stands out for its simplicity and efficiency, inspiring the development of a
series of variants. However, LoRA and its successors disregard the knowledge
that is noisy or irrelevant to the targeted task, detrimentally impacting model
performance and leading to suboptimality. To address this limitation, we
introduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that
leverages singular value decomposition (SVD) with knowledge-aware singular
values to dynamically activate knowledge based on its relevance to the task at
hand. We conduct extensive experiments across a range of LLMs on tasks spanning
natural language understanding (NLU), generation (NLG), instruction following,
and commonsense reasoning. The experimental results demonstrate that KaSA
consistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks
and 4 synthetic datasets, underscoring our method's efficacy and adaptability.
The source code of our method is available at
https://github.com/juyongjiang/KaSA.",2024-12-08,"Fan Wang, Juyong Jiang, Chansung Park, Sunghun Kim, Jing Tang",http://arxiv.org/pdf/2412.06071v2,cs.CL
Steering Large Language Models to Evaluate and Amplify Creativity,"Although capable of generating creative text, Large Language Models (LLMs)
are poor judges of what constitutes ""creativity"". In this work, we show that we
can leverage this knowledge of how to write creatively in order to better judge
what is creative. We take a mechanistic approach that extracts differences in
the internal states of an LLM when prompted to respond ""boringly"" or
""creatively"" to provide a robust measure of creativity that corresponds
strongly with human judgment. We also show these internal state differences can
be applied to enhance the creativity of generated text at inference time.",2024-12-08,"Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Shao-yen Tseng, Vasudev Lal",http://arxiv.org/pdf/2412.06060v1,cs.CL
Can Generative AI Solve Your In-Context Learning Problem? A Martingale Perspective,"This work is about estimating when a conditional generative model (CGM) can
solve an in-context learning (ICL) problem. An in-context learning (ICL)
problem comprises a CGM, a dataset, and a prediction task. The CGM could be a
multi-modal foundation model; the dataset, a collection of patient histories,
test results, and recorded diagnoses; and the prediction task to communicate a
diagnosis to a new patient. A Bayesian interpretation of ICL assumes that the
CGM computes a posterior predictive distribution over an unknown Bayesian model
defining a joint distribution over latent explanations and observable data.
From this perspective, Bayesian model criticism is a reasonable approach to
assess the suitability of a given CGM for an ICL problem. However, such
approaches -- like posterior predictive checks (PPCs) -- often assume that we
can sample from the likelihood and posterior defined by the Bayesian model,
which are not explicitly given for contemporary CGMs. To address this, we show
when ancestral sampling from the predictive distribution of a CGM is equivalent
to sampling datasets from the posterior predictive of the assumed Bayesian
model. Then we develop the generative predictive $p$-value, which enables PPCs
and their cousins for contemporary CGMs. The generative predictive $p$-value
can then be used in a statistical decision procedure to determine when the
model is appropriate for an ICL problem. Our method only requires generating
queries and responses from a CGM and evaluating its response log probability.
We empirically evaluate our method on synthetic tabular, imaging, and natural
language ICL tasks using large language models.",2024-12-08,"Andrew Jesson, Nicolas Beltran-Velez, David Blei",http://arxiv.org/pdf/2412.06033v1,cs.CL
1-800-SHARED-TASKS at RegNLP: Lexical Reranking of Semantic Retrieval (LeSeR) for Regulatory Question Answering,"This paper presents the system description of our entry for the COLING 2025
RegNLP RIRAG (Regulatory Information Retrieval and Answer Generation)
challenge, focusing on leveraging advanced information retrieval and answer
generation techniques in regulatory domains. We experimented with a combination
of embedding models, including Stella, BGE, CDE, and Mpnet, and leveraged
fine-tuning and reranking for retrieving relevant documents in top ranks. We
utilized a novel approach, LeSeR, which achieved competitive results with a
recall@10 of 0.8201 and map@10 of 0.6655 for retrievals. This work highlights
the transformative potential of natural language processing techniques in
regulatory applications, offering insights into their capabilities for
implementing a retrieval augmented generation system while identifying areas
for future improvement in robustness and domain adaptation.",2024-12-08,"Jebish Purbey, Drishti Sharma, Siddhant Gupta, Khawaja Murad, Siddartha Pullakhandam, Ram Mohan Rao Kadiyala",http://arxiv.org/pdf/2412.06009v1,cs.CL
"Does RLHF Scale? Exploring the Impacts From Data, Model, and Method","This study explores the scaling properties of Reinforcement Learning from
Human Feedback (RLHF) in Large Language Models (LLMs). Although RLHF is
considered an important step in post-training of LLMs, its scaling potential is
still largely unknown. We systematically analyze key components in the RLHF
framework--model size, data composition, and inference budget--and their
impacts on performance. Our findings show that increasing data diversity and
volume improves reward model performance, helping process-supervision models
scale better. For policy training, more response samples per prompt boost
performance initially but quickly plateau. And larger reward models offer
modest gains in policy training. In addition, larger policy models benefit less
from RLHF with a fixed reward model. Overall, RLHF scales less efficiently than
pretraining, with diminishing returns from additional computational resources.
Based on these observations, we propose strategies to optimize RLHF performance
within computational limits.",2024-12-08,"Zhenyu Hou, Pengfan Du, Yilin Niu, Zhengxiao Du, Aohan Zeng, Xiao Liu, Minlie Huang, Hongning Wang, Jie Tang, Yuxiao Dong",http://arxiv.org/pdf/2412.06000v1,cs.CL
Language hooks: a modular framework for augmenting LLM reasoning that decouples tool usage from the model and its prompt,"Prompting and fine-tuning have emerged as two competing paradigms for
augmenting language models with new capabilities, such as the use of tools.
Prompting approaches are quick to set up but rely on providing explicit
demonstrations of each tool's usage in the model's prompt, thus coupling tool
use to the task at hand and limiting generalisation. Fine-tuning removes the
need for task-specific demonstrations of tool usage at runtime; however, this
ties new capabilities to a single model, thus making already-heavier setup
costs a recurring expense. In this paper, we introduce language hooks, a novel
framework for augmenting language models with new capabilities that is
decoupled both from the model's task-specific prompt and from the model itself.
The language hook algorithm interleaves text generation by the base model with
the execution of modular programs that trigger conditionally based on the
existing text and the available capabilities. Upon triggering, programs may
call external tools, auxiliary language models (e.g. using tool specific
prompts), and modify the existing context. We benchmark our method against
state-of-the-art baselines, find that it outperforms task-aware approaches, and
demonstrate its ability to generalise to novel tasks.",2024-12-08,"Damien de Mijolla, Wen Yang, Philippa Duckett, Christopher Frye, Mark Worrall",http://arxiv.org/pdf/2412.05967v1,cs.CL
A Cross-Validation Study of Turkish Sentiment Analysis Datasets and Tools,"In recent years, sentiment analysis has gained increasing significance,
prompting researchers to explore datasets in various languages, including
Turkish. However, the limited availability of Turkish datasets has led to their
multifaceted usage in different studies, yielding diverse outcomes. To overcome
this challenge, a rigorous review was conducted of research articles published
between 2012 and 2022. 31 studies were listed, and 23 Turkish datasets obtained
from publicly available sources and email requests used in these studies were
collected. We labeled these 31 studies using a taxonomy. We provide a map of
sentiment analysis datasets according to this taxonomy in Turkish over 10
years. Moreover, we run state-of-the-art sentiment analysis tools on these
datasets and analyzed performance across popular Turkish sentiment datasets. We
observed that the performance of the sentiment analysis tools significantly
depends on the characteristics of the target text. Our study fosters a more
nuanced understanding of sentiment analysis in the Turkish language.",2024-12-08,"Şevval Çakıcı, Dilara Karaduman, Mehmet Akif Çırlan, Ali Hürriyetoğlu",http://arxiv.org/pdf/2412.05964v1,cs.CL
Towards AI-$45^{\circ}$ Law: A Roadmap to Trustworthy AGI,"Ensuring Artificial General Intelligence (AGI) reliably avoids harmful
behaviors is a critical challenge, especially for systems with high autonomy or
in safety-critical domains. Despite various safety assurance proposals and
extreme risk warnings, comprehensive guidelines balancing AI safety and
capability remain lacking. In this position paper, we propose the
\textit{AI-\textbf{$45^{\circ}$} Law} as a guiding principle for a balanced
roadmap toward trustworthy AGI, and introduce the \textit{Causal Ladder of
Trustworthy AGI} as a practical framework. This framework provides a systematic
taxonomy and hierarchical structure for current AI capability and safety
research, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder
comprises three core layers: the Approximate Alignment Layer, the Intervenable
Layer, and the Reflectable Layer. These layers address the key challenges of
safety and trustworthiness in AGI and contemporary AI systems. Building upon
this framework, we define five levels of trustworthy AGI: perception,
reasoning, decision-making, autonomy, and collaboration trustworthiness. These
levels represent distinct yet progressive aspects of trustworthy AGI. Finally,
we present a series of potential governance measures to support the development
of trustworthy AGI.",2024-12-08,"Chao Yang, Chaochao Lu, Yingchun Wang, Bowen Zhou",http://arxiv.org/pdf/2412.14186v2,cs.CL
Exploring Multi-Grained Concept Annotations for Multimodal Large Language Models,"Multimodal Large Language Models (MLLMs) excel in vision--language tasks by
pre-training solely on coarse-grained concept annotations (e.g., image
captions). We hypothesize that integrating fine-grained concept annotations
(e.g., object labels and object regions) will further improve performance, as
both data granularities complement each other in terms of breadth and depth in
concept representation. We introduce a new dataset featuring Multimodal
Multi-Grained Concept annotations (MMGiC) for MLLMs. In constructing MMGiC, we
explore the impact of different data recipes on multimodal comprehension and
generation. Our analyses reveal that multi-grained concept annotations
integrate and complement each other, under our structured template and a
general MLLM framework. We clearly explore and demonstrate the potential of
MMGiC to help MLLMs better locate and learn concepts, aligning vision and
language at multiple granularities. We further validate our hypothesis by
investigating the fair comparison and effective collaboration between MMGiC and
image--caption data on 12 multimodal comprehension and generation benchmarks,
e.g., their appropriate combination achieve 3.95% and 2.34% absolute
improvements over image--caption data alone on POPE and SEED-Bench. Code, data
and models will be available at https://github.com/LooperXX/MMGiC.",2024-12-08,"Xiao Xu, Tianhao Niu, Yuxi Xie, Libo Qin, Wanxiang Che, Min-Yen Kan",http://arxiv.org/pdf/2412.05939v1,cs.CL
Paraphrase-Aligned Machine Translation,"Large Language Models (LLMs) have demonstrated significant capabilities in
machine translation. However, their translation quality is sometimes
questioned, as the generated outputs may deviate from expressions typically
used by native speakers. These deviations often arise from differences in
sentence structure between language systems. To address this issue, we propose
ParaAlign Translator, a method that fine-tunes LLMs to paraphrase sentences,
aligning their structures with those of the target language systems. This
approach improves the performance of subsequent translations. Experimental
results demonstrate that the proposed method enhances the LLaMA-3-8B model's
performance in both resource-rich and low-resource scenarios and achieves
parity with or surpassing the much larger LLaMA-3-70B model.",2024-12-08,"Ke-Ching Chang, Chung-Chi Chen, An-Zi Yen",http://arxiv.org/pdf/2412.05916v1,cs.CL
XKV: Personalized KV Cache Memory Reduction for Long-Context LLM Inference,"Recently the generative Large Language Model (LLM) has achieved remarkable
success in numerous applications. Notably its inference generates output tokens
one-by-one, leading to many redundant computations. The widely-used KV-Cache
framework makes a compromise between time and space complexities. However,
caching data generates the increasingly growing memory demand, that can quickly
exhaust the limited memory capacity of the modern accelerator like GPUs,
particularly in long-context inference tasks. Existing studies reduce memory
consumption by evicting some of cached data that have less important impact on
inference accuracy. But the benefit in practice is far from ideal due to the
static cache allocation across different LLM network layers. This paper
observes that the layer-specific cached data have very different impacts on
accuracy. We quantify this difference, and give experimental and theoretical
validation. We accordingly make a formal analysis and shows that customizing
the cache size for each layer in a personalized manner can yield a significant
memory reduction, while still providing comparable accuracy. We simulate the
cache allocation as a combinatorial optimization problem and give a global
optimal solution. In particular, we devise a mini- and sampling-based inference
over a lightweight variant of the LLM model, so as to quickly capture the
difference and then feed it into the personalized algorithms. Extensive
experiments on real-world datasets demonstrate that our proposals can reduce KV
cache memory consumption by 61.6% on average, improve computational efficiency
by 2.1x and then increase the throughput by up to 5.5x.",2024-12-08,"Weizhuo Li, Zhigang Wang, Yu Gu, Ge Yu",http://arxiv.org/pdf/2412.05896v1,cs.CL
"Evaluating Robustness of LLMs on Crisis-Related Microblogs across Events, Information Types, and Linguistic Features","The widespread use of microblogging platforms like X (formerly Twitter)
during disasters provides real-time information to governments and response
authorities. However, the data from these platforms is often noisy, requiring
automated methods to filter relevant information. Traditionally, supervised
machine learning models have been used, but they lack generalizability. In
contrast, Large Language Models (LLMs) show better capabilities in
understanding and processing natural language out of the box. This paper
provides a detailed analysis of the performance of six well-known LLMs in
processing disaster-related social media data from a large-set of real-world
events. Our findings indicate that while LLMs, particularly GPT-4o and GPT-4,
offer better generalizability across different disasters and information types,
most LLMs face challenges in processing flood-related data, show minimal
improvement despite the provision of examples (i.e., shots), and struggle to
identify critical information categories like urgent requests and needs.
Additionally, we examine how various linguistic features affect model
performance and highlight LLMs' vulnerabilities against certain features like
typos. Lastly, we provide benchmarking results for all events across both zero-
and few-shot settings and observe that proprietary models outperform
open-source ones in all tasks.",2024-12-08,"Muhammad Imran, Abdul Wahab Ziaullah, Kai Chen, Ferda Ofli",http://arxiv.org/pdf/2412.10413v1,cs.CL
Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information,"Ontology-based knowledge graphs (KG) are desirable for effective knowledge
management and reuse in various decision making scenarios, including design.
Creating and populating extensive KG based on specific ontological models can
be highly labour and time-intensive unless automated processes are developed
for knowledge extraction and graph creation. Most research and development on
automated extraction and creation of KG is based on extensive unstructured data
sets that provide contextual information. However, some of the most useful
information about the products and services of a company has traditionally been
recorded as structured data. Such structured data sets rarely follow a standard
ontology, do not capture explicit mapping of relationships between the
entities, and provide no contextual information. Therefore, this research
reports a method and digital workflow developed to address this gap. The
developed method and workflow employ rule-based techniques to extract and
create a Function Behaviour-Structure (FBS) ontology-based KG from legacy
structured data, especially specification sheets and product catalogues. The
solution approach consists of two main components: a process for deriving
context and context-based classification rules for FBS ontology concepts and a
workflow for populating and retrieving the FBS ontology-based KG. KG and
Natural Language Processing (NLP) are used to automate knowledge extraction,
representation, and retrieval. The workflow's effectiveness is demonstrated via
pilot implementation in an industrial context. Insights gained from the pilot
study are reported regarding the challenges and opportunities, including
discussing the FBS ontology and concepts.",2024-12-08,"Vijayalaxmi Sahadevan, Sushil Mario, Yash Jaiswal, Divyanshu Bajpai, Vishal Singh, Hiralal Aggarwal, Suhas Suresh, Manjunath Maigur",http://arxiv.org/pdf/2412.05868v1,cs.CL
From Critique to Clarity: A Pathway to Faithful and Personalized Code Explanations with Large Language Models,"In the realm of software development, providing accurate and personalized
code explanations is crucial for both technical professionals and business
stakeholders. Technical professionals benefit from enhanced understanding and
improved problem-solving skills, while business stakeholders gain insights into
project alignments and transparency. Despite the potential, generating such
explanations is often time-consuming and challenging. This paper presents an
innovative approach that leverages the advanced capabilities of large language
models (LLMs) to generate faithful and personalized code explanations. Our
methodology integrates prompt enhancement, self-correction mechanisms,
personalized content customization, and interaction with external tools,
facilitated by collaboration among multiple LLM agents. We evaluate our
approach using both automatic and human assessments, demonstrating that our
method not only produces accurate explanations but also tailors them to
individual user preferences. Our findings suggest that this approach
significantly improves the quality and relevance of code explanations, offering
a valuable tool for developers and stakeholders alike.",2024-12-08,"Zexing Xu, Zhuang Luo, Yichuan Li, Kyumin Lee, S. Rasoul Etesami",http://arxiv.org/pdf/2501.14731v1,cs.CL
Domain-Specific Translation with Open-Source Large Language Models: Resource-Oriented Analysis,"In this work, we compare the domain-specific translation performance of
open-source autoregressive decoder-only large language models (LLMs) with
task-oriented machine translation (MT) models. Our experiments focus on the
medical domain and cover four language directions with varied resource
availability: English-to-French, English-to-Portuguese, English-to-Swahili, and
Swahili-to-English. Despite recent advancements, LLMs demonstrate a significant
quality gap in specialized translation compared to multilingual encoder-decoder
MT models such as NLLB-200. Our results indicate that NLLB-200 3.3B outperforms
all evaluated LLMs in the 7-8B parameter range across three out of the four
language directions. While fine-tuning improves the performance of LLMs such as
Mistral and Llama, these models still underperform compared to fine-tuned
NLLB-200 3.3B models. Our findings highlight the ongoing need for specialized
MT models to achieve high-quality domain-specific translation, especially in
medium-resource and low-resource settings. Moreover, the superior performance
of larger LLMs over their 8B variants suggests potential value in pre-training
domain-specific medium-sized language models, employing targeted data selection
and knowledge distillation approaches to enhance both quality and efficiency in
specialized translation tasks.",2024-12-08,"Aman Kassahun Wassie, Mahdi Molaei, Yasmin Moslem",http://arxiv.org/pdf/2412.05862v3,cs.CL
Depression detection from Social Media Bangla Text Using Recurrent Neural Networks,"Emotion artificial intelligence is a field of study that focuses on figuring
out how to recognize emotions, especially in the area of text mining. Today is
the age of social media which has opened a door for us to share our individual
expressions, emotions, and perspectives on any event. We can analyze sentiment
on social media posts to detect positive, negative, or emotional behavior
toward society. One of the key challenges in sentiment analysis is to identify
depressed text from social media text that is a root cause of mental
ill-health. Furthermore, depression leads to severe impairment in day-to-day
living and is a major source of suicide incidents. In this paper, we apply
natural language processing techniques on Facebook texts for conducting emotion
analysis focusing on depression using multiple machine learning algorithms.
Preprocessing steps like stemming, stop word removal, etc. are used to clean
the collected data, and feature extraction techniques like stylometric feature,
TF-IDF, word embedding, etc. are applied to the collected dataset which
consists of 983 texts collected from social media posts. In the process of
class prediction, LSTM, GRU, support vector machine, and Naive-Bayes
classifiers have been used. We have presented the results using the primary
classification metrics including F1-score, and accuracy. This work focuses on
depression detection from social media posts to help psychologists to analyze
sentiment from shared posts which may reduce the undesirable behaviors of
depressed individuals through diagnosis and treatment.",2024-12-08,"Sultan Ahmed, Salman Rakin, Mohammad Washeef Ibn Waliur, Nuzhat Binte Islam, Billal Hossain, Md. Mostofa Akbar",http://arxiv.org/pdf/2412.05861v1,cs.CL
Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents,"Text-to-SQL task aims to automatically yield SQL queries according to user
text questions. To address this problem, we propose a Cooperative SQL
Generation framework based on Multi-functional Agents (CSMA) through
information interaction among large language model (LLM) based agents who own
part of the database schema seperately. Inspired by the collaboration in human
teamwork, CSMA consists of three stages: 1) Question-related schema collection,
2) Question-corresponding SQL query generation, and 3) SQL query correctness
check. In the first stage, agents analyze their respective schema and
communicate with each other to collect the schema information relevant to the
question. In the second stage, agents try to generate the corresponding SQL
query for the question using the collected information. In the third stage,
agents check if the SQL query is created correctly according to their known
information. This interaction-based method makes the question-relevant part of
database schema from each agent to be used for SQL generation and check.
Experiments on the Spider and Bird benckmark demonstrate that CSMA achieves a
high performance level comparable to the state-of-the-arts, meanwhile holding
the private data in these individual agents.",2024-12-08,"Zhiguang Wu, Fengbin Zhu, Xuequn Shang, Yupei Zhang, Pan Zhou",http://arxiv.org/pdf/2412.05850v1,cs.CL
Are Clinical T5 Models Better for Clinical Text?,"Large language models with a transformer-based encoder/decoder architecture,
such as T5, have become standard platforms for supervised tasks. To bring these
technologies to the clinical domain, recent work has trained new or adapted
existing models to clinical data. However, the evaluation of these clinical T5
models and comparison to other models has been limited. Are the clinical T5
models better choices than FLAN-tuned generic T5 models? Do they generalize
better to new clinical domains that differ from the training sets? We
comprehensively evaluate these models across several clinical tasks and
domains. We find that clinical T5 models provide marginal improvements over
existing models, and perform worse when evaluated on different domains. Our
results inform future choices in developing clinical LLMs.",2024-12-08,"Yahan Li, Keith Harrigian, Ayah Zirikly, Mark Dredze",http://arxiv.org/pdf/2412.05845v1,cs.CL
A Self-Learning Multimodal Approach for Fake News Detection,"The rapid growth of social media has resulted in an explosion of online news
content, leading to a significant increase in the spread of misleading or false
information. While machine learning techniques have been widely applied to
detect fake news, the scarcity of labeled datasets remains a critical
challenge. Misinformation frequently appears as paired text and images, where a
news article or headline is accompanied by a related visuals. In this paper, we
introduce a self-learning multimodal model for fake news classification. The
model leverages contrastive learning, a robust method for feature extraction
that operates without requiring labeled data, and integrates the strengths of
Large Language Models (LLMs) to jointly analyze both text and image features.
LLMs are excel at this task due to their ability to process diverse linguistic
data drawn from extensive training corpora. Our experimental results on a
public dataset demonstrate that the proposed model outperforms several
state-of-the-art classification approaches, achieving over 85% accuracy,
precision, recall, and F1-score. These findings highlight the model's
effectiveness in tackling the challenges of multimodal fake news detection.",2024-12-08,"Hao Chen, Hui Guo, Baochen Hu, Shu Hu, Jinrong Hu, Siwei Lyu, Xi Wu, Xin Wang",http://arxiv.org/pdf/2412.05843v1,cs.CL
Experimenting with Multi-modal Information to Predict Success of Indian IPOs,"With consistent growth in Indian Economy, Initial Public Offerings (IPOs)
have become a popular avenue for investment. With the modern technology
simplifying investments, more investors are interested in making data driven
decisions while subscribing for IPOs. In this paper, we describe a machine
learning and natural language processing based approach for estimating if an
IPO will be successful. We have extensively studied the impact of various facts
mentioned in IPO filing prospectus, macroeconomic factors, market conditions,
Grey Market Price, etc. on the success of an IPO. We created two new datasets
relating to the IPOs of Indian companies. Finally, we investigated how
information from multiple modalities (texts, images, numbers, and categorical
features) can be used for estimating the direction and underpricing with
respect to opening, high and closing prices of stocks on the IPO listing day.",2024-12-08,"Sohom Ghosh, Arnab Maji, N Harsha Vardhan, Sudip Kumar Naskar",http://arxiv.org/pdf/2412.16174v1,cs.CL
GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model,"Recent research on integrating Large Language Models (LLMs) with Graph Neural
Networks (GNNs) typically follows two approaches: LLM-centered models, which
convert graph data into tokens for LLM processing, and GNN-centered models,
which use LLMs to encode text features into node and edge representations for
GNN input. LLM-centered models often struggle to capture graph structures
effectively, while GNN-centered models compress variable-length textual data
into fixed-size vectors, limiting their ability to understand complex
semantics. Additionally, GNN-centered approaches require converting tasks into
a uniform, manually-designed format, restricting them to classification tasks
and preventing language output. To address these limitations, we introduce a
new architecture that deeply integrates GNN with LLM, featuring three key
innovations: (1) Structure-Aware Transformers, which incorporate GNN's
message-passing capabilities directly into LLM's transformer layers, allowing
simultaneous processing of textual and structural information and generating
outputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes
full, uncompressed text from graph nodes and edges, ensuring complete semantic
integration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible
autoregressive generation alongside GNN's scalable one-pass prediction.
GL-Fusion achieves outstand performance on various tasks. Notably, it achieves
state-of-the-art performance on OGBN-Arxiv and OGBG-Code2.",2024-12-08,"Haotong Yang, Xiyuan Wang, Qian Tao, Shuxian Hu, Zhouchen Lin, Muhan Zhang",http://arxiv.org/pdf/2412.06849v1,cs.CL
An Entailment Tree Generation Approach for Multimodal Multi-Hop Question Answering with Mixture-of-Experts and Iterative Feedback Mechanism,"With the rise of large-scale language models (LLMs), it is currently popular
and effective to convert multimodal information into text descriptions for
multimodal multi-hop question answering. However, we argue that the current
methods of multi-modal multi-hop question answering still mainly face two
challenges: 1) The retrieved evidence containing a large amount of redundant
information, inevitably leads to a significant drop in performance due to
irrelevant information misleading the prediction. 2) The reasoning process
without interpretable reasoning steps makes the model difficult to discover the
logical errors for handling complex questions. To solve these problems, we
propose a unified LLMs-based approach but without heavily relying on them due
to the LLM's potential errors, and innovatively treat multimodal multi-hop
question answering as a joint entailment tree generation and question answering
problem. Specifically, we design a multi-task learning framework with a focus
on facilitating common knowledge sharing across interpretability and prediction
tasks while preventing task-specific errors from interfering with each other
via mixture of experts. Afterward, we design an iterative feedback mechanism to
further enhance both tasks by feeding back the results of the joint training to
the LLM for regenerating entailment trees, aiming to iteratively refine the
potential answer. Notably, our method has won the first place in the official
leaderboard of WebQA (since April 10, 2024), and achieves competitive results
on MultimodalQA.",2024-12-08,"Qing Zhang, Haocheng Lv, Jie Liu, Zhiyun Chen, Jianyong Duan, Hao Wang, Li He, Mingying Xv",http://arxiv.org/pdf/2412.05821v2,cs.CL
SILMM: Self-Improving Large Multimodal Models for Compositional Text-to-Image Generation,"Large Multimodal Models (LMMs) have demonstrated impressive capabilities in
multimodal understanding and generation, pushing forward advancements in
text-to-image generation. However, achieving accurate text-image alignment for
LMMs, particularly in compositional scenarios, remains challenging. Existing
approaches, such as layout planning for multi-step generation and learning from
human feedback or AI feedback, depend heavily on prompt engineering, costly
human annotations, and continual upgrading, limiting flexibility and
scalability. In this work, we introduce a model-agnostic iterative
self-improvement framework (SILMM) that can enable LMMs to provide helpful and
scalable self-feedback and optimize text-image alignment via Direct Preference
Optimization (DPO). DPO can readily applied to LMMs that use discrete visual
tokens as intermediate image representations; while it is less suitable for
LMMs with continuous visual features, as obtaining generation probabilities is
challenging. To adapt SILMM to LMMs with continuous features, we propose a
diversity mechanism to obtain diverse representations and a kernel-based
continuous DPO for alignment. Extensive experiments on three compositional
text-to-image generation benchmarks validate the effectiveness and superiority
of SILMM, showing improvements exceeding 30% on T2I-CompBench++ and around 20%
on DPG-Bench.",2024-12-08,"Leigang Qu, Haochuan Li, Wenjie Wang, Xiang Liu, Juncheng Li, Liqiang Nie, Tat-Seng Chua",http://arxiv.org/pdf/2412.05818v2,cs.CL
Learning to Correction: Explainable Feedback Generation for Visual Commonsense Reasoning Distractor,"Large multimodal models (LMMs) have shown remarkable performance in the
visual commonsense reasoning (VCR) task, which aims to answer a multiple-choice
question based on visual commonsense within an image. However, the ability of
LMMs to correct potential visual commonsense errors in the distractor upon
their occurrence is yet under-explored. Drawing inspiration from how a human
teacher crafts challenging distractors to test students' comprehension of the
concepts or skills and assists them in identifying and correcting errors toward
the answer, we are the pioneering research for LMMs to simulate this error
correction process. To this end, we employ GPT-4 as a ``teacher'' to collect
the explainable feedback dataset VCR-DF for error correction, which serves as a
benchmark to evaluate the ability of LMMs to identify misconceptions and
clarify reasons behind the error in VCR distractors toward final answers. In
addition, we propose an LMM-based Pedagogical Expert Instructed Feedback
Generation (PEIFG) model to incorporate the learnable expert prompts and
multimodal instruction as guidance for feedback generation. Experimental
results show that our PEIFG significantly outperforms existing LMMs. We believe
that our benchmark provides a new direction for evaluating the capabilities of
LMMs.",2024-12-08,"Jiali Chen, Xusen Hei, Yuqi Xue, Yuancheng Wei, Jiayuan Xie, Yi Cai, Qing Li",http://arxiv.org/pdf/2412.07801v1,cs.CL
Speech Is Not Enough: Interpreting Nonverbal Indicators of Common Knowledge and Engagement,"Our goal is to develop an AI Partner that can provide support for group
problem solving and social dynamics. In multi-party working group environments,
multimodal analytics is crucial for identifying non-verbal interactions of
group members. In conjunction with their verbal participation, this creates an
holistic understanding of collaboration and engagement that provides necessary
context for the AI Partner. In this demo, we illustrate our present
capabilities at detecting and tracking nonverbal behavior in student
task-oriented interactions in the classroom, and the implications for tracking
common ground and engagement.",2024-12-08,"Derek Palmer, Yifan Zhu, Kenneth Lai, Hannah VanderHoeven, Mariah Bradford, Ibrahim Khebour, Carlos Mabrey, Jack Fitzgerald, Nikhil Krishnaswamy, Martha Palmer, James Pustejovsky",http://arxiv.org/pdf/2412.05797v1,cs.CL
7B Fully Open Source Moxin-LLM -- From Pretraining to GRPO-based Reinforcement Learning Enhancement,"Recently, Large Language Models (LLMs) have undergone a significant
transformation, marked by a rapid rise in both their popularity and
capabilities. Leading this evolution are proprietary LLMs like GPT-4 and
GPT-o1, which have captured widespread attention in the AI community due to
their remarkable performance and versatility. Simultaneously, open-source LLMs,
such as LLaMA, have made great contributions to the ever-increasing popularity
of LLMs due to the ease to customize and deploy the models across diverse
applications. Although open-source LLMs present unprecedented opportunities for
innovation and research, the commercialization of LLMs has raised concerns
about transparency, reproducibility, and safety. Many open-source LLMs fail to
meet fundamental transparency requirements by withholding essential components
like training code and data, which may hinder further innovations on LLMs. To
mitigate this issue, we introduce Moxin 7B, a fully open-source LLM developed,
adhering to principles of open science, open source, open data, and open
access. We release the pre-training code and configurations, training and
fine-tuning datasets, and intermediate and final checkpoints, aiming to make
continuous commitments to fully open-source LLMs. After pre-training and
obtaining the base model, we finetune the Moxin Base model with SOTA
post-training framework and instruction data to obtain Moxin Instruct model. To
improve the reasoning capability, we further finetune our Instruct model with
chain-of-thought data distilled from DeepSeek R1, and then use Group Relative
Policy Optimization (GRPO), an efficient and effective reinforcement learning
algorithm following DeepSeek R1, to finetune our model, leading to the Moxin
Reasoning model. Experiments show that our models achieve superior performance
in various evaluations such as zero-shot evaluation, few-shot evaluation, and
CoT evaluation.",2024-12-08,"Pu Zhao, Xuan Shen, Zhenglun Kong, Yixin Shen, Sung-En Chang, Timothy Rupprecht, Lei Lu, Enfu Nan, Changdi Yang, Yumei He, Weiyan Shi, Xingchen Xu, Yu Huang, Wei Jiang, Wei Wang, Yue Chen, Yong He, Yanzhi Wang",http://arxiv.org/pdf/2412.06845v4,cs.CL
Uncovering Uncertainty in Transformer Inference,"We explore the Iterative Inference Hypothesis (IIH) within the context of
transformer-based language models, aiming to understand how a model's latent
representations are progressively refined and whether observable differences
are present between correct and incorrect generations. Our findings provide
empirical support for the IIH, showing that the nth token embedding in the
residual stream follows a trajectory of decreasing loss. Additionally, we
observe that the rate at which residual embeddings converge to a stable output
representation reflects uncertainty in the token generation process. Finally,
we introduce a method utilizing cross-entropy to detect this uncertainty and
demonstrate its potential to distinguish between correct and incorrect token
generations on a dataset of idioms.",2024-12-08,"Greyson Brothers, Willa Mannering, Amber Tien, John Winder",http://arxiv.org/pdf/2412.05768v1,cs.CL
A Comparative Study on Code Generation with Transformers,"In an era of widespread influence of Natural Language Processing (NLP), there
have been multiple research efforts to supplant traditional manual coding
techniques with automated systems capable of generating solutions autonomously.
With rapid research for code generation and a sole focus on large language
models, there emerges a need to compare and evaluate the performance of
transformer architectures based on several complexities of the model. This
paper introduces the concept of a ""A Comparative Study on Code Generation with
Transformers,"" a model based on Transformer architecture, and NLP methodologies
to automatically generate C++ source code for different varieties of problems.
Here, a comparative study is performed to evaluate the robustness of
transformer-based models on the basis of their architecture complexities and
their capability to handle diverse problem sets, from basic arithmetic to
complex computations.",2024-12-07,"Namrata Das, Rakshya Panta, Neelam Karki, Ruchi Manandhar, Dinesh Baniya Kshatri",http://arxiv.org/pdf/2412.05749v1,cs.CL
Training-Free Bayesianization for Low-Rank Adapters of Large Language Models,"Estimating the uncertainty of responses from Large Language Models (LLMs)
remains a critical challenge. While recent Bayesian methods have demonstrated
effectiveness in quantifying uncertainty through low-rank weight updates, they
typically require complex fine-tuning or post-training procedures. In this
paper, we propose Training-Free Bayesianization (TFB), a simple yet
theoretically grounded framework that efficiently transforms trained low-rank
adapters into Bayesian ones without additional training. TFB systematically
searches for the maximally acceptable level of variance in the weight
posterior, constrained within a family of low-rank isotropic Gaussian
distributions. Our theoretical analysis shows that under mild conditions, this
search process is equivalent to KL-regularized variational optimization, a
generalized form of variational inference. Through comprehensive experiments,
we show that TFB achieves superior uncertainty estimation and generalization
compared to existing methods while eliminating the need for complex
Bayesianization training procedures. Code will be available at
https://github.com/Wang-ML-Lab/bayesian-peft.",2024-12-07,"Haizhou Shi, Yibin Wang, Ligong Han, Huan Zhang, Hao Wang",http://arxiv.org/pdf/2412.05723v2,cs.CL
PromptRefine: Enhancing Few-Shot Performance on Low-Resource Indic Languages with Example Selection from Related Example Banks,"Large Language Models (LLMs) have recently demonstrated impressive few-shot
learning capabilities through in-context learning (ICL). However, ICL
performance is highly dependent on the choice of few-shot demonstrations,
making the selection of the most optimal examples a persistent research
challenge. This issue is further amplified in low-resource Indic languages,
where the scarcity of ground-truth data complicates the selection process. In
this work, we propose PromptRefine, a novel Alternating Minimization approach
for example selection that improves ICL performance on low-resource Indic
languages. PromptRefine leverages auxiliary example banks from related
high-resource Indic languages and employs multi-task learning techniques to
align language-specific retrievers, enabling effective cross-language
retrieval. Additionally, we incorporate diversity in the selected examples to
enhance generalization and reduce bias. Through comprehensive evaluations on
four text generation tasks -- Cross-Lingual Question Answering, Multilingual
Question Answering, Machine Translation, and Cross-Lingual Summarization using
state-of-the-art LLMs such as LLAMA-3.1-8B, LLAMA-2-7B, Qwen-2-7B, and
Qwen-2.5-7B, we demonstrate that PromptRefine significantly outperforms
existing frameworks for retrieving examples.",2024-12-07,"Soumya Suvra Ghosal, Soumyabrata Pal, Koyel Mukherjee, Dinesh Manocha",http://arxiv.org/pdf/2412.05710v1,cs.CL
On the effective transfer of knowledge from English to Hindi Wikipedia,"Although Wikipedia is the largest multilingual encyclopedia, it remains
inherently incomplete. There is a significant disparity in the quality of
content between high-resource languages (HRLs, e.g., English) and low-resource
languages (LRLs, e.g., Hindi), with many LRL articles lacking adequate
information. To bridge these content gaps, we propose a lightweight framework
to enhance knowledge equity between English and Hindi. In case the English
Wikipedia page is not up-to-date, our framework extracts relevant information
from external resources readily available (such as English books) and adapts it
to align with Wikipedia's distinctive style, including its \textit{neutral
point of view} (NPOV) policy, using in-context learning capabilities of large
language models. The adapted content is then machine-translated into Hindi for
integration into the corresponding Wikipedia articles. On the other hand, if
the English version is comprehensive and up-to-date, the framework directly
transfers knowledge from English to Hindi. Our framework effectively generates
new content for Hindi Wikipedia sections, enhancing Hindi Wikipedia articles
respectively by 65% and 62% according to automatic and human judgment-based
evaluations.",2024-12-07,"Paramita Das, Amartya Roy, Ritabrata Chakraborty, Animesh Mukherjee",http://arxiv.org/pdf/2412.05708v1,cs.CL
Batch-Max: Higher LLM Throughput using Larger Batch Sizes and KV Cache Compression,"Several works have developed eviction policies to remove key-value (KV) pairs
from the KV cache for more efficient inference. The focus has been on
compressing the KV cache after the input prompt has been processed for faster
token generation. In settings with limited GPU memory, and when the input
context is longer than the generation length, we show that by also compressing
the KV cache during the input processing phase, larger batch sizes can be used
resulting in significantly higher throughput while still maintaining the
original model's accuracy.",2024-12-07,"Michael R. Metel, Boxing Chen, Mehdi Rezagholizadeh",http://arxiv.org/pdf/2412.05693v1,cs.CL
Semantic Loss Guided Data Efficient Supervised Fine Tuning for Safe Responses in LLMs,"Large Language Models (LLMs) generating unsafe responses to toxic prompts is
a significant issue in their applications. While various efforts aim to address
this safety concern, previous approaches often demand substantial human data
collection or rely on the less dependable option of using another LLM to
generate corrective data. In this paper, we aim to take this problem and
overcome limitations of requiring significant high-quality human data. Our
method requires only a small set of unsafe responses to toxic prompts, easily
obtained from the unsafe LLM itself. By employing a semantic cost combined with
a negative Earth Mover Distance (EMD) loss, we guide the LLM away from
generating unsafe responses. Additionally, we propose a novel lower bound for
EMD loss, enabling more efficient optimization. Our results demonstrate
superior performance and data efficiency compared to baselines, and we further
examine the nuanced effects of over-alignment and potential degradation of
language capabilities when using contrastive data.",2024-12-07,"Yuxiao Lu, Arunesh Sinha, Pradeep Varakantham",http://arxiv.org/pdf/2412.06843v2,cs.CL
Graph with Sequence: Broad-Range Semantic Modeling for Fake News Detection,"The rapid proliferation of fake news on social media threatens social
stability, creating an urgent demand for more effective detection methods.
While many promising approaches have emerged, most rely on content analysis
with limited semantic depth, leading to suboptimal comprehension of news
content.To address this limitation, capturing broader-range semantics is
essential yet challenging, as it introduces two primary types of noise: fully
connecting sentences in news graphs often adds unnecessary structural noise,
while highly similar but authenticity-irrelevant sentences introduce feature
noise, complicating the detection process. To tackle these issues, we propose
BREAK, a broad-range semantics model for fake news detection that leverages a
fully connected graph to capture comprehensive semantics while employing dual
denoising modules to minimize both structural and feature noise. The semantic
structure denoising module balances the graph's connectivity by iteratively
refining it between two bounds: a sequence-based structure as a lower bound and
a fully connected graph as the upper bound. This refinement uncovers
label-relevant semantic interrelations structures. Meanwhile, the semantic
feature denoising module reduces noise from similar semantics by diversifying
representations, aligning distinct outputs from the denoised graph and sequence
encoders using KL-divergence to achieve feature diversification in
high-dimensional space. The two modules are jointly optimized in a bi-level
framework, enhancing the integration of denoised semantics into a comprehensive
representation for detection. Extensive experiments across four datasets
demonstrate that BREAK significantly outperforms existing fake news detection
methods.",2024-12-07,"Junwei Yin, Min Gao, Kai Shu, Wentao Li, Yinqiu Huang, Zongwei Wang",http://arxiv.org/pdf/2412.05672v2,cs.CL
Shifting NER into High Gear: The Auto-AdvER Approach,"This paper presents a case study on the development of Auto-AdvER, a
specialised named entity recognition schema and dataset for text in the car
advertisement genre. Developed with industry needs in mind, Auto-AdvER is
designed to enhance text mining analytics in this domain and contributes a
linguistically unique NER dataset. We present a schema consisting of three
labels: ""Condition"", ""Historic"" and ""Sales Options"". We outline the guiding
principles for annotation, describe the methodology for schema development, and
show the results of an annotation study demonstrating inter-annotator agreement
of 92% F1-Score. Furthermore, we compare the performance by using encoder-only
models: BERT, DeBERTaV3 and decoder-only open and closed source Large Language
Models (LLMs): Llama, Qwen, GPT-4 and Gemini. Our results show that the class
of LLMs outperforms the smaller encoder-only models. However, the LLMs are
costly and far from perfect for this task. We present this work as a stepping
stone toward more fine-grained analysis and discuss Auto-AdvER's potential
impact on advertisement analytics and customer insights, including applications
such as the analysis of market dynamics and data-driven predictive maintenance.
Our schema, as well as our associated findings, are suitable for both private
and public entities considering named entity recognition in the automotive
domain, or other specialist domains.",2024-12-07,"Filippos Ventirozos, Ioanna Nteka, Tania Nandy, Jozef Baca, Peter Appleby, Matthew Shardlow",http://arxiv.org/pdf/2412.05655v1,cs.CL
Mixture of Hidden-Dimensions Transformer,"Transformer models encounter challenges in scaling hidden dimensions
efficiently, as uniformly increasing them inflates computational and memory
costs while failing to emphasize the most relevant features for each token. For
further understanding, we study hidden dimension sparsity and observe that
trained Transformers utilize only a small fraction of token dimensions,
revealing an ""activation flow"" pattern. Notably, there are shared
sub-dimensions with sustained activation across multiple consecutive tokens and
specialized sub-dimensions uniquely activated for each token. To better model
token-relevant sub-dimensions, we propose MoHD (Mixture of Hidden Dimensions),
a sparse conditional activation architecture. Particularly, MoHD employs shared
sub-dimensions for common token features and a routing mechanism to dynamically
activate specialized sub-dimensions. To mitigate potential information loss
from sparsity, we design activation scaling and group fusion mechanisms to
preserve activation flow. In this way, MoHD expands hidden dimensions with
negligible increases in computation or parameters, efficient training and
inference while maintaining performance. Evaluations across 10 NLP tasks show
that MoHD surpasses Vanilla Transformers in parameter efficiency and task
performance. It achieves 1.7% higher performance with 50% fewer activation
parameters and 3.7% higher performance with a 3x parameter expansion at
constant activation cost. MOHD offers a new perspective for scaling the model,
showcasing the potential of hidden dimension sparsity to boost efficiency",2024-12-07,"Yilong Chen, Junyuan Shang, Zhengyu Zhang, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang",http://arxiv.org/pdf/2412.05644v3,cs.CL
CharacterBox: Evaluating the Role-Playing Capabilities of LLMs in Text-Based Virtual Worlds,"Role-playing is a crucial capability of Large Language Models (LLMs),
enabling a wide range of practical applications, including intelligent
non-player characters, digital twins, and emotional companions. Evaluating this
capability in LLMs is challenging due to the complex dynamics involved in
role-playing, such as maintaining character fidelity throughout a storyline and
navigating open-ended narratives without a definitive ground truth. Current
evaluation methods, which primarily focus on question-answering or
conversational snapshots, fall short of adequately capturing the nuanced
character traits and behaviors essential for authentic role-playing. In this
paper, we propose CharacterBox, which is a simulation sandbox designed to
generate situational fine-grained character behavior trajectories. These
behavior trajectories enable a more comprehensive and in-depth evaluation of
role-playing capabilities. CharacterBox consists of two main components: the
character agent and the narrator agent. The character agent, grounded in
psychological and behavioral science, exhibits human-like behaviors, while the
narrator agent coordinates interactions between character agents and
environmental changes. Additionally, we introduce two trajectory-based methods
that leverage CharacterBox to enhance LLM performance. To reduce costs and
facilitate the adoption of CharacterBox by public communities, we fine-tune two
smaller models, CharacterNR and CharacterRM, as substitutes for GPT API calls,
and demonstrate their competitive performance compared to advanced GPT APIs.",2024-12-07,"Lei Wang, Jianxun Lian, Yi Huang, Yanqi Dai, Haoxuan Li, Xu Chen, Xing Xie, Ji-Rong Wen",http://arxiv.org/pdf/2412.05631v1,cs.CL
BERTCaps: BERT Capsule for Persian Multi-Domain Sentiment Analysis,"Multidomain sentiment analysis involves estimating the polarity of an
unstructured text by exploiting domain specific information. One of the main
issues common to the approaches discussed in the literature is their poor
applicability to domains that differ from those used to construct opinion
models.This paper aims to present a new method for Persian multidomain SA
analysis using deep learning approaches. The proposed BERTCapsules approach
consists of a combination of BERT and Capsule models. In this approach, BERT
was used for Instance representation, and Capsule Structure was used to learn
the extracted graphs. Digikala dataset, including ten domains with both
positive and negative polarity, was used to evaluate this approach. The
evaluation of the BERTCaps model achieved an accuracy of 0.9712 in sentiment
classification binary classification and 0.8509 in domain classification .",2024-12-07,"Mohammadali Memari, Soghra Mikaeyl Nejad, Amir Parsa Rabiei, Mehrshad Eisaei, Saba Hesaraki",http://arxiv.org/pdf/2412.05591v1,cs.CL
UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation,"Breast cancer stands as a prevalent cause of fatality among females on a
global scale, with prompt detection playing a pivotal role in diminishing
mortality rates. The utilization of ultrasound scans in the BUSI dataset for
medical imagery pertaining to breast cancer has exhibited commendable
segmentation outcomes through the application of UNet and UNet++ networks.
Nevertheless, a notable drawback of these models resides in their inattention
towards the temporal aspects embedded within the images. This research
endeavors to enrich the UNet++ architecture by integrating LSTM layers and
self-attention mechanisms to exploit temporal characteristics for segmentation
purposes. Furthermore, the incorporation of a Multiscale Feature Extraction
Module aims to grasp varied scale features within the UNet++. Through the
amalgamation of our proposed methodology with data augmentation on the BUSI
with GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision
of 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of
92.74% are achieved. These findings demonstrate competitiveness with
cutting-edge techniques outlined in existing literature.",2024-12-07,"Saba Hesaraki, Morteza Akbari, Ramin Mousa",http://arxiv.org/pdf/2412.05585v1,cs.CL
LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods,"The rapid advancement of Large Language Models (LLMs) has driven their
expanding application across various fields. One of the most promising
applications is their role as evaluators based on natural language responses,
referred to as ''LLMs-as-judges''. This framework has attracted growing
attention from both academia and industry due to their excellent effectiveness,
ability to generalize across tasks, and interpretability in the form of natural
language. This paper presents a comprehensive survey of the LLMs-as-judges
paradigm from five key perspectives: Functionality, Methodology, Applications,
Meta-evaluation, and Limitations. We begin by providing a systematic definition
of LLMs-as-Judges and introduce their functionality (Why use LLM judges?). Then
we address methodology to construct an evaluation system with LLMs (How to use
LLM judges?). Additionally, we investigate the potential domains for their
application (Where to use LLM judges?) and discuss methods for evaluating them
in various contexts (How to evaluate LLM judges?). Finally, we provide a
detailed analysis of the limitations of LLM judges and discuss potential future
directions. Through a structured and comprehensive analysis, we aim aims to
provide insights on the development and application of LLMs-as-judges in both
research and practice. We will continue to maintain the relevant resource list
at https://github.com/CSHaitao/Awesome-LLMs-as-Judges.",2024-12-07,"Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou, Qingyao Ai, Ziyi Ye, Yiqun Liu",http://arxiv.org/pdf/2412.05579v2,cs.CL
A polar coordinate system represents syntax in large language models,"Originally formalized with symbolic representations, syntactic trees may also
be effectively represented in the activations of large language models (LLMs).
Indeed, a 'Structural Probe' can find a subspace of neural activations, where
syntactically related words are relatively close to one-another. However, this
syntactic code remains incomplete: the distance between the Structural Probe
word embeddings can represent the existence but not the type and direction of
syntactic relations. Here, we hypothesize that syntactic relations are, in
fact, coded by the relative direction between nearby embeddings. To test this
hypothesis, we introduce a 'Polar Probe' trained to read syntactic relations
from both the distance and the direction between word embeddings. Our approach
reveals three main findings. First, our Polar Probe successfully recovers the
type and direction of syntactic relations, and substantially outperforms the
Structural Probe by nearly two folds. Second, we confirm that this polar
coordinate system exists in a low-dimensional subspace of the intermediate
layers of many LLMs and becomes increasingly precise in the latest frontier
models. Third, we demonstrate with a new benchmark that similar syntactic
relations are coded similarly across the nested levels of syntactic trees.
Overall, this work shows that LLMs spontaneously learn a geometry of neural
activations that explicitly represents the main symbolic structures of
linguistic theory.",2024-12-07,"Pablo Diego-Simón, Stéphane D'Ascoli, Emmanuel Chemla, Yair Lakretz, Jean-Rémi King",http://arxiv.org/pdf/2412.05571v1,cs.CL
"A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions","The remarkable performance of large language models (LLMs) in content
generation, coding, and common-sense reasoning has spurred widespread
integration into many facets of society. However, integration of LLMs raises
valid questions on their reliability and trustworthiness, given their
propensity to generate hallucinations: plausible, factually-incorrect
responses, which are expressed with striking confidence. Previous work has
shown that hallucinations and other non-factual responses generated by LLMs can
be detected by examining the uncertainty of the LLM in its response to the
pertinent prompt, driving significant research efforts devoted to quantifying
the uncertainty of LLMs. This survey seeks to provide an extensive review of
existing uncertainty quantification methods for LLMs, identifying their salient
features, along with their strengths and weaknesses. We present existing
methods within a relevant taxonomy, unifying ostensibly disparate methods to
aid understanding of the state of the art. Furthermore, we highlight
applications of uncertainty quantification methods for LLMs, spanning chatbot
and textual applications to embodied artificial intelligence applications in
robotics. We conclude with open research challenges in uncertainty
quantification of LLMs, seeking to motivate future research.",2024-12-07,"Ola Shorinwa, Zhiting Mei, Justin Lidard, Allen Z. Ren, Anirudha Majumdar",http://arxiv.org/pdf/2412.05563v1,cs.CL
On the Expressive Power of Modern Hopfield Networks,"Modern Hopfield networks (MHNs) have emerged as powerful tools in deep
learning, capable of replacing components such as pooling layers, LSTMs, and
attention mechanisms. Recent advancements have enhanced their storage capacity,
retrieval speed, and error rates. However, the fundamental limits of their
computational expressiveness remain unexplored. Understanding the expressive
power of MHNs is crucial for optimizing their integration into deep learning
architectures. In this work, we establish rigorous theoretical bounds on the
computational capabilities of MHNs using circuit complexity theory. Our key
contribution is that we show that MHNs are $\mathsf{DLOGTIME}$-uniform
$\mathsf{TC}^0$. Hence, unless $\mathsf{TC}^0 = \mathsf{NC}^1$, a
$\mathrm{poly}(n)$-precision modern Hopfield networks with a constant number of
layers and $O(n)$ hidden dimension cannot solve $\mathsf{NC}^1$-hard problems
such as the undirected graph connectivity problem and the tree isomorphism
problem. We also extended our results to Kernelized Hopfield Networks. These
results demonstrate the limitation in the expressive power of the modern
Hopfield networks. Moreover, Our theoretical analysis provides insights to
guide the development of new Hopfield-based architectures.",2024-12-07,"Xiaoyu Li, Yuanpeng Li, Yingyu Liang, Zhenmei Shi, Zhao Song",http://arxiv.org/pdf/2412.05562v1,cs.CL
SAME: Learning Generic Language-Guided Visual Navigation with State-Adaptive Mixture of Experts,"The academic field of learning instruction-guided visual navigation can be
generally categorized into high-level category-specific search and low-level
language-guided navigation, depending on the granularity of language
instruction, in which the former emphasizes the exploration process, while the
latter concentrates on following detailed textual commands. Despite the
differing focuses of these tasks, the underlying requirements of interpreting
instructions, comprehending the surroundings, and inferring action decisions
remain consistent. This paper consolidates diverse navigation tasks into a
unified and generic framework -- we investigate the core difficulties of
sharing general knowledge and exploiting task-specific capabilities in learning
navigation and propose a novel State-Adaptive Mixture of Experts (SAME) model
that effectively enables an agent to infer decisions based on
different-granularity language and dynamic observations. Powered by SAME, we
present a versatile agent capable of addressing seven navigation tasks
simultaneously that outperforms or achieves highly comparable performance to
task-specific agents.",2024-12-07,"Gengze Zhou, Yicong Hong, Zun Wang, Chongyang Zhao, Mohit Bansal, Qi Wu",http://arxiv.org/pdf/2412.05552v1,cs.CL
Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison,"This study introduces an evaluation framework for multimodal models in
medical imaging diagnostics. We developed a pipeline incorporating data
preprocessing, model inference, and preference-based evaluation, expanding an
initial set of 500 clinical cases to 3,000 through controlled augmentation. Our
method combined medical images with clinical observations to generate
assessments, using Claude 3.5 Sonnet for independent evaluation against
physician-authored diagnoses. The results indicated varying performance across
models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In
contrast, specialized vision models like BLIP2 and Llava showed preferences in
41.36% and 46.77% of cases, respectively. This framework highlights the
potential of large multimodal models to outperform human diagnostics in certain
tasks.",2024-12-07,"Cailian Ruan, Chengyue Huang, Yahe Yang",http://arxiv.org/pdf/2412.05536v1,cs.CL
The Illusion-Illusion: Vision Language Models See Illusions Where There are None,"Illusions are entertaining, but they are also a useful diagnostic tool in
cognitive science, philosophy, and neuroscience. A typical illusion shows a gap
between how something ""really is"" and how something ""appears to be"", and this
gap helps us understand the mental processing that lead to how something
appears to be. Illusions are also useful for investigating artificial systems,
and much research has examined whether computational models of perceptions fall
prey to the same illusions as people. Here, I invert the standard use of
perceptual illusions to examine basic processing errors in current vision
language models. I present these models with illusory-illusions, neighbors of
common illusions that should not elicit processing errors. These include such
things as perfectly reasonable ducks, crooked lines that truly are crooked,
circles that seem to have different sizes because they are, in fact, of
different sizes, and so on. I show that many current vision language systems
mistakenly see these illusion-illusions as illusions. I suggest that such
failures are part of broader failures already discussed in the literature.",2024-12-07,Tomer Ullman,http://arxiv.org/pdf/2412.18613v1,cs.CL
SplaXBERT: Leveraging Mixed Precision Training and Context Splitting for Question Answering,"SplaXBERT, built on ALBERT-xlarge with context-splitting and mixed precision
training, achieves high efficiency in question-answering tasks on lengthy
texts. Tested on SQuAD v1.1, it attains an Exact Match of 85.95% and an F1
Score of 92.97%, outperforming traditional BERT-based models in both accuracy
and resource efficiency.",2024-12-07,"Zhu Yufan, Hao Zeyu, Li Siqi, Niu Boqian",http://arxiv.org/pdf/2412.05499v1,cs.CL
SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering,"Retrieval Augmented Generation (RAG) enables Large Language Models (LLMs) to
generalize to new information by decoupling reasoning capabilities from static
knowledge bases. Traditional RAG enhancements have explored vertical
scaling-assigning subtasks to specialized modules-and horizontal
scaling-replicating tasks across multiple agents-to improve performance.
However, real-world applications impose diverse Service Level Agreements (SLAs)
and Quality of Service (QoS) requirements, involving trade-offs among
objectives such as reducing cost, ensuring answer quality, and adhering to
specific operational constraints.
  In this work, we present a systems-oriented approach to multi-agent RAG
tailored for real-world Question Answering (QA) applications. By integrating
task-specific non-functional requirements-such as answer quality, cost, and
latency-into the system, we enable dynamic reconfiguration to meet diverse
SLAs. Our method maps these Service Level Objectives (SLOs) to system-level
parameters, allowing the generation of optimal results within specified
resource constraints.
  We conduct a case study in the QA domain, demonstrating how dynamic
re-orchestration of a multi-agent RAG system can effectively manage the
trade-off between answer quality and cost. By adjusting the system based on
query intent and operational conditions, we systematically balance performance
and resource utilization. This approach allows the system to meet SLOs for
various query types, showcasing its practicality for real-world applications.",2024-12-07,"Michael Iannelli, Sneha Kuchipudi, Vera Dvorak",http://arxiv.org/pdf/2412.06832v2,cs.CL
TransitGPT: A Generative AI-based framework for interacting with GTFS data using Large Language Models,"This paper introduces a framework that leverages Large Language Models (LLMs)
to answer natural language queries about General Transit Feed Specification
(GTFS) data. The framework is implemented in a chatbot called TransitGPT with
open-source code. TransitGPT works by guiding LLMs to generate Python code that
extracts and manipulates GTFS data relevant to a query, which is then executed
on a server where the GTFS feed is stored. It can accomplish a wide range of
tasks, including data retrieval, calculations, and interactive visualizations,
without requiring users to have extensive knowledge of GTFS or programming. The
LLMs that produce the code are guided entirely by prompts, without fine-tuning
or access to the actual GTFS feeds. We evaluate TransitGPT using GPT-4o and
Claude-3.5-Sonnet LLMs on a benchmark dataset of 100 tasks, to demonstrate its
effectiveness and versatility. The results show that TransitGPT can
significantly enhance the accessibility and usability of transit data.",2024-12-07,"Saipraneeth Devunuri, Lewis Lehe",http://arxiv.org/pdf/2412.06831v1,cs.CL
LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System,"The complexity of laboratory environments requires solutions that simplify
instrument interaction and enhance measurement automation. Traditional tools
often require configuration, software, and programming skills, creating
barriers to productivity. Previous approaches, including dedicated software
suites and custom scripts, frequently fall short in providing user-friendly
solutions that align with programming practices. We present LABIIUM, an
AI-enhanced, zero-configuration measurement automation system designed to
streamline experimental workflows and improve user productivity. LABIIUM
integrates an AI assistant powered by Large Language Models (LLMs) to generate
code. LABIIUM's Lab-Automation-Measurement Bridges (LAMBs) enable seamless
instrument connectivity using standard tools such as VSCode and Python,
eliminating setup overhead. To demonstrate its capabilities, we conducted
experiments involving the measurement of the parametric transfer curve of a
simple two-transistor inverting amplifier with a current source load. The AI
assistant was evaluated using different prompt scenarios and compared with
multiple models, including Claude Sonnet 3.5, Gemini Pro 1.5, and GPT-4o. An
expert solution implementing the Gradient-Weighted Adaptive Stochastic Sampling
(GWASS) method was used as a baseline. The solutions generated by the AI
assistant were compared with the expert solution and a uniform linear sweep
baseline with 10,000 points. The graph results show that the LLMs were able to
successfully complete the most basic uniform sweep, but LLMs were unable to
develop adaptive sweeping algorithms to compete with GWASS. The evaluation
underscores LABIIUM's ability to enhance laboratory productivity and support
digital transformation in research and industry, and emphasizes the future work
required to improve LLM performance in Electronic Measurement Science Tasks.",2024-12-07,"Emmanuel A. Olowe, Danial Chitnis",http://arxiv.org/pdf/2412.16172v2,cs.CL
Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering,"This study explores the effectiveness of using knowledge graphs generated by
large language models to decompose high school-level physics questions into
sub-questions. We introduce a pipeline aimed at enhancing model response
quality for Question Answering tasks. By employing LLMs to construct knowledge
graphs that capture the internal logic of the questions, these graphs then
guide the generation of subquestions. We hypothesize that this method yields
sub-questions that are more logically consistent with the original questions
compared to traditional decomposition techniques. Our results show that
sub-questions derived from knowledge graphs exhibit significantly improved
fidelity to the original question's logic. This approach not only enhances the
learning experience by providing clearer and more contextually appropriate
sub-questions but also highlights the potential of LLMs to transform
educational methodologies. The findings indicate a promising direction for
applying AI to improve the quality and effectiveness of educational content.",2024-12-06,"Krishnasai Addala, Kabir Dev Paul Baghel, Dhruv Jain, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah",http://arxiv.org/pdf/2412.05453v2,cs.CL
TrajLearn: Trajectory Prediction Learning using Deep Generative Models,"Trajectory prediction aims to estimate an entity's future path using its
current position and historical movement data, benefiting fields like
autonomous navigation, robotics, and human movement analytics. Deep learning
approaches have become key in this area, utilizing large-scale trajectory
datasets to model movement patterns, but face challenges in managing complex
spatial dependencies and adapting to dynamic environments. To address these
challenges, we introduce TrajLearn, a novel model for trajectory prediction
that leverages generative modeling of higher-order mobility flows based on
hexagonal spatial representation. TrajLearn predicts the next $k$ steps by
integrating a customized beam search for exploring multiple potential paths
while maintaining spatial continuity. We conducted a rigorous evaluation of
TrajLearn, benchmarking it against leading state-of-the-art approaches and
meaningful baselines. The results indicate that TrajLearn achieves significant
performance gains, with improvements of up to ~40% across multiple real-world
trajectory datasets. In addition, we evaluated different prediction horizons
(i.e., various values of $k$), conducted resolution sensitivity analysis, and
performed ablation studies to assess the impact of key model components.
Furthermore, we developed a novel algorithm to generate mixed-resolution maps
by hierarchically subdividing hexagonal regions into finer segments within a
specified observation area. This approach supports selective detailing,
applying finer resolution to areas of interest or high activity (e.g., urban
centers) while using coarser resolution for less significant regions (e.g.,
rural areas), effectively reducing data storage requirements and computational
overhead. We promote reproducibility and adaptability by offering complete
code, data, and detailed documentation with flexible configuration options for
various applications.",2024-12-30,"Amirhossein Nadiri, Jing Li, Ali Faraji, Ghadeer Abuoda, Manos Papagelis",http://arxiv.org/pdf/2501.00184v2,cs.LG
Federated Learning with Workload Reduction through Partial Training of Client Models and Entropy-Based Data Selection,"With the rapid expansion of edge devices, such as IoT devices, where crucial
data needed for machine learning applications is generated, it becomes
essential to promote their participation in privacy-preserving Federated
Learning (FL) systems. The best way to achieve this desiderate is by reducing
their training workload to match their constrained computational resources.
While prior FL research has address the workload constrains by introducing
lightweight models on the edge, limited attention has been given to optimizing
on-device training efficiency through reducing the amount of data need during
training. In this work, we propose FedFT-EDS, a novel approach that combines
Fine-Tuning of partial client models with Entropy-based Data Selection to
reduce training workloads on edge devices. By actively selecting the most
informative local instances for learning, FedFT-EDS reduces training data
significantly in FL and demonstrates that not all user data is equally
beneficial for FL on all rounds. Our experiments on CIFAR-10 and CIFAR-100 show
that FedFT-EDS uses only 50% user data while improving the global model
performance compared to baseline methods, FedAvg and FedProx. Importantly,
FedFT-EDS improves client learning efficiency by up to 3 times, using one third
of training time on clients to achieve an equivalent performance to the
baselines. This work highlights the importance of data selection in FL and
presents a promising pathway to scalable and efficient Federate Learning.",2024-12-30,"Hongrui Shi, Valentin Radu, Po Yang",http://arxiv.org/pdf/2501.00170v1,cs.LG
Class-based Subset Selection for Transfer Learning under Extreme Label Shift,"Existing work within transfer learning often follows a two-step process --
pre-training over a large-scale source domain and then finetuning over limited
samples from the target domain. Yet, despite its popularity, this methodology
has been shown to suffer in the presence of distributional shift --
specifically when the output spaces diverge. Previous work has focused on
increasing model performance within this setting by identifying and classifying
only the shared output classes between distributions. However, these methods
are inherently limited as they ignore classes outside the shared class set,
disregarding potential information relevant to the model transfer. This paper
proposes a new process for few-shot transfer learning that selects and weighs
classes from the source domain to optimize the transfer between domains. More
concretely, we use Wasserstein distance to choose a set of source classes and
their weights that minimize the distance between the source and target domain.
To justify our proposed algorithm, we provide a generalization analysis of the
performance of the learned classifier over the target domain and show that our
method corresponds to a bound minimization algorithm. We empirically
demonstrate the effectiveness of our approach (WaSS) by experimenting on
several different datasets and presenting superior performance within various
label shift settings, including the extreme case where the label spaces are
disjoint.",2024-12-30,"Akul Goyal, Carl Edwards",http://arxiv.org/pdf/2501.00162v1,cs.LG
Urban Water Consumption Forecasting Using Deep Learning and Correlated District Metered Areas,"Accurate water consumption forecasting is a crucial tool for water utilities
and policymakers, as it helps ensure a reliable supply, optimize operations,
and support infrastructure planning. Urban Water Distribution Networks (WDNs)
are divided into District Metered Areas (DMAs), where water flow is monitored
to efficiently manage resources. This work focuses on short-term forecasting of
DMA consumption using deep learning and aims to address two key challenging
issues. First, forecasting based solely on a DMA's historical data may lack
broader context and provide limited insights. Second, DMAs may experience
sensor malfunctions providing incorrect data, or some DMAs may not be monitored
at all due to computational costs, complicating accurate forecasting. We
propose a novel method that first identifies DMAs with correlated consumption
patterns and then uses these patterns, along with the DMA's local data, as
input to a deep learning model for forecasting. In a real-world study with data
from five DMAs, we show that: i) the deep learning model outperforms a
classical statistical model; ii) accurate forecasting can be carried out using
only correlated DMAs' consumption patterns; and iii) even when a DMA's local
data is available, including correlated DMAs' data improves accuracy.",2024-12-30,"Kleanthis Malialis, Nefeli Mavri, Stelios G. Vrachimis, Marios S. Kyriakou, Demetrios G. Eliades, Marios M. Polycarpou",http://arxiv.org/pdf/2501.00158v1,cs.LG
LASSE: Learning Active Sampling for Storm Tide Extremes in Non-Stationary Climate Regimes,"Identifying tropical cyclones that generate destructive storm tides for risk
assessment, such as from large downscaled storm catalogs for climate studies,
is often intractable because it entails many expensive Monte Carlo hydrodynamic
simulations. Here, we show that surrogate models are promising from accuracy,
recall, and precision perspectives, and they ""generalize"" to novel climate
scenarios. We then present an informative online learning approach to rapidly
search for extreme storm tide-producing cyclones using only a few hydrodynamic
simulations. Starting from a minimal subset of TCs with detailed storm tide
hydrodynamic simulations, a surrogate model selects informative data to retrain
online and iteratively improves its predictions of damaging TCs. Results on an
extensive catalog of downscaled TCs indicate 100% precision in retrieving rare
destructive storms using less than 20% of the simulations as training. The
informative sampling approach is efficient, scalable to large storm catalogs,
and generalizable to climate scenarios.",2024-12-30,"Grace Jiang, Jiangchao Qiu, Sai Ravela",http://arxiv.org/pdf/2501.00149v2,cs.LG
Detection-Fusion for Knowledge Graph Extraction from Videos,"One of the challenging tasks in the field of video understanding is
extracting semantic content from video inputs. Most existing systems use
language models to describe videos in natural language sentences, but this has
several major shortcomings. Such systems can rely too heavily on the language
model component and base their output on statistical regularities in natural
language text rather than on the visual contents of the video. Additionally,
natural language annotations cannot be readily processed by a computer, are
difficult to evaluate with performance metrics and cannot be easily translated
into a different natural language. In this paper, we propose a method to
annotate videos with knowledge graphs, and so avoid these problems.
Specifically, we propose a deep-learning-based model for this task that first
predicts pairs of individuals and then the relations between them.
Additionally, we propose an extension of our model for the inclusion of
background knowledge in the construction of knowledge graphs.",2024-12-30,"Taniya Das, Louis Mahon, Thomas Lukasiewicz",http://arxiv.org/pdf/2501.00136v1,cs.LG
GroverGPT: A Large Language Model with 8 Billion Parameters for Quantum Searching,"Quantum computing is an exciting non-Von Neumann paradigm, offering provable
speedups over classical computing for specific problems. However, the practical
limits of classical simulatability for quantum circuits remain unclear,
especially with current noisy quantum devices. In this work, we explore the
potential of leveraging Large Language Models (LLMs) to simulate the output of
a quantum Turing machine using Grover's quantum circuits, known to provide
quadratic speedups over classical counterparts. To this end, we developed
GroverGPT, a specialized model based on LLaMA's 8-billion-parameter
architecture, trained on over 15 trillion tokens. Unlike brute-force
state-vector simulations, which demand substantial computational resources,
GroverGPT employs pattern recognition to approximate quantum search algorithms
without explicitly representing quantum states. Analyzing 97K quantum search
instances, GroverGPT consistently outperformed OpenAI's GPT-4o (45\% accuracy),
achieving nearly 100\% accuracy on 6- and 10-qubit datasets when trained on
4-qubit or larger datasets. It also demonstrated strong generalization,
surpassing 95\% accuracy for systems with over 20 qubits when trained on 3- to
6-qubit data. Analysis indicates GroverGPT captures quantum features of
Grover's search rather than classical patterns, supported by novel prompting
strategies to enhance performance. Although accuracy declines with increasing
system size, these findings offer insights into the practical boundaries of
classical simulatability. This work suggests task-specific LLMs can surpass
general-purpose models like GPT-4o in quantum algorithm learning and serve as
powerful tools for advancing quantum research.",2024-12-30,"Haoran Wang, Pingzhi Li, Min Chen, Jinglei Cheng, Junyu Liu, Tianlong Chen",http://arxiv.org/pdf/2501.00135v4,cs.LG
PQD: Post-training Quantization for Efficient Diffusion Models,"Diffusionmodels(DMs)havedemonstratedremarkableachievements in synthesizing
images of high fidelity and diversity. However, the extensive computational
requirements and slow generative speed of diffusion models have limited their
widespread adoption. In this paper, we propose a novel post-training
quantization for diffusion models (PQD), which is a time-aware optimization
framework for diffusion models based on post-training quantization. The
proposed framework optimizes the inference process by selecting representative
samples and conducting time-aware calibration. Experimental results show that
our proposed method is able to directly quantize full-precision diffusion
models into 8-bit or 4-bit models while maintaining comparable performance in a
training-free manner, achieving a few FID change on ImageNet for unconditional
image generation. Our approach demonstrates compatibility and can also be
applied to 512x512 text-guided image generation for the first time.",2024-12-30,"Jiaojiao Ye, Zhen Wang, Linnan Jiang",http://arxiv.org/pdf/2501.00124v1,cs.LG
Post Launch Evaluation of Policies in a High-Dimensional Setting,"A/B tests, also known as randomized controlled experiments (RCTs), are the
gold standard for evaluating the impact of new policies, products, or
decisions. However, these tests can be costly in terms of time and resources,
potentially exposing users, customers, or other test subjects (units) to
inferior options. This paper explores practical considerations in applying
methodologies inspired by ""synthetic control"" as an alternative to traditional
A/B testing in settings with very large numbers of units, involving up to
hundreds of millions of units, which is common in modern applications such as
e-commerce and ride-sharing platforms. This method is particularly valuable in
settings where the treatment affects only a subset of units, leaving many units
unaffected. In these scenarios, synthetic control methods leverage data from
unaffected units to estimate counterfactual outcomes for treated units. After
the treatment is implemented, these estimates can be compared to actual
outcomes to measure the treatment effect. A key challenge in creating accurate
counterfactual outcomes is interpolation bias, a well-documented phenomenon
that occurs when control units differ significantly from treated units. To
address this, we propose a two-phase approach: first using nearest neighbor
matching based on unit covariates to select similar control units, then
applying supervised learning methods suitable for high-dimensional data to
estimate counterfactual outcomes. Testing using six large-scale experiments
demonstrates that this approach successfully improves estimate accuracy.
However, our analysis reveals that machine learning bias -- which arises from
methods that trade off bias for variance reduction -- can impact results and
affect conclusions about treatment effects. We document this bias in
large-scale experimental settings and propose effective de-biasing techniques
to address this challenge.",2024-12-30,"Shima Nassiri, Mohsen Bayati, Joe Cooprider",http://arxiv.org/pdf/2501.00119v1,cs.LG
Text-to-Image GAN with Pretrained Representations,"Generating desired images conditioned on given text descriptions has received
lots of attention. Recently, diffusion models and autoregressive models have
demonstrated their outstanding expressivity and gradually replaced GAN as the
favored architectures for text-to-image synthesis. However, they still face
some obstacles: slow inference speed and expensive training costs. To achieve
more powerful and faster text-to-image synthesis under complex scenes, we
propose TIGER, a text-to-image GAN with pretrained representations. To be
specific, we propose a vision-empowered discriminator and a high-capacity
generator. (i) The vision-empowered discriminator absorbs the complex scene
understanding ability and the domain generalization ability from pretrained
vision models to enhance model performance. Unlike previous works, we explore
stacking multiple pretrained models in our discriminator to collect multiple
different representations. (ii) The high-capacity generator aims to achieve
effective text-image fusion while increasing the model capacity. The
high-capacity generator consists of multiple novel high-capacity fusion blocks
(HFBlock). And the HFBlock contains several deep fusion modules and a global
fusion module, which play different roles to benefit our model. Extensive
experiments demonstrate the outstanding performance of our proposed TIGER both
on standard and zero-shot text-to-image synthesis tasks. On the standard
text-to-image synthesis task, TIGER achieves state-of-the-art performance on
two challenging datasets, which obtain a new FID 5.48 (COCO) and 9.38 (CUB). On
the zero-shot text-to-image synthesis task, we achieve comparable performance
with fewer model parameters, smaller training data size and faster inference
speed. Additionally, more experiments and analyses are conducted in the
Supplementary Material.",2024-12-30,"Xiaozhou You, Jian Zhang",http://arxiv.org/pdf/2501.00116v1,cs.LG
An Unsupervised Anomaly Detection in Electricity Consumption Using Reinforcement Learning and Time Series Forest Based Framework,"Anomaly detection (AD) plays a crucial role in time series applications,
primarily because time series data is employed across real-world scenarios.
Detecting anomalies poses significant challenges since anomalies take diverse
forms making them hard to pinpoint accurately. Previous research has explored
different AD models, making specific assumptions with varying sensitivity
toward particular anomaly types. To address this issue, we propose a novel
model selection for unsupervised AD using a combination of time series forest
(TSF) and reinforcement learning (RL) approaches that dynamically chooses an AD
technique. Our approach allows for effective AD without explicitly depending on
ground truth labels that are often scarce and expensive to obtain. Results from
the real-time series dataset demonstrate that the proposed model selection
approach outperforms all other AD models in terms of the F1 score metric. For
the synthetic dataset, our proposed model surpasses all other AD models except
for KNN, with an impressive F1 score of 0.989. The proposed model selection
framework also exceeded the performance of GPT-4 when prompted to act as an
anomaly detector on the synthetic dataset. Exploring different reward functions
revealed that the original reward function in our proposed AD model selection
approach yielded the best overall scores. We evaluated the performance of the
six AD models on an additional three datasets, having global, local, and
clustered anomalies respectively, showing that each AD model exhibited distinct
performance depending on the type of anomalies. This emphasizes the
significance of our proposed AD model selection framework, maintaining high
performance across all datasets, and showcasing superior performance across
different anomaly types.",2024-12-30,"Jihan Ghanim, Mariette Awad",http://arxiv.org/pdf/2501.00107v1,cs.LG
CaseSumm: A Large-Scale Dataset for Long-Context Summarization from U.S. Supreme Court Opinions,"This paper introduces CaseSumm, a novel dataset for long-context
summarization in the legal domain that addresses the need for longer and more
complex datasets for summarization evaluation. We collect 25.6K U.S. Supreme
Court (SCOTUS) opinions and their official summaries, known as ""syllabuses.""
Our dataset is the largest open legal case summarization dataset, and is the
first to include summaries of SCOTUS decisions dating back to 1815.
  We also present a comprehensive evaluation of LLM-generated summaries using
both automatic metrics and expert human evaluation, revealing discrepancies
between these assessment methods. Our evaluation shows Mistral 7b, a smaller
open-source model, outperforms larger models on most automatic metrics and
successfully generates syllabus-like summaries. In contrast, human expert
annotators indicate that Mistral summaries contain hallucinations. The
annotators consistently rank GPT-4 summaries as clearer and exhibiting greater
sensitivity and specificity. Further, we find that LLM-based evaluations are
not more correlated with human evaluations than traditional automatic metrics.
Furthermore, our analysis identifies specific hallucinations in generated
summaries, including precedent citation errors and misrepresentations of case
facts. These findings demonstrate the limitations of current automatic
evaluation methods for legal summarization and highlight the critical role of
human evaluation in assessing summary quality, particularly in complex,
high-stakes domains.
  CaseSumm is available at https://huggingface.co/datasets/ChicagoHAI/CaseSumm",2024-12-30,"Mourad Heddaya, Kyle MacMillan, Anup Malani, Hongyuan Mei, Chenhao Tan",http://arxiv.org/pdf/2501.00097v1,cs.LG
Insights on Galaxy Evolution from Interpretable Sparse Feature Networks,"Galaxy appearances reveal the physics of how they formed and evolved. Machine
learning models can now exploit galaxies' information-rich morphologies to
predict physical properties directly from image cutouts. Learning the
relationship between pixel-level features and galaxy properties is essential
for building a physical understanding of galaxy evolution, but we are still
unable to explicate the details of how deep neural networks represent image
features. To address this lack of interpretability, we present a novel neural
network architecture called a Sparse Feature Network (SFNet). SFNets produce
interpretable features that can be linearly combined in order to estimate
galaxy properties like optical emission line ratios or gas-phase metallicity.
We find that SFNets do not sacrifice accuracy in order to gain
interpretability, and that they perform comparably well to cutting-edge models
on astronomical machine learning tasks. Our novel approach is valuable for
finding physical patterns in large datasets and helping astronomers interpret
machine learning results.",2024-12-30,John F. Wu,http://arxiv.org/pdf/2501.00089v1,cs.LG
Machine Learning Gravity Compactifications on Negatively Curved Manifolds,"Constructing the landscape of vacua of higher-dimensional theories of gravity
by directly solving the low-energy (semi-)classical equations of motion is
notoriously difficult. In this work, we investigate the feasibility of Machine
Learning techniques as tools for solving the equations of motion for general
warped gravity compactifications. As a proof-of-concept we use Neural Networks
to solve the Einstein PDEs on non-trivial three manifolds obtained by filling
one or more cusps of hyperbolic manifolds. While in three dimensions an
Einstein metric is also locally hyperbolic, the generality and scalability of
Machine Learning methods, the availability of explicit families of hyperbolic
manifolds in higher dimensions, and the universality of the filling procedure
strongly suggest that the methods and code developed in this work can be of
broader applicability. Specifically, they can be used to tackle both the
geometric problem of numerically constructing novel higher-dimensional
negatively curved Einstein metrics, as well as the physical problem of
constructing four-dimensional de Sitter compactifications of M-theory on the
same manifolds.",2024-12-30,G. Bruno De Luca,http://arxiv.org/pdf/2501.00093v1,cs.LG
Action-Agnostic Point-Level Supervision for Temporal Action Detection,"We propose action-agnostic point-level (AAPL) supervision for temporal action
detection to achieve accurate action instance detection with a lightly
annotated dataset. In the proposed scheme, a small portion of video frames is
sampled in an unsupervised manner and presented to human annotators, who then
label the frames with action categories. Unlike point-level supervision, which
requires annotators to search for every action instance in an untrimmed video,
frames to annotate are selected without human intervention in AAPL supervision.
We also propose a detection model and learning method to effectively utilize
the AAPL labels. Extensive experiments on the variety of datasets (THUMOS '14,
FineAction, GTEA, BEOID, and ActivityNet 1.3) demonstrate that the proposed
approach is competitive with or outperforms prior methods for video-level and
point-level supervision in terms of the trade-off between the annotation cost
and detection performance.",2024-12-30,"Shuhei M. Yoshida, Takashi Shibata, Makoto Terao, Takayuki Okatani, Masashi Sugiyama",http://arxiv.org/pdf/2412.21205v1,cs.LG
"SoS Certificates for Sparse Singular Values and Their Applications: Robust Statistics, Subspace Distortion, and More","We study $\textit{sparse singular value certificates}$ for random rectangular
matrices. If $M$ is an $n \times d$ matrix with independent Gaussian entries,
we give a new family of polynomial-time algorithms which can certify upper
bounds on the maximum of $\|M u\|$, where $u$ is a unit vector with at most
$\eta n$ nonzero entries for a given $\eta \in (0,1)$. This basic algorithmic
primitive lies at the heart of a wide range of problems across algorithmic
statistics and theoretical computer science.
  Our algorithms certify a bound which is asymptotically smaller than the naive
one, given by the maximum singular value of $M$, for nearly the widest-possible
range of $n,d,$ and $\eta$. Efficiently certifying such a bound for a range of
$n,d$ and $\eta$ which is larger by any polynomial factor than what is achieved
by our algorithm would violate lower bounds in the SQ and low-degree
polynomials models. Our certification algorithm makes essential use of the
Sum-of-Squares hierarchy. To prove the correctness of our algorithm, we develop
a new combinatorial connection between the graph matrix approach to analyze
random matrices with dependent entries, and the Efron-Stein decomposition of
functions of independent random variables.
  As applications of our certification algorithm, we obtain new efficient
algorithms for a wide range of well-studied algorithmic tasks. In algorithmic
robust statistics, we obtain new algorithms for robust mean and covariance
estimation with tradeoffs between breakdown point and sample complexity, which
are nearly matched by SQ and low-degree polynomial lower bounds (that we
establish). We also obtain new polynomial-time guarantees for certification of
$\ell_1/\ell_2$ distortion of random subspaces of $\mathbb{R}^n$ (also with
nearly matching lower bounds), sparse principal component analysis, and
certification of the $2\rightarrow p$ norm of a random matrix.",2024-12-30,"Ilias Diakonikolas, Samuel B. Hopkins, Ankit Pensia, Stefan Tiegel",http://arxiv.org/pdf/2412.21203v1,cs.LG
Distributed Mixture-of-Agents for Edge Inference with Large Language Models,"Mixture-of-Agents (MoA) has recently been proposed as a method to enhance
performance of large language models (LLMs), enabling multiple individual LLMs
to work together for collaborative inference. This collaborative approach
results in improved responses to user prompts compared to relying on a single
LLM. In this paper, we consider such an MoA architecture in a distributed
setting, where LLMs operate on individual edge devices, each uniquely
associated with a user and equipped with its own distributed computing power.
These devices exchange information using decentralized gossip algorithms,
allowing different device nodes to talk without the supervision of a
centralized server. In the considered setup, different users have their own LLM
models to address user prompts. Additionally, the devices gossip either their
own user-specific prompts or augmented prompts to generate more refined answers
to certain queries. User prompts are temporarily stored in the device queues
when their corresponding LLMs are busy. Given the memory limitations of edge
devices, it is crucial to ensure that the average queue sizes in the system
remain bounded. In this paper, we address this by theoretically calculating the
queuing stability conditions for the device queues under reasonable
assumptions, which we validate experimentally as well. Further, we demonstrate
through experiments, leveraging open-source LLMs for the implementation of
distributed MoA, that certain MoA configurations produce higher-quality
responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The
implementation is available at:
https://github.com/purbeshmitra/distributed_moa.",2024-12-30,"Purbesh Mitra, Priyanka Kaswan, Sennur Ulukus",http://arxiv.org/pdf/2412.21200v1,cs.LG
Sparse chaos in cortical circuits,"Nerve impulses, the currency of information flow in the brain, are generated
by an instability of the neuronal membrane potential dynamics. Neuronal
circuits exhibit collective chaos that appears essential for learning, memory,
sensory processing, and motor control. However, the factors controlling the
nature and intensity of collective chaos in neuronal circuits are not well
understood. Here we use computational ergodic theory to demonstrate that basic
features of nerve impulse generation profoundly affect collective chaos in
neuronal circuits. Numerically exact calculations of Lyapunov spectra,
Kolmogorov-Sinai-entropy, and upper and lower bounds on attractor dimension
show that changes in nerve impulse generation in individual neurons moderately
impact information encoding rates but qualitatively transform phase space
structure. Specifically, we find a drastic reduction in the number of unstable
manifolds, Kolmogorov-Sinai entropy, and attractor dimension. Beyond a critical
point, marked by the simultaneous breakdown of the diffusion approximation, a
peak in the largest Lyapunov exponent, and a localization transition of the
leading covariant Lyapunov vector, networks exhibit sparse chaos: prolonged
periods of near stable dynamics interrupted by short bursts of intense chaos.
Analysis of large, more realistically structured networks supports the
generality of these findings. In cortical circuits, biophysical properties
appear tuned to this regime of sparse chaos. Our results reveal a close link
between fundamental aspects of single-neuron biophysics and the collective
dynamics of cortical circuits, suggesting that nerve impulse generation
mechanisms are adapted to enhance circuit controllability and information flow.",2024-12-30,"Rainer Engelken, Michael Monteforte, Fred Wolf",http://arxiv.org/pdf/2412.21188v1,cs.LG
Two-component spatiotemporal template for activation-inhibition of speech in ECoG,"I compute the average trial-by-trial power of band-limited speech activity
across epochs of multi-channel high-density electrocorticography (ECoG)
recorded from multiple subjects during a consonant-vowel speaking task. I show
that previously seen anti-correlations of average beta frequency activity
(12-35 Hz) to high-frequency gamma activity (70-140 Hz) during speech movement
are observable between individual ECoG channels in the sensorimotor cortex
(SMC). With this I fit a variance-based model using principal component
analysis to the band-powers of individual channels of session-averaged ECoG
data in the SMC and project SMC channels onto their lower-dimensional principal
components.
  Spatiotemporal relationships between speech-related activity and principal
components are identified by correlating the principal components of both
frequency bands to individual ECoG channels over time using windowed
correlation. Correlations of principal component areas to sensorimotor areas
reveal a distinct two-component activation-inhibition-like representation for
speech that resembles distinct local sensorimotor areas recently shown to have
complex interplay in whole-body motor control, inhibition, and posture. Notably
the third principal component shows insignificant correlations across all
subjects, suggesting two components of ECoG are sufficient to represent SMC
activity during speech movement.",2024-12-30,Eric Easthope,http://arxiv.org/pdf/2412.21178v1,cs.LG
Adversarial Attack and Defense for LoRa Device Identification and Authentication via Deep Learning,"LoRa provides long-range, energy-efficient communications in Internet of
Things (IoT) applications that rely on Low-Power Wide-Area Network (LPWAN)
capabilities. Despite these merits, concerns persist regarding the security of
LoRa networks, especially in situations where device identification and
authentication are imperative to secure the reliable access to the LoRa
networks. This paper explores a deep learning (DL) approach to tackle these
concerns, focusing on two critical tasks, namely (i) identifying LoRa devices
and (ii) classifying them to legitimate and rogue devices. Deep neural networks
(DNNs), encompassing both convolutional and feedforward neural networks, are
trained for these tasks using actual LoRa signal data. In this setting, the
adversaries may spoof rogue LoRa signals through the kernel density estimation
(KDE) method based on legitimate device signals that are received by the
adversaries. Two cases are considered, (i) training two separate classifiers,
one for each of the two tasks, and (ii) training a multi-task classifier for
both tasks. The vulnerabilities of the resulting DNNs to manipulations in input
samples are studied in form of untargeted and targeted adversarial attacks
using the Fast Gradient Sign Method (FGSM). Individual and common perturbations
are considered against single-task and multi-task classifiers for the LoRa
signal analysis. To provide resilience against such attacks, a defense approach
is presented by increasing the robustness of classifiers with adversarial
training. Results quantify how vulnerable LoRa signal classification tasks are
to adversarial attacks and emphasize the need to fortify IoT applications
against these subtle yet effective threats.",2024-12-30,"Yalin E. Sagduyu, Tugba Erpek",http://arxiv.org/pdf/2412.21164v1,cs.LG
High-Dimensional Markov-switching Ordinary Differential Processes,"We investigate the parameter recovery of Markov-switching ordinary
differential processes from discrete observations, where the differential
equations are nonlinear additive models. This framework has been widely applied
in biological systems, control systems, and other domains; however, limited
research has been conducted on reconstructing the generating processes from
observations. In contrast, many physical systems, such as human brains, cannot
be directly experimented upon and rely on observations to infer the underlying
systems. To address this gap, this manuscript presents a comprehensive study of
the model, encompassing algorithm design, optimization guarantees, and
quantification of statistical errors. Specifically, we develop a two-stage
algorithm that first recovers the continuous sample path from discrete samples
and then estimates the parameters of the processes. We provide novel
theoretical insights into the statistical error and linear convergence
guarantee when the processes are $\beta$-mixing. Our analysis is based on the
truncation of the latent posterior processes and demonstrates that the
truncated processes approximate the true processes under mixing conditions. We
apply this model to investigate the differences in resting-state brain networks
between the ADHD group and normal controls, revealing differences in the
transition rate matrices of the two groups.",2024-12-30,"Katherine Tsai, Mladen Kolar, Sanmi Koyejo",http://arxiv.org/pdf/2501.00087v1,cs.LG
Unified dimensionality reduction techniques in chronic liver disease detection,"Globally, chronic liver disease continues to be a major health concern that
requires precise predictive models for prompt detection and treatment. Using
the Indian Liver Patient Dataset (ILPD) from the University of California at
Irvine's UCI Machine Learning Repository, a number of machine learning
algorithms are investigated in this study. The main focus of our research is
this dataset, which includes the medical records of 583 patients, 416 of whom
have been diagnosed with liver disease and 167 of whom have not. There are
several aspects to this work, including feature extraction and dimensionality
reduction methods like Linear Discriminant Analysis (LDA), Factor Analysis
(FA), t-distributed Stochastic Neighbour Embedding (t-SNE), and Uniform
Manifold Approximation and Projection (UMAP). The purpose of the study is to
investigate how well these approaches work for converting high-dimensional
datasets and improving prediction accuracy. To assess the prediction ability of
the improved models, a number of classification methods were used, such as
Multi-layer Perceptron, Random Forest, K-nearest neighbours, and Logistic
Regression. Remarkably, the improved models performed admirably, with Random
Forest having the highest accuracy of 98.31\% in 10-fold cross-validation and
95.79\% in train-test split evaluation. Findings offer important new
perspectives on the choice and use of customized feature extraction and
dimensionality reduction methods, which improve predictive models for patients
with chronic liver disease.",2024-12-30,"Anand Karna, Naina Khan, Rahul Rauniyar, Prashant Giridhar Shambharkar",http://arxiv.org/pdf/2412.21156v1,cs.LG
Aviary: training language agents on challenging scientific tasks,"Solving complex real-world tasks requires cycles of actions and observations.
This is particularly true in science, where tasks require many cycles of
analysis, tool use, and experimentation. Language agents are promising for
automating intellectual tasks in science because they can interact with tools
via natural language or code. Yet their flexibility creates conceptual and
practical challenges for software implementations, since agents may comprise
non-standard components such as internal reasoning, planning, tool usage, as
well as the inherent stochasticity of temperature-sampled language models.
Here, we introduce Aviary, an extensible gymnasium for language agents. We
formalize agents as policies solving language-grounded partially observable
Markov decision processes, which we term language decision processes. We then
implement five environments, including three challenging scientific
environments: (1) manipulating DNA constructs for molecular cloning, (2)
answering research questions by accessing scientific literature, and (3)
engineering protein stability. These environments were selected for their focus
on multi-step reasoning and their relevance to contemporary biology research.
Finally, with online training and scaling inference-time compute, we show that
language agents backed by open-source, non-frontier LLMs can match and exceed
both frontier LLM agents and human experts on multiple tasks at up to 100x
lower inference cost.",2024-12-30,"Siddharth Narayanan, James D. Braza, Ryan-Rhys Griffiths, Manu Ponnapati, Albert Bou, Jon Laurent, Ori Kabeli, Geemi Wellawatte, Sam Cox, Samuel G. Rodriques, Andrew D. White",http://arxiv.org/pdf/2412.21154v1,cs.LG
PyG-SSL: A Graph Self-Supervised Learning Toolkit,"Graph Self-Supervised Learning (SSL) has emerged as a pivotal area of
research in recent years. By engaging in pretext tasks to learn the intricate
topological structures and properties of graphs using unlabeled data, these
graph SSL models achieve enhanced performance, improved generalization, and
heightened robustness. Despite the remarkable achievements of these graph SSL
methods, their current implementation poses significant challenges for
beginners and practitioners due to the complex nature of graph structures,
inconsistent evaluation metrics, and concerns regarding reproducibility hinder
further progress in this field. Recognizing the growing interest within the
research community, there is an urgent need for a comprehensive,
beginner-friendly, and accessible toolkit consisting of the most representative
graph SSL algorithms. To address these challenges, we present a Graph SSL
toolkit named PyG-SSL, which is built upon PyTorch and is compatible with
various deep learning and scientific computing backends. Within the toolkit, we
offer a unified framework encompassing dataset loading, hyper-parameter
configuration, model training, and comprehensive performance evaluation for
diverse downstream tasks. Moreover, we provide beginner-friendly tutorials and
the best hyper-parameters of each graph SSL algorithm on different graph
datasets, facilitating the reproduction of results. The GitHub repository of
the library is https://github.com/iDEA-iSAIL-Lab-UIUC/pyg-ssl.",2024-12-30,"Lecheng Zheng, Baoyu Jing, Zihao Li, Zhichen Zeng, Tianxin Wei, Mengting Ai, Xinrui He, Lihui Liu, Dongqi Fu, Jiaxuan You, Hanghang Tong, Jingrui He",http://arxiv.org/pdf/2412.21151v1,cs.LG
Functional Risk Minimization,"The field of Machine Learning has changed significantly since the 1970s.
However, its most basic principle, Empirical Risk Minimization (ERM), remains
unchanged. We propose Functional Risk Minimization~(FRM), a general framework
where losses compare functions rather than outputs. This results in better
performance in supervised, unsupervised, and RL experiments. In the FRM
paradigm, for each data point $(x_i,y_i)$ there is function $f_{\theta_i}$ that
fits it: $y_i = f_{\theta_i}(x_i)$. This allows FRM to subsume ERM for many
common loss functions and to capture more realistic noise processes. We also
show that FRM provides an avenue towards understanding generalization in the
modern over-parameterized regime, as its objective can be framed as finding the
simplest model that fits the training data.",2024-12-30,"Ferran Alet, Clement Gehring, Tomás Lozano-Pérez, Kenji Kawaguchi, Joshua B. Tenenbaum, Leslie Pack Kaelbling",http://arxiv.org/pdf/2412.21149v1,cs.LG
Machine Learning-Based Security Policy Analysis,"Security-Enhanced Linux (SELinux) is a robust security mechanism that
enforces mandatory access controls (MAC), but its policy language's complexity
creates challenges for policy analysis and management. This research
investigates the automation of SELinux policy analysis using graph-based
techniques combined with machine learning approaches to detect policy
anomalies. The study addresses two key questions: Can SELinux policy analysis
be automated through graph analysis, and how do different anomaly detection
models compare in analyzing SELinux policies? We will be comparing different
machine learning models by evaluating their effectiveness in detecting policy
violations and anomalies. Our approach utilizes Neo4j for graph representation
of policies, with Node2vec transforming these graph structures into meaningful
vector embeddings that can be processed by our machine learning models. In our
results, the MLP Neural Network consistently demonstrated superior performance
across different dataset sizes, achieving 95% accuracy with balanced precision
and recall metrics, while both Random Forest and SVM models showed competitive
but slightly lower performance in detecting policy violations. This combination
of graph-based modeling and machine learning provides a more sophisticated and
automated approach to understanding and analyzing complex SELinux policies
compared to traditional manual analysis methods.",2024-12-30,"Krish Jain, Joann Sum, Pranav Kapoor, Amir Eaman",http://arxiv.org/pdf/2501.00085v2,cs.LG
DeepF-fNet: a physics-informed neural network for vibration isolation optimization,"Structural optimization is essential for designing safe, efficient, and
durable components with minimal material usage. Traditional methods for
vibration control often rely on active systems to mitigate unpredictable
vibrations, which may lead to resonance and potential structural failure.
However, these methods face significant challenges when addressing the
nonlinear inverse eigenvalue problems required for optimizing structures
subjected to a wide range of frequencies. As a result, no existing approach has
effectively addressed the need for real-time vibration suppression within this
context, particularly in high-performance environments such as automotive
noise, vibration and harshness, where computational efficiency is crucial.
  This study introduces DeepF-fNet, a novel neural network framework designed
to replace traditional active systems in vibration-based structural
optimization. Leveraging DeepONets within the context of physics-informed
neural networks, DeepF-fNet integrates both data and the governing physical
laws. This enables rapid identification of optimal parameters to suppress
critical vibrations at specific frequencies, offering a more efficient and
real-time alternative to conventional methods.
  The proposed framework is validated through a case study involving a locally
resonant metamaterial used to isolate structures from user-defined frequency
ranges. The results demonstrate that DeepF-fNet outperforms traditional genetic
algorithms in terms of computational speed while achieving comparable results,
making it a promising tool for vibration-sensitive applications. By replacing
active systems with machine learning techniques, DeepF-fNet paves the way for
more efficient and cost-effective structural optimization in real-world
scenarios.",2024-12-30,"A. Tollardo, F. Cadini, M. Giglio, L. Lomazzi",http://arxiv.org/pdf/2412.21132v1,cs.LG
Gender Bias in Text-to-Video Generation Models: A case study of Sora,"The advent of text-to-video generation models has revolutionized content
creation as it produces high-quality videos from textual prompts. However,
concerns regarding inherent biases in such models have prompted scrutiny,
particularly regarding gender representation. Our study investigates the
presence of gender bias in OpenAI's Sora, a state-of-the-art text-to-video
generation model. We uncover significant evidence of bias by analyzing the
generated videos from a diverse set of gender-neutral and stereotypical
prompts. The results indicate that Sora disproportionately associates specific
genders with stereotypical behaviors and professions, which reflects societal
prejudices embedded in its training data.",2024-12-30,"Mohammad Nadeem, Shahab Saquib Sohail, Erik Cambria, Björn W. Schuller, Amir Hussain",http://arxiv.org/pdf/2501.01987v2,cs.LG
Adaptive Batch Size Schedules for Distributed Training of Language Models with Data and Model Parallelism,"An appropriate choice of batch sizes in large-scale model training is
crucial, yet it involves an intrinsic yet inevitable dilemma: large-batch
training improves training efficiency in terms of memory utilization, while
generalization performance often deteriorates due to small amounts of gradient
noise. Despite this dilemma, the common practice of choosing batch sizes in
language model training often prioritizes training efficiency -- employing
either constant large sizes with data parallelism or implementing batch size
warmup schedules. However, such batch size schedule designs remain heuristic
and often fail to adapt to training dynamics, presenting the challenge of
designing adaptive batch size schedules. Given the abundance of available
datasets and the data-hungry nature of language models, data parallelism has
become an indispensable distributed training paradigm, enabling the use of
larger batch sizes for gradient computation. However, vanilla data parallelism
requires replicas of model parameters, gradients, and optimizer states at each
worker, which prohibits training larger models with billions of parameters. To
optimize memory usage, more advanced parallelism strategies must be employed.
In this work, we propose general-purpose and theoretically principled adaptive
batch size schedules compatible with data parallelism and model parallelism. We
develop a practical implementation with PyTorch Fully Sharded Data Parallel,
facilitating the pretraining of language models of different sizes. We
empirically demonstrate that our proposed approaches outperform constant batch
sizes and heuristic batch size warmup schedules in the pretraining of models in
the Llama 2 family, with particular focus on smaller models with up to 3
billion parameters. We also establish theoretical convergence guarantees for
such adaptive batch size schedules with Adam for general smooth nonconvex
objectives.",2024-12-30,"Tim Tsz-Kit Lau, Weijian Li, Chenwei Xu, Han Liu, Mladen Kolar",http://arxiv.org/pdf/2412.21124v2,cs.LG
On the Generalizability of Machine Learning-based Ransomware Detection in Block Storage,"Ransomware represents a pervasive threat, traditionally countered at the
operating system, file-system, or network levels. However, these approaches
often introduce significant overhead and remain susceptible to circumvention by
attackers. Recent research activity started looking into the detection of
ransomware by observing block IO operations. However, this approach exhibits
significant detection challenges. Recognizing these limitations, our research
pivots towards enabling robust ransomware detection in storage systems keeping
in mind their limited computational resources available. To perform our
studies, we propose a kernel-based framework capable of efficiently extracting
and analyzing IO operations to identify ransomware activity. The framework can
be adopted to storage systems using computational storage devices to improve
security and fully hide detection overheads. Our method employs a refined set
of computationally light features optimized for ML models to accurately discern
malicious from benign activities.
  Using this lightweight approach, we study a wide range of generalizability
aspects and analyze the performance of these models across a large space of
setups and configurations covering a wide range of realistic real-world
scenarios. We reveal various trade-offs and provide strong arguments for the
generalizability of storage-based detection of ransomware and show that our
approach outperforms currently available ML-based ransomware detection in
storage. Empirical validation reveals that our decision tree-based models
achieve remarkable effectiveness, evidenced by higher median F1 scores of up to
12.8%, lower false negative rates of up to 10.9% and particularly decreased
false positive rates of up to 17.1% compared to existing storage-based
detection approaches.",2024-12-30,"Nicolas Reategui, Roman Pletka, Dionysios Diamantopoulos",http://arxiv.org/pdf/2412.21084v1,cs.LG
Quantum Diffusion Model for Quark and Gluon Jet Generation,"Diffusion models have demonstrated remarkable success in image generation,
but they are computationally intensive and time-consuming to train. In this
paper, we introduce a novel diffusion model that benefits from quantum
computing techniques in order to mitigate computational challenges and enhance
generative performance within high energy physics data. The fully quantum
diffusion model replaces Gaussian noise with random unitary matrices in the
forward process and incorporates a variational quantum circuit within the U-Net
in the denoising architecture. We run evaluations on the structurally complex
quark and gluon jets dataset from the Large Hadron Collider. The results
demonstrate that the fully quantum and hybrid models are competitive with a
similar classical model for jet generation, highlighting the potential of using
quantum techniques for machine learning problems.",2024-12-30,"Mariia Baidachna, Rey Guadarrama, Gopal Ramesh Dahale, Tom Magorsch, Isabel Pedraza, Konstantin T. Matchev, Katia Matcheva, Kyoungchul Kong, Sergei Gleyzer",http://arxiv.org/pdf/2412.21082v1,cs.LG
Enhanced coarsening of charge density waves induced by electron correlation: Machine-learning enabled large-scale dynamical simulations,"The phase ordering kinetics of emergent orders in correlated electron systems
is a fundamental topic in non-equilibrium physics, yet it remains largely
unexplored. The intricate interplay between quasiparticles and emergent
order-parameter fields could lead to unusual coarsening dynamics that is beyond
the standard theories. However, accurate treatment of both quasiparticles and
collective degrees of freedom is a multi-scale challenge in dynamical
simulations of correlated electrons. Here we leverage modern machine learning
(ML) methods to achieve a linear-scaling algorithm for simulating the
coarsening of charge density waves (CDWs), one of the fundamental symmetry
breaking phases in functional electron materials. We demonstrate our approach
on the square-lattice Hubbard-Holstein model and uncover an intriguing
enhancement of CDW coarsening which is related to the screening of on-site
potential by electron-electron interactions. Our study provides fresh insights
into the role of electron correlations in non-equilibrium dynamics and
underscores the promise of ML force-field approaches for advancing multi-scale
dynamical modeling of correlated electron systems.",2024-12-30,"Yang Yang, Chen Cheng, Yunhao Fan, Gia-Wei Chern",http://arxiv.org/pdf/2412.21072v1,cs.LG
Investigating layer-selective transfer learning of QAOA parameters for Max-Cut problem,"Quantum approximate optimization algorithm (QAOA) is a variational quantum
algorithm (VQA) ideal for noisy intermediate-scale quantum (NISQ) processors,
and is highly successful for solving combinatorial optimization problems
(COPs). It has been observed that the optimal variational parameters obtained
from one instance of a COP can be transferred to another instance, producing
sufficiently satisfactory solutions for the latter. In this context, a suitable
method for further improving the solution is to fine-tune a subset of the
transferred parameters. We numerically explore the role of optimizing
individual QAOA layers in improving the approximate solution of the Max-Cut
problem after parameter transfer. We also investigate the trade-off between a
good approximation and the required optimization time when optimizing
transferred QAOA parameters. These studies show that optimizing a subset of
layers can be more effective at a lower time-cost compared to optimizing all
layers.",2024-12-30,"Francesco Aldo Venturelli, Sreetama Das, Filippo Caruso",http://arxiv.org/pdf/2412.21071v1,cs.LG
Privacy-Aware Multi-Device Cooperative Edge Inference with Distributed Resource Bidding,"Mobile edge computing (MEC) has empowered mobile devices (MDs) in supporting
artificial intelligence (AI) applications through collaborative efforts with
proximal MEC servers. Unfortunately, despite the great promise of device-edge
cooperative AI inference, data privacy becomes an increasing concern. In this
paper, we develop a privacy-aware multi-device cooperative edge inference
system for classification tasks, which integrates a distributed bidding
mechanism for the MEC server's computational resources. Intermediate feature
compression is adopted as a principled approach to minimize data privacy
leakage. To determine the bidding values and feature compression ratios in a
distributed fashion, we formulate a decentralized partially observable Markov
decision process (DEC-POMDP) model, for which, a multi-agent deep deterministic
policy gradient (MADDPG)-based algorithm is developed. Simulation results
demonstrate the effectiveness of the proposed algorithm in privacy-preserving
cooperative edge inference. Specifically, given a sufficient level of data
privacy protection, the proposed algorithm achieves 0.31-0.95% improvements in
classification accuracy compared to the approach being agnostic to the wireless
channel conditions. The performance is further enhanced by 1.54-1.67% by
considering the difficulties of inference data.",2024-12-30,"Wenhao Zhuang, Yuyi Mao",http://arxiv.org/pdf/2412.21069v1,cs.LG
BridgePure: Limited Protection Leakage Can Break Black-Box Data Protection,"Availability attacks, or unlearnable examples, are defensive techniques that
allow data owners to modify their datasets in ways that prevent unauthorized
machine learning models from learning effectively while maintaining the data's
intended functionality. It has led to the release of popular black-box tools
(e.g., APIs) for users to upload personal data and receive protected
counterparts. In this work, we show that such black-box protections can be
substantially compromised if a small set of unprotected in-distribution data is
available. Specifically, we propose a novel threat model of protection leakage,
where an adversary can (1) easily acquire (unprotected, protected) pairs by
querying the black-box protections with a small unprotected dataset; and (2)
train a diffusion bridge model to build a mapping between unprotected and
protected data. This mapping, termed BridgePure, can effectively remove the
protection from any previously unseen data within the same distribution.
BridgePure demonstrates superior purification performance on classification and
style mimicry tasks, exposing critical vulnerabilities in black-box data
protection. We suggest that practitioners implement multi-level countermeasures
to mitigate such risks.",2024-12-30,"Yihan Wang, Yiwei Lu, Xiao-Shan Gao, Gautam Kamath, Yaoliang Yu",http://arxiv.org/pdf/2412.21061v2,cs.LG
Towards Effective Discrimination Testing for Generative AI,"Generative AI (GenAI) models present new challenges in regulating against
discriminatory behavior. In this paper, we argue that GenAI fairness research
still has not met these challenges; instead, a significant gap remains between
existing bias assessment methods and regulatory goals. This leads to
ineffective regulation that can allow deployment of reportedly fair, yet
actually discriminatory, GenAI systems. Towards remedying this problem, we
connect the legal and technical literature around GenAI bias evaluation and
identify areas of misalignment. Through four case studies, we demonstrate how
this misalignment between fairness testing techniques and regulatory goals can
result in discriminatory outcomes in real-world deployments, especially in
adaptive or complex environments. We offer practical recommendations for
improving discrimination testing to better align with regulatory goals and
enhance the reliability of fairness assessments in future deployments.",2024-12-30,"Thomas P. Zollo, Nikita Rajaneesh, Richard Zemel, Talia B. Gillis, Emily Black",http://arxiv.org/pdf/2412.21052v1,cs.LG
Learning Epidemiological Dynamics via the Finite Expression Method,"Modeling and forecasting the spread of infectious diseases is essential for
effective public health decision-making. Traditional epidemiological models
rely on expert-defined frameworks to describe complex dynamics, while neural
networks, despite their predictive power, often lack interpretability due to
their ``black-box"" nature. This paper introduces the Finite Expression Method,
a symbolic learning framework that leverages reinforcement learning to derive
explicit mathematical expressions for epidemiological dynamics. Through
numerical experiments on both synthetic and real-world datasets, FEX
demonstrates high accuracy in modeling and predicting disease spread, while
uncovering explicit relationships among epidemiological variables. These
results highlight FEX as a powerful tool for infectious disease modeling,
combining interpretability with strong predictive performance to support
practical applications in public health.",2024-12-30,"Jianda Du, Senwei Liang, Chunmei Wang",http://arxiv.org/pdf/2412.21049v1,cs.LG
Mind the truncation gap: challenges of learning on dynamic graphs with recurrent architectures,"Systems characterized by evolving interactions, prevalent in social,
financial, and biological domains, are effectively modeled as continuous-time
dynamic graphs (CTDGs). To manage the scale and complexity of these graph
datasets, machine learning (ML) approaches have become essential. However,
CTDGs pose challenges for ML because traditional static graph methods do not
naturally account for event timings. Newer approaches, such as graph recurrent
neural networks (GRNNs), are inherently time-aware and offer advantages over
static methods for CTDGs. However, GRNNs face another issue: the short
truncation of backpropagation-through-time (BPTT), whose impact has not been
properly examined until now. In this work, we demonstrate that this truncation
can limit the learning of dependencies beyond a single hop, resulting in
reduced performance. Through experiments on a novel synthetic task and
real-world datasets, we reveal a performance gap between full
backpropagation-through-time (F-BPTT) and the truncated
backpropagation-through-time (T-BPTT) commonly used to train GRNN models. We
term this gap the ""truncation gap"" and argue that understanding and addressing
it is essential as the importance of CTDGs grows, discussing potential future
directions for research in this area.",2024-12-30,"João Bravo, Jacopo Bono, Pedro Saleiro, Hugo Ferreira, Pedro Bizarro",http://arxiv.org/pdf/2412.21046v1,cs.LG
Machine Learning Optimal Ordering in Global Routing Problems in Semiconductors,"In this work, we propose a new method for ordering nets during the process of
layer assignment in global routing problems. The global routing problems that
we focus on in this work are based on routing problems that occur in the design
of substrates in multilayered semiconductor packages. The proposed new method
is based on machine learning techniques and we show that the proposed method
supersedes conventional net ordering techniques based on heuristic score
functions. We perform global routing experiments in multilayered semiconductor
package environments in order to illustrate that the routing order based on our
new proposed technique outperforms previous methods based on heuristics. Our
approach of using machine learning for global routing targets specifically the
net ordering step which we show in this work can be significantly improved by
deep learning.",2024-12-30,"Heejin Choi, Minji Lee, Chang Hyeong Lee, Jaeho Yang, Rak-Kyeong Seong",http://arxiv.org/pdf/2412.21035v1,cs.LG
Improving Location-based Thermal Emission Side-Channel Analysis Using Iterative Transfer Learning,"This paper proposes the use of iterative transfer learning applied to deep
learning models for side-channel attacks. Currently, most of the side-channel
attack methods train a model for each individual byte, without considering the
correlation between bytes. However, since the models' parameters for attacking
different bytes may be similar, we can leverage transfer learning, meaning that
we first train the model for one of the key bytes, then use the trained model
as a pretrained model for the remaining bytes. This technique can be applied
iteratively, a process known as iterative transfer learning. Experimental
results show that when using thermal or power consumption map images as input,
and multilayer perceptron or convolutional neural network as the model, our
method improves average performance, especially when the amount of data is
insufficient.",2024-12-30,"Tun-Chieh Lou, Chung-Che Wang, Jyh-Shing Roger Jang, Henian Li, Lang Lin, Norman Chang",http://arxiv.org/pdf/2412.21030v1,cs.LG
EdgeRAG: Online-Indexed RAG for Edge Devices,"Deploying Retrieval Augmented Generation (RAG) on resource-constrained edge
devices is challenging due to limited memory and processing power. In this
work, we propose EdgeRAG which addresses the memory constraint by pruning
embeddings within clusters and generating embeddings on-demand during
retrieval. To avoid the latency of generating embeddings for large tail
clusters, EdgeRAG pre-computes and stores embeddings for these clusters, while
adaptively caching remaining embeddings to minimize redundant computations and
further optimize latency. The result from BEIR suite shows that EdgeRAG offers
significant latency reduction over the baseline IVF index, but with similar
generation quality while allowing all of our evaluated datasets to fit into the
memory.",2024-12-30,"Korakit Seemakhupt, Sihang Liu, Samira Khan",http://arxiv.org/pdf/2412.21023v2,cs.LG
Text Classification: Neural Networks VS Machine Learning Models VS Pre-trained Models,"Text classification is a very common task nowadays and there are many
efficient methods and algorithms that we can employ to accomplish it.
Transformers have revolutionized the field of deep learning, particularly in
Natural Language Processing (NLP) and have rapidly expanded to other domains
such as computer vision, time-series analysis and more. The transformer model
was firstly introduced in the context of machine translation and its
architecture relies on self-attention mechanisms to capture complex
relationships within data sequences. It is able to handle long-range
dependencies more effectively than traditional neural networks (such as
Recurrent Neural Networks and Multilayer Perceptrons). In this work, we present
a comparison between different techniques to perform text classification. We
take into consideration seven pre-trained models, three standard neural
networks and three machine learning models. For standard neural networks and
machine learning models we also compare two embedding techniques: TF-IDF and
GloVe, with the latter consistently outperforming the former. Finally, we
demonstrate the results from our experiments where pre-trained models such as
BERT and DistilBERT always perform better than standard models/algorithms.",2024-12-30,Christos Petridis,http://arxiv.org/pdf/2412.21022v1,cs.LG
Weber-Fechner Law in Temporal Difference learning derived from Control as Inference,"This paper investigates a novel nonlinear update rule based on temporal
difference (TD) errors in reinforcement learning (RL). The update rule in the
standard RL states that the TD error is linearly proportional to the degree of
updates, treating all rewards equally without no bias. On the other hand, the
recent biological studies revealed that there are nonlinearities in the TD
error and the degree of updates, biasing policies optimistic or pessimistic.
Such biases in learning due to nonlinearities are expected to be useful and
intentionally leftover features in biological learning. Therefore, this
research explores a theoretical framework that can leverage the nonlinearity
between the degree of the update and TD errors. To this end, we focus on a
control as inference framework, since it is known as a generalized formulation
encompassing various RL and optimal control methods. In particular, we
investigate the uncomputable nonlinear term needed to be approximately excluded
in the derivation of the standard RL from control as inference. By analyzing
it, Weber-Fechner law (WFL) is found, namely, perception (a.k.a. the degree of
updates) in response to stimulus change (a.k.a. TD error) is attenuated by
increase in the stimulus intensity (a.k.a. the value function). To numerically
reveal the utilities of WFL on RL, we then propose a practical implementation
using a reward-punishment framework and modifying the definition of optimality.
Analysis of this implementation reveals that two utilities can be expected i)
to increase rewards to a certain level early, and ii) to sufficiently suppress
punishment. We finally investigate and discuss the expected utilities through
simulations and robot experiments. As a result, the proposed RL algorithm with
WFL shows the expected utilities that accelerate the reward-maximizing startup
and continue to suppress punishments during learning.",2024-12-30,"Keiichiro Takahashi, Taisuke Kobayashi, Tomoya Yamanokuchi, Takamitsu Matsubara",http://arxiv.org/pdf/2412.21004v1,cs.LG
LEASE: Offline Preference-based Reinforcement Learning with High Sample Efficiency,"Offline preference-based reinforcement learning (PbRL) provides an effective
way to overcome the challenges of designing reward and the high costs of online
interaction. However, since labeling preference needs real-time human feedback,
acquiring sufficient preference labels is challenging. To solve this, this
paper proposes a offLine prEference-bAsed RL with high Sample Efficiency
(LEASE) algorithm, where a learned transition model is leveraged to generate
unlabeled preference data. Considering the pretrained reward model may generate
incorrect labels for unlabeled data, we design an uncertainty-aware mechanism
to ensure the performance of reward model, where only high confidence and low
variance data are selected. Moreover, we provide the generalization bound of
reward model to analyze the factors influencing reward accuracy, and
demonstrate that the policy learned by LEASE has theoretical improvement
guarantee. The developed theory is based on state-action pair, which can be
easily combined with other offline algorithms. The experimental results show
that LEASE can achieve comparable performance to baseline under fewer
preference data without online interaction.",2024-12-30,"Xiao-Yin Liu, Guotao Li, Xiao-Hu Zhou, Zeng-Guang Hou",http://arxiv.org/pdf/2412.21001v1,cs.LG
Efficiently Serving LLM Reasoning Programs with Certaindex,"The rapid evolution of large language models (LLMs) has unlocked their
capabilities in advanced reasoning tasks like mathematical problem-solving,
code generation, and legal analysis. Central to this progress are
inference-time reasoning algorithms, which refine outputs by exploring multiple
solution paths, at the cost of increasing compute demands and response
latencies. Existing serving systems fail to adapt to the scaling behaviors of
these algorithms or the varying difficulty of queries, leading to inefficient
resource use and unmet latency targets.
  We present Dynasor, a system that optimizes inference-time compute for LLM
reasoning queries. Unlike traditional engines, Dynasor tracks and schedules
requests within reasoning queries and uses Certaindex, a proxy that measures
statistical reasoning progress based on model certainty, to guide compute
allocation dynamically. Dynasor co-adapts scheduling with reasoning progress:
it allocates more compute to hard queries, reduces compute for simpler ones,
and terminates unpromising queries early, balancing accuracy, latency, and
cost. On diverse datasets and algorithms, Dynasor reduces compute by up to 50%
in batch processing and sustaining 3.3x higher query rates or 4.7x tighter
latency SLOs in online serving.",2024-12-30,"Yichao Fu, Junda Chen, Siqi Zhu, Zheyu Fu, Zhongdongming Dai, Aurick Qiao, Hao Zhang",http://arxiv.org/pdf/2412.20993v1,cs.LG
Verified Lifting of Deep learning Operators,"Deep learning operators are fundamental components of modern deep learning
frameworks. With the growing demand for customized operators, it has become
increasingly common for developers to create their own. However, designing and
implementing operators is complex and error-prone, due to hardware-specific
optimizations and the need for numerical stability. There is a pressing need
for tools that can summarize the functionality of both existing and
user-defined operators. To address this gap, this work introduces a novel
framework for the verified lifting of deep learning operators, which
synthesizes high-level mathematical formulas from low-level implementations.
Our approach combines symbolic execution, syntax-guided synthesis, and
SMT-based verification to produce readable and formally verified mathematical
formulas. In synthesis, we employ a combination of top-down and bottom-up
strategies to explore the vast search space efficiently; In verification, we
design invariant synthesis patterns and leverage SMT solvers to validate the
correctness of the derived summaries; In simplification, we use egraph-based
techniques with custom rules to restore complex formulas to their natural,
intuitive forms. Evaluated on a dataset of deep learning operators implemented
in Triton from the real world, our method demonstrates the effectiveness of
synthesis and verification compared to existing techniques. This framework
bridges the gap between low-level implementations and high-level abstractions,
improving understanding and reliability in deep learning operator development.",2024-12-30,"Qi Zhan, Xing Hu, Xin Xia, Shanping Li",http://arxiv.org/pdf/2412.20992v1,cs.LG
RobustBlack: Challenging Black-Box Adversarial Attacks on State-of-the-Art Defenses,"Although adversarial robustness has been extensively studied in white-box
settings, recent advances in black-box attacks (including transfer- and
query-based approaches) are primarily benchmarked against weak defenses,
leaving a significant gap in the evaluation of their effectiveness against more
recent and moderate robust models (e.g., those featured in the Robustbench
leaderboard). In this paper, we question this lack of attention from black-box
attacks to robust models. We establish a framework to evaluate the
effectiveness of recent black-box attacks against both top-performing and
standard defense mechanisms, on the ImageNet dataset. Our empirical evaluation
reveals the following key findings: (1) the most advanced black-box attacks
struggle to succeed even against simple adversarially trained models; (2)
robust models that are optimized to withstand strong white-box attacks, such as
AutoAttack, also exhibits enhanced resilience against black-box attacks; and
(3) robustness alignment between the surrogate models and the target model
plays a key factor in the success rate of transfer-based attacks",2024-12-30,"Mohamed Djilani, Salah Ghamizi, Maxime Cordy",http://arxiv.org/pdf/2412.20987v1,cs.LG
AlignAb: Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies,"We present a three-stage framework for training deep learning models
specializing in antibody sequence-structure co-design. We first pre-train a
language model using millions of antibody sequence data. Then, we employ the
learned representations to guide the training of a diffusion model for joint
optimization over both sequence and structure of antibodies. During the final
alignment stage, we optimize the model to favor antibodies with low repulsion
and high attraction to the antigen binding site, enhancing the rationality and
functionality of the designs. To mitigate conflicting energy preferences, we
extend AbDPO (Antibody Direct Preference Optimization) to guide the model
towards Pareto optimality under multiple energy-based alignment objectives.
Furthermore, we adopt an iterative learning paradigm with temperature scaling,
enabling the model to benefit from diverse online datasets without requiring
additional data. In practice, our proposed methods achieve high stability and
efficiency in producing a better Pareto front of antibody designs compared to
top samples generated by baselines and previous alignment techniques. Through
extensive experiments, we showcase the superior performance of our methods in
generating nature-like antibodies with high binding affinity consistently.",2024-12-30,"Yibo Wen, Chenwei Xu, Jerry Yao-Chieh Hu, Han Liu",http://arxiv.org/pdf/2412.20984v1,cs.LG
Pressing Intensity: An Intuitive Measure for Pressing in Soccer,"Pressing is a fundamental defensive strategy in football, characterized by
applying pressure on the ball owning team to regain possession. Despite its
significance, existing metrics for measuring pressing often lack precision or
comprehensive consideration of positional data, player movement and speed. This
research introduces an innovative framework for quantifying pressing intensity,
leveraging advancements in positional tracking data and components from
Spearman's Pitch Control model. Our method integrates player velocities,
movement directions, and reaction times to compute the time required for a
defender to intercept an attacker or the ball. This time-to-intercept measure
is then transformed into probabilistic values using a logistic function,
enabling dynamic and intuitive analysis of pressing situations at the
individual frame level. the model captures how every player's movement
influences pressure on the field, offering actionable insights for coaches,
analysts, and decision-makers. By providing a robust and intepretable metric,
our approach facilitates the identification of pressing strategies, advanced
situational analyses, and the derivation of metrics, advancing the analytical
capabilities for modern football.",2024-12-30,Joris Bekkers,http://arxiv.org/pdf/2501.04712v1,cs.LG
Conservation-informed Graph Learning for Spatiotemporal Dynamics Prediction,"Data-centric methods have shown great potential in understanding and
predicting spatiotemporal dynamics, enabling better design and control of the
object system. However, deep learning models often lack interpretability, fail
to obey intrinsic physics, and struggle to cope with the various domains. While
geometry-based methods, e.g., graph neural networks (GNNs), have been proposed
to further tackle these challenges, they still need to find the implicit
physical laws from large datasets and rely excessively on rich labeled data. In
this paper, we herein introduce the conservation-informed GNN (CiGNN), an
end-to-end explainable learning framework, to learn spatiotemporal dynamics
based on limited training data. The network is designed to conform to the
general conservation law via symmetry, where conservative and non-conservative
information passes over a multiscale space enhanced by a latent temporal
marching strategy. The efficacy of our model has been verified in various
spatiotemporal systems based on synthetic and real-world datasets, showing
superiority over baseline models. Results demonstrate that CiGNN exhibits
remarkable accuracy and generalizability, and is readily applicable to learning
for prediction of various spatiotemporal dynamics in a spatial domain with
complex geometry.",2024-12-30,"Yuan Mi, Pu Ren, Hongteng Xu, Hongsheng Liu, Zidong Wang, Yike Guo, Ji-Rong Wen, Hao Sun, Yang Liu",http://arxiv.org/pdf/2412.20962v3,cs.LG
Generalizing in Net-Zero Microgrids: A Study with Federated PPO and TRPO,"This work addresses the challenge of optimal energy management in microgrids
through a collaborative and privacy-preserving framework. We propose the
FedTRPO methodology, which integrates Federated Learning (FL) and Trust Region
Policy Optimization (TRPO) to manage distributed energy resources (DERs)
efficiently. Using a customized version of the CityLearn environment and
synthetically generated data, we simulate designed net-zero energy scenarios
for microgrids composed of multiple buildings. Our approach emphasizes reducing
energy costs and carbon emissions while ensuring privacy. Experimental results
demonstrate that FedTRPO is comparable with state-of-the-art federated RL
methodologies without hyperparameter tunning. The proposed framework highlights
the feasibility of collaborative learning for achieving optimal control
policies in energy systems, advancing the goals of sustainable and efficient
smart grids.",2024-12-30,"Nicolas M Cuadrado Avila, Samuel Horváth, Martin Takáč",http://arxiv.org/pdf/2412.20946v1,cs.LG
Active Learning with Variational Quantum Circuits for Quantum Process Tomography,"Quantum process tomography (QPT), used for reconstruction of an unknown
quantum process from measurement data, is a fundamental tool for the diagnostic
and full characterization of quantum systems. It relies on querying a set of
quantum states as input to the quantum process. Previous works commonly use a
straightforward strategy to select a set of quantum states randomly,
overlooking differences in informativeness among quantum states. Since querying
the quantum system requires multiple experiments that can be prohibitively
costly, it is always the case that there are not enough quantum states for
high-quality reconstruction. In this paper, we propose a general framework for
active learning (AL) to adaptively select a set of informative quantum states
that improves the reconstruction most efficiently. In particular, we introduce
a learning framework that leverages the widely-used variational quantum
circuits (VQCs) to perform the QPT task and integrate our AL algorithms into
the query step. We design and evaluate three various types of AL algorithms:
committee-based, uncertainty-based, and diversity-based, each exhibiting
distinct advantages in terms of performance and computational cost.
Additionally, we provide a guideline for selecting algorithms suitable for
different scenarios. Numerical results demonstrate that our algorithms achieve
significantly improved reconstruction compared to the baseline method that
selects a set of quantum states randomly. Moreover, these results suggest that
active learning based approaches are applicable to other complicated learning
tasks in large-scale quantum information processing.",2024-12-30,"Jiaqi Yang, Xiaohua Xu, Wei Xie",http://arxiv.org/pdf/2412.20925v1,cs.LG
Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes,"Deep neural networks (DNNs) are often constructed under the closed-world
assumption, which may fail to generalize to the out-of-distribution (OOD) data.
This leads to DNNs producing overconfident wrong predictions and can result in
disastrous consequences in safety-critical applications. Existing OOD detection
methods mainly rely on curating a set of OOD data for model training or
hyper-parameter tuning to distinguish OOD data from training data (also known
as in-distribution data or InD data). However, OOD samples are not always
available during the training phase in real-world applications, hindering the
OOD detection accuracy. To overcome this limitation, we propose a
Gaussian-process-based OOD detection method to establish a decision boundary
based on InD data only. The basic idea is to perform uncertainty quantification
of the unconstrained softmax scores of a DNN via a multi-class Gaussian process
(GP), and then define a score function to separate InD and potential OOD data
based on their fundamental differences in the posterior predictive distribution
from the GP. Two case studies on conventional image classification datasets and
real-world image datasets are conducted to demonstrate that the proposed method
outperforms the state-of-the-art OOD detection methods when OOD samples are not
observed in the training phase.",2024-12-30,"Yang Chen, Chih-Li Sung, Arpan Kusari, Xiaoyang Song, Wenbo Sun",http://arxiv.org/pdf/2412.20918v1,cs.LG
"DDIM sampling for Generative AIBIM, a faster intelligent structural design framework","Generative AIBIM, a successful structural design pipeline, has proven its
ability to intelligently generate high-quality, diverse, and creative shear
wall designs that are tailored to specific physical conditions. However, the
current module of Generative AIBIM that generates designs, known as the
physics-based conditional diffusion model (PCDM), necessitates 1000 iterations
for each generation due to its reliance on the denoising diffusion
probabilistic model (DDPM) sampling process. This leads to a time-consuming and
computationally demanding generation process. To address this issue, this study
introduces the denoising diffusion implicit model (DDIM), an accelerated
generation method that replaces the DDPM sampling process in PCDM. While the
original DDIM was designed for DDPM and the optimization process of PCDM
differs from that of DDPM, this paper designs ""DDIM sampling for PCDM,"" which
modifies the original DDIM formulations to adapt to the optimization process of
PCDM. Experimental results demonstrate that DDIM sampling for PCDM can
accelerate the generation process of the original PCDM by a factor of 100 while
maintaining the same visual quality in the generated results. This study
effectively showcases the effectiveness of DDIM sampling for PCDM in expediting
intelligent structural design. Furthermore, this paper reorganizes the contents
of DDIM, focusing on the practical usage of DDIM. This change is particularly
meaningful for researchers who may not possess a strong background in machine
learning theory but are interested in utilizing the tool effectively.",2024-12-30,"Zhili He, Yu-Hsing Wang",http://arxiv.org/pdf/2412.20899v1,cs.LG
Human-like Bots for Tactical Shooters Using Compute-Efficient Sensors,"Artificial intelligence (AI) has enabled agents to master complex video
games, from first-person shooters like Counter-Strike to real-time strategy
games such as StarCraft II and racing games like Gran Turismo. While these
achievements are notable, applying these AI methods in commercial video game
production remains challenging due to computational constraints. In commercial
scenarios, the majority of computational resources are allocated to 3D
rendering, leaving limited capacity for AI methods, which often demand high
computational power, particularly those relying on pixel-based sensors.
Moreover, the gaming industry prioritizes creating human-like behavior in AI
agents to enhance player experience, unlike academic models that focus on
maximizing game performance. This paper introduces a novel methodology for
training neural networks via imitation learning to play a complex,
commercial-standard, VALORANT-like 2v2 tactical shooter game, requiring only
modest CPU hardware during inference. Our approach leverages an innovative,
pixel-free perception architecture using a small set of ray-cast sensors, which
capture essential spatial information efficiently. These sensors allow AI to
perform competently without the computational overhead of traditional methods.
Models are trained to mimic human behavior using supervised learning on human
trajectory data, resulting in realistic and engaging AI agents. Human
evaluation tests confirm that our AI agents provide human-like gameplay
experiences while operating efficiently under computational constraints. This
offers a significant advancement in AI model development for tactical shooter
games and possibly other genres.",2024-12-30,"Niels Justesen, Maria Kaselimi, Sam Snodgrass, Miruna Vozaru, Matthew Schlegel, Jonas Wingren, Gabriella A. B. Barros, Tobias Mahlmann, Shyam Sudhakaran, Wesley Kerr, Albert Wang, Christoffer Holmgård, Georgios N. Yannakakis, Sebastian Risi, Julian Togelius",http://arxiv.org/pdf/2501.00078v1,cs.LG
Towards Compatible Fine-tuning for Vision-Language Model Updates,"So far, efficient fine-tuning has become a popular strategy for enhancing the
capabilities of foundation models on downstream tasks by learning plug-and-play
modules. However, existing methods overlook a crucial issue: if the underlying
foundation model is updated, are these plug-and-play modules still effective?
In this paper, we first conduct a detailed analysis of various fine-tuning
methods on the CLIP in terms of their compatibility with model updates. The
study reveals that many high-performing fine-tuning methods fail to be
compatible with the upgraded models. To address this, we propose a novel
approach, Class-conditioned Context Optimization (ContCoOp), which integrates
learnable prompts with class embeddings using an attention layer before
inputting them into the text encoder. Consequently, the prompts can dynamically
adapt to the changes in embedding space (due to model updates), ensuring
continued effectiveness. Extensive experiments over 15 datasets show that our
ContCoOp achieves the highest compatibility over the baseline methods, and
exhibits robust out-of-distribution generalization.",2024-12-30,"Zhengbo Wang, Jian Liang, Lijun Sheng, Ran He, Zilei Wang, Tieniu Tan",http://arxiv.org/pdf/2412.20895v1,cs.LG
Rethinking Aleatoric and Epistemic Uncertainty,"The ideas of aleatoric and epistemic uncertainty are widely used to reason
about the probabilistic predictions of machine-learning models. We identify
incoherence in existing discussions of these ideas and suggest this stems from
the aleatoric-epistemic view being insufficiently expressive to capture all of
the distinct quantities that researchers are interested in. To explain and
address this we derive a simple delineation of different model-based
uncertainties and the data-generating processes associated with training and
evaluation. Using this in place of the aleatoric-epistemic view could produce
clearer discourse as the field moves forward.",2024-12-30,"Freddie Bickford Smith, Jannik Kossen, Eleanor Trollope, Mark van der Wilk, Adam Foster, Tom Rainforth",http://arxiv.org/pdf/2412.20892v1,cs.LG
DoTA: Weight-Decomposed Tensor Adaptation for Large Language Models,"Low-rank adaptation (LoRA) reduces the computational and memory demands of
fine-tuning large language models (LLMs) by approximating updates with low-rank
matrices. However, low-rank approximation in two-dimensional space fails to
capture high-dimensional structures within the target matrix. Recently, tensor
decomposition methods have been explored for fine-tuning LLMs, leveraging their
ability to extract structured information. Yet, these approaches primarily rely
on random initialization, and the impact of initialization on tensor adaptation
remains underexplored. In this paper, we reveal that random initialization
significantly diverges from the validation loss achieved by full fine-tuning.
To address this, we propose Weight-Decomposed Tensor Adaptation (DoTA), which
leverages the Matrix Product Operator (MPO) decomposition of pre-trained
weights for effective initialization in fine-tuning LLMs. Additionally, we
introduce QDoTA, a quantized version of DoTA designed for 4-bit quantization.
Experiments on commonsense and arithmetic reasoning tasks show that DoTA
outperforms random initialization methods with fewer parameters. QDoTA further
reduces memory consumption and achieves comparable performance to DoTA on
commonsense reasoning tasks. We will release our code to support future
research.",2024-12-30,"Xiaolin Hu, Xiang Cheng, Peiyu Liu, Wei Liu, Jian Luan, Bin Wang, Yong Liu",http://arxiv.org/pdf/2412.20891v1,cs.LG
CF-CGN: Channel Fingerprints Extrapolation for Multi-band Massive MIMO Transmission based on Cycle-Consistent Generative Networks,"Multi-band massive multiple-input multiple-output (MIMO) communication can
promote the cooperation of licensed and unlicensed spectra, effectively
enhancing spectrum efficiency for Wi-Fi and other wireless systems. As an
enabler for multi-band transmission, channel fingerprints (CF), also known as
the channel knowledge map or radio environment map, are used to assist channel
state information (CSI) acquisition and reduce computational complexity. In
this paper, we propose CF-CGN (Channel Fingerprints with Cycle-consistent
Generative Networks) to extrapolate CF for multi-band massive MIMO transmission
where licensed and unlicensed spectra cooperate to provide ubiquitous
connectivity. Specifically, we first model CF as a multichannel image and
transform the extrapolation problem into an image translation task, which
converts CF from one frequency to another by exploring the shared
characteristics of statistical CSI in the beam domain. Then, paired generative
networks are designed and coupled by variable-weight cycle consistency losses
to fit the reciprocal relationship at different bands. Matched with the coupled
networks, a joint training strategy is developed accordingly, supporting
synchronous optimization of all trainable parameters. During the inference
process, we also introduce a refining scheme to improve the extrapolation
accuracy based on the resolution of CF. Numerical results illustrate that our
proposed CF-CGN can achieve bidirectional extrapolation with an error of 5-17
dB lower than the benchmarks in different communication scenarios,
demonstrating its excellent generalization ability. We further show that the
sum rate performance assisted by CF-CGN-based CF is close to that with perfect
CSI for multi-band massive MIMO transmission.",2024-12-30,"Chenjie Xie, Li You, Zhenzhou Jin, Jinke Tang, Xiqi Gao, Xiang-Gen Xia",http://arxiv.org/pdf/2412.20885v1,cs.LG
Machine Learning of Slow Collective Variables and Enhanced Sampling via Spatial Techniques,"Understanding the long-time dynamics of complex physical processes depends on
our ability to recognize patterns. To simplify the description of these
processes, we often introduce a set of reaction coordinates, customarily
referred to as collective variables (CVs). The quality of these CVs heavily
impacts our comprehension of the dynamics, often influencing the estimates of
thermodynamics and kinetics from atomistic simulations. Consequently,
identifying CVs poses a fundamental challenge in chemical physics. Recently,
significant progress was made by leveraging the predictive ability of
unsupervised machine learning techniques to determine CVs. Many of these
techniques require temporal information to learn slow CVs that correspond to
the long timescale behavior of the studied process. Here, however, we
specifically focus on techniques that can identify CVs corresponding to the
slowest transitions between states without needing temporal trajectories as
input, instead using the spatial characteristics of the data. We discuss the
latest developments in this category of techniques and briefly discuss
potential directions for thermodynamics-informed spatial learning of slow CVs.",2024-12-30,"Tuğçe Gökdemir, Jakub Rydzewski",http://arxiv.org/pdf/2412.20868v1,cs.LG
Enhancing Annotated Bibliography Generation with LLM Ensembles,"This work proposes a novel approach to enhancing annotated bibliography
generation through Large Language Model (LLM) ensembles. In particular,
multiple LLMs in different roles -- controllable text generation, evaluation,
and summarization -- are introduced and validated using a systematic
methodology to enhance model performance in scholarly tasks. Output diversity
among the ensemble that generates text is obtained using different LLM
parameters, followed by an LLM acting as a judge to assess relevance, accuracy,
and coherence. Responses selected by several combining strategies are then
merged and refined through summarization and redundancy removal techniques. The
preliminary experimental validation demonstrates that the combined outputs from
the LLM ensemble improve coherence and relevance compared to individual
responses, leading to a 38% improvement in annotation quality and a 51%
reduction in content redundancy, thus highlighting the potential for automating
complex scholarly tasks while maintaining high-quality standards.",2024-12-30,Sergio Bermejo,http://arxiv.org/pdf/2412.20864v1,cs.LG
Hgformer: Hyperbolic Graph Transformer for Recommendation,"The cold start problem is a challenging problem faced by most modern
recommender systems. By leveraging knowledge from other domains, cross-domain
recommendation can be an effective method to alleviate the cold start problem.
However, the modelling distortion for long-tail data, which is widely present
in recommender systems, is often overlooked in cross-domain recommendation. In
this research, we propose a hyperbolic manifold based cross-domain
collaborative filtering model using BiTGCF as the base model. We introduce the
hyperbolic manifold and construct new propagation layer and transfer layer to
address these challenges. The significant performance improvements across
various datasets compared to the baseline models demonstrate the effectiveness
of our proposed model.",2024-12-30,"Xin Yang, Xingrun Li, Heng Chang, Jinze Yang, Xihong Yang, Shengyu Tao, Ningkang Chang, Maiko Shigeno, Junfeng Wang, Dawei Yin, Erxue Min",http://arxiv.org/pdf/2502.15693v1,cs.LG
About rectified sigmoid function for enhancing the accuracy of Physics-Informed Neural Networks,"The article is devoted to the study of neural networks with one hidden layer
and a modified activation function for solving physical problems. A rectified
sigmoid activation function has been proposed to solve physical problems
described by the ODE with neural networks. Algorithms for physics-informed
data-driven initialization of a neural network and a neuron-by-neuron
gradient-free fitting method have been presented for the neural network with
this activation function. Numerical experiments demonstrate the superiority of
neural networks with a rectified sigmoid function over neural networks with a
sigmoid function in the accuracy of solving physical problems (harmonic
oscillator, relativistic slingshot, and Lorentz system).",2024-12-30,"Vasiliy A. Es'kin, Alexey O. Malkhanov, Mikhail E. Smorkalov",http://arxiv.org/pdf/2412.20851v1,cs.LG
Acquisition-Independent Deep Learning for Quantitative MRI Parameter Estimation using Neural Controlled Differential Equations,"Deep learning has proven to be a suitable alternative to least-squares (LSQ)
fitting for parameter estimation in various quantitative MRI (QMRI) models.
However, current deep learning implementations are not robust to changes in MR
acquisition protocols. In practice, QMRI acquisition protocols differ
substantially between different studies and clinical settings. The lack of
generalizability and adoptability of current deep learning approaches for QMRI
parameter estimation impedes the implementation of these algorithms in clinical
trials and clinical practice. Neural Controlled Differential Equations (NCDEs)
allow for the sampling of incomplete and irregularly sampled data with variable
length, making them ideal for use in QMRI parameter estimation. In this study,
we show that NCDEs can function as a generic tool for the accurate prediction
of QMRI parameters, regardless of QMRI sequence length, configuration of
independent variables and QMRI forward model (variable flip angle T1-mapping,
intravoxel incoherent motion MRI, dynamic contrast-enhanced MRI). NCDEs
achieved lower mean squared error than LSQ fitting in low-SNR simulations and
in vivo in challenging anatomical regions like the abdomen and leg, but this
improvement was no longer evident at high SNR. NCDEs reduce estimation error
interquartile range without increasing bias, particularly under conditions of
high uncertainty. These findings suggest that NCDEs offer a robust approach for
reliable QMRI parameter estimation, especially in scenarios with high
uncertainty or low image quality. We believe that with NCDEs, we have solved
one of the main challenges for using deep learning for QMRI parameter
estimation in a broader clinical and research setting.",2024-12-30,"Daan Kuppens, Sebastiano Barbieri, Daisy van den Berg, Pepijn Schouten, Harriet C. Thoeny, Myrte Wennen, Oliver J. Gurney-Champion",http://arxiv.org/pdf/2412.20844v1,cs.LG
Dual-Space Augmented Intrinsic-LoRA for Wind Turbine Segmentation,"Accurate segmentation of wind turbine blade (WTB) images is critical for
effective assessments, as it directly influences the performance of automated
damage detection systems. Despite advancements in large universal vision
models, these models often underperform in domain-specific tasks like WTB
segmentation. To address this, we extend Intrinsic LoRA for image segmentation,
and propose a novel dual-space augmentation strategy that integrates both
image-level and latent-space augmentations. The image-space augmentation is
achieved through linear interpolation between image pairs, while the
latent-space augmentation is accomplished by introducing a noise-based latent
probabilistic model. Our approach significantly boosts segmentation accuracy,
surpassing current state-of-the-art methods in WTB image segmentation.",2024-12-30,"Shubh Singhal, Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo",http://arxiv.org/pdf/2412.20838v1,cs.LG
Isoperimetry is All We Need: Langevin Posterior Sampling for RL with Sublinear Regret,"Common assumptions, like linear or RKHS models, and Gaussian or log-concave
posteriors over the models, do not explain practical success of RL across a
wider range of distributions and models. Thus, we study how to design RL
algorithms with sublinear regret for isoperimetric distributions, specifically
the ones satisfying the Log-Sobolev Inequality (LSI). LSI distributions include
the standard setups of RL theory, and others, such as many non-log-concave and
perturbed distributions. First, we show that the Posterior Sampling-based RL
(PSRL) algorithm yields sublinear regret if the data distributions satisfy LSI
and some mild additional assumptions. Also, when we cannot compute or sample
from an exact posterior, we propose a Langevin sampling-based algorithm design:
LaPSRL. We show that LaPSRL achieves order-optimal regret and subquadratic
complexity per episode. Finally, we deploy LaPSRL with a Langevin sampler --
SARAH-LD, and test it for different bandit and MDP environments. Experimental
results validate the generality of LaPSRL across environments and its
competitive performance with respect to the baselines.",2024-12-30,"Emilio Jorge, Christos Dimitrakakis, Debabrota Basu",http://arxiv.org/pdf/2412.20824v2,cs.LG
TimeRAF: Retrieval-Augmented Foundation model for Zero-shot Time Series Forecasting,"Time series forecasting plays a crucial role in data mining, driving rapid
advancements across numerous industries. With the emergence of large models,
time series foundation models (TSFMs) have exhibited remarkable generalization
capabilities, such as zero-shot learning, through large-scale pre-training.
Meanwhile, Retrieval-Augmented Generation (RAG) methods have been widely
employed to enhance the performance of foundation models on unseen data,
allowing models to access to external knowledge. In this paper, we introduce
TimeRAF, a Retrieval-Augmented Forecasting model that enhance zero-shot time
series forecasting through retrieval-augmented techniques. We develop
customized time series knowledge bases that are tailored to the specific
forecasting tasks. TimeRAF employs an end-to-end learnable retriever to extract
valuable information from the knowledge base. Additionally, we propose Channel
Prompting for knowledge integration, which effectively extracts relevant
information from the retrieved knowledge along the channel dimension. Extensive
experiments demonstrate the effectiveness of our model, showing significant
improvement across various domains and datasets.",2024-12-30,"Huanyu Zhang, Chang Xu, Yi-Fan Zhang, Zhang Zhang, Liang Wang, Jiang Bian, Tieniu Tan",http://arxiv.org/pdf/2412.20810v1,cs.LG
Robust Matrix Completion for Discrete Rating-Scale Data,"Matrix completion has gained considerable interest in recent years. The goal
of matrix completion is to predict the unknown entries of a partially observed
matrix using its known entries. Although common applications feature discrete
rating-scale data, such as user-product rating matrices in recommender systems
or surveys in the social and behavioral sciences, methods for matrix completion
are almost always designed for and studied in the context of continuous data.
Furthermore, only a small subset of the literature considers matrix completion
in the presence of corrupted observations despite their common occurrence in
practice. Examples include attacks on recommender systems (i.e., malicious
users deliberately manipulating ratings to influence the recommender system to
their advantage), or careless respondents in surveys (i.e., respondents
providing answers irrespective of what the survey asks of them due to a lack of
attention). We introduce a matrix completion algorithm that is tailored towards
the discrete nature of rating-scale data and robust to the presence of
corrupted observations. In addition, we investigate the performance of the
proposed method and its competitors with discrete rating-scale (rather than
continuous) data as well as under various missing data mechanisms and types of
corrupted observations.",2024-12-30,"Aurore Archimbaud, Andreas Alfons, Ines Wilms",http://arxiv.org/pdf/2412.20802v1,cs.LG
FastCHGNet: Training one Universal Interatomic Potential to 1.5 Hours with 32 GPUs,"Graph neural network universal interatomic potentials (GNN-UIPs) have
demonstrated remarkable generalization and transfer capabilities in material
discovery and property prediction. These models can accelerate molecular
dynamics (MD) simulation by several orders of magnitude while maintaining
\textit{ab initio} accuracy, making them a promising new paradigm in material
simulations. One notable example is Crystal Hamiltonian Graph Neural Network
(CHGNet), pretrained on the energies, forces, stresses, and magnetic moments
from the MPtrj dataset, representing a state-of-the-art GNN-UIP model for
charge-informed MD simulations. However, training the CHGNet model is
time-consuming(8.3 days on one A100 GPU) for three reasons: (i) requiring
multi-layer propagation to reach more distant atom information, (ii) requiring
second-order derivatives calculation to finish weights updating and (iii) the
implementation of reference CHGNet does not fully leverage the computational
capabilities. This paper introduces FastCHGNet, an optimized CHGNet, with three
contributions: Firstly, we design innovative Force/Stress Readout modules to
decompose Force/Stress prediction. Secondly, we adopt massive optimizations
such as kernel fusion, redundancy bypass, etc, to exploit GPU computation power
sufficiently. Finally, we extend CHGNet to support multiple GPUs and propose a
load-balancing technique to enhance GPU utilization. Numerical results show
that FastCHGNet reduces memory footprint by a factor of 3.59. The final
training time of FastCHGNet can be decreased to \textbf{1.53 hours} on 32 GPUs
without sacrificing model accuracy.",2024-12-30,"Yuanchang Zhou, Siyu Hu, Chen Wang, Lin-Wang Wang, Guangming Tan, Weile Jia",http://arxiv.org/pdf/2412.20796v2,cs.LG
Frequency-Masked Embedding Inference: A Non-Contrastive Approach for Time Series Representation Learning,"Contrastive learning underpins most current self-supervised time series
representation methods. The strategy for constructing positive and negative
sample pairs significantly affects the final representation quality. However,
due to the continuous nature of time series semantics, the modeling approach of
contrastive learning struggles to accommodate the characteristics of time
series data. This results in issues such as difficulties in constructing hard
negative samples and the potential introduction of inappropriate biases during
positive sample construction. Although some recent works have developed several
scientific strategies for constructing positive and negative sample pairs with
improved effectiveness, they remain constrained by the contrastive learning
framework. To fundamentally overcome the limitations of contrastive learning,
this paper introduces Frequency-masked Embedding Inference (FEI), a novel
non-contrastive method that completely eliminates the need for positive and
negative samples. The proposed FEI constructs 2 inference branches based on a
prompting strategy: 1) Using frequency masking as prompts to infer the
embedding representation of the target series with missing frequency bands in
the embedding space, and 2) Using the target series as prompts to infer its
frequency masking embedding. In this way, FEI enables continuous semantic
relationship modeling for time series. Experiments on 8 widely used time series
datasets for classification and regression tasks, using linear evaluation and
end-to-end fine-tuning, show that FEI significantly outperforms existing
contrastive-based methods in terms of generalization. This study provides new
insights into self-supervised representation learning for time series. The code
is available at
https://github.com/USTBInnovationPark/Frequency-masked-Embedding-Inference.",2024-12-30,"En Fu, Yanyan Hu",http://arxiv.org/pdf/2412.20790v2,cs.LG
Accelerating Energy-Efficient Federated Learning in Cell-Free Networks with Adaptive Quantization,"Federated Learning (FL) enables clients to share learning parameters instead
of local data, reducing communication overhead. Traditional wireless networks
face latency challenges with FL. In contrast, Cell-Free Massive MIMO (CFmMIMO)
can serve multiple clients on shared resources, boosting spectral efficiency
and reducing latency for large-scale FL. However, clients' communication
resource limitations can hinder the completion of the FL training. To address
this challenge, we propose an energy-efficient, low-latency FL framework
featuring optimized uplink power allocation for seamless client-server
collaboration. Our framework employs an adaptive quantization scheme,
dynamically adjusting bit allocation for local gradient updates to reduce
communication costs. We formulate a joint optimization problem covering FL
model updates, local iterations, and power allocation, solved using sequential
quadratic programming (SQP) to balance energy and latency. Additionally,
clients use the AdaDelta method for local FL model updates, enhancing local
model convergence compared to standard SGD, and we provide a comprehensive
analysis of FL convergence with AdaDelta local updates. Numerical results show
that, within the same energy and latency budgets, our power allocation scheme
outperforms the Dinkelbach and max-sum rate methods by increasing the test
accuracy up to $7$\% and $19$\%, respectively. Moreover, for the three power
allocation methods, our proposed quantization scheme outperforms AQUILA and LAQ
by increasing test accuracy by up to $36$\% and $35$\%, respectively.",2024-12-30,"Afsaneh Mahmoudi, Ming Xiao, Emil Björnson",http://arxiv.org/pdf/2412.20785v1,cs.LG
A Novel Framework for Learning Stochastic Representations for Sequence Generation and Recognition,"The ability to generate and recognize sequential data is fundamental for
autonomous systems operating in dynamic environments. Inspired by the key
principles of the brain-predictive coding and the Bayesian brain-we propose a
novel stochastic Recurrent Neural Network with Parametric Biases (RNNPB). The
proposed model incorporates stochasticity into the latent space using the
reparameterization trick used in variational autoencoders. This approach
enables the model to learn probabilistic representations of multidimensional
sequences, capturing uncertainty and enhancing robustness against overfitting.
We tested the proposed model on a robotic motion dataset to assess its
performance in generating and recognizing temporal patterns. The experimental
results showed that the stochastic RNNPB model outperformed its deterministic
counterpart in generating and recognizing motion sequences. The results
highlighted the proposed model's capability to quantify and adjust uncertainty
during both learning and inference. The stochasticity resulted in a continuous
latent space representation, facilitating stable motion generation and enhanced
generalization when recognizing novel sequences. Our approach provides a
biologically inspired framework for modeling temporal patterns and advances the
development of robust and adaptable systems in artificial intelligence and
robotics.",2024-12-30,"Jungsik Hwang, Ahmadreza Ahmadi",http://arxiv.org/pdf/2501.00076v1,cs.LG
Enhancing Privacy in Federated Learning through Quantum Teleportation Integration,"Federated learning enables collaborative model training across multiple
clients without sharing raw data, thereby enhancing privacy. However, the
exchange of model updates can still expose sensitive information. Quantum
teleportation, a process that transfers quantum states between distant
locations without physical transmission of the particles themselves, has
recently been implemented in real-world networks. This position paper explores
the potential of integrating quantum teleportation into federated learning
frameworks to bolster privacy. By leveraging quantum entanglement and the
no-cloning theorem, quantum teleportation ensures that data remains secure
during transmission, as any eavesdropping attempt would be detectable. We
propose a novel architecture where quantum teleportation facilitates the secure
exchange of model parameters and gradients among clients and servers. This
integration aims to mitigate risks associated with data leakage and adversarial
attacks inherent in classical federated learning setups. We also discuss the
practical challenges of implementing such a system, including the current
limitations of quantum network infrastructure and the need for hybrid
quantum-classical protocols. Our analysis suggests that, despite these
challenges, the convergence of quantum communication technologies and federated
learning presents a promising avenue for achieving unprecedented levels of
privacy in distributed machine learning.",2024-12-30,Koffka Khan,http://arxiv.org/pdf/2412.20762v1,cs.LG
Solar Filaments Detection using Active Contours Without Edges,"In this article, an active contours without edges (ACWE)-based algorithm has
been proposed for the detection of solar filaments in H-alpha full-disk solar
images. The overall algorithm consists of three main steps of image processing.
These are image pre-processing, image segmentation, and image post-processing.
Here in the work, contours are initialized on the solar image and allowed to
deform based on the energy function. As soon as the contour reaches the
boundary of the desired object, the energy function gets reduced, and the
contour stops evolving. The proposed algorithm has been applied to few
benchmark datasets and has been compared with the classical technique of object
detection. The results analysis indicates that the proposed algorithm
outperforms the results obtained using the existing classical algorithm of
object detection.",2024-12-30,"Sanmoy Bandyopadhyay, Vaibhav Pant",http://arxiv.org/pdf/2412.20749v1,cs.LG
Advancing Parkinson's Disease Progression Prediction: Comparing Long Short-Term Memory Networks and Kolmogorov-Arnold Networks,"Parkinson's Disease (PD) is a degenerative neurological disorder that impairs
motor and non-motor functions, significantly reducing quality of life and
increasing mortality risk. Early and accurate detection of PD progression is
vital for effective management and improved patient outcomes. Current
diagnostic methods, however, are often costly, time-consuming, and require
specialized equipment and expertise. This work proposes an innovative approach
to predicting PD progression using regression methods, Long Short-Term Memory
(LSTM) networks, and Kolmogorov Arnold Networks (KAN). KAN, utilizing
spline-parametrized univariate functions, allows for dynamic learning of
activation patterns, unlike traditional linear models.
  The Movement Disorder Society-Sponsored Revision of the Unified Parkinson's
Disease Rating Scale (MDS-UPDRS) is a comprehensive tool for evaluating PD
symptoms and is commonly used to measure disease progression. Additionally,
protein or peptide abnormalities are linked to PD onset and progression.
Identifying these associations can aid in predicting disease progression and
understanding molecular changes.
  Comparing multiple models, including LSTM and KAN, this study aims to
identify the method that delivers the highest metrics. The analysis reveals
that KAN, with its dynamic learning capabilities, outperforms other approaches
in predicting PD progression. This research highlights the potential of AI and
machine learning in healthcare, paving the way for advanced computational
models to enhance clinical predictions and improve patient care and treatment
strategies in PD management.",2024-12-30,"Abhinav Roy, Bhavesh Gyanchandani, Aditya Oza, Abhishek Sharma",http://arxiv.org/pdf/2412.20744v1,cs.LG
Joint Scoring Rules: Zero-Sum Competition Avoids Performative Prediction,"In a decision-making scenario, a principal could use conditional predictions
from an expert agent to inform their choice. However, this approach would
introduce a fundamental conflict of interest. An agent optimizing for
predictive accuracy is incentivized to manipulate their principal towards more
predictable actions, which prevents that principal from being able to
deterministically select their true preference. We demonstrate that this
impossibility result can be overcome through the joint evaluation of multiple
agents. When agents are made to engage in zero-sum competition, their incentive
to influence the action taken is eliminated, and the principal can identify and
take the action they most prefer. We further prove that this zero-sum setup is
unique, efficiently implementable, and applicable under stochastic choice.
Experiments in a toy environment demonstrate that training on a zero-sum
objective significantly enhances both predictive accuracy and principal
utility, and can eliminate previously learned manipulative behavior.",2024-12-30,Rubi Hudson,http://arxiv.org/pdf/2412.20732v1,cs.LG
AverageTime: Enhance Long-Term Time Series Forecasting with Simple Averaging,"Long-term time series forecasting focuses on leveraging historical data to
predict future trends. The core challenge lies in effectively modeling
dependencies both within sequences and channels. Convolutional Neural Networks
and Linear models often excel in sequence modeling but frequently fall short in
capturing complex channel dependencies. In contrast, Transformer-based models,
with their attention mechanisms applied to both sequences and channels, have
demonstrated strong predictive performance. Our research proposes a new
approach for capturing sequence and channel dependencies: AverageTime, an
exceptionally simple yet effective structure. By employing mixed channel
embedding and averaging operations, AverageTime separately captures
correlations for sequences and channels through channel mapping and result
averaging. In addition, we integrate clustering methods to further accelerate
the model's training process. Experiments on real-world datasets demonstrate
that AverageTime surpasses state-of-the-art models in predictive performance
while maintaining efficiency comparable to lightweight linear models. This
provides a new and effective framework for modeling long time series.",2024-12-30,"Gaoxiang Zhao, Li Zhou, Xiaoqiang Wang",http://arxiv.org/pdf/2412.20727v3,cs.LG
Training Deep Neural Classifiers with Soft Diamond Regularizers,"We introduce new \emph{soft diamond} regularizers that both improve synaptic
sparsity and maintain classification accuracy in deep neural networks. These
parametrized regularizers outperform the state-of-the-art hard-diamond
Laplacian regularizer of Lasso regression and classification. They use
thick-tailed symmetric alpha-stable ($\mathcal{S \alpha S}$) bell-curve
synaptic weight priors that are not Gaussian and so have thicker tails. The
geometry of the diamond-shaped constraint set varies from a circle to a star
depending on the tail thickness and dispersion of the prior probability density
function. Training directly with these priors is computationally intensive
because almost all $\mathcal{S \alpha S}$ probability densities lack a closed
form. A precomputed look-up table removed this computational bottleneck. We
tested the new soft diamond regularizers with deep neural classifiers on the
three datasets CIFAR-10, CIFAR-100, and Caltech-256. The regularizers improved
the accuracy of the classifiers. The improvements included $4.57\%$ on
CIFAR-10, $4.27\%$ on CIFAR-100, and $6.69\%$ on Caltech-256. They also
outperformed $L_2$ regularizers on all the test cases. Soft diamond
regularizers also outperformed $L_1$ lasso or Laplace regularizers because they
better increased sparsity while improving classification accuracy. Soft-diamond
priors substantially improved accuracy on CIFAR-10 when combined with dropout,
batch, or data-augmentation regularization.",2024-12-30,"Olaoluwa Adigun, Bart Kosko",http://arxiv.org/pdf/2412.20724v1,cs.LG
HFI: A unified framework for training-free detection and implicit watermarking of latent diffusion model generated images,"Dramatic advances in the quality of the latent diffusion models (LDMs) also
led to the malicious use of AI-generated images. While current AI-generated
image detection methods assume the availability of real/AI-generated images for
training, this is practically limited given the vast expressibility of LDMs.
This motivates the training-free detection setup where no related data are
available in advance. The existing LDM-generated image detection method assumes
that images generated by LDM are easier to reconstruct using an autoencoder
than real images. However, we observe that this reconstruction distance is
overfitted to background information, leading the current method to
underperform in detecting images with simple backgrounds. To address this, we
propose a novel method called HFI. Specifically, by viewing the autoencoder of
LDM as a downsampling-upsampling kernel, HFI measures the extent of aliasing, a
distortion of high-frequency information that appears in the reconstructed
image. HFI is training-free, efficient, and consistently outperforms other
training-free methods in detecting challenging images generated by various
generative models. We also show that HFI can successfully detect the images
generated from the specified LDM as a means of implicit watermarking. HFI
outperforms the best baseline method while achieving magnitudes of",2024-12-30,"Sungik Choi, Sungwoo Park, Jaehoon Lee, Seunghyun Kim, Stanley Jungkyu Choi, Moontae Lee",http://arxiv.org/pdf/2412.20704v1,cs.LG
Position Information Emerges in Causal Transformers Without Positional Encodings via Similarity of Nearby Embeddings,"Transformers with causal attention can solve tasks that require positional
information without using positional encodings. In this work, we propose and
investigate a new hypothesis about how positional information can be stored
without using explicit positional encoding. We observe that nearby embeddings
are more similar to each other than faraway embeddings, allowing the
transformer to potentially reconstruct the positions of tokens. We show that
this pattern can occur in both the trained and the randomly initialized
Transformer models with causal attention and no positional encodings over a
common range of hyperparameters.",2024-12-30,"Chunsheng Zuo, Pavel Guerzhoy, Michael Guerzhoy",http://arxiv.org/pdf/2501.00073v1,cs.LG
Learning to Rank Pre-trained Vision-Language Models for Downstream Tasks,"Vision language models (VLMs) like CLIP show stellar zero-shot capability on
classification benchmarks. However, selecting the VLM with the highest
performance on the unlabeled downstream task is non-trivial. Existing VLM
selection methods focus on the class-name-only setting, relying on a supervised
large-scale dataset and large language models, which may not be accessible or
feasible during deployment. This paper introduces the problem of
\textbf{unsupervised vision-language model selection}, where only unsupervised
downstream datasets are available, with no additional information provided. To
solve this problem, we propose a method termed Visual-tExtual Graph Alignment
(VEGA), to select VLMs without any annotations by measuring the alignment of
the VLM between the two modalities on the downstream task. VEGA is motivated by
the pretraining paradigm of VLMs, which aligns features with the same semantics
from the visual and textual modalities, thereby mapping both modalities into a
shared representation space. Specifically, we first construct two graphs on the
vision and textual features, respectively. VEGA is then defined as the overall
similarity between the visual and textual graphs at both node and edge levels.
Extensive experiments across three different benchmarks, covering a variety of
application scenarios and downstream datasets, demonstrate that VEGA
consistently provides reliable and accurate estimates of VLMs' performance on
unlabeled downstream tasks.",2024-12-30,"Yuhe Ding, Bo Jiang, Aihua Zheng, Qin Xu, Jian Liang",http://arxiv.org/pdf/2412.20682v1,cs.LG
Differentiable Convex Optimization Layers in Neural Architectures: Foundations and Perspectives,"The integration of optimization problems within neural network architectures
represents a fundamental shift from traditional approaches to handling
constraints in deep learning. While it is long known that neural networks can
incorporate soft constraints with techniques such as regularization, strict
adherence to hard constraints is generally more difficult. A recent advance in
this field, however, has addressed this problem by enabling the direct
embedding of optimization layers as differentiable components within deep
networks. This paper surveys the evolution and current state of this approach,
from early implementations limited to quadratic programming, to more recent
frameworks supporting general convex optimization problems. We provide a
comprehensive review of the background, theoretical foundations, and emerging
applications of this technology. Our analysis includes detailed mathematical
proofs and an examination of various use cases that demonstrate the potential
of this hybrid approach. This work synthesizes developments at the intersection
of optimization theory and deep learning, offering insights into both current
capabilities and future research directions in this rapidly evolving field.",2024-12-30,Calder Katyal,http://arxiv.org/pdf/2412.20679v1,cs.LG
Attention-Driven Metapath Encoding in Heterogeneous Graphs,"One of the emerging techniques in node classification in heterogeneous graphs
is to restrict message aggregation to pre-defined, semantically meaningful
structures called metapaths. This work is the first attempt to incorporate
attention into the process of encoding entire metapaths without dropping
intermediate nodes. In particular, we construct two encoders: the first uses
sequential attention to extend the multi-hop message passing algorithm designed
in \citet{magna} to the metapath setting, and the second incorporates direct
attention to extract semantic relations in the metapath. The model then employs
the intra-metapath and inter-metapath aggregation mechanisms of \citet{han}. We
furthermore use the powerful training scheduler specialized for heterogeneous
graphs that was developed in \citet{lts}, ensuring the model slowly learns how
to classify the most difficult nodes. The result is a resilient,
general-purpose framework for capturing semantic structures in heterogeneous
graphs. In particular, we demonstrate that our model is competitive with
state-of-the-art models on performing node classification on the IMDB dataset,
a popular benchmark introduced in \citet{benchmark}.",2024-12-30,Calder Katyal,http://arxiv.org/pdf/2412.20678v1,cs.LG
Blockchain-Empowered Cyber-Secure Federated Learning for Trustworthy Edge Computing,"Federated Learning (FL) is a privacy-preserving distributed machine learning
scheme, where each participant data remains on the participating devices and
only the local model generated utilizing the local computational power is
transmitted throughout the database. However, the distributed computational
nature of FL creates the necessity to develop a mechanism that can remotely
trigger any network agents, track their activities, and prevent threats to the
overall process posed by malicious participants. Particularly, the FL paradigm
may become vulnerable due to an active attack from the network participants,
called a poisonous attack. In such an attack, the malicious participant acts as
a benign agent capable of affecting the global model quality by uploading an
obfuscated poisoned local model update to the server. This paper presents a
cross-device FL model that ensures trustworthiness, fairness, and authenticity
in the underlying FL training process. We leverage trustworthiness by
constructing a reputation-based trust model based on contributions of agents
toward model convergence. We ensure fairness by identifying and removing
malicious agents from the training process through an outlier detection
technique. Further, we establish authenticity by generating a token for each
participating device through a distributed sensing mechanism and storing that
unique token in a blockchain smart contract. Further, we insert the trust
scores of all agents into a blockchain and validate their reputations using
various consensus mechanisms that consider the computational task.",2024-12-30,"Ervin Moore, Ahmed Imteaj, Md Zarif Hossain, Shabnam Rezapour, M. Hadi Amini",http://arxiv.org/pdf/2412.20674v1,cs.LG
Two Birds with One Stone: Improving Rumor Detection by Addressing the Unfairness Issue,"The degraded performance and group unfairness caused by confounding sensitive
attributes in rumor detection remains relatively unexplored. To address this,
we propose a two-step framework. Initially, it identifies confounding sensitive
attributes that limit rumor detection performance and cause unfairness across
groups. Subsequently, we aim to learn equally informative representations
through invariant learning. Our method considers diverse sets of groups without
sensitive attribute annotations. Experiments show our method easily integrates
with existing rumor detectors, significantly improving both their detection
performance and fairness.",2024-12-30,"Junyi Chen, Mengjia Wu, Qian Liu, Ying Ding, Yi Zhang",http://arxiv.org/pdf/2412.20671v1,cs.LG
Analyzing Country-Level Vaccination Rates and Determinants of Practical Capacity to Administer COVID-19 Vaccines,"The COVID-19 vaccine development, manufacturing, transportation, and
administration proved an extreme logistics operation of global magnitude.
Global vaccination levels, however, remain a key concern in preventing the
emergence of new strains and minimizing the impact of the pandemic's disruption
of daily life. In this paper, country-level vaccination rates are analyzed
through a queuing framework to extract service rates that represent the
practical capacity of a country to administer vaccines. These rates are further
characterized through regression and interpretable machine learning methods
with country-level demographic, governmental, and socio-economic variates.
Model results show that participation in multi-governmental collaborations such
as COVAX may improve the ability to vaccinate. Similarly, improved
transportation and accessibility variates such as roads per area for low-income
countries and rail lines per area for high-income countries can improve rates.
It was also found that for low-income countries specifically, improvements in
basic and health infrastructure (as measured through spending on healthcare,
number of doctors and hospital beds per 100k, population percent with access to
electricity, life expectancy, and vehicles per 1000 people) resulted in higher
vaccination rates. Of the high-income countries, those with larger 65-plus
populations struggled to vaccinate at high rates, indicating potential
accessibility issues for the elderly. This study finds that improving basic and
health infrastructure, focusing on accessibility in the last mile, particularly
for the elderly, and fostering global partnerships can improve logistical
operations of such a scale. Such structural impediments and inequities in
global health care must be addressed in preparation for future global public
health crises.",2024-12-30,"Sharika J. Hegde, Max T. M. Ng, Marcos Rios, Hani S. Mahmassani, Ying Chen, Karen Smilowitz",http://arxiv.org/pdf/2501.01447v2,cs.LG
Prototypical Distillation and Debiased Tuning for Black-box Unsupervised Domain Adaptation,"Unsupervised domain adaptation aims to transfer knowledge from a related,
label-rich source domain to an unlabeled target domain, thereby circumventing
the high costs associated with manual annotation. Recently, there has been
growing interest in source-free domain adaptation, a paradigm in which only a
pre-trained model, rather than the labeled source data, is provided to the
target domain. Given the potential risk of source data leakage via model
inversion attacks, this paper introduces a novel setting called black-box
domain adaptation, where the source model is accessible only through an API
that provides the predicted label along with the corresponding confidence value
for each query. We develop a two-step framework named $\textbf{Pro}$totypical
$\textbf{D}$istillation and $\textbf{D}$ebiased tun$\textbf{ing}$
($\textbf{ProDDing}$). In the first step, ProDDing leverages both the raw
predictions from the source model and prototypes derived from the target domain
as teachers to distill a customized target model. In the second step, ProDDing
keeps fine-tuning the distilled model by penalizing logits that are biased
toward certain classes. Empirical results across multiple benchmarks
demonstrate that ProDDing outperforms existing black-box domain adaptation
methods. Moreover, in the case of hard-label black-box domain adaptation, where
only predicted labels are available, ProDDing achieves significant improvements
over these methods. Code will be available at
\url{https://github.com/tim-learn/ProDDing/}.",2024-12-30,"Jian Liang, Lijun Sheng, Hongmin Liu, Ran He",http://arxiv.org/pdf/2412.20670v1,cs.LG
Overcoming Class Imbalance: Unified GNN Learning with Structural and Semantic Connectivity Representations,"Class imbalance is pervasive in real-world graph datasets, where the majority
of annotated nodes belong to a small set of classes (majority classes), leaving
many other classes (minority classes) with only a handful of labeled nodes.
Graph Neural Networks (GNNs) suffer from significant performance degradation in
the presence of class imbalance, exhibiting bias towards majority classes and
struggling to generalize effectively on minority classes. This limitation
stems, in part, from the message passing process, leading GNNs to overfit to
the limited neighborhood of annotated nodes from minority classes and impeding
the propagation of discriminative information throughout the entire graph. In
this paper, we introduce a novel Unified Graph Neural Network Learning
(Uni-GNN) framework to tackle class-imbalanced node classification. The
proposed framework seamlessly integrates both structural and semantic
connectivity representations through semantic and structural node encoders. By
combining these connectivity types, Uni-GNN extends the propagation of node
embeddings beyond immediate neighbors, encompassing non-adjacent structural
nodes and semantically similar nodes, enabling efficient diffusion of
discriminative information throughout the graph. Moreover, to harness the
potential of unlabeled nodes within the graph, we employ a balanced
pseudo-label generation mechanism that augments the pool of available labeled
nodes from minority classes in the training set. Experimental results
underscore the superior performance of our proposed Uni-GNN framework compared
to state-of-the-art class-imbalanced graph learning baselines across multiple
benchmark datasets.",2024-12-30,"Abdullah Alchihabi, Hao Yan, Yuhong Guo",http://arxiv.org/pdf/2412.20656v1,cs.LG
Open-Book Neural Algorithmic Reasoning,"Neural algorithmic reasoning is an emerging area of machine learning that
focuses on building neural networks capable of solving complex algorithmic
tasks. Recent advancements predominantly follow the standard supervised
learning paradigm -- feeding an individual problem instance into the network
each time and training it to approximate the execution steps of a classical
algorithm. We challenge this mode and propose a novel open-book learning
framework. In this framework, whether during training or testing, the network
can access and utilize all instances in the training dataset when reasoning for
a given instance.
  Empirical evaluation is conducted on the challenging CLRS Algorithmic
Reasoning Benchmark, which consists of 30 diverse algorithmic tasks. Our
open-book learning framework exhibits a significant enhancement in neural
reasoning capabilities. Further, we notice that there is recent literature
suggesting that multi-task training on CLRS can improve the reasoning accuracy
of certain tasks, implying intrinsic connections between different algorithmic
tasks. We delve into this direction via the open-book framework. When the
network reasons for a specific task, we enable it to aggregate information from
training instances of other tasks in an attention-based manner. We show that
this open-book attention mechanism offers insights into the inherent
relationships among various tasks in the benchmark and provides a robust tool
for interpretable multi-task training.",2024-12-30,"Hefei Li, Chao Peng, Chenyang Xu, Zhengfeng Yang",http://arxiv.org/pdf/2501.00072v1,cs.LG
Uncertainty Herding: One Active Learning Method for All Label Budgets,"Most active learning research has focused on methods which perform well when
many labels are available, but can be dramatically worse than random selection
when label budgets are small. Other methods have focused on the low-budget
regime, but do poorly as label budgets increase. As the line between ""low"" and
""high"" budgets varies by problem, this is a serious issue in practice. We
propose uncertainty coverage, an objective which generalizes a variety of low-
and high-budget objectives, as well as natural, hyperparameter-light methods to
smoothly interpolate between low- and high-budget regimes. We call greedy
optimization of the estimate Uncertainty Herding; this simple method is
computationally fast, and we prove that it nearly optimizes the
distribution-level coverage. In experimental validation across a variety of
active learning tasks, our proposal matches or beats state-of-the-art
performance in essentially all cases; it is the only method of which we are
aware that reliably works well in both low- and high-budget settings.",2024-12-30,"Wonho Bae, Gabriel L. Oliveira, Danica J. Sutherland",http://arxiv.org/pdf/2412.20644v2,cs.LG
SafeSynthDP: Leveraging Large Language Models for Privacy-Preserving Synthetic Data Generation Using Differential Privacy,"Machine learning (ML) models frequently rely on training data that may
include sensitive or personal information, raising substantial privacy
concerns. Legislative frameworks such as the General Data Protection Regulation
(GDPR) and the California Consumer Privacy Act (CCPA) have necessitated the
development of strategies that preserve privacy while maintaining the utility
of data. In this paper, we investigate the capability of Large Language Models
(LLMs) to generate synthetic datasets integrated with Differential Privacy (DP)
mechanisms, thereby enabling data-driven research and model training without
direct exposure of sensitive information. Our approach incorporates DP-based
noise injection methods, including Laplace and Gaussian distributions, into the
data generation process. We then evaluate the utility of these DP-enhanced
synthetic datasets by comparing the performance of ML models trained on them
against models trained on the original data. To substantiate privacy
guarantees, we assess the resilience of the generated synthetic data to
membership inference attacks and related threats. The experimental results
demonstrate that integrating DP within LLM-driven synthetic data generation
offers a viable balance between privacy protection and data utility. This study
provides a foundational methodology and insight into the privacy-preserving
capabilities of LLMs, paving the way for compliant and effective ML research
and applications.",2024-12-30,"Md Mahadi Hasan Nahid, Sadid Bin Hasan",http://arxiv.org/pdf/2412.20641v1,cs.LG
Predicting Long Term Sequential Policy Value Using Softer Surrogates,"Off-policy policy evaluation (OPE) estimates the outcome of a new policy
using historical data collected from a different policy. However, existing OPE
methods cannot handle cases when the new policy introduces novel actions. This
issue commonly occurs in real-world domains, like healthcare, as new drugs and
treatments are continuously developed. Novel actions necessitate on-policy data
collection, which can be burdensome and expensive if the outcome of interest
takes a substantial amount of time to observe--for example, in multi-year
clinical trials. This raises a key question of how to predict the long-term
outcome of a policy after only observing its short-term effects? Though in
general this problem is intractable, under some surrogacy conditions, the
short-term on-policy data can be combined with the long-term historical data to
make accurate predictions about the new policy's long-term value. In two
simulated healthcare examples--HIV and sepsis management--we show that our
estimators can provide accurate predictions about the policy value only after
observing 10\% of the full horizon data. We also provide finite sample analysis
of our doubly robust estimators.",2024-12-30,"Hyunji Nam, Allen Nie, Ge Gao, Vasilis Syrgkanis, Emma Brunskill",http://arxiv.org/pdf/2412.20638v2,cs.LG
NetFlowGen: Leveraging Generative Pre-training for Network Traffic Dynamics,"Understanding the traffic dynamics in networks is a core capability for
automated systems to monitor and analyze networking behaviors, reducing
expensive human efforts and economic risks through tasks such as traffic
classification, congestion prediction, and attack detection. However, it is
still challenging to accurately model network traffic with machine learning
approaches in an efficient and broadly applicable manner. Task-specific models
trained from scratch are used for different networking applications, which
limits the efficiency of model development and generalization of model
deployment. Furthermore, while networking data is abundant, high-quality
task-specific labels are often insufficient for training individual models.
Large-scale self-supervised learning on unlabeled data provides a natural
pathway for tackling these challenges. We propose to pre-train a
general-purpose machine learning model to capture traffic dynamics with only
traffic data from NetFlow records, with the goal of fine-tuning for different
downstream tasks with small amount of labels. Our presented NetFlowGen
framework goes beyond a proof-of-concept for network traffic pre-training and
addresses specific challenges such as unifying network feature representations,
learning from large unlabeled traffic data volume, and testing on real
downstream tasks in DDoS attack detection. Experiments demonstrate promising
results of our pre-training framework on capturing traffic dynamics and
adapting to different networking tasks.",2024-12-30,"Jiawei Zhou, Woojeong Kim, Zhiying Xu, Alexander M. Rush, Minlan Yu",http://arxiv.org/pdf/2412.20635v1,cs.LG
Matrix Concentration for Random Signed Graphs and Community Recovery in the Signed Stochastic Block Model,"We consider graphs where edges and their signs are added independently at
random from among all pairs of nodes. We establish strong concentration
inequalities for adjacency and Laplacian matrices obtained from this family of
random graph models. Then, we apply our results to study graphs sampled from
the signed stochastic block model. Namely, we take a two-community setting
where edges within the communities have positive signs and edges between the
communities have negative signs and apply a random sign perturbation with
probability $0< s <1/2$. In this setting, our findings include: first, the
spectral gap of the corresponding signed Laplacian matrix concentrates near
$2s$ with high probability; and second, the sign of the first eigenvector of
the Laplacian matrix defines a weakly consistent estimator for the balanced
community detection problem, or equivalently, the $\pm 1$ synchronization
problem. We supplement our theoretical contributions with experimental data
obtained from the models under consideration.",2024-12-29,Sawyer Jack Robertson,http://arxiv.org/pdf/2412.20620v1,cs.LG
Audiopedia: Audio QA with Knowledge,"In this paper, we introduce Audiopedia, a novel task called Audio Question
Answering with Knowledge, which requires both audio comprehension and external
knowledge reasoning. Unlike traditional Audio Question Answering (AQA)
benchmarks that focus on simple queries answerable from audio alone, Audiopedia
targets knowledge-intensive questions. We define three sub-tasks: (i) Single
Audio Question Answering (s-AQA), where questions are answered based on a
single audio sample, (ii) Multi-Audio Question Answering (m-AQA), which
requires reasoning over multiple audio samples, and (iii) Retrieval-Augmented
Audio Question Answering (r-AQA), which involves retrieving relevant audio to
answer the question. We benchmark large audio language models (LALMs) on these
sub-tasks and observe suboptimal performance. To address this, we propose a
generic framework that can be adapted to any LALM, equipping them with
knowledge reasoning capabilities. Our framework has two components: (i) Audio
Entity Linking (AEL) and (ii) Knowledge-Augmented Audio Large Multimodal Model
(KA2LM), which together improve performance on knowledge-intensive AQA tasks.
To our knowledge, this is the first work to address advanced audio
understanding via knowledge-intensive tasks like Audiopedia.",2024-12-29,"Abhirama Subramanyam Penamakuri, Kiran Chhatre, Akshat Jain",http://arxiv.org/pdf/2412.20619v1,cs.LG
Converting Time Series Data to Numeric Representations Using Alphabetic Mapping and k-mer strategy,"In the realm of data analysis and bioinformatics, representing time series
data in a manner akin to biological sequences offers a novel approach to
leverage sequence analysis techniques. Transforming time series signals into
molecular sequence-type representations allows us to enhance pattern
recognition by applying sophisticated sequence analysis techniques (e.g.
$k$-mers based representation) developed in bioinformatics, uncovering hidden
patterns and relationships in complex, non-linear time series data. This paper
proposes a method to transform time series signals into biological/molecular
sequence-type representations using a unique alphabetic mapping technique. By
generating 26 ranges corresponding to the 26 letters of the English alphabet,
each value within the time series is mapped to a specific character based on
its range. This conversion facilitates the application of sequence analysis
algorithms, typically used in bioinformatics, to analyze time series data. We
demonstrate the effectiveness of this approach by converting real-world time
series signals into character sequences and performing sequence classification.
The resulting sequences can be utilized for various sequence-based analysis
techniques, offering a new perspective on time series data representation and
analysis.",2024-12-29,"Sarwan Ali, Tamkanat E Ali, Imdad Ullah Khan, Murray Patterson",http://arxiv.org/pdf/2412.20617v1,cs.LG
Hilbert Curve Based Molecular Sequence Analysis,"Accurate molecular sequence analysis is a key task in the field of
bioinformatics. To apply molecular sequence classification algorithms, we first
need to generate the appropriate representations of the sequences. Traditional
numeric sequence representation techniques are mostly based on sequence
alignment that faces limitations in the form of lack of accuracy. Although
several alignment-free techniques have also been introduced, their tabular data
form results in low performance when used with Deep Learning (DL) models
compared to the competitive performance observed in the case of image-based
data. To find a solution to this problem and to make Deep Learning (DL) models
function to their maximum potential while capturing the important spatial
information in the sequence data, we propose a universal Hibert curve-based
Chaos Game Representation (CGR) method. This method is a transformative
function that involves a novel Alphabetic index mapping technique used in
constructing Hilbert curve-based image representation from molecular sequences.
Our method can be globally applied to any type of molecular sequence data. The
Hilbert curve-based image representations can be used as input to sophisticated
vision DL models for sequence classification. The proposed method shows
promising results as it outperforms current state-of-the-art methods by
achieving a high accuracy of $94.5$\% and an F1 score of $93.9\%$ when tested
with the CNN model on the lung cancer dataset. This approach opens up a new
horizon for exploring molecular sequence analysis using image classification
methods.",2024-12-29,"Sarwan Ali, Tamkanat E Ali, Imdad Ullah Khan, Murray Patterson",http://arxiv.org/pdf/2412.20616v1,cs.LG
MATEY: multiscale adaptive foundation models for spatiotemporal physical systems,"Accurate representation of the multiscale features in spatiotemporal physical
systems using vision transformer (ViT) architectures requires extremely long,
computationally prohibitive token sequences. To address this issue, we propose
two adaptive tokenization schemes that dynamically adjust patch sizes based on
local features: one ensures convergent behavior to uniform patch refinement,
while the other offers better computational efficiency. Moreover, we present a
set of spatiotemporal attention schemes, where the temporal or axial spatial
dimensions are decoupled, and evaluate their computational and data
efficiencies. We assess the performance of the proposed multiscale adaptive
model, MATEY, in a sequence of experiments. The results show that adaptive
tokenization schemes achieve improved accuracy without significantly increasing
the length of the token sequence. Compared to a full spatiotemporal attention
scheme or a scheme that decouples only the temporal dimension, we find that
fully decoupled axial attention is less efficient and expressive, requiring
more training time and model weights to achieve the same accuracy. Finally, we
demonstrate in two fine-tuning tasks featuring different physics that models
pretrained on PDEBench data outperform the ones trained from scratch,
especially in the low data regime with frozen attention.",2024-12-29,"Pei Zhang, M. Paul Laiu, Matthew Norman, Doug Stefanski, John Gounley",http://arxiv.org/pdf/2412.20601v1,cs.LG
Kryptonite-N: Machine Learning Strikes Back,"Quinn et al propose challenge datasets in their work called ``Kryptonite-N"".
These datasets aim to counter the universal function approximation argument of
machine learning, breaking the notation that machine learning can ``approximate
any continuous function"" \cite{original_paper}. Our work refutes this claim and
shows that universal function approximations can be applied successfully; the
Kryptonite datasets are constructed predictably, allowing logistic regression
with sufficient polynomial expansion and L1 regularization to solve for any
dimension N.",2024-12-29,"Albus Li, Nathan Bailey, Will Sumerfield, Kira Kim",http://arxiv.org/pdf/2412.20588v2,cs.LG
Testing and Improving the Robustness of Amortized Bayesian Inference for Cognitive Models,"Contaminant observations and outliers often cause problems when estimating
the parameters of cognitive models, which are statistical models representing
cognitive processes. In this study, we test and improve the robustness of
parameter estimation using amortized Bayesian inference (ABI) with neural
networks. To this end, we conduct systematic analyses on a toy example and
analyze both synthetic and real data using a popular cognitive model, the Drift
Diffusion Models (DDM). First, we study the sensitivity of ABI to contaminants
with tools from robust statistics: the empirical influence function and the
breakdown point. Next, we propose a data augmentation or noise injection
approach that incorporates a contamination distribution into the
data-generating process during training. We examine several candidate
distributions and evaluate their performance and cost in terms of accuracy and
efficiency loss relative to a standard estimator. Introducing contaminants from
a Cauchy distribution during training considerably increases the robustness of
the neural density estimator as measured by bounded influence functions and a
much higher breakdown point. Overall, the proposed method is straightforward
and practical to implement and has a broad applicability in fields where
outlier detection or removal is challenging.",2024-12-29,"Yufei Wu, Stefan Radev, Francis Tuerlinckx",http://arxiv.org/pdf/2412.20586v1,cs.LG
Bridging the Gap: A Decade Review of Time-Series Clustering Methods,"Time series, as one of the most fundamental representations of sequential
data, has been extensively studied across diverse disciplines, including
computer science, biology, geology, astronomy, and environmental sciences. The
advent of advanced sensing, storage, and networking technologies has resulted
in high-dimensional time-series data, however, posing significant challenges
for analyzing latent structures over extended temporal scales. Time-series
clustering, an established unsupervised learning strategy that groups similar
time series together, helps unveil hidden patterns in these complex datasets.
In this survey, we trace the evolution of time-series clustering methods from
classical approaches to recent advances in neural networks. While previous
surveys have focused on specific methodological categories, we bridge the gap
between traditional clustering methods and emerging deep learning-based
algorithms, presenting a comprehensive, unified taxonomy for this research
area. This survey highlights key developments and provides insights to guide
future research in time-series clustering.",2024-12-29,"John Paparrizos, Fan Yang, Haojun Li",http://arxiv.org/pdf/2412.20582v1,cs.LG
A Survey on Time-Series Distance Measures,"Distance measures have been recognized as one of the fundamental building
blocks in time-series analysis tasks, e.g., querying, indexing, classification,
clustering, anomaly detection, and similarity search. The vast proliferation of
time-series data across a wide range of fields has increased the relevance of
evaluating the effectiveness and efficiency of these distance measures. To
provide a comprehensive view of this field, this work considers over 100
state-of-the-art distance measures, classified into 7 categories: lock-step
measures, sliding measures, elastic measures, kernel measures, feature-based
measures, model-based measures, and embedding measures. Beyond providing
comprehensive mathematical frameworks, this work also delves into the
distinctions and applications across these categories for both univariate and
multivariate cases. By providing comprehensive collections and insights, this
study paves the way for the future development of innovative time-series
distance measures.",2024-12-29,"John Paparrizos, Haojun Li, Fan Yang, Kaize Wu, Jens E. d'Hondt, Odysseas Papapetrou",http://arxiv.org/pdf/2412.20574v1,cs.LG
The intrinsic motivation of reinforcement and imitation learning for sequential tasks,"This work in the field of developmental cognitive robotics aims to devise a
new domain bridging between reinforcement learning and imitation learning, with
a model of the intrinsic motivation for learning agents to learn with guidance
from tutors multiple tasks, including sequential tasks. The main contribution
has been to propose a common formulation of intrinsic motivation based on
empirical progress for a learning agent to choose automatically its learning
curriculum by actively choosing its learning strategy for simple or sequential
tasks: which task to learn, between autonomous exploration or imitation
learning, between low-level actions or task decomposition, between several
tutors. The originality is to design a learner that benefits not only passively
from data provided by tutors, but to actively choose when to request tutoring
and what and whom to ask. The learner is thus more robust to the quality of the
tutoring and learns faster with fewer demonstrations. We developed the
framework of socially guided intrinsic motivation with machine learning
algorithms to learn multiple tasks by taking advantage of the generalisability
properties of human demonstrations in a passive manner or in an active manner
through requests of demonstrations from the best tutor for simple and composing
subtasks. The latter relies on a representation of subtask composition proposed
for a construction process, which should be refined by representations used for
observational processes of analysing human movements and activities of daily
living. With the outlook of a language-like communication with the tutor, we
investigated the emergence of a symbolic representation of the continuous
sensorimotor space and of tasks using intrinsic motivation. We proposed within
the reinforcement learning framework, a reward function for interacting with
tutors for automatic curriculum learning in multi-task learning.",2024-12-29,Sao Mai Nguyen,http://arxiv.org/pdf/2412.20573v1,cs.LG
Distributionally Robust Optimization via Iterative Algorithms in Continuous Probability Spaces,"We consider a minimax problem motivated by distributionally robust
optimization (DRO) when the worst-case distribution is continuous, leading to
significant computational challenges due to the infinite-dimensional nature of
the optimization problem. Recent research has explored learning the worst-case
distribution using neural network-based generative models to address these
computational challenges but lacks algorithmic convergence guarantees. This
paper bridges this theoretical gap by presenting an iterative algorithm to
solve such a minimax problem, achieving global convergence under mild
assumptions and leveraging technical tools from vector space minimax
optimization and convex analysis in the space of continuous probability
densities. In particular, leveraging Brenier's theorem, we represent the
worst-case distribution as a transport map applied to a continuous reference
measure and reformulate the regularized discrepancy-based DRO as a minimax
problem in the Wasserstein space. Furthermore, we demonstrate that the
worst-case distribution can be efficiently computed using a modified
Jordan-Kinderlehrer-Otto (JKO) scheme with sufficiently large regularization
parameters for commonly used discrepancy functions, linked to the radius of the
ambiguity set. Additionally, we derive the global convergence rate and quantify
the total number of subgradient and inexact modified JKO iterations required to
obtain approximate stationary points. These results are potentially applicable
to nonconvex and nonsmooth scenarios, with broad relevance to modern machine
learning applications.",2024-12-29,"Linglingzhi Zhu, Yao Xie",http://arxiv.org/pdf/2412.20556v1,cs.LG
Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD,"Recent findings by Cohen et al., 2021, demonstrate that when training neural
networks with full-batch gradient descent with a step size of $\eta$, the
largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently
stabilizes at $\lambda_{\max} = 2/\eta$. These results have significant
implications for convergence and generalization. This, however, is not the case
of mini-batch stochastic gradient descent (SGD), limiting the broader
applicability of its consequences. We show that SGD trains in a different
regime we term Edge of Stochastic Stability (EoSS). In this regime, what
stabilizes at $2/\eta$ is *Batch Sharpness*: the expected directional curvature
of mini-batch Hessians along their corresponding stochastic gradients. As a
consequence $\lambda_{\max}$--which is generally smaller than Batch
Sharpness--is suppressed, aligning with the long-standing empirical observation
that smaller batches and larger step sizes favor flatter minima. We further
discuss implications for mathematical modeling of SGD trajectories.",2024-12-29,"Arseniy Andreyev, Pierfrancesco Beneventano",http://arxiv.org/pdf/2412.20553v3,cs.LG
ICLR: In-Context Learning of Representations,"Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
""graph tracing"" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.",2024-12-29,"Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka",http://arxiv.org/pdf/2501.00070v2,cs.LG
The Impact of Prompt Programming on Function-Level Code Generation,"Large Language Models (LLMs) are increasingly used by software engineers for
code generation. However, limitations of LLMs such as irrelevant or incorrect
code have highlighted the need for prompt programming (or prompt engineering)
where engineers apply specific prompt techniques (e.g., chain-of-thought or
input-output examples) to improve the generated code. Despite this, the impact
of different prompt techniques -- and their combinations -- on code generation
remains underexplored. In this study, we introduce CodePromptEval, a dataset of
7072 prompts designed to evaluate five prompt techniques (few-shot, persona,
chain-of-thought, function signature, list of packages) and their effect on the
correctness, similarity, and quality of complete functions generated by three
LLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt
techniques significantly influence the generated code, combining multiple
techniques does not necessarily improve the outcome. Additionally, we observed
a trade-off between correctness and quality when using prompt techniques. Our
dataset and replication package enable future research on improving
LLM-generated code and evaluating new prompt techniques.",2024-12-29,"Ranim Khojah, Francisco Gomes de Oliveira Neto, Mazen Mohamad, Philipp Leitner",http://arxiv.org/pdf/2412.20545v1,cs.LG
Diminishing Return of Value Expansion Methods,"Model-based reinforcement learning aims to increase sample efficiency, but
the accuracy of dynamics models and the resulting compounding errors are often
seen as key limitations. This paper empirically investigates potential sample
efficiency gains from improved dynamics models in model-based value expansion
methods. Our study reveals two key findings when using oracle dynamics models
to eliminate compounding errors. First, longer rollout horizons enhance sample
efficiency, but the improvements quickly diminish with each additional
expansion step. Second, increased model accuracy only marginally improves
sample efficiency compared to learned models with identical horizons. These
diminishing returns in sample efficiency are particularly noteworthy when
compared to model-free value expansion methods. These model-free algorithms
achieve comparable performance without the computational overhead. Our results
suggest that the limitation of model-based value expansion methods cannot be
attributed to model accuracy. Although higher accuracy is beneficial, even
perfect models do not provide unrivaled sample efficiency. Therefore, the
bottleneck exists elsewhere. These results challenge the common assumption that
model accuracy is the primary constraint in model-based reinforcement learning.",2024-12-29,"Daniel Palenicek, Michael Lutter, João Carvalho, Daniel Dennert, Faran Ahmad, Jan Peters",http://arxiv.org/pdf/2412.20537v1,cs.LG
Dynamic Optimization of Storage Systems Using Reinforcement Learning Techniques,"The exponential growth of data-intensive applications has placed
unprecedented demands on modern storage systems, necessitating dynamic and
efficient optimization strategies. Traditional heuristics employed for storage
performance optimization often fail to adapt to the variability and complexity
of contemporary workloads, leading to significant performance bottlenecks and
resource inefficiencies. To address these challenges, this paper introduces
RL-Storage, a novel reinforcement learning (RL)-based framework designed to
dynamically optimize storage system configurations. RL-Storage leverages deep
Q-learning algorithms to continuously learn from real-time I/O patterns and
predict optimal storage parameters, such as cache size, queue depths, and
readahead settings[1]. The proposed framework operates within the storage
kernel, ensuring minimal latency and low computational overhead. Through an
adaptive feedback mechanism, RL-Storage dynamically adjusts critical
parameters, achieving efficient resource utilization across a wide range of
workloads. Experimental evaluations conducted on a range of benchmarks,
including RocksDB and PostgreSQL, demonstrate significant improvements, with
throughput gains of up to 2.6x and latency reductions of 43% compared to
baseline heuristics. Additionally, RL-Storage achieves these performance
enhancements with a negligible CPU overhead of 0.11% and a memory footprint of
only 5 KB, making it suitable for seamless deployment in production
environments. This work underscores the transformative potential of
reinforcement learning techniques in addressing the dynamic nature of modern
storage systems. By autonomously adapting to workload variations in real time,
RL-Storage provides a robust and scalable solution for optimizing storage
performance, paving the way for next-generation intelligent storage
infrastructures.",2024-12-29,"Chiyu Cheng, Chang Zhou, Yang Zhao, Jin Cao",http://arxiv.org/pdf/2501.00068v1,cs.LG
Dynamic Adaptation in Data Storage: Real-Time Machine Learning for Enhanced Prefetching,"The exponential growth of data storage demands has necessitated the evolution
of hierarchical storage management strategies [1]. This study explores the
application of streaming machine learning [3] to revolutionize data prefetching
within multi-tiered storage systems. Unlike traditional batch-trained models,
streaming machine learning [5] offers adaptability, real-time insights, and
computational efficiency, responding dynamically to workload variations. This
work designs and validates an innovative framework that integrates streaming
classification models for predicting file access patterns, specifically the
next file offset. Leveraging comprehensive feature engineering and real-time
evaluation over extensive production traces, the proposed methodology achieves
substantial improvements in prediction accuracy, memory efficiency, and system
adaptability. The results underscore the potential of streaming models in
real-time storage management, setting a precedent for advanced caching and
tiering strategies.",2024-12-29,"Chiyu Cheng, Chang Zhou, Yang Zhao, Jin Cao",http://arxiv.org/pdf/2501.14771v2,cs.LG
Optimizing SSD Caches for Cloud Block Storage Systems Using Machine Learning Approaches,"The growing demand for efficient cloud storage solutions has led to the
widespread adoption of Solid-State Drives (SSDs) for caching in cloud block
storage systems. The management of data writes to SSD caches plays a crucial
role in improving overall system performance, reducing latency, and extending
the lifespan of storage devices. A critical challenge arises from the large
volume of write-only data, which significantly impacts the performance of SSD
caches when handled inefficiently. Specifically, writes that have not been read
for a certain period may introduce unnecessary write traffic to the SSD cache
without offering substantial benefits for cache performance. This paper
proposes a novel approach to mitigate this issue by leveraging machine learning
techniques to dynamically optimize the write policy in cloud-based storage
systems. The proposed method identifies write-only data and selectively filters
it out in real-time, thereby minimizing the number of unnecessary write
operations and improving the overall performance of the cache system.
Experimental results demonstrate that the proposed machine learning-based
policy significantly outperforms traditional approaches by reducing the number
of harmful writes and optimizing cache utilization. This solution is
particularly suitable for cloud environments with varying and unpredictable
workloads, where traditional cache management strategies often fall short.",2024-12-29,"Chiyu Cheng, Chang Zhou, Yang Zhao, Jin Cao",http://arxiv.org/pdf/2501.14770v2,cs.LG
Goal-Conditioned Data Augmentation for Offline Reinforcement Learning,"Offline reinforcement learning (RL) enables policy learning from
pre-collected offline datasets, relaxing the need to interact directly with the
environment. However, limited by the quality of offline datasets, it generally
fails to learn well-qualified policies in suboptimal datasets. To address
datasets with insufficient optimal demonstrations, we introduce
Goal-cOnditioned Data Augmentation (GODA), a novel goal-conditioned
diffusion-based method for augmenting samples with higher quality. Leveraging
recent advancements in generative modeling, GODA incorporates a novel
return-oriented goal condition with various selection mechanisms. Specifically,
we introduce a controllable scaling technique to provide enhanced return-based
guidance during data sampling. GODA learns a comprehensive distribution
representation of the original offline datasets while generating new data with
selectively higher-return goals, thereby maximizing the utility of limited
optimal demonstrations. Furthermore, we propose a novel adaptive gated
conditioning method for processing noised inputs and conditions, enhancing the
capture of goal-oriented guidance. We conduct experiments on the D4RL benchmark
and real-world challenges, specifically traffic signal control (TSC) tasks, to
demonstrate GODA's effectiveness in enhancing data quality and superior
performance compared to state-of-the-art data augmentation methods across
various offline RL algorithms.",2024-12-29,"Xingshuai Huang, Di Wu Member, Benoit Boulet",http://arxiv.org/pdf/2412.20519v1,cs.LG
Dive into Time-Series Anomaly Detection: A Decade Review,"Recent advances in data collection technology, accompanied by the ever-rising
volume and velocity of streaming data, underscore the vital need for time
series analytics. In this regard, time-series anomaly detection has been an
important activity, entailing various applications in fields such as cyber
security, financial markets, law enforcement, and health care. While
traditional literature on anomaly detection is centered on statistical
measures, the increasing number of machine learning algorithms in recent years
call for a structured, general characterization of the research methods for
time-series anomaly detection. This survey groups and summarizes anomaly
detection existing solutions under a process-centric taxonomy in the time
series context. In addition to giving an original categorization of anomaly
detection methods, we also perform a meta-analysis of the literature and
outline general trends in time-series anomaly detection research.",2024-12-29,"Paul Boniol, Qinghua Liu, Mingyi Huang, Themis Palpanas, John Paparrizos",http://arxiv.org/pdf/2412.20512v1,cs.LG
Stratify: Unifying Multi-Step Forecasting Strategies,"A key aspect of temporal domains is the ability to make predictions multiple
time steps into the future, a process known as multi-step forecasting (MSF). At
the core of this process is selecting a forecasting strategy, however, with no
existing frameworks to map out the space of strategies, practitioners are left
with ad-hoc methods for strategy selection. In this work, we propose Stratify,
a parameterised framework that addresses multi-step forecasting, unifying
existing strategies and introducing novel, improved strategies. We evaluate
Stratify on 18 benchmark datasets, five function classes, and short to long
forecast horizons (10, 20, 40, 80). In over 84% of 1080 experiments, novel
strategies in Stratify improved performance compared to all existing ones.
Importantly, we find that no single strategy consistently outperforms others in
all task settings, highlighting the need for practitioners explore the Stratify
space to carefully search and select forecasting strategies based on
task-specific requirements. Our results are the most comprehensive benchmarking
of known and novel forecasting strategies. We make code available to reproduce
our results.",2024-12-29,"Riku Green, Grant Stevens, Zahraa Abdallah, Telmo M. Silva Filho",http://arxiv.org/pdf/2412.20510v1,cs.LG
On Adversarial Robustness of Language Models in Transfer Learning,"We investigate the adversarial robustness of LLMs in transfer learning
scenarios. Through comprehensive experiments on multiple datasets (MBIB Hate
Speech, MBIB Political Bias, MBIB Gender Bias) and various model architectures
(BERT, RoBERTa, GPT-2, Gemma, Phi), we reveal that transfer learning, while
improving standard performance metrics, often leads to increased vulnerability
to adversarial attacks. Our findings demonstrate that larger models exhibit
greater resilience to this phenomenon, suggesting a complex interplay between
model size, architecture, and adaptation methods. Our work highlights the
crucial need for considering adversarial robustness in transfer learning
scenarios and provides insights into maintaining model security without
compromising performance. These findings have significant implications for the
development and deployment of LLMs in real-world applications where both
performance and robustness are paramount.",2024-12-29,"Bohdan Turbal, Anastasiia Mazur, Jiaxu Zhao, Mykola Pechenizkiy",http://arxiv.org/pdf/2501.00066v1,cs.LG
"Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning","Urban regeneration presents significant challenges within the context of
urbanization, requiring adaptive approaches to tackle evolving needs.
Leveraging advancements in large language models (LLMs), we propose Cyclical
Urban Planning (CUP), a new paradigm that continuously generates, evaluates,
and refines urban plans in a closed-loop. Specifically, our multi-agent
LLM-based framework consists of three key components: (1) Planning, where LLM
agents generate and refine urban plans based on contextual data; (2) Living,
where agents simulate the behaviors and interactions of residents, modeling
life in the urban environment; and (3) Judging, which involves evaluating plan
effectiveness and providing iterative feedback for improvement. The cyclical
process enables a dynamic and responsive planning approach. Experiments on the
real-world dataset demonstrate the effectiveness of our framework as a
continuous and adaptive planning process.",2024-12-29,"Hang Ni, Yuzhi Wang, Hao Liu",http://arxiv.org/pdf/2412.20505v1,cs.LG
Random Matrix Theory for Stochastic Gradient Descent,"Investigating the dynamics of learning in machine learning algorithms is of
paramount importance for understanding how and why an approach may be
successful. The tools of physics and statistics provide a robust setting for
such investigations. Here we apply concepts from random matrix theory to
describe stochastic weight matrix dynamics, using the framework of Dyson
Brownian motion. We derive the linear scaling rule between the learning rate
(step size) and the batch size, and identify universal and non-universal
aspects of weight matrix dynamics. We test our findings in the (near-)solvable
case of the Gaussian Restricted Boltzmann Machine and in a linear
one-hidden-layer neural network.",2024-12-29,"Chanju Park, Matteo Favoni, Biagio Lucini, Gert Aarts",http://arxiv.org/pdf/2412.20496v1,cs.LG
A Multiparty Homomorphic Encryption Approach to Confidential Federated Kaplan Meier Survival Analysis,"The proliferation of healthcare data has expanded opportunities for
collaborative research, yet stringent privacy regulations hinder pooling
sensitive patient records. We propose a \emph{multiparty homomorphic
encryption-based} framework for \emph{privacy-preserving federated
Kaplan--Meier survival analysis}, offering native floating-point support, a
theoretical model, and explicit reconstruction-attack mitigation. Compared to
prior work, our framework ensures encrypted federated survival estimates
closely match centralized outcomes, supported by formal utility-loss bounds
that demonstrate convergence as aggregation and decryption noise diminish.
Extensive experiments on the NCCTG Lung Cancer and synthetic Breast Cancer
datasets confirm low \emph{mean absolute error (MAE)} and \emph{root mean
squared error (RMSE)}, indicating negligible deviations between encrypted and
non-encrypted survival curves. Log-rank and numerical accuracy tests reveal
\emph{no significant difference} between federated encrypted and non-encrypted
analyses, preserving statistical validity. A reconstruction-attack evaluation
shows smaller federations (2--3 providers) with overlapping data between the
institutions are vulnerable, a challenge mitigated by multiparty encryption.
Larger federations (5--50 sites) degrade reconstruction accuracy further, with
encryption improving confidentiality. Despite an 8--19$\times$ computational
overhead, threshold-based homomorphic encryption is \emph{feasible for
moderate-scale deployments}, balancing security and runtime. By providing
robust privacy guarantees alongside high-fidelity survival estimates, our
framework advances the state-of-the art in secure multi-institutional survival
analysis.",2024-12-29,"Narasimha Raghavan Veeraragavan, Svetlana Boudko, Jan Franz Nygård",http://arxiv.org/pdf/2412.20495v1,cs.LG
Multimodal Variational Autoencoder: a Barycentric View,"Multiple signal modalities, such as vision and sounds, are naturally present
in real-world phenomena. Recently, there has been growing interest in learning
generative models, in particular variational autoencoder (VAE), to for
multimodal representation learning especially in the case of missing
modalities. The primary goal of these models is to learn a modality-invariant
and modality-specific representation that characterizes information across
multiple modalities. Previous attempts at multimodal VAEs approach this mainly
through the lens of experts, aggregating unimodal inference distributions with
a product of experts (PoE), a mixture of experts (MoE), or a combination of
both. In this paper, we provide an alternative generic and theoretical
formulation of multimodal VAE through the lens of barycenter. We first show
that PoE and MoE are specific instances of barycenters, derived by minimizing
the asymmetric weighted KL divergence to unimodal inference distributions. Our
novel formulation extends these two barycenters to a more flexible choice by
considering different types of divergences. In particular, we explore the
Wasserstein barycenter defined by the 2-Wasserstein distance, which better
preserves the geometry of unimodal distributions by capturing both
modality-specific and modality-invariant representations compared to KL
divergence. Empirical studies on three multimodal benchmarks demonstrated the
effectiveness of the proposed method.",2024-12-29,"Peijie Qiu, Wenhui Zhu, Sayantan Kumar, Xiwen Chen, Xiaotong Sun, Jin Yang, Abolfazl Razi, Yalin Wang, Aristeidis Sotiras",http://arxiv.org/pdf/2412.20487v1,cs.LG
Predicting Preschoolers' Externalizing Problems with Mother-Child Interaction Dynamics and Deep Learning,"Objective: Predicting children's future levels of externalizing problems
helps to identify children at risk and guide targeted prevention. Existing
studies have shown that mothers providing support in response to children's
dysregulation was associated with children's lower levels of externalizing
problems. The current study aims to evaluate and improve the accuracy of
predicting children's externalizing problems with mother-child interaction
dynamics. Method: This study used mother-child interaction dynamics during a
challenging puzzle task to predict children's externalizing problems six months
later (N=101, 46 boys, Mage=57.41 months, SD=6.58). Performance of the Residual
Dynamic Structural Equation Model (RDSEM) was compared with the Attention-based
Sequential Behavior Interaction Modeling (ASBIM) model, developed using the
deep learning techniques. Results: The RDSEM revealed that children whose
mothers provided more autonomy support after increases of child defeat had
lower levels of externalizing problems. Five-fold cross-validation showed that
the RDSEM had good prediction accuracy. The ASBIM model further improved
prediction accuracy, especially after including child inhibitory control as a
personalized individual feature. Conclusions: The dynamic process of
mother-child interaction provides important information for predicting
children's externalizing problems, especially maternal autonomy supportive
response to child defeat. The deep learning model is a useful tool to further
improve prediction accuracy.",2024-12-29,"Xi Chen, Yu Ji, Cong Xia, Wen Wu",http://arxiv.org/pdf/2501.00065v1,cs.LG
On the Convergence of Min-Max Langevin Dynamics and Algorithm,"We study zero-sum games in the space of probability distributions over the
Euclidean space $\mathbb{R}^d$ with entropy regularization, in the setting when
the interaction function between the players is smooth and strongly
convex-strongly concave. We prove an exponential convergence guarantee for the
mean-field min-max Langevin dynamics to compute the equilibrium distribution of
the zero-sum game. We also study the finite-particle approximation of the
mean-field min-max Langevin dynamics, both in continuous and discrete times. We
prove biased convergence guarantees for the continuous-time finite-particle
min-max Langevin dynamics to the stationary mean-field equilibrium distribution
with an explicit bias term which does not scale with the number of particles.
We also prove biased convergence guarantees for the discrete-time
finite-particle min-max Langevin algorithm to the stationary mean-field
equilibrium distribution with an additional bias term which scales with the
step size and the number of particles. This provides an explicit iteration
complexity for the average particle along the finite-particle algorithm to
approximately compute the equilibrium distribution of the zero-sum game.",2024-12-29,"Yang Cai, Siddharth Mitra, Xiuyuan Wang, Andre Wibisono",http://arxiv.org/pdf/2412.20471v2,cs.LG
Lungmix: A Mixup-Based Strategy for Generalization in Respiratory Sound Classification,"Respiratory sound classification plays a pivotal role in diagnosing
respiratory diseases. While deep learning models have shown success with
various respiratory sound datasets, our experiments indicate that models
trained on one dataset often fail to generalize effectively to others, mainly
due to data collection and annotation \emph{inconsistencies}. To address this
limitation, we introduce \emph{Lungmix}, a novel data augmentation technique
inspired by Mixup. Lungmix generates augmented data by blending waveforms using
loudness and random masks while interpolating labels based on their semantic
meaning, helping the model learn more generalized representations.
Comprehensive evaluations across three datasets, namely ICBHI, SPR, and HF,
demonstrate that Lungmix significantly enhances model generalization to unseen
data. In particular, Lungmix boosts the 4-class classification score by up to
3.55\%, achieving performance comparable to models trained directly on the
target dataset.",2024-12-29,"Shijia Ge, Weixiang Zhang, Shuzhao Xie, Baixu Yan, Zhi Wang",http://arxiv.org/pdf/2501.00064v1,cs.LG
Treatment Effect Estimation for Graph-Structured Targets,"Treatment effect estimation, which helps understand the causality between
treatment and outcome variable, is a central task in decision-making across
various domains. While most studies focus on treatment effect estimation on
individual targets, in specific contexts, there is a necessity to comprehend
the treatment effect on a group of targets, especially those that have
relationships represented as a graph structure between them. In such cases, the
focus of treatment assignment is prone to depend on a particular node of the
graph, such as the one with the highest degree, thus resulting in an
observational bias from a small part of the entire graph. Whereas a bias tends
to be caused by the small part, straightforward extensions of previous studies
cannot provide efficient bias mitigation owing to the use of the entire graph
information. In this study, we propose Graph-target Treatment Effect Estimation
(GraphTEE), a framework designed to estimate treatment effects specifically on
graph-structured targets. GraphTEE aims to mitigate observational bias by
focusing on confounding variable sets and consider a new regularization
framework. Additionally, we provide a theoretical analysis on how GraphTEE
performs better in terms of bias mitigation. Experiments on synthetic and
semi-synthetic datasets demonstrate the effectiveness of our proposed method.",2024-12-29,"Shonosuke Harada, Ryosuke Yoneda, Hisashi Kashima",http://arxiv.org/pdf/2412.20436v2,cs.LG
Multi-Objective Large Language Model Unlearning,"Machine unlearning in the domain of large language models (LLMs) has
attracted great attention recently, which aims to effectively eliminate
undesirable behaviors from LLMs without full retraining from scratch. In this
paper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is
a proactive way to decrease the prediction probability of the model on the
target data in order to remove their influence. We analyze two challenges that
render the process impractical: gradient explosion and catastrophic forgetting.
To address these issues, we propose Multi-Objective Large Language Model
Unlearning (MOLLM) algorithm. We first formulate LLM unlearning as a
multi-objective optimization problem, in which the cross-entropy loss is
modified to the unlearning version to overcome the gradient explosion issue. A
common descent update direction is then calculated, which enables the model to
forget the target data while preserving the utility of the LLM. Our empirical
results verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods
in terms of unlearning effect and model utility preservation. The source code
is available at https://github.com/zibinpan/MOLLM.",2024-12-29,"Zibin Pan, Shuwen Zhang, Yuesheng Zheng, Chi Li, Yuheng Cheng, Junhua Zhao",http://arxiv.org/pdf/2412.20412v2,cs.LG
"""Generative Models for Financial Time Series Data: Enhancing Signal-to-Noise Ratio and Addressing Data Scarcity in A-Share Market","The financial industry is increasingly seeking robust methods to address the
challenges posed by data scarcity and low signal-to-noise ratios, which limit
the application of deep learning techniques in stock market analysis. This
paper presents two innovative generative model-based approaches to synthesize
stock data, specifically tailored for different scenarios within the A-share
market in China. The first method, a sector-based synthesis approach, enhances
the signal-to-noise ratio of stock data by classifying the characteristics of
stocks from various sectors in China's A-share market. This method employs an
Approximate Non-Local Total Variation algorithm to smooth the generated data, a
bandpass filtering method based on Fourier Transform to eliminate noise, and
Denoising Diffusion Implicit Models to accelerate sampling speed. The second
method, a recursive stock data synthesis approach based on pattern recognition,
is designed to synthesize data for stocks with short listing periods and
limited comparable companies. It leverages pattern recognition techniques and
Markov models to learn and generate variable-length stock sequences, while
introducing a sub-time-level data augmentation method to alleviate data
scarcity issues.We validate the effectiveness of these methods through
extensive experiments on various datasets, including those from the main board,
STAR Market, Growth Enterprise Market Board, Beijing Stock Exchange, NASDAQ,
NYSE, and AMEX. The results demonstrate that our synthesized data not only
improve the performance of predictive models but also enhance the
signal-to-noise ratio of individual stock signals in price trading strategies.
Furthermore, the introduction of sub-time-level data significantly improves the
quality of synthesized data.",2024-12-29,Guangming Che,http://arxiv.org/pdf/2501.00063v1,cs.LG
A Multidisciplinary Approach to Telegram Data Analysis,"This paper presents a multidisciplinary approach to analyzing data from
Telegram for early warning information regarding cyber threats. With the
proliferation of hacktivist groups utilizing Telegram to disseminate
information regarding future cyberattacks or to boast about successful ones,
the need for effective data analysis methods is paramount. The primary
challenge lies in the vast number of channels and the overwhelming volume of
data, necessitating advanced techniques for discerning pertinent risks amidst
the noise. To address this challenge, we employ a combination of neural network
architectures and traditional machine learning algorithms. These methods are
utilized to classify and identify potential cyber threats within the Telegram
data. Additionally, sentiment analysis and entity recognition techniques are
incorporated to provide deeper insights into the nature and context of the
communicated information. The study evaluates the effectiveness of each method
in detecting and categorizing cyber threats, comparing their performance and
identifying areas for improvement. By leveraging these diverse analytical
tools, we aim to enhance early warning systems for cyber threats, enabling more
proactive responses to potential security breaches. This research contributes
to the ongoing efforts to bolster cybersecurity measures in an increasingly
interconnected digital landscape.",2024-12-29,"Velizar Varbanov, Kalin Kopanov, Tatiana Atanasova",http://arxiv.org/pdf/2412.20406v1,cs.LG
PTQ4VM: Post-Training Quantization for Visual Mamba,"Visual Mamba is an approach that extends the selective space state model,
Mamba, to vision tasks. It processes image tokens sequentially in a fixed
order, accumulating information to generate outputs. Despite its growing
popularity for delivering high-quality outputs at a low computational cost
across various tasks, Visual Mamba is highly susceptible to quantization, which
makes further performance improvements challenging. Our analysis reveals that
the fixed token access order in Visual Mamba introduces unique quantization
challenges, which we categorize into three main issues: 1) token-wise variance,
2) channel-wise outliers, and 3) a long tail of activations. To address these
challenges, we propose Post-Training Quantization for Visual Mamba (PTQ4VM),
which introduces two key strategies: Per-Token Static (PTS) quantization and
Joint Learning of Smoothing Scale and Step Size (JLSS). To the our best
knowledge, this is the first quantization study on Visual Mamba. PTQ4VM can be
applied to various Visual Mamba backbones, converting the pretrained model to a
quantized format in under 15 minutes without notable quality degradation.
Extensive experiments on large-scale classification and regression tasks
demonstrate its effectiveness, achieving up to 1.83x speedup on GPUs with
negligible accuracy loss compared to FP16. Our code is available at
https://github.com/YoungHyun197/ptq4vm.",2024-12-29,"Younghyun Cho, Changhun Lee, Seonggon Kim, Eunhyeok Park",http://arxiv.org/pdf/2412.20386v2,cs.LG
A Particle Algorithm for Mean-Field Variational Inference,"Variational inference is a fast and scalable alternative to Markov chain
Monte Carlo and has been widely applied to posterior inference tasks in
statistics and machine learning. A traditional approach for implementing
mean-field variational inference (MFVI) is coordinate ascent variational
inference (CAVI), which relies crucially on parametric assumptions on complete
conditionals. In this paper, we introduce a novel particle-based algorithm for
mean-field variational inference, which we term PArticle VI (PAVI). Notably,
our algorithm does not rely on parametric assumptions on complete conditionals,
and it applies to the nonparametric setting. We provide non-asymptotic
finite-particle convergence guarantee for our algorithm. To our knowledge, this
is the first end-to-end guarantee for particle-based MFVI.",2024-12-29,"Qiang Du, Kaizheng Wang, Edith Zhang, Chenyang Zhong",http://arxiv.org/pdf/2412.20385v2,cs.LG
Impact of Data Distribution on Fairness Guarantees in Equitable Deep Learning,"We present a comprehensive theoretical framework analyzing the relationship
between data distributions and fairness guarantees in equitable deep learning.
Our work establishes novel theoretical bounds that explicitly account for data
distribution heterogeneity across demographic groups, while introducing a
formal analysis framework that minimizes expected loss differences across these
groups. We derive comprehensive theoretical bounds for fairness errors and
convergence rates, and characterize how distributional differences between
groups affect the fundamental trade-off between fairness and accuracy. Through
extensive experiments on diverse datasets, including FairVision
(ophthalmology), CheXpert (chest X-rays), HAM10000 (dermatology), and FairFace
(facial recognition), we validate our theoretical findings and demonstrate that
differences in feature distributions across demographic groups significantly
impact model fairness, with performance disparities particularly pronounced in
racial categories. The theoretical bounds we derive crroborate these empirical
observations, providing insights into the fundamental limits of achieving
fairness in deep learning models when faced with heterogeneous data
distributions. This work advances our understanding of fairness in AI-based
diagnosis systems and provides a theoretical foundation for developing more
equitable algorithms. The code for analysis is publicly available via
\url{https://github.com/Harvard-Ophthalmology-AI-Lab/fairness_guarantees}.",2024-12-29,"Yan Luo, Congcong Wen, Min Shi, Hao Huang, Yi Fang, Mengyu Wang",http://arxiv.org/pdf/2412.20377v1,cs.LG
Scalable Bayesian Optimization via Focalized Sparse Gaussian Processes,"Bayesian optimization is an effective technique for black-box optimization,
but its applicability is typically limited to low-dimensional and small-budget
problems due to the cubic complexity of computing the Gaussian process (GP)
surrogate. While various approximate GP models have been employed to scale
Bayesian optimization to larger sample sizes, most suffer from overly-smooth
estimation and focus primarily on problems that allow for large online samples.
In this work, we argue that Bayesian optimization algorithms with sparse GPs
can more efficiently allocate their representational power to relevant regions
of the search space. To achieve this, we propose focalized GP, which leverages
a novel variational loss function to achieve stronger local prediction, as well
as FocalBO, which hierarchically optimizes the focalized GP acquisition
function over progressively smaller search spaces. Experimental results
demonstrate that FocalBO can efficiently leverage large amounts of offline and
online data to achieve state-of-the-art performance on robot morphology design
and to control a 585-dimensional musculoskeletal system.",2024-12-29,"Yunyue Wei, Vincent Zhuang, Saraswati Soedarmadji, Yanan Sui",http://arxiv.org/pdf/2412.20375v1,cs.LG
FairDiffusion: Enhancing Equity in Latent Diffusion Models via Fair Bayesian Perturbation,"Recent progress in generative AI, especially diffusion models, has
demonstrated significant utility in text-to-image synthesis. Particularly in
healthcare, these models offer immense potential in generating synthetic
datasets and training medical students. However, despite these strong
performances, it remains uncertain if the image generation quality is
consistent across different demographic subgroups. To address this critical
concern, we present the first comprehensive study on the fairness of medical
text-to-image diffusion models. Our extensive evaluations of the popular Stable
Diffusion model reveal significant disparities across gender, race, and
ethnicity. To mitigate these biases, we introduce FairDiffusion, an
equity-aware latent diffusion model that enhances fairness in both image
generation quality as well as the semantic correlation of clinical features. In
addition, we also design and curate FairGenMed, the first dataset for studying
the fairness of medical generative models. Complementing this effort, we
further evaluate FairDiffusion on two widely-used external medical datasets:
HAM10000 (dermatoscopic images) and CheXpert (chest X-rays) to demonstrate
FairDiffusion's effectiveness in addressing fairness concerns across diverse
medical imaging modalities. Together, FairDiffusion and FairGenMed
significantly advance research in fair generative learning, promoting equitable
benefits of generative AI in healthcare.",2024-12-29,"Yan Luo, Muhammad Osama Khan, Congcong Wen, Muhammad Muneeb Afzal, Titus Fidelis Wuermeling, Min Shi, Yu Tian, Yi Fang, Mengyu Wang",http://arxiv.org/pdf/2412.20374v2,cs.LG
A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data,"Drug repurposing identifies new therapeutic uses for existing drugs, reducing
the time and costs compared to traditional de novo drug discovery. Most
existing drug repurposing studies using real-world patient data often treat the
entire population as homogeneous, ignoring the heterogeneity of treatment
responses across patient subgroups. This approach may overlook promising drugs
that benefit specific subgroups but lack notable treatment effects across the
entire population, potentially limiting the number of repurposable candidates
identified. To address this, we introduce STEDR, a novel drug repurposing
framework that integrates subgroup analysis with treatment effect estimation.
Our approach first identifies repurposing candidates by emulating multiple
clinical trials on real-world patient data and then characterizes patient
subgroups by learning subgroup-specific treatment effects. We deploy \model to
Alzheimer's Disease (AD), a condition with few approved drugs and known
heterogeneity in treatment responses. We emulate trials for over one thousand
medications on a large-scale real-world database covering over 8 million
patients, identifying 14 drug candidates with beneficial effects to AD in
characterized subgroups. Experiments demonstrate STEDR's superior capability in
identifying repurposing candidates compared to existing approaches.
Additionally, our method can characterize clinically relevant patient subgroups
associated with important AD-related risk factors, paving the way for precision
drug repurposing.",2024-12-29,"Seungyeon Lee, Ruoqi Liu, Feixiong Cheng, Ping Zhang",http://arxiv.org/pdf/2412.20373v1,cs.LG
Accelerated regularized learning in finite N-person games,"Motivated by the success of Nesterov's accelerated gradient algorithm for
convex minimization problems, we examine whether it is possible to achieve
similar performance gains in the context of online learning in games. To that
end, we introduce a family of accelerated learning methods, which we call
""follow the accelerated leader"" (FTXL), and which incorporates the use of
momentum within the general framework of regularized learning - and, in
particular, the exponential/multiplicative weights algorithm and its variants.
Drawing inspiration and techniques from the continuous-time analysis of
Nesterov's algorithm, we show that FTXL converges locally to strict Nash
equilibria at a superlinear rate, achieving in this way an exponential speed-up
over vanilla regularized learning methods (which, by comparison, converge to
strict equilibria at a geometric, linear rate). Importantly, FTXL maintains its
superlinear convergence rate in a broad range of feedback structures, from
deterministic, full information models to stochastic, realization-based ones,
and even when run with bandit, payoff-based information, where players are only
able to observe their individual realized payoffs.",2024-12-29,"Kyriakos Lotidis, Angeliki Giannou, Panayotis Mertikopoulos, Nicholas Bambos",http://arxiv.org/pdf/2412.20365v1,cs.LG
Confidence Interval Construction and Conditional Variance Estimation with Dense ReLU Networks,"This paper addresses the problems of conditional variance estimation and
confidence interval construction in nonparametric regression using dense
networks with the Rectified Linear Unit (ReLU) activation function. We present
a residual-based framework for conditional variance estimation, deriving
nonasymptotic bounds for variance estimation under both heteroscedastic and
homoscedastic settings. We relax the sub-Gaussian noise assumption, allowing
the proposed bounds to accommodate sub-Exponential noise and beyond. Building
on this, for a ReLU neural network estimator, we derive non-asymptotic bounds
for both its conditional mean and variance estimation, representing the first
result for variance estimation using ReLU networks. Furthermore, we develop a
ReLU network based robust bootstrap procedure (Efron, 1992) for constructing
confidence intervals for the true mean that comes with a theoretical guarantee
on the coverage, providing a significant advancement in uncertainty
quantification and the construction of reliable confidence intervals in deep
learning settings.",2024-12-29,"Carlos Misael Madrid Padilla, Oscar Hernan Madrid Padilla, Yik Lun Kei, Zhi Zhang, Yanzhen Chen",http://arxiv.org/pdf/2412.20355v2,cs.LG
Training-free Heterogeneous Model Merging,"Model merging has attracted significant attention as a powerful paradigm for
model reuse, facilitating the integration of task-specific models into a
singular, versatile framework endowed with multifarious capabilities. Previous
studies, predominantly utilizing methods such as Weight Average (WA), have
shown that model merging can effectively leverage pretrained models without the
need for laborious retraining. However, the inherent heterogeneity among models
poses a substantial constraint on its applicability, particularly when
confronted with discrepancies in model architectures. To overcome this
challenge, we propose an innovative model merging framework designed for
heterogeneous models, encompassing both depth and width heterogeneity. To
address depth heterogeneity, we introduce a layer alignment strategy that
harmonizes model layers by segmenting deeper models, treating consecutive
layers with similar representations as a cohesive segment, thus enabling the
seamless merging of models with differing layer depths. For width
heterogeneity, we propose a novel elastic neuron zipping algorithm that
projects the weights from models of varying widths onto a common dimensional
space, eliminating the need for identical widths. Extensive experiments
validate the efficacy of these proposed methods, demonstrating that the merging
of structurally heterogeneous models can achieve performance levels comparable
to those of homogeneous merging, across both vision and NLP tasks. Our code is
publicly available at
https://github.com/zju-vipa/training_free_heterogeneous_model_merging.",2024-12-29,"Zhengqi Xu, Han Zheng, Jie Song, Li Sun, Mingli Song",http://arxiv.org/pdf/2501.00061v1,cs.LG
Safe Bayesian Optimization for the Control of High-Dimensional Embodied Systems,"Learning to move is a primary goal for animals and robots, where ensuring
safety is often important when optimizing control policies on the embodied
systems. For complex tasks such as the control of human or humanoid control,
the high-dimensional parameter space adds complexity to the safe optimization
effort. Current safe exploration algorithms exhibit inefficiency and may even
become infeasible with large high-dimensional input spaces. Furthermore,
existing high-dimensional constrained optimization methods neglect safety in
the search process. In this paper, we propose High-dimensional Safe Bayesian
Optimization with local optimistic exploration (HdSafeBO), a novel approach
designed to handle high-dimensional sampling problems under probabilistic
safety constraints. We introduce a local optimistic strategy to efficiently and
safely optimize the objective function, providing a probabilistic safety
guarantee and a cumulative safety violation bound. Through the use of isometric
embedding, HdSafeBO addresses problems ranging from a few hundred to several
thousand dimensions while maintaining safety guarantees. To our knowledge,
HdSafeBO is the first algorithm capable of optimizing the control of
high-dimensional musculoskeletal systems with high safety probability. We also
demonstrate the real-world applicability of HdSafeBO through its use in the
safe online optimization of neural stimulation induced human motion control.",2024-12-29,"Yunyue Wei, Zeji Yi, Hongda Li, Saraswati Soedarmadji, Yanan Sui",http://arxiv.org/pdf/2412.20350v1,cs.LG
Deep Learning in Image Classification: Evaluating VGG19's Performance on Complex Visual Data,"This study aims to explore the automatic classification method of pneumonia
X-ray images based on VGG19 deep convolutional neural network, and evaluate its
application effect in pneumonia diagnosis by comparing with classic models such
as SVM, XGBoost, MLP, and ResNet50. The experimental results show that VGG19
performs well in multiple indicators such as accuracy (92%), AUC (0.95), F1
score (0.90) and recall rate (0.87), which is better than other comparison
models, especially in image feature extraction and classification accuracy.
Although ResNet50 performs well in some indicators, it is slightly inferior to
VGG19 in recall rate and F1 score. Traditional machine learning models SVM and
XGBoost are obviously limited in image classification tasks, especially in
complex medical image analysis tasks, and their performance is relatively
mediocre. The research results show that deep learning, especially
convolutional neural networks, have significant advantages in medical image
classification tasks, especially in pneumonia X-ray image analysis, and can
provide efficient and accurate automatic diagnosis support. This research
provides strong technical support for the early detection of pneumonia and the
development of automated diagnosis systems and also lays the foundation for
further promoting the application and development of automated medical image
processing technology.",2024-12-29,"Weijie He, Tong Zhou, Yanlin Xiang, Yang Lin, Jiacheng Hu, Runyuan Bao",http://arxiv.org/pdf/2412.20345v1,cs.LG
Asynchronous Federated Clustering with Unknown Number of Clusters,"Federated Clustering (FC) is crucial to mining knowledge from unlabeled
non-Independent Identically Distributed (non-IID) data provided by multiple
clients while preserving their privacy. Most existing attempts learn cluster
distributions at local clients, and then securely pass the desensitized
information to the server for aggregation. However, some tricky but common FC
problems are still relatively unexplored, including the heterogeneity in terms
of clients' communication capacity and the unknown number of proper clusters
$k^*$. To further bridge the gap between FC and real application scenarios,
this paper first shows that the clients' communication asynchrony and unknown
$k^*$ are complex coupling problems, and then proposes an Asynchronous
Federated Cluster Learning (AFCL) method accordingly. It spreads the excessive
number of seed points to the clients as a learning medium and coordinates them
across the clients to form a consensus. To alleviate the distribution imbalance
cumulated due to the unforeseen asynchronous uploading from the heterogeneous
clients, we also design a balancing mechanism for seeds updating. As a result,
the seeds gradually adapt to each other to reveal a proper number of clusters.
Extensive experiments demonstrate the efficacy of AFCL.",2024-12-29,"Yunfan Zhang, Yiqun Zhang, Yang Lu, Mengke Li, Xi Chen, Yiu-ming Cheung",http://arxiv.org/pdf/2412.20341v1,cs.LG
Exploiting Hybrid Policy in Reinforcement Learning for Interpretable Temporal Logic Manipulation,"Reinforcement Learning (RL) based methods have been increasingly explored for
robot learning. However, RL based methods often suffer from low sampling
efficiency in the exploration phase, especially for long-horizon manipulation
tasks, and generally neglect the semantic information from the task level,
resulted in a delayed convergence or even tasks failure. To tackle these
challenges, we propose a Temporal-Logic-guided Hybrid policy framework (HyTL)
which leverages three-level decision layers to improve the agent's performance.
Specifically, the task specifications are encoded via linear temporal logic
(LTL) to improve performance and offer interpretability. And a waypoints
planning module is designed with the feedback from the LTL-encoded task level
as a high-level policy to improve the exploration efficiency. The middle-level
policy selects which behavior primitives to execute, and the low-level policy
specifies the corresponding parameters to interact with the environment. We
evaluate HyTL on four challenging manipulation tasks, which demonstrate its
effectiveness and interpretability. Our project is available at:
https://sites.google.com/view/hytl-0257/.",2024-12-29,"Hao Zhang, Hao Wang, Xiucai Huang, Wenrui Chen, Zhen Kan",http://arxiv.org/pdf/2412.20338v1,cs.LG
Mind the Data Gap: Bridging LLMs to Enterprise Data Integration,"Leading large language models (LLMs) are trained on public data. However,
most of the world's data is dark data that is not publicly accessible, mainly
in the form of private organizational or enterprise data. We show that the
performance of methods based on LLMs seriously degrades when tested on
real-world enterprise datasets. Current benchmarks, based on public data,
overestimate the performance of LLMs. We release a new benchmark dataset, the
GOBY Benchmark, to advance discovery in enterprise data integration. Based on
our experience with this enterprise benchmark, we propose techniques to uplift
the performance of LLMs on enterprise data, including (1) hierarchical
annotation, (2) runtime class-learning, and (3) ontology synthesis. We show
that, once these techniques are deployed, the performance on enterprise data
becomes on par with that of public data. The Goby benchmark can be obtained at
https://goby-benchmark.github.io/.",2024-12-29,"Moe Kayali, Fabian Wenz, Nesime Tatbul, Çağatay Demiralp",http://arxiv.org/pdf/2412.20331v1,cs.LG
Zeroth-Order Methods for Nonconvex Stochastic Problems with Decision-Dependent Distributions,"In this study, we consider an optimization problem with uncertainty dependent
on decision variables, which has recently attracted attention due to its
importance in machine learning and pricing applications. In this problem, the
gradient of the objective function cannot be obtained explicitly because the
decision-dependent distribution is unknown. Therefore, several zeroth-order
methods have been proposed, which obtain noisy objective values by sampling and
update the iterates. Although these existing methods have theoretical
convergence for optimization problems with decision-dependent uncertainty, they
require strong assumptions about the function and distribution or exhibit large
variances in their gradient estimators. To overcome these issues, we propose
two zeroth-order methods under mild assumptions. First, we develop a
zeroth-order method with a new one-point gradient estimator including a
variance reduction parameter. The proposed method updates the decision
variables while adjusting the variance reduction parameter. Second, we develop
a zeroth-order method with a two-point gradient estimator. There are situations
where only one-point estimators can be used, but if both one-point and
two-point estimators are available, it is more practical to use the two-point
estimator. As theoretical results, we show the convergence of our methods to
stationary points and provide the worst-case iteration and sample complexity
analysis. Our simulation experiments with real data on a retail service
application show that our methods output solutions with lower objective values
than the conventional zeroth-order methods.",2024-12-29,"Yuya Hikima, Akiko Takeda",http://arxiv.org/pdf/2412.20330v1,cs.LG
Protein Structure Prediction in the 3D HP Model Using Deep Reinforcement Learning,"We address protein structure prediction in the 3D Hydrophobic-Polar lattice
model through two novel deep learning architectures. For proteins under 36
residues, our hybrid reservoir-based model combines fixed random projections
with trainable deep layers, achieving optimal conformations with 25% fewer
training episodes. For longer sequences, we employ a long short-term memory
network with multi-headed attention, matching best-known energy values. Both
architectures leverage a stabilized Deep Q-Learning framework with experience
replay and target networks, demonstrating consistent achievement of optimal
conformations while significantly improving training efficiency compared to
existing methods.",2024-12-29,"Giovanny Espitia, Yui Tik Pang, James C. Gumbart",http://arxiv.org/pdf/2412.20329v1,cs.LG
EXAdam: The Power of Adaptive Cross-Moments,"This paper introduces EXAdam ($\textbf{EX}$tended $\textbf{Adam}$), a novel
optimization algorithm that builds upon the widely-used Adam optimizer. EXAdam
incorporates two key enhancements: (1) new debiasing terms for improved moment
estimation and (2) a gradient-based acceleration mechanism for increased
responsiveness to the current loss landscape. These innovations work
synergistically to address limitations of the original Adam algorithm,
potentially offering improved convergence properties, enhanced ability to
escape saddle points, and potentially greater robustness to hyperparameter
choices, though this requires further investigation. We provide a theoretical
analysis of EXAdam's components and their interactions, highlighting the
algorithm's potential advantages in navigating complex optimization landscapes.
Empirical evaluations demonstrate EXAdam's superiority over Adam, achieving
38.46% faster convergence and yielding improvements of 1.96%, 2.17%, and 1.17%
in training, validation, and testing accuracies, respectively, when applied to
a CNN trained on the CIFAR-10 dataset. While these results are promising,
further empirical validation across diverse tasks is essential to fully gauge
EXAdam's efficacy. Nevertheless, EXAdam represents a significant advancement in
adaptive optimization techniques, with promising implications for a wide range
of machine learning applications. This work aims to contribute to the ongoing
development of more efficient, adaptive, and universally applicable
optimization methods in the field of machine learning and artificial
intelligence.",2024-12-29,Ahmed M. Adly,http://arxiv.org/pdf/2412.20302v2,cs.LG
An experimental study on fairness-aware machine learning for credit scoring problem,"Digitalization of credit scoring is an essential requirement for financial
organizations and commercial banks, especially in the context of digital
transformation. Machine learning techniques are commonly used to evaluate
customers' creditworthiness. However, the predicted outcomes of machine
learning models can be biased toward protected attributes, such as race or
gender. Numerous fairness-aware machine learning models and fairness measures
have been proposed. Nevertheless, their performance in the context of credit
scoring has not been thoroughly investigated. In this paper, we present a
comprehensive experimental study of fairness-aware machine learning in credit
scoring. The study explores key aspects of credit scoring, including financial
datasets, predictive models, and fairness measures. We also provide a detailed
evaluation of fairness-aware predictive models and fairness measures on widely
used financial datasets.",2024-12-28,"Huyen Giang Thi Thu, Thang Viet Doan, Tai Le Quy",http://arxiv.org/pdf/2412.20298v1,cs.LG
Predicting Customer Lifetime Value Using Recurrent Neural Net,"This paper introduces a recurrent neural network approach for predicting user
lifetime value in Software as a Service (SaaS) applications. The approach
accounts for three connected time dimensions. These dimensions are the user
cohort (the date the user joined), user age-in-system (the time since the user
joined the service) and the calendar date the user is an age-in-system (i.e.,
contemporaneous information).The recurrent neural networks use a multi-cell
architecture, where each cell resembles a long short-term memory neural
network. The approach is applied to predicting both acquisition (new users) and
rolling (existing user) lifetime values for a variety of time horizons. It is
found to significantly improve median absolute percent error versus light
gradient boost models and Buy Until You Die models.",2024-12-28,"Huigang Chen, Edwin Ng, Slawek Smyl, Gavin Steininger",http://arxiv.org/pdf/2412.20295v2,cs.LG
An analytic theory of creativity in convolutional diffusion models,"We obtain the first analytic, interpretable and predictive theory of
creativity in convolutional diffusion models. Indeed, score-based diffusion
models can generate highly creative images that lie far from their training
data. But optimal score-matching theory suggests that these models should only
be able to produce memorized training examples. To reconcile this
theory-experiment gap, we identify two simple inductive biases, locality and
equivariance, that: (1) induce a form of combinatorial creativity by preventing
optimal score-matching; (2) result in a fully analytic, completely
mechanistically interpretable, equivariant local score (ELS) machine that, (3)
without any training can quantitatively predict the outputs of trained
convolution only diffusion models (like ResNets and UNets) with high accuracy
(median $r^2$ of $0.90, 0.91, 0.94$ on CIFAR10, FashionMNIST, and MNIST). Our
ELS machine reveals a locally consistent patch mosaic model of creativity, in
which diffusion models create exponentially many novel images by mixing and
matching different local training set patches in different image locations. Our
theory also partially predicts the outputs of pre-trained self-attention
enabled UNets (median $r^2 \sim 0.75$ on CIFAR10), revealing an intriguing role
for attention in carving out semantic coherence from local patch mosaics.",2024-12-28,"Mason Kamb, Surya Ganguli",http://arxiv.org/pdf/2412.20292v1,cs.LG
Transformer-Based Contrastive Meta-Learning For Low-Resource Generalizable Activity Recognition,"Deep learning has been widely adopted for human activity recognition (HAR)
while generalizing a trained model across diverse users and scenarios remains
challenging due to distribution shifts. The inherent low-resource challenge in
HAR, i.e., collecting and labeling adequate human-involved data can be
prohibitively costly, further raising the difficulty of tackling DS. We propose
TACO, a novel transformer-based contrastive meta-learning approach for
generalizable HAR. TACO addresses DS by synthesizing virtual target domains in
training with explicit consideration of model generalizability. Additionally,
we extract expressive feature with the attention mechanism of Transformer and
incorporate the supervised contrastive loss function within our
meta-optimization to enhance representation learning. Our evaluation
demonstrates that TACO achieves notably better performance across various
low-resource DS scenarios.",2024-12-28,"Junyao Wang, Mohammad Abdullah Al Faruque",http://arxiv.org/pdf/2412.20290v1,cs.LG
Causal Discovery on Dependent Binary Data,"The assumption of independence between observations (units) in a dataset is
prevalent across various methodologies for learning causal graphical models.
However, this assumption often finds itself in conflict with real-world data,
posing challenges to accurate structure learning. We propose a
decorrelation-based approach for causal graph learning on dependent binary
data, where the local conditional distribution is defined by a latent utility
model with dependent errors across units. We develop a pairwise maximum
likelihood method to estimate the covariance matrix for the dependence among
the units. Then, leveraging the estimated covariance matrix, we develop an
EM-like iterative algorithm to generate and decorrelate samples of the latent
utility variables, which serve as decorrelated data. Any standard causal
discovery method can be applied on the decorrelated data to learn the
underlying causal graph. We demonstrate that the proposed decorrelation
approach significantly improves the accuracy in causal graph learning, through
numerical experiments on both synthetic and real-world datasets.",2024-12-28,"Alex Chen, Qing Zhou",http://arxiv.org/pdf/2412.20289v1,cs.LG
Deep Generalized Schrödinger Bridges: From Image Generation to Solving Mean-Field Games,"Generalized Schr\""odinger Bridges (GSBs) are a fundamental mathematical
framework used to analyze the most likely particle evolution based on the
principle of least action including kinetic and potential energy. In parallel
to their well-established presence in the theoretical realms of quantum
mechanics and optimal transport, this paper focuses on an algorithmic
perspective, aiming to enhance practical usage. Our motivated observation is
that transportation problems with the optimality structures delineated by GSBs
are pervasive across various scientific domains, such as generative modeling in
machine learning, mean-field games in stochastic control, and more. Exploring
the intrinsic connection between the mathematical modeling of GSBs and the
modern algorithmic characterization therefore presents a crucial, yet untapped,
avenue. In this paper, we reinterpret GSBs as probabilistic models and
demonstrate that, with a delicate mathematical tool known as the nonlinear
Feynman-Kac lemma, rich algorithmic concepts, such as likelihoods, variational
gaps, and temporal differences, emerge naturally from the optimality structures
of GSBs. The resulting computational framework, driven by deep learning and
neural networks, operates in a fully continuous state space (i.e., mesh-free)
and satisfies distribution constraints, setting it apart from prior numerical
solvers relying on spatial discretization or constraint relaxation. We
demonstrate the efficacy of our method in generative modeling and mean-field
games, highlighting its transformative applications at the intersection of
mathematical modeling, stochastic process, control, and machine learning.",2024-12-28,"Guan-Horng Liu, Tianrong Chen, Evangelos A. Theodorou",http://arxiv.org/pdf/2412.20279v1,cs.LG
Towards General Purpose Robots at Scale: Lifelong Learning and Learning to Use Memory,"The widespread success of artificial intelligence in fields like natural
language processing and computer vision has not yet fully transferred to
robotics, where progress is hindered by the lack of large-scale training data
and the complexity of real-world tasks. To address this, many robot learning
researchers are pushing to get robots deployed at scale in everyday
unstructured environments like our homes to initiate a data flywheel. While
current robot learning systems are effective for certain short-horizon tasks,
they are not designed to autonomously operate over long time horizons in
unstructured environments. This thesis focuses on addressing two key challenges
for robots operating over long time horizons: memory and lifelong learning.
  We propose two novel methods to advance these capabilities. First, we
introduce t-DGR, a trajectory-based deep generative replay method that achieves
state-of-the-art performance on Continual World benchmarks, advancing lifelong
learning. Second, we develop a framework that leverages human demonstrations to
teach agents effective memory utilization, improving learning efficiency and
success rates on Memory Gym tasks. Finally, we discuss future directions for
achieving the lifelong learning and memory capabilities necessary for robots to
function at scale in real-world settings.",2024-12-28,William Yue,http://arxiv.org/pdf/2501.10395v1,cs.LG
TeLU Activation Function for Fast and Stable Deep Learning,"We propose the Hyperbolic Tangent Exponential Linear Unit (TeLU), a neural
network hidden activation function defined as TeLU(x)=xtanh(exp(x)). TeLU's
design is grounded in the core principles of key activation functions,
achieving strong convergence by closely approximating the identity function in
its active region while effectively mitigating the vanishing gradient problem
in its saturating region. Its simple formulation enhances computational
efficiency, leading to improvements in scalability and convergence speed.
Unlike many modern activation functions, TeLU seamlessly combines the
simplicity and effectiveness of ReLU with the smoothness and analytic
properties essential for learning stability in deep neural networks. TeLU's
ability to mimic the behavior and optimal hyperparameter settings of ReLU,
while introducing the benefits of smoothness and curvature, makes it an ideal
drop-in replacement. Its analytic nature positions TeLU as a powerful universal
approximator, enhancing both robustness and generalization across a multitude
of experiments. We rigorously validate these claims through theoretical
analysis and experimental validation, demonstrating TeLU's performance across
challenging benchmarks; including ResNet18 on ImageNet, Dynamic-Pooling
Transformers on Text8, and Recurrent Neural Networks (RNNs) on the Penn
TreeBank dataset. These results highlight TeLU's potential to set a new
standard in activation functions, driving more efficient and stable learning in
deep neural networks, thereby accelerating scientific discoveries across
various fields.",2024-12-28,"Alfredo Fernandez, Ankur Mali",http://arxiv.org/pdf/2412.20269v2,cs.LG
"Towards Ideal Temporal Graph Neural Networks: Evaluations and Conclusions after 10,000 GPU Hours","Temporal Graph Neural Networks (TGNNs) have emerged as powerful tools for
modeling dynamic interactions across various domains. The design space of TGNNs
is notably complex, given the unique challenges in runtime efficiency and
scalability raised by the evolving nature of temporal graphs. We contend that
many of the existing works on TGNN modeling inadequately explore the design
space, leading to suboptimal designs. Viewing TGNN models through a
performance-focused lens often obstructs a deeper understanding of the
advantages and disadvantages of each technique. Specifically, benchmarking
efforts inherently evaluate models in their original designs and
implementations, resulting in unclear accuracy comparisons and misleading
runtime. To address these shortcomings, we propose a practical comparative
evaluation framework that performs a design space search across well-known TGNN
modules based on a unified, optimized code implementation. Using our framework,
we make the first efforts towards addressing three critical questions in TGNN
design, spending over 10,000 GPU hours: (1) investigating the efficiency of
TGNN module designs, (2) analyzing how the effectiveness of these modules
correlates with dataset patterns, and (3) exploring the interplay between
multiple modules. Key outcomes of this directed investigative approach include
demonstrating that the most recent neighbor sampling and attention aggregator
outperform uniform neighbor sampling and MLP-Mixer aggregator; Assessing static
node memory as an effective node memory alternative, and showing that the
choice between static or dynamic node memory should be based on the repetition
patterns in the dataset. Our in-depth analysis of the interplay between TGNN
modules and dataset patterns should provide a deeper insight into TGNN
performance along with potential research directions for designing more general
and effective TGNNs.",2024-12-28,"Yuxin Yang, Hongkuan Zhou, Rajgopal Kannan, Viktor Prasanna",http://arxiv.org/pdf/2412.20256v1,cs.LG
An Anomaly Detection System Based on Generative Classifiers for Controller Area Network,"As electronic systems become increasingly complex and prevalent in modern
vehicles, securing onboard networks is crucial, particularly as many of these
systems are safety-critical. Researchers have demonstrated that modern vehicles
are susceptible to various types of attacks, enabling attackers to gain control
and compromise safety-critical electronic systems. Consequently, several
Intrusion Detection Systems (IDSs) have been proposed in the literature to
detect such cyber-attacks on vehicles. This paper introduces a novel generative
classifier-based Intrusion Detection System (IDS) designed for anomaly
detection in automotive networks, specifically focusing on the Controller Area
Network (CAN). Leveraging variational Bayes, our proposed IDS utilizes a deep
latent variable model to construct a causal graph for conditional
probabilities. An auto-encoder architecture is utilized to build the classifier
to estimate conditional probabilities, which contribute to the final prediction
probabilities through Bayesian inference. Comparative evaluations against
state-of-the-art IDSs on a public Car-hacking dataset highlight our proposed
classifier's superior performance in improving detection accuracy and F1-score.
The proposed IDS demonstrates its efficacy by outperforming existing models
with limited training data, providing enhanced security assurance for
automotive systems.",2024-12-28,"Chunheng Zhao, Stefano Longari, Michele Carminati, Pierluigi Pisu",http://arxiv.org/pdf/2412.20255v1,cs.LG
Election of Collaborators via Reinforcement Learning for Federated Brain Tumor Segmentation,"Federated learning (FL) enables collaborative model training across
decentralized datasets while preserving data privacy. However, optimally
selecting participating collaborators in dynamic FL environments remains
challenging. We present RL-HSimAgg, a novel reinforcement learning (RL) and
similarity-weighted aggregation (simAgg) algorithm using harmonic mean to
manage outlier data points. This paper proposes applying multi-armed bandit
algorithms to improve collaborator selection and model generalization. By
balancing exploration-exploitation trade-offs, these RL methods can promote
resource-efficient training with diverse datasets. We demonstrate the
effectiveness of Epsilon-greedy (EG) and upper confidence bound (UCB)
algorithms for federated brain lesion segmentation. In simulation experiments
on internal and external validation sets, RL-HSimAgg with UCB collaborator
outperformed the EG method across all metrics, achieving higher Dice scores for
Enhancing Tumor (0.7334 vs 0.6797), Tumor Core (0.7432 vs 0.6821), and Whole
Tumor (0.8252 vs 0.7931) segmentation. Therefore, for the Federated Tumor
Segmentation Challenge (FeTS 2024), we consider UCB as our primary client
selection approach in federated Glioblastoma lesion segmentation of multi-modal
MRIs. In conclusion, our research demonstrates that RL-based collaborator
management, e.g. using UCB, can potentially improve model robustness and
flexibility in distributed learning environments, particularly in domains like
brain tumor segmentation.",2024-12-28,"Muhammad Irfan Khan, Elina Kontio, Suleiman A. Khan, Mojtaba Jafaritadi",http://arxiv.org/pdf/2412.20253v1,cs.LG
Recommender Engine Driven Client Selection in Federated Brain Tumor Segmentation,"This study presents a robust and efficient client selection protocol designed
to optimize the Federated Learning (FL) process for the Federated Tumor
Segmentation Challenge (FeTS 2024). In the evolving landscape of FL, the
judicious selection of collaborators emerges as a critical determinant for the
success and efficiency of collective learning endeavors, particularly in
domains requiring high precision. This work introduces a recommender engine
framework based on non-negative matrix factorization (NNMF) and a hybrid
aggregation approach that blends content-based and collaborative filtering.
This method intelligently analyzes historical performance, expertise, and other
relevant metrics to identify the most suitable collaborators. This approach not
only addresses the cold start problem where new or inactive collaborators pose
selection challenges due to limited data but also significantly improves the
precision and efficiency of the FL process. Additionally, we propose harmonic
similarity weight aggregation (HSimAgg) for adaptive aggregation of model
parameters. We utilized a dataset comprising 1,251 multi-parametric magnetic
resonance imaging (mpMRI) scans from individuals diagnosed with glioblastoma
(GBM) for training purposes and an additional 219 mpMRI scans for external
evaluations. Our federated tumor segmentation approach achieved dice scores of
0.7298, 0.7424, and 0.8218 for enhancing tumor (ET), tumor core (TC), and whole
tumor (WT) segmentation tasks respectively on the external validation set. In
conclusion, this research demonstrates that selecting collaborators with
expertise aligned to specific tasks, like brain tumor segmentation, improves
the effectiveness of FL networks.",2024-12-28,"Muhammad Irfan Khan, Elina Kontio, Suleiman A. Khan, Mojtaba Jafaritadi",http://arxiv.org/pdf/2412.20250v1,cs.LG
Machine and Deep Learning for Credit Scoring: A compliant approach,"Credit Scoring is one of the problems banks and financial institutions have
to solve on a daily basis. If the state-of-the-art research in Machine and Deep
Learning for finance has reached interesting results about Credit Scoring
models, usage of such models in a heavily regulated context such as the one in
banks has never been done so far. Our work is thus a tentative to challenge the
current regulatory status-quo and introduce new BASEL 2 and 3 compliant
techniques, while still answering the Federal Reserve Bank and the European
Central Bank requirements. With the help of Gradient Boosting Machines (mainly
XGBoost) we challenge an actual model used by BANK A for scoring through the
door Auto Loan applicants. We prove that the usage of such algorithms for
Credit Scoring models drastically improves performance and default capture
rate. Furthermore, we leverage the power of Shapley Values to prove that these
relatively simple models are not as black-box as the current regulatory system
thinks they are, and we attempt to explain the model outputs and Credit Scores
within the BANK A Model Design and Validation framework",2024-12-28,Abdollah Rida,http://arxiv.org/pdf/2412.20225v1,cs.LG
IMSSA: Deploying modern state-space models on memristive in-memory compute hardware,"Processing long temporal sequences is a key challenge in deep learning. In
recent years, Transformers have become state-of-the-art for this task, but
suffer from excessive memory requirements due to the need to explicitly store
the sequences. To address this issue, structured state-space sequential (S4)
models recently emerged, offering a fixed memory state while still enabling the
processing of very long sequence contexts. The recurrent linear update of the
state in these models makes them highly efficient on modern graphics processing
units (GPU) by unrolling the recurrence into a convolution. However, this
approach demands significant memory and massively parallel computation, which
is only available on the latest GPUs. In this work, we aim to bring the power
of S4 models to edge hardware by significantly reducing the size and
computational demand of an S4D model through quantization-aware training, even
achieving ternary weights for a simple real-world task. To this end, we extend
conventional quantization-aware training to tailor it for analog in-memory
compute hardware. We then demonstrate the deployment of recurrent S4D kernels
on memrisitve crossbar arrays, enabling their computation in an in-memory
compute fashion. To our knowledge, this is the first implementation of S4
kernels on in-memory compute hardware.",2024-12-28,"Sebastian Siegel, Ming-Jay Yang, John-Paul Strachan",http://arxiv.org/pdf/2412.20215v1,cs.LG
Generative Regression Based Watch Time Prediction for Short-Video Recommendation,"Watch time prediction (WTP) has emerged as a pivotal task in short video
recommendation systems, designed to quantify user engagement through continuous
interaction modeling. Predicting users' watch times on videos often encounters
fundamental challenges, including wide value ranges and imbalanced data
distributions, which can lead to significant estimation bias when directly
applying regression techniques. Recent studies have attempted to address these
issues by converting the continuous watch time estimation into an ordinal
regression task. While these methods demonstrate partial effectiveness, they
exhibit notable limitations: (1) the discretization process frequently relies
on bucket partitioning, inherently reducing prediction flexibility and accuracy
and (2) the interdependencies among different partition intervals remain
underutilized, missing opportunities for effective error correction.
  Inspired by language modeling paradigms, we propose a novel Generative
Regression (GR) framework that reformulates WTP as a sequence generation task.
Our approach employs \textit{structural discretization} to enable nearly
lossless value reconstruction while maintaining prediction fidelity. Through
carefully designed vocabulary construction and label encoding schemes, each
watch time is bijectively mapped to a token sequence. To mitigate the
training-inference discrepancy caused by teacher-forcing, we introduce a
\textit{curriculum learning with embedding mixup} strategy that gradually
transitions from guided to free-generation modes. We evaluate our method
against state-of-the-art approaches on two public datasets and one industrial
dataset. We also perform online A/B testing on the Kuaishou App to confirm the
real-world effectiveness. The results conclusively show that GR outperforms
existing techniques significantly.",2024-12-28,"Hongxu Ma, Kai Tian, Tao Zhang, Xuefeng Zhang, Han Zhou, Chunjie Chen, Han Li, Jihong Guan, Shuigeng Zhou",http://arxiv.org/pdf/2412.20211v3,cs.LG
"Towards Real-Time 2D Mapping: Harnessing Drones, AI, and Computer Vision for Advanced Insights","This paper presents an advanced mapping system that combines drone imagery
with machine learning and computer vision to overcome challenges in speed,
accuracy, and adaptability across diverse terrains. By automating processes
like feature detection, image matching, and stitching, the system produces
seamless, high-resolution maps with minimal latency, offering strategic
advantages in defense operations. Developed in Python, the system utilizes
OpenCV for image processing, NumPy for efficient computations, and
Concurrent[dot]futures for parallel execution. ORB (Oriented FAST and Rotated
BRIEF) is employed for feature detection, while FLANN (Fast Library for
Approximate Nearest Neighbors) ensures accurate keypoint matching. Homography
transformations align overlapping images, resulting in distortion-free maps in
real time. This automation eliminates manual intervention, enabling live
updates essential in rapidly changing environments. Designed for versatility,
the system performs reliably under various lighting conditions and rugged
terrains, making it highly suitable for aerospace and defense applications.
Testing has shown notable improvements in processing speed and accuracy
compared to conventional methods, enhancing situational awareness and informed
decision-making. This scalable solution leverages cutting-edge technologies to
provide actionable, reliable data for mission-critical operations.",2024-12-28,Bharath Kumar Agnur,http://arxiv.org/pdf/2412.20210v2,cs.LG
No-regret learning in harmonic games: Extrapolation in the face of conflicting interests,"The long-run behavior of multi-agent learning - and, in particular, no-regret
learning - is relatively well-understood in potential games, where players have
aligned interests. By contrast, in harmonic games - the strategic counterpart
of potential games, where players have conflicting interests - very little is
known outside the narrow subclass of 2-player zero-sum games with a fully-mixed
equilibrium. Our paper seeks to partially fill this gap by focusing on the full
class of (generalized) harmonic games and examining the convergence properties
of follow-the-regularized-leader (FTRL), the most widely studied class of
no-regret learning schemes. As a first result, we show that the continuous-time
dynamics of FTRL are Poincar\'e recurrent, that is, they return arbitrarily
close to their starting point infinitely often, and hence fail to converge. In
discrete time, the standard, ""vanilla"" implementation of FTRL may lead to even
worse outcomes, eventually trapping the players in a perpetual cycle of
best-responses. However, if FTRL is augmented with a suitable extrapolation
step - which includes as special cases the optimistic and mirror-prox variants
of FTRL - we show that learning converges to a Nash equilibrium from any
initial condition, and all players are guaranteed at most O(1) regret. These
results provide an in-depth understanding of no-regret learning in harmonic
games, nesting prior work on 2-player zero-sum games, and showing at a high
level that harmonic games are the canonical complement of potential games, not
only from a strategic, but also from a dynamic viewpoint.",2024-12-28,"Davide Legacci, Panayotis Mertikopoulos, Christos H. Papadimitriou, Georgios Piliouras, Bary S. R. Pradelski",http://arxiv.org/pdf/2412.20203v1,cs.LG
Federated Unlearning with Gradient Descent and Conflict Mitigation,"Federated Learning (FL) has received much attention in recent years. However,
although clients are not required to share their data in FL, the global model
itself can implicitly remember clients' local data. Therefore, it's necessary
to effectively remove the target client's data from the FL global model to ease
the risk of privacy leakage and implement ``the right to be forgotten"".
Federated Unlearning (FU) has been considered a promising way to remove data
without full retraining. But the model utility easily suffers significant
reduction during unlearning due to the gradient conflicts. Furthermore, when
conducting the post-training to recover the model utility, the model is prone
to move back and revert what has already been unlearned. To address these
issues, we propose Federated Unlearning with Orthogonal Steepest Descent
(FedOSD). We first design an unlearning Cross-Entropy loss to overcome the
convergence issue of the gradient ascent. A steepest descent direction for
unlearning is then calculated in the condition of being non-conflicting with
other clients' gradients and closest to the target client's gradient. This
benefits to efficiently unlearn and mitigate the model utility reduction. After
unlearning, we recover the model utility by maintaining the achievement of
unlearning. Finally, extensive experiments in several FL scenarios verify that
FedOSD outperforms the SOTA FU algorithms in terms of unlearning and model
utility.",2024-12-28,"Zibin Pan, Zhichao Wang, Chi Li, Kaiyan Zheng, Boqi Wang, Xiaoying Tang, Junhua Zhao",http://arxiv.org/pdf/2412.20200v1,cs.LG
Lower bounds on transformers with infinite precision,"In this note, we use the VC dimension technique to prove the first lower
bound against one-layer softmax transformers with infinite precision. We do so
for two tasks: function composition, considered by Peng, Narayanan, and
Papadimitriou, and the SUM$_2$ task, considered by Sanford, Hsu, and Telgarsky.",2024-12-28,Alexander Kozachinskiy,http://arxiv.org/pdf/2412.20195v1,cs.LG
Imitation Learning from Suboptimal Demonstrations via Meta-Learning An Action Ranker,"A major bottleneck in imitation learning is the requirement of a large number
of expert demonstrations, which can be expensive or inaccessible. Learning from
supplementary demonstrations without strict quality requirements has emerged as
a powerful paradigm to address this challenge. However, previous methods often
fail to fully utilize their potential by discarding non-expert data. Our key
insight is that even demonstrations that fall outside the expert distribution
but outperform the learned policy can enhance policy performance. To utilize
this potential, we propose a novel approach named imitation learning via
meta-learning an action ranker (ILMAR). ILMAR implements weighted behavior
cloning (weighted BC) on a limited set of expert demonstrations along with
supplementary demonstrations. It utilizes the functional of the advantage
function to selectively integrate knowledge from the supplementary
demonstrations. To make more effective use of supplementary demonstrations, we
introduce meta-goal in ILMAR to optimize the functional of the advantage
function by explicitly minimizing the distance between the current policy and
the expert policy. Comprehensive experiments using extensive tasks demonstrate
that ILMAR significantly outperforms previous methods in handling suboptimal
demonstrations. Code is available at https://github.com/F-GOD6/ILMAR.",2024-12-28,"Jiangdong Fan, Hongcai He, Paul Weng, Hui Xu, Jie Shao",http://arxiv.org/pdf/2412.20193v1,cs.LG
Learning physical unknowns from hydrodynamic shock and material interface features in ICF capsule implosions,"In high energy density physics (HEDP) and inertial confinement fusion (ICF),
predictive modeling is complicated by uncertainty in parameters that
characterize various aspects of the modeled system, such as those
characterizing material properties, equation of state (EOS), opacities, and
initial conditions. Typically, however, these parameters are not directly
observable. What is observed instead is a time sequence of radiographic
projections using X-rays. In this work, we define a set of sparse hydrodynamic
features derived from the outgoing shock profile and outer material edge, which
can be obtained from radiographic measurements, to directly infer such
parameters. Our machine learning (ML)-based methodology involves a pipeline of
two architectures, a radiograph-to-features network (R2FNet) and a
features-to-parameters network (F2PNet), that are trained independently and
later combined to approximate a posterior distribution for the parameters from
radiographs. We show that the estimated parameters can be used in a
hydrodynamics code to obtain density fields and hydrodynamic shock and outer
edge features that are consistent with the data. Finally, we demonstrate that
features resulting from an unknown EOS model can be successfully mapped onto
parameters of a chosen analytical EOS model, implying that network predictions
are learning physics, with a degree of invariance to the underlying choice of
EOS model.",2024-12-28,"Daniel A. Serino, Evan Bell, Marc Klasky, Ben S. Southworth, Balasubramanya Nadiga, Trevor Wilcox, Oleg Korobkin",http://arxiv.org/pdf/2412.20192v1,cs.LG
Accurate Coresets for Latent Variable Models and Regularized Regression,"Accurate coresets are a weighted subset of the original dataset, ensuring a
model trained on the accurate coreset maintains the same level of accuracy as a
model trained on the full dataset. Primarily, these coresets have been studied
for a limited range of machine learning models. In this paper, we introduce a
unified framework for constructing accurate coresets. Using this framework, we
present accurate coreset construction algorithms for general problems,
including a wide range of latent variable model problems and
$\ell_p$-regularized $\ell_p$-regression. For latent variable models, our
coreset size is $O\left(\mathrm{poly}(k)\right)$, where $k$ is the number of
latent variables. For $\ell_p$-regularized $\ell_p$-regression, our algorithm
captures the reduction of model complexity due to regularization, resulting in
a coreset whose size is always smaller than $d^{p}$ for a regularization
parameter $\lambda > 0$. Here, $d$ is the dimension of the input points. This
inherently improves the size of the accurate coreset for ridge regression. We
substantiate our theoretical findings with extensive experimental evaluations
on real datasets.",2024-12-28,"Sanskar Ranjan, Supratim Shit",http://arxiv.org/pdf/2412.20189v1,cs.LG
Equation discovery framework EPDE: Towards a better equation discovery,"Equation discovery methods hold promise for extracting knowledge from
physics-related data. However, existing approaches often require substantial
prior information that significantly reduces the amount of knowledge extracted.
In this paper, we enhance the EPDE algorithm -- an evolutionary
optimization-based discovery framework. In contrast to methods like SINDy,
which rely on pre-defined libraries of terms and linearities, our approach
generates terms using fundamental building blocks such as elementary functions
and individual differentials. Within evolutionary optimization, we may improve
the computation of the fitness function as is done in gradient methods and
enhance the optimization algorithm itself. By incorporating multi-objective
optimization, we effectively explore the search space, yielding more robust
equation extraction, even when dealing with complex experimental data. We
validate our algorithm's noise resilience and overall performance by comparing
its results with those from the state-of-the-art equation discovery framework
SINDy.",2024-12-28,"Mikhail Maslyaev, Alexander Hvatov",http://arxiv.org/pdf/2501.14768v1,cs.LG
Pushing the Envelope of Low-Bit LLM via Dynamic Error Compensation,"Quantization of Large Language Models (LLMs) has recently gained popularity,
particularly for on-device settings with limited hardware resources. While
efficient, quantization inevitably degrades model quality, especially in
aggressive low-bit settings such as 3-bit and 4-bit precision. In this paper,
we propose QDEC, an inference scheme that improves the quality of low-bit LLMs
while preserving the key benefits of quantization: GPU memory savings and
inference latency reduction. QDEC stores the residual matrix -- the difference
between full-precision and quantized weights -- in CPU, and dynamically fetches
the residuals for only a small portion of the weights. This portion corresponds
to the salient channels, marked by activation outliers, with the fetched
residuals helping to correct quantization errors in these channels. Salient
channels are identified dynamically at each decoding step by analyzing the
input activations -- this allows for the adaptation to the dynamic nature of
activation distribution, and thus maximizes the effectiveness of error
compensation. We demonstrate the effectiveness of QDEC by augmenting
state-of-the-art quantization methods. For example, QDEC reduces the perplexity
of a 3-bit Llama-3-8B-Instruct model from 10.15 to 9.12 -- outperforming its
3.5-bit counterpart -- while adding less than 0.0003\% to GPU memory usage and
incurring only a 1.7\% inference slowdown on NVIDIA RTX 4050 Mobile GPU. The
code will be publicly available soon.",2024-12-28,"Yeonhong Park, Jake Hyun, Hojoon Kim, Jae W. Lee",http://arxiv.org/pdf/2412.20185v1,cs.LG
Debiased Nonparametric Regression for Statistical Inference and Distributionally Robustness,"This study proposes a debiasing method for smooth nonparametric estimators.
While machine learning techniques such as random forests and neural networks
have demonstrated strong predictive performance, their theoretical properties
remain relatively underexplored. In particular, many modern algorithms lack
guarantees of pointwise and uniform risk convergence, as well as asymptotic
normality. These properties are essential for statistical inference and robust
estimation and have been well-established for classical methods such as
Nadaraya-Watson regression. To ensure these properties for various
nonparametric regression estimators, we introduce a model-free debiasing
method. By incorporating a correction term that estimates the conditional
expected residual of the original estimator, or equivalently, its estimation
error, into the initial nonparametric regression estimator, we obtain a
debiased estimator that satisfies pointwise and uniform risk convergence, along
with asymptotic normality, under mild smoothness conditions. These properties
facilitate statistical inference and enhance robustness to covariate shift,
making the method broadly applicable to a wide range of nonparametric
regression problems.",2024-12-28,Masahiro Kato,http://arxiv.org/pdf/2412.20173v3,cs.LG
Real-time Calibration Model for Low-cost Sensor in Fine-grained Time series,"Precise measurements from sensors are crucial, but data is usually collected
from low-cost, low-tech systems, which are often inaccurate. Thus, they require
further calibrations. To that end, we first identify three requirements for
effective calibration under practical low-tech sensor conditions. Based on the
requirements, we develop a model called TESLA, Transformer for effective sensor
calibration utilizing logarithmic-binned attention. TESLA uses a
high-performance deep learning model, Transformers, to calibrate and capture
non-linear components. At its core, it employs logarithmic binning to minimize
attention complexity. TESLA achieves consistent real-time calibration, even
with longer sequences and finer-grained time series in hardware-constrained
systems. Experiments show that TESLA outperforms existing novel deep learning
and newly crafted linear models in accuracy, calibration speed, and energy
efficiency.",2024-12-28,"Seokho Ahn, Hyungjin Kim, Sungbok Shin, Young-Duk Seo",http://arxiv.org/pdf/2412.20170v1,cs.LG
VisTabNet: Adapting Vision Transformers for Tabular Data,"Although deep learning models have had great success in natural language
processing and computer vision, we do not observe comparable improvements in
the case of tabular data, which is still the most common data type used in
biological, industrial and financial applications. In particular, it is
challenging to transfer large-scale pre-trained models to downstream tasks
defined on small tabular datasets. To address this, we propose VisTabNet -- a
cross-modal transfer learning method, which allows for adapting Vision
Transformer (ViT) with pre-trained weights to process tabular data. By
projecting tabular inputs to patch embeddings acceptable by ViT, we can
directly apply a pre-trained Transformer Encoder to tabular inputs. This
approach eliminates the conceptual cost of designing a suitable architecture
for processing tabular data, while reducing the computational cost of training
the model from scratch. Experimental results on multiple small tabular datasets
(less than 1k samples) demonstrate VisTabNet's superiority, outperforming both
traditional ensemble methods and recent deep learning models. The proposed
method goes beyond conventional transfer learning practice and shows that
pre-trained image models can be transferred to solve tabular problems,
extending the boundaries of transfer learning. We share our example
implementation as a GitHub repository available at
https://github.com/wwydmanski/VisTabNet.",2024-12-28,"Witold Wydmański, Ulvi Movsum-zada, Jacek Tabor, Marek Śmieja",http://arxiv.org/pdf/2501.00057v2,cs.LG
Transforming CCTV cameras into NO$_2$ sensors at city scale for adaptive policymaking,"Air pollution in cities, especially NO\textsubscript{2}, is linked to
numerous health problems, ranging from mortality to mental health challenges
and attention deficits in children. While cities globally have initiated
policies to curtail emissions, real-time monitoring remains challenging due to
limited environmental sensors and their inconsistent distribution. This gap
hinders the creation of adaptive urban policies that respond to the sequence of
events and daily activities affecting pollution in cities. Here, we demonstrate
how city CCTV cameras can act as a pseudo-NO\textsubscript{2} sensors. Using a
predictive graph deep model, we utilised traffic flow from London's cameras in
addition to environmental and spatial factors, generating NO\textsubscript{2}
predictions from over 133 million frames. Our analysis of London's mobility
patterns unveiled critical spatiotemporal connections, showing how specific
traffic patterns affect NO\textsubscript{2} levels, sometimes with temporal
lags of up to 6 hours. For instance, if trucks only drive at night, their
effects on NO\textsubscript{2} levels are most likely to be seen in the morning
when people commute. These findings cast doubt on the efficacy of some of the
urban policies currently being implemented to reduce pollution. By leveraging
existing camera infrastructure and our introduced methods, city planners and
policymakers could cost-effectively monitor and mitigate the impact of
NO\textsubscript{2} and other pollutants.",2024-12-28,"Mohamed R. Ibrahim, Terry Lyons",http://arxiv.org/pdf/2501.00056v1,cs.LG
TradingAgents: Multi-Agents LLM Financial Trading Framework,"Significant progress has been made in automated problem-solving using
societies of agents powered by large language models (LLMs). In finance,
efforts have largely focused on single-agent systems handling specific tasks or
multi-agent frameworks independently gathering data. However, multi-agent
systems' potential to replicate real-world trading firms' collaborative
dynamics remains underexplored. TradingAgents proposes a novel stock trading
framework inspired by trading firms, featuring LLM-powered agents in
specialized roles such as fundamental analysts, sentiment analysts, technical
analysts, and traders with varied risk profiles. The framework includes Bull
and Bear researcher agents assessing market conditions, a risk management team
monitoring exposure, and traders synthesizing insights from debates and
historical data to make informed decisions. By simulating a dynamic,
collaborative trading environment, this framework aims to improve trading
performance. Detailed architecture and extensive experiments reveal its
superiority over baseline models, with notable improvements in cumulative
returns, Sharpe ratio, and maximum drawdown, highlighting the potential of
multi-agent LLM frameworks in financial trading. TradingAgents is available at
https://github.com/TauricResearch.",2024-12-28,"Yijia Xiao, Edward Sun, Di Luo, Wei Wang",http://arxiv.org/pdf/2412.20138v6,cs.LG
Gradient Descent Methods for Regularized Optimization,"Regularization is a widely recognized technique in mathematical optimization.
It can be used to smooth out objective functions, refine the feasible solution
set, or prevent overfitting in machine learning models. Due to its simplicity
and robustness, the gradient descent (GD) method is one of the primary methods
used for numerical optimization of differentiable objective functions. However,
GD is not well-suited for solving $\ell^1$ regularized optimization problems
since these problems are non-differentiable at zero, causing iteration updates
to oscillate or fail to converge. Instead, a more effective version of GD,
called the proximal gradient descent employs a technique known as
soft-thresholding to shrink the iteration updates toward zero, thus enabling
sparsity in the solution. Motivated by the widespread applications of proximal
GD in sparse and low-rank recovery across various engineering disciplines, we
provide an overview of the GD and proximal GD methods for solving regularized
optimization problems. Furthermore, this paper proposes a novel algorithm for
the proximal GD method that incorporates a variable step size. Unlike
conventional proximal GD, which uses a fixed step size based on the global
Lipschitz constant, our method estimates the Lipschitz constant locally at each
iteration and uses its reciprocal as the step size. This eliminates the need
for a global Lipschitz constant, which can be impractical to compute. Numerical
experiments we performed on synthetic and real-data sets show notable
performance improvement of the proposed method compared to the conventional
proximal GD with constant step size, both in terms of number of iterations and
in time requirements.",2024-12-28,"Filip Nikolovski, Irena Stojkovska, Katerina Hadzi-Velkova Saneva, Zoran Hadzi-Velkov",http://arxiv.org/pdf/2412.20115v1,cs.LG
SyncDiff: Synchronized Motion Diffusion for Multi-Body Human-Object Interaction Synthesis,"Synthesizing realistic human-object interaction motions is a critical problem
in VR/AR and human animation. Unlike the commonly studied scenarios involving a
single human or hand interacting with one object, we address a more generic
multi-body setting with arbitrary numbers of humans, hands, and objects. This
complexity introduces significant challenges in synchronizing motions due to
the high correlations and mutual influences among bodies. To address these
challenges, we introduce SyncDiff, a novel method for multi-body interaction
synthesis using a synchronized motion diffusion strategy. SyncDiff employs a
single diffusion model to capture the joint distribution of multi-body motions.
To enhance motion fidelity, we propose a frequency-domain motion decomposition
scheme. Additionally, we introduce a new set of alignment scores to emphasize
the synchronization of different body motions. SyncDiff jointly optimizes both
data sample likelihood and alignment likelihood through an explicit
synchronization strategy. Extensive experiments across four datasets with
various multi-body configurations demonstrate the superiority of SyncDiff over
existing state-of-the-art motion synthesis methods.",2024-12-28,"Wenkun He, Yun Liu, Ruitao Liu, Li Yi",http://arxiv.org/pdf/2412.20104v4,cs.LG
From Worms to Mice: Homeostasis Maybe All You Need,"In this brief and speculative commentary, we explore ideas inspired by neural
networks in machine learning, proposing that a simple neural XOR motif,
involving both excitatory and inhibitory connections, may provide the basis for
a relevant mode of plasticity in neural circuits of living organisms, with
homeostasis as the sole guiding principle. This XOR motif simply signals the
discrepancy between incoming signals and reference signals, thereby providing a
basis for a loss function in learning neural circuits, and at the same time
regulating homeostasis by halting the propagation of these incoming signals.
The core motif uses a 4:1 ratio of excitatory to inhibitory neurons, and
supports broader neural patterns such as the well-known 'winner takes all'
(WTA) mechanism. We examined the prevalence of the XOR motif in the published
connectomes of various organisms with increasing complexity, and found that it
ranges from tens (in C. elegans) to millions (in several Drosophila neuropils)
and more than tens of millions (in mouse V1 visual cortex). If validated, our
hypothesis identifies two of the three key components in analogy to machine
learning models: the architecture and the loss function. And we propose that a
relevant type of biological neural plasticity is simply driven by a basic
control or regulatory system, which has persisted and adapted despite the
increasing complexity of organisms throughout evolution.",2024-12-28,Jesus Marco de Lucas,http://arxiv.org/pdf/2412.20090v1,cs.LG
MAFT: Efficient Model-Agnostic Fairness Testing for Deep Neural Networks via Zero-Order Gradient Search,"Deep neural networks (DNNs) have shown powerful performance in various
applications and are increasingly being used in decision-making systems.
However, concerns about fairness in DNNs always persist. Some efficient
white-box fairness testing methods about individual fairness have been
proposed. Nevertheless, the development of black-box methods has stagnated, and
the performance of existing methods is far behind that of white-box methods. In
this paper, we propose a novel black-box individual fairness testing method
called Model-Agnostic Fairness Testing (MAFT). By leveraging MAFT,
practitioners can effectively identify and address discrimination in DL models,
regardless of the specific algorithm or architecture employed. Our approach
adopts lightweight procedures such as gradient estimation and attribute
perturbation rather than non-trivial procedures like symbol execution,
rendering it significantly more scalable and applicable than existing methods.
We demonstrate that MAFT achieves the same effectiveness as state-of-the-art
white-box methods whilst improving the applicability to large-scale networks.
Compared to existing black-box approaches, our approach demonstrates
distinguished performance in discovering fairness violations w.r.t
effectiveness (approximately 14.69 times) and efficiency (approximately 32.58
times).",2024-12-28,"Zhaohui Wang, Min Zhang, Jingran Yang, Bojie Shao, Min Zhang",http://arxiv.org/pdf/2412.20086v1,cs.LG
On the Compositional Generalization of Multimodal LLMs for Medical Imaging,"Multimodal large language models (MLLMs) hold significant potential in the
medical field, but their capabilities are often limited by insufficient data in
certain medical domains, highlighting the need for understanding what kinds of
images can be used by MLLMs for generalization. Current research suggests that
multi-task training outperforms single-task as different tasks can benefit each
other, but they often overlook the internal relationships within these tasks,
providing limited guidance on selecting datasets to enhance specific tasks. To
analyze this phenomenon, we attempted to employ compositional generalization
(CG)-the ability of models to understand novel combinations by recombining
learned elements-as a guiding framework. Since medical images can be precisely
defined by Modality, Anatomical area, and Task, naturally providing an
environment for exploring CG. Therefore, we assembled 106 medical datasets to
create Med-MAT for comprehensive experiments. The experiments confirmed that
MLLMs can use CG to understand unseen medical images and identified CG as one
of the main drivers of the generalization observed in multi-task training.
Additionally, further studies demonstrated that CG effectively supports
datasets with limited data and delivers consistent performance across different
backbones, highlighting its versatility and broad applicability. Med-MAT is
publicly available at https://github.com/FreedomIntelligence/Med-MAT.",2024-12-28,"Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang",http://arxiv.org/pdf/2412.20070v1,cs.LG
Self-Calibrated Dual Contrasting for Annotation-Efficient Bacteria Raman Spectroscopy Clustering and Classification,"Raman scattering is based on molecular vibration spectroscopy and provides a
powerful technology for pathogenic bacteria diagnosis using the unique
molecular fingerprint information of a substance. The integration of deep
learning technology has significantly improved the efficiency and accuracy of
intelligent Raman spectroscopy (RS) recognition. However, the current RS
recognition methods based on deep neural networks still require the annotation
of a large amount of spectral data, which is labor-intensive. This paper
presents a novel annotation-efficient Self-Calibrated Dual Contrasting (SCDC)
method for RS recognition that operates effectively with few or no annotation.
Our core motivation is to represent the spectrum from two different
perspectives in two distinct subspaces: embedding and category. The embedding
perspective captures instance-level information, while the category perspective
reflects category-level information. Accordingly, we have implemented a dual
contrastive learning approach from two perspectives to obtain discriminative
representations, which are applicable for Raman spectroscopy recognition under
both unsupervised and semi-supervised learning conditions. Furthermore, a
self-calibration mechanism is proposed to enhance robustness. Validation of the
identification task on three large-scale bacterial Raman spectroscopy datasets
demonstrates that our SCDC method achieves robust recognition performance with
very few (5$\%$ or 10$\%$) or no annotations, highlighting the potential of the
proposed method for biospectral identification in annotation-efficient clinical
scenarios.",2024-12-28,"Haiming Yao, Wei Luo, Tao Zhou, Ang Gao, Xue Wang",http://arxiv.org/pdf/2412.20060v1,cs.LG
Hawkes based Representation Learning for Reasoning over Scale-free Community-structured Temporal Knowledge Graphs,"Temporal knowledge graph (TKG) reasoning has become a hot topic due to its
great value in many practical tasks. The key to TKG reasoning is modeling the
structural information and evolutional patterns of the TKGs. While great
efforts have been devoted to TKG reasoning, the structural and evolutional
characteristics of real-world networks have not been considered. In the aspect
of structure, real-world networks usually exhibit clear community structure and
scale-free (long-tailed distribution) properties. In the aspect of evolution,
the impact of an event decays with the time elapsing. In this paper, we propose
a novel TKG reasoning model called Hawkes process-based Evolutional
Representation Learning Network (HERLN), which learns structural information
and evolutional patterns of a TKG simultaneously, considering the
characteristics of real-world networks: community structure, scale-free and
temporal decaying. First, we find communities in the input TKG to make the
encoding get more similar intra-community embeddings. Second, we design a
Hawkes process-based relational graph convolutional network to cope with the
event impact-decaying phenomenon. Third, we design a conditional decoding
method to alleviate biases towards frequent entities caused by long-tailed
distribution. Experimental results show that HERLN achieves significant
improvements over the state-of-the-art models.",2024-12-28,"Yuwei Du, Xinyue Liu, Wenxin Liang, Linlin Zong, Xianchao Zhang",http://arxiv.org/pdf/2501.01974v1,cs.LG
SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection,"While modern visual recognition systems have made significant advancements,
many continue to struggle with the open problem of learning from few exemplars.
This paper focuses on the task of object detection in the setting where object
classes follow a natural long-tailed distribution. Existing methods for
long-tailed detection resort to external ImageNet labels to augment the
low-shot training instances. However, such dependency on a large labeled
database has limited utility in practical scenarios. We propose a versatile and
scalable approach to leverage optional unlabeled images, which are easy to
collect without the burden of human annotations. Our SimLTD framework is
straightforward and intuitive, and consists of three simple steps: (1)
pre-training on abundant head classes; (2) transfer learning on scarce tail
classes; and (3) fine-tuning on a sampled set of both head and tail classes.
Our approach can be viewed as an improved head-to-tail model transfer paradigm
without the added complexities of meta-learning or knowledge distillation, as
was required in past research. By harnessing supplementary unlabeled images,
without extra image labels, SimLTD establishes new record results on the
challenging LVIS v1 benchmark across both supervised and semi-supervised
settings.",2024-12-28,Phi Vu Tran,http://arxiv.org/pdf/2412.20047v2,cs.LG
A Greedy Strategy for Graph Cut,"We propose a Greedy strategy to solve the problem of Graph Cut, called GGC.
It starts from the state where each data sample is regarded as a cluster and
dynamically merges the two clusters which reduces the value of the global
objective function the most until the required number of clusters is obtained,
and the monotonicity of the sequence of objective function values is proved. To
reduce the computational complexity of GGC, only mergers between clusters and
their neighbors are considered. Therefore, GGC has a nearly linear
computational complexity with respect to the number of samples. Also, unlike
other algorithms, due to the greedy strategy, the solution of the proposed
algorithm is unique. In other words, its performance is not affected by
randomness. We apply the proposed method to solve the problem of normalized cut
which is a widely concerned graph cut problem. Extensive experiments show that
better solutions can often be achieved compared to the traditional two-stage
optimization algorithm (eigendecomposition + k-means), on the normalized cut
problem. In addition, the performance of GGC also has advantages compared to
several state-of-the-art clustering algorithms.",2024-12-28,"Feiping Nie, Shenfei Pei, Zengwei Zheng, Rong Wang, Xuelong Li",http://arxiv.org/pdf/2412.20035v1,cs.LG
Global Search of Optimal Spacecraft Trajectories using Amortization and Deep Generative Models,"Preliminary spacecraft trajectory optimization is a parameter dependent
global search problem that aims to provide a set of solutions that are of high
quality and diverse. In the case of numerical solution, it is dependent on the
original optimal control problem, the choice of a control transcription, and
the behavior of a gradient based numerical solver. In this paper we formulate
the parameterized global search problem as the task of sampling a conditional
probability distribution with support on the neighborhoods of local basins of
attraction to the high quality solutions. The conditional distribution is
learned and represented using deep generative models that allow for prediction
of how the local basins change as parameters vary. The approach is benchmarked
on a low thrust spacecraft trajectory optimization problem in the circular
restricted three-body problem, showing significant speed-up over a simple
multi-start method and vanilla machine learning approaches. The paper also
provides an in-depth analysis of the multi-modal funnel structure of a
low-thrust spacecraft trajectory optimization problem.",2024-12-28,"Ryne Beeson, Anjian Li, Amlan Sinha",http://arxiv.org/pdf/2412.20023v1,cs.LG
AdvAnchor: Enhancing Diffusion Model Unlearning with Adversarial Anchors,"Security concerns surrounding text-to-image diffusion models have driven
researchers to unlearn inappropriate concepts through fine-tuning. Recent
fine-tuning methods typically align the prediction distributions of unsafe
prompts with those of predefined text anchors. However, these techniques
exhibit a considerable performance trade-off between eliminating undesirable
concepts and preserving other concepts. In this paper, we systematically
analyze the impact of diverse text anchors on unlearning performance. Guided by
this analysis, we propose AdvAnchor, a novel approach that generates
adversarial anchors to alleviate the trade-off issue. These adversarial anchors
are crafted to closely resemble the embeddings of undesirable concepts to
maintain overall model performance, while selectively excluding defining
attributes of these concepts for effective erasure. Extensive experiments
demonstrate that AdvAnchor outperforms state-of-the-art methods. Our code is
publicly available at https://anonymous.4open.science/r/AdvAnchor.",2024-12-28,"Mengnan Zhao, Lihe Zhang, Xingyi Yang, Tianhang Zheng, Baocai Yin",http://arxiv.org/pdf/2501.00054v1,cs.LG
Calibre: Towards Fair and Accurate Personalized Federated Learning with Self-Supervised Learning,"In the context of personalized federated learning, existing approaches train
a global model to extract transferable representations, based on which any
client could train personalized models with a limited number of data samples.
Self-supervised learning is considered a promising direction as the global
model it produces is generic and facilitates personalization for all clients
fairly. However, when data is heterogeneous across clients, the global model
trained using SSL is unable to learn high-quality personalized models. In this
paper, we show that when the global model is trained with SSL without
modifications, its produced representations have fuzzy class boundaries. As a
result, personalized learning within each client produces models with low
accuracy. In order to improve SSL towards better accuracy without sacrificing
its advantage in fairness, we propose Calibre, a new personalized federated
learning framework designed to calibrate SSL representations by maintaining a
suitable balance between more generic and more client-specific representations.
Calibre is designed based on theoretically-sound properties, and introduces (1)
a client-specific prototype loss as an auxiliary training objective; and (2) an
aggregation algorithm guided by such prototypes across clients. Our
experimental results in an extensive array of non-i.i.d.~settings show that
Calibre achieves state-of-the-art performance in terms of both mean accuracy
and fairness across clients. Code repo:
https://github.com/TL-System/plato/tree/main/examples/ssl/calibre.",2024-12-28,"Sijia Chen, Ningxin Su, Baochun Li",http://arxiv.org/pdf/2412.20020v1,cs.LG
A Nearly Optimal Single Loop Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness,"This paper studies the problem of stochastic bilevel optimization where the
upper-level function is nonconvex with potentially unbounded smoothness and the
lower-level function is strongly convex. This problem is motivated by
meta-learning applied to sequential data, such as text classification using
recurrent neural networks, where the smoothness constant of the upper-level
loss function scales linearly with the gradient norm and can be potentially
unbounded. Existing algorithm crucially relies on the nested loop design, which
requires significant tuning efforts and is not practical. In this paper, we
address this issue by proposing a Single Loop bIlevel oPtimizer (SLIP). The
proposed algorithm first updates the lower-level variable by a few steps of
stochastic gradient descent, and then simultaneously updates the upper-level
variable by normalized stochastic gradient descent with momentum and the
lower-level variable by stochastic gradient descent. Under standard
assumptions, we show that our algorithm finds an $\epsilon$-stationary point
within $\widetilde{O}(1/\epsilon^4)$\footnote{Here $\widetilde{O}(\cdot)$
compresses logarithmic factors of $1/\epsilon$ and $1/\delta$, where
$\delta\in(0,1)$ denotes the failure probability.} oracle calls of stochastic
gradient or Hessian-vector product, both in expectation and with high
probability. This complexity result is nearly optimal up to logarithmic factors
without mean-square smoothness of the stochastic gradient oracle. Our proof
relies on (i) a refined characterization and control of the lower-level
variable and (ii) establishing a novel connection between bilevel optimization
and stochastic optimization under distributional drift. Our experiments on
various tasks show that our algorithm significantly outperforms strong
baselines in bilevel optimization.",2024-12-28,"Xiaochuan Gong, Jie Hao, Mingrui Liu",http://arxiv.org/pdf/2412.20017v1,cs.LG
ProtCLIP: Function-Informed Protein Multi-Modal Learning,"Multi-modality pre-training paradigm that aligns protein sequences and
biological descriptions has learned general protein representations and
achieved promising performance in various downstream applications. However,
these works were still unable to replicate the extraordinary success of
language-supervised visual foundation models due to the ineffective usage of
aligned protein-text paired data and the lack of an effective function-informed
pre-training paradigm. To address these issues, this paper curates a
large-scale protein-text paired dataset called ProtAnno with a property-driven
sampling strategy, and introduces a novel function-informed protein
pre-training paradigm. Specifically, the sampling strategy determines selecting
probability based on the sample confidence and property coverage, balancing the
data quality and data quantity in face of large-scale noisy data. Furthermore,
motivated by significance of the protein specific functional mechanism, the
proposed paradigm explicitly model protein static and dynamic functional
segments by two segment-wise pre-training objectives, injecting fine-grained
information in a function-informed manner. Leveraging all these innovations, we
develop ProtCLIP, a multi-modality foundation model that comprehensively
represents function-aware protein embeddings. On 22 different protein
benchmarks within 5 types, including protein functionality classification,
mutation effect prediction, cross-modal transformation, semantic similarity
inference and protein-protein interaction prediction, our ProtCLIP consistently
achieves SOTA performance, with remarkable improvements of 75% on average in
five cross-modal transformation benchmarks, 59.9% in GO-CC and 39.7% in GO-BP
protein function prediction. The experimental results verify the extraordinary
potential of ProtCLIP serving as the protein multi-modality foundation model.",2024-12-28,"Hanjing Zhou, Mingze Yin, Wei Wu, Mingyang Li, Kun Fu, Jintai Chen, Jian Wu, Zheng Wang",http://arxiv.org/pdf/2412.20014v1,cs.LG
Adversarial Robustness for Deep Learning-based Wildfire Prediction Models,"Rapidly growing wildfires have recently devastated societal assets, exposing
a critical need for early warning systems to expedite relief efforts. Smoke
detection using camera-based Deep Neural Networks (DNNs) offers a promising
solution for wildfire prediction. However, the rarity of smoke across time and
space limits training data, raising model overfitting and bias concerns.
Current DNNs, primarily Convolutional Neural Networks (CNNs) and transformers,
complicate robustness evaluation due to architectural differences. To address
these challenges, we introduce WARP (Wildfire Adversarial Robustness
Procedure), the first model-agnostic framework for evaluating wildfire
detection models' adversarial robustness. WARP addresses inherent limitations
in data diversity by generating adversarial examples through image-global and
-local perturbations. Global and local attacks superimpose Gaussian noise and
PNG patches onto image inputs, respectively; this suits both CNNs and
transformers while generating realistic adversarial scenarios. Using WARP, we
assessed real-time CNNs and Transformers, uncovering key vulnerabilities. At
times, transformers exhibited over 70% precision degradation under global
attacks, while both models generally struggled to differentiate cloud-like PNG
patches from real smoke during local attacks. To enhance model robustness, we
proposed four wildfire-oriented data augmentation techniques based on WARP's
methodology and results, which diversify smoke image data and improve model
precision and robustness. These advancements represent a substantial step
toward developing a reliable early wildfire warning system, which may be our
first safeguard against wildfire destruction.",2024-12-28,"Ryo Ide, Lei Yang",http://arxiv.org/pdf/2412.20006v3,cs.LG
OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System,"We introduce OneKE, a dockerized schema-guided knowledge extraction system,
which can extract knowledge from the Web and raw PDF Books, and support various
domains (science, news, etc.). Specifically, we design OneKE with multiple
agents and a configure knowledge base. Different agents perform their
respective roles, enabling support for various extraction scenarios. The
configure knowledge base facilitates schema configuration, error case debugging
and correction, further improving the performance. Empirical evaluations on
benchmark datasets demonstrate OneKE's efficacy, while case studies further
elucidate its adaptability to diverse tasks across multiple domains,
highlighting its potential for broad applications. We have open-sourced the
Code at https://github.com/zjunlp/OneKE and released a Video at
http://oneke.openkg.cn/demo.mp4.",2024-12-28,"Yujie Luo, Xiangyuan Ru, Kangwei Liu, Lin Yuan, Mengshu Sun, Ningyu Zhang, Lei Liang, Zhiqiang Zhang, Jun Zhou, Lanning Wei, Da Zheng, Haofen Wang, Huajun Chen",http://arxiv.org/pdf/2412.20005v2,cs.LG
From Generalist to Specialist: A Survey of Large Language Models for Chemistry,"Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.",2024-12-28,"Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen",http://arxiv.org/pdf/2412.19994v1,cs.LG
Discrete Curvature Graph Information Bottleneck,"Graph neural networks(GNNs) have been demonstrated to depend on whether the
node effective information is sufficiently passing. Discrete curvature (Ricci
curvature) is used to study graph connectivity and information propagation
efficiency with a geometric perspective, and has been raised in recent years to
explore the efficient message-passing structure of GNNs. However, most
empirical studies are based on directly observed graph structures or heuristic
topological assumptions and lack in-depth exploration of underlying optimal
information transport structures for downstream tasks. We suggest that graph
curvature optimization is more in-depth and essential than directly rewiring or
learning for graph structure with richer message-passing characterization and
better information transport interpretability. From both graph geometry and
information theory perspectives, we propose the novel Discrete Curvature Graph
Information Bottleneck (CurvGIB) framework to optimize the information
transport structure and learn better node representations simultaneously.
CurvGIB advances the Variational Information Bottleneck (VIB) principle for
Ricci curvature optimization to learn the optimal information transport pattern
for specific downstream tasks. The learned Ricci curvature is used to refine
the optimal transport structure of the graph, and the node representation is
fully and efficiently learned. Moreover, for the computational complexity of
Ricci curvature differentiation, we combine Ricci flow and VIB to deduce a
curvature optimization approximation to form a tractable IB objective function.
Extensive experiments on various datasets demonstrate the superior
effectiveness and interpretability of CurvGIB.",2024-12-28,"Xingcheng Fu, Jian Wang, Yisen Gao, Qingyun Sun, Haonan Yuan, Jianxin Li, Xianxian Li",http://arxiv.org/pdf/2412.19993v1,cs.LG
A Robust Federated Learning Framework for Undependable Devices at Scale,"In a federated learning (FL) system, many devices, such as smartphones, are
often undependable (e.g., frequently disconnected from WiFi) during training.
Existing FL frameworks always assume a dependable environment and exclude
undependable devices from training, leading to poor model performance and
resource wastage. In this paper, we propose FLUDE to effectively deal with
undependable environments. First, FLUDE assesses the dependability of devices
based on the probability distribution of their historical behaviors (e.g., the
likelihood of successfully completing training). Based on this assessment,
FLUDE adaptively selects devices with high dependability for training. To
mitigate resource wastage during the training phase, FLUDE maintains a model
cache on each device, aiming to preserve the latest training state for later
use in case local training on an undependable device is interrupted. Moreover,
FLUDE proposes a staleness-aware strategy to judiciously distribute the global
model to a subset of devices, thus significantly reducing resource wastage
while maintaining model performance. We have implemented FLUDE on two physical
platforms with 120 smartphones and NVIDIA Jetson devices. Extensive
experimental results demonstrate that FLUDE can effectively improve model
performance and resource efficiency of FL training in undependable
environments.",2024-12-28,"Shilong Wang, Jianchun Liu, Hongli Xu, Chunming Qiao, Huarong Deng, Qiuye Zheng, Jiantao Gong",http://arxiv.org/pdf/2412.19991v1,cs.LG
Caesar: A Low-deviation Compression Approach for Efficient Federated Learning,"Compression is an efficient way to relieve the tremendous communication
overhead of federated learning (FL) systems. However, for the existing works,
the information loss under compression will lead to unexpected model/gradient
deviation for the FL training, significantly degrading the training
performance, especially under the challenges of data heterogeneity and model
obsolescence. To strike a delicate trade-off between model accuracy and traffic
cost, we propose Caesar, a novel FL framework with a low-deviation compression
approach. For the global model download, we design a greedy method to optimize
the compression ratio for each device based on the staleness of the local
model, ensuring a precise initial model for local training. Regarding the local
gradient upload, we utilize the device's local data properties (\ie, sample
volume and label distribution) to quantify its local gradient's importance,
which then guides the determination of the gradient compression ratio. Besides,
with the fine-grained batch size optimization, Caesar can significantly
diminish the devices' idle waiting time under the synchronized barrier. We have
implemented Caesar on two physical platforms with 40 smartphones and 80 NVIDIA
Jetson devices. Extensive results show that Caesar can reduce the traffic costs
by about 25.54%$\thicksim$37.88% compared to the compression-based baselines
with the same target accuracy, while incurring only a 0.68% degradation in
final test accuracy relative to the full-precision communication.",2024-12-28,"Jiaming Yan, Jianchun Liu, Hongli Xu, Liusheng Huang, Jiantao Gong, Xudong Liu, Kun Hou",http://arxiv.org/pdf/2412.19989v1,cs.LG
Delayed Random Partial Gradient Averaging for Federated Learning,"Federated learning (FL) is a distributed machine learning paradigm that
enables multiple clients to train a shared model collaboratively while
preserving privacy. However, the scaling of real-world FL systems is often
limited by two communication bottlenecks:(a) while the increasing computing
power of edge devices enables the deployment of large-scale Deep Neural
Networks (DNNs), the limited bandwidth constraints frequent transmissions over
large DNNs; and (b) high latency cost greatly degrades the performance of FL.
In light of these bottlenecks, we propose a Delayed Random Partial Gradient
Averaging (DPGA) to enhance FL. Under DPGA, clients only share partial local
model gradients with the server. The size of the shared part in a local model
is determined by the update rate, which is coarsely initialized and
subsequently refined over the temporal dimension. Moreover, DPGA largely
reduces the system run time by enabling computation in parallel with
communication. We conduct experiments on non-IID CIFAR-10/100 to demonstrate
the efficacy of our method.",2024-12-28,Xinyi Hu,http://arxiv.org/pdf/2412.19987v1,cs.LG
The Fifth International Verification of Neural Networks Competition (VNN-COMP 2024): Summary and Results,"This report summarizes the 5th International Verification of Neural Networks
Competition (VNN-COMP 2024), held as a part of the 7th International Symposium
on AI Verification (SAIV), that was collocated with the 36th International
Conference on Computer-Aided Verification (CAV). VNN-COMP is held annually to
facilitate the fair and objective comparison of state-of-the-art neural network
verification tools, encourage the standardization of tool interfaces, and bring
together the neural network verification community. To this end, standardized
formats for networks (ONNX) and specification (VNN-LIB) were defined, tools
were evaluated on equal-cost hardware (using an automatic evaluation pipeline
based on AWS instances), and tool parameters were chosen by the participants
before the final test sets were made public. In the 2024 iteration, 8 teams
participated on a diverse set of 12 regular and 8 extended benchmarks. This
report summarizes the rules, benchmarks, participating tools, results, and
lessons learned from this iteration of this competition.",2024-12-28,"Christopher Brix, Stanley Bak, Taylor T. Johnson, Haoze Wu",http://arxiv.org/pdf/2412.19985v1,cs.LG
Explainable Semantic Federated Learning Enabled Industrial Edge Network for Fire Surveillance,"In fire surveillance, Industrial Internet of Things (IIoT) devices require
transmitting large monitoring data frequently, which leads to huge consumption
of spectrum resources. Hence, we propose an Industrial Edge Semantic Network
(IESN) to allow IIoT devices to send warnings through Semantic communication
(SC). Thus, we should consider (1) Data privacy and security. (2) SC model
adaptation for heterogeneous devices. (3) Explainability of semantics.
Therefore, first, we present an eXplainable Semantic Federated Learning (XSFL)
to train the SC model, thus ensuring data privacy and security. Then, we
present an Adaptive Client Training (ACT) strategy to provide a specific SC
model for each device according to its Fisher information matrix, thus
overcoming the heterogeneity. Next, an Explainable SC (ESC) mechanism is
designed, which introduces a leakyReLU-based activation mapping to explain the
relationship between the extracted semantics and monitoring data. Finally,
simulation results demonstrate the effectiveness of XSFL.",2024-12-28,"Li Dong, Yubo Peng, Feibo Jiang, Kezhi Wang, Kun Yang",http://arxiv.org/pdf/2412.19979v1,cs.LG
Implementing Trust in Non-Small Cell Lung Cancer Diagnosis with a Conformalized Uncertainty-Aware AI Framework in Whole-Slide Images,"Ensuring trustworthiness is fundamental to the development of artificial
intelligence (AI) that is considered societally responsible, particularly in
cancer diagnostics, where a misdiagnosis can have dire consequences. Current
digital pathology AI models lack systematic solutions to address
trustworthiness concerns arising from model limitations and data discrepancies
between model deployment and development environments. To address this issue,
we developed TRUECAM, a framework designed to ensure both data and model
trustworthiness in non-small cell lung cancer subtyping with whole-slide
images. TRUECAM integrates 1) a spectral-normalized neural Gaussian process for
identifying out-of-scope inputs and 2) an ambiguity-guided elimination of tiles
to filter out highly ambiguous regions, addressing data trustworthiness, as
well as 3) conformal prediction to ensure controlled error rates. We
systematically evaluated the framework across multiple large-scale cancer
datasets, leveraging both task-specific and foundation models, illustrate that
an AI model wrapped with TRUECAM significantly outperforms models that lack
such guidance, in terms of classification accuracy, robustness,
interpretability, and data efficiency, while also achieving improvements in
fairness. These findings highlight TRUECAM as a versatile wrapper framework for
digital pathology AI models with diverse architectural designs, promoting their
responsible and effective applications in real-world settings.",2024-12-28,"Xiaoge Zhang, Tao Wang, Chao Yan, Fedaa Najdawi, Kai Zhou, Yuan Ma, Yiu-ming Cheung, Bradley A. Malin",http://arxiv.org/pdf/2501.00053v1,cs.LG
Efficient and Scalable Deep Reinforcement Learning for Mean Field Control Games,"Mean Field Control Games (MFCGs) provide a powerful theoretical framework for
analyzing systems of infinitely many interacting agents, blending elements from
Mean Field Games (MFGs) and Mean Field Control (MFC). However, solving the
coupled Hamilton-Jacobi-Bellman and Fokker-Planck equations that characterize
MFCG equilibria remains a significant computational challenge, particularly in
high-dimensional or complex environments.
  This paper presents a scalable deep Reinforcement Learning (RL) approach to
approximate equilibrium solutions of MFCGs. Building on previous works, We
reformulate the infinite-agent stochastic control problem as a Markov Decision
Process, where each representative agent interacts with the evolving mean field
distribution. We use the actor-critic based algorithm from a previous paper
(Angiuli et.al., 2024) as the baseline and propose several versions of more
scalable and efficient algorithms, utilizing techniques including parallel
sample collection (batching); mini-batching; target network; proximal policy
optimization (PPO); generalized advantage estimation (GAE); and entropy
regularization. By leveraging these techniques, we effectively improved the
efficiency, scalability, and training stability of the baseline algorithm.
  We evaluate our method on a linear-quadratic benchmark problem, where an
analytical solution to the MFCG equilibrium is available. Our results show that
some versions of our proposed approach achieve faster convergence and closely
approximate the theoretical optimum, outperforming the baseline algorithm by an
order of magnitude in sample efficiency. Our work lays the foundation for
adapting deep RL to solve more complicated MFCGs closely related to real life,
such as large-scale autonomous transportation systems, multi-firm economic
competition, and inter-bank borrowing problems.",2024-12-28,"Nianli Peng, Yilin Wang",http://arxiv.org/pdf/2501.00052v1,cs.LG
MobileNetV2: A lightweight classification model for home-based sleep apnea screening,"This study proposes a novel lightweight neural network model leveraging
features extracted from electrocardiogram (ECG) and respiratory signals for
early OSA screening. ECG signals are used to generate feature spectrograms to
predict sleep stages, while respiratory signals are employed to detect
sleep-related breathing abnormalities. By integrating these predictions, the
method calculates the apnea-hypopnea index (AHI) with enhanced accuracy,
facilitating precise OSA diagnosis.
  The method was validated on three publicly available sleep apnea databases:
the Apnea-ECG database, the UCDDB dataset, and the MIT-BIH Polysomnographic
database. Results showed an overall OSA detection accuracy of 0.978,
highlighting the model's robustness. Respiratory event classification achieved
an accuracy of 0.969 and an area under the receiver operating characteristic
curve (ROC-AUC) of 0.98. For sleep stage classification, in UCDDB dataset, the
ROC-AUC exceeded 0.85 across all stages, with recall for Sleep reaching 0.906
and specificity for REM and Wake states at 0.956 and 0.937, respectively.
  This study underscores the potential of integrating lightweight neural
networks with multi-signal analysis for accurate, portable, and cost-effective
OSA screening, paving the way for broader adoption in home-based and wearable
health monitoring systems.",2024-12-28,"Hui Pan, Yanxuan Yu, Jilun Ye, Xu Zhang",http://arxiv.org/pdf/2412.19967v2,cs.LG
DDD-GenDT: Dynamic Data-driven Generative Digital Twin Framework,"Digital twin (DT) technology has emerged as a transformative approach to
simulate, predict, and optimize the behavior of physical systems, with
applications that span manufacturing, healthcare, climate science, and more.
However, the development of DT models often faces challenges such as high data
requirements, integration complexity, and limited adaptability to dynamic
changes in physical systems. This paper presents a new method inspired by
dynamic data-driven applications systems (DDDAS), called the dynamic
data-driven generative of digital twins framework (DDD-GenDT), which combines
the physical system with LLM, allowing LLM to act as DT to interact with the
physical system operating status and generate the corresponding physical
behaviors. We apply DDD-GenDT to the computer numerical control (CNC) machining
process, and we use the spindle current measurement data in the NASA milling
wear data set as an example to enable LLMs to forecast the physical behavior
from historical data and interact with current observations. Experimental
results show that in the zero-shot prediction setting, the LLM-based DT can
adapt to the change in the system, and the average RMSE of the GPT-4 prediction
is 0.479A, which is 4.79% of the maximum spindle motor current measurement of
10A, with little training data and instructions required. Furthermore, we
analyze the performance of DDD-GenDT in this specific application and their
potential to construct digital twins. We also discuss the limitations and
challenges that may arise in practical implementations.",2024-12-28,"Yu-Zheng Lin, Qinxuan Shi, Zhanglong Yang, Banafsheh Saber Latibari, Sicong Shao, Soheil Salehi, Pratik Satam",http://arxiv.org/pdf/2501.00051v1,cs.LG
Learning in Multiple Spaces: Few-Shot Network Attack Detection with Metric-Fused Prototypical Networks,"Network intrusion detection systems face significant challenges in
identifying emerging attack patterns, especially when limited data samples are
available. To address this, we propose a novel Multi-Space Prototypical
Learning (MSPL) framework tailored for few-shot attack detection. The framework
operates across multiple metric spaces-Euclidean, Cosine, Chebyshev, and
Wasserstein distances-integrated through a constrained weighting scheme to
enhance embedding robustness and improve pattern recognition. By leveraging
Polyak-averaged prototype generation, the framework stabilizes the learning
process and effectively adapts to rare and zero-day attacks. Additionally, an
episodic training paradigm ensures balanced representation across diverse
attack classes, enabling robust generalization. Experimental results on
benchmark datasets demonstrate that MSPL outperforms traditional approaches in
detecting low-profile and novel attack types, establishing it as a robust
solution for zero-day attack detection.",2024-12-28,"Fernando Martinez-Lopez, Lesther Santana, Mohamed Rahouti",http://arxiv.org/pdf/2501.00050v1,cs.LG
ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers,"In the construction sector, workers often endure prolonged periods of
high-intensity physical work and prolonged use of tools, resulting in injuries
and illnesses primarily linked to postural ergonomic risks, a longstanding
predominant health concern. To mitigate these risks, researchers have applied
various technological methods to identify the ergonomic risks that construction
workers face. However, traditional ergonomic risk assessment (ERA) techniques
do not offer interactive feedback. The rapidly developing vision-language
models (VLMs), capable of generating textual descriptions or answering
questions about ergonomic risks based on image inputs, have not yet received
widespread attention. This research introduces an interactive visual query
system tailored to assess the postural ergonomic risks of construction workers.
The system's capabilities include visual question answering (VQA), which
responds to visual queries regarding workers' exposure to postural ergonomic
risks, and image captioning (IC), which generates textual descriptions of these
risks from images. Additionally, this study proposes a dataset designed for
training and testing such methodologies. Systematic testing indicates that the
VQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using
nine metrics for IC and assessments from human experts indicate that the
proposed approach surpasses the performance of a method using the same
architecture trained solely on generic datasets. This study sets a new
direction for future developments in interactive ERA using generative
artificial intelligence (AI) technologies.",2024-12-27,"Chao Fan, Qipei Mei, Xiaonan Wang, Xinming Li",http://arxiv.org/pdf/2412.19954v1,cs.LG
"Data-driven tool wear prediction in milling, based on a process-integrated single-sensor approach","Accurate tool wear prediction is essential for maintaining productivity and
minimizing costs in machining. However, the complex nature of the tool wear
process poses significant challenges to achieving reliable predictions. This
study explores data-driven methods, in particular deep learning, for tool wear
prediction. Traditional data-driven approaches often focus on a single process,
relying on multi-sensor setups and extensive data generation, which limits
generalization to new settings. Moreover, multi-sensor integration is often
impractical in industrial environments. To address these limitations, this
research investigates the transferability of predictive models using minimal
training data, validated across two processes. Furthermore, it uses a simple
setup with a single acceleration sensor to establish a low-cost data generation
approach that facilitates the generalization of models to other processes via
transfer learning. The study evaluates several machine learning models,
including transformer-inspired convolutional neural networks (CNN), long
short-term memory networks (LSTM), support vector machines (SVM), and decision
trees, trained on different input formats such as feature vectors and
short-time Fourier transform (STFT). The performance of the models is evaluated
on two machines and on different amounts of training data, including scenarios
with significantly reduced datasets, providing insight into their effectiveness
under constrained data conditions. The results demonstrate the potential of
specific models and configurations for effective tool wear prediction,
contributing to the development of more adaptable and efficient predictive
maintenance strategies in machining. Notably, the ConvNeXt model has an
exceptional performance, achieving 99.1\% accuracy in identifying tool wear
using data from only four milling tools operated until they are worn.",2024-12-27,"Eric Hirsch, Christian Friedrich",http://arxiv.org/pdf/2412.19950v3,cs.LG
Stroke Prediction using Clinical and Social Features in Machine Learning,"Every year in the United States, 800,000 individuals suffer a stroke - one
person every 40 seconds, with a death occurring every four minutes. While
individual factors vary, certain predictors are more prevalent in determining
stroke risk. As strokes are the second leading cause of death and disability
worldwide, predicting stroke likelihood based on lifestyle factors is crucial.
Showing individuals their stroke risk could motivate lifestyle changes, and
machine learning offers solutions to this prediction challenge. Neural networks
excel at predicting outcomes based on training features like lifestyle factors,
however, they're not the only option. Logistic regression models can also
effectively compute the likelihood of binary outcomes based on independent
variables, making them well-suited for stroke prediction. This analysis will
compare both neural networks (dense and convolutional) and logistic regression
models for stroke prediction, examining their pros, cons, and differences to
develop the most effective predictor that minimizes false negatives.",2024-12-27,Aidan Chadha,http://arxiv.org/pdf/2501.00048v1,cs.LG
Standard-Deviation-Inspired Regularization for Improving Adversarial Robustness,"Adversarial Training (AT) has been demonstrated to improve the robustness of
deep neural networks (DNNs) against adversarial attacks. AT is a min-max
optimization procedure where in adversarial examples are generated to train a
more robust DNN. The inner maximization step of AT increases the losses of
inputs with respect to their actual classes. The outer minimization involves
minimizing the losses on the adversarial examples obtained from the inner
maximization. This work proposes a standard-deviation-inspired (SDI)
regularization term to improve adversarial robustness and generalization. We
argue that the inner maximization in AT is similar to minimizing a modified
standard deviation of the model's output probabilities. Moreover, we suggest
that maximizing this modified standard deviation can complement the outer
minimization of the AT framework. To support our argument, we experimentally
show that the SDI measure can be used to craft adversarial examples.
Additionally, we demonstrate that combining the SDI regularization term with
existing AT variants enhances the robustness of DNNs against stronger attacks,
such as CW and Auto-attack, and improves generalization.",2024-12-27,"Olukorede Fakorede, Modeste Atsague, Jin Tian",http://arxiv.org/pdf/2412.19947v1,cs.LG
Hidformer: Transformer-Style Neural Network in Stock Price Forecasting,"This paper investigates the application of Transformer-based neural networks
to stock price forecasting, with a special focus on the intersection of machine
learning techniques and financial market analysis. The evolution of Transformer
models, from their inception to their adaptation for time series analysis in
financial contexts, is reviewed and discussed. Central to our study is the
exploration of the Hidformer model, which is currently recognized for its
promising performance in time series prediction. The primary aim of this paper
is to determine whether Hidformer will also prove itself in the task of stock
price prediction. This slightly modified model serves as the framework for our
experiments, integrating the principles of technical analysis with advanced
machine learning concepts to enhance stock price prediction accuracy. We
conduct an evaluation of the Hidformer model's performance, using a set of
criteria to determine its efficacy. Our findings offer additional insights into
the practical application of Transformer architectures in financial time series
forecasting, highlighting their potential to improve algorithmic trading
strategies, including human decision making.",2024-12-27,"Kamil Ł. Szydłowski, Jarosław A. Chudziak",http://arxiv.org/pdf/2412.19932v1,cs.LG
On the Convergence of DP-SGD with Adaptive Clipping,"Stochastic Gradient Descent (SGD) with gradient clipping is a powerful
technique for enabling differentially private optimization. Although prior
works extensively investigated clipping with a constant threshold, private
training remains highly sensitive to threshold selection, which can be
expensive or even infeasible to tune. This sensitivity motivates the
development of adaptive approaches, such as quantile clipping, which have
demonstrated empirical success but lack a solid theoretical understanding. This
paper provides the first comprehensive convergence analysis of SGD with
quantile clipping (QC-SGD). We demonstrate that QC-SGD suffers from a bias
problem similar to constant-threshold clipped SGD but show how this can be
mitigated through a carefully designed quantile and step size schedule. Our
analysis reveals crucial relationships between quantile selection, step size,
and convergence behavior, providing practical guidelines for parameter
selection. We extend these results to differentially private optimization,
establishing the first theoretical guarantees for DP-QC-SGD. Our findings
provide theoretical foundations for widely used adaptive clipping heuristic and
highlight open avenues for future research.",2024-12-27,"Egor Shulgin, Peter Richtárik",http://arxiv.org/pdf/2412.19916v1,cs.LG
"Approximation Rates in Fréchet Metrics: Barron Spaces, Paley-Wiener Spaces, and Fourier Multipliers","Operator learning is a recent development in the simulation of Partial
Differential Equations (PDEs) by means of neural networks. The idea behind this
approach is to learn the behavior of an operator, such that the resulting
neural network is an (approximate) mapping in infinite-dimensional spaces that
is capable of (approximately) simulating the solution operator governed by the
PDE. In our work, we study some general approximation capabilities for linear
differential operators by approximating the corresponding symbol in the Fourier
domain. Analogous to the structure of the class of H\""ormander-Symbols, we
consider the approximation with respect to a topology that is induced by a
sequence of semi-norms. In that sense, we measure the approximation error in
terms of a Fr\'echet metric, and our main result identifies sufficient
conditions for achieving a predefined approximation error. Secondly, we then
focus on a natural extension of our main theorem, in which we manage to reduce
the assumptions on the sequence of semi-norms. Based on existing approximation
results for the exponential spectral Barron space, we then present a concrete
example of symbols that can be approximated well.",2024-12-27,"Ahmed Abdeljawad, Thomas Dittrich",http://arxiv.org/pdf/2501.04023v2,cs.LG
Mouth Articulation-Based Anchoring for Improved Cross-Corpus Speech Emotion Recognition,"Cross-corpus speech emotion recognition (SER) plays a vital role in numerous
practical applications. Traditional approaches to cross-corpus emotion transfer
often concentrate on adapting acoustic features to align with different
corpora, domains, or labels. However, acoustic features are inherently variable
and error-prone due to factors like speaker differences, domain shifts, and
recording conditions. To address these challenges, this study adopts a novel
contrastive approach by focusing on emotion-specific articulatory gestures as
the core elements for analysis. By shifting the emphasis on the more stable and
consistent articulatory gestures, we aim to enhance emotion transfer learning
in SER tasks. Our research leverages the CREMA-D and MSP-IMPROV corpora as
benchmarks and it reveals valuable insights into the commonality and
reliability of these articulatory gestures. The findings highlight mouth
articulatory gesture potential as a better constraint for improving emotion
recognition across different settings or domains.",2024-12-27,"Shreya G. Upadhyay, Ali N. Salman, Carlos Busso, Chi-Chun Lee",http://arxiv.org/pdf/2412.19909v1,cs.LG
Surrogate Modeling for Explainable Predictive Time Series Corrections,"We introduce a local surrogate approach for explainable time-series
forecasting. An initially non-interpretable predictive model to improve the
forecast of a classical time-series 'base model' is used. 'Explainability' of
the correction is provided by fitting the base model again to the data from
which the error prediction is removed (subtracted), yielding a difference in
the model parameters which can be interpreted. We provide illustrative examples
to demonstrate the potential of the method to discover and explain underlying
patterns in the data.",2024-12-27,"Alfredo Lopez, Florian Sobieczky",http://arxiv.org/pdf/2412.19897v2,cs.LG
A Neural Network-Based Search for Unmodeled Transients in LIGO-Virgo-KAGRA's Third Observing Run,"This paper presents the results of a Neural Network (NN)-based search for
short-duration gravitational-wave transients in data from the third observing
run of LIGO, Virgo, and KAGRA. The search targets unmodeled transients with
durations of milliseconds to a few seconds in the 30-1500 Hz frequency band,
without assumptions about the incoming signal direction, polarization, or
morphology. Using the Gravitational Wave Anomalous Knowledge (GWAK) method,
three compact binary coalescences (CBCs) identified by existing pipelines are
successfully detected, along with a range of detector glitches. The algorithm
constructs a low-dimensional embedded space to capture the physical features of
signals, enabling the detection of CBCs, detector glitches, and unmodeled
transients. This study demonstrates GWAK's ability to enhance
gravitational-wave searches beyond the limits of existing pipelines, laying the
groundwork for future detection strategies.",2024-12-27,"Ryan Raikman, Eric A. Moreno, Katya Govorkova, Siddharth Soni, Ethan Marx, William Benoit, Alec Gunny, Deep Chatterjee, Christina Reissel, Malina M. Desai, Rafia Omer, Muhammed Saleem, Philip Harris, Erik Katsavounidis, Michael W. Coughlin, Dylan Rankin",http://arxiv.org/pdf/2412.19883v1,cs.LG
A new approach to locally adaptive polynomial regression,"Adaptive bandwidth selection is a fundamental challenge in nonparametric
regression. This paper introduces a new bandwidth selection procedure inspired
by the optimality criteria for $\ell_0$-penalized regression. Although similar
in spirit to Lepski's method and its variants in selecting the largest interval
satisfying an admissibility criterion, our approach stems from a distinct
philosophy, utilizing criteria based on $\ell_2$-norms of interval projections
rather than explicit point and variance estimates. We obtain non-asymptotic
risk bounds for the local polynomial regression methods based on our bandwidth
selection procedure which adapt (near-)optimally to the local H\""{o}lder
exponent of the underlying regression function simultaneously at all points in
its domain. Furthermore, we show that there is a single ideal choice of a
global tuning parameter in each case under which the above-mentioned local
adaptivity holds. The optimal risks of our methods derive from the properties
of solutions to a new ``bandwidth selection equation'' which is of independent
interest. We believe that the principles underlying our approach provide a new
perspective to the classical yet ever relevant problem of locally adaptive
nonparametric regression.",2024-12-27,"Sabyasachi Chatterjee, Subhajit Goswami, Soumendu Sundar Mukherjee",http://arxiv.org/pdf/2412.19802v2,cs.LG
InfAlign: Inference-aware language model alignment,"Language model alignment is a critical step in training modern generative
language models. Alignment targets to improve win rate of a sample from the
aligned model against the base model. Today, we are increasingly using
inference-time algorithms (e.g., Best-of-N, controlled decoding, tree search)
to decode from language models rather than standard sampling. We show that this
train/test mismatch makes standard RLHF framework sub-optimal in view of such
inference-time methods. To this end, we propose a framework for inference-aware
alignment (InfAlign), which aims to optimize inference-time win rate of the
aligned policy against the base model. We prove that for any inference-time
decoding procedure, the optimal aligned policy is the solution to the standard
RLHF problem with a transformation of the reward. This motivates us to provide
the calibrate-and-transform RL (InfAlign-CTRL) algorithm to solve this problem,
which involves a reward calibration step and a KL-regularized reward
maximization step with a transformation of the calibrated reward. For best-of-N
sampling and best-of-N jailbreaking, we propose specific transformations
offering up to 3-8% improvement on inference-time win rates. Finally, we also
show that our proposed reward calibration method is a strong baseline for
optimizing standard win rate.",2024-12-27,"Ananth Balashankar, Ziteng Sun, Jonathan Berant, Jacob Eisenstein, Michael Collins, Adrian Hutter, Jong Lee, Chirag Nagpal, Flavien Prost, Aradhana Sinha, Ananda Theertha Suresh, Ahmad Beirami",http://arxiv.org/pdf/2412.19792v3,cs.LG
Can AI Help with Your Personal Finances?,"In recent years, Large Language Models (LLMs) have emerged as a
transformative development in artificial intelligence (AI), drawing significant
attention from industry and academia. Trained on vast datasets, these
sophisticated AI systems exhibit impressive natural language processing and
content generation capabilities. This paper explores the potential of LLMs to
address key challenges in personal finance, focusing on the United States. We
evaluate several leading LLMs, including OpenAI's ChatGPT, Google's Gemini,
Anthropic's Claude, and Meta's Llama, to assess their effectiveness in
providing accurate financial advice on topics such as mortgages, taxes, loans,
and investments. Our findings show that while these models achieve an average
accuracy rate of approximately 70%, they also display notable limitations in
certain areas. Specifically, LLMs struggle to provide accurate responses for
complex financial queries, with performance varying significantly across
different topics. Despite these limitations, the analysis reveals notable
improvements in newer versions of these models, highlighting their growing
utility for individuals and financial advisors. As these AI systems continue to
evolve, their potential for advancing AI-driven applications in personal
finance becomes increasingly promising.",2024-12-27,"Oudom Hean, Utsha Saha, Binita Saha",http://arxiv.org/pdf/2412.19784v4,cs.LG
Machine Learning for Sentiment Analysis of Imported Food in Trinidad and Tobago,"This research investigates the performance of various machine learning
algorithms (CNN, LSTM, VADER, and RoBERTa) for sentiment analysis of Twitter
data related to imported food items in Trinidad and Tobago. The study addresses
three primary research questions: the comparative accuracy and efficiency of
the algorithms, the optimal configurations for each model, and the potential
applications of the optimized models in a live system for monitoring public
sentiment and its impact on the import bill. The dataset comprises tweets from
2018 to 2024, divided into imbalanced, balanced, and temporal subsets to assess
the impact of data balancing and the COVID-19 pandemic on sentiment trends. Ten
experiments were conducted to evaluate the models under various configurations.
Results indicated that VADER outperformed the other models in both multi-class
and binary sentiment classifications. The study highlights significant changes
in sentiment trends pre- and post-COVID-19, with implications for import
policies.",2024-12-27,"Cassandra Daniels, Koffka Khan",http://arxiv.org/pdf/2412.19781v1,cs.LG
Tensor Network Estimation of Distribution Algorithms,"Tensor networks are a tool first employed in the context of many-body quantum
physics that now have a wide range of uses across the computational sciences,
from numerical methods to machine learning. Methods integrating tensor networks
into evolutionary optimization algorithms have appeared in the recent
literature. In essence, these methods can be understood as replacing the
traditional crossover operation of a genetic algorithm with a tensor
network-based generative model. We investigate these methods from the point of
view that they are Estimation of Distribution Algorithms (EDAs). We find that
optimization performance of these methods is not related to the power of the
generative model in a straightforward way. Generative models that are better
(in the sense that they better model the distribution from which their training
data is drawn) do not necessarily result in better performance of the
optimization algorithm they form a part of. This raises the question of how
best to incorporate powerful generative models into optimization routines. In
light of this we find that adding an explicit mutation operator to the output
of the generative model often improves optimization performance.",2024-12-27,"John Gardiner, Javier Lopez-Piqueres",http://arxiv.org/pdf/2412.19780v1,cs.LG
Symbolic Approximations to Ricci-flat Metrics Via Extrinsic Symmetries of Calabi-Yau Hypersurfaces,"Ever since Yau's non-constructive existence proof of Ricci-flat metrics on
Calabi-Yau manifolds, finding their explicit construction remains a major
obstacle to development of both string theory and algebraic geometry. Recent
computational approaches employ machine learning to create novel neural
representations for approximating these metrics, offering high accuracy but
limited interpretability. In this paper, we analyse machine learning
approximations to flat metrics of Fermat Calabi-Yau n-folds and some of their
one-parameter deformations in three dimensions in order to discover their new
properties. We formalise cases in which the flat metric has more symmetries
than the underlying manifold, and prove that these symmetries imply that the
flat metric admits a surprisingly compact representation for certain choices of
complex structure moduli. We show that such symmetries uniquely determine the
flat metric on certain loci, for which we present an analytic form. We also
incorporate our theoretical results into neural networks to reduce Ricci
curvature for multiple Calabi--Yau manifolds compared to previous machine
learning approaches. We conclude by distilling the ML models to obtain for the
first time closed form expressions for Kahler metrics with near-zero scalar
curvature.",2024-12-27,"Viktor Mirjanić, Challenger Mishra",http://arxiv.org/pdf/2412.19778v2,cs.LG
"Analysis of Premature Death Rates in Texas Counties: The Impact of Air Quality, Socioeconomic Factors, and COPD Prevalence","Understanding factors contributing to premature mortality is critical for
public health planning. This study examines the relationships between premature
death rates and multiple risk factors across several Texas counties, utilizing
EPA air quality data, Census information, and county health records from recent
years. We analyze the impact of air quality (PM2.5 levels), socioeconomic
factors (median household income), and health conditions (COPD prevalence)
through statistical analysis and modeling techniques. Results reveal COPD
prevalence as a strong predictor of premature death rates, with higher
prevalence associated with a substantial increase in years of potential life
lost. While socioeconomic factors show a significant negative correlation, air
quality demonstrates more complex indirect relationships. These findings
emphasize the need for integrated public health interventions that prioritize
key health conditions while addressing underlying socioeconomic disparities.",2024-12-27,"Richard Rich, Ernesto Diaz",http://arxiv.org/pdf/2412.19774v1,cs.LG
Fortran2CPP: Automating Fortran-to-C++ Translation using LLMs via Multi-Turn Dialogue and Dual-Agent Integration,"Translating legacy Fortran code into C++ is a crucial step in modernizing
high-performance computing (HPC) applications. However, the scarcity of
high-quality, parallel Fortran-to-C++ datasets and the limited domain-specific
expertise in large language models (LLMs) present significant challenges for
automated translation. In this paper, we introduce Fortran2CPP, a multi-turn
dialogue dataset generated by a novel LLM agent-based approach that integrates
a dual-LLM Questioner-Solver module to enhance translation accuracy. Our
dataset comprises 11.7k dialogues capturing iterative feedback-decision
workflows including code translation, compilation, execution, unit testing, and
error-fixing. Using this dataset, we fine-tune several open-weight LLMs and
achieve up to a 3.31x improvement in CodeBLEU scores and a 92\% increase in
compilation success rate, demonstrating enhanced syntactic accuracy and
functional reliability. Our findings highlight the value of dialogue-based LLM
training for complex code translation tasks. The dataset and model have been
open-sourced and are available on our public GitHub
repository\footnote{\url{https://github.com/HPC-Fortran2CPP/Fortran2Cpp}}.",2024-12-27,"Le Chen, Bin Lei, Dunzhi Zhou, Pei-Hung Lin, Chunhua Liao, Caiwen Ding, Ali Jannesari",http://arxiv.org/pdf/2412.19770v2,cs.LG
Numerical solutions of fixed points in two-dimensional Kuramoto-Sivashinsky equation expedited by reinforcement learning,"This paper presents a combined approach to enhancing the effectiveness of
Jacobian-Free Newton-Krylov (JFNK) method by deep reinforcement learning (DRL)
in identifying fixed points within the 2D Kuramoto-Sivashinsky Equation (KSE).
JFNK approach entails a good initial guess for improved convergence when
searching for fixed points. With a properly defined reward function, we utilise
DRL as a preliminary step to enhance the initial guess in the converging
process. We report new results of fixed points in the 2D KSE which have not
been reported in the literature. Additionally, we explored control optimization
for the 2D KSE to navigate the system trajectories between known fixed points,
based on parallel reinforcement learning techniques. This combined method
underscores the improved JFNK approach to finding new fixed-point solutions
within the context of 2D KSE, which may be instructive for other
high-dimensional dynamical systems.",2024-12-27,"Juncheng Jiang, Dongdong Wan, Mengqi Zhang",http://arxiv.org/pdf/2501.00046v1,cs.LG
From Ceilings to Walls: Universal Dynamic Perching of Small Aerial Robots on Surfaces with Variable Orientations,"This work demonstrates universal dynamic perching capabilities for quadrotors
of various sizes and on surfaces with different orientations. By employing a
non-dimensionalization framework and deep reinforcement learning, we
systematically assessed how robot size and surface orientation affect landing
capabilities. We hypothesized that maintaining geometric proportions across
different robot scales ensures consistent perching behavior, which was
validated in both simulation and experimental tests. Additionally, we
investigated the effects of joint stiffness and damping in the landing gear on
perching behaviors and performance. While joint stiffness had minimal impact,
joint damping ratios influenced landing success under vertical approaching
conditions. The study also identified a critical velocity threshold necessary
for successful perching, determined by the robot's maneuverability and leg
geometry. Overall, this research advances robotic perching capabilities,
offering insights into the role of mechanical design and scaling effects, and
lays the groundwork for future drone autonomy and operational efficiency in
unstructured environments.",2024-12-27,"Bryan Habas, Aaron Brown, Donghyeon Lee, Mitchell Goldman, Bo Cheng",http://arxiv.org/pdf/2412.19765v1,cs.LG
Enhancing Adversarial Robustness of Deep Neural Networks Through Supervised Contrastive Learning,"Adversarial attacks exploit the vulnerabilities of convolutional neural
networks by introducing imperceptible perturbations that lead to
misclassifications, exposing weaknesses in feature representations and decision
boundaries. This paper presents a novel framework combining supervised
contrastive learning and margin-based contrastive loss to enhance adversarial
robustness. Supervised contrastive learning improves the structure of the
feature space by clustering embeddings of samples within the same class and
separating those from different classes. Margin-based contrastive loss,
inspired by support vector machines, enforces explicit constraints to create
robust decision boundaries with well-defined margins. Experiments on the
CIFAR-100 dataset with a ResNet-18 backbone demonstrate robustness performance
improvements in adversarial accuracy under Fast Gradient Sign Method attacks.",2024-12-27,"Longwei Wang, Navid Nayyem, Abdullah Rakin",http://arxiv.org/pdf/2412.19747v1,cs.LG
Generative Pretrained Embedding and Hierarchical Irregular Time Series Representation for Daily Living Activity Recognition,"Within the evolving landscape of smart homes, the precise recognition of
daily living activities using ambient sensor data stands paramount. This paper
not only aims to bolster existing algorithms by evaluating two distinct
pretrained embeddings suited for ambient sensor activations but also introduces
a novel hierarchical architecture. We delve into an architecture anchored on
Transformer Decoder-based pre-trained embeddings, reminiscent of the GPT
design, and contrast it with the previously established state-of-the-art (SOTA)
ELMo embeddings for ambient sensors. Our proposed hierarchical structure
leverages the strengths of each pre-trained embedding, enabling the discernment
of activity dependencies and sequence order, thereby enhancing classification
precision. To further refine recognition, we incorporate into our proposed
architecture an hour-of-the-day embedding. Empirical evaluations underscore the
preeminence of the Transformer Decoder embedding in classification endeavors.
Additionally, our innovative hierarchical design significantly bolsters the
efficacy of both pre-trained embeddings, notably in capturing inter-activity
nuances. The integration of temporal aspects subtly but distinctively augments
classification, especially for time-sensitive activities. In conclusion, our
GPT-inspired hierarchical approach, infused with temporal insights, outshines
the SOTA ELMo benchmark.",2024-12-27,"Damien Bouchabou, Sao Mai Nguyen",http://arxiv.org/pdf/2412.19732v1,cs.LG
Minimax-Optimal Multi-Agent Robust Reinforcement Learning,"Multi-agent robust reinforcement learning, also known as multi-player robust
Markov games (RMGs), is a crucial framework for modeling competitive
interactions under environmental uncertainties, with wide applications in
multi-agent systems. However, existing results on sample complexity in RMGs
suffer from at least one of three obstacles: restrictive range of uncertainty
level or accuracy, the curse of multiple agents, and the barrier of long
horizons, all of which cause existing results to significantly exceed the
information-theoretic lower bound. To close this gap, we extend the Q-FTRL
algorithm \citep{li2022minimax} to the RMGs in finite-horizon setting, assuming
access to a generative model. We prove that the proposed algorithm achieves an
$\varepsilon$-robust coarse correlated equilibrium (CCE) with a sample
complexity (up to log factors) of
$\widetilde{O}\left(H^3S\sum_{i=1}^mA_i\min\left\{H,1/R\right\}/\varepsilon^2\right)$,
where $S$ denotes the number of states, $A_i$ is the number of actions of the
$i$-th agent, $H$ is the finite horizon length, and $R$ is uncertainty level.
We also show that this sample compelxity is minimax optimal by combining an
information-theoretic lower bound. Additionally, in the special case of
two-player zero-sum RMGs, the algorithm achieves an $\varepsilon$-robust Nash
equilibrium (NE) with the same sample complexity.",2024-12-27,"Yuchen Jiao, Gen Li",http://arxiv.org/pdf/2412.19873v1,cs.LG
Cross-Linguistic Examination of Machine Translation Transfer Learning,"This study investigates the effectiveness of transfer learning in machine
translation across diverse linguistic families by evaluating five distinct
language pairs. Leveraging pre-trained models on high-resource languages, these
models were fine-tuned on low-resource languages, examining variations in
hyperparameters such as learning rate, batch size, number of epochs, and weight
decay. The research encompasses language pairs from different linguistic
backgrounds: Semitic (Modern Standard Arabic - Levantine Arabic), Bantu (Hausa
- Zulu), Romance (Spanish - Catalan), Slavic (Slovakian - Macedonian), and
language isolates (Eastern Armenian - Western Armenian). Results demonstrate
that transfer learning is effective across different language families,
although the impact of hyperparameters varies. A moderate batch size (e.g., 32)
is generally more effective, while very high learning rates can disrupt model
training. The study highlights the universality of transfer learning in
multilingual contexts and suggests that consistent hyperparameter settings can
simplify and enhance the efficiency of multilingual model training.",2024-12-27,Saughmon Boujkian,http://arxiv.org/pdf/2501.00045v1,cs.LG
Learning to Forget: Bayesian Time Series Forecasting using Recurrent Sparse Spectrum Signature Gaussian Processes,"The signature kernel is a kernel between time series of arbitrary length and
comes with strong theoretical guarantees from stochastic analysis. It has found
applications in machine learning such as covariance functions for Gaussian
processes. A strength of the underlying signature features is that they provide
a structured global description of a time series. However, this property can
quickly become a curse when local information is essential and forgetting is
required; so far this has only been addressed with ad-hoc methods such as
slicing the time series into subsegments. To overcome this, we propose a
principled, data-driven approach by introducing a novel forgetting mechanism
for signatures. This allows the model to dynamically adapt its context length
to focus on more recent information. To achieve this, we revisit the recently
introduced Random Fourier Signature Features, and develop Random Fourier
Decayed Signature Features (RFDSF) with Gaussian processes (GPs). This results
in a Bayesian time series forecasting algorithm with variational inference,
that offers a scalable probabilistic algorithm that processes and transforms a
time series into a joint predictive distribution over time steps in one pass
using recurrence. For example, processing a sequence of length $10^4$ steps in
$\approx 10^{-2}$ seconds and in $< 1\text{GB}$ of GPU memory. We demonstrate
that it outperforms other GP-based alternatives and competes with
state-of-the-art probabilistic time series forecasting algorithms.",2024-12-27,"Csaba Tóth, Masaki Adachi, Michael A. Osborne, Harald Oberhauser",http://arxiv.org/pdf/2412.19727v1,cs.LG
EEG-Reptile: An Automatized Reptile-Based Meta-Learning Library for BCIs,"Meta-learning, i.e., ""learning to learn"", is a promising approach to enable
efficient BCI classifier training with limited amounts of data. It can
effectively use collections of in some way similar classification tasks, with
rapid adaptation to new tasks where only minimal data are available. However,
applying meta-learning to existing classifiers and BCI tasks requires
significant effort. To address this issue, we propose EEG-Reptile, an automated
library that leverages meta-learning to improve classification accuracy of
neural networks in BCIs and other EEG-based applications. It utilizes the
Reptile meta-learning algorithm to adapt neural network classifiers of EEG data
to the inter-subject domain, allowing for more efficient fine-tuning for a new
subject on a small amount of data. The proposed library incorporates an
automated hyperparameter tuning module, a data management pipeline, and an
implementation of the Reptile meta-learning algorithm. EEG-Reptile automation
level allows using it without deep understanding of meta-learning. We
demonstrate the effectiveness of EEG-Reptile on two benchmark datasets (BCI IV
2a, Lee2019 MI) and three neural network architectures (EEGNet, FBCNet,
EEG-Inception). Our library achieved improvement in both zero-shot and few-shot
learning scenarios compared to traditional transfer learning approaches.",2024-12-27,"Daniil A. Berdyshev, Artem M. Grachev, Sergei L. Shishkin, Bogdan L. Kozyrskiy",http://arxiv.org/pdf/2412.19725v2,cs.LG
Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture,"The growing demand for dynamic, user-centric data analysis and visualization
is evident across domains like healthcare, finance, and research. Traditional
visualization tools often fail to meet individual user needs due to their
static and predefined nature. To address this gap, Text2Insight is introduced
as an innovative solution that delivers customized data analysis and
visualizations based on user-defined natural language requirements. Leveraging
a multi-model architecture, Text2Insight transforms user inputs into actionable
insights and dynamic visualizations.
  The methodology begins with analyzing the input dataset to extract structural
details such as columns and values. A pre-trained Llama3 model converts the
user's natural language query into an SQL query, which is further refined using
a Named Entity Recognition (NER) model for accuracy. A chart predictor
determines the most suitable visualization type, while the Llama3 model
generates insights based on the SQL query's results. The output is a
user-friendly and visually informative chart. To enhance analysis capabilities,
the system integrates a question-answering model and a predictive model using
the BERT framework. These models provide insights into historical data and
predict future trends.
  Performance evaluation of Text2Insight demonstrates its effectiveness,
achieving high accuracy (99%), precision (100%), recall (99%), and F1-score
(99%), with a BLEU score of 0.5. The question-answering model attained an
accuracy of 89% and the predictive model achieved 70% accuracy. These results
validate Text2Insight as a robust and viable solution for transforming natural
language text into dynamic, user-specific data analysis and visualizations.",2024-12-27,Pradeep Sain,http://arxiv.org/pdf/2412.19718v1,cs.LG
ProKAN: Progressive Stacking of Kolmogorov-Arnold Networks for Efficient Liver Segmentation,"The growing need for accurate and efficient 3D identification of tumors,
particularly in liver segmentation, has spurred considerable research into deep
learning models. While many existing architectures offer strong performance,
they often face challenges such as overfitting and excessive computational
costs. An adjustable and flexible architecture that strikes a balance between
time efficiency and model complexity remains an unmet requirement. In this
paper, we introduce proKAN, a progressive stacking methodology for
Kolmogorov-Arnold Networks (KANs) designed to address these challenges. Unlike
traditional architectures, proKAN dynamically adjusts its complexity by
progressively adding KAN blocks during training, based on overfitting behavior.
This approach allows the network to stop growing when overfitting is detected,
preventing unnecessary computational overhead while maintaining high accuracy.
Additionally, proKAN utilizes KAN's learnable activation functions modeled
through B-splines, which provide enhanced flexibility in learning complex
relationships in 3D medical data. Our proposed architecture achieves
state-of-the-art performance in liver segmentation tasks, outperforming
standard Multi-Layer Perceptrons (MLPs) and fixed KAN architectures. The
dynamic nature of proKAN ensures efficient training times and high accuracy
without the risk of overfitting. Furthermore, proKAN provides better
interpretability by allowing insight into the decision-making process through
its learnable coefficients. The experimental results demonstrate a significant
improvement in accuracy, Dice score, and time efficiency, making proKAN a
compelling solution for 3D medical image segmentation tasks.",2024-12-27,"Bhavesh Gyanchandani, Aditya Oza, Abhinav Roy",http://arxiv.org/pdf/2412.19713v1,cs.LG
Causal machine learning for heterogeneous treatment effects in the presence of missing outcome data,"When estimating heterogeneous treatment effects, missing outcome data can
complicate treatment effect estimation, causing certain subgroups of the
population to be poorly represented. In this work, we discuss this commonly
overlooked problem and consider the impact that missing at random (MAR) outcome
data has on causal machine learning estimators for the conditional average
treatment effect (CATE). We propose two de-biased machine learning estimators
for the CATE, the mDR-learner and mEP-learner, which address the issue of
under-representation by integrating inverse probability of censoring weights
into the DR-learner and EP-learner respectively. We show that under reasonable
conditions, these estimators are oracle efficient, and illustrate their
favorable performance through simulated data settings, comparing them to
existing CATE estimators, including comparison to estimators which use common
missing data techniques. We present an example of their application using the
GBSG2 trial, exploring treatment effect heterogeneity when comparing hormonal
therapies to non-hormonal therapies among breast cancer patients post surgery,
and offer guidance on the decisions a practitioner must make when implementing
these estimators.",2024-12-27,"Matthew Pryce, Karla Diaz-Ordaz, Ruth H. Keogh, Stijn Vansteelandt",http://arxiv.org/pdf/2412.19711v2,cs.LG
Toward Adaptive Reasoning in Large Language Models with Thought Rollback,"Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.",2024-12-27,"Sijia Chen, Baochun Li",http://arxiv.org/pdf/2412.19707v1,cs.LG
Combining Machine Learning with Recurrence Analysis for resonance detection,"The width of a resonance in a nearly integrable system, i.e. in a
non-integrable system where chaotic motion is still not prominent, can tell us
how a perturbation parameter is driving the system away from integrability.
Although the tool that we are presenting here can be used is quite generic and
can be used in a variety of systems, our particular interest lies in binary
compact object systems known as extreme mass ratio inspirals (EMRIs). In an
EMRI a lighter compact object, like a black hole or a neutron star, inspirals
into a supermassive black hole due to gravitational radiation reaction. During
this inspiral the lighter object crosses resonances, which are still not very
well modeled. Measuring the width of resonances in EMRI models allows us to
estimate the importance of each perturbation parameter able to drive the system
away from resonances and decide whether its impact should be included in EMRI
waveform modeling or not. To tackle this issue in our study we show first that
recurrence quantifiers of orbits carry imprints of resonant behavior,
regardless of the system's dimensionality. As a next step, we apply a long
short-term memory machine learning architecture to automate the resonance
detection procedure. Our analysis is developed on a simple standard map and
gradually we extend it to more complicated systems until finally we employ it
in a generic deformed Kerr spacetime known in the literature as the
Johannsen-Psaltis spacetime.",2024-12-27,"Ondřej Zelenka, Ondřej Kopáček, Georgios Lukes-Gerakopoulos",http://arxiv.org/pdf/2412.19683v1,cs.LG
Deep ReLU networks -- injectivity capacity upper bounds,"We study deep ReLU feed forward neural networks (NN) and their injectivity
abilities. The main focus is on \emph{precisely} determining the so-called
injectivity capacity. For any given hidden layers architecture, it is defined
as the minimal ratio between number of network's outputs and inputs which
ensures unique recoverability of the input from a realizable output. A strong
recent progress in precisely studying single ReLU layer injectivity properties
is here moved to a deep network level. In particular, we develop a program that
connects deep $l$-layer net injectivity to an $l$-extension of the $\ell_0$
spherical perceptrons, thereby massively generalizing an isomorphism between
studying single layer injectivity and the capacity of the so-called
(1-extension) $\ell_0$ spherical perceptrons discussed in [82]. \emph{Random
duality theory} (RDT) based machinery is then created and utilized to
statistically handle properties of the extended $\ell_0$ spherical perceptrons
and implicitly of the deep ReLU NNs. A sizeable set of numerical evaluations is
conducted as well to put the entire RDT machinery in practical use. From these
we observe a rapidly decreasing tendency in needed layers' expansions, i.e., we
observe a rapid \emph{expansion saturation effect}. Only $4$ layers of depth
are sufficient to closely approach level of no needed expansion -- a result
that fairly closely resembles observations made in practical experiments and
that has so far remained completely untouchable by any of the existing
mathematical methodologies.",2024-12-27,Mihailo Stojnic,http://arxiv.org/pdf/2412.19677v1,cs.LG
Toward Scalable Multirobot Control: Fast Policy Learning in Distributed MPC,"Distributed model predictive control (DMPC) is promising in achieving optimal
cooperative control in multirobot systems (MRS). However, real-time DMPC
implementation relies on numerical optimization tools to periodically calculate
local control sequences online. This process is computationally demanding and
lacks scalability for large-scale, nonlinear MRS. This article proposes a novel
distributed learning-based predictive control (DLPC) framework for scalable
multirobot control. Unlike conventional DMPC methods that calculate open-loop
control sequences, our approach centers around a computationally fast and
efficient distributed policy learning algorithm that generates explicit
closed-loop DMPC policies for MRS without using numerical solvers. The policy
learning is executed incrementally and forward in time in each prediction
interval through an online distributed actor-critic implementation. The control
policies are successively updated in a receding-horizon manner, enabling fast
and efficient policy learning with the closed-loop stability guarantee. The
learned control policies could be deployed online to MRS with varying robot
scales, enhancing scalability and transferability for large-scale MRS.
Furthermore, we extend our methodology to address the multirobot safe learning
challenge through a force field-inspired policy learning approach. We validate
our approach's effectiveness, scalability, and efficiency through extensive
experiments on cooperative tasks of large-scale wheeled robots and multirotor
drones. Our results demonstrate the rapid learning and deployment of DMPC
policies for MRS with scales up to 10,000 units.",2024-12-27,"Xinglong Zhang, Wei Pan, Cong Li, Xin Xu, Xiangke Wang, Ronghua Zhang, Dewen Hu",http://arxiv.org/pdf/2412.19669v1,cs.LG
Asymmetrical Reciprocity-based Federated Learning for Resolving Disparities in Medical Diagnosis,"Geographic health disparities pose a pressing global challenge, particularly
in underserved regions of low- and middle-income nations. Addressing this issue
requires a collaborative approach to enhance healthcare quality, leveraging
support from medically more developed areas. Federated learning emerges as a
promising tool for this purpose. However, the scarcity of medical data and
limited computation resources in underserved regions make collaborative
training of powerful machine learning models challenging. Furthermore, there
exists an asymmetrical reciprocity between underserved and developed regions.
To overcome these challenges, we propose a novel cross-silo federated learning
framework, named FedHelp, aimed at alleviating geographic health disparities
and fortifying the diagnostic capabilities of underserved regions.
Specifically, FedHelp leverages foundational model knowledge via one-time API
access to guide the learning process of underserved small clients, addressing
the challenge of insufficient data. Additionally, we introduce a novel
asymmetric dual knowledge distillation module to manage the issue of asymmetric
reciprocity, facilitating the exchange of necessary knowledge between developed
large clients and underserved small clients. We validate the effectiveness and
utility of FedHelp through extensive experiments on both medical image
classification and segmentation tasks. The experimental results demonstrate
significant performance improvement compared to state-of-the-art baselines,
particularly benefiting clients in underserved regions.",2024-12-27,"Jiaqi Wang, Ziyi Yin, Quanzeng You, Lingjuan Lyu, Fenglong Ma",http://arxiv.org/pdf/2412.19654v1,cs.LG
Neighbor Does Matter: Density-Aware Contrastive Learning for Medical Semi-supervised Segmentation,"In medical image analysis, multi-organ semi-supervised segmentation faces
challenges such as insufficient labels and low contrast in soft tissues. To
address these issues, existing studies typically employ semi-supervised
segmentation techniques using pseudo-labeling and consistency regularization.
However, these methods mainly rely on individual data samples for training,
ignoring the rich neighborhood information present in the feature space. In
this work, we argue that supervisory information can be directly extracted from
the geometry of the feature space. Inspired by the density-based clustering
hypothesis, we propose using feature density to locate sparse regions within
feature clusters. Our goal is to increase intra-class compactness by addressing
sparsity issues. To achieve this, we propose a Density-Aware Contrastive
Learning (DACL) strategy, pushing anchored features in sparse regions towards
cluster centers approximated by high-density positive samples, resulting in
more compact clusters. Specifically, our method constructs density-aware
neighbor graphs using labeled and unlabeled data samples to estimate feature
density and locate sparse regions. We also combine label-guided co-training
with density-guided geometric regularization to form complementary supervision
for unlabeled data. Experiments on the Multi-Organ Segmentation Challenge
dataset demonstrate that our proposed method outperforms state-of-the-art
methods, highlighting its efficacy in medical image segmentation tasks.",2024-12-27,"Feilong Tang, Zhongxing Xu, Ming Hu, Wenxue Li, Peng Xia, Yiheng Zhong, Hanjun Wu, Jionglong Su, Zongyuan Ge",http://arxiv.org/pdf/2412.19871v1,cs.LG
Toward Modality Gap: Vision Prototype Learning for Weakly-supervised Semantic Segmentation with CLIP,"The application of Contrastive Language-Image Pre-training (CLIP) in Weakly
Supervised Semantic Segmentation (WSSS) research powerful cross-modal semantic
understanding capabilities. Existing methods attempt to optimize input text
prompts for improved alignment of images and text, by finely adjusting text
prototypes to facilitate semantic matching. Nevertheless, given the modality
gap between text and vision spaces, the text prototypes employed by these
methods have not effectively established a close correspondence with
pixel-level vision features. In this work, our theoretical analysis indicates
that the inherent modality gap results in misalignment of text and region
features, and that this gap cannot be sufficiently reduced by minimizing
contrast loss in CLIP. To mitigate the impact of the modality gap, we propose a
Vision Prototype Learning (VPL) framework, by introducing more representative
vision prototypes. The core of this framework is to learn class-specific vision
prototypes in vision space with the help of text prototypes, for capturing
high-quality localization maps. Moreover, we propose a regional semantic
contrast module that contrasts regions embedding with corresponding prototypes,
leading to more comprehensive and robust feature learning. Experimental results
show that our proposed framework achieves state-of-the-art performance on two
benchmark datasets.",2024-12-27,"Zhongxing Xu, Feilong Tang, Zhe Chen, Yingxue Su, Zhiyi Zhao, Ge Zhang, Jionglong Su, Zongyuan Ge",http://arxiv.org/pdf/2412.19650v1,cs.LG
Deep Linear Hawkes Processes,"Marked temporal point processes (MTPPs) are used to model sequences of
different types of events with irregular arrival times, with broad applications
ranging from healthcare and social networks to finance. We address shortcomings
in existing point process models by drawing connections between modern deep
state-space models (SSMs) and linear Hawkes processes (LHPs), culminating in an
MTPP that we call the deep linear Hawkes process (DLHP). The DLHP modifies the
linear differential equations in deep SSMs to be stochastic jump differential
equations, akin to LHPs. After discretizing, the resulting recurrence can be
implemented efficiently using a parallel scan. This brings parallelism and
linear scaling to MTPP models. This contrasts with attention-based MTPPs, which
scale quadratically, and RNN-based MTPPs, which do not parallelize across the
sequence length. We show empirically that DLHPs match or outperform existing
models across a broad range of metrics on eight real-world datasets. Our
proposed DLHP model is the first instance of the unique architectural
capabilities of SSMs being leveraged to construct a new class of MTPP models.",2024-12-27,"Yuxin Chang, Alex Boyd, Cao Xiao, Taha Kass-Hout, Parminder Bhatia, Padhraic Smyth, Andrew Warrington",http://arxiv.org/pdf/2412.19634v1,cs.LG
Gradient Weight-normalized Low-rank Projection for Efficient LLM Training,"Large Language Models (LLMs) have shown remarkable performance across various
tasks, but the escalating demands on computational resources pose significant
challenges, particularly in the extensive utilization of full fine-tuning for
downstream tasks. To address this, parameter-efficient fine-tuning (PEFT)
methods have been developed, but they often underperform compared to full
fine-tuning and struggle with memory efficiency. In this work, we introduce
Gradient Weight-Normalized Low-Rank Projection (GradNormLoRP), a novel approach
that enhances both parameter and memory efficiency while maintaining comparable
performance to full fine-tuning. GradNormLoRP normalizes the weight matrix to
improve gradient conditioning, facilitating better convergence during
optimization. Additionally, it applies low-rank approximations to the weight
and gradient matrices, significantly reducing memory usage during training.
Extensive experiments demonstrate that our 8-bit GradNormLoRP reduces optimizer
memory usage by up to 89.5% and enables the pre-training of large LLMs, such as
LLaMA 7B, on consumer-level GPUs like the NVIDIA RTX 4090, without additional
inference costs. Moreover, GradNormLoRP outperforms existing low-rank methods
in fine-tuning tasks. For instance, when fine-tuning the RoBERTa model on all
GLUE tasks with a rank of 8, GradNormLoRP achieves an average score of 80.65,
surpassing LoRA's score of 79.23. These results underscore GradNormLoRP as a
promising alternative for efficient LLM pre-training and fine-tuning. Source
code:
https://github.com/Jhhuangkay/Gradient-Weight-normalized-Low-rank-Projection-for-Efficient-LLM-Training",2024-12-27,"Jia-Hong Huang, Yixian Shen, Hongyi Zhu, Stevan Rudinac, Evangelos Kanoulas",http://arxiv.org/pdf/2412.19616v2,cs.LG
ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion,"Drug-target interaction is fundamental in understanding how drugs affect
biological systems, and accurately predicting drug-target affinity (DTA) is
vital for drug discovery. Recently, deep learning methods have emerged as a
significant approach for estimating the binding strength between drugs and
target proteins. However, existing methods simply utilize the drug's local
information from molecular topology rather than global information.
Additionally, the features of drugs and proteins are usually fused with a
simple concatenation operation, limiting their effectiveness. To address these
challenges, we proposed ViDTA, an enhanced DTA prediction framework. We
introduce virtual nodes into the Graph Neural Network (GNN)-based drug feature
extraction network, which acts as a global memory to exchange messages more
efficiently. By incorporating virtual graph nodes, we seamlessly integrate
local and global features of drug molecular structures, expanding the GNN's
receptive field. Additionally, we propose an attention-based linear feature
fusion network for better capturing the interaction information between drugs
and proteins. Experimental results evaluated on various benchmarks including
Davis, Metz, and KIBA demonstrate that our proposed ViDTA outperforms the
state-of-the-art baselines.",2024-12-27,"Minghui Li, Zikang Guo, Yang Wu, Peijin Guo, Yao Shi, Shengshan Hu, Wei Wan, Shengqing Hu",http://arxiv.org/pdf/2412.19589v1,cs.LG
Goal-oriented Communications based on Recursive Early Exit Neural Networks,"This paper presents a novel framework for goal-oriented semantic
communications leveraging recursive early exit models. The proposed approach is
built on two key components. First, we introduce an innovative early exit
strategy that dynamically partitions computations, enabling samples to be
offloaded to a server based on layer-wise recursive prediction dynamics that
detect samples for which the confidence is not increasing fast enough over
layers. Second, we develop a Reinforcement Learning-based online optimization
framework that jointly determines early exit points, computation splitting, and
offloading strategies, while accounting for wireless conditions, inference
accuracy, and resource costs. Numerical evaluations in an edge inference
scenario demonstrate the method's adaptability and effectiveness in striking an
excellent trade-off between performance, latency, and resource efficiency.",2024-12-27,"Jary Pomponi, Mattia Merluzzi, Alessio Devoto, Mateus Pontes Mota, Paolo Di Lorenzo, Simone Scardapane",http://arxiv.org/pdf/2412.19587v1,cs.LG
Ultralight Signal Classification Model for Automatic Modulation Recognition,"The growing complexity of radar signals demands responsive and accurate
detection systems that can operate efficiently on resource-constrained edge
devices. Existing models, while effective, often rely on substantial
computational resources and large datasets, making them impractical for edge
deployment. In this work, we propose an ultralight hybrid neural network
optimized for edge applications, delivering robust performance across
unfavorable signal-to-noise ratios (mean accuracy of 96.3% at 0 dB) using less
than 100 samples per class, and significantly reducing computational overhead.",2024-12-27,"Alessandro Daniele Genuardi Oquendo, Agustín Matías Galante Cerviño, Nilotpal Kanti Sinha, Luc Andrea, Sam Mugel, Román Orús",http://arxiv.org/pdf/2412.19585v2,cs.LG
A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models,"Machine Unlearning has emerged as a critical area in artificial intelligence,
addressing the need to selectively remove learned data from machine learning
models in response to data privacy regulations. This paper provides a
comprehensive comparative analysis of six state-of-theart unlearning techniques
applied to image and text classification tasks. We evaluate their performance,
efficiency, and compliance with regulatory requirements, highlighting their
strengths and limitations in practical scenarios. By systematically analyzing
these methods, we aim to provide insights into their applicability,
challenges,and tradeoffs, fostering advancements in the field of ethical and
adaptable machine learning.",2024-12-27,"Omar M. Safa, Mahmoud M. Abdelaziz, Mustafa Eltawy, Mohamed Mamdouh, Moamen Gharib, Salaheldin Eltenihy, Nagia M. Ghanem, Mohamed M. Ismail",http://arxiv.org/pdf/2412.19583v1,cs.LG
Graph-attention-based Casual Discovery with Trust Region-navigated Clipping Policy Optimization,"In many domains of empirical sciences, discovering the causal structure
within variables remains an indispensable task. Recently, to tackle with
unoriented edges or latent assumptions violation suffered by conventional
methods, researchers formulated a reinforcement learning (RL) procedure for
causal discovery, and equipped REINFORCE algorithm to search for the
best-rewarded directed acyclic graph. The two keys to the overall performance
of the procedure are the robustness of RL methods and the efficient encoding of
variables. However, on the one hand, REINFORCE is prone to local convergence
and unstable performance during training. Neither trust region policy
optimization, being computationally-expensive, nor proximal policy optimization
(PPO), suffering from aggregate constraint deviation, is decent alternative for
combinatory optimization problems with considerable individual subactions. We
propose a trust region-navigated clipping policy optimization method for causal
discovery that guarantees both better search efficiency and steadiness in
policy optimization, in comparison with REINFORCE, PPO and our prioritized
sampling-guided REINFORCE implementation. On the other hand, to boost the
efficient encoding of variables, we propose a refined graph attention encoder
called SDGAT that can grasp more feature information without priori
neighbourhood information. With these improvements, the proposed method
outperforms former RL method in both synthetic and benchmark datasets in terms
of output results and optimization robustness.",2024-12-27,"Shixuan Liu, Yanghe Feng, Keyu Wu, Guangquan Cheng, Jincai Huang, Zhong Liu",http://arxiv.org/pdf/2412.19578v1,cs.LG
Interacted Object Grounding in Spatio-Temporal Human-Object Interactions,"Spatio-temporal Human-Object Interaction (ST-HOI) understanding aims at
detecting HOIs from videos, which is crucial for activity understanding.
However, existing whole-body-object interaction video benchmarks overlook the
truth that open-world objects are diverse, that is, they usually provide
limited and predefined object classes. Therefore, we introduce a new open-world
benchmark: Grounding Interacted Objects (GIO) including 1,098 interacted
objects class and 290K interacted object boxes annotation. Accordingly, an
object grounding task is proposed expecting vision systems to discover
interacted objects. Even though today's detectors and grounding methods have
succeeded greatly, they perform unsatisfactorily in localizing diverse and rare
objects in GIO. This profoundly reveals the limitations of current vision
systems and poses a great challenge. Thus, we explore leveraging
spatio-temporal cues to address object grounding and propose a 4D
question-answering framework (4D-QA) to discover interacted objects from
diverse videos. Our method demonstrates significant superiority in extensive
experiments compared to current baselines. Data and code will be publicly
available at https://github.com/DirtyHarryLYL/HAKE-AVA.",2024-12-27,"Xiaoyang Liu, Boran Wen, Xinpeng Liu, Zizheng Zhou, Hongwei Fan, Cewu Lu, Lizhuang Ma, Yulong Chen, Yong-Lu Li",http://arxiv.org/pdf/2412.19542v2,cs.LG
Data-Free Group-Wise Fully Quantized Winograd Convolution via Learnable Scales,"Despite the revolutionary breakthroughs of large-scale text-to-image
diffusion models for complex vision and downstream tasks, their extremely high
computational and storage costs limit their usability. Quantization of
diffusion models has been explored in recent works to reduce compute costs and
memory bandwidth usage. To further improve inference time, fast convolution
algorithms such as Winograd can be used for convolution layers, which account
for a significant portion of computations in diffusion models. However, the
significant quality loss of fully quantized Winograd using existing
coarser-grained post-training quantization methods, combined with the
complexity and cost of finetuning the Winograd transformation matrices for such
large models to recover quality, makes them unsuitable for large-scale
foundation models. Motivated by the presence of a large range of values in
them, we investigate the impact of finer-grained group-wise quantization in
quantizing diffusion models. While group-wise quantization can largely handle
the fully quantized Winograd convolution, it struggles to deal with the large
distribution imbalance in a sizable portion of the Winograd domain computation.
To reduce range differences in the Winograd domain, we propose finetuning only
the scale parameters of the Winograd transform matrices without using any
domain-specific training data. Because our method does not depend on any
training data, the generalization performance of quantized diffusion models is
safely guaranteed. For text-to-image generation task, the 8-bit fully-quantized
diffusion model with Winograd provides near-lossless quality (FID and CLIP
scores) in comparison to the full-precision model. For image classification,
our method outperforms the state-of-the-art Winograd PTQ method by 1.62% and
2.56% in top-1 ImageNet accuracy on ResNet18 and ResNet-34, respectively, with
Winograd F(6, 3).",2024-12-27,"Shuokai Pan, Gerti Tuzi, Sudarshan Sreeram, Dibakar Gope",http://arxiv.org/pdf/2412.19867v2,cs.LG
The Value of AI Advice: Personalized and Value-Maximizing AI Advisors Are Necessary to Reliably Benefit Experts and Organizations,"Despite advances in AI's performance and interpretability, AI advisors can
undermine experts' decisions and increase the time and effort experts must
invest to make decisions. Consequently, AI systems deployed in high-stakes
settings often fail to consistently add value across contexts and can even
diminish the value that experts alone provide. Beyond harm in specific domains,
such outcomes impede progress in research and practice, underscoring the need
to understand when and why different AI advisors add or diminish value. To
bridge this gap, we stress the importance of assessing the value AI advice
brings to real-world contexts when designing and evaluating AI advisors.
Building on this perspective, we characterize key pillars -- pathways through
which AI advice impacts value -- and develop a framework that incorporates
these pillars to create reliable, personalized, and value-adding advisors. Our
results highlight the need for system-level, value-driven development of AI
advisors that advise selectively, are tailored to experts' unique behaviors,
and are optimized for context-specific trade-offs between decision improvements
and advising costs. They also reveal how the lack of inclusion of these pillars
in the design of AI advising systems may be contributing to the failures
observed in practical applications.",2024-12-27,"Nicholas Wolczynski, Maytal Saar-Tsechansky, Tong Wang",http://arxiv.org/pdf/2412.19530v1,cs.LG
Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping,"Recently, the study of heavy-tailed noises in first-order nonconvex
stochastic optimization has gotten a lot of attention since it was recognized
as a more realistic condition as suggested by many empirical observations.
Specifically, the stochastic noise (the difference between the stochastic and
true gradient) is considered to have only a finite $\mathfrak{p}$-th moment
where $\mathfrak{p}\in\left(1,2\right]$ instead of assuming it always satisfies
the classical finite variance assumption. To deal with this more challenging
setting, people have proposed different algorithms and proved them to converge
at an optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate
for smooth objectives after $T$ iterations. Notably, all these new-designed
algorithms are based on the same technique - gradient clipping. Naturally, one
may want to know whether the clipping method is a necessary ingredient and the
only way to guarantee convergence under heavy-tailed noises. In this work, by
revisiting the existing Batched Normalized Stochastic Gradient Descent with
Momentum (Batched NSGDM) algorithm, we provide the first convergence result
under heavy-tailed noises but without gradient clipping. Concretely, we prove
that Batched NSGDM can achieve the optimal
$\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate even under the
relaxed smooth condition. More interestingly, we also establish the first
$\mathcal{O}(T^{\frac{1-\mathfrak{p}}{2\mathfrak{p}}})$ convergence rate in the
case where the tail index $\mathfrak{p}$ is unknown in advance, which is
arguably the common scenario in practice.",2024-12-27,"Zijian Liu, Zhengyuan Zhou",http://arxiv.org/pdf/2412.19529v3,cs.LG
Estimation of System Parameters Including Repeated Cross-Sectional Data through Emulator-Informed Deep Generative Model,"Differential equations (DEs) are crucial for modeling the evolution of
natural or engineered systems. Traditionally, the parameters in DEs are
adjusted to fit data from system observations. However, in fields such as
politics, economics, and biology, available data are often independently
collected at distinct time points from different subjects (i.e., repeated
cross-sectional (RCS) data). Conventional optimization techniques struggle to
accurately estimate DE parameters when RCS data exhibit various
heterogeneities, leading to a significant loss of information. To address this
issue, we propose a new estimation method called the emulator-informed
deep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM
integrates a physics-informed neural network-based emulator that immediately
generates DE solutions and a Wasserstein generative adversarial network-based
parameter generator that can effectively mimic the RCS data. We evaluated EIDGM
on exponential growth, logistic population models, and the Lorenz system,
demonstrating its superior ability to accurately capture parameter
distributions. Additionally, we applied EIDGM to an experimental dataset of
Amyloid beta 40 and beta 42, successfully capturing diverse parameter
distribution shapes. This shows that EIDGM can be applied to model a wide range
of systems and extended to uncover the operating principles of systems based on
limited data.",2024-12-27,"Hyunwoo Cho, Sung Woong Cho, Hyeontae Jo, Hyung Ju Hwang",http://arxiv.org/pdf/2412.19517v1,cs.LG
Real-time classification of EEG signals using Machine Learning deployment,"The prevailing educational methods predominantly rely on traditional
classroom instruction or online delivery, often limiting the teachers' ability
to engage effectively with all the students simultaneously. A more intrinsic
method of evaluating student attentiveness during lectures can enable the
educators to tailor the course materials and their teaching styles in order to
better meet the students' needs. The aim of this paper is to enhance teaching
quality in real time, thereby fostering a higher student engagement in the
classroom activities. By monitoring the students' electroencephalography (EEG)
signals and employing machine learning algorithms, this study proposes a
comprehensive solution for addressing this challenge. Machine learning has
emerged as a powerful tool for simplifying the analysis of complex variables,
enabling the effective assessment of the students' concentration levels based
on specific parameters. However, the real-time impact of machine learning
models necessitates a careful consideration as their deployment is concerned.
This study proposes a machine learning-based approach for predicting the level
of students' comprehension with regard to a certain topic. A browser interface
was introduced that accesses the values of the system's parameters to determine
a student's level of concentration on a chosen topic. The deployment of the
proposed system made it necessary to address the real-time challenges faced by
the students, consider the system's cost, and establish trust in its efficacy.
This paper presents the efforts made for approaching this pertinent issue
through the implementation of innovative technologies and provides a framework
for addressing key considerations for future research directions.",2024-12-27,"Swati Chowdhuri, Satadip Saha, Samadrita Karmakar, Ankur Chanda",http://arxiv.org/pdf/2412.19515v1,cs.LG
Uncertainty quantification for improving radiomic-based models in radiation pneumonitis prediction,"Background: Radiation pneumonitis is a side effect of thoracic radiation
therapy. Recently, machine learning models with radiomic features have improved
radiation pneumonitis prediction by capturing spatial information. To further
support clinical decision-making, this study explores the role of post hoc
uncertainty quantification methods in enhancing model uncertainty estimate.
Methods: We retrospectively analyzed a cohort of 101 esophageal cancer
patients. This study evaluated four machine learning models: logistic
regression, support vector machines, extreme gradient boosting, and random
forest, using 15 dosimetric, 79 dosiomic, and 237 radiomic features to predict
radiation pneumonitis. We applied uncertainty quantification methods, including
Platt scaling, isotonic regression, Venn-ABERS predictor, and conformal
prediction, to quantify uncertainty. Model performance was assessed through an
area under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and adaptive calibration error using
leave-one-out cross-validation. Results: Highest AUROC is achieved by the
logistic regression model with the conformal prediction method (AUROC
0.75+-0.01, AUPRC 0.74+-0.01) at a certainty cut point of 0.8. Highest AUPRC of
0.82+-0.02 (with AUROC of 0.67+-0.04) achieved by The extreme gradient boosting
model with conformal prediction at the 0.9 certainty threshold. Radiomic and
dosiomic features improve both discriminative and calibration performance.
Conclusions: Integrating uncertainty quantification into machine learning
models with radiomic and dosiomic features may improve both predictive accuracy
and calibration, supporting more reliable clinical decision-making. The
findings emphasize the value of uncertainty quantification methods in enhancing
applicability of predictive models for radiation pneumonitis in healthcare
settings.",2024-12-27,"Chanon Puttanawarut, Romen Samuel Wabina, Nat Sirirutbunkajorn",http://arxiv.org/pdf/2412.19511v3,cs.LG
RobotDiffuse: Motion Planning for Redundant Manipulator based on Diffusion Model,"Redundant manipulators, with their higher Degrees of Freedom (DOFs), offer
enhanced kinematic performance and versatility, making them suitable for
applications like manufacturing, surgical robotics, and human-robot
collaboration. However, motion planning for these manipulators is challenging
due to increased DOFs and complex, dynamic environments. While traditional
motion planning algorithms struggle with high-dimensional spaces, deep
learning-based methods often face instability and inefficiency in complex
tasks. This paper introduces RobotDiffuse, a diffusion model-based approach for
motion planning in redundant manipulators. By integrating physical constraints
with a point cloud encoder and replacing the U-Net structure with an
encoder-only transformer, RobotDiffuse improves the model's ability to capture
temporal dependencies and generate smoother, more coherent motion plans. We
validate the approach using a complex simulator, and release a new dataset with
35M robot poses and 0.14M obstacle avoidance scenarios. Experimental results
demonstrate the effectiveness of RobotDiffuse and the promise of diffusion
models for motion planning tasks. The code can be accessed at
https://github.com/ACRoboT-buaa/RobotDiffuse.",2024-12-27,"Xiaohan Zhang, Xudong Mou, Rui Wang, Tianyu Wo, Ningbo Gu, Tiejun Wang, Cangbai Xu, Xudong Liu",http://arxiv.org/pdf/2412.19500v1,cs.LG
Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases,"Machine Learning (ML) algorithms are vital for supporting clinical
decision-making in biomedical informatics. However, their predictive
performance can vary across demographic groups, often due to the
underrepresentation of historically marginalized populations in training
datasets. The investigation reveals widespread sex- and age-related inequities
in chronic disease datasets and their derived ML models. Thus, a novel
analytical framework is introduced, combining systematic arbitrariness with
traditional metrics like accuracy and data complexity. The analysis of data
from over 25,000 individuals with chronic diseases revealed mild sex-related
disparities, favoring predictive accuracy for males, and significant
age-related differences, with better accuracy for younger patients. Notably,
older patients showed inconsistent predictive accuracy across seven datasets,
linked to higher data complexity and lower model performance. This highlights
that representativeness in training data alone does not guarantee equitable
outcomes, and model arbitrariness must be addressed before deploying models in
clinical settings.",2024-12-27,"Ioannis Bilionis, Ricardo C. Berrios, Luis Fernandez-Luque, Carlos Castillo",http://arxiv.org/pdf/2412.19495v2,cs.LG
Meta-Learning-Based Delayless Subband Adaptive Filter using Complex Self-Attention for Active Noise Control,"Active noise control typically employs adaptive filtering to generate
secondary noise, where the least mean square algorithm is the most widely used.
However, traditional updating rules are linear and exhibit limited
effectiveness in addressing nonlinear environments and nonstationary noise. To
tackle this challenge, we reformulate the active noise control problem as a
meta-learning problem and propose a meta-learning-based delayless subband
adaptive filter with deep neural networks. The core idea is to utilize a neural
network as an adaptive algorithm that can adapt to different environments and
types of noise. The neural network will train under noisy observations,
implying that it recognizes the optimized updating rule without true labels. A
single-headed attention recurrent neural network is devised with learnable
feature embedding to update the adaptive filter weight efficiently, enabling
accurate computation of the secondary source to attenuate the unwanted primary
noise. In order to relax the time constraint on updating the adaptive filter
weights, the delayless subband architecture is employed, which will allow the
system to be updated less frequently as the downsampling factor increases. In
addition, the delayless subband architecture does not introduce additional time
delays in active noise control systems. A skip updating strategy is introduced
to decrease the updating frequency further so that machines with limited
resources have more possibility to board our meta-learning-based model.
Extensive multi-condition training ensures generalization and robustness
against various types of noise and environments. Simulation results demonstrate
that our meta-learning-based model achieves superior noise reduction
performance compared to traditional methods.",2024-12-27,"Pengxing Feng, Hing Cheung So",http://arxiv.org/pdf/2412.19471v1,cs.LG
Optimizing Helmet Detection with Hybrid YOLO Pipelines: A Detailed Analysis,"Helmet detection is crucial for advancing protection levels in public road
traffic dynamics. This problem statement translates to an object detection
task. Therefore, this paper compares recent You Only Look Once (YOLO) models in
the context of helmet detection in terms of reliability and computational load.
Specifically, YOLOv8, YOLOv9, and the newly released YOLOv11 have been used.
Besides, a modified architectural pipeline that remarkably improves the overall
performance has been proposed in this manuscript. This hybridized YOLO model
(h-YOLO) has been pitted against the independent models for analysis that
proves h-YOLO is preferable for helmet detection over plain YOLO models. The
models were tested using a range of standard object detection benchmarks such
as recall, precision, and mAP (Mean Average Precision). In addition, training
and testing times were recorded to provide the overall scope of the models in a
real-time detection scenario.",2024-12-27,"Vaikunth M, Dejey D, Vishaal C, Balamurali S",http://arxiv.org/pdf/2412.19467v1,cs.LG
Towards Simple and Provable Parameter-Free Adaptive Gradient Methods,"Optimization algorithms such as AdaGrad and Adam have significantly advanced
the training of deep models by dynamically adjusting the learning rate during
the optimization process. However, adhoc tuning of learning rates poses a
challenge, leading to inefficiencies in practice. To address this issue, recent
research has focused on developing ""learning-rate-free"" or ""parameter-free""
algorithms that operate effectively without the need for learning rate tuning.
Despite these efforts, existing parameter-free variants of AdaGrad and Adam
tend to be overly complex and/or lack formal convergence guarantees. In this
paper, we present AdaGrad++ and Adam++, novel and simple parameter-free
variants of AdaGrad and Adam with convergence guarantees. We prove that
AdaGrad++ achieves comparable convergence rates to AdaGrad in convex
optimization without predefined learning rate assumptions. Similarly, Adam++
matches the convergence rate of Adam without relying on any conditions on the
learning rates. Experimental results across various deep learning tasks
validate the competitive performance of AdaGrad++ and Adam++.",2024-12-27,"Yuanzhe Tao, Huizhuo Yuan, Xun Zhou, Yuan Cao, Quanquan Gu",http://arxiv.org/pdf/2412.19444v1,cs.LG
Comparative Performance Analysis of Quantum Machine Learning Architectures for Credit Card Fraud Detection,"As financial fraud becomes increasingly complex, effective detection methods
are essential. Quantum Machine Learning (QML) introduces certain capabilities
that may enhance both accuracy and efficiency in this area. This study examines
how different quantum feature map and ansatz configurations affect the
performance of three QML-based classifiers-the Variational Quantum Classifier
(VQC), the Sampler Quantum Neural Network (SQNN), and the Estimator Quantum
Neural Network (EQNN)-when applied to two non-standardized financial fraud
datasets. Different quantum feature map and ansatz configurations are
evaluated, revealing distinct performance patterns. The VQC consistently
demonstrates strong classification results, achieving an F1 score of 0.88,
while the SQNN also delivers promising outcomes. In contrast, the EQNN
struggles to produce robust results, emphasizing the challenges presented by
non-standardized data. These findings highlight the importance of careful model
configuration in QML-based financial fraud detection. By showing how specific
feature maps and ansatz choices influence predictive success, this work guides
researchers and practitioners in refining QML approaches for complex financial
applications.",2024-12-27,"Mansour El Alami, Nouhaila Innan, Muhammad Shafique, Mohamed Bennai",http://arxiv.org/pdf/2412.19441v2,cs.LG
Low-Rank Contextual Reinforcement Learning from Heterogeneous Human Feedback,"Reinforcement learning from human feedback (RLHF) has become a cornerstone
for aligning large language models with human preferences. However, the
heterogeneity of human feedback, driven by diverse individual contexts and
preferences, poses significant challenges for reward learning. To address this,
we propose a Low-rank Contextual RLHF (LoCo-RLHF) framework that integrates
contextual information to better model heterogeneous feedback while maintaining
computational efficiency. Our approach builds on a contextual preference model,
leveraging the intrinsic low-rank structure of the interaction between user
contexts and query-answer pairs to mitigate the high dimensionality of feature
representations. Furthermore, we address the challenge of distributional shifts
in feedback through our Pessimism in Reduced Subspace (PRS) policy, inspired by
pessimistic offline reinforcement learning techniques. We theoretically
demonstrate that our policy achieves a tighter sub-optimality gap compared to
existing methods. Extensive experiments validate the effectiveness of
LoCo-RLHF, showcasing its superior performance in personalized RLHF settings
and its robustness to distribution shifts.",2024-12-27,"Seong Jin Lee, Will Wei Sun, Yufeng Liu",http://arxiv.org/pdf/2412.19436v1,cs.LG
Revisiting PCA for time series reduction in temporal dimension,"Revisiting PCA for Time Series Reduction in Temporal Dimension; Jiaxin Gao,
Wenbo Hu, Yuntian Chen; Deep learning has significantly advanced time series
analysis (TSA), enabling the extraction of complex patterns for tasks like
classification, forecasting, and regression. Although dimensionality reduction
has traditionally focused on the variable space-achieving notable success in
minimizing data redundancy and computational complexity-less attention has been
paid to reducing the temporal dimension. In this study, we revisit Principal
Component Analysis (PCA), a classical dimensionality reduction technique, to
explore its utility in temporal dimension reduction for time series data. It is
generally thought that applying PCA to the temporal dimension would disrupt
temporal dependencies, leading to limited exploration in this area. However,
our theoretical analysis and extensive experiments demonstrate that applying
PCA to sliding series windows not only maintains model performance, but also
enhances computational efficiency. In auto-regressive forecasting, the temporal
structure is partially preserved through windowing, and PCA is applied within
these windows to denoise the time series while retaining their statistical
information. By preprocessing time-series data with PCA, we reduce the temporal
dimensionality before feeding it into TSA models such as Linear, Transformer,
CNN, and RNN architectures. This approach accelerates training and inference
and reduces resource consumption. Notably, PCA improves Informer training and
inference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%,
without sacrificing model accuracy. Comparative analysis against other
reduction methods further highlights the effectiveness of PCA in improving the
efficiency of TSA models.",2024-12-27,"Jiaxin Gao, Wenbo Hu, Yuntian Chen",http://arxiv.org/pdf/2412.19423v1,cs.LG
De Novo Generation of Hit-like Molecules from Gene Expression Profiles via Deep Learning,"De novo generation of hit-like molecules is a challenging task in the drug
discovery process. Most methods in previous studies learn the semantics and
syntax of molecular structures by analyzing molecular graphs or simplified
molecular input line entry system (SMILES) strings; however, they do not take
into account the drug responses of the biological systems consisting of genes
and proteins. In this study we propose a hybrid neural network, HNN2Mol, which
utilizes gene expression profiles to generate molecular structures with
desirable phenotypes for arbitrary target proteins. In the algorithm, a
variational autoencoder is employed as a feature extractor to learn the latent
feature distribution of the gene expression profiles. Then, a long short-term
memory is leveraged as the chemical generator to produce syntactically valid
SMILES strings that satisfy the feature conditions of the gene expression
profile extracted by the feature extractor. Experimental results and case
studies demonstrate that the proposed HNN2Mol model can produce new molecules
with potential bioactivities and drug-like properties.",2024-12-27,"Chen Li, Yoshihiro Yamanishi",http://arxiv.org/pdf/2412.19422v2,cs.LG
Introduction to Graph Neural Networks: A Starting Point for Machine Learning Engineers,"Graph neural networks are deep neural networks designed for graphs with
attributes attached to nodes or edges. The number of research papers in the
literature concerning these models is growing rapidly due to their impressive
performance on a broad range of tasks. This survey introduces graph neural
networks through the encoder-decoder framework and provides examples of
decoders for a range of graph analytic tasks. It uses theory and numerous
experiments on homogeneous graphs to illustrate the behavior of graph neural
networks for different training sizes and degrees of graph complexity.",2024-12-27,"James H. Tanis, Chris Giannella, Adrian V. Mariano",http://arxiv.org/pdf/2412.19419v1,cs.LG
Spectral-Temporal Fusion Representation for Person-in-Bed Detection,"This study is based on the ICASSP 2025 Signal Processing Grand Challenge's
Accelerometer-Based Person-in-Bed Detection Challenge, which aims to determine
bed occupancy using accelerometer signals. The task is divided into two tracks:
""in bed"" and ""not in bed"" segmented detection, and streaming detection, facing
challenges such as individual differences, posture variations, and external
disturbances. We propose a spectral-temporal fusion-based feature
representation method with mixup data augmentation, and adopt Intersection over
Union (IoU) loss to optimize detection accuracy. In the two tracks, our method
achieved outstanding results of 100.00% and 95.55% in detection scores,
securing first place and third place, respectively.",2024-12-27,"Xuefeng Yang, Shiheng Zhang, Jian Guan, Feiyang Xiao, Wei Lu, Qiaoxi Zhu",http://arxiv.org/pdf/2412.19404v1,cs.LG
Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model,"Discrete choice models are essential for modelling various decision-making
processes in human behaviour. However, the specification of these models has
depended heavily on domain knowledge from experts, and the fully automated but
interpretable modelling of complex human behaviours has been a long-standing
challenge. In this paper, we introduce the differentiable discrete choice model
(Diff-DCM), a fully data-driven method for the interpretable modelling,
learning, prediction, and control of complex human behaviours, which is
realised by differentiable programming. Solely from input features and choice
outcomes without any prior knowledge, Diff-DCM can estimate interpretable
closed-form utility functions that reproduce observed behaviours. Comprehensive
experiments with both synthetic and real-world data demonstrate that Diff-DCM
can be applied to various types of data and requires only a small amount of
computational resources for the estimations, which can be completed within tens
of seconds on a laptop without any accelerators. In these experiments, we also
demonstrate that, using its differentiability, Diff-DCM can provide useful
insights into human behaviours, such as an optimal intervention path for
effective behavioural changes. This study provides a strong basis for the fully
automated and reliable modelling, prediction, and control of human behaviours.",2024-12-27,"Fumiyasu Makinoshima, Tatsuya Mitomi, Fumiya Makihara, Eigo Segawa",http://arxiv.org/pdf/2412.19403v2,cs.LG
Comparing Few to Rank Many: Active Human Preference Learning using Randomized Frank-Wolfe,"We study learning of human preferences from a limited comparison feedback.
This task is ubiquitous in machine learning. Its applications such as
reinforcement learning from human feedback, have been transformational. We
formulate this problem as learning a Plackett-Luce model over a universe of $N$
choices from $K$-way comparison feedback, where typically $K \ll N$. Our
solution is the D-optimal design for the Plackett-Luce objective. The design
defines a data logging policy that elicits comparison feedback for a small
collection of optimally chosen points from all ${N \choose K}$ feasible
subsets. The main algorithmic challenge in this work is that even fast methods
for solving D-optimal designs would have $O({N \choose K})$ time complexity. To
address this issue, we propose a randomized Frank-Wolfe (FW) algorithm that
solves the linear maximization sub-problems in the FW method on randomly chosen
variables. We analyze the algorithm, and evaluate it empirically on synthetic
and open-source NLP datasets.",2024-12-27,"Kiran Koshy Thekumparampil, Gaurush Hiranandani, Kousha Kalantari, Shoham Sabach, Branislav Kveton",http://arxiv.org/pdf/2412.19396v1,cs.LG
Asymptotically Optimal Search for a Change Point Anomaly under a Composite Hypothesis Model,"We address the problem of searching for a change point in an anomalous
process among a finite set of M processes. Specifically, we address a composite
hypothesis model in which each process generates measurements following a
common distribution with an unknown parameter (vector). This parameter belongs
to either a normal or abnormal space depending on the current state of the
process. Before the change point, all processes, including the anomalous one,
are in a normal state; after the change point, the anomalous process
transitions to an abnormal state. Our goal is to design a sequential search
strategy that minimizes the Bayes risk by balancing sample complexity and
detection accuracy. We propose a deterministic search algorithm with the
following notable properties. First, we analytically demonstrate that when the
distributions of both normal and abnormal processes are unknown, the algorithm
is asymptotically optimal in minimizing the Bayes risk as the error probability
approaches zero. In the second setting, where the parameter under the null
hypothesis is known, the algorithm achieves asymptotic optimality with improved
detection time based on the true normal state. Simulation results are presented
to validate the theoretical findings.",2024-12-27,"Liad Lea Didi, Tomer Gafni, Kobi Cohen",http://arxiv.org/pdf/2412.19392v1,cs.LG
An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for Digit Classification,"Domain adaptation is an active area of research driven by the growing demand
for robust machine learning models that perform well on real-world data.
Adversarial learning for deep neural networks (DNNs) has emerged as a promising
approach to improving generalization ability, particularly for image
classification. In this paper, we implement a specific adversarial learning
technique known as Adversarial Discriminative Domain Adaptation (ADDA) and
replicate digit classification experiments from the original ADDA paper. We
extend their findings by examining a broader range of domain shifts and provide
a detailed analysis of in-domain classification accuracy post-ADDA. Our results
demonstrate that ADDA significantly improves accuracy across certain domain
shifts with minimal impact on in-domain performance. Furthermore, we provide
qualitative analysis and propose potential explanations for ADDA's limitations
in less successful domain shifts. Code is at
https://github.com/eugenechoi2004/COS429_FINAL .",2024-12-27,"Eugene Choi, Julian Rodriguez, Edmund Young",http://arxiv.org/pdf/2412.19391v2,cs.LG
Minimal Batch Adaptive Learning Policy Engine for Real-Time Mid-Price Forecasting in High-Frequency Trading,"High-frequency trading (HFT) has transformed modern financial markets, making
reliable short-term price forecasting models essential. In this study, we
present a novel approach to mid-price forecasting using Level 1 limit order
book (LOB) data from NASDAQ, focusing on 100 U.S. stocks from the S&P 500 index
during the period from September to November 2022. Expanding on our previous
work with Radial Basis Function Neural Networks (RBFNN), which leveraged
automated feature importance techniques based on mean decrease impurity (MDI)
and gradient descent (GD), we introduce the Adaptive Learning Policy Engine
(ALPE) - a reinforcement learning (RL)-based agent designed for batch-free,
immediate mid-price forecasting. ALPE incorporates adaptive epsilon decay to
dynamically balance exploration and exploitation, outperforming a diverse range
of highly effective machine learning (ML) and deep learning (DL) models in
forecasting performance.",2024-12-26,"Adamantios Ntakaris, Gbenga Ibikunle",http://arxiv.org/pdf/2412.19372v2,cs.LG
Large Language Models for Market Research: A Data-augmentation Approach,"Large Language Models (LLMs) have transformed artificial intelligence by
excelling in complex natural language processing tasks. Their ability to
generate human-like text has opened new possibilities for market research,
particularly in conjoint analysis, where understanding consumer preferences is
essential but often resource-intensive. Traditional survey-based methods face
limitations in scalability and cost, making LLM-generated data a promising
alternative. However, while LLMs have the potential to simulate real consumer
behavior, recent studies highlight a significant gap between LLM-generated and
human data, with biases introduced when substituting between the two. In this
paper, we address this gap by proposing a novel statistical data augmentation
approach that efficiently integrates LLM-generated data with real data in
conjoint analysis. Our method leverages transfer learning principles to debias
the LLM-generated data using a small amount of human data. This results in
statistically robust estimators with consistent and asymptotically normal
properties, in contrast to naive approaches that simply substitute human data
with LLM-generated data, which can exacerbate bias. We validate our framework
through an empirical study on COVID-19 vaccine preferences, demonstrating its
superior ability to reduce estimation error and save data and costs by 24.9% to
79.8%. In contrast, naive approaches fail to save data due to the inherent
biases in LLM-generated data compared to human data. Another empirical study on
sports car choices validates the robustness of our results. Our findings
suggest that while LLM-generated data is not a direct substitute for human
responses, it can serve as a valuable complement when used within a robust
statistical framework.",2024-12-26,"Mengxin Wang, Dennis J. Zhang, Heng Zhang",http://arxiv.org/pdf/2412.19363v2,cs.LG
Evaluating Convolutional Neural Networks for COVID-19 classification in chest X-ray images,"Coronavirus Disease 2019 (COVID-19) pandemic rapidly spread globally,
impacting the lives of billions of people. The effective screening of infected
patients is a critical step to struggle with COVID-19, and treating the
patients avoiding this quickly disease spread. The need for automated and
scalable methods has increased due to the unavailability of accurate automated
toolkits. Recent researches using chest X-ray images suggest they include
relevant information about the COVID-19 virus. Hence, applying machine learning
techniques combined with radiological imaging promises to identify this disease
accurately. It is straightforward to collect these images once it is spreadly
shared and analyzed in the world. This paper presents a method for automatic
COVID-19 detection using chest Xray images through four convolutional neural
networks, namely: AlexNet, VGG-11, SqueezeNet, and DenseNet-121. This method
had been providing accurate diagnostics for positive or negative COVID-19
classification. We validate our experiments using a ten-fold cross-validation
procedure over the training and test sets. Our findings include the shallow
fine-tuning and data augmentation strategies that can assist in dealing with
the low number of positive COVID-19 images publicly available. The accuracy for
all CNNs is higher than 97.00%, and the SqueezeNet model achieved the best
result with 99.20%.",2024-12-26,"Leonardo Gabriel Ferreira Rodrigues, Danilo Ferreira da Silva, Larissa Ferreira Rodrigues, João Fernando Mari",http://arxiv.org/pdf/2412.19362v1,cs.LG
Federated Hybrid Training and Self-Adversarial Distillation: Towards Robust Edge Networks,"Federated learning (FL) is a distributed training technology that enhances
data privacy in mobile edge networks by allowing data owners to collaborate
without transmitting raw data to the edge server. However, data heterogeneity
and adversarial attacks pose challenges to develop an unbiased and robust
global model for edge deployment. To address this, we propose Federated hyBrid
Adversarial training and self-adversarial disTillation (FedBAT), a new
framework designed to improve both robustness and generalization of the global
model. FedBAT seamlessly integrates hybrid adversarial training and
self-adversarial distillation into the conventional FL framework from data
augmentation and feature distillation perspectives. From a data augmentation
perspective, we propose hybrid adversarial training to defend against
adversarial attacks by balancing accuracy and robustness through a weighted
combination of standard and adversarial training. From a feature distillation
perspective, we introduce a novel augmentation-invariant adversarial
distillation method that aligns local adversarial features of augmented images
with their corresponding unbiased global clean features. This alignment can
effectively mitigate bias from data heterogeneity while enhancing both the
robustness and generalization of the global model. Extensive experimental
results across multiple datasets demonstrate that FedBAT yields comparable or
superior performance gains in improving robustness while maintaining accuracy
compared to several baselines.",2024-12-26,"Yu Qiao, Apurba Adhikary, Kitae Kim, Eui-Nam Huh, Zhu Han, Choong Seon Hong",http://arxiv.org/pdf/2412.19354v1,cs.LG
ETTA: Elucidating the Design Space of Text-to-Audio Models,"Recent years have seen significant progress in Text-To-Audio (TTA) synthesis,
enabling users to enrich their creative workflows with synthetic audio
generated from natural language prompts. Despite this progress, the effects of
data, model architecture, training objective functions, and sampling strategies
on target benchmarks are not well understood. With the purpose of providing a
holistic understanding of the design space of TTA models, we set up a
large-scale empirical experiment focused on diffusion and flow matching models.
Our contributions include: 1) AF-Synthetic, a large dataset of high quality
synthetic captions obtained from an audio understanding model; 2) a systematic
comparison of different architectural, training, and inference design choices
for TTA models; 3) an analysis of sampling methods and their Pareto curves with
respect to generation quality and inference speed. We leverage the knowledge
obtained from this extensive analysis to propose our best model dubbed
Elucidated Text-To-Audio (ETTA). When evaluated on AudioCaps and MusicCaps,
ETTA provides improvements over the baselines trained on publicly available
data, while being competitive with models trained on proprietary data. Finally,
we show ETTA's improved ability to generate creative audio following complex
and imaginative captions -- a task that is more challenging than current
benchmarks.",2024-12-26,"Sang-gil Lee, Zhifeng Kong, Arushi Goel, Sungwon Kim, Rafael Valle, Bryan Catanzaro",http://arxiv.org/pdf/2412.19351v1,cs.LG
On the Expressiveness and Length Generalization of Selective State-Space Models on Regular Languages,"Selective state-space models (SSMs) are an emerging alternative to the
Transformer, offering the unique advantage of parallel training and sequential
inference. Although these models have shown promising performance on a variety
of tasks, their formal expressiveness and length generalization properties
remain underexplored. In this work, we provide insight into the workings of
selective SSMs by analyzing their expressiveness and length generalization
performance on regular language tasks, i.e., finite-state automaton (FSA)
emulation. We address certain limitations of modern SSM-based architectures by
introducing the Selective Dense State-Space Model (SD-SSM), the first selective
SSM that exhibits perfect length generalization on a set of various regular
language tasks using a single layer. It utilizes a dictionary of dense
transition matrices, a softmax selection mechanism that creates a convex
combination of dictionary matrices at each time step, and a readout consisting
of layer normalization followed by a linear map. We then proceed to evaluate
variants of diagonal selective SSMs by considering their empirical performance
on commutative and non-commutative automata. We explain the experimental
results with theoretical considerations. Our code is available at
https://github.com/IBM/selective-dense-state-space-model.",2024-12-26,"Aleksandar Terzić, Michael Hersche, Giacomo Camposampiero, Thomas Hofmann, Abu Sebastian, Abbas Rahimi",http://arxiv.org/pdf/2412.19350v1,cs.LG
A Reinforcement Learning-Based Task Mapping Method to Improve the Reliability of Clustered Manycores,"The increasing scale of manycore systems poses significant challenges in
managing reliability while meeting performance demands. Simultaneously, these
systems become more susceptible to different aging mechanisms such as
negative-bias temperature instability (NBTI), hot carrier injection (HCI), and
thermal cycling (TC), as well as the electromigration (EM) phenomenon. In this
paper, we propose a reinforcement learning (RL)-based task mapping method to
improve the reliability of manycore systems considering the aforementioned
aging mechanisms, which consists of three steps including bin packing,
task-to-bin mapping, and task-to-core mapping. In the initial step, a
density-based spatial application with noise (DBSCAN) clustering method is
employed to compose some clusters (bins) based on the cores temperature. Then,
the Q-learning algorithm is used for the two latter steps, to map the arrived
task on a core such that the minimum thermal variation is occurred among all
the bins. Compared to the state-of-the-art works, the proposed method is
performed during runtime without requiring any parameter to be calculated
offline. The effectiveness of the proposed technique is evaluated on 16, 32,
and 64 cores systems using SPLASH2 and PARSEC benchmark suite applications. The
results demonstrate up to 27% increase in the mean time to failure (MTTF)
compared to the state-of-the-art task mapping techniques.",2024-12-26,"Fatemeh Hossein-Khani, Omid Akbari",http://arxiv.org/pdf/2412.19340v1,cs.LG
CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models,"Recent advances in Large Vision-Language Models (LVLMs) have enabled
general-purpose vision tasks through visual instruction tuning. While existing
LVLMs can generate segmentation masks from text prompts for single images, they
struggle with segmentation-grounded reasoning across images, especially at
finer granularities such as object parts. In this paper, we introduce the new
task of part-focused semantic co-segmentation, which involves identifying and
segmenting common objects, as well as common and unique object parts across
images. To address this task, we present CALICO, the first LVLM designed for
multi-image part-level reasoning segmentation. CALICO features two key
components, a novel Correspondence Extraction Module that identifies semantic
part-level correspondences, and Correspondence Adaptation Modules that embed
this information into the LVLM to facilitate multi-image understanding in a
parameter-efficient manner. To support training and evaluation, we curate
MixedParts, a large-scale multi-image segmentation dataset containing
$\sim$2.4M samples across $\sim$44K images spanning diverse object and part
categories. Experimental results demonstrate that CALICO, with just 0.3% of its
parameters finetuned, achieves strong performance on this challenging task.",2024-12-26,"Kiet A. Nguyen, Adheesh Juvekar, Tianjiao Yu, Muntasir Wahed, Ismini Lourentzou",http://arxiv.org/pdf/2412.19331v2,cs.LG
Deep learning and whole-brain networks for biomarker discovery: modeling the dynamics of brain fluctuations in resting-state and cognitive tasks,"Background: Brain network models offer insights into brain dynamics, but the
utility of model-derived bifurcation parameters as biomarkers remains
underexplored. Objective: This study evaluates bifurcation parameters from a
whole-brain network model as biomarkers for distinguishing brain states
associated with resting-state and task-based cognitive conditions. Methods:
Synthetic BOLD signals were generated using a supercritical Hopf brain network
model to train deep learning models for bifurcation parameter prediction.
Inference was performed on Human Connectome Project data, including both
resting-state and task-based conditions. Statistical analyses assessed the
separability of brain states based on bifurcation parameter distributions.
Results: Bifurcation parameter distributions differed significantly across task
and resting-state conditions ($p < 0.0001$ for all but one comparison).
Task-based brain states exhibited higher bifurcation values compared to rest.
Conclusion: Bifurcation parameters effectively differentiate cognitive and
resting states, warranting further investigation as biomarkers for brain state
characterization and neurological disorder assessment.",2024-12-26,"Facundo Roffet, Gustavo Deco, Claudio Delrieux, Gustavo Patow",http://arxiv.org/pdf/2412.19329v1,cs.LG
Performance Control in Early Exiting to Deploy Large Models at the Same Cost of Smaller Ones,"Early Exiting (EE) is a promising technique for speeding up inference by
adaptively allocating compute resources to data points based on their
difficulty. The approach enables predictions to exit at earlier layers for
simpler samples while reserving more computation for challenging ones. In this
study, we first present a novel perspective on the EE approach, showing that
larger models deployed with EE can achieve higher performance than smaller
models while maintaining similar computational costs. As existing EE approaches
rely on confidence estimation at each exit point, we further study the impact
of overconfidence on the controllability of the compute-performance trade-off.
We introduce Performance Control Early Exiting (PCEE), a method that enables
accuracy thresholding by basing decisions not on a data point's confidence but
on the average accuracy of samples with similar confidence levels from a
held-out validation set. In our experiments, we show that PCEE offers a simple
yet computationally efficient approach that provides better control over
performance than standard confidence-based approaches, and allows us to scale
up model sizes to yield performance gain while reducing the computational cost.",2024-12-26,"Mehrnaz Mofakhami, Reza Bayat, Ioannis Mitliagkas, Joao Monteiro, Valentina Zantedeschi",http://arxiv.org/pdf/2412.19325v1,cs.LG
Adaptive Conformal Inference by Betting,"Conformal prediction is a valuable tool for quantifying predictive
uncertainty of machine learning models. However, its applicability relies on
the assumption of data exchangeability, a condition which is often not met in
real-world scenarios. In this paper, we consider the problem of adaptive
conformal inference without any assumptions about the data generating process.
Existing approaches for adaptive conformal inference are based on optimizing
the pinball loss using variants of online gradient descent. A notable
shortcoming of such approaches is in their explicit dependence on and
sensitivity to the choice of the learning rates. In this paper, we propose a
different approach for adaptive conformal inference that leverages
parameter-free online convex optimization techniques. We prove that our method
controls long-term miscoverage frequency at a nominal level and demonstrate its
convincing empirical performance without any need of performing cumbersome
parameter tuning.",2024-12-26,"Aleksandr Podkopaev, Darren Xu, Kuang-Chih Lee",http://arxiv.org/pdf/2412.19318v1,cs.LG
xSRL: Safety-Aware Explainable Reinforcement Learning -- Safety as a Product of Explainability,"Reinforcement learning (RL) has shown great promise in simulated
environments, such as games, where failures have minimal consequences. However,
the deployment of RL agents in real-world systems such as autonomous vehicles,
robotics, UAVs, and medical devices demands a higher level of safety and
transparency, particularly when facing adversarial threats. Safe RL algorithms
have been developed to address these concerns by optimizing both task
performance and safety constraints. However, errors are inevitable, and when
they occur, it is essential that the RL agents can also explain their actions
to human operators. This makes trust in the safety mechanisms of RL systems
crucial for effective deployment. Explainability plays a key role in building
this trust by providing clear, actionable insights into the agent's
decision-making process, ensuring that safety-critical decisions are well
understood. While machine learning (ML) has seen significant advances in
interpretability and visualization, explainability methods for RL remain
limited. Current tools fail to address the dynamic, sequential nature of RL and
its needs to balance task performance with safety constraints over time. The
re-purposing of traditional ML methods, such as saliency maps, is inadequate
for safety-critical RL applications where mistakes can result in severe
consequences. To bridge this gap, we propose xSRL, a framework that integrates
both local and global explanations to provide a comprehensive understanding of
RL agents' behavior. xSRL also enables developers to identify policy
vulnerabilities through adversarial attacks, offering tools to debug and patch
agents without retraining. Our experiments and user studies demonstrate xSRL's
effectiveness in increasing safety in RL systems, making them more reliable and
trustworthy for real-world deployment. Code is available at
https://github.com/risal-shefin/xSRL.",2024-12-26,"Risal Shahriar Shefin, Md Asifur Rahman, Thai Le, Sarra Alqahtani",http://arxiv.org/pdf/2412.19311v1,cs.LG
RAG with Differential Privacy,"Retrieval-Augmented Generation (RAG) has emerged as the dominant technique to
provide \emph{Large Language Models} (LLM) with fresh and relevant context,
mitigating the risk of hallucinations and improving the overall quality of
responses in environments with large and fast moving knowledge bases. However,
the integration of external documents into the generation process raises
significant privacy concerns. Indeed, when added to a prompt, it is not
possible to guarantee a response will not inadvertently expose confidential
data, leading to potential breaches of privacy and ethical dilemmas. This paper
explores a practical solution to this problem suitable to general knowledge
extraction from personal data. It shows \emph{differentially private token
generation} is a viable approach to private RAG.",2024-12-26,Nicolas Grislain,http://arxiv.org/pdf/2412.19291v2,cs.LG
ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning,"Recent lightweight image captioning models using retrieved data mainly focus
on text prompts. However, previous works only utilize the retrieved text as
text prompts, and the visual information relies only on the CLIP visual
embedding. Because of this issue, there is a limitation that the image
descriptions inherent in the prompt are not sufficiently reflected in the
visual embedding space. To tackle this issue, we propose ViPCap, a novel
retrieval text-based visual prompt for lightweight image captioning. ViPCap
leverages the retrieved text with image information as visual prompts to
enhance the ability of the model to capture relevant visual information. By
mapping text prompts into the CLIP space and generating multiple randomized
Gaussian distributions, our method leverages sampling to explore randomly
augmented distributions and effectively retrieves the semantic features that
contain image information. These retrieved features are integrated into the
image and designated as the visual prompt, leading to performance improvements
on the datasets such as COCO, Flickr30k, and NoCaps. Experimental results
demonstrate that ViPCap significantly outperforms prior lightweight captioning
models in efficiency and effectiveness, demonstrating the potential for a
plug-and-play solution. The source code is available at
https://github.com/taewhankim/VIPCAP.",2024-12-26,"Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim",http://arxiv.org/pdf/2412.19289v3,cs.LG
Time Series Foundational Models: Their Role in Anomaly Detection and Prediction,"Time series foundational models (TSFM) have gained prominence in time series
forecasting, promising state-of-the-art performance across various
applications. However, their application in anomaly detection and prediction
remains underexplored, with growing concerns regarding their black-box nature,
lack of interpretability and applicability. This paper critically evaluates the
efficacy of TSFM in anomaly detection and prediction tasks. We systematically
analyze TSFM across multiple datasets, including those characterized by the
absence of discernible patterns, trends and seasonality. Our analysis shows
that while TSFMs can be extended for anomaly detection and prediction,
traditional statistical and deep learning models often match or outperform TSFM
in these tasks. Additionally, TSFMs require high computational resources but
fail to capture sequential dependencies effectively or improve performance in
few-shot or zero-shot scenarios. \noindent The preprocessed datasets, codes to
reproduce the results and supplementary materials are available at
https://github.com/smtmnfg/TSFM.",2024-12-26,"Chathurangi Shyalika, Harleen Kaur Bagga, Ahan Bhatt, Renjith Prasad, Alaa Al Ghazo, Amit Sheth",http://arxiv.org/pdf/2412.19286v1,cs.LG
PearSAN: A Machine Learning Method for Inverse Design using Pearson Correlated Surrogate Annealing,"PearSAN is a machine learning-assisted optimization algorithm applicable to
inverse design problems with large design spaces, where traditional optimizers
struggle. The algorithm leverages the latent space of a generative model for
rapid sampling and employs a Pearson correlated surrogate model to predict the
figure of merit of the true design metric. As a showcase example, PearSAN is
applied to thermophotovoltaic (TPV) metasurface design by matching the working
bands between a thermal radiator and a photovoltaic cell. PearSAN can work with
any pretrained generative model with a discretized latent space, making it easy
to integrate with VQ-VAEs and binary autoencoders. Its novel Pearson
correlational loss can be used as both a latent regularization method, similar
to batch and layer normalization, and as a surrogate training loss. We compare
both to previous energy matching losses, which are shown to enforce poor
regularization and performance, even with upgraded affine parameters. PearSAN
achieves a state-of-the-art maximum design efficiency of 97%, and is at least
an order of magnitude faster than previous methods, with an improved maximum
figure-of-merit gain.",2024-12-26,"Michael Bezick, Blake A. Wilson, Vaishnavi Iyer, Yuheng Chen, Vladimir M. Shalaev, Sabre Kais, Alexander V. Kildishev, Alexandra Boltasseva, Brad Lackey",http://arxiv.org/pdf/2412.19284v1,cs.LG
Improving Generalization for AI-Synthesized Voice Detection,"AI-synthesized voice technology has the potential to create realistic human
voices for beneficial applications, but it can also be misused for malicious
purposes. While existing AI-synthesized voice detection models excel in
intra-domain evaluation, they face challenges in generalizing across different
domains, potentially becoming obsolete as new voice generators emerge. Current
solutions use diverse data and advanced machine learning techniques (e.g.,
domain-invariant representation, self-supervised learning), but are limited by
predefined vocoders and sensitivity to factors like background noise and
speaker identity. In this work, we introduce an innovative disentanglement
framework aimed at extracting domain-agnostic artifact features related to
vocoders. Utilizing these features, we enhance model learning in a flat loss
landscape, enabling escape from suboptimal solutions and improving
generalization. Extensive experiments on benchmarks show our approach
outperforms state-of-the-art methods, achieving up to 5.12% improvement in the
equal error rate metric in intra-domain and 7.59% in cross-domain evaluations.",2024-12-26,"Hainan Ren, Li Lin, Chun-Hao Liu, Xin Wang, Shu Hu",http://arxiv.org/pdf/2412.19279v2,cs.LG
Optimizing Multi-Stage Language Models for Effective Text Retrieval,"Efficient text retrieval is critical for applications such as legal document
analysis, particularly in specialized contexts like Japanese legal systems.
Existing retrieval methods often underperform in such domain-specific
scenarios, necessitating tailored approaches. In this paper, we introduce a
novel two-phase text retrieval pipeline optimized for Japanese legal datasets.
Our method leverages advanced language models to achieve state-of-the-art
performance, significantly improving retrieval efficiency and accuracy. To
further enhance robustness and adaptability, we incorporate an ensemble model
that integrates multiple retrieval strategies, resulting in superior outcomes
across diverse tasks. Extensive experiments validate the effectiveness of our
approach, demonstrating strong performance on both Japanese legal datasets and
widely recognized benchmarks like MS-MARCO. Our work establishes new standards
for text retrieval in domain-specific and general contexts, providing a
comprehensive solution for addressing complex queries in legal and multilingual
environments.",2024-12-26,"Quang Hoang Trung, Le Trung Hoang, Nguyen Van Hoang Phuc",http://arxiv.org/pdf/2412.19265v1,cs.LG
MEDEC: A Benchmark for Medical Error Detection and Correction in Clinical Notes,"Several studies showed that Large Language Models (LLMs) can answer medical
questions correctly, even outperforming the average human score in some medical
exams. However, to our knowledge, no study has been conducted to assess the
ability of language models to validate existing or generated medical text for
correctness and consistency. In this paper, we introduce MEDEC
(https://github.com/abachaa/MEDEC), the first publicly available benchmark for
medical error detection and correction in clinical notes, covering five types
of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal
Organism). MEDEC consists of 3,848 clinical texts, including 488 clinical notes
from three US hospital systems that were not previously seen by any LLM. The
dataset has been used for the MEDIQA-CORR shared task to evaluate seventeen
participating systems [Ben Abacha et al., 2024]. In this paper, we describe the
data creation methods and we evaluate recent LLMs (e.g., o1-preview, GPT-4,
Claude 3.5 Sonnet, and Gemini 2.0 Flash) for the tasks of detecting and
correcting medical errors requiring both medical knowledge and reasoning
capabilities. We also conducted a comparative study where two medical doctors
performed the same task on the MEDEC test set. The results showed that MEDEC is
a sufficiently challenging benchmark to assess the ability of models to
validate existing or generated notes and to correct medical errors. We also
found that although recent LLMs have a good performance in error detection and
correction, they are still outperformed by medical doctors in these tasks. We
discuss the potential factors behind this gap, the insights from our
experiments, the limitations of current evaluation metrics, and share potential
pointers for future research.",2024-12-26,"Asma Ben Abacha, Wen-wai Yim, Yujuan Fu, Zhaoyi Sun, Meliha Yetisgen, Fei Xia, Thomas Lin",http://arxiv.org/pdf/2412.19260v2,cs.LG
Multi-matrix Factorization Attention,"We propose novel attention architectures, Multi-matrix Factorization
Attention (MFA) and MFA-Key-Reuse (MFA-KR). Existing variants for standard
Multi-Head Attention (MHA), including SOTA methods like MLA, fail to maintain
as strong performance under stringent Key-Value cache (KV cache) constraints.
MFA enhances model capacity by efficiently scaling up both the number and
dimension of attention heads through low-rank matrix factorization in the
Query-Key (QK) circuit. Extending MFA, MFA-KR further reduces memory
requirements by repurposing the key cache as value through value projection
re-parameterization. MFA's design enables strong model capacity when working
under tight KV cache budget, while MFA-KR is suitable for even harsher KV cache
limits with minor performance trade-off. Notably, in our extensive and
large-scale experiments, the proposed architecture outperforms MLA and performs
comparably to MHA, while reducing KV cache usage by up to 56% and 93.7%,
respectively.",2024-12-26,"Jingcheng Hu, Houyi Li, Yinmin Zhang, Zili Wang, Shuigeng Zhou, Xiangyu Zhang, Heung-Yeung Shum, Daxin Jiang",http://arxiv.org/pdf/2412.19255v2,cs.LG
Localized exploration in contextual dynamic pricing achieves dimension-free regret,"We study the problem of contextual dynamic pricing with a linear demand
model. We propose a novel localized exploration-then-commit (LetC) algorithm
which starts with a pure exploration stage, followed by a refinement stage that
explores near the learned optimal pricing policy, and finally enters a pure
exploitation stage. The algorithm is shown to achieve a minimax optimal,
dimension-free regret bound when the time horizon exceeds a polynomial of the
covariate dimension. Furthermore, we provide a general theoretical framework
that encompasses the entire time spectrum, demonstrating how to balance
exploration and exploitation when the horizon is limited. The analysis is
powered by a novel critical inequality that depicts the
exploration-exploitation trade-off in dynamic pricing, mirroring its existing
counterpart for the bias-variance trade-off in regularized regression. Our
theoretical results are validated by extensive experiments on synthetic and
real-world data.",2024-12-26,"Jinhang Chai, Yaqi Duan, Jianqing Fan, Kaizheng Wang",http://arxiv.org/pdf/2412.19252v1,cs.LG
Sentiment trading with large language models,"We investigate the efficacy of large language models (LLMs) in sentiment
analysis of U.S. financial news and their potential in predicting stock market
returns. We analyze a dataset comprising 965,375 news articles that span from
January 1, 2010, to June 30, 2023; we focus on the performance of various LLMs,
including BERT, OPT, FINBERT, and the traditional Loughran-McDonald dictionary
model, which has been a dominant methodology in the finance literature. The
study documents a significant association between LLM scores and subsequent
daily stock returns. Specifically, OPT, which is a GPT-3 based LLM, shows the
highest accuracy in sentiment prediction with an accuracy of 74.4%, slightly
ahead of BERT (72.5%) and FINBERT (72.2%). In contrast, the Loughran-McDonald
dictionary model demonstrates considerably lower effectiveness with only 50.1%
accuracy. Regression analyses highlight a robust positive impact of OPT model
scores on next-day stock returns, with coefficients of 0.274 and 0.254 in
different model specifications. BERT and FINBERT also exhibit predictive
relevance, though to a lesser extent. Notably, we do not observe a significant
relationship between the Loughran-McDonald dictionary model scores and stock
returns, challenging the efficacy of this traditional method in the current
financial context. In portfolio performance, the long-short OPT strategy excels
with a Sharpe ratio of 3.05, compared to 2.11 for BERT and 2.07 for FINBERT
long-short strategies. Strategies based on the Loughran-McDonald dictionary
yield the lowest Sharpe ratio of 1.23. Our findings emphasize the superior
performance of advanced LLMs, especially OPT, in financial market prediction
and portfolio management, marking a significant shift in the landscape of
financial analysis tools with implications to financial regulation and policy
analysis.",2024-12-26,"Kemal Kirtac, Guido Germano",http://arxiv.org/pdf/2412.19245v1,cs.LG
Latenrgy: Model Agnostic Latency and Energy Consumption Prediction for Binary Classifiers,"Machine learning systems increasingly drive innovation across scientific
fields and industry, yet challenges in compute overhead, specifically during
inference, limit their scalability and sustainability. Responsible AI
guardrails, essential for ensuring fairness, transparency, and privacy, further
exacerbate these computational demands. This study addresses critical gaps in
the literature, chiefly the lack of generalized predictive techniques for
latency and energy consumption, limited cross-comparisons of classifiers, and
unquantified impacts of RAI guardrails on inference performance. Using Theory
Construction Methodology, this work constructed a model-agnostic theoretical
framework for predicting latency and energy consumption in binary
classification models during inference. The framework synthesizes classifier
characteristics, dataset properties, and RAI guardrails into a unified
analytical instrument. Two predictive equations are derived that capture the
interplay between these factors while offering generalizability across diverse
classifiers. The proposed framework provides foundational insights for
designing efficient, responsible ML systems. It enables researchers to
benchmark and optimize inference performance and assists practitioners in
deploying scalable solutions. Finally, this work establishes a theoretical
foundation for balancing computational efficiency with ethical AI principles,
paving the way for future empirical validation and broader applications.",2024-12-26,Jason M. Pittman,http://arxiv.org/pdf/2412.19241v1,cs.LG
FineVQ: Fine-Grained User Generated Content Video Quality Assessment,"The rapid growth of user-generated content (UGC) videos has produced an
urgent need for effective video quality assessment (VQA) algorithms to monitor
video quality and guide optimization and recommendation procedures. However,
current VQA models generally only give an overall rating for a UGC video, which
lacks fine-grained labels for serving video processing and recommendation
applications. To address the challenges and promote the development of UGC
videos, we establish the first large-scale Fine-grained Video quality
assessment Database, termed FineVD, which comprises 6104 UGC videos with
fine-grained quality scores and descriptions across multiple dimensions. Based
on this database, we propose a Fine-grained Video Quality assessment (FineVQ)
model to learn the fine-grained quality of UGC videos, with the capabilities of
quality rating, quality scoring, and quality attribution. Extensive
experimental results demonstrate that our proposed FineVQ can produce
fine-grained video-quality results and achieve state-of-the-art performance on
FineVD and other commonly used UGC-VQA datasets.",2024-12-26,"Huiyu Duan, Qiang Hu, Jiarui Wang, Liu Yang, Zitong Xu, Lu Liu, Xiongkuo Min, Chunlei Cai, Tianxiao Ye, Xiaoyun Zhang, Guangtao Zhai",http://arxiv.org/pdf/2412.19238v2,cs.LG
SeaMo: A Season-Aware Multimodal Foundation Model for Remote Sensing,"Remote Sensing (RS) data encapsulates rich multi-dimensional information
essential for Earth observation. Its vast volume, diverse sources, and temporal
continuity make it particularly well-suited for developing large Visual
Foundation Models (VFMs). These models serve as powerful feature extractors,
leveraging extensive RS data for pretraining and subsequent fine-tuning in
various geoscientific applications. However, existing VFMs in the RS domain
often concentrate on specific image characteristics, neglecting the full
season-aware potential of RS data. To bridge this gap, we introduce SeaMo, a
novel VFM that effectively integrates multimodal and multi-seasonal RS
information. SeaMo leverages a masked image modeling framework to fully exploit
the spatial, spectral, and seasonal dimensions of RS data. Specifically, we
employ unaligned spatial region selection to capture spatial heterogeneity,
incorporate multi-source inputs for enhanced multimodal integration, and
introduce temporal-multimodal fusion blocks to assimilate seasonal variations
effectively. By explicitly modeling the complex, season-dependent attributes of
RS data, SeaMo enhances generalization, robustness, and adaptability across
geoscientific tasks. Extensive experiments and ablation studies demonstrate its
superior performance, underscoring its potential as a foundational model for
Earth observation.",2024-12-26,"Xuyang Li, Chenyu Li, Gemine Vivone, Danfeng Hong",http://arxiv.org/pdf/2412.19237v2,cs.LG
Are Two Hidden Layers Still Enough for the Physics-Informed Neural Networks?,"The article discusses the development of various methods and techniques for
initializing and training neural networks with a single hidden layer, as well
as training a separable physics-informed neural network consisting of neural
networks with a single hidden layer to solve physical problems described by
ordinary differential equations (ODEs) and partial differential equations
(PDEs). A method for strictly deterministic initialization of a neural network
with one hidden layer for solving physical problems described by an ODE is
proposed. Modifications to existing methods for weighting the loss function are
given, as well as new methods developed for training strictly
deterministic-initialized neural networks to solve ODEs (detaching, additional
weighting based on the second derivative, predicted solution-based weighting,
relative residuals). An algorithm for physics-informed data-driven
initialization of a neural network with one hidden layer is proposed. A neural
network with pronounced generalizing properties is presented, whose
generalizing abilities of which can be precisely controlled by adjusting
network parameters. A metric for measuring the generalization of such neural
network has been introduced. A gradient-free neuron-by-neuron fitting method
has been developed for adjusting the parameters of a single-hidden-layer neural
network, which does not require the use of an optimizer or solver for its
implementation. The proposed methods have been extended to 2D problems using
the separable physics-informed neural networks approach. Numerous experiments
have been carried out to develop the above methods and approaches. Experiments
on physical problems, such as solving various ODEs and PDEs, have demonstrated
that these methods for initializing and training neural networks with one or
two hidden layers (SPINN) achieve competitive accuracy and, in some cases,
state-of-the-art results.",2024-12-26,"Vasiliy A. Es'kin, Alexey O. Malkhanov, Mikhail E. Smorkalov",http://arxiv.org/pdf/2412.19235v1,cs.LG
Virtual Nodes Can Help: Tackling Distribution Shifts in Federated Graph Learning,"Federated Graph Learning (FGL) enables multiple clients to jointly train
powerful graph learning models, e.g., Graph Neural Networks (GNNs), without
sharing their local graph data for graph-related downstream tasks, such as
graph property prediction. In the real world, however, the graph data can
suffer from significant distribution shifts across clients as the clients may
collect their graph data for different purposes. In particular, graph
properties are usually associated with invariant label-relevant substructures
(i.e., subgraphs) across clients, while label-irrelevant substructures can
appear in a client-specific manner. The issue of distribution shifts of graph
data hinders the efficiency of GNN training and leads to serious performance
degradation in FGL. To tackle the aforementioned issue, we propose a novel FGL
framework entitled FedVN that eliminates distribution shifts through
client-specific graph augmentation strategies with multiple learnable Virtual
Nodes (VNs). Specifically, FedVN lets the clients jointly learn a set of shared
VNs while training a global GNN model. To eliminate distribution shifts, each
client trains a personalized edge generator that determines how the VNs connect
local graphs in a client-specific manner. Furthermore, we provide theoretical
analyses indicating that FedVN can eliminate distribution shifts of graph data
across clients. Comprehensive experiments on four datasets under five settings
demonstrate the superiority of our proposed FedVN over nine baselines.",2024-12-26,"Xingbo Fu, Zihan Chen, Yinhan He, Song Wang, Binchi Zhang, Chen Chen, Jundong Li",http://arxiv.org/pdf/2412.19229v2,cs.LG
Learning Cross-Domain Representations for Transferable Drug Perturbations on Single-Cell Transcriptional Responses,"Phenotypic drug discovery has attracted widespread attention because of its
potential to identify bioactive molecules. Transcriptomic profiling provides a
comprehensive reflection of phenotypic changes in cellular responses to
external perturbations. In this paper, we propose XTransferCDR, a novel
generative framework designed for feature decoupling and transferable
representation learning across domains. Given a pair of perturbed expression
profiles, our approach decouples the perturbation representations from basal
states through domain separation encoders and then cross-transfers them in the
latent space. The transferred representations are then used to reconstruct the
corresponding perturbed expression profiles via a shared decoder. This
cross-transfer constraint effectively promotes the learning of transferable
drug perturbation representations. We conducted extensive evaluations of our
model on multiple datasets, including single-cell transcriptional responses to
drugs and single- and combinatorial genetic perturbations. The experimental
results show that XTransferCDR achieved better performance than current
state-of-the-art methods, showcasing its potential to advance phenotypic drug
discovery.",2024-12-26,"Hui Liu, Shikai Jin",http://arxiv.org/pdf/2412.19228v2,cs.LG
Multi-view Fake News Detection Model Based on Dynamic Hypergraph,"With the rapid development of online social networks and the inadequacies in
content moderation mechanisms, the detection of fake news has emerged as a
pressing concern for the public. Various methods have been proposed for fake
news detection, including text-based approaches as well as a series of
graph-based approaches. However, the deceptive nature of fake news renders
text-based approaches less effective. Propagation tree-based methods focus on
the propagation process of individual news, capturing pairwise relationships
but lacking the capability to capture high-order complex relationships. Large
heterogeneous graph-based approaches necessitate the incorporation of
substantial additional information beyond news text and user data, while
hypergraph-based approaches rely on predefined hypergraph structures. To tackle
these issues, we propose a novel dynamic hypergraph-based multi-view fake news
detection model (DHy-MFND) that learns news embeddings across three distinct
views: text-level, propagation tree-level, and hypergraph-level. By employing
hypergraph structures to model complex high-order relationships among multiple
news pieces and introducing dynamic hypergraph structure learning, we optimize
predefined hypergraph structures while learning news embeddings. Additionally,
we introduce contrastive learning to capture authenticity-relevant embeddings
across different views. Extensive experiments on two benchmark datasets
demonstrate the effectiveness of our proposed DHy-MFND compared with a broad
range of competing baselines.",2024-12-26,"Rongping Ye, Xiaobing Pei",http://arxiv.org/pdf/2412.19227v1,cs.LG
VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring of Heterogeneous Applications and Infrastructures,"Monitoring heterogeneous infrastructures and applications is essential to
cope with user requirements properly, but it still lacks enhancements. The
well-known state-of-the-art methods and tools do not support seamless
monitoring of bare-metal, low-cost infrastructures, neither hosted nor
virtualized services with fine-grained details. This work proposes VIrtualized
NEtwork VIsion architecture (VINEVI), an intelligent method for seamless
monitoring heterogeneous infrastructures and applications. The VINEVI
architecture advances state of the art with a node-embedded traffic
classification agent placing physical and virtualized infrastructures enabling
real-time traffic classification. VINEVI combines this real-time traffic
classification with well-known tools such as Prometheus and Victoria Metrics to
monitor the entire stack from the hardware to the virtualized applications.
Experimental results showcased that VINEVI architecture allowed seamless
heterogeneous infrastructure monitoring with a higher level of detail beyond
literature. Also, our node-embedded real-time Internet traffic classifier
evolved with flexibility the methods with monitoring heterogeneous
infrastructures seamlessly.",2024-12-26,"Rodrigo Moreira, Hugo G. V. O. da Cunha, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva",http://arxiv.org/pdf/2412.19226v1,cs.LG
Applying the maximum entropy principle to neural networks enhances multi-species distribution models,"The rapid expansion of citizen science initiatives has led to a significant
growth of biodiversity databases, and particularly presence-only (PO)
observations. PO data are invaluable for understanding species distributions
and their dynamics, but their use in a Species Distribution Model (SDM) is
curtailed by sampling biases and the lack of information on absences. Poisson
point processes are widely used for SDMs, with Maxent being one of the most
popular methods. Maxent maximises the entropy of a probability distribution
across sites as a function of predefined transformations of variables, called
features. In contrast, neural networks and deep learning have emerged as a
promising technique for automatic feature extraction from complex input
variables. Arbitrarily complex transformations of input variables can be
learned from the data efficiently through backpropagation and stochastic
gradient descent (SGD). In this paper, we propose DeepMaxent, which harnesses
neural networks to automatically learn shared features among species, using the
maximum entropy principle. To do so, it employs a normalised Poisson loss where
for each species, presence probabilities across sites are modelled by a neural
network. We evaluate DeepMaxent on a benchmark dataset known for its spatial
sampling biases, using PO data for calibration and presence-absence (PA) data
for validation across six regions with different biological groups and
covariates. Our results indicate that DeepMaxent performs better than Maxent
and other leading SDMs across all regions and taxonomic groups. The method
performs particularly well in regions of uneven sampling, demonstrating
substantial potential to increase SDM performances. In particular, our approach
yields more accurate predictions than traditional single-species models, which
opens up new possibilities for methodological enhancement.",2024-12-26,"Maxime Ryckewaert, Diego Marcos, Christophe Botella, Maximilien Servajean, Pierre Bonnet, Alexis Joly",http://arxiv.org/pdf/2412.19217v3,cs.LG
Optimizing Fantasy Sports Team Selection with Deep Reinforcement Learning,"Fantasy sports, particularly fantasy cricket, have garnered immense
popularity in India in recent years, offering enthusiasts the opportunity to
engage in strategic team-building and compete based on the real-world
performance of professional athletes. In this paper, we address the challenge
of optimizing fantasy cricket team selection using reinforcement learning (RL)
techniques. By framing the team creation process as a sequential
decision-making problem, we aim to develop a model that can adaptively select
players to maximize the team's potential performance. Our approach leverages
historical player data to train RL algorithms, which then predict future
performance and optimize team composition. This not only represents a huge
business opportunity by enabling more accurate predictions of high-performing
teams but also enhances the overall user experience. Through empirical
evaluation and comparison with traditional fantasy team drafting methods, we
demonstrate the effectiveness of RL in constructing competitive fantasy teams.
Our results show that RL-based strategies provide valuable insights into player
selection in fantasy sports.",2024-12-26,"Shamik Bhattacharjee, Kamlesh Marathe, Hitesh Kapoor, Nilesh Patil",http://arxiv.org/pdf/2412.19215v1,cs.LG
Towards Better Spherical Sliced-Wasserstein Distance Learning with Data-Adaptive Discriminative Projection Direction,"Spherical Sliced-Wasserstein (SSW) has recently been proposed to measure the
discrepancy between spherical data distributions in various fields, such as
geology, medical domains, computer vision, and deep representation learning.
However, in the original SSW, all projection directions are treated equally,
which is too idealistic and cannot accurately reflect the importance of
different projection directions for various data distributions. To address this
issue, we propose a novel data-adaptive Discriminative Spherical
Sliced-Wasserstein (DSSW) distance, which utilizes a projected energy function
to determine the discriminative projection direction for SSW. In our new DSSW,
we introduce two types of projected energy functions to generate the weights
for projection directions with complete theoretical guarantees. The first type
employs a non-parametric deterministic function that transforms the projected
Wasserstein distance into its corresponding weight in each projection
direction. This improves the performance of the original SSW distance with
negligible additional computational overhead. The second type utilizes a neural
network-induced function that learns the projection direction weight through a
parameterized neural network based on data projections. This further enhances
the performance of the original SSW distance with less extra computational
overhead. Finally, we evaluate the performance of our proposed DSSW by
comparing it with several state-of-the-art methods across a variety of machine
learning tasks, including gradient flows, density estimation on real earth
data, and self-supervised learning.",2024-12-26,"Hongliang Zhang, Shuo Chen, Lei Luo, Jian Yang",http://arxiv.org/pdf/2412.19212v1,cs.LG
Large Language Models Meet Graph Neural Networks: A Perspective of Graph Mining,"Graph mining is an important area in data mining and machine learning that
involves extracting valuable information from graph-structured data. In recent
years, significant progress has been made in this field through the development
of graph neural networks (GNNs). However, GNNs are still deficient in
generalizing to diverse graph data. Aiming to this issue, Large Language Models
(LLMs) could provide new solutions for graph mining tasks with their superior
semantic understanding. In this review, we systematically review the
combination and application techniques of LLMs and GNNs and present a novel
taxonomy for research in this interdisciplinary field, which involves three
main categories: GNN-driving-LLM, LLM-driving-GNN, and GNN-LLM-co-driving.
Within this framework, we reveal the capabilities of LLMs in enhancing graph
feature extraction as well as improving the effectiveness of downstream tasks
such as node classification, link prediction, and community detection. Although
LLMs have demonstrated their great potential in handling graph-structured data,
their high computational requirements and complexity remain challenges. Future
research needs to continue to explore how to efficiently fuse LLMs and GNNs to
achieve more powerful graph learning and reasoning capabilities and provide new
impetus for the development of graph mining techniques.",2024-12-26,"Yuxin You, Zhen Liu, Xiangchao Wen, Yongtao Zhang, Wei Ai",http://arxiv.org/pdf/2412.19211v1,cs.LG
Context-Aware Deep Learning for Multi Modal Depression Detection,"In this study, we focus on automated approaches to detect depression from
clinical interviews using multi-modal machine learning (ML). Our approach
differentiates from other successful ML methods such as context-aware analysis
through feature engineering and end-to-end deep neural networks for depression
detection utilizing the Distress Analysis Interview Corpus. We propose a novel
method that incorporates: (1) pre-trained Transformer combined with data
augmentation based on topic modelling for textual data; and (2) deep 1D
convolutional neural network (CNN) for acoustic feature modeling. The
simulation results demonstrate the effectiveness of the proposed method for
training multi-modal deep learning models. Our deep 1D CNN and Transformer
models achieved state-of-the-art performance for audio and text modalities
respectively. Combining them in a multi-modal framework also outperforms
state-of-the-art for the combined setting. Code available at
https://github.com/genandlam/multi-modal-depression-detection",2024-12-26,"Genevieve Lam, Huang Dongyan, Weisi Lin",http://arxiv.org/pdf/2412.19209v1,cs.LG
Developing Explainable Machine Learning Model using Augmented Concept Activation Vector,"Machine learning models use high dimensional feature spaces to map their
inputs to the corresponding class labels. However, these features often do not
have a one-to-one correspondence with physical concepts understandable by
humans, which hinders the ability to provide a meaningful explanation for the
decisions made by these models. We propose a method for measuring the
correlation between high-level concepts and the decisions made by a machine
learning model. Our method can isolate the impact of a given high-level concept
and accurately measure it quantitatively. Additionally, this study aims to
determine the prevalence of frequent patterns in machine learning models, which
often occur in imbalanced datasets. We have successfully applied the proposed
method to fundus images and managed to quantitatively measure the impact of
radiomic patterns on the model decisions.",2024-12-26,"Reza Hassanpour, Kasim Oztoprak, Niels Netten, Tony Busker, Mortaza S. Bargh, Sunil Choenni, Beyza Kizildag, Leyla Sena Kilinc",http://arxiv.org/pdf/2412.19208v1,cs.LG
GAIS: A Novel Approach to Instance Selection with Graph Attention Networks,"Instance selection (IS) is a crucial technique in machine learning that aims
to reduce dataset size while maintaining model performance. This paper
introduces a novel method called Graph Attention-based Instance Selection
(GAIS), which leverages Graph Attention Networks (GATs) to identify the most
informative instances in a dataset. GAIS represents the data as a graph and
uses GATs to learn node representations, enabling it to capture complex
relationships between instances. The method processes data in chunks, applies
random masking and similarity thresholding during graph construction, and
selects instances based on confidence scores from the trained GAT model.
Experiments on 13 diverse datasets demonstrate that GAIS consistently
outperforms traditional IS methods in terms of effectiveness, achieving high
reduction rates (average 96\%) while maintaining or improving model
performance. Although GAIS exhibits slightly higher computational costs, its
superior performance in maintaining accuracy with significantly reduced
training data makes it a promising approach for graph-based data selection.",2024-12-26,"Zahiriddin Rustamov, Ayham Zaitouny, Rafat Damseh, Nazar Zaki",http://arxiv.org/pdf/2412.19201v1,cs.LG
Provably Efficient Exploration in Reward Machines with Low Regret,"We study reinforcement learning (RL) for decision processes with
non-Markovian reward, in which high-level knowledge of the task in the form of
reward machines is available to the learner. We consider probabilistic reward
machines with initially unknown dynamics, and investigate RL under the
average-reward criterion, where the learning performance is assessed through
the notion of regret. Our main algorithmic contribution is a model-based RL
algorithm for decision processes involving probabilistic reward machines that
is capable of exploiting the structure induced by such machines. We further
derive high-probability and non-asymptotic bounds on its regret and demonstrate
the gain in terms of regret over existing algorithms that could be applied, but
obliviously to the structure. We also present a regret lower bound for the
studied setting. To the best of our knowledge, the proposed algorithm
constitutes the first attempt to tailor and analyze regret specifically for RL
with probabilistic reward machines.",2024-12-26,"Hippolyte Bourel, Anders Jonsson, Odalric-Ambrym Maillard, Chenxiao Ma, Mohammad Sadegh Talebi",http://arxiv.org/pdf/2412.19194v1,cs.LG
Biology Instructions: A Dataset and Benchmark for Multi-Omics Sequence Understanding Capability of Large Language Models,"Large language models have already demonstrated their formidable capabilities
in general domains, ushering in a revolutionary transformation. However,
exploring and exploiting the extensive knowledge of these models to comprehend
multi-omics biology remains underexplored. To fill this research gap, we first
introduce Biology-Instructions, the first large-scale multi-omics biological
sequences-related instruction-tuning dataset including DNA, RNA, proteins, and
multi-molecules, designed to bridge the gap between large language models
(LLMs) and complex biological sequences-related tasks. This dataset can enhance
the versatility of LLMs by integrating diverse biological sequenced-based
prediction tasks with advanced reasoning capabilities, while maintaining
conversational fluency. Additionally, we reveal significant performance
limitations in even state-of-the-art LLMs on biological sequence-related
multi-omics tasks without specialized pre-training and instruction-tuning. We
further develop a strong baseline called ChatMultiOmics with a novel
three-stage training pipeline, demonstrating the powerful ability to understand
biology by using Biology-Instructions. Biology-Instructions and ChatMultiOmics
are publicly available and crucial resources for enabling more effective
integration of LLMs with multi-omics sequence analysis.",2024-12-26,"Haonan He, Yuchen Ren, Yining Tang, Ziyang Xu, Junxian Li, Minghao Yang, Di Zhang, Dong Yuan, Tao Chen, Shufei Zhang, Yuqiang Li, Nanqing Dong, Wanli Ouyang, Dongzhan Zhou, Peng Ye",http://arxiv.org/pdf/2412.19191v1,cs.LG
An End-to-End Depth-Based Pipeline for Selfie Image Rectification,"Portraits or selfie images taken from a close distance typically suffer from
perspective distortion. In this paper, we propose an end-to-end deep
learning-based rectification pipeline to mitigate the effects of perspective
distortion. We learn to predict the facial depth by training a deep CNN. The
estimated depth is utilized to adjust the camera-to-subject distance by moving
the camera farther, increasing the camera focal length, and reprojecting the 3D
image features to the new perspective. The reprojected features are then fed to
an inpainting module to fill in the missing pixels. We leverage a
differentiable renderer to enable end-to-end training of our depth estimation
and feature extraction nets to improve the rectified outputs. To boost the
results of the inpainting module, we incorporate an auxiliary module to predict
the horizontal movement of the camera which decreases the area that requires
hallucination of challenging face parts such as ears. Unlike previous works, we
process the full-frame input image at once without cropping the subject's face
and processing it separately from the rest of the body, eliminating the need
for complex post-processing steps to attach the face back to the subject's
body. To train our network, we utilize the popular game engine Unreal Engine to
generate a large synthetic face dataset containing various subjects, head
poses, expressions, eyewear, clothes, and lighting. Quantitative and
qualitative results show that our rectification pipeline outperforms previous
methods, and produces comparable results with a time-consuming 3D GAN-based
method while being more than 260 times faster.",2024-12-26,"Ahmed Alhawwary, Phong Nguyen-Ha, Janne Mustaniemi, Janne Heikkilä",http://arxiv.org/pdf/2412.19189v1,cs.LG
Mask Approximation Net: A Novel Diffusion Model Approach for Remote Sensing Change Captioning,"Remote sensing image change description represents an innovative multimodal
task within the realm of remote sensing processing. This task not only
facilitates the detection of alterations in surface conditions, but also
provides comprehensive descriptions of these changes, thereby improving human
interpretability and interactivity.Generally, existing deep-learning-based
methods predominantly utilized a three-stage framework that successively
perform feature extraction, feature fusion, and localization from bitemporal
images before text generation. However, this reliance often leads to an
excessive focus on the design of specific network architectures and restricts
the feature distributions to the dataset at hand, which in turn results in
limited generalizability and robustness during application.To address these
limitations, this paper proposes a novel approach for remote sensing image
change detection and description that incorporates diffusion models, aiming to
transition the emphasis of modeling paradigms from conventional feature
learning to data distribution learning. The proposed method primarily includes
a simple multi-scale change detection module, whose output features are
subsequently refined by an well-designed diffusion model. Furthermore, we
introduce a frequency-guided complex filter module to boost the model
performance by managing high-frequency noise throughout the diffusion process.
We validate the effectiveness of our proposed method across several datasets
for remote sensing change detection and description, showcasing its superior
performance compared to existing techniques. The code will be available at
\href{https://github.com/sundongwei}{MaskApproxNet} after a possible
publication.",2024-12-26,"Dongwei Sun, Jing Yao, Changsheng Zhou, Xiangyong Cao, Pedram Ghamisi",http://arxiv.org/pdf/2412.19179v2,cs.LG
Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal Video-Text Retrieval,"Cross-modal (e.g. image-text, video-text) retrieval is an important task in
information retrieval and multimodal vision-language understanding field.
Temporal understanding makes video-text retrieval more challenging than
image-text retrieval. However, we find that the widely used video-text
benchmarks have shortcomings in comprehensively assessing abilities of models,
especially in temporal understanding, causing large-scale image-text
pre-trained models can already achieve comparable zero-shot performance with
video-text pre-trained models. In this paper, we introduce RTime, a novel
temporal-emphasized video-text retrieval dataset. We first obtain videos of
actions or events with significant temporality, and then reverse these videos
to create harder negative samples. We then recruit annotators to judge the
significance and reversibility of candidate videos, and write captions for
qualified videos. We further adopt GPT-4 to extend more captions based on
human-written captions. Our RTime dataset currently consists of 21k videos with
10 captions per video, totalling about 122 hours. Based on RTime, we propose
three retrieval benchmark tasks: RTime-Origin, RTime-Hard, and RTime-Binary. We
further enhance the use of harder-negatives in model training, and benchmark a
variety of video-text models on RTime. Extensive experiment analysis proves
that RTime indeed poses new and higher challenges to video-text retrieval. We
release our RTime
dataset\footnote{\url{https://github.com/qyr0403/Reversed-in-Time}} to further
advance video-text retrieval and multimodal understanding research.",2024-12-26,"Yang Du, Yuqi Liu, Qin Jin",http://arxiv.org/pdf/2412.19178v1,cs.LG
Cross-Spectral Vision Transformer for Biometric Authentication using Forehead Subcutaneous Vein Pattern and Periocular Pattern,"Traditional biometric systems have encountered significant setbacks due to
various unavoidable factors, for example, face recognition-based biometrics
fails due to the wearing of face masks and fingerprints create hygiene
concerns. This paper proposes a novel lightweight cross-spectral vision
transformer (CS-ViT) for biometric authentication using forehead subcutaneous
vein patterns and periocular patterns, offering a promising alternative to
traditional methods, capable of performing well even with the face masks and
without any physical touch. The proposed framework comprises a cross-spectral
dual-channel architecture designed to handle two distinct biometric traits and
to capture inter-dependencies in terms of relative spectral patterns. Each
channel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)
that captures their individual as well as correlated patterns. The computation
of cross-spectral attention using POC extracts the phase correlation in the
spatial features. Therefore, it is robust against the resolution/intensity
variations and illumination of the input images, assuming both biometric traits
are from the same person. The lightweight model is suitable for edge device
deployment. The performance of the proposed algorithm was rigorously evaluated
using the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern
(FSVP-PBP) database. The results demonstrated the superiority of the algorithm
over state-of-the-art methods, achieving a remarkable classification accuracy
of 98.8% with the combined vein and periocular patterns.",2024-12-26,"Arun K. Sharma, Shubhobrata Bhattacharya, Motahar Reza, Bishakh Bhattacharya",http://arxiv.org/pdf/2412.19160v2,cs.LG
To Predict or Not To Predict? Proportionally Masked Autoencoders for Tabular Data Imputation,"Masked autoencoders (MAEs) have recently demonstrated effectiveness in
tabular data imputation. However, due to the inherent heterogeneity of tabular
data, the uniform random masking strategy commonly used in MAEs can disrupt the
distribution of missingness, leading to suboptimal performance. To address
this, we propose a proportional masking strategy for MAEs. Specifically, we
first compute the statistics of missingness based on the observed proportions
in the dataset, and then generate masks that align with these statistics,
ensuring that the distribution of missingness is preserved after masking.
Furthermore, we argue that simple MLP-based token mixing offers competitive or
often superior performance compared to attention mechanisms while being more
computationally efficient, especially in the tabular domain with the inherent
heterogeneity. Experimental results validate the effectiveness of the proposed
proportional masking strategy across various missing data patterns in tabular
datasets. Code is available at: \url{https://github.com/normal-kim/PMAE}.",2024-12-26,"Jungkyu Kim, Kibok Lee, Taeyoung Park",http://arxiv.org/pdf/2412.19152v1,cs.LG
PlanLLM: Video Procedure Planning with Refinable Large Language Models,"Video procedure planning, i.e., planning a sequence of action steps given the
video frames of start and goal states, is an essential ability for embodied AI.
Recent works utilize Large Language Models (LLMs) to generate enriched action
step description texts to guide action step decoding. Although LLMs are
introduced, these methods decode the action steps into a closed-set of one-hot
vectors, limiting the model's capability of generalizing to new steps or tasks.
Additionally, fixed action step descriptions based on world-level commonsense
may contain noise in specific instances of visual states. In this paper, we
propose PlanLLM, a cross-modal joint learning framework with LLMs for video
procedure planning. We propose an LLM-Enhanced Planning module which fully uses
the generalization ability of LLMs to produce free-form planning output and to
enhance action step decoding. We also propose Mutual Information Maximization
module to connect world-level commonsense of step descriptions and
sample-specific information of visual states, enabling LLMs to employ the
reasoning ability to generate step sequences. With the assistance of LLMs, our
method can both closed-set and open vocabulary procedure planning tasks. Our
PlanLLM achieves superior performance on three benchmarks, demonstrating the
effectiveness of our designs.",2024-12-26,"Dejie Yang, Zijing Zhao, Yang Liu",http://arxiv.org/pdf/2412.19139v2,cs.LG
SUTrack: Towards Simple and Unified Single Object Tracking,"In this paper, we propose a simple yet unified single object tracking (SOT)
framework, dubbed SUTrack. It consolidates five SOT tasks (RGB-based,
RGB-Depth, RGB-Thermal, RGB-Event, RGB-Language Tracking) into a unified model
trained in a single session. Due to the distinct nature of the data, current
methods typically design individual architectures and train separate models for
each task. This fragmentation results in redundant training processes,
repetitive technological innovations, and limited cross-modal knowledge
sharing. In contrast, SUTrack demonstrates that a single model with a unified
input representation can effectively handle various common SOT tasks,
eliminating the need for task-specific designs and separate training sessions.
Additionally, we introduce a task-recognition auxiliary training strategy and a
soft token type embedding to further enhance SUTrack's performance with minimal
overhead. Experiments show that SUTrack outperforms previous task-specific
counterparts across 11 datasets spanning five SOT tasks. Moreover, we provide a
range of models catering edge devices as well as high-performance GPUs,
striking a good trade-off between speed and accuracy. We hope SUTrack could
serve as a strong foundation for further compelling research into unified
tracking models. Code and models are available at
github.com/chenxin-dlut/SUTrack.",2024-12-26,"Xin Chen, Ben Kang, Wanting Geng, Jiawen Zhu, Yi Liu, Dong Wang, Huchuan Lu",http://arxiv.org/pdf/2412.19138v1,cs.LG
Extended Cross-Modality United Learning for Unsupervised Visible-Infrared Person Re-identification,"Unsupervised learning visible-infrared person re-identification (USL-VI-ReID)
aims to learn modality-invariant features from unlabeled cross-modality
datasets and reduce the inter-modality gap. However, the existing methods lack
cross-modality clustering or excessively pursue cluster-level association,
which makes it difficult to perform reliable modality-invariant features
learning. To deal with this issue, we propose a Extended Cross-Modality United
Learning (ECUL) framework, incorporating Extended Modality-Camera Clustering
(EMCC) and Two-Step Memory Updating Strategy (TSMem) modules. Specifically, we
design ECUL to naturally integrates intra-modality clustering, inter-modality
clustering and inter-modality instance selection, establishing compact and
accurate cross-modality associations while reducing the introduction of noisy
labels. Moreover, EMCC captures and filters the neighborhood relationships by
extending the encoding vector, which further promotes the learning of
modality-invariant and camera-invariant knowledge in terms of clustering
algorithm. Finally, TSMem provides accurate and generalized proxy points for
contrastive learning by updating the memory in stages. Extensive experiments
results on SYSU-MM01 and RegDB datasets demonstrate that the proposed ECUL
shows promising performance and even outperforms certain supervised methods.",2024-12-26,"Ruixing Wu, Yiming Yang, Jiakai He, Haifeng Hu",http://arxiv.org/pdf/2412.19134v1,cs.LG
Semantic Residual for Multimodal Unified Discrete Representation,"Recent research in the domain of multimodal unified representations
predominantly employs codebook as representation forms, utilizing Vector
Quantization(VQ) for quantization, yet there has been insufficient exploration
of other quantization representation forms. Our work explores more precise
quantization methods and introduces a new framework, Semantic Residual
Cross-modal Information Disentanglement (SRCID), inspired by the numerical
residual concept inherent to Residual Vector Quantization (RVQ). SRCID employs
semantic residual-based information disentanglement for multimodal data to
better handle the inherent discrepancies between different modalities. Our
method enhances the capabilities of unified multimodal representations and
demonstrates exceptional performance in cross-modal generalization and
cross-modal zero-shot retrieval. Its average results significantly surpass
existing state-of-the-art models, as well as previous attempts with RVQ and
Finite Scalar Quantization (FSQ) based on these modals.",2024-12-26,"Hai Huang, Shulei Wang, Yan Xia",http://arxiv.org/pdf/2412.19128v1,cs.LG
Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing,"We introduce AKT (Advanced Knowledge Transfer), a novel method to enhance the
training ability of low-bit quantized (Q) models in the field of zero-shot
quantization (ZSQ). Existing research in ZSQ has focused on generating
high-quality data from full-precision (FP) models. However, these approaches
struggle with reduced learning ability in low-bit quantization due to its
limited information capacity. To overcome this limitation, we propose effective
training strategy compared to data generation. Particularly, we analyzed that
refining feature maps in the feature distillation process is an effective way
to transfer knowledge to the Q model. Based on this analysis, AKT efficiently
transfer core information from the FP model to the Q model. AKT is the first
approach to utilize both spatial and channel attention information in feature
distillation in ZSQ. Our method addresses the fundamental gradient exploding
problem in low-bit Q models. Experiments on CIFAR-10 and CIFAR-100 datasets
demonstrated the effectiveness of the AKT. Our method led to significant
performance enhancement in existing generative models. Notably, AKT achieved
significant accuracy improvements in low-bit Q models, achieving
state-of-the-art in the 3,5bit scenarios on CIFAR-10. The code is available at
https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer.",2024-12-26,"Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park",http://arxiv.org/pdf/2412.19125v2,cs.LG
"Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact","Self-supervised learning (SSL) has emerged as a promising paradigm in medical
imaging, addressing the chronic challenge of limited labeled data in healthcare
settings. While SSL has shown impressive results, existing studies in the
medical domain are often limited in scope, focusing on specific datasets or
modalities, or evaluating only isolated aspects of model performance. This
fragmented evaluation approach poses a significant challenge, as models
deployed in critical medical settings must not only achieve high accuracy but
also demonstrate robust performance and generalizability across diverse
datasets and varying conditions. To address this gap, we present a
comprehensive evaluation of SSL methods within the medical domain, with a
particular focus on robustness and generalizability. Using the MedMNIST dataset
collection as a standardized benchmark, we evaluate 8 major SSL methods across
11 different medical datasets. Our study provides an in-depth analysis of model
performance in both in-domain scenarios and the detection of
out-of-distribution (OOD) samples, while exploring the effect of various
initialization strategies, model architectures, and multi-domain pre-training.
We further assess the generalizability of SSL methods through cross-dataset
evaluations and the in-domain performance with varying label proportions (1%,
10%, and 100%) to simulate real-world scenarios with limited supervision. We
hope this comprehensive benchmark helps practitioners and researchers make more
informed decisions when applying SSL methods to medical applications.",2024-12-26,"Valay Bundele, Oğuz Ata Çal, Bora Kargi, Karahan Sarıtaş, Kıvanç Tezören, Zohreh Ghaderi, Hendrik Lensch",http://arxiv.org/pdf/2412.19124v1,cs.LG
Discrete vs. Continuous Trade-offs for Generative Models,"This work explores the theoretical and practical foundations of denoising
diffusion probabilistic models (DDPMs) and score-based generative models, which
leverage stochastic processes and Brownian motion to model complex data
distributions. These models employ forward and reverse diffusion processes
defined through stochastic differential equations (SDEs) to iteratively add and
remove noise, enabling high-quality data generation. By analyzing the
performance bounds of these models, we demonstrate how score estimation errors
propagate through the reverse process and bound the total variation distance
using discrete Girsanov transformations, Pinsker's inequality, and the data
processing inequality (DPI) for an information theoretic lens.",2024-12-26,"Jathin Korrapati, Tanish Baranwal, Rahul Shah",http://arxiv.org/pdf/2412.19114v1,cs.LG
SketchFill: Sketch-Guided Code Generation for Imputing Derived Missing Values,"Missing value is a critical issue in data science, significantly impacting
the reliability of analyses and predictions. Missing value imputation (MVI) is
a longstanding problem because it highly relies on domain knowledge. Large
language models (LLMs) have emerged as a promising tool for data cleaning,
including MVI for tabular data, offering advanced capabilities for
understanding and generating content. However, despite their promise, existing
LLM techniques such as in-context learning and Chain-of-Thought (CoT) often
fall short in guiding LLMs to perform complex reasoning for MVI, particularly
when imputing derived missing values, which require mathematical formulas and
data relationships across rows and columns. This gap underscores the need for
further advancements in LLM methodologies to enhance their reasoning
capabilities for more reliable imputation outcomes. To fill this gap, we
propose SketchFill, a novel sketch-based method to guide LLMs in generating
accurate formulas to impute missing numerical values. Our experimental results
demonstrate that SketchFill significantly outperforms state-of-the-art methods,
achieving 56.2% higher accuracy than CoT-based methods and 78.8% higher
accuracy than MetaGPT. This sets a new standard for automated data cleaning and
advances the field of MVI for numerical values.",2024-12-26,"Yunfan Zhang, Changlun Li, Yuyu Luo, Nan Tang",http://arxiv.org/pdf/2412.19113v1,cs.LG
Spectral Enhancement and Pseudo-Anchor Guidance for Infrared-Visible Person Re-Identification,"The development of deep learning has facilitated the application of person
re-identification (ReID) technology in intelligent security. Visible-infrared
person re-identification (VI-ReID) aims to match pedestrians across infrared
and visible modality images enabling 24-hour surveillance. Current studies
relying on unsupervised modality transformations as well as inefficient
embedding constraints to bridge the spectral differences between infrared and
visible images, however, limit their potential performance. To tackle the
limitations of the above approaches, this paper introduces a simple yet
effective Spectral Enhancement and Pseudo-anchor Guidance Network, named
SEPG-Net. Specifically, we propose a more homogeneous spectral enhancement
scheme based on frequency domain information and greyscale space, which avoids
the information loss typically caused by inefficient modality transformations.
Further, a Pseudo Anchor-guided Bidirectional Aggregation (PABA) loss is
introduced to bridge local modality discrepancies while better preserving
discriminative identity embeddings. Experimental results on two public
benchmark datasets demonstrate the superior performance of SEPG-Net against
other state-of-the-art methods. The code is available at
https://github.com/1024AILab/ReID-SEPG.",2024-12-26,"Yiyuan Ge, Zhihao Chen, Ziyang Wang, Jiaju Kang, Mingya Zhang",http://arxiv.org/pdf/2412.19111v2,cs.LG
Stochastic normalizing flows for Effective String Theory,"Effective String Theory (EST) is a powerful tool used to study confinement in
pure gauge theories by modeling the confining flux tube connecting a static
quark-anti-quark pair as a thin vibrating string. Recently, flow-based samplers
have been applied as an efficient numerical method to study EST regularized on
the lattice, opening the route to study observables previously inaccessible to
standard analytical methods. Flow-based samplers are a class of algorithms
based on Normalizing Flows (NFs), deep generative models recently proposed as a
promising alternative to traditional Markov Chain Monte Carlo methods in
lattice field theory calculations. By combining NF layers with
out-of-equilibrium stochastic updates, we obtain Stochastic Normalizing Flows
(SNFs), a scalable class of machine learning algorithms that can be explained
in terms of stochastic thermodynamics. In this contribution, we outline EST and
SNFs, and report some numerical results for the shape of the flux tube.",2024-12-26,"Michele Caselle, Elia Cellini, Alessandro Nada",http://arxiv.org/pdf/2412.19109v2,cs.LG
Graph Mixture of Experts and Memory-augmented Routers for Multivariate Time Series Anomaly Detection,"Multivariate time series (MTS) anomaly detection is a critical task that
involves identifying abnormal patterns or events in data that consist of
multiple interrelated time series. In order to better model the complex
interdependence between entities and the various inherent characteristics of
each entity, the GNN based methods are widely adopted by existing methods. In
each layer of GNN, node features aggregate information from their neighboring
nodes to update their information. In doing so, from shallow layer to deep
layer in GNN, original individual node features continue to be weakened and
more structural information,i.e., from short-distance neighborhood to
long-distance neighborhood, continues to be enhanced. However, research to date
has largely ignored the understanding of how hierarchical graph information is
represented and their characteristics that can benefit anomaly detection.
Existing methods simply leverage the output from the last layer of GNN for
anomaly estimation while neglecting the essential information contained in the
intermediate GNN layers. To address such limitations, in this paper, we propose
a Graph Mixture of Experts (Graph-MoE) network for multivariate time series
anomaly detection, which incorporates the mixture of experts (MoE) module to
adaptively represent and integrate hierarchical multi-layer graph information
into entity representations. It is worth noting that our Graph-MoE can be
integrated into any GNN-based MTS anomaly detection method in a plug-and-play
manner. In addition, the memory-augmented routers are proposed in this paper to
capture the correlation temporal information in terms of the global historical
features of MTS to adaptively weigh the obtained entity representations to
achieve successful anomaly estimation. Extensive experiments on five
challenging datasets prove the superiority of our approach and each proposed
module.",2024-12-26,"Xiaoyu Huang, Weidong Chen, Bo Hu, Zhendong Mao",http://arxiv.org/pdf/2412.19108v2,cs.LG
ERGNN: Spectral Graph Neural Network With Explicitly-Optimized Rational Graph Filters,"Approximation-based spectral graph neural networks, which construct graph
filters with function approximation, have shown substantial performance in
graph learning tasks. Despite their great success, existing works primarily
employ polynomial approximation to construct the filters, whereas another
superior option, namely ration approximation, remains underexplored. Although a
handful of prior works have attempted to deploy the rational approximation,
their implementations often involve intensive computational demands or still
resort to polynomial approximations, hindering full potential of the rational
graph filters. To address the issues, this paper introduces ERGNN, a novel
spectral GNN with explicitly-optimized rational filter. ERGNN adopts a unique
two-step framework that sequentially applies the numerator filter and the
denominator filter to the input signals, thus streamlining the model paradigm
while enabling explicit optimization of both numerator and denominator of the
rational filter. Extensive experiments validate the superiority of ERGNN over
state-of-the-art methods, establishing it as a practical solution for deploying
rational-based GNNs.",2024-12-26,"Guoming Li, Jian Yang, Shangsong Liang",http://arxiv.org/pdf/2412.19106v3,cs.LG
Improving Generative Pre-Training: An In-depth Study of Masked Image Modeling and Denoising Models,"In this work, we dive deep into the impact of additive noise in pre-training
deep networks. While various methods have attempted to use additive noise
inspired by the success of latent denoising diffusion models, when used in
combination with masked image modeling, their gains have been marginal when it
comes to recognition tasks. We thus investigate why this would be the case, in
an attempt to find effective ways to combine the two ideas. Specifically, we
find three critical conditions: corruption and restoration must be applied
within the encoder, noise must be introduced in the feature space, and an
explicit disentanglement between noised and masked tokens is necessary. By
implementing these findings, we demonstrate improved pre-training performance
for a wide range of recognition tasks, including those that require
fine-grained, high-frequency information to solve.",2024-12-26,"Hyesong Choi, Daeun Kim, Sungmin Cha, Kwang Moo Yi, Dongbo Min",http://arxiv.org/pdf/2412.19104v1,cs.LG
Why Train Everything? Tint a Single Layer for Multi-task Model Merging,"Model merging integrates independently fine-tuned models into a single
multi-task model, offering a flexible alternative to joint training. However,
many existing model merging methods introduce additional task-specific
components, increasing complexity and requiring extra modifications. We propose
Model Tinting, a lightweight yet highly effective approach that improves model
merging by updating just a single layer, accounting for as low as 0.5% of total
parameters. Our key observation is that explicit task-specific modules are not
necessary; instead, subtle adjustments to a single layer can effectively
capture task-specific variations within the merged model while maintaining
generalization. We introduce a confidence-based filtering mechanism to
alleviate the impact of unreliable predictions from individual models on the
merged model. Extensive experiments across vision and NLP tasks demonstrate
that Model Tinting achieves state-of-the-art performance, even in challenging
dense prediction tasks. Our code is available at
https://github.com/AIM-SKKU/ModelTinting",2024-12-26,"Aecheon Jung, Seunghwan Lee, Dongyoon Han, Sungeun Hong",http://arxiv.org/pdf/2412.19098v2,cs.LG
MoPD: Mixture-of-Prompts Distillation for Vision-Language Models,"Soft prompt learning methods are effective for adapting vision-language
models (VLMs) to downstream tasks. Nevertheless, empirical evidence reveals a
tendency of existing methods that they overfit seen classes and exhibit
degraded performance on unseen classes. This limitation is due to the inherent
bias in the training data towards the seen classes. To address this issue, we
propose a novel soft prompt learning method, named Mixture-of-Prompts
Distillation (MoPD), which can effectively transfer useful knowledge from hard
prompts manually hand-crafted (a.k.a. teacher prompts) to the learnable soft
prompt (a.k.a. student prompt), thereby enhancing the generalization ability of
soft prompts on unseen classes. Moreover, the proposed MoPD method utilizes a
gating network that learns to select hard prompts used for prompt distillation.
Extensive experiments demonstrate that the proposed MoPD method outperforms
state-of-the-art baselines especially on on unseen classes.",2024-12-26,"Yang Chen, Shuai Fu, Yu Zhang",http://arxiv.org/pdf/2412.19087v1,cs.LG
Assessing Pre-Trained Models for Transfer Learning Through Distribution of Spectral Components,"Pre-trained model assessment for transfer learning aims to identify the
optimal candidate for the downstream tasks from a model hub, without the need
of time-consuming fine-tuning. Existing advanced works mainly focus on
analyzing the intrinsic characteristics of the entire features extracted by
each pre-trained model or how well such features fit the target labels. This
paper proposes a novel perspective for pre-trained model assessment through the
Distribution of Spectral Components (DISCO). Through singular value
decomposition of features extracted from pre-trained models, we investigate
different spectral components and observe that they possess distinct
transferability, contributing diversely to the fine-tuning performance.
Inspired by this, we propose an assessment method based on the distribution of
spectral components which measures the proportions of their corresponding
singular values. Pre-trained models with features concentrating on more
transferable components are regarded as better choices for transfer learning.
We further leverage the labels of downstream data to better estimate the
transferability of each spectral component and derive the final assessment
criterion. Our proposed method is flexible and can be applied to both
classification and regression tasks. We conducted comprehensive experiments
across three benchmarks and two tasks including image classification and object
detection, demonstrating that our method achieves state-of-the-art performance
in choosing proper pre-trained models from the model hub for transfer learning.",2024-12-26,"Tengxue Zhang, Yang Shu, Xinyang Chen, Yifei Long, Chenjuan Guo, Bin Yang",http://arxiv.org/pdf/2412.19085v2,cs.LG
Effective and secure federated online learning to rank,"Online Learning to Rank (OLTR) optimises ranking models using implicit user
feedback, such as clicks. Unlike traditional Learning to Rank (LTR) methods
that rely on a static set of training data with relevance judgements to learn a
ranking model, OLTR methods update the model continually as new data arrives.
Thus, it addresses several drawbacks such as the high cost of human
annotations, potential misalignment between user preferences and human
judgments, and the rapid changes in user query intents. However, OLTR methods
typically require the collection of searchable data, user queries, and clicks,
which poses privacy concerns for users.
  Federated Online Learning to Rank (FOLTR) integrates OLTR within a Federated
Learning (FL) framework to enhance privacy by not sharing raw data. While
promising, FOLTR methods currently lag behind traditional centralised OLTR due
to challenges in ranking effectiveness, robustness with respect to data
distribution across clients, susceptibility to attacks, and the ability to
unlearn client interactions and data. This thesis presents a comprehensive
study on Federated Online Learning to Rank, addressing its effectiveness,
robustness, security, and unlearning capabilities, thereby expanding the
landscape of FOLTR.",2024-12-26,Shuyi Wang,http://arxiv.org/pdf/2412.19069v1,cs.LG
Instruction-Guided Fusion of Multi-Layer Visual Features in Large Vision-Language Models,"Large Vision-Language Models (LVLMs) have achieved remarkable success in a
wide range of multimodal tasks by integrating pre-trained vision encoders and
large language models. However, current LVLMs primarily rely on visual features
extracted from the final layers of the vision encoder, overlooking the
complementary information available in shallower layers. While recent
approaches have explored the use of multilayer visual features in LVLMs, they
tend to be task-agnostic and fail to examine the dependencies of hierarchical
visual features on specific tasks. To address these gaps, we systematically
investigate the contributions of visual features from different encoder layers
using 18 benchmarks spanning 6 task categories. Our findings reveal that
multilayer features provide complementary strengths with varying task
dependencies, and uniform fusion leads to suboptimal performance. Building on
these insights, we propose the instruction-guided vision aggregator, a module
that dynamically integrates multi-layer visual features based on textual
instructions, without increasing the number of visual tokens. Extensive
evaluations demonstrate the superior performance of our method. Additionally,
an in-depth analysis of the aggregator's behavior highlights the dominance of
mid-to-high-level features in semantic-rich tasks and the critical role of
low-level features in fine-grained perception.",2024-12-26,"Xu Li, Yi Zheng, Haotian Chen, Xiaolei Chen, Yuxuan Liang, Chenghang Lai, Bin Li, Xiangyang Xue",http://arxiv.org/pdf/2501.08443v3,cs.LG
Learning Monocular Depth from Events via Egomotion Compensation,"Event cameras are neuromorphically inspired sensors that sparsely and
asynchronously report brightness changes. Their unique characteristics of high
temporal resolution, high dynamic range, and low power consumption make them
well-suited for addressing challenges in monocular depth estimation (e.g.,
high-speed or low-lighting conditions). However, current existing methods
primarily treat event streams as black-box learning systems without
incorporating prior physical principles, thus becoming over-parameterized and
failing to fully exploit the rich temporal information inherent in event camera
data. To address this limitation, we incorporate physical motion principles to
propose an interpretable monocular depth estimation framework, where the
likelihood of various depth hypotheses is explicitly determined by the effect
of motion compensation. To achieve this, we propose a Focus Cost Discrimination
(FCD) module that measures the clarity of edges as an essential indicator of
focus level and integrates spatial surroundings to facilitate cost estimation.
Furthermore, we analyze the noise patterns within our framework and improve it
with the newly introduced Inter-Hypotheses Cost Aggregation (IHCA) module,
where the cost volume is refined through cost trend prediction and multi-scale
cost consistency constraints. Extensive experiments on real-world and synthetic
datasets demonstrate that our proposed framework outperforms cutting-edge
methods by up to 10\% in terms of the absolute relative error metric, revealing
superior performance in predicting accuracy.",2024-12-26,"Haitao Meng, Chonghao Zhong, Sheng Tang, Lian JunJia, Wenwei Lin, Zhenshan Bing, Yi Chang, Gang Chen, Alois Knoll",http://arxiv.org/pdf/2412.19067v1,cs.LG
FFCG: Effective and Fast Family Column Generation for Solving Large-Scale Linear Program,"Column Generation (CG) is an effective and iterative algorithm to solve
large-scale linear programs (LP). During each CG iteration, new columns are
added to improve the solution of the LP. Typically, CG greedily selects one
column with the most negative reduced cost, which can be improved by adding
more columns at once. However, selecting all columns with negative reduced
costs would lead to the addition of redundant columns that do not improve the
objective value. Therefore, selecting the appropriate columns to add is still
an open problem and previous machine-learning-based approaches for CG only add
a constant quantity of columns per iteration due to the state-space explosion
problem. To address this, we propose Fast Family Column Generation (FFCG) -- a
novel reinforcement-learning-based CG that selects a variable number of columns
as needed in an iteration. Specifically, we formulate the column selection
problem in CG as an MDP and design a reward metric that balances both the
convergence speed and the number of redundant columns. In our experiments, FFCG
converges faster on the common benchmarks and reduces the number of CG
iterations by 77.1% for Cutting Stock Problem (CSP) and 84.8% for Vehicle
Routing Problem with Time Windows (VRPTW), and a 71.4% reduction in computing
time for CSP and 84.0% for VRPTW on average compared to several
state-of-the-art baselines.",2024-12-26,"Yi-Xiang Hu, Feng Wu, Shaoang Li, Yifang Zhao, Xiang-Yang Li",http://arxiv.org/pdf/2412.19066v1,cs.LG
DAPoinTr: Domain Adaptive Point Transformer for Point Cloud Completion,"Point Transformers (PoinTr) have shown great potential in point cloud
completion recently. Nevertheless, effective domain adaptation that improves
transferability toward target domains remains unexplored. In this paper, we
delve into this topic and empirically discover that direct feature alignment on
point Transformer's CNN backbone only brings limited improvements since it
cannot guarantee sequence-wise domain-invariant features in the Transformer. To
this end, we propose a pioneering Domain Adaptive Point Transformer (DAPoinTr)
framework for point cloud completion. DAPoinTr consists of three key
components: Domain Query-based Feature Alignment (DQFA), Point Token-wise
Feature alignment (PTFA), and Voted Prediction Consistency (VPC). In
particular, DQFA is presented to narrow the global domain gaps from the
sequence via the presented domain proxy and domain query at the Transformer
encoder and decoder, respectively. PTFA is proposed to close the local domain
shifts by aligning the tokens, \emph{i.e.,} point proxy and dynamic query, at
the Transformer encoder and decoder, respectively. VPC is designed to consider
different Transformer decoders as multiple of experts (MoE) for ensembled
prediction voting and pseudo-label generation. Extensive experiments with
visualization on several domain adaptation benchmarks demonstrate the
effectiveness and superiority of our DAPoinTr compared with state-of-the-art
methods. Code will be publicly available at:
https://github.com/Yinghui-Li-New/DAPoinTr",2024-12-26,"Yinghui Li, Qianyu Zhou, Jingyu Gong, Ye Zhu, Richard Dazeley, Xinkui Zhao, Xuequan Lu",http://arxiv.org/pdf/2412.19062v1,cs.LG
SpectralKD: A Unified Framework for Interpreting and Distilling Vision Transformers via Spectral Analysis,"Knowledge Distillation (KD) has achieved widespread success in compressing
large Vision Transformers (ViTs), but a unified theoretical framework for both
ViTs and KD is still lacking. In this paper, we propose SpectralKD, a novel
unified analytical framework that offers deeper insights into ViTs and
optimizes KD via spectral analysis. Our model-wise analysis reveals that CaiT
concentrates information in their first and last few layers, informing optimal
layer selection for KD. Surprisingly, our layer-wise analysis discovers that
Swin Transformer and CaiT exhibit similar spectral encoding patterns despite
their architectural differences, leading to feature map alignment guideline.
Building on these insights, we propose a simple yet effective spectral
alignment method for KD. Benefiting from the deeper understanding by above
analysis results, even such a simple strategy achieves state-of-the-art
performance on ImageNet-1K without introducing any trainable parameters,
improving DeiT-Tiny by $+5.2\%$ and Swin-Tiny by $+1.4\%$ in top-1 accuracy.
Furthermore, our post-training analysis reveals that distilled students can
reproduce spectral patterns similar to their teachers, opening a new area we
term ``distillation dynamics"". Code and experimental logs are available in
https://github.com/thy960112/SpectralKD.",2024-12-26,"Huiyuan Tian, Bonan Xu, Shijian Li, Gang Pan",http://arxiv.org/pdf/2412.19055v3,cs.LG
Revealing the Self: Brainwave-Based Human Trait Identification,"People exhibit unique emotional responses. In the same scenario, the
emotional reactions of two individuals can be either similar or vastly
different. For instance, consider one person's reaction to an invitation to
smoke versus another person's response to a query about their sleep quality.
The identification of these individual traits through the observation of common
physical parameters opens the door to a wide range of applications, including
psychological analysis, criminology, disease prediction, addiction control, and
more. While there has been previous research in the fields of psychometrics,
inertial sensors, computer vision, and audio analysis, this paper introduces a
novel technique for identifying human traits in real time using brainwave data.
To achieve this, we begin with an extensive study of brainwave data collected
from 80 participants using a portable EEG headset. We also conduct a
statistical analysis of the collected data utilizing box plots. Our analysis
uncovers several new insights, leading us to a groundbreaking unified approach
for identifying diverse human traits by leveraging machine learning techniques
on EEG data. Our analysis demonstrates that this proposed solution achieves
high accuracy. Moreover, we explore two deep-learning models to compare the
performance of our solution. Consequently, we have developed an integrated,
real-time trait identification solution using EEG data, based on the insights
from our analysis. To validate our approach, we conducted a rigorous user
evaluation with an additional 20 participants. The outcomes of this evaluation
illustrate both high accuracy and favorable user ratings, emphasizing the
robust potential of our proposed method to serve as a versatile solution for
human trait identification.",2024-12-26,"Md Mirajul Islam, Md Nahiyan Uddin, Maoyejatun Hasana, Debojit Pandit, Nafis Mahmud Rahman, Sriram Chellappan, Sami Azam, A. B. M. Alim Al Islam",http://arxiv.org/pdf/2412.19041v1,cs.LG
Neural Networks Perform Sufficient Dimension Reduction,"This paper investigates the connection between neural networks and sufficient
dimension reduction (SDR), demonstrating that neural networks inherently
perform SDR in regression tasks under appropriate rank regularizations.
Specifically, the weights in the first layer span the central mean subspace. We
establish the statistical consistency of the neural network-based estimator for
the central mean subspace, underscoring the suitability of neural networks in
addressing SDR-related challenges. Numerical experiments further validate our
theoretical findings, and highlight the underlying capability of neural
networks to facilitate SDR compared to the existing methods. Additionally, we
discuss an extension to unravel the central subspace, broadening the scope of
our investigation.",2024-12-26,"Shuntuo Xu, Zhou Yu",http://arxiv.org/pdf/2412.19033v1,cs.LG
Adaptivity can help exponentially for shadow tomography,"In recent years there has been significant interest in understanding the
statistical complexity of learning from quantum data under the constraint that
one can only make unentangled measurements. While a key challenge in
establishing tight lower bounds in this setting is to deal with the fact that
the measurements can be chosen in an adaptive fashion, a recurring theme has
been that adaptivity offers little advantage over more straightforward,
nonadaptive protocols.
  In this note, we offer a counterpoint to this. We show that for the basic
task of shadow tomography, protocols that use adaptively chosen two-copy
measurements can be exponentially more sample-efficient than any protocol that
uses nonadaptive two-copy measurements.",2024-12-26,"Sitan Chen, Weiyuan Gong, Zhihan Zhang",http://arxiv.org/pdf/2412.19022v1,cs.LG
MGAN-CRCM: A Novel Multiple Generative Adversarial Network and Coarse-Refinement Based Cognizant Method for Image Inpainting,"Image inpainting is a widely used technique in computer vision for
reconstructing missing or damaged pixels in images. Recent advancements with
Generative Adversarial Networks (GANs) have demonstrated superior performance
over traditional methods due to their deep learning capabilities and
adaptability across diverse image domains. Residual Networks (ResNet) have also
gained prominence for their ability to enhance feature representation and
compatibility with other architectures. This paper introduces a novel
architecture combining GAN and ResNet models to improve image inpainting
outcomes. Our framework integrates three components: Transpose
Convolution-based GAN for guided and blind inpainting, Fast
ResNet-Convolutional Neural Network (FR-CNN) for object removal, and
Co-Modulation GAN (Co-Mod GAN) for refinement. The model's performance was
evaluated on benchmark datasets, achieving accuracies of 96.59% on Image-Net,
96.70% on Places2, and 96.16% on CelebA. Comparative analyses demonstrate that
the proposed architecture outperforms existing methods, highlighting its
effectiveness in both qualitative and quantitative evaluations.",2024-12-25,"Nafiz Al Asad, Md. Appel Mahmud Pranto, Shbiruzzaman Shiam, Musaddeq Mahmud Akand, Mohammad Abu Yousuf, Khondokar Fida Hasan, Mohammad Ali Moni",http://arxiv.org/pdf/2412.19000v1,cs.LG
WaveDiffUR: A diffusion SDE-based solver for ultra magnification super-resolution in remote sensing images,"Deep neural networks have recently achieved significant advancements in
remote sensing superresolu-tion (SR). However, most existing methods are
limited to low magnification rates (e.g., 2 or 4) due to the escalating
ill-posedness at higher magnification scales. To tackle this challenge, we
redefine high-magnification SR as the ultra-resolution (UR) problem, reframing
it as solving a conditional diffusion stochastic differential equation (SDE).
In this context, we propose WaveDiffUR, a novel wavelet-domain diffusion UR
solver that decomposes the UR process into sequential sub-processes addressing
conditional wavelet components. WaveDiffUR iteratively reconstructs
low-frequency wavelet details (ensuring global consistency) and high-frequency
components (enhancing local fidelity) by incorporating pre-trained SR models as
plug-and-play modules. This modularity mitigates the ill-posedness of the SDE
and ensures scalability across diverse applications. To address limitations in
fixed boundary conditions at extreme magnifications, we introduce the
cross-scale pyramid (CSP) constraint, a dynamic and adaptive framework that
guides WaveDiffUR in generating fine-grained wavelet details, ensuring
consistent and high-fidelity outputs even at extreme magnification rates.",2024-12-25,"Yue Shi, Liangxiu Han, Darren Dancy, Lianghao Han",http://arxiv.org/pdf/2412.18996v1,cs.LG
MiTREE: Multi-input Transformer Ecoregion Encoder for Species Distribution Modelling,"Climate change poses an extreme threat to biodiversity, making it imperative
to efficiently model the geographical range of different species. The
availability of large-scale remote sensing images and environmental data has
facilitated the use of machine learning in Species Distribution Models (SDMs),
which aim to predict the presence of a species at any given location.
Traditional SDMs, reliant on expert observation, are labor-intensive, but
advancements in remote sensing and citizen science data have facilitated
machine learning approaches to SDM development. However, these models often
struggle with leveraging spatial relationships between different inputs -- for
instance, learning how climate data should inform the data present in satellite
imagery -- without upsampling or distorting the original inputs. Additionally,
location information and ecological characteristics at a location play a
crucial role in predicting species distribution models, but these aspects have
not yet been incorporated into state-of-the-art approaches. In this work, we
introduce MiTREE: a multi-input Vision-Transformer-based model with an
ecoregion encoder. MiTREE computes spatial cross-modal relationships without
upsampling as well as integrates location and ecological context. We evaluate
our model on the SatBird Summer and Winter datasets, the goal of which is to
predict bird species encounter rates, and we find that our approach improves
upon state-of-the-art baselines.",2024-12-25,"Theresa Chen, Yao-Yi Chiang",http://arxiv.org/pdf/2412.18995v1,cs.LG
Optimal Federated Learning for Functional Mean Estimation under Heterogeneous Privacy Constraints,"Federated learning (FL) is a distributed machine learning technique designed
to preserve data privacy and security, and it has gained significant importance
due to its broad range of applications. This paper addresses the problem of
optimal functional mean estimation from discretely sampled data in a federated
setting.
  We consider a heterogeneous framework where the number of individuals,
measurements per individual, and privacy parameters vary across one or more
servers, under both common and independent design settings. In the common
design setting, the same design points are measured for each individual,
whereas in the independent design, each individual has their own random
collection of design points. Within this framework, we establish minimax upper
and lower bounds for the estimation error of the underlying mean function,
highlighting the nuanced differences between common and independent designs
under distributed privacy constraints.
  We propose algorithms that achieve the optimal trade-off between privacy and
accuracy and provide optimality results that quantify the fundamental limits of
private functional mean estimation across diverse distributed settings. These
results characterize the cost of privacy and offer practical insights into the
potential for privacy-preserving statistical analysis in federated
environments.",2024-12-25,"Tony Cai, Abhinav Chakraborty, Lasse Vuursteen",http://arxiv.org/pdf/2412.18992v2,cs.LG
Detection and classification of DDoS flooding attacks by machine learning method,"This study focuses on a method for detecting and classifying distributed
denial of service (DDoS) attacks, such as SYN Flooding, ACK Flooding, HTTP
Flooding, and UDP Flooding, using neural networks. Machine learning,
particularly neural networks, is highly effective in detecting malicious
traffic. A dataset containing normal traffic and various DDoS attacks was used
to train a neural network model with a 24-106-5 architecture. The model
achieved high Accuracy (99.35%), Precision (99.32%), Recall (99.54%), and
F-score (0.99) in the classification task. All major attack types were
correctly identified. The model was also further tested in the lab using
virtual infrastructures to generate normal and DDoS traffic. The results showed
that the model can accurately classify attacks under near-real-world
conditions, demonstrating 95.05% accuracy and balanced F-score scores for all
attack types. This confirms that neural networks are an effective tool for
detecting DDoS attacks in modern information security systems.",2024-12-25,"Dmytro Tymoshchuk, Oleh Yasniy, Mykola Mytnyk, Nataliya Zagorodna, Vitaliy Tymoshchuk",http://arxiv.org/pdf/2412.18990v2,cs.LG
MTCAE-DFER: Multi-Task Cascaded Autoencoder for Dynamic Facial Expression Recognition,"This paper expands the cascaded network branch of the autoencoder-based
multi-task learning (MTL) framework for dynamic facial expression recognition,
namely Multi-Task Cascaded Autoencoder for Dynamic Facial Expression
Recognition (MTCAE-DFER). MTCAE-DFER builds a plug-and-play cascaded decoder
module, which is based on the Vision Transformer (ViT) architecture and employs
the decoder concept of Transformer to reconstruct the multi-head attention
module. The decoder output from the previous task serves as the query (Q),
representing local dynamic features, while the Video Masked Autoencoder
(VideoMAE) shared encoder output acts as both the key (K) and value (V),
representing global dynamic features. This setup facilitates interaction
between global and local dynamic features across related tasks. Additionally,
this proposal aims to alleviate overfitting of complex large model. We utilize
autoencoder-based multi-task cascaded learning approach to explore the impact
of dynamic face detection and dynamic face landmark on dynamic facial
expression recognition, which enhances the model's generalization ability.
After we conduct extensive ablation experiments and comparison with
state-of-the-art (SOTA) methods on various public datasets for dynamic facial
expression recognition, the robustness of the MTCAE-DFER model and the
effectiveness of global-local dynamic feature interaction among related tasks
have been proven.",2024-12-25,"Peihao Xiang, Kaida Wu, Chaohao Lin, Ou Bai",http://arxiv.org/pdf/2412.18988v1,cs.LG
HAND: Hierarchical Attention Network for Multi-Scale Handwritten Document Recognition and Layout Analysis,"Handwritten document recognition (HDR) is one of the most challenging tasks
in the field of computer vision, due to the various writing styles and complex
layouts inherent in handwritten texts. Traditionally, this problem has been
approached as two separate tasks, handwritten text recognition and layout
analysis, and struggled to integrate the two processes effectively. This paper
introduces HAND (Hierarchical Attention Network for Multi-Scale Document), a
novel end-to-end and segmentation-free architecture for simultaneous text
recognition and layout analysis tasks. Our model's key components include an
advanced convolutional encoder integrating Gated Depth-wise Separable and
Octave Convolutions for robust feature extraction, a Multi-Scale Adaptive
Processing (MSAP) framework that dynamically adjusts to document complexity and
a hierarchical attention decoder with memory-augmented and sparse attention
mechanisms. These components enable our model to scale effectively from
single-line to triple-column pages while maintaining computational efficiency.
Additionally, HAND adopts curriculum learning across five complexity levels. To
improve the recognition accuracy of complex ancient manuscripts, we fine-tune
and integrate a Domain-Adaptive Pre-trained mT5 model for post-processing
refinement. Extensive evaluations on the READ 2016 dataset demonstrate the
superior performance of HAND, achieving up to 59.8% reduction in CER for
line-level recognition and 31.2% for page-level recognition compared to
state-of-the-art methods. The model also maintains a compact size of 5.60M
parameters while establishing new benchmarks in both text recognition and
layout analysis. Source code and pre-trained models are available at :
https://github.com/MHHamdan/HAND.",2024-12-25,"Mohammed Hamdan, Abderrahmane Rahiche, Mohamed Cheriet",http://arxiv.org/pdf/2412.18981v1,cs.LG
Evaluating deep learning models for fault diagnosis of a rotating machinery with epistemic and aleatoric uncertainty,"Uncertainty-aware deep learning (DL) models recently gained attention in
fault diagnosis as a way to promote the reliable detection of faults when
out-of-distribution (OOD) data arise from unseen faults (epistemic uncertainty)
or the presence of noise (aleatoric uncertainty). In this paper, we present the
first comprehensive comparative study of state-of-the-art uncertainty-aware DL
architectures for fault diagnosis in rotating machinery, where different
scenarios affected by epistemic uncertainty and different types of aleatoric
uncertainty are investigated. The selected architectures include sampling by
dropout, Bayesian neural networks, and deep ensembles. Moreover, to distinguish
between in-distribution and OOD data in the different scenarios two uncertainty
thresholds, one of which is introduced in this paper, are alternatively
applied. Our empirical findings offer guidance to practitioners and researchers
who have to deploy real-world uncertainty-aware fault diagnosis systems. In
particular, they reveal that, in the presence of epistemic uncertainty, all DL
models are capable of effectively detecting, on average, a substantial portion
of OOD data across all the scenarios. However, deep ensemble models show
superior performance, independently of the uncertainty threshold used for
discrimination. In the presence of aleatoric uncertainty, the noise level plays
an important role. Specifically, low noise levels hinder the models' ability to
effectively detect OOD data. Even in this case, however, deep ensemble models
exhibit a milder degradation in performance, dominating the others. These
achievements, combined with their shorter inference time, make deep ensemble
architectures the preferred choice.",2024-12-25,"Reza Jalayer, Masoud Jalayer, Andrea Mor, Carlotta Orsenigo, Carlo Vercellis",http://arxiv.org/pdf/2412.18980v1,cs.LG
CGCOD: Class-Guided Camouflaged Object Detection,"Camouflaged Object Detection (COD) aims to identify objects that blend
seamlessly into their surroundings. The inherent visual complexity of
camouflaged objects, including their low contrast with the background, diverse
textures, and subtle appearance variations, often obscures semantic cues,
making accurate segmentation highly challenging. Existing methods primarily
rely on visual features, which are insufficient to handle the variability and
intricacy of camouflaged objects, leading to unstable object perception and
ambiguous segmentation results. To tackle these limitations, we introduce a
novel task, class-guided camouflaged object detection (CGCOD), which extends
traditional COD task by incorporating object-specific class knowledge to
enhance detection robustness and accuracy. To facilitate this task, we present
a new dataset, CamoClass, comprising real-world camouflaged objects with class
annotations. Furthermore, we propose a multi-stage framework, CGNet, which
incorporates a plug-and-play class prompt generator and a simple yet effective
class-guided detector. This establishes a new paradigm for COD, bridging the
gap between contextual understanding and class-guided detection. Extensive
experimental results demonstrate the effectiveness of our flexible framework in
improving the performance of proposed and existing detectors by leveraging
class-level textual information.",2024-12-25,"Chenxi Zhang, Qing Zhang, Jiayun Wu, Youwei Pang",http://arxiv.org/pdf/2412.18977v2,cs.LG
Derandomized shallow shadows: Efficient Pauli learning with bounded-depth circuits,"Efficiently estimating large numbers of non-commuting observables is an
important subroutine of many quantum science tasks. We present the derandomized
shallow shadows (DSS) algorithm for efficiently learning a large set of
non-commuting observables, using shallow circuits to rotate into measurement
bases. Exploiting tensor network techniques to ensure polynomial scaling of
classical resources, our algorithm outputs a set of shallow measurement
circuits that approximately minimizes the sample complexity of estimating a
given set of Pauli strings. We numerically demonstrate systematic improvement,
in comparison with state-of-the-art techniques, for energy estimation of
quantum chemistry benchmarks and verification of quantum many-body systems, and
we observe DSS's performance consistently improves as one allows deeper
measurement circuits. These results indicate that in addition to being an
efficient, low-depth, stand-alone algorithm, DSS can also benefit many larger
quantum algorithms requiring estimation of multiple non-commuting observables.",2024-12-25,"Katherine Van Kirk, Christian Kokail, Jonathan Kunjummen, Hong-Ye Hu, Yanting Teng, Madelyn Cain, Jacob Taylor, Susanne F. Yelin, Hannes Pichler, Mikhail Lukin",http://arxiv.org/pdf/2412.18973v1,cs.LG
Recommending Pre-Trained Models for IoT Devices,"The availability of pre-trained models (PTMs) has enabled faster deployment
of machine learning across applications by reducing the need for extensive
training. Techniques like quantization and distillation have further expanded
PTM applicability to resource-constrained IoT hardware. Given the many PTM
options for any given task, engineers often find it too costly to evaluate each
model's suitability. Approaches such as LogME, LEEP, and ModelSpider help
streamline model selection by estimating task relevance without exhaustive
tuning. However, these methods largely leave hardware constraints as future
work-a significant limitation in IoT settings. In this paper, we identify the
limitations of current model recommendation approaches regarding hardware
constraints and introduce a novel, hardware-aware method for PTM selection. We
also propose a research agenda to guide the development of effective,
hardware-conscious model recommendation systems for IoT applications.",2024-12-25,"Parth V. Patil, Wenxin Jiang, Huiyun Peng, Daniel Lugo, Kelechi G. Kalu, Josh LeBlanc, Lawrence Smith, Hyeonwoo Heo, Nathanael Aou, James C. Davis",http://arxiv.org/pdf/2412.18972v1,cs.LG
Adopting Trustworthy AI for Sleep Disorder Prediction: Deep Time Series Analysis with Temporal Attention Mechanism and Counterfactual Explanations,"Sleep disorders have a major impact on both lifestyle and health. Effective
sleep disorder prediction from lifestyle and physiological data can provide
essential details for early intervention. This research utilizes three deep
time series models and facilitates them with explainability approaches for
sleep disorder prediction. Specifically, our approach adopts Temporal
Convolutional Networks (TCN), Long Short-Term Memory (LSTM) for time series
data analysis, and Temporal Fusion Transformer model (TFT). Meanwhile, the
temporal attention mechanism and counterfactual explanation with SHapley
Additive exPlanations (SHAP) approach are employed to ensure dependable,
accurate, and interpretable predictions. Finally, using a large dataset of
sleep health measures, our evaluation demonstrates the effect of our method in
predicting sleep disorders.",2024-12-25,"Pegah Ahadian, Wei Xu, Sherry Wang, Qiang Guan",http://arxiv.org/pdf/2412.18971v1,cs.LG
ModelGrow: Continual Text-to-Video Pre-training with Model Expansion and Language Understanding Enhancement,"Text-to-video (T2V) generation has gained significant attention recently.
However, the costs of training a T2V model from scratch remain persistently
high, and there is considerable room for improving the generation performance,
especially under limited computation resources. This work explores the
continual general pre-training of text-to-video models, enabling the model to
""grow"" its abilities based on a pre-trained foundation, analogous to how humans
acquire new knowledge based on past experiences. There is a lack of extensive
study of the continual pre-training techniques in T2V generation. In this work,
we take the initial step toward exploring this task systematically and propose
ModelGrow. Specifically, we break this task into two key aspects: increasing
model capacity and improving semantic understanding. For model capacity, we
introduce several novel techniques to expand the model size, enabling it to
store new knowledge and improve generation performance. For semantic
understanding, we propose a method that leverages large language models as
advanced text encoders, integrating them into T2V models to enhance language
comprehension and guide generation results according to detailed prompts. This
approach enables the model to achieve better semantic alignment, particularly
in response to complex user prompts. Extensive experiments demonstrate the
effectiveness of our method across various metrics. The source code and the
model of ModelGrow will be publicly available.",2024-12-25,"Zhefan Rao, Liya Ji, Yazhou Xing, Runtao Liu, Zhaoyang Liu, Jiaxin Xie, Ziqiao Peng, Yingqing He, Qifeng Chen",http://arxiv.org/pdf/2412.18966v1,cs.LG
Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation,"Balancing content fidelity and artistic style is a pivotal challenge in image
generation. While traditional style transfer methods and modern Denoising
Diffusion Probabilistic Models (DDPMs) strive to achieve this balance, they
often struggle to do so without sacrificing either style, content, or sometimes
both. This work addresses this challenge by analyzing the ability of DDPMs to
maintain content and style equilibrium. We introduce a novel method to identify
sensitivities within the DDPM attention layers, identifying specific layers
that correspond to different stylistic aspects. By directing conditional inputs
only to these sensitive layers, our approach enables fine-grained control over
style and content, significantly reducing issues arising from over-constrained
inputs. Our findings demonstrate that this method enhances recent stylization
techniques by better aligning style and content, ultimately improving the
quality of generated visual content.",2024-12-25,"Nadav Z. Cohen, Oron Nir, Ariel Shamir",http://arxiv.org/pdf/2412.19853v1,cs.LG
Bridging Interpretability and Robustness Using LIME-Guided Model Refinement,"This paper explores the intricate relationship between interpretability and
robustness in deep learning models. Despite their remarkable performance across
various tasks, deep learning models often exhibit critical vulnerabilities,
including susceptibility to adversarial attacks, over-reliance on spurious
correlations, and a lack of transparency in their decision-making processes. To
address these limitations, we propose a novel framework that leverages Local
Interpretable Model-Agnostic Explanations (LIME) to systematically enhance
model robustness. By identifying and mitigating the influence of irrelevant or
misleading features, our approach iteratively refines the model, penalizing
reliance on these features during training. Empirical evaluations on multiple
benchmark datasets demonstrate that LIME-guided refinement not only improves
interpretability but also significantly enhances resistance to adversarial
perturbations and generalization to out-of-distribution data.",2024-12-25,"Navid Nayyem, Abdullah Rakin, Longwei Wang",http://arxiv.org/pdf/2412.18952v1,cs.LG
Constraint-Adaptive Policy Switching for Offline Safe Reinforcement Learning,"Offline safe reinforcement learning (OSRL) involves learning a
decision-making policy to maximize rewards from a fixed batch of training data
to satisfy pre-defined safety constraints. However, adapting to varying safety
constraints during deployment without retraining remains an under-explored
challenge. To address this challenge, we introduce constraint-adaptive policy
switching (CAPS), a wrapper framework around existing offline RL algorithms.
During training, CAPS uses offline data to learn multiple policies with a
shared representation that optimize different reward and cost trade-offs.
During testing, CAPS switches between those policies by selecting at each state
the policy that maximizes future rewards among those that satisfy the current
cost constraint. Our experiments on 38 tasks from the DSRL benchmark
demonstrate that CAPS consistently outperforms existing methods, establishing a
strong wrapper-based baseline for OSRL. The code is publicly available at
https://github.com/yassineCh/CAPS.",2024-12-25,"Yassine Chemingui, Aryan Deshwal, Honghao Wei, Alan Fern, Janardhan Rao Doppa",http://arxiv.org/pdf/2412.18946v1,cs.LG
Generative Models with ELBOs Converging to Entropy Sums,"The evidence lower bound (ELBO) is one of the most central objectives for
probabilistic unsupervised learning. For the ELBOs of several generative models
and model classes, we here prove convergence to entropy sums. As one result, we
provide a list of generative models for which entropy convergence has been
shown, so far, along with the corresponding expressions for entropy sums. Our
considerations include very prominent generative models such as probabilistic
PCA, sigmoid belief nets or Gaussian mixture models. However, we treat more
models and entire model classes such as general mixtures of exponential family
distributions. Our main contributions are the proofs for the individual models.
For each given model we show that the conditions stated in Theorem 1 or Theorem
2 of [arXiv:2209.03077] are fulfilled such that by virtue of the theorems the
given model's ELBO is equal to an entropy sum at all stationary points. The
equality of the ELBO at stationary points applies under realistic conditions:
for finite numbers of data points, for model/data mismatches, at any stationary
point including saddle points etc, and it applies for any well behaved family
of variational distributions.",2024-12-25,"Jan Warnken, Dmytro Velychko, Simon Damm, Asja Fischer, Jörg Lücke",http://arxiv.org/pdf/2501.09022v1,cs.LG
Label-free SERS Discrimination of Proline from Hydroxylated Proline at Single-molecule Level Assisted by a Deep Learning Model,"Discriminating the low-abundance hydroxylated proline from hydroxylated
proline is crucial for monitoring diseases and eval-uating therapeutic outcomes
that require single-molecule sensors. While the plasmonic nanopore sensor can
detect the hydrox-ylation with single-molecule sensitivity by surface enhanced
Raman spectroscopy (SERS), it suffers from intrinsic fluctuations of
single-molecule signals as well as strong interference from citrates. Here, we
used the occurrence frequency histogram of the single-molecule SERS peaks to
extract overall dataset spectral features, overcome the signal fluctuations and
investigate the citrate-replaced plasmonic nanopore sensors for clean and
distinguishable signals of proline and hydroxylated proline. By ligand exchange
of the citrates by analyte molecules, the representative peaks of citrates
decreased with incubation time, prov-ing occupation of the plasmonic hot spot
by the analytes. As a result, the discrimination of the single-molecule SERS
signals of proline and hydroxylated proline was possible with the convolutional
neural network model with 96.6% accuracy.",2024-12-25,"Yingqi Zhao, Kuo Zhan, Pei-Lin Xin, Zuyan Chen, Shuai Li, Francesco De Angelis, Jianan Huang",http://arxiv.org/pdf/2412.18935v1,cs.LG
Malware Classification using a Hybrid Hidden Markov Model-Convolutional Neural Network,"The proliferation of malware variants poses a significant challenges to
traditional malware detection approaches, such as signature-based methods,
necessitating the development of advanced machine learning techniques. In this
research, we present a novel approach based on a hybrid architecture combining
features extracted using a Hidden Markov Model (HMM), with a Convolutional
Neural Network (CNN) then used for malware classification. Inspired by the
strong results in previous work using an HMM-Random Forest model, we propose
integrating HMMs, which serve to capture sequential patterns in opcode
sequences, with CNNs, which are adept at extracting hierarchical features. We
demonstrate the effectiveness of our approach on the popular Malicia dataset,
and we obtain superior performance, as compared to other machine learning
methods -- our results surpass the aforementioned HMM-Random Forest model. Our
findings underscore the potential of hybrid HMM-CNN architectures in bolstering
malware classification capabilities, offering several promising avenues for
further research in the field of cybersecurity.",2024-12-25,"Ritik Mehta, Olha Jureckova, Mark Stamp",http://arxiv.org/pdf/2412.18932v1,cs.LG
UNIC-Adapter: Unified Image-instruction Adapter with Multi-modal Transformer for Image Generation,"Recently, text-to-image generation models have achieved remarkable
advancements, particularly with diffusion models facilitating high-quality
image synthesis from textual descriptions. However, these models often struggle
with achieving precise control over pixel-level layouts, object appearances,
and global styles when using text prompts alone. To mitigate this issue,
previous works introduce conditional images as auxiliary inputs for image
generation, enhancing control but typically necessitating specialized models
tailored to different types of reference inputs. In this paper, we explore a
new approach to unify controllable generation within a single framework.
Specifically, we propose the unified image-instruction adapter (UNIC-Adapter)
built on the Multi-Modal-Diffusion Transformer architecture, to enable flexible
and controllable generation across diverse conditions without the need for
multiple specialized models. Our UNIC-Adapter effectively extracts multi-modal
instruction information by incorporating both conditional images and task
instructions, injecting this information into the image generation process
through a cross-attention mechanism enhanced by Rotary Position Embedding.
Experimental results across a variety of tasks, including pixel-level spatial
control, subject-driven image generation, and style-image-based image
synthesis, demonstrate the effectiveness of our UNIC-Adapter in unified
controllable image generation.",2024-12-25,"Lunhao Duan, Shanshan Zhao, Wenjun Yan, Yinglun Li, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Mingming Gong, Gui-Song Xia",http://arxiv.org/pdf/2412.18928v1,cs.LG
Exemplar-condensed Federated Class-incremental Learning,"We propose Exemplar-Condensed federated class-incremental learning (ECoral)
to distil the training characteristics of real images from streaming data into
informative rehearsal exemplars. The proposed method eliminates the limitations
of exemplar selection in replay-based approaches for mitigating catastrophic
forgetting in federated continual learning (FCL). The limitations particularly
related to the heterogeneity of information density of each summarized data.
Our approach maintains the consistency of training gradients and the
relationship to past tasks for the summarized exemplars to represent the
streaming data compared to the original images effectively. Additionally, our
approach reduces the information-level heterogeneity of the summarized data by
inter-client sharing of the disentanglement generative model. Extensive
experiments show that our ECoral outperforms several state-of-the-art methods
and can be seamlessly integrated with many existing approaches to enhance
performance.",2024-12-25,"Rui Sun, Yumin Zhang, Varun Ojha, Tejal Shah, Haoran Duan, Bo Wei, Rajiv Ranjan",http://arxiv.org/pdf/2412.18926v1,cs.LG
"HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs","The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning
to improve LLM. Yet, most research in reasoning has focused on mathematical
tasks, leaving domains like medicine underexplored. The medical domain, though
distinct from mathematics, also demands robust reasoning to provide reliable
answers, given the high standards of healthcare. However, verifying medical
reasoning is challenging, unlike those in mathematics. To address this, we
propose verifiable medical problems with a medical verifier to check the
correctness of model outputs. This verifiable nature enables advancements in
medical reasoning through a two-stage approach: (1) using the verifier to guide
the search for a complex reasoning trajectory for fine-tuning LLMs, (2)
applying reinforcement learning (RL) with verifier-based rewards to enhance
complex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM
capable of complex reasoning, which outperforms general and medical-specific
baselines using only 40K verifiable problems. Experiments show complex
reasoning improves medical problem-solving and benefits more from RL. We hope
our approach inspires advancements in reasoning across medical and other
specialized domains.",2024-12-25,"Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, Benyou Wang",http://arxiv.org/pdf/2412.18925v1,cs.LG
An Attentive Dual-Encoder Framework Leveraging Multimodal Visual and Semantic Information for Automatic OSAHS Diagnosis,"Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a common sleep disorder
caused by upper airway blockage, leading to oxygen deprivation and disrupted
sleep. Traditional diagnosis using polysomnography (PSG) is expensive,
time-consuming, and uncomfortable. Existing deep learning methods using facial
image analysis lack accuracy due to poor facial feature capture and limited
sample sizes. To address this, we propose a multimodal dual encoder model that
integrates visual and language inputs for automated OSAHS diagnosis. The model
balances data using randomOverSampler, extracts key facial features with
attention grids, and converts physiological data into meaningful text.
Cross-attention combines image and text data for better feature extraction, and
ordered regression loss ensures stable learning. Our approach improves
diagnostic efficiency and accuracy, achieving 91.3% top-1 accuracy in a
four-class severity classification task, demonstrating state-of-the-art
performance. Code will be released upon acceptance.",2024-12-25,"Yingchen Wei, Xihe Qiu, Xiaoyu Tan, Jingjing Huang, Wei Chu, Yinghui Xu, Yuan Qi",http://arxiv.org/pdf/2412.18919v1,cs.LG
Resource-Efficient Transformer Architecture: Optimizing Memory and Execution Time for Real-Time Applications,"This paper describes a memory-efficient transformer model designed to drive a
reduction in memory usage and execution time by substantial orders of magnitude
without impairing the model's performance near that of the original model.
Recently, new architectures of transformers were presented, focused on
parameter efficiency and computational optimization; however, such models
usually require considerable resources in terms of hardware when deployed in
real-world applications on edge devices. This approach addresses this concern
by halving embedding size and applying targeted techniques such as parameter
pruning and quantization to optimize the memory footprint with minimum
sacrifices in terms of accuracy. Experimental results include a 52% reduction
in memory usage and a 33% decrease in execution time, resulting in better
efficiency than state-of-the-art models. This work compared our model with
existing compelling architectures, such as MobileBERT and DistilBERT, and
proved its feasibility in the domain of resource-friendly deep learning
architectures, mainly for applications in real-time and in resource-constrained
applications.",2024-12-25,"Krisvarish V, Priyadarshini T, K P Abhishek Sri Saai, Vaidehi Vijayakumar",http://arxiv.org/pdf/2501.00042v1,cs.LG
Open-Vocabulary Panoptic Segmentation Using BERT Pre-Training of Vision-Language Multiway Transformer Model,"Open-vocabulary panoptic segmentation remains a challenging problem. One of
the biggest difficulties lies in training models to generalize to an unlimited
number of classes using limited categorized training data. Recent popular
methods involve large-scale vision-language pre-trained foundation models, such
as CLIP. In this paper, we propose OMTSeg for open-vocabulary segmentation
using another large-scale vision-language pre-trained model called BEiT-3 and
leveraging the cross-modal attention between visual and linguistic features in
BEiT-3 to achieve better performance. Experiments result demonstrates that
OMTSeg performs favorably against state-of-the-art models.",2024-12-25,"Yi-Chia Chen, Wei-Hua Li, Chu-Song Chen",http://arxiv.org/pdf/2412.18917v1,cs.LG
Accelerating Diffusion Transformers with Dual Feature Caching,"Diffusion Transformers (DiT) have become the dominant methods in image and
video generation yet still suffer substantial computational costs. As an
effective approach for DiT acceleration, feature caching methods are designed
to cache the features of DiT in previous timesteps and reuse them in the next
timesteps, allowing us to skip the computation in the next timesteps. However,
on the one hand, aggressively reusing all the features cached in previous
timesteps leads to a severe drop in generation quality. On the other hand,
conservatively caching only the features in the redundant layers or tokens but
still computing the important ones successfully preserves the generation
quality but results in reductions in acceleration ratios. Observing such a
tradeoff between generation quality and acceleration performance, this paper
begins by quantitatively studying the accumulated error from cached features.
Surprisingly, we find that aggressive caching does not introduce significantly
more caching errors in the caching step, and the conservative feature caching
can fix the error introduced by aggressive caching. Thereby, we propose a dual
caching strategy that adopts aggressive and conservative caching iteratively,
leading to significant acceleration and high generation quality at the same
time. Besides, we further introduce a V-caching strategy for token-wise
conservative caching, which is compatible with flash attention and requires no
training and calibration data.
  Our codes have been released in Github: \textbf{Code:
\href{https://github.com/Shenyi-Z/DuCa}{\texttt{\textcolor{cyan}{https://github.com/Shenyi-Z/DuCa}}}}",2024-12-25,"Chang Zou, Evelyn Zhang, Runlin Guo, Haohang Xu, Conghui He, Xuming Hu, Linfeng Zhang",http://arxiv.org/pdf/2412.18911v1,cs.LG
FedCFA: Alleviating Simpson's Paradox in Model Aggregation with Counterfactual Federated Learning,"Federated learning (FL) is a promising technology for data privacy and
distributed optimization, but it suffers from data imbalance and heterogeneity
among clients. Existing FL methods try to solve the problems by aligning client
with server model or by correcting client model with control variables. These
methods excel on IID and general Non-IID data but perform mediocrely in
Simpson's Paradox scenarios. Simpson's Paradox refers to the phenomenon that
the trend observed on the global dataset disappears or reverses on a subset,
which may lead to the fact that global model obtained through aggregation in FL
does not accurately reflect the distribution of global data. Thus, we propose
FedCFA, a novel FL framework employing counterfactual learning to generate
counterfactual samples by replacing local data critical factors with global
average data, aligning local data distributions with the global and mitigating
Simpson's Paradox effects. In addition, to improve the quality of
counterfactual samples, we introduce factor decorrelation (FDC) loss to reduce
the correlation among features and thus improve the independence of extracted
factors. We conduct extensive experiments on six datasets and verify that our
method outperforms other FL methods in terms of efficiency and global model
accuracy under limited communication rounds.",2024-12-25,"Zhonghua Jiang, Jimin Xu, Shengyu Zhang, Tao Shen, Jiwei Li, Kun Kuang, Haibin Cai, Fei Wu",http://arxiv.org/pdf/2412.18904v1,cs.LG
CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models,"Large Language Models (LLMs) have emerged as transformative tools in
artificial intelligence, capable of processing and understanding extensive
human knowledge to enhance problem-solving across various domains. This paper
explores the potential of LLMs to drive the discovery of symbolic solutions
within scientific and engineering disciplines, where such solutions are crucial
for advancing theoretical and practical applications. We propose a novel
framework that utilizes LLMs in an evolutionary search methodology, augmented
by a dynamic knowledge library that integrates and refines insights in an
\textit{open-ended manner}. This approach aims to tackle the dual challenges of
efficiently navigating complex symbolic representation spaces and leveraging
both existing and newly generated knowledge to foster open-ended innovation. By
enabling LLMs to interact with and expand upon a knowledge library, we
facilitate the continuous generation of novel solutions in diverse forms such
as language, code, and mathematical expressions. Our experimental results
demonstrate that this method not only enhances the efficiency of searching for
symbolic solutions but also supports the ongoing discovery process, akin to
human scientific endeavors. This study represents a first effort in
conceptualizing the search for symbolic solutions as a lifelong, iterative
process, marking a significant step towards harnessing AI in the perpetual
pursuit of scientific and engineering breakthroughs. We have open-sourced our
code and data, please visit \url{https://github.com/pgg3/CoEvo} for more
information.",2024-12-25,"Ping Guo, Qingfu Zhang, Xi Lin",http://arxiv.org/pdf/2412.18890v1,cs.LG
Adversarial Training for Graph Neural Networks via Graph Subspace Energy Optimization,"Despite impressive capability in learning over graph-structured data, graph
neural networks (GNN) suffer from adversarial topology perturbation in both
training and inference phases. While adversarial training has demonstrated
remarkable effectiveness in image classification tasks, its suitability for GNN
models has been doubted until a recent advance that shifts the focus from
transductive to inductive learning. Still, GNN robustness in the inductive
setting is under-explored, and it calls for deeper understanding of GNN
adversarial training. To this end, we propose a new concept of graph subspace
energy (GSE) -- a generalization of graph energy that measures graph stability
-- of the adjacency matrix, as an indicator of GNN robustness against topology
perturbations. To further demonstrate the effectiveness of such concept, we
propose an adversarial training method with the perturbed graphs generated by
maximizing the GSE regularization term, referred to as AT-GSE. To deal with the
local and global topology perturbations raised respectively by LRBCD and PRBCD,
we employ randomized SVD (RndSVD) and Nystrom low-rank approximation to favor
the different aspects of the GSE terms. An extensive set of experiments shows
that AT-GSE outperforms consistently the state-of-the-art GNN adversarial
training methods over different homophily and heterophily datasets in terms of
adversarial accuracy, whilst more surprisingly achieving a superior clean
accuracy on non-perturbed graphs.",2024-12-25,"Ganlin Liu, Ziling Liang, Xiaowei Huang, Xinping Yi, Shi Jin",http://arxiv.org/pdf/2412.18886v1,cs.LG
Renaissance of Literate Programming in the Era of LLMs: Enhancing LLM-Based Code Generation in Large-Scale Projects,"Large Language Models (LLMs) have helped programmers increase efficiency
through code generation, comprehension, and repair. However, their application
to large-scale projects remains challenging due to complex interdependencies
and the extensive size of modern codebases. Although Knuth's concept of
Literate Programming (LP) combines code and natural language to convey logic
and intent, its potential for enhancing relationships in large projects has not
been fully explored. In this study, we introduce the idea of Interoperable LP
(ILP), which leverages literate programming principles to enhance the
development of both small-scale documents and large-scale projects with LLMs.
We investigate how LLMs perform under ILP-style instructions for both
document-oriented tasks and entire projects. Recognizing that many researchers
rely on well-structured templates to guide LLMs, we propose a concise prompt
engineering method to write LP documents so LLMs can better be involved in code
generation. We also examine the capacity of various LLMs to generate Scheme and
Python code on the RepoBench benchmark, illustrating the advantages of our
approach. Our findings indicate that ILP with LLMs can enhance LLM-based code
generation in large-scale project development.",2024-12-25,"Wuyang Zhang, Yansong Li, Zeyu Dong, Yu Wu, Yingyao Zhou, Duolei Wang, Songsirou Xing, Chichun Zhou, Da Shen",http://arxiv.org/pdf/2502.17441v1,cs.LG
Efficiently Serving Large Multimodal Models Using EPD Disaggregation,"Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by
handling diverse inputs such as images, audio, and video, but at the cost of
adding a multimodal encoding stage that increases both computational and memory
overhead. This step negatively impacting key Service Level Objectives (SLOs)
like time to first token (TTFT) and end-to-end throughput (E2ETP). We introduce
Encode-Prefill-Decode (EPD) Disaggregation, a novel framework that separates
the encoding, prefill, and decode stages onto dedicated resources. Unlike
current systems, which bundle encoding and prefill together, our approach
decouple these steps unlocking new opportunities and optimizations. These
include a new mechanism to cache multimedia tokens for efficient transfer, a
novel way to parallelize encoding load within a request, a module to find the
optimal resource allocation for disaggregated serving, and a novel role
switching method to handle changing workload characteristics. Experimental
evaluations with popular LMMs show substantial gains in memory efficiency (up
to 15$\times$ less utilization), batch sizes (up to 22$\times$ larger),
10$\times$ more images/request, and 2.2$\times$ larger KV caches. Further, it
leads to significant improvements in latency metrics (TTFT up to 71\%
reduction) and end-to-end throughput (up to 57\% reduction), compared to
systems that do not disaggregate.",2024-12-25,"Gursimran Singh, Xinglu Wang, Yifan Hu, Timothy Yu, Linzi Xing, Wei Jiang, Zhefeng Wang, Xiaolong Bai, Yi Li, Ying Xiong, Yong Zhang, Zhenan Fan",http://arxiv.org/pdf/2501.05460v2,cs.LG
Few-shot Metric Domain Adaptation: Practical Learning Strategies for an Automated Plant Disease Diagnosis,"Numerous studies have explored image-based automated systems for plant
disease diagnosis, demonstrating impressive diagnostic capabilities. However,
recent large-scale analyses have revealed a critical limitation: that the
diagnostic capability suffers significantly when validated on images captured
in environments (domains) differing from those used during training. This
shortfall stems from the inherently limited dataset size and the diverse
manifestation of disease symptoms, combined with substantial variations in
cultivation environments and imaging conditions, such as equipment and
composition. These factors lead to insufficient variety in training data,
ultimately constraining the system's robustness and generalization. To address
these challenges, we propose Few-shot Metric Domain Adaptation (FMDA), a
flexible and effective approach for enhancing diagnostic accuracy in practical
systems, even when only limited target data is available. FMDA reduces domain
discrepancies by introducing a constraint to the diagnostic model that
minimizes the ""distance"" between feature spaces of source (training) data and
target data with limited samples. FMDA is computationally efficient, requiring
only basic feature distance calculations and backpropagation, and can be
seamlessly integrated into any machine learning (ML) pipeline. In large-scale
experiments, involving 223,015 leaf images across 20 fields and 3 crop species,
FMDA achieved F1 score improvements of 11.1 to 29.3 points compared to cases
without target data, using only 10 images per disease from the target domain.
Moreover, FMDA consistently outperformed fine-tuning methods utilizing the same
data, with an average improvement of 8.5 points.",2024-12-25,"Shoma Kudo, Satoshi Kagiwada, Hitoshi Iyatomi",http://arxiv.org/pdf/2412.18859v1,cs.LG
Computing Approximate Graph Edit Distance via Optimal Transport,"Given a graph pair $(G^1, G^2)$, graph edit distance (GED) is defined as the
minimum number of edit operations converting $G^1$ to $G^2$. GED is a
fundamental operation widely used in many applications, but its exact
computation is NP-hard, so the approximation of GED has gained a lot of
attention. Data-driven learning-based methods have been found to provide
superior results compared to classical approximate algorithms, but they
directly fit the coupling relationship between a pair of vertices from their
vertex features. We argue that while pairwise vertex features can capture the
coupling cost (discrepancy) of a pair of vertices, the vertex coupling matrix
should be derived from the vertex-pair cost matrix through a more
well-established method that is aware of the global context of the graph pair,
such as optimal transport. In this paper, we propose an ensemble approach that
integrates a supervised learning-based method and an unsupervised method, both
based on optimal transport. Our learning method, GEDIOT, is based on inverse
optimal transport that leverages a learnable Sinkhorn algorithm to generate the
coupling matrix. Our unsupervised method, GEDGW, models GED computation as a
linear combination of optimal transport and its variant, Gromov-Wasserstein
discrepancy, for node and edge operations, respectively, which can be solved
efficiently without needing the ground truth. Our ensemble method, GEDHOT,
combines GEDIOT and GEDGW to further boost the performance. Extensive
experiments demonstrate that our methods significantly outperform the existing
methods in terms of the performance of GED computation, edit path generation,
and model generalizability.",2024-12-25,"Qihao Cheng, Da Yan, Tianhao Wu, Zhongyi Huang, Qin Zhang",http://arxiv.org/pdf/2412.18857v1,cs.LG
Optimistic Critic Reconstruction and Constrained Fine-Tuning for General Offline-to-Online RL,"Offline-to-online (O2O) reinforcement learning (RL) provides an effective
means of leveraging an offline pre-trained policy as initialization to improve
performance rapidly with limited online interactions. Recent studies often
design fine-tuning strategies for a specific offline RL method and cannot
perform general O2O learning from any offline method. To deal with this
problem, we disclose that there are evaluation and improvement mismatches
between the offline dataset and the online environment, which hinders the
direct application of pre-trained policies to online fine-tuning. In this
paper, we propose to handle these two mismatches simultaneously, which aims to
achieve general O2O learning from any offline method to any online method.
Before online fine-tuning, we re-evaluate the pessimistic critic trained on the
offline dataset in an optimistic way and then calibrate the misaligned critic
with the reliable offline actor to avoid erroneous update. After obtaining an
optimistic and and aligned critic, we perform constrained fine-tuning to combat
distribution shift during online learning. We show empirically that the
proposed method can achieve stable and efficient performance improvement on
multiple simulated tasks when compared to the state-of-the-art methods.",2024-12-25,"Qin-Wen Luo, Ming-Kun Xie, Ye-Wen Wang, Sheng-Jun Huang",http://arxiv.org/pdf/2412.18855v1,cs.LG
SWAG: Long-term Surgical Workflow Prediction with Generative-based Anticipation,"While existing approaches excel at recognising current surgical phases, they
provide limited foresight and intraoperative guidance into future procedural
steps. Similarly, current anticipation methods are constrained to predicting
short-term and singular events, neglecting the dense and sequential nature of
surgical workflows. To address these needs and limitations, we propose SWAG
(Surgical Workflow Anticipative Generation), a framework to combine phase
recognition and anticipation, using a generative approach for surgical workflow
guidance. This paper investigates two distinct decoding methods-single-pass
(SP) and auto-regressive (AR)-to generate sequences of future surgical phases
at minute intervals over long horizons of up to 60 minutes. We propose a novel
embedding approach using prior knowledge to enhance the accuracy of phase
anticipation. Additionally, our anticipative framework offers remaining time
regression and proposes a regression-to-classification (R2C) method. SWAG's
performance was evaluated on the Cholec80 and AutoLaparo21 datasets. Our
single-pass model with prior knowledge embeddings (SP*) achieves 49.8% mean
accuracy over 18-minute anticipation on AutoLaparo21, while the simple SP with
R2C extension reaches 56.6% mean accuracy over the same horizon on Cholec80.
Moreover, our approach outperforms existing methods on the phase remaining time
regression task, achieving weighted mean absolute errors of 0.32 and 0.48
minutes for 2- and 3-minute horizons, respectively. SWAG demonstrates
versatility across classification and regression tasks and creates a temporal
continuity between surgical workflow recognition and anticipation. While
further studies are required to understand the impact of generative-based
anticipation intraoperatively, our method provides steps towards this
direction.",2024-12-25,"Maxence Boels, Yang Liu, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin",http://arxiv.org/pdf/2412.18849v2,cs.LG
TPCH: Tensor-interacted Projection and Cooperative Hashing for Multi-view Clustering,"In recent years, anchor and hash-based multi-view clustering methods have
gained attention for their efficiency and simplicity in handling large-scale
data. However, existing methods often overlook the interactions among
multi-view data and higher-order cooperative relationships during projection,
negatively impacting the quality of hash representation in low-dimensional
spaces, clustering performance, and sensitivity to noise. To address this
issue, we propose a novel approach named Tensor-Interacted Projection and
Cooperative Hashing for Multi-View Clustering(TPCH). TPCH stacks multiple
projection matrices into a tensor, taking into account the synergies and
communications during the projection process. By capturing higher-order
multi-view information through dual projection and Hamming space, TPCH employs
an enhanced tensor nuclear norm to learn more compact and distinguishable hash
representations, promoting communication within and between views. Experimental
results demonstrate that this refined method significantly outperforms
state-of-the-art methods in clustering on five large-scale multi-view datasets.
Moreover, in terms of CPU time, TPCH achieves substantial acceleration compared
to the most advanced current methods. The code is available at
\textcolor{red}{\url{https://github.com/jankin-wang/TPCH}}.",2024-12-25,"Zhongwen Wang, Xingfeng Li, Yinghui Sun, Quansen Sun, Yuan Sun, Han Ling, Jian Dai, Zhenwen Ren",http://arxiv.org/pdf/2412.18847v1,cs.LG
Symbolic Disentangled Representations for Images,"The idea of disentangled representations is to reduce the data to a set of
generative factors that produce it. Typically, such representations are vectors
in latent space, where each coordinate corresponds to one of the generative
factors. The object can then be modified by changing the value of a particular
coordinate, but it is necessary to determine which coordinate corresponds to
the desired generative factor -- a difficult task if the vector representation
has a high dimension. In this article, we propose ArSyD (Architecture for
Symbolic Disentanglement), which represents each generative factor as a vector
of the same dimension as the resulting representation. In ArSyD, the object
representation is obtained as a superposition of the generative factor vector
representations. We call such a representation a \textit{symbolic disentangled
representation}. We use the principles of Hyperdimensional Computing (also
known as Vector Symbolic Architectures), where symbols are represented as
hypervectors, allowing vector operations on them. Disentanglement is achieved
by construction, no additional assumptions about the underlying distributions
are made during training, and the model is only trained to reconstruct images
in a weakly supervised manner. We study ArSyD on the dSprites and CLEVR
datasets and provide a comprehensive analysis of the learned symbolic
disentangled representations. We also propose new disentanglement metrics that
allow comparison of methods using latent representations of different
dimensions. ArSyD allows to edit the object properties in a controlled and
interpretable way, and the dimensionality of the object property representation
coincides with the dimensionality of the object representation itself.",2024-12-25,"Alexandr Korchemnyi, Alexey K. Kovalev, Aleksandr I. Panov",http://arxiv.org/pdf/2412.19847v1,cs.LG
Enhancing Federated Graph Learning via Adaptive Fusion of Structural and Node Characteristics,"Federated Graph Learning (FGL) has demonstrated the advantage of training a
global Graph Neural Network (GNN) model across distributed clients using their
local graph data. Unlike Euclidean data (\eg, images), graph data is composed
of nodes and edges, where the overall node-edge connections determine the
topological structure, and individual nodes along with their neighbors capture
local node features. However, existing studies tend to prioritize one aspect
over the other, leading to an incomplete understanding of the data and the
potential misidentification of key characteristics across varying graph
scenarios. Additionally, the non-independent and identically distributed
(non-IID) nature of graph data makes the extraction of these two data
characteristics even more challenging. To address the above issues, we propose
a novel FGL framework, named FedGCF, which aims to simultaneously extract and
fuse structural properties and node features to effectively handle diverse
graph scenarios. FedGCF first clusters clients by structural similarity,
performing model aggregation within each cluster to form the shared structural
model. Next, FedGCF selects the clients with common node features and
aggregates their models to generate a common node model. This model is then
propagated to all clients, allowing common node features to be shared. By
combining these two models with a proper ratio, FedGCF can achieve a
comprehensive understanding of the graph data and deliver better performance,
even under non-IID distributions. Experimental results show that FedGCF
improves accuracy by 4.94%-7.24% under different data distributions and reduces
communication cost by 64.18%-81.25% to reach the same accuracy compared to
baselines.",2024-12-25,"Xianjun Gao, Jianchun Liu, Hongli Xu, Shilong Wang, Liusheng Huang",http://arxiv.org/pdf/2412.18845v1,cs.LG
Improving Integrated Gradient-based Transferable Adversarial Examples by Refining the Integration Path,"Transferable adversarial examples are known to cause threats in practical,
black-box attack scenarios. A notable approach to improving transferability is
using integrated gradients (IG), originally developed for model
interpretability. In this paper, we find that existing IG-based attacks have
limited transferability due to their naive adoption of IG in model
interpretability. To address this limitation, we focus on the IG integration
path and refine it in three aspects: multiplicity, monotonicity, and diversity,
supported by theoretical analyses. We propose the Multiple Monotonic
Diversified Integrated Gradients (MuMoDIG) attack, which can generate highly
transferable adversarial examples on different CNN and ViT models and defenses.
Experiments validate that MuMoDIG outperforms the latest IG-based attack by up
to 37.3\% and other state-of-the-art attacks by 8.4\%. In general, our study
reveals that migrating established techniques to improve transferability may
require non-trivial efforts. Code is available at
\url{https://github.com/RYC-98/MuMoDIG}.",2024-12-25,"Yuchen Ren, Zhengyu Zhao, Chenhao Lin, Bo Yang, Lu Zhou, Zhe Liu, Chao Shen",http://arxiv.org/pdf/2412.18844v1,cs.LG
Context-Based Semantic-Aware Alignment for Semi-Supervised Multi-Label Learning,"Due to the lack of extensive precisely-annotated multi-label data in real
word, semi-supervised multi-label learning (SSMLL) has gradually gained
attention. Abundant knowledge embedded in vision-language models (VLMs)
pre-trained on large-scale image-text pairs could alleviate the challenge of
limited labeled data under SSMLL setting.Despite existing methods based on
fine-tuning VLMs have achieved advances in weakly-supervised multi-label
learning, they failed to fully leverage the information from labeled data to
enhance the learning of unlabeled data. In this paper, we propose a
context-based semantic-aware alignment method to solve the SSMLL problem by
leveraging the knowledge of VLMs. To address the challenge of handling multiple
semantics within an image, we introduce a novel framework design to extract
label-specific image features. This design allows us to achieve a more compact
alignment between text features and label-specific image features, leading the
model to generate high-quality pseudo-labels. To incorporate the model with
comprehensive understanding of image, we design a semi-supervised context
identification auxiliary task to enhance the feature representation by
capturing co-occurrence information. Extensive experiments on multiple
benchmark datasets demonstrate the effectiveness of our proposed method.",2024-12-25,"Heng-Bo Fan, Ming-Kun Xie, Jia-Hao Xiao, Sheng-Jun Huang",http://arxiv.org/pdf/2412.18842v1,cs.LG
DiFiC: Your Diffusion Model Holds the Secret to Fine-Grained Clustering,"Fine-grained clustering is a practical yet challenging task, whose essence
lies in capturing the subtle differences between instances of different
classes. Such subtle differences can be easily disrupted by data augmentation
or be overwhelmed by redundant information in data, leading to significant
performance degradation for existing clustering methods. In this work, we
introduce DiFiC a fine-grained clustering method building upon the conditional
diffusion model. Distinct from existing works that focus on extracting
discriminative features from images, DiFiC resorts to deducing the textual
conditions used for image generation. To distill more precise and
clustering-favorable object semantics, DiFiC further regularizes the diffusion
target and guides the distillation process utilizing neighborhood similarity.
Extensive experiments demonstrate that DiFiC outperforms both state-of-the-art
discriminative and generative clustering methods on four fine-grained image
clustering benchmarks. We hope the success of DiFiC will inspire future
research to unlock the potential of diffusion models in tasks beyond
generation. The code will be released.",2024-12-25,"Ruohong Yang, Peng Hu, Xi Peng, Xiting Liu, Yunfan Li",http://arxiv.org/pdf/2412.18838v1,cs.LG
CausalTAD: Causal Implicit Generative Model for Debiased Online Trajectory Anomaly Detection,"Trajectory anomaly detection, aiming to estimate the anomaly risk of
trajectories given the Source-Destination (SD) pairs, has become a critical
problem for many real-world applications. Existing solutions directly train a
generative model for observed trajectories and calculate the conditional
generative probability $P({T}|{C})$ as the anomaly risk, where ${T}$ and ${C}$
represent the trajectory and SD pair respectively. However, we argue that the
observed trajectories are confounded by road network preference which is a
common cause of both SD distribution and trajectories. Existing methods ignore
this issue limiting their generalization ability on out-of-distribution
trajectories. In this paper, we define the debiased trajectory anomaly
detection problem and propose a causal implicit generative model, namely
CausalTAD, to solve it. CausalTAD adopts do-calculus to eliminate the
confounding bias of road network preference and estimates $P({T}|do({C}))$ as
the anomaly criterion. Extensive experiments show that CausalTAD can not only
achieve superior performance on trained trajectories but also generally improve
the performance of out-of-distribution data, with improvements of $2.1\% \sim
5.7\%$ and $10.6\% \sim 32.7\%$ respectively.",2024-12-25,"Wenbin Li, Di Yao, Chang Gong, Xiaokai Chu, Quanliang Jing, Xiaolei Zhou, Yuxuan Zhang, Yunxia Fan, Jingping Bi",http://arxiv.org/pdf/2412.18820v1,cs.LG
LLM-assisted Vector Similarity Search,"As data retrieval demands become increasingly complex, traditional search
methods often fall short in addressing nuanced and conceptual queries. Vector
similarity search has emerged as a promising technique for finding semantically
similar information efficiently. However, its effectiveness diminishes when
handling intricate queries with contextual nuances. This paper explores a
hybrid approach combining vector similarity search with Large Language Models
(LLMs) to enhance search accuracy and relevance. The proposed two-step solution
first employs vector similarity search to shortlist potential matches, followed
by an LLM for context-aware ranking of the results. Experiments on structured
datasets demonstrate that while vector similarity search alone performs well
for straightforward queries, the LLM-assisted approach excels in processing
complex queries involving constraints, negations, or conceptual requirements.
By leveraging the natural language understanding capabilities of LLMs, this
method improves the accuracy of search results for complex tasks without
sacrificing efficiency. We also discuss real-world applications and propose
directions for future research to refine and scale this technique for diverse
datasets and use cases.
  Original article:
https://engineering.grab.com/llm-assisted-vector-similarity-search",2024-12-25,"Md Riyadh, Muqi Li, Felix Haryanto Lie, Jia Long Loh, Haotian Mi, Sayam Bohra",http://arxiv.org/pdf/2412.18819v2,cs.LG
GSAVS: Gaussian Splatting-based Autonomous Vehicle Simulator,"Modern autonomous vehicle simulators feature an ever-growing library of
assets, including vehicles, buildings, roads, pedestrians, and more. While this
level of customization proves beneficial when creating virtual urban
environments, this process becomes cumbersome when intending to train within a
digital twin or a duplicate of a real scene. Gaussian splatting emerged as a
powerful technique in scene reconstruction and novel view synthesis, boasting
high fidelity and rendering speeds. In this paper, we introduce GSAVS, an
autonomous vehicle simulator that supports the creation and development of
autonomous vehicle models. Every asset within the simulator is a 3D Gaussian
splat, including the vehicles and the environment. However, the simulator runs
within a classical 3D engine, rendering 3D Gaussian splats in real-time. This
allows the simulator to utilize the photorealism that 3D Gaussian splatting
boasts while providing the customization and ease of use of a classical 3D
engine.",2024-12-25,Rami Wilson,http://arxiv.org/pdf/2412.18816v1,cs.LG
Provable Uncertainty Decomposition via Higher-Order Calibration,"We give a principled method for decomposing the predictive uncertainty of a
model into aleatoric and epistemic components with explicit semantics relating
them to the real-world data distribution. While many works in the literature
have proposed such decompositions, they lack the type of formal guarantees we
provide. Our method is based on the new notion of higher-order calibration,
which generalizes ordinary calibration to the setting of higher-order
predictors that predict mixtures over label distributions at every point. We
show how to measure as well as achieve higher-order calibration using access to
$k$-snapshots, namely examples where each point has $k$ independent conditional
labels. Under higher-order calibration, the estimated aleatoric uncertainty at
a point is guaranteed to match the real-world aleatoric uncertainty averaged
over all points where the prediction is made. To our knowledge, this is the
first formal guarantee of this type that places no assumptions whatsoever on
the real-world data distribution. Importantly, higher-order calibration is also
applicable to existing higher-order predictors such as Bayesian and ensemble
models and provides a natural evaluation metric for such models. We demonstrate
through experiments that our method produces meaningful uncertainty
decompositions for image classification.",2024-12-25,"Gustaf Ahdritz, Aravind Gollakota, Parikshit Gopalan, Charlotte Peale, Udi Wieder",http://arxiv.org/pdf/2412.18808v1,cs.LG
FOR: Finetuning for Object Level Open Vocabulary Image Retrieval,"As working with large datasets becomes standard, the task of accurately
retrieving images containing objects of interest by an open set textual query
gains practical importance. The current leading approach utilizes a pre-trained
CLIP model without any adaptation to the target domain, balancing accuracy and
efficiency through additional post-processing. In this work, we propose FOR:
Finetuning for Object-centric Open-vocabulary Image Retrieval, which allows
finetuning on a target dataset using closed-set labels while keeping the
visual-language association crucial for open vocabulary retrieval. FOR is based
on two design elements: a specialized decoder variant of the CLIP head
customized for the intended task, and its coupling within a multi-objective
training framework. Together, these design choices result in a significant
increase in accuracy, showcasing improvements of up to 8 mAP@50 points over
SoTA across three datasets. Additionally, we demonstrate that FOR is also
effective in a semi-supervised setting, achieving impressive results even when
only a small portion of the dataset is labeled.",2024-12-25,"Hila Levi, Guy Heller, Dan Levi",http://arxiv.org/pdf/2412.18806v1,cs.LG
Ister: Inverted Seasonal-Trend Decomposition Transformer for Explainable Multivariate Time Series Forecasting,"In long-term time series forecasting, Transformer-based models have achieved
great success, due to its ability to capture long-range dependencies. However,
existing models face challenges in identifying critical components for
prediction, leading to limited interpretability and suboptimal performance. To
address these issues, we propose the Inverted Seasonal-Trend Decomposition
Transformer (Ister), a novel Transformer-based model for multivariate time
series forecasting. Ister decomposes time series into seasonal and trend
components, further modeling multi-periodicity and inter-series dependencies
using a Dual Transformer architecture. We introduce a novel Dot-attention
mechanism that improves interpretability, computational efficiency, and
predictive accuracy. Comprehensive experiments on benchmark datasets
demonstrate that Ister outperforms existing state-of-the-art models, achieving
up to 10% improvement in MSE. Moreover, Ister enables intuitive visualization
of component contributions, shedding lights on model's decision process and
enhancing transparency in prediction results.",2024-12-25,"Fanpu Cao, Shu Yang, Zhengjian Chen, Ye Liu, Laizhong Cui",http://arxiv.org/pdf/2412.18798v2,cs.LG
Torque-Aware Momentum,"Efficiently exploring complex loss landscapes is key to the performance of
deep neural networks. While momentum-based optimizers are widely used in
state-of-the-art setups, classical momentum can still struggle with large,
misaligned gradients, leading to oscillations. To address this, we propose
Torque-Aware Momentum (TAM), which introduces a damping factor based on the
angle between the new gradients and previous momentum, stabilizing the update
direction during training. Empirical results show that TAM, which can be
combined with both SGD and Adam, enhances exploration, handles distribution
shifts more effectively, and improves generalization performance across various
tasks, including image classification and large language model fine-tuning,
when compared to classical momentum-based optimizers.",2024-12-25,"Pranshu Malviya, Goncalo Mordido, Aristide Baratin, Reza Babanezhad Harikandeh, Gintare Karolina Dziugaite, Razvan Pascanu, Sarath Chandar",http://arxiv.org/pdf/2412.18790v1,cs.LG
On Improved Regret Bounds In Bayesian Optimization with Gaussian Noise,"Bayesian optimization (BO) with Gaussian process (GP) surrogate models is a
powerful black-box optimization method. Acquisition functions are a critical
part of a BO algorithm as they determine how the new samples are selected. Some
of the most widely used acquisition functions include upper confidence bound
(UCB) and Thompson sampling (TS). The convergence analysis of BO algorithms has
focused on the cumulative regret under both the Bayesian and frequentist
settings for the objective. In this paper, we establish new pointwise bounds on
the prediction error of GP under the frequentist setting with Gaussian noise.
Consequently, we prove improved convergence rates of cumulative regret bound
for both GP-UCB and GP-TS. Of note, the new prediction error bound under
Gaussian noise can be applied to general BO algorithms and convergence
analysis, e.g., the asymptotic convergence of expected improvement (EI) with
noise.",2024-12-25,"Jingyi Wang, Haowei Wang, Cosmin G. Petra, Nai-Yuan Chiang",http://arxiv.org/pdf/2412.18789v1,cs.LG
Thermal-Mechanical Physics Informed Deep Learning For Fast Prediction of Thermal Stress Evolution in Laser Metal Deposition,"Understanding thermal stress evolution in metal additive manufacturing (AM)
is crucial for producing high-quality components. Recent advancements in
machine learning (ML) have shown great potential for modeling complex
multiphysics problems in metal AM. While physics-based simulations face the
challenge of high computational costs, conventional data-driven ML models
require large, labeled training datasets to achieve accurate predictions.
Unfortunately, generating large datasets for ML model training through
time-consuming experiments or high-fidelity simulations is highly expensive in
metal AM. To address these challenges, this study introduces a physics-informed
neural network (PINN) framework that incorporates governing physical laws into
deep neural networks (NNs) to predict temperature and thermal stress evolution
during the laser metal deposition (LMD) process. The study also discusses the
enhanced accuracy and efficiency of the PINN model when supplemented with small
simulation data. Furthermore, it highlights the PINN transferability, enabling
fast predictions with a set of new process parameters using a pre-trained PINN
model as an online soft sensor, significantly reducing computation time
compared to physics-based numerical models while maintaining accuracy.",2024-12-25,"R. Sharma, Y. B. Guo",http://arxiv.org/pdf/2412.18786v1,cs.LG
Robustness Evaluation of Offline Reinforcement Learning for Robot Control Against Action Perturbations,"Offline reinforcement learning, which learns solely from datasets without
environmental interaction, has gained attention. This approach, similar to
traditional online deep reinforcement learning, is particularly promising for
robot control applications. Nevertheless, its robustness against real-world
challenges, such as joint actuator faults in robots, remains a critical
concern. This study evaluates the robustness of existing offline reinforcement
learning methods using legged robots from OpenAI Gym based on average episodic
rewards. For robustness evaluation, we simulate failures by incorporating both
random and adversarial perturbations, representing worst-case scenarios, into
the joint torque signals. Our experiments show that existing offline
reinforcement learning methods exhibit significant vulnerabilities to these
action perturbations and are more vulnerable than online reinforcement learning
methods, highlighting the need for more robust approaches in this field.",2024-12-25,"Shingo Ayabe, Takuto Otomo, Hiroshi Kera, Kazuhiko Kawamoto",http://arxiv.org/pdf/2412.18781v1,cs.LG
Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion,"Human skeleton-based action recognition has long been an indispensable aspect
of artificial intelligence. Current state-of-the-art methods tend to consider
only the dependencies between connected skeletal joints, limiting their ability
to capture non-linear dependencies between physically distant joints. Moreover,
most existing approaches distinguish action classes by estimating the
probability density of motion representations, yet the high-dimensional nature
of human motions invokes inherent difficulties in accomplishing such
measurements. In this paper, we seek to tackle these challenges from two
directions: (1) We propose a novel dependency refinement approach that
explicitly models dependencies between any pair of joints, effectively
transcending the limitations imposed by joint distance. (2) We further propose
a framework that utilizes the Hilbert-Schmidt Independence Criterion to
differentiate action classes without being affected by data dimensionality, and
mathematically derive learning objectives guaranteeing precise recognition.
Empirically, our approach sets the state-of-the-art performance on NTU RGB+D,
NTU RGB+D 120, and Northwestern-UCLA datasets.",2024-12-25,Yuheng Yang,http://arxiv.org/pdf/2412.18780v1,cs.LG
Unified Local and Global Attention Interaction Modeling for Vision Transformers,"We present a novel method that extends the self-attention mechanism of a
vision transformer (ViT) for more accurate object detection across diverse
datasets. ViTs show strong capability for image understanding tasks such as
object detection, segmentation, and classification. This is due in part to
their ability to leverage global information from interactions among visual
tokens. However, the self-attention mechanism in ViTs are limited because they
do not allow visual tokens to exchange local or global information with
neighboring features before computing global attention. This is problematic
because tokens are treated in isolation when attending (matching) to other
tokens, and valuable spatial relationships are overlooked. This isolation is
further compounded by dot-product similarity operations that make tokens from
different semantic classes appear visually similar. To address these
limitations, we introduce two modifications to the traditional self-attention
framework; a novel aggressive convolution pooling strategy for local feature
mixing, and a new conceptual attention transformation to facilitate interaction
and feature exchange between semantic concepts. Experimental results
demonstrate that local and global information exchange among visual features
before self-attention significantly improves performance on challenging object
detection tasks and generalizes across multiple benchmark datasets and
challenging medical datasets. We publish source code and a novel dataset of
cancerous tumors (chimeric cell clusters).",2024-12-25,"Tan Nguyen, Coy D. Heldermon, Corey Toler-Franklin",http://arxiv.org/pdf/2412.18778v1,cs.LG
ObitoNet: Multimodal High-Resolution Point Cloud Reconstruction,"ObitoNet employs a Cross Attention mechanism to integrate multimodal inputs,
where Vision Transformers (ViT) extract semantic features from images and a
point cloud tokenizer processes geometric information using Farthest Point
Sampling (FPS) and K Nearest Neighbors (KNN) for spatial structure capture. The
learned multimodal features are fed into a transformer-based decoder for
high-resolution point cloud reconstruction. This approach leverages the
complementary strengths of both modalities rich image features and precise
geometric details ensuring robust point cloud generation even in challenging
conditions such as sparse or noisy data.",2024-12-25,"Apoorv Thapliyal, Vinay Lanka, Swathi Baskaran",http://arxiv.org/pdf/2412.18775v1,cs.LG
Learning Broken Symmetries with Approximate Invariance,"Recognizing symmetries in data allows for significant boosts in neural
network training, which is especially important where training data are
limited. In many cases, however, the exact underlying symmetry is present only
in an idealized dataset, and is broken in actual data, due to asymmetries in
the detector, or varying response resolution as a function of particle
momentum. Standard approaches, such as data augmentation or equivariant
networks fail to represent the nature of the full, broken symmetry, effectively
overconstraining the response of the neural network. We propose a learning
model which balances the generality and asymptotic performance of unconstrained
networks with the rapid learning of constrained networks. This is achieved
through a dual-subnet structure, where one network is constrained by the
symmetry and the other is not, along with a learned symmetry factor. In a
simplified toy example that demonstrates violation of Lorentz invariance, our
model learns as rapidly as symmetry-constrained networks but escapes its
performance limitations.",2024-12-25,"Seth Nabat, Aishik Ghosh, Edmund Witkowski, Gregor Kasieczka, Daniel Whiteson",http://arxiv.org/pdf/2412.18773v2,cs.LG
Hierarchical Multi-Graphs Learning for Robust Group Re-Identification,"Group Re-identification (G-ReID) faces greater complexity than individual
Re-identification (ReID) due to challenges like mutual occlusion, dynamic
member interactions, and evolving group structures. Prior graph-based
approaches have aimed to capture these dynamics by modeling the group as a
single topological structure. However, these methods struggle to generalize
across diverse group compositions, as they fail to fully represent the
multifaceted relationships within the group.
  In this study, we introduce a Hierarchical Multi-Graphs Learning (HMGL)
framework to address these challenges. Our approach models the group as a
collection of multi-relational graphs, leveraging both explicit features (such
as occlusion, appearance, and foreground information) and implicit dependencies
between members. This hierarchical representation, encoded via a Multi-Graphs
Neural Network (MGNN), allows us to resolve ambiguities in member
relationships, particularly in complex, densely populated scenes. To further
enhance matching accuracy, we propose a Multi-Scale Matching (MSM) algorithm,
which mitigates issues of member information ambiguity and sensitivity to hard
samples, improving robustness in challenging scenarios.
  Our method achieves state-of-the-art performance on two standard benchmarks,
CSG and RoadGroup, with Rank-1/mAP scores of 95.3%/94.4% and 93.9%/95.4%,
respectively. These results mark notable improvements of 1.7% and 2.5% in
Rank-1 accuracy over existing approaches.",2024-12-25,"Ruiqi Liu, Xingyu Liu, Xiaohao Xu, Yixuan Zhang, Yongxin Ge, Lubin Weng",http://arxiv.org/pdf/2412.18766v1,cs.LG
Towards a Statistical Understanding of Neural Networks: Beyond the Neural Tangent Kernel Theories,"A primary advantage of neural networks lies in their feature learning
characteristics, which is challenging to theoretically analyze due to the
complexity of their training dynamics. We propose a new paradigm for studying
feature learning and the resulting benefits in generalizability. After
reviewing the neural tangent kernel (NTK) theory and recent results in kernel
regression, which address the generalization issue of sufficiently wide neural
networks, we examine limitations and implications of the fixed kernel theory
(as the NTK theory) and review recent theoretical advancements in feature
learning. Moving beyond the fixed kernel/feature theory, we consider neural
networks as adaptive feature models. Finally, we propose an over-parameterized
Gaussian sequence model as a prototype model to study the feature learning
characteristics of neural networks.",2024-12-25,"Haobo Zhang, Jianfa Lai, Yicheng Li, Qian Lin, Jun S. Liu",http://arxiv.org/pdf/2412.18756v1,cs.LG
The Impact of Input Order Bias on Large Language Models for Software Fault Localization,"Large Language Models (LLMs) have shown significant potential in software
engineering tasks such as Fault Localization (FL) and Automatic Program Repair
(APR). This study investigates how input order and context size influence LLM
performance in FL, a crucial step for many downstream software engineering
tasks. We evaluate different method orderings using Kendall Tau distances,
including ""perfect"" (where ground truths appear first) and ""worst"" (where
ground truths appear last), across two benchmarks containing Java and Python
projects. Our results reveal a strong order bias: in Java projects, Top-1 FL
accuracy drops from 57% to 20% when reversing the order, while in Python
projects, it decreases from 38% to approximately 3%. However, segmenting inputs
into smaller contexts mitigates this bias, reducing the performance gap in FL
from 22% and 6% to just 1% across both benchmarks. We replaced method names
with semantically meaningful alternatives to determine whether this bias is due
to data leakage. The observed trends remained consistent, suggesting that the
bias is not caused by memorization from training data but rather by the
inherent effect of input order. Additionally, we explored ordering methods
based on traditional FL techniques and metrics, finding that DepGraph's ranking
achieves 48% Top-1 accuracy, outperforming simpler approaches such as
CallGraph(DFS). These findings highlight the importance of structuring inputs,
managing context effectively, and selecting appropriate ordering strategies to
enhance LLM performance in FL and other software engineering applications.",2024-12-25,"Md Nakhla Rafi, Dong Jae Kim, Tse-Hsun Chen, Shaowei Wang",http://arxiv.org/pdf/2412.18750v2,cs.LG
Successes and Limitations of Object-centric Models at Compositional Generalisation,"In recent years, it has been shown empirically that standard disentangled
latent variable models do not support robust compositional learning in the
visual domain. Indeed, in spite of being designed with the goal of factorising
datasets into their constituent factors of variations, disentangled models show
extremely limited compositional generalisation capabilities. On the other hand,
object-centric architectures have shown promising compositional skills, albeit
these have 1) not been extensively tested and 2) experiments have been limited
to scene composition -- where models must generalise to novel combinations of
objects in a visual scene instead of novel combinations of object properties.
In this work, we show that these compositional generalisation skills extend to
this later setting. Furthermore, we present evidence pointing to the source of
these skills and how they can be improved through careful training. Finally, we
point to one important limitation that still exists which suggests new
directions of research.",2024-12-25,"Milton L. Montero, Jeffrey S. Bowers, Gaurav Malhotra",http://arxiv.org/pdf/2412.18743v1,cs.LG
Automatic Self-supervised Learning for Social Recommendations,"In recent years, researchers have attempted to exploit social relations to
improve the performance in recommendation systems. Generally, most existing
social recommendation methods heavily depends on substantial domain knowledge
and expertise in primary recommendation tasks for designing useful auxiliary
tasks. Meanwhile, Self-Supervised Learning (SSL) recently has received
considerable attention in the field of recommendation, since it can provide
self-supervision signals in assisting the improvement of target recommendation
systems by constructing self-supervised auxiliary tasks from raw data without
human-annotated labels. Despite the great success, these SSL-based social
recommendations are insufficient to adaptively balance various self-supervised
auxiliary tasks, since assigning equal weights on various auxiliary tasks can
result in sub-optimal recommendation performance, where different
self-supervised auxiliary tasks may contribute differently to improving the
primary social recommendation across different datasets. To address this issue,
in this work, we propose Adaptive Self-supervised Learning for Social
Recommendations (AdasRec) by taking advantage of various self-supervised
auxiliary tasks. More specifically, an adaptive weighting mechanism is proposed
to learn adaptive weights for various self-supervised auxiliary tasks, so as to
balance the contribution of such self-supervised auxiliary tasks for enhancing
representation learning in social recommendations. The adaptive weighting
mechanism is used to assign different weights on auxiliary tasks to achieve an
overall weighting of the entire auxiliary tasks and ultimately assist the
primary recommendation task, achieved by a meta learning optimization problem
with an adaptive weighting network. Comprehensive experiments on various
real-world datasets are constructed to verify the effectiveness of our proposed
method.",2024-12-25,"Xin He, Wenqi Fan, Mingchen Sun, Ying Wang, Xin Wang",http://arxiv.org/pdf/2412.18735v2,cs.LG
Predicting Time Series of Networked Dynamical Systems without Knowing Topology,"Many real-world complex systems, such as epidemic spreading networks and
ecosystems, can be modeled as networked dynamical systems that produce
multivariate time series. Learning the intrinsic dynamics from observational
data is pivotal for forecasting system behaviors and making informed decisions.
However, existing methods for modeling networked time series often assume known
topologies, whereas real-world networks are typically incomplete or inaccurate,
with missing or spurious links that hinder precise predictions. Moreover, while
networked time series often originate from diverse topologies, the ability of
models to generalize across topologies has not been systematically evaluated.
To address these gaps, we propose a novel framework for learning network
dynamics directly from observed time-series data, when prior knowledge of graph
topology or governing dynamical equations is absent. Our approach leverages
continuous graph neural networks with an attention mechanism to construct a
latent topology, enabling accurate reconstruction of future trajectories for
network states. Extensive experiments on real and synthetic networks
demonstrate that our model not only captures dynamics effectively without
topology knowledge but also generalizes to unseen time series originating from
diverse topologies.",2024-12-25,"Yanna Ding, Zijie Huang, Malik Magdon-Ismail, Jianxi Gao",http://arxiv.org/pdf/2412.18734v1,cs.LG
Elucidating Flow Matching ODE Dynamics with Respect to Data Geometries,"Diffusion-based generative models have become the standard for image
generation. ODE-based samplers and flow matching models improve efficiency, in
comparison to diffusion models, by reducing sampling steps through learned
vector fields. However, the theoretical foundations of flow matching models
remain limited, particularly regarding the convergence of individual sample
trajectories at terminal time - a critical property that impacts sample quality
and being critical assumption for models like the consistency model. In this
paper, we advance the theory of flow matching models through a comprehensive
analysis of sample trajectories, centered on the denoiser that drives ODE
dynamics. We establish the existence, uniqueness and convergence of ODE
trajectories at terminal time, ensuring stable sampling outcomes under minimal
assumptions. Our analysis reveals how trajectories evolve from capturing global
data features to local structures, providing the geometric characterization of
per-sample behavior in flow matching models. We also explain the memorization
phenomenon in diffusion-based training through our terminal time analysis.
These findings bridge critical gaps in understanding flow matching models, with
practical implications for sampling stability and model design.",2024-12-25,"Zhengchao Wan, Qingsong Wang, Gal Mishne, Yusu Wang",http://arxiv.org/pdf/2412.18730v2,cs.LG
Optimizing Large Language Models with an Enhanced LoRA Fine-Tuning Algorithm for Efficiency and Robustness in NLP Tasks,"This study proposes a large language model optimization method based on the
improved LoRA fine-tuning algorithm, aiming to improve the accuracy and
computational efficiency of the model in natural language processing tasks. We
fine-tune the large language model through a low-rank adaptation strategy,
which significantly reduces the consumption of computing resources while
maintaining the powerful capabilities of the pre-trained model. The experiment
uses the QQP task as the evaluation scenario. The results show that the
improved LoRA algorithm shows significant improvements in accuracy, F1 score,
and MCC compared with traditional models such as BERT, Roberta, T5, and GPT-4.
In particular, in terms of F1 score and MCC, our model shows stronger
robustness and discrimination ability, which proves the potential of the
improved LoRA algorithm in fine-tuning large-scale pre-trained models. In
addition, this paper also discusses the application prospects of the improved
LoRA algorithm in other natural language processing tasks, emphasizing its
advantages in multi-task learning and scenarios with limited computing
resources. Future research can further optimize the LoRA fine-tuning strategy
and expand its application in larger-scale pre-trained models to improve the
generalization ability and task adaptability of the model.",2024-12-25,"Jiacheng Hu, Xiaoxuan Liao, Jia Gao, Zhen Qi, Hongye Zheng, Chihang Wang",http://arxiv.org/pdf/2412.18729v1,cs.LG
MRI Reconstruction with Regularized 3D Diffusion Model (R3DM),"Magnetic Resonance Imaging (MRI) is a powerful imaging technique widely used
for visualizing structures within the human body and in other fields such as
plant sciences. However, there is a demand to develop fast 3D-MRI
reconstruction algorithms to show the fine structure of objects from
under-sampled acquisition data, i.e., k-space data. This emphasizes the need
for efficient solutions that can handle limited input while maintaining
high-quality imaging. In contrast to previous methods only using 2D, we propose
a 3D MRI reconstruction method that leverages a regularized 3D diffusion model
combined with optimization method. By incorporating diffusion based priors, our
method improves image quality, reduces noise, and enhances the overall fidelity
of 3D MRI reconstructions. We conduct comprehensive experiments analysis on
clinical and plant science MRI datasets. To evaluate the algorithm
effectiveness for under-sampled k-space data, we also demonstrate its
reconstruction performance with several undersampling patterns, as well as with
in- and out-of-distribution pre-trained data. In experiments, we show that our
method improves upon tested competitors.",2024-12-25,"Arya Bangun, Zhuo Cao, Alessio Quercia, Hanno Scharr, Elisabeth Pfaehler",http://arxiv.org/pdf/2412.18723v1,cs.LG
Effective and Lightweight Representation Learning for Link Sign Prediction in Signed Bipartite Graphs,"How can we effectively and efficiently learn node representations in signed
bipartite graphs? A signed bipartite graph is a graph consisting of two nodes
sets where nodes of different types are positively or negative connected, and
it has been extensively used to model various real-world relationships such as
e-commerce, etc. To analyze such a graph, previous studies have focused on
designing methods for learning node representations using graph neural
networks. In particular, these methods insert edges between nodes of the same
type based on balance theory, enabling them to leverage augmented structures in
their learning. However, the existing methods rely on a naive message passing
design, which is prone to over-smoothing and susceptible to noisy interactions
in real-world graphs. Furthermore, they suffer from computational inefficiency
due to their heavy design and the significant increase in the number of added
edges.
  In this paper, we propose ELISE, an effective and lightweight GNN-based
approach for learning signed bipartite graphs. We first extend personalized
propagation to a signed bipartite graph, incorporating signed edges during
message passing. This extension adheres to balance theory without introducing
additional edges, mitigating the over-smoothing issue and enhancing
representation power. We then jointly learn node embeddings on a low-rank
approximation of the signed bipartite graph, which reduces potential noise and
emphasizes its global structure, further improving expressiveness without
significant loss of efficiency. We encapsulate these ideas into ELISE,
designing it to be lightweight, unlike the previous methods that add too many
edges and cause inefficiency. Through extensive experiments on real-world
signed bipartite graphs, we demonstrate that ELISE outperforms its competitors
for predicting link signs while providing faster training and inference time.",2024-12-25,"Gyeongmin Gu, Minseo Jeon, Hyun-Je Song, Jinhong Jung",http://arxiv.org/pdf/2412.18720v1,cs.LG
Evaluating the Adversarial Robustness of Detection Transformers,"Robust object detection is critical for autonomous driving and mobile
robotics, where accurate detection of vehicles, pedestrians, and obstacles is
essential for ensuring safety. Despite the advancements in object detection
transformers (DETRs), their robustness against adversarial attacks remains
underexplored. This paper presents a comprehensive evaluation of DETR model and
its variants under both white-box and black-box adversarial attacks, using the
MS-COCO and KITTI datasets to cover general and autonomous driving scenarios.
We extend prominent white-box attack methods (FGSM, PGD, and CW) to assess DETR
vulnerability, demonstrating that DETR models are significantly susceptible to
adversarial attacks, similar to traditional CNN-based detectors. Our extensive
transferability analysis reveals high intra-network transferability among DETR
variants, but limited cross-network transferability to CNN-based models.
Additionally, we propose a novel untargeted attack designed specifically for
DETR, exploiting its intermediate loss functions to induce misclassification
with minimal perturbations. Visualizations of self-attention feature maps
provide insights into how adversarial attacks affect the internal
representations of DETR models. These findings reveal critical vulnerabilities
in detection transformers under standard adversarial attacks, emphasizing the
need for future research to enhance the robustness of transformer-based object
detectors in safety-critical applications.",2024-12-25,"Amirhossein Nazeri, Chunheng Zhao, Pierluigi Pisu",http://arxiv.org/pdf/2412.18718v1,cs.LG
Variational Bayesian Inference for Tensor Robust Principal Component Analysis,"Tensor Robust Principal Component Analysis (TRPCA) holds a crucial position
in machine learning and computer vision. It aims to recover underlying low-rank
structures and characterizing the sparse structures of noise. Current
approaches often encounter difficulties in accurately capturing the low-rank
properties of tensors and balancing the trade-off between low-rank and sparse
components, especially in a mixed-noise scenario. To address these challenges,
we introduce a Bayesian framework for TRPCA, which integrates a low-rank tensor
nuclear norm prior and a generalized sparsity-inducing prior. By embedding the
proposed priors within the Bayesian framework, our method can automatically
determine the optimal tensor nuclear norm and achieve a balance between the
nuclear norm and sparse components. Furthermore, our method can be efficiently
extended to the weighted tensor nuclear norm model. Experiments conducted on
synthetic and real-world datasets demonstrate the effectiveness and superiority
of our method compared to state-of-the-art approaches.",2024-12-25,"Chao Wang, Huiwen Zheng, Raymond Chan, Youwen Wen",http://arxiv.org/pdf/2412.18717v1,cs.LG
Speech Recognition With LLMs Adapted to Disordered Speech Using Reinforcement Learning,"We introduce a large language model (LLM) capable of processing speech inputs
and show that tuning it further with reinforcement learning on human preference
(RLHF) enables it to adapt better to disordered speech than traditional
fine-tuning. Our method replaces low-frequency text tokens in an LLM's
vocabulary with audio tokens and enables the model to recognize speech by
fine-tuning it on speech with transcripts. We then use RL with rewards based on
syntactic and semantic accuracy measures generalizing the LLM further to
recognize disordered speech. While the resulting LLM does not outperform
existing systems for speech recognition, we find that tuning with reinforcement
learning using custom rewards leads to substantially better performance than
supervised fine-tuning of the language model, specifically when adapting to
speech in a different setting. This presents a compelling alternative tuning
strategy for speech recognition using large language models.",2024-12-25,"Chirag Nagpal, Subhashini Venugopalan, Jimmy Tobin, Marilyn Ladewig, Katherine Heller, Katrin Tomanek",http://arxiv.org/pdf/2501.00039v1,cs.LG
SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation,"Survival analysis (SA) models have been widely studied in mining electronic
health records (EHRs), particularly in forecasting the risk of critical
conditions for prioritizing high-risk patients. However, their vulnerability to
adversarial attacks is much less explored in the literature. Developing
black-box perturbation algorithms and evaluating their impact on
state-of-the-art survival models brings two benefits to medical applications.
First, it can effectively evaluate the robustness of models in pre-deployment
testing. Also, exploring how subtle perturbations would result in significantly
different outcomes can provide counterfactual insights into the clinical
interpretation of model prediction. In this work, we introduce SurvAttack, a
novel black-box adversarial attack framework leveraging subtle clinically
compatible, and semantically consistent perturbations on longitudinal EHRs to
degrade survival models' predictive performance. We specifically develop a
greedy algorithm to manipulate medical codes with various adversarial actions
throughout a patient's medical history. Then, these adversarial actions are
prioritized using a composite scoring strategy based on multi-aspect
perturbation quality, including saliency, perturbation stealthiness, and
clinical meaningfulness. The proposed adversarial EHR perturbation algorithm is
then used in an efficient SA-specific strategy to attack a survival model when
estimating the temporal ranking of survival urgency for patients. To
demonstrate the significance of our work, we conduct extensive experiments,
including baseline comparisons, explainability analysis, and case studies. The
experimental results affirm our research's effectiveness in illustrating the
vulnerabilities of patient survival models, model interpretation, and
ultimately contributing to healthcare quality.",2024-12-24,"Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao",http://arxiv.org/pdf/2412.18706v1,cs.LG
STITCH: Surface reconstrucTion using Implicit neural representations with Topology Constraints and persistent Homology,"We present STITCH, a novel approach for neural implicit surface
reconstruction of a sparse and irregularly spaced point cloud while enforcing
topological constraints (such as having a single connected component). We
develop a new differentiable framework based on persistent homology to
formulate topological loss terms that enforce the prior of a single 2-manifold
object. Our method demonstrates excellent performance in preserving the
topology of complex 3D geometries, evident through both visual and empirical
comparisons. We supplement this with a theoretical analysis, and provably show
that optimizing the loss with stochastic (sub)gradient descent leads to
convergence and enables reconstructing shapes with a single connected
component. Our approach showcases the integration of differentiable topological
data analysis tools for implicit surface reconstruction.",2024-12-24,"Anushrut Jignasu, Ethan Herron, Zhanhong Jiang, Soumik Sarkar, Chinmay Hegde, Baskar Ganapathysubramanian, Aditya Balu, Adarsh Krishnamurthy",http://arxiv.org/pdf/2412.18696v2,cs.LG
TimelyLLM: Segmented LLM Serving System for Time-sensitive Robotic Applications,"Large Language Models (LLMs) such as GPT-4 and Llama3 can already comprehend
complex commands and process diverse tasks. This advancement facilitates their
application in controlling drones and robots for various tasks. However,
existing LLM serving systems typically employ a first-come, first-served (FCFS)
batching mechanism, which fails to address the time-sensitive requirements of
robotic applications. To address it, this paper proposes a new system named
TimelyLLM serving multiple robotic agents with time-sensitive requests.
TimelyLLM introduces novel mechanisms of segmented generation and scheduling
that optimally leverage redundancy between robot plan generation and execution
phases. We report an implementation of TimelyLLM on a widely-used LLM serving
framework and evaluate it on a range of robotic applications. Our evaluation
shows that TimelyLLM improves the time utility up to 1.97x, and reduces the
overall waiting time by 84%.",2024-12-24,"Neiwen Ling, Guojun Chen, Lin Zhong",http://arxiv.org/pdf/2412.18695v1,cs.LG
Diverse and Effective Red Teaming with Auto-generated Rewards and Multi-step Reinforcement Learning,"Automated red teaming can discover rare model failures and generate
challenging examples that can be used for training or evaluation. However, a
core challenge in automated red teaming is ensuring that the attacks are both
diverse and effective. Prior methods typically succeed in optimizing either for
diversity or for effectiveness, but rarely both. In this paper, we provide
methods that enable automated red teaming to generate a large number of diverse
and successful attacks.
  Our approach decomposes the task into two steps: (1) automated methods for
generating diverse attack goals and (2) generating effective attacks for those
goals. While we provide multiple straightforward methods for generating diverse
goals, our key contributions are to train an RL attacker that both follows
those goals and generates diverse attacks for those goals. First, we
demonstrate that it is easy to use a large language model (LLM) to generate
diverse attacker goals with per-goal prompts and rewards, including rule-based
rewards (RBRs) to grade whether the attacks are successful for the particular
goal. Second, we demonstrate how training the attacker model with multi-step
RL, where the model is rewarded for generating attacks that are different from
past attempts further increases diversity while remaining effective. We use our
approach to generate both prompt injection attacks and prompts that elicit
unsafe responses. In both cases, we find that our approach is able to generate
highly-effective and considerably more diverse attacks than past general
red-teaming approaches.",2024-12-24,"Alex Beutel, Kai Xiao, Johannes Heidecke, Lilian Weng",http://arxiv.org/pdf/2412.18693v1,cs.LG
AgreeMate: Teaching LLMs to Haggle,"We introduce AgreeMate, a framework for training Large Language Models (LLMs)
to perform strategic price negotiations through natural language. We apply
recent advances to a negotiation setting where two agents (i.e. buyer or
seller) use natural language to bargain on goods using coarse actions.
Specifically, we present the performance of Large Language Models when used as
agents within a decoupled (modular) bargaining architecture. We demonstrate
that using prompt engineering, fine-tuning, and chain-of-thought prompting
enhances model performance, as defined by novel metrics. We use attention
probing to show model attention to semantic relationships between tokens during
negotiations.",2024-12-24,"Ainesh Chatterjee, Samuel Miller, Nithin Parepally",http://arxiv.org/pdf/2412.18690v1,cs.LG
Generative Modeling: A Review,"Generative methods (Gen-AI) are reviewed with a particular goal of solving
tasks in machine learning and Bayesian inference. Generative models require one
to simulate a large training dataset and to use deep neural networks to solve a
supervised learning problem. To do this, we require high-dimensional regression
methods and tools for dimensionality reduction (a.k.a. feature selection). The
main advantage of Gen-AI methods is their ability to be model-free and to use
deep neural networks to estimate conditional densities or posterior quintiles
of interest. To illustrate generative methods , we analyze the well-known Ebola
data set. Finally, we conclude with directions for future research.",2024-12-24,"Maria Nareklishvili, Nick Polson, Vadim Sokolov",http://arxiv.org/pdf/2501.05458v2,cs.LG
Pruning Unrolled Networks (PUN) at Initialization for MRI Reconstruction Improves Generalization,"Deep learning methods are highly effective for many image reconstruction
tasks. However, the performance of supervised learned models can degrade when
applied to distinct experimental settings at test time or in the presence of
distribution shifts. In this study, we demonstrate that pruning deep image
reconstruction networks at training time can improve their robustness to
distribution shifts. In particular, we consider unrolled reconstruction
architectures for accelerated magnetic resonance imaging and introduce a method
for pruning unrolled networks (PUN) at initialization. Our experiments
demonstrate that when compared to traditional dense networks, PUN offers
improved generalization across a variety of experimental settings and even
slight performance gains on in-distribution data.",2024-12-24,"Shijun Liang, Evan Bell, Avrajit Ghosh, Saiprasad Ravishankar",http://arxiv.org/pdf/2412.18668v1,cs.LG
Comparing analytic and data-driven approaches to parameter identifiability: A power systems case study,"Parameter identifiability refers to the capability of accurately inferring
the parameter values of a model from its observations (data). Traditional
analysis methods exploit analytical properties of the closed form model, in
particular sensitivity analysis, to quantify the response of the model
predictions to variations in parameters. Techniques developed to analyze data,
specifically manifold learning methods, have the potential to complement, and
even extend the scope of the traditional analytical approaches. We report on a
study comparing and contrasting analytical and data-driven approaches to
quantify parameter identifiability and, importantly, perform parameter
reduction tasks. We use the infinite bus synchronous generator model, a
well-understood model from the power systems domain, as our benchmark problem.
Our traditional analysis methods use the Fisher Information Matrix to quantify
parameter identifiability analysis, and the Manifold Boundary Approximation
Method to perform parameter reduction. We compare these results to those
arrived at through data-driven manifold learning schemes: Output - Diffusion
Maps and Geometric Harmonics. For our test case, we find that the two suites of
tools (analytical when a model is explicitly available, as well as data-driven
when the model is lacking and only measurement data are available) give
(correct) comparable results; these results are also in agreement with
traditional analysis based on singular perturbation theory. We then discuss the
prospects of using data-driven methods for such model analysis.",2024-12-24,"Nikolaos Evangelou, Alexander M. Stankovic, Ioannis G. Kevrekidis, Mark K. Transtrum",http://arxiv.org/pdf/2412.18663v1,cs.LG
A Review of Latent Representation Models in Neuroimaging,"Neuroimaging data, particularly from techniques like MRI or PET, offer rich
but complex information about brain structure and activity. To manage this
complexity, latent representation models - such as Autoencoders, Generative
Adversarial Networks (GANs), and Latent Diffusion Models (LDMs) - are
increasingly applied. These models are designed to reduce high-dimensional
neuroimaging data to lower-dimensional latent spaces, where key patterns and
variations related to brain function can be identified. By modeling these
latent spaces, researchers hope to gain insights into the biology and function
of the brain, including how its structure changes with age or disease, or how
it encodes sensory information, predicts and adapts to new inputs. This review
discusses how these models are used for clinical applications, like disease
diagnosis and progression monitoring, but also for exploring fundamental brain
mechanisms such as active inference and predictive coding. These approaches
provide a powerful tool for both understanding and simulating the brain's
complex computational tasks, potentially advancing our knowledge of cognition,
perception, and neural disorders.",2024-12-24,"C. Vázquez-García, F. J. Martínez-Murcia, F. Segovia Román, Juan M. Górriz",http://arxiv.org/pdf/2412.19844v1,cs.LG
1.58-bit FLUX,"We present 1.58-bit FLUX, the first successful approach to quantizing the
state-of-the-art text-to-image generation model, FLUX.1-dev, using 1.58-bit
weights (i.e., values in {-1, 0, +1}) while maintaining comparable performance
for generating 1024 x 1024 images. Notably, our quantization method operates
without access to image data, relying solely on self-supervision from the
FLUX.1-dev model. Additionally, we develop a custom kernel optimized for
1.58-bit operations, achieving a 7.7x reduction in model storage, a 5.1x
reduction in inference memory, and improved inference latency. Extensive
evaluations on the GenEval and T2I Compbench benchmarks demonstrate the
effectiveness of 1.58-bit FLUX in maintaining generation quality while
significantly enhancing computational efficiency.",2024-12-24,"Chenglin Yang, Celong Liu, Xueqing Deng, Dongwon Kim, Xing Mei, Xiaohui Shen, Liang-Chieh Chen",http://arxiv.org/pdf/2412.18653v1,cs.LG
Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems,"In the rapidly evolving landscape of GameFi, a fusion of gaming and
decentralized finance (DeFi), there exists a critical need to enhance player
engagement and economic interaction within gaming ecosystems. Our GameFi
ecosystem aims to fundamentally transform this landscape by integrating
advanced embodied AI agents into GameFi platforms. These AI agents, developed
using cutting-edge large language models (LLMs), such as GPT-4 and Claude AI,
are capable of proactive, adaptive, and contextually rich interactions with
players. By going beyond traditional scripted responses, these agents become
integral participants in the game's narrative and economic systems, directly
influencing player strategies and in-game economies. We address the limitations
of current GameFi platforms, which often lack immersive AI interactions and
mechanisms for community engagement or creator monetization. Through the deep
integration of AI agents with blockchain technology, we establish a
consensus-driven, decentralized GameFi ecosystem. This ecosystem empowers
creators to monetize their contributions and fosters democratic collaboration
among players and creators. Furthermore, by embedding DeFi mechanisms into the
gaming experience, we enhance economic participation and provide new
opportunities for financial interactions within the game. Our approach enhances
player immersion and retention and advances the GameFi ecosystem by bridging
traditional gaming with Web3 technologies. By integrating sophisticated AI and
DeFi elements, we contribute to the development of more engaging, economically
robust, and community-centric gaming environments. This project represents a
significant advancement in the state-of-the-art in GameFi, offering insights
and methodologies that can be applied throughout the gaming industry.",2024-12-24,"Fernando Jia, Jade Zheng, Florence Li",http://arxiv.org/pdf/2412.18601v1,cs.LG
Structure Learning in Gaussian Graphical Models from Glauber Dynamics,"Gaussian graphical model selection is an important paradigm with numerous
applications, including biological network modeling, financial network
modeling, and social network analysis. Traditional approaches assume access to
independent and identically distributed (i.i.d) samples, which is often
impractical in real-world scenarios. In this paper, we address Gaussian
graphical model selection under observations from a more realistic dependent
stochastic process known as Glauber dynamics. Glauber dynamics, also called the
Gibbs sampler, is a Markov chain that sequentially updates the variables of the
underlying model based on the statistics of the remaining model. Such models,
aside from frequently being employed to generate samples from complex
multivariate distributions, naturally arise in various settings, such as
opinion consensus in social networks and clearing/stock-price dynamics in
financial networks.
  In contrast to the extensive body of existing work, we present the first
algorithm for Gaussian graphical model selection when data are sampled
according to the Glauber dynamics. We provide theoretical guarantees on the
computational and statistical complexity of the proposed algorithm's structure
learning performance. Additionally, we provide information-theoretic lower
bounds on the statistical complexity and show that our algorithm is nearly
minimax optimal for a broad class of problems.",2024-12-24,"Vignesh Tirukkonda, Anirudh Rayas, Gautam Dasarathy",http://arxiv.org/pdf/2412.18594v2,cs.LG
Resolution-Robust 3D MRI Reconstruction with 2D Diffusion Priors: Diverse-Resolution Training Outperforms Interpolation,"Deep learning-based 3D imaging, in particular magnetic resonance imaging
(MRI), is challenging because of limited availability of 3D training data.
Therefore, 2D diffusion models trained on 2D slices are starting to be
leveraged for 3D MRI reconstruction. However, as we show in this paper,
existing methods pertain to a fixed voxel size, and performance degrades when
the voxel size is varied, as it is often the case in clinical practice. In this
paper, we propose and study several approaches for resolution-robust 3D MRI
reconstruction with 2D diffusion priors. As a result of this investigation, we
obtain a simple resolution-robust variational 3D reconstruction approach based
on diffusion-guided regularization of randomly sampled 2D slices. This method
provides competitive reconstruction quality compared to posterior sampling
baselines. Towards resolving the sensitivity to resolution-shifts, we
investigate state-of-the-art model-based approaches including Gaussian
splatting, neural representations, and infinite-dimensional diffusion models,
as well as a simple data-centric approach of training the diffusion model on
several resolutions. Our experiments demonstrate that the model-based
approaches fail to close the performance gap in 3D MRI. In contrast, the
data-centric approach of training the diffusion model on various resolutions
effectively provides a resolution-robust method without compromising accuracy.",2024-12-24,"Anselm Krainovic, Stefan Ruschke, Reinhard Heckel",http://arxiv.org/pdf/2412.18584v1,cs.LG
Exploring Embedding Priors in Prompt-Tuning for Improved Interpretability and Control,"Prompt-Tuning is an efficient method for adapting pre-trained language models
to new tasks with minimal computational overhead by modifying prompt
embeddings. In this work, we investigate how crucial the phenomenon of
embedding collapse, frequently observed in Prompt-Tuning, is for the final
performance of the model. To address this question, we designed embedding
priors and compared them with posteriors of the converged Soft and Deep
Prompt-Tuning methods. Our findings suggest that priors strongly affect the
position of the tuned embeddings, and models can effectively work with
embeddings from different parts of activation spaces, including completely new
regions. As the final Prompt-Tuning capabilities are limited, we hypothesize
that controllable Prompt-Tuning posteriors may serve as a good starting point
for tasks such as chain-of-thought (COT) distillation. Our experiments also
show that generated trajectories are not localized in the activation space of
the models. However, there are distinct clusters of activations for distant
tasks (e.g., NLP and arithmetic), while activations between NLP tasks (e.g.,
Question-Answering and MLM) lie in the same cluster. These observations raise
questions about the importance of a single activation cluster for the
generalization abilities of large language models.",2024-12-24,"Sergey Sedov, Sumanth Bharadwaj Hachalli Karanam, Venu Gopal Kadamba",http://arxiv.org/pdf/2412.18582v1,cs.LG
"ReducedLUT: Table Decomposition with ""Don't Care"" Conditions","Lookup tables (LUTs) are frequently used to efficiently store arrays of
precomputed values for complex mathematical computations. When used in the
context of neural networks, these functions exhibit a lack of recognizable
patterns which presents an unusual challenge for conventional logic synthesis
techniques. Several approaches are known to break down a single large lookup
table into multiple smaller ones that can be recombined. Traditional methods,
such as plain tabulation, piecewise linear approximation, and multipartite
table methods, often yield inefficient hardware solutions when applied to
LUT-based NNs.
  This paper introduces ReducedLUT, a novel method to reduce the footprint of
the LUTs by injecting don't cares into the compression process. This additional
freedom introduces more self-similarities which can be exploited using known
decomposition techniques. We then demonstrate a particular application to
machine learning; by replacing unobserved patterns within the training data of
neural network models with don't cares, we enable greater compression with
minimal model accuracy degradation. In practice, we achieve up to $1.63\times$
reduction in Physical LUT utilization, with a test accuracy drop of no more
than $0.01$ accuracy points.",2024-12-24,"Oliver Cassidy, Marta Andronic, Samuel Coward, George A. Constantinides",http://arxiv.org/pdf/2412.18579v2,cs.LG
Scalable Quantum-Inspired Optimization through Dynamic Qubit Compression,"Hard combinatorial optimization problems, often mapped to Ising models,
promise potential solutions with quantum advantage but are constrained by
limited qubit counts in near-term devices. We present an innovative
quantum-inspired framework that dynamically compresses large Ising models to
fit available quantum hardware of different sizes. Thus, we aim to bridge the
gap between large-scale optimization and current hardware capabilities. Our
method leverages a physics-inspired GNN architecture to capture complex
interactions in Ising models and accurately predict alignments among
neighboring spins (aka qubits) at ground states. By progressively merging such
aligned spins, we can reduce the model size while preserving the underlying
optimization structure. It also provides a natural trade-off between the
solution quality and size reduction, meeting different hardware constraints of
quantum computing devices. Extensive numerical studies on Ising instances of
diverse topologies show that our method can reduce instance size at multiple
levels with virtually no losses in solution quality on the latest D-wave
quantum annealers.",2024-12-24,"Co Tran, Quoc-Bao Tran, Hy Truong Son, Thang N Dinh",http://arxiv.org/pdf/2412.18571v1,cs.LG
HNCI: High-Dimensional Network Causal Inference,"The problem of evaluating the effectiveness of a treatment or policy commonly
appears in causal inference applications under network interference. In this
paper, we suggest the new method of high-dimensional network causal inference
(HNCI) that provides both valid confidence interval on the average direct
treatment effect on the treated (ADET) and valid confidence set for the
neighborhood size for interference effect. We exploit the model setting in
Belloni et al. (2022) and allow certain type of heterogeneity in node
interference neighborhood sizes. We propose a linear regression formulation of
potential outcomes, where the regression coefficients correspond to the
underlying true interference function values of nodes and exhibit a latent
homogeneous structure. Such a formulation allows us to leverage existing
literature from linear regression and homogeneity pursuit to conduct valid
statistical inferences with theoretical guarantees. The resulting confidence
intervals for the ADET are formally justified through asymptotic normalities
with estimable variances. We further provide the confidence set for the
neighborhood size with theoretical guarantees exploiting the repro samples
approach. The practical utilities of the newly suggested methods are
demonstrated through simulation and real data examples.",2024-12-24,"Wenqin Du, Rundong Ding, Yingying Fan, Jinchi Lv",http://arxiv.org/pdf/2412.18568v1,cs.LG
Efficient Aircraft Design Optimization Using Multi-Fidelity Models and Multi-fidelity Physics Informed Neural Networks,"Aircraft design optimization traditionally relies on computationally
expensive simulation techniques such as Finite Element Method (FEM) and Finite
Volume Method (FVM), which, while accurate, can significantly slow down the
design iteration process. The challenge lies in reducing the computational
complexity while maintaining high accuracy for quick evaluations of multiple
design alternatives. This research explores advanced methods, including
surrogate models, reduced-order models (ROM), and multi-fidelity machine
learning techniques, to achieve more efficient aircraft design evaluations.
Specifically, the study investigates the application of Multi-fidelity
Physics-Informed Neural Networks (MPINN) and autoencoders for manifold
alignment, alongside the potential of Generative Adversarial Networks (GANs)
for refining design geometries. Through a proof-of-concept task, the research
demonstrates the ability to predict high-fidelity results from low-fidelity
simulations, offering a path toward faster and more cost effective aircraft
design iterations.",2024-12-24,Apurba Sarker,http://arxiv.org/pdf/2412.18564v1,cs.LG
FedVCK: Non-IID Robust and Communication-Efficient Federated Learning via Valuable Condensed Knowledge for Medical Image Analysis,"Federated learning has become a promising solution for collaboration among
medical institutions. However, data owned by each institution would be highly
heterogeneous and the distribution is always non-independent and identical
distribution (non-IID), resulting in client drift and unsatisfactory
performance. Despite existing federated learning methods attempting to solve
the non-IID problems, they still show marginal advantages but rely on frequent
communication which would incur high costs and privacy concerns. In this paper,
we propose a novel federated learning method: \textbf{Fed}erated learning via
\textbf{V}aluable \textbf{C}ondensed \textbf{K}nowledge (FedVCK). We enhance
the quality of condensed knowledge and select the most necessary knowledge
guided by models, to tackle the non-IID problem within limited communication
budgets effectively. Specifically, on the client side, we condense the
knowledge of each client into a small dataset and further enhance the
condensation procedure with latent distribution constraints, facilitating the
effective capture of high-quality knowledge. During each round, we specifically
target and condense knowledge that has not been assimilated by the current
model, thereby preventing unnecessary repetition of homogeneous knowledge and
minimizing the frequency of communications required. On the server side, we
propose relational supervised contrastive learning to provide more supervision
signals to aid the global model updating. Comprehensive experiments across
various medical tasks show that FedVCK can outperform state-of-the-art methods,
demonstrating that it's non-IID robust and communication-efficient.",2024-12-24,"Guochen Yan, Luyuan Xie, Xinyi Gao, Wentao Zhang, Qingni Shen, Yuejian Fang, Zhonghai Wu",http://arxiv.org/pdf/2412.18557v1,cs.LG
Token-Budget-Aware LLM Reasoning,"Reasoning is critical for large language models (LLMs) to excel in a wide
range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM
performance by decomposing problems into intermediate steps, they also incur
significant overhead in token usage, leading to increased costs. We find that
the reasoning process of current LLMs is unnecessarily lengthy and it can be
compressed by including a reasonable token budget in the prompt, but the choice
of token budget plays a crucial role in the actual compression effectiveness.
We then propose a token-budget-aware LLM reasoning framework, which dynamically
estimates token budgets for different problems based on reasoning complexity
and uses the estimated token budgets to guide the reasoning process.
Experiments show that our method effectively reduces token costs in CoT
reasoning with only a slight performance reduction, offering a practical
solution to balance efficiency and accuracy in LLM reasoning. Code:
https://github.com/GeniusHTX/TALE.",2024-12-24,"Tingxu Han, Zhenting Wang, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen",http://arxiv.org/pdf/2412.18547v4,cs.LG
Consistency Checks for Language Model Forecasters,"Forecasting is a task that is difficult to evaluate: the ground truth can
only be known in the future. Recent work showing LLM forecasters rapidly
approaching human-level performance begs the question: how can we benchmark and
evaluate these forecasters instantaneously? Following the consistency check
framework, we measure the performance of forecasters in terms of the
consistency of their predictions on different logically-related questions. We
propose a new, general consistency metric based on arbitrage: for example, if a
forecasting AI illogically predicts that both the Democratic and Republican
parties have 60% probability of winning the 2024 US presidential election, an
arbitrageur can trade against the forecaster's predictions and make a profit.
We build an automated evaluation system that generates a set of base questions,
instantiates consistency checks from these questions, elicits the predictions
of the forecaster, and measures the consistency of the predictions. We then
build a standard, proper-scoring-rule forecasting benchmark, and show that our
(instantaneous) consistency metrics correlate with LLM forecasters' ground
truth Brier scores (which are only known in the future). We also release a
consistency benchmark that resolves in 2028, providing a long-term evaluation
tool for forecasting.",2024-12-24,"Daniel Paleka, Abhimanyu Pallavi Sudhir, Alejandro Alvarez, Vineeth Bhat, Adam Shen, Evan Wang, Florian Tramèr",http://arxiv.org/pdf/2412.18544v2,cs.LG
Convergence of Statistical Estimators via Mutual Information Bounds,"Recent advances in statistical learning theory have revealed profound
connections between mutual information (MI) bounds, PAC-Bayesian theory, and
Bayesian nonparametrics. This work introduces a novel mutual information bound
for statistical models. The derived bound has wide-ranging applications in
statistical inference. It yields improved contraction rates for fractional
posteriors in Bayesian nonparametrics. It can also be used to study a wide
range of estimation methods, such as variational inference or Maximum
Likelihood Estimation (MLE). By bridging these diverse areas, this work
advances our understanding of the fundamental limits of statistical inference
and the role of information in learning from data. We hope that these results
will not only clarify connections between statistical inference and information
theory but also help to develop a new toolbox to study a wide range of
estimators.",2024-12-24,"El Mahdi Khribch, Pierre Alquier",http://arxiv.org/pdf/2412.18539v1,cs.LG
Graph Structure Learning for Spatial-Temporal Imputation: Adapting to Node and Feature Scales,"Spatial-temporal data collected across different geographic locations often
suffer from missing values, posing challenges to data analysis. Existing
methods primarily leverage fixed spatial graphs to impute missing values, which
implicitly assume that the spatial relationship is roughly the same for all
features across different locations. However, they may overlook the different
spatial relationships of diverse features recorded by sensors in different
locations. To address this, we introduce the multi-scale Graph Structure
Learning framework for spatial-temporal Imputation (GSLI) that dynamically
adapts to the heterogeneous spatial correlations. Our framework encompasses
node-scale graph structure learning to cater to the distinct global spatial
correlations of different features, and feature-scale graph structure learning
to unveil common spatial correlation across features within all stations.
Integrated with prominence modeling, our framework emphasizes nodes and
features with greater significance in the imputation process. Furthermore, GSLI
incorporates cross-feature and cross-temporal representation learning to
capture spatial-temporal dependencies. Evaluated on six real incomplete
spatial-temporal datasets, GSLI showcases the improvement in data imputation.",2024-12-24,"Xinyu Yang, Yu Sun, Xinyang Chen, Ying Zhang, Xiaojie Yuan",http://arxiv.org/pdf/2412.18535v2,cs.LG
GCN-ABFT: Low-Cost Online Error Checking for Graph Convolutional Networks,"Graph convolutional networks (GCNs) are popular for building machine-learning
application for graph-structured data. This widespread adoption led to the
development of specialized GCN hardware accelerators. In this work, we address
a key architectural challenge for GCN accelerators: how to detect errors in GCN
computations arising from random hardware faults with the least computation
cost. Each GCN layer performs a graph convolution, mathematically equivalent to
multiplying three matrices, computed through two separate matrix
multiplications. Existing Algorithm-based Fault Tolerance(ABFT) techniques can
check the results of individual matrix multiplications. However, for a GCN
layer, this check should be performed twice. To avoid this overhead, this work
introduces GCN-ABFT that directly calculates a checksum for the entire
three-matrix product within a single GCN layer, providing a cost-effective
approach for error detection in GCN accelerators. Experimental results
demonstrate that GCN-ABFT reduces the number of operations needed for checksum
computation by over 21% on average for representative GCN applications. These
savings are achieved without sacrificing fault-detection accuracy, as evidenced
by the presented fault-injection analysis.",2024-12-24,"Christodoulos Peltekis, Giorgos Dimitrakopoulos",http://arxiv.org/pdf/2412.18534v1,cs.LG
Characterizations of Language Generation With Breadth,"We study language generation in the limit, introduced by Kleinberg and
Mullainathan [KM24], building on classical works of Gold [Gol67] and Angluin
[Ang79]. [KM24] proposed an algorithm that generates strings from any countable
language collection in the limit. While their algorithm eventually outputs
strings from the target language $K$, it sacrifices breadth, i.e., the ability
to generate all strings in $K$. A key open question in [KM24] is whether this
trade-off between consistency and breadth is inherrent.
  Recent works proposed different notions of consistent generation with
breadth. Kalavasis, Mehrotra, and Velegkas [KVM24] introduced three
definitions: generation with exact breadth, approximate breadth, and
unambiguous generation. Concurrently and independently, Charikar and Pabbaraju
[CP24a] proposed exhaustive generation. Both works examined when generation
with these notions of breadth is possible.
  Building on [CP24a, KVM24], we fully characterize language generation for
these notions and their natural combinations. For exact breadth, we provide an
unconditional lower bound, removing a technical condition from [KVM24] and
extending the result of [CP24a] that holds for specific collections of
languages. We show that generation with exact breadth is characterized by
Angluin's condition for identification. We further introduce a weaker version
of Angluin's condition that tightly characterizes both approximate breadth and
exhaustive generation, proving their equivalence. Additionally, we show that
unambiguous generation is also characterized by Angluin's condition as a
special case of a broader result. Finally, we strengthen [KVM24] by giving
unconditional lower bounds for stable generators, showing that Angluin's
condition characterizes the previous breadth notions for stable generators.
This shows a separation between stable and unstable generation with approximate
breadth.",2024-12-24,"Alkis Kalavasis, Anay Mehrotra, Grigoris Velegkas",http://arxiv.org/pdf/2412.18530v1,cs.LG
Accelerating process control and optimization via machine learning: A review,"Process control and optimization have been widely used to solve
decision-making problems in chemical engineering applications. However,
identifying and tuning the best solution algorithm is challenging and
time-consuming. Machine learning tools can be used to automate these steps by
learning the behavior of a numerical solver from data. In this paper, we
discuss recent advances in (i) the representation of decision-making problems
for machine learning tasks, (ii) algorithm selection, and (iii) algorithm
configuration for monolithic and decomposition-based algorithms. Finally, we
discuss open problems related to the application of machine learning for
accelerating process optimization and control.",2024-12-24,"Ilias Mitrai, Prodromos Daoutidis",http://arxiv.org/pdf/2412.18529v1,cs.LG
DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation,"Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to
enhance language understanding and generation by leveraging external knowledge.
However, effectively capturing and integrating the rich semantic information
present in textual and structured data remains a challenge. To address this, a
novel GRAG framework, Dynamic Graph Retrieval-Agumented Generation (DynaGRAG),
is proposed to focus on enhancing subgraph representation and diversity within
the knowledge graph. By improving graph density, capturing entity and relation
information more effectively, and dynamically prioritizing relevant and diverse
subgraphs and information within them, the proposed approach enables a more
comprehensive understanding of the underlying semantic structure. This is
achieved through a combination of de-duplication processes, two-step mean
pooling of embeddings, query-aware retrieval considering unique nodes, and a
Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph
Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard
prompting further enhances the learning of rich node and edge representations
while preserving the hierarchical subgraph structure. Experimental results
demonstrate the effectiveness of DynaGRAG, showcasing the significance of
enhanced subgraph representation and diversity for improved language
understanding and generation.",2024-12-24,Karishma Thakrar,http://arxiv.org/pdf/2412.18644v3,cs.LG
Bayesian Optimization of Bilevel Problems,"Bilevel optimization, a hierarchical mathematical framework where one
optimization problem is nested within another, has emerged as a powerful tool
for modeling complex decision-making processes in various fields such as
economics, engineering, and machine learning. This paper focuses on bilevel
optimization where both upper-level and lower-level functions are black boxes
and expensive to evaluate. We propose a Bayesian Optimization framework that
models the upper and lower-level functions as Gaussian processes over the
combined space of upper and lower-level decisions, allowing us to exploit
knowledge transfer between different sub-problems. Additionally, we propose a
novel acquisition function for this model. Our experimental results demonstrate
that the proposed algorithm is highly sample-efficient and outperforms existing
methods in finding high-quality solutions.",2024-12-24,"Omer Ekmekcioglu, Nursen Aydin, Juergen Branke",http://arxiv.org/pdf/2412.18518v1,cs.LG
"Subsampling, aligning, and averaging to find circular coordinates in recurrent time series","We introduce a new algorithm for finding robust circular coordinates on data
that is expected to exhibit recurrence, such as that which appears in neuronal
recordings of C. elegans. Techniques exist to create circular coordinates on a
simplicial complex from a dimension 1 cohomology class, and these can be
applied to the Rips complex of a dataset when it has a prominent class in its
dimension 1 cohomology. However, it is known this approach is extremely
sensitive to uneven sampling density.
  Our algorithm comes with a new method to correct for uneven sampling density,
adapting our prior work on averaging coordinates in manifold learning. We use
rejection sampling to correct for inhomogeneous sampling and then apply
Procrustes matching to align and average the subsamples. In addition to
providing a more robust coordinate than other approaches, this subsampling and
averaging approach has better efficiency.
  We validate our technique on both synthetic data sets and neuronal activity
recordings. Our results reveal a topological model of neuronal trajectories for
C. elegans that is constructed from loops in which different regions of the
brain state space can be mapped to specific and interpretable macroscopic
behaviors in the worm.",2024-12-24,"Andrew J. Blumberg, Mathieu Carrière, Jun Hou Fung, Michael A. Mandell",http://arxiv.org/pdf/2412.18515v1,cs.LG
FedGIG: Graph Inversion from Gradient in Federated Learning,"Recent studies have shown that Federated learning (FL) is vulnerable to
Gradient Inversion Attacks (GIA), which can recover private training data from
shared gradients. However, existing methods are designed for dense, continuous
data such as images or vectorized texts, and cannot be directly applied to
sparse and discrete graph data. This paper first explores GIA's impact on
Federated Graph Learning (FGL) and introduces Graph Inversion from Gradient in
Federated Learning (FedGIG), a novel GIA method specifically designed for
graph-structured data. FedGIG includes the adjacency matrix constraining
module, which ensures the sparsity and discreteness of the reconstructed graph
data, and the subgraph reconstruction module, which is designed to complete
missing common subgraph structures. Extensive experiments on molecular datasets
demonstrate FedGIG's superior accuracy over existing GIA techniques.",2024-12-24,"Tianzhe Xiao, Yichen Li, Yining Qi, Haozhao Wang, Ruixuan Li",http://arxiv.org/pdf/2412.18513v1,cs.LG
An Empirical Analysis of Federated Learning Models Subject to Label-Flipping Adversarial Attack,"In this paper, we empirically analyze adversarial attacks on selected
federated learning models. The specific learning models considered are
Multinominal Logistic Regression (MLR), Support Vector Classifier (SVC),
Multilayer Perceptron (MLP), Convolution Neural Network (CNN), %Recurrent
Neural Network (RNN), Random Forest, XGBoost, and Long Short-Term Memory
(LSTM). For each model, we simulate label-flipping attacks, experimenting
extensively with 10 federated clients and 100 federated clients. We vary the
percentage of adversarial clients from 10% to 100% and, simultaneously, the
percentage of labels flipped by each adversarial client is also varied from 10%
to 100%. Among other results, we find that models differ in their inherent
robustness to the two vectors in our label-flipping attack, i.e., the
percentage of adversarial clients, and the percentage of labels flipped by each
adversarial client. We discuss the potential practical implications of our
results.",2024-12-24,"Kunal Bhatnagar, Sagana Chattanathan, Angela Dang, Bhargav Eranki, Ronnit Rana, Charan Sridhar, Siddharth Vedam, Angie Yao, Mark Stamp",http://arxiv.org/pdf/2412.18507v1,cs.LG
VORTEX: A Spatial Computing Framework for Optimized Drone Telemetry Extraction from First-Person View Flight Data,"This paper presents the Visual Optical Recognition Telemetry EXtraction
(VORTEX) system for extracting and analyzing drone telemetry data from First
Person View (FPV) Uncrewed Aerial System (UAS) footage. VORTEX employs MMOCR, a
PyTorch-based Optical Character Recognition (OCR) toolbox, to extract telemetry
variables from drone Heads Up Display (HUD) recordings, utilizing advanced
image preprocessing techniques, including CLAHE enhancement and adaptive
thresholding. The study optimizes spatial accuracy and computational efficiency
through systematic investigation of temporal sampling rates (1s, 5s, 10s, 15s,
20s) and coordinate processing methods. Results demonstrate that the 5-second
sampling rate, utilizing 4.07% of available frames, provides the optimal
balance with a point retention rate of 64% and mean speed accuracy within 4.2%
of the 1-second baseline while reducing computational overhead by 80.5%.
Comparative analysis of coordinate processing methods reveals that while UTM
Zone 33N projection and Haversine calculations provide consistently similar
results (within 0.1% difference), raw WGS84 coordinates underestimate distances
by 15-30% and speeds by 20-35%. Altitude measurements showed unexpected
resilience to sampling rate variations, with only 2.1% variation across all
intervals. This research is the first of its kind, providing quantitative
benchmarks for establishing a robust framework for drone telemetry extraction
and analysis using open-source tools and spatial libraries.",2024-12-24,"James E. Gallagher, Edward J. Oughton",http://arxiv.org/pdf/2412.18505v1,cs.LG
"The Jungle of Generative Drug Discovery: Traps, Treasures, and Ways Out","""How to evaluate de novo designs proposed by a generative model?"" Despite the
transformative potential of generative deep learning in drug discovery, this
seemingly simple question has no clear answer. The absence of standardized
guidelines challenges both the benchmarking of generative approaches and the
selection of molecules for prospective studies. In this work, we take a fresh
$- \textit{critical}$ and $\textit{constructive} -$ perspective on de novo
design evaluation. We systematically investigate widely used evaluation metrics
and expose key pitfalls ('traps') that were previously overlooked. In addition,
we identify tools ('treasures') and strategies ('ways out') to navigate the
complex 'jungle' of generative drug discovery, and strengthen the connections
between the molecular and deep learning fields along the way. Our systematic
and large-scale results are expected to provide a new lens for evaluating the
de novo designs proposed by generative deep learning approaches.",2024-12-24,"Rıza Özçelik, Francesca Grisoni",http://arxiv.org/pdf/2501.05457v1,cs.LG
An Overview and Discussion of the Suitability of Existing Speech Datasets to Train Machine Learning Models for Collective Problem Solving,"This report characterized the suitability of existing datasets for devising
new Machine Learning models, decision making methods, and analysis algorithms
to improve Collaborative Problem Solving and then enumerated requirements for
future datasets to be devised. Problem solving was assumed to be performed in
teams of about three, four members, which talked to each other. A dataset
consists of the speech recordings of such teams. The characterization
methodology was based on metrics that capture cognitive, social, and emotional
activities and situations. The report presented the analysis of a large group
of datasets developed for Spoken Language Understanding, a research area with
some similarity to Collaborative Problem Solving.",2024-12-24,"Gnaneswar Villuri, Alex Doboli",http://arxiv.org/pdf/2412.18489v1,cs.LG
GeFL: Model-Agnostic Federated Learning with Generative Models,"Federated learning (FL) is a distributed training paradigm that enables
collaborative learning across clients without sharing local data, thereby
preserving privacy. However, the increasing scale and complexity of modern deep
models often exceed the computational or memory capabilities of edge devices.
Furthermore, clients may be constrained to use heterogeneous model
architectures due to hardware variability (e.g., ASICs, FPGAs) or proprietary
requirements that prevent the disclosure or modification of local model
structures. These practical considerations motivate the need for
model-heterogeneous FL, where clients participate using distinct model
architectures. In this work, we propose Generative Model-Aided Federated
Learning (GeFL), a framework that enables cross-client knowledge sharing via a
generative model trained in a federated manner. This generative model captures
global data semantics and facilitates local training without requiring model
homogeneity across clients. While GeFL achieves strong performance, empirical
analysis reveals limitations in scalability and potential privacy leakage due
to generative sample memorization. To address these concerns, we propose
GeFL-F, which utilizes feature-level generative modeling. This approach
enhances scalability to large client populations and mitigates privacy risks.
Extensive experiments across image classification tasks demonstrate that both
GeFL and GeFL-F offer competitive performance in heterogeneous settings. Code
is available at [1].",2024-12-24,"Honggu Kang, Seohyeon Cha, Joonhyuk Kang",http://arxiv.org/pdf/2412.18460v2,cs.LG
SoK: On the Offensive Potential of AI,"Our society increasingly benefits from Artificial Intelligence (AI).
Unfortunately, more and more evidence shows that AI is also used for offensive
purposes. Prior works have revealed various examples of use cases in which the
deployment of AI can lead to violation of security and privacy objectives. No
extant work, however, has been able to draw a holistic picture of the offensive
potential of AI. In this SoK paper we seek to lay the ground for a systematic
analysis of the heterogeneous capabilities of offensive AI. In particular we
(i) account for AI risks to both humans and systems while (ii) consolidating
and distilling knowledge from academic literature, expert opinions, industrial
venues, as well as laypeople -- all of which being valuable sources of
information on offensive AI.
  To enable alignment of such diverse sources of knowledge, we devise a common
set of criteria reflecting essential technological factors related to offensive
AI. With the help of such criteria, we systematically analyze: 95 research
papers; 38 InfoSec briefings (from, e.g., BlackHat); the responses of a user
study (N=549) entailing individuals with diverse backgrounds and expertise; and
the opinion of 12 experts. Our contributions not only reveal concerning ways
(some of which overlooked by prior work) in which AI can be offensively used
today, but also represent a foothold to address this threat in the years to
come.",2024-12-24,"Saskia Laura Schröer, Giovanni Apruzzese, Soheil Human, Pavel Laskov, Hyrum S. Anderson, Edward W. N. Bernroider, Aurore Fass, Ben Nassi, Vera Rimmer, Fabio Roli, Samer Salam, Ashley Shen, Ali Sunyaev, Tim Wadhwa-Brown, Isabel Wagner, Gang Wang",http://arxiv.org/pdf/2412.18442v4,cs.LG
MixMAS: A Framework for Sampling-Based Mixer Architecture Search for Multimodal Fusion and Learning,"Choosing a suitable deep learning architecture for multimodal data fusion is
a challenging task, as it requires the effective integration and processing of
diverse data types, each with distinct structures and characteristics. In this
paper, we introduce MixMAS, a novel framework for sampling-based mixer
architecture search tailored to multimodal learning. Our approach automatically
selects the optimal MLP-based architecture for a given multimodal machine
learning (MML) task. Specifically, MixMAS utilizes a sampling-based
micro-benchmarking strategy to explore various combinations of
modality-specific encoders, fusion functions, and fusion networks,
systematically identifying the architecture that best meets the task's
performance metrics.",2024-12-24,"Abdelmadjid Chergui, Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier",http://arxiv.org/pdf/2412.18437v1,cs.LG
Gaussian entropic optimal transport: Schrödinger bridges and the Sinkhorn algorithm,"Entropic optimal transport problems are regularized versions of optimal
transport problems. These models play an increasingly important role in machine
learning and generative modelling. For finite spaces, these problems are
commonly solved using Sinkhorn algorithm (a.k.a. iterative proportional fitting
procedure). However, in more general settings the Sinkhorn iterations are based
on nonlinear conditional/conjugate transformations and exact finite-dimensional
solutions cannot be computed.
  This article presents a finite-dimensional recursive formulation of the
iterative proportional fitting procedure for general Gaussian multivariate
models. As expected, this recursive formulation is closely related to the
celebrated Kalman filter and related Riccati matrix difference equations, and
it yields algorithms that can be implemented in practical settings without
further approximations. We extend this filtering methodology to develop a
refined and self-contained convergence analysis of Gaussian Sinkhorn
algorithms, including closed form expressions of entropic transport maps and
Schr\""odinger bridges.",2024-12-24,"O. Deniz Akyildiz, Pierre Del Moral, Joaquín Miguez",http://arxiv.org/pdf/2412.18432v4,cs.LG
Discovery of 2D Materials via Symmetry-Constrained Diffusion Model,"Generative model for 2D materials has shown significant promise in
accelerating the material discovery process. The stability and performance of
these materials are strongly influenced by their underlying symmetry. However,
existing generative models for 2D materials often neglect symmetry constraints,
which limits both the diversity and quality of the generated structures. Here,
we introduce a symmetry-constrained diffusion model (SCDM) that integrates
space group symmetry into the generative process. By incorporating Wyckoff
positions, the model ensures adherence to symmetry principles, leading to the
generation of 2,000 candidate structures. DFT calculations were conducted to
evaluate the convex hull energies of these structures after structural
relaxation. From the generated samples, 843 materials that met the energy
stability criteria (Ehull < 0.6 eV/atom) were identified. Among these, six
candidates were selected for further stability analysis, including phonon band
structure evaluations and electronic properties investigations, all of which
exhibited phonon spectrum stability. To benchmark the performance of SCDM, a
symmetry-unconstrained diffusion model was also evaluated via crystal structure
prediction model. The results highlight that incorporating symmetry constraints
enhances the effectiveness of generated 2D materials, making a contribution to
the discovery of 2D materials through generative modeling.",2024-12-24,"Shihang Xu, Shibing Chu, Rami Mrad, Zhejun Zhang, Zhelin Li, Runxian Jiao, Yuanping Chen",http://arxiv.org/pdf/2412.18414v1,cs.LG
A Statistical Framework for Ranking LLM-Based Chatbots,"Large language models (LLMs) have transformed natural language processing,
with frameworks like Chatbot Arena providing pioneering platforms for
evaluating these models. By facilitating millions of pairwise comparisons based
on human judgments, Chatbot Arena has become a cornerstone in LLM evaluation,
offering rich datasets for ranking models in open-ended conversational tasks.
Building upon this foundation, we propose a statistical framework that
incorporates key advancements to address specific challenges in pairwise
comparison analysis. First, we introduce a factored tie model that enhances the
ability to handle ties -- an integral aspect of human-judged comparisons --
significantly improving the model's fit to observed data. Second, we extend the
framework to model covariance between competitors, enabling deeper insights
into performance relationships and facilitating intuitive groupings into
performance tiers. Third, we resolve optimization challenges arising from
parameter non-uniqueness by introducing novel constraints, ensuring stable and
interpretable parameter estimation. Through rigorous evaluation and extensive
experimentation, our framework demonstrates substantial improvements over
existing methods in modeling pairwise comparison data. To support
reproducibility and practical adoption, we release leaderbot, an open-source
Python package implementing our models and analyses.",2024-12-24,"Siavash Ameli, Siyuan Zhuang, Ion Stoica, Michael W. Mahoney",http://arxiv.org/pdf/2412.18407v1,cs.LG
Extract Free Dense Misalignment from CLIP,"Recent vision-language foundation models still frequently produce outputs
misaligned with their inputs, evidenced by object hallucination in captioning
and prompt misalignment in the text-to-image generation model. Recent studies
have explored methods for identifying misaligned elements, aiming not only to
enhance interpretability but also to improve model performance. However,
current approaches primarily rely on large foundation models in a zero-shot
manner or fine-tuned models with human annotations, which limits scalability
due to significant computational costs. This work proposes a novel approach,
dubbed CLIP4DM, for detecting dense misalignments from pre-trained CLIP,
specifically focusing on pinpointing misaligned words between image and text.
We carefully revamp the gradient-based attribution computation method, enabling
negative gradient of individual text tokens to indicate misalignment. We also
propose F-CLIPScore, which aggregates misaligned attributions with a global
alignment score. We evaluate our method on various dense misalignment detection
benchmarks, covering various image and text domains and misalignment types. Our
method demonstrates state-of-the-art performance among zero-shot models and
competitive performance with fine-tuned models while maintaining superior
efficiency. Our qualitative examples show that our method has a unique strength
to detect entity-level objects, intangible objects, and attributes that can not
be easily detected for existing works. We conduct ablation studies and analyses
to highlight the strengths and limitations of our approach. Our code is
publicly available at https://github.com/naver-ai/CLIP4DM.",2024-12-24,"JeongYeon Nam, Jinbae Im, Wonjae Kim, Taeho Kil",http://arxiv.org/pdf/2412.18404v1,cs.LG
RDPM: Solve Diffusion Probabilistic Models via Recurrent Token Prediction,"Diffusion Probabilistic Models (DPMs) have emerged as the de facto approach
for high-fidelity image synthesis, operating diffusion processes on continuous
VAE latent, which significantly differ from the text generation methods
employed by Large Language Models (LLMs). In this paper, we introduce a novel
generative framework, the Recurrent Diffusion Probabilistic Model (RDPM), which
enhances the diffusion process through a recurrent token prediction mechanism,
thereby pioneering the field of Discrete Diffusion. By progressively
introducing Gaussian noise into the latent representations of images and
encoding them into vector-quantized tokens in a recurrent manner, RDPM
facilitates a unique diffusion process on discrete-value domains. This process
iteratively predicts the token codes for subsequent timesteps, transforming the
initial standard Gaussian noise into the source data distribution, aligning
with GPT-style models in terms of the loss function. RDPM demonstrates superior
performance while benefiting from the speed advantage of requiring only a few
inference steps. This model not only leverages the diffusion process to ensure
high-quality generation but also converts continuous signals into a series of
high-fidelity discrete tokens, thereby maintaining a unified optimization
strategy with other discrete tokens, such as text. We anticipate that this work
will contribute to the development of a unified model for multimodal
generation, specifically by integrating continuous signal domains such as
images, videos, and audio with text. We will release the code and model weights
to the open-source community.",2024-12-24,"Xiaoping Wu, Jie Hu, Xiaoming Wei",http://arxiv.org/pdf/2412.18390v2,cs.LG
Scaling Capability in Token Space: An Analysis of Large Vision Language Model,"The scaling capability has been widely validated in neural language models
with respect to the number of parameters and the size of training data.
  One important question is that does the scaling capability also exists
similarly with respect to the number of vision tokens in large vision language
Model?
  This study fills the gap by investigating the relationship between the number
of vision tokens and the performance on vision-language models.
  Our theoretical analysis and empirical evaluations demonstrate that the model
exhibits scalable performance \(S(N_l)\) with respect to the number of vision
tokens \(N_l\), characterized by the relationship \(S(N_l) \approx
(c/N_l)^{\alpha}\).
  Furthermore, we also investigate the impact of a fusion mechanism that
integrates the user's question with vision tokens.
  The results reveal two key findings.
  First, the scaling capability remains intact with the incorporation of the
fusion mechanism.
  Second, the fusion mechanism enhances model performance, particularly when
the user's question is task-specific and relevant.
  The analysis, conducted on fifteen diverse benchmarks spanning a broad range
of tasks and domains, validates the effectiveness of the proposed approach.",2024-12-24,"Tenghui Li, Guoxu Zhou, Xuyang Zhao, Qibin Zhao",http://arxiv.org/pdf/2412.18387v2,cs.LG
ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots,"The rise of LLMs has deflected a growing portion of human-computer
interactions towards LLM-based chatbots. The remarkable abilities of these
models allow users to interact using long, diverse natural language text
covering a wide range of topics and styles. Phrasing these messages is a time
and effort consuming task, calling for an autocomplete solution to assist
users. We introduce the task of chatbot interaction autocomplete. We present
ChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework
for LLM-based chatbot interactions. The framework includes a formal definition
of the task, coupled with suitable datasets and metrics. We use the framework
to evaluate After formally defining the task along with suitable datasets and
metrics, we test 9 models on the defined auto completion task, finding that
while current off-the-shelf models perform fairly, there is still much room for
improvement, mainly in ranking of the generated suggestions. We provide
insights for practitioners working on this task and open new research
directions for researchers in the field. We release our framework to serve as a
foundation for future research.",2024-12-24,"Shani Goren, Oren Kalinsky, Tomer Stav, Yuri Rapoport, Yaron Fairstein, Ram Yazdi, Nachshon Cohen, Alexander Libov, Guy Kushilevitz",http://arxiv.org/pdf/2412.18377v3,cs.LG
Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors,"Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.",2024-12-24,"Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang",http://arxiv.org/pdf/2412.18370v3,cs.LG
Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges,"Recent studies have shown that Hypergraph Neural Networks (HGNNs) are
vulnerable to adversarial attacks. Existing approaches focus on hypergraph
modification attacks guided by gradients, overlooking node spanning in the
hypergraph and the group identity of hyperedges, thereby resulting in limited
attack performance and detectable attacks. In this manuscript, we present a
novel framework, i.e., Hypergraph Attacks via Injecting Homogeneous Nodes into
Elite Hyperedges (IE-Attack), to tackle these challenges. Initially, utilizing
the node spanning in the hypergraph, we propose the elite hyperedges sampler to
identify hyperedges to be injected. Subsequently, a node generator utilizing
Kernel Density Estimation (KDE) is proposed to generate the homogeneous node
with the group identity of hyperedges. Finally, by injecting the homogeneous
node into elite hyperedges, IE-Attack improves the attack performance and
enhances the imperceptibility of attacks. Extensive experiments are conducted
on five authentic datasets to validate the effectiveness of IE-Attack and the
corresponding superiority to state-of-the-art methods.",2024-12-24,"Meixia He, Peican Zhu, Keke Tang, Yangming Guo",http://arxiv.org/pdf/2412.18365v1,cs.LG
Point-DeepONet: A Deep Operator Network Integrating PointNet for Nonlinear Analysis of Non-Parametric 3D Geometries and Load Conditions,"Nonlinear structural analyses in engineering often require extensive finite
element simulations, limiting their applicability in design optimization,
uncertainty quantification, and real-time control. Conventional deep learning
surrogates, such as convolutional neural networks (CNNs), physics-informed
neural networks (PINNs), and fourier neural operators (FNOs), face challenges
with complex non-parametric three-dimensional (3D) geometries, directionally
varying loads, and high-fidelity predictions on unstructured meshes. This work
presents Point-DeepONet, an operator-learning-based surrogate that integrates
PointNet into the DeepONet framework. By directly processing non-parametric
point clouds and incorporating signed distance functions (SDF) for geometric
context, Point-DeepONet accurately predicts three-dimensional displacement and
von Mises stress fields without mesh parameterization or retraining. Trained
using only about 5,000 nodes (2.5% of the original 200,000-node mesh),
Point-DeepONet can still predict the entire mesh at high fidelity, achieving a
coefficient of determination reaching 0.987 for displacement and 0.923 for von
Mises stress under a horizontal load case. Compared to nonlinear finite element
analyses that require about 19.32 minutes per case, Point-DeepONet provides
predictions in mere seconds-approximately 400 times faster-while maintaining
excellent scalability and accuracy with increasing dataset sizes. These
findings highlight the potential of Point-DeepONet to enable rapid,
high-fidelity structural analyses, ultimately supporting more effective design
exploration and informed decision-making in complex engineering workflows.",2024-12-24,"Jangseop Park, Namwoo Kang",http://arxiv.org/pdf/2412.18362v1,cs.LG
Handling Spatial-Temporal Data Heterogeneity for Federated Continual Learning via Tail Anchor,"Federated continual learning (FCL) allows each client to continually update
its knowledge from task streams, enhancing the applicability of federated
learning in real-world scenarios. However, FCL needs to address not only
spatial data heterogeneity between clients but also temporal data heterogeneity
between tasks. In this paper, empirical experiments demonstrate that such
input-level heterogeneity significantly affects the model's internal parameters
and outputs, leading to severe spatial-temporal catastrophic forgetting of
local and previous knowledge. To this end, we propose Federated Tail Anchor
(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust
their position in the feature space, thereby overcoming parameter-forgetting
and output-forgetting. Three novel components are also included: Input
Enhancement for improving the performance of pre-trained models on downstream
tasks; Selective Input Knowledge Fusion for fusion of heterogeneous local
knowledge on the server; and Best Global Prototype Selection for finding the
best anchor point for each class in the feature space. Extensive experiments
demonstrate that FedTA not only outperforms existing FCL methods but also
effectively preserves the relative positions of features.",2024-12-24,"Hao Yu, Xin Yang, Le Zhang, Hanlin Gu, Tianrui Li, Lixin Fan, Qiang Yang",http://arxiv.org/pdf/2412.18355v2,cs.LG
Predator Prey Scavenger Model using Holling's Functional Response of Type III and Physics-Informed Deep Neural Networks,"Nonlinear mathematical models introduce the relation between various physical
and biological interactions present in nature. One of the most famous models is
the Lotka-Volterra model which defined the interaction between predator and
prey species present in nature. However, predators, scavengers, and prey
populations coexist in a natural system where scavengers can additionally rely
on the dead bodies of predators present in the system. Keeping this in mind,
the formulation and simulation of the predator prey scavenger model is
introduced in this paper. For the predation response, respective prey species
are assumed to have Holling's functional response of type III. The proposed
model is tested for various simulations and is found to be showing satisfactory
results in different scenarios. After simulations, the American forest dataset
is taken for parameter estimation which imitates the real-world case. For
parameter estimation, a physics-informed deep neural network is used with the
Adam backpropagation method which prevents the avalanche effect in trainable
parameters updation. For neural networks, mean square error and
physics-informed informed error are considered. After the neural network, the
hence-found parameters are fine-tuned using the
Broyden-Fletcher-Goldfarb-Shanno algorithm. Finally, the hence-found parameters
using a natural dataset are tested for stability using Jacobian stability
analysis. Future research work includes minimization of error induced by
parameters, bifurcation analysis, and sensitivity analysis of the parameters.",2024-12-24,"Aneesh Panchal, Kirti Beniwal, Vivek Kumar",http://arxiv.org/pdf/2412.18344v1,cs.LG
Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization,"Open-Set Domain Generalization (OSDG) is a challenging task requiring models
to accurately predict familiar categories while minimizing confidence for
unknown categories to effectively reject them in unseen domains. While the OSDG
field has seen considerable advancements, the impact of label noise--a common
issue in real-world datasets--has been largely overlooked. Label noise can
mislead model optimization, thereby exacerbating the challenges of open-set
recognition in novel domains. In this study, we take the first step towards
addressing Open-Set Domain Generalization under Noisy Labels (OSDG-NL) by
constructing dedicated benchmarks derived from widely used OSDG datasets,
including PACS and DigitsDG. We evaluate baseline approaches by integrating
techniques from both label denoising and OSDG methodologies, highlighting the
limitations of existing strategies in handling label noise effectively. To
address these limitations, we propose HyProMeta, a novel framework that
integrates hyperbolic category prototypes for label noise-aware meta-learning
alongside a learnable new-category agnostic prompt designed to enhance
generalization to unseen classes. Our extensive experiments demonstrate the
superior performance of HyProMeta compared to state-of-the-art methods across
the newly established benchmarks. The source code of this work is released at
https://github.com/KPeng9510/HyProMeta.",2024-12-24,"Kunyu Peng, Di Wen, Sarfraz M. Saquib, Yufan Chen, Junwei Zheng, David Schneider, Kailun Yang, Jiamin Wu, Alina Roitberg, Rainer Stiefelhagen",http://arxiv.org/pdf/2412.18342v1,cs.LG
Exploring Graph Mamba: A Comprehensive Survey on State-Space Models for Graph Learning,"Graph Mamba, a powerful graph embedding technique, has emerged as a
cornerstone in various domains, including bioinformatics, social networks, and
recommendation systems. This survey represents the first comprehensive study
devoted to Graph Mamba, to address the critical gaps in understanding its
applications, challenges, and future potential. We start by offering a detailed
explanation of the original Graph Mamba architecture, highlighting its key
components and underlying mechanisms. Subsequently, we explore the most recent
modifications and enhancements proposed to improve its performance and
applicability. To demonstrate the versatility of Graph Mamba, we examine its
applications across diverse domains. A comparative analysis of Graph Mamba and
its variants is conducted to shed light on their unique characteristics and
potential use cases. Furthermore, we identify potential areas where Graph Mamba
can be applied in the future, highlighting its potential to revolutionize data
analysis in these fields. Finally, we address the current limitations and open
research questions associated with Graph Mamba. By acknowledging these
challenges, we aim to stimulate further research and development in this
promising area. This survey serves as a valuable resource for both newcomers
and experienced researchers seeking to understand and leverage the power of
Graph Mamba.",2024-12-24,"Safa Ben Atitallah, Chaima Ben Rabah, Maha Driss, Wadii Boulila, Anis Koubaa",http://arxiv.org/pdf/2412.18322v1,cs.LG
Data-Driven Self-Supervised Graph Representation Learning,"Self-supervised graph representation learning (SSGRL) is a representation
learning paradigm used to reduce or avoid manual labeling. An essential part of
SSGRL is graph data augmentation. Existing methods usually rely on heuristics
commonly identified through trial and error and are effective only within some
application domains. Also, it is not clear why one heuristic is better than
another. Moreover, recent studies have argued against some techniques (e.g.,
dropout: that can change the properties of molecular graphs or destroy relevant
signals for graph-based document classification tasks).
  In this study, we propose a novel data-driven SSGRL approach that
automatically learns a suitable graph augmentation from the signal encoded in
the graph (i.e., the nodes' predictive feature and topological information). We
propose two complementary approaches that produce learnable feature and
topological augmentations. The former learns multi-view augmentation of node
features, and the latter learns a high-order view of the topology. Moreover,
the augmentations are jointly learned with the representation. Our approach is
general that it can be applied to homogeneous and heterogeneous graphs. We
perform extensive experiments on node classification (using nine homogeneous
and heterogeneous datasets) and graph property prediction (using another eight
datasets). The results show that the proposed method matches or outperforms the
SOTA SSGRL baselines and performs similarly to semi-supervised methods. The
anonymised source code is available at https://github.com/AhmedESamy/dsgrl/",2024-12-24,"Ahmed E. Samy, Zekarias T. Kefatoa, Sarunas Girdzijauskasa",http://arxiv.org/pdf/2412.18316v1,cs.LG
FameBias: Embedding Manipulation Bias Attack in Text-to-Image Models,"Text-to-Image (T2I) diffusion models have rapidly advanced, enabling the
generation of high-quality images that align closely with textual descriptions.
However, this progress has also raised concerns about their misuse for
propaganda and other malicious activities. Recent studies reveal that attackers
can embed biases into these models through simple fine-tuning, causing them to
generate targeted imagery when triggered by specific phrases. This underscores
the potential for T2I models to act as tools for disseminating propaganda,
producing images aligned with an attacker's objective for end-users.
  Building on this concept, we introduce FameBias, a T2I biasing attack that
manipulates the embeddings of input prompts to generate images featuring
specific public figures. Unlike prior methods, Famebias operates solely on the
input embedding vectors without requiring additional model training. We
evaluate FameBias comprehensively using Stable Diffusion V2, generating a large
corpus of images based on various trigger nouns and target public figures. Our
experiments demonstrate that FameBias achieves a high attack success rate while
preserving the semantic context of the original prompts across multiple
trigger-target pairs.",2024-12-24,"Jaechul Roh, Andrew Yuan, Jinsong Mao",http://arxiv.org/pdf/2412.18302v1,cs.LG
"Quo Vadis, Anomaly Detection? LLMs and VLMs in the Spotlight","Video anomaly detection (VAD) has witnessed significant advancements through
the integration of large language models (LLMs) and vision-language models
(VLMs), addressing critical challenges such as interpretability, temporal
reasoning, and generalization in dynamic, open-world scenarios. This paper
presents an in-depth review of cutting-edge LLM-/VLM-based methods in 2024,
focusing on four key aspects: (i) enhancing interpretability through semantic
insights and textual explanations, making visual anomalies more understandable;
(ii) capturing intricate temporal relationships to detect and localize dynamic
anomalies across video frames; (iii) enabling few-shot and zero-shot detection
to minimize reliance on large, annotated datasets; and (iv) addressing
open-world and class-agnostic anomalies by using semantic understanding and
motion features for spatiotemporal coherence. We highlight their potential to
redefine the landscape of VAD. Additionally, we explore the synergy between
visual and textual modalities offered by LLMs and VLMs, highlighting their
combined strengths and proposing future directions to fully exploit the
potential in enhancing video anomaly detection.",2024-12-24,"Xi Ding, Lei Wang",http://arxiv.org/pdf/2412.18298v1,cs.LG
Learning to Play Against Unknown Opponents,"We consider the problem of a learning agent who has to repeatedly play a
general sum game against a strategic opponent who acts to maximize their own
payoff by optimally responding against the learner's algorithm. The learning
agent knows their own payoff function, but is uncertain about the payoff of
their opponent (knowing only that it is drawn from some distribution
$\mathcal{D}$). What learning algorithm should the agent run in order to
maximize their own total utility, either in expectation or in the worst-case
over $\mathcal{D}$?
  When the learning algorithm is constrained to be a no-regret algorithm, we
demonstrate how to efficiently construct an optimal learning algorithm
(asymptotically achieving the optimal utility) in polynomial time for both the
in-expectation and worst-case problems, independent of any other assumptions.
When the learning algorithm is not constrained to no-regret, we show how to
construct an $\varepsilon$-optimal learning algorithm (obtaining average
utility within $\varepsilon$ of the optimal utility) for both the
in-expectation and worst-case problems in time polynomial in the size of the
input and $1/\varepsilon$, when either the size of the game or the support of
$\mathcal{D}$ is constant. Finally, for the special case of the maximin
objective, where the learner wishes to maximize their minimum payoff over all
possible optimizer types, we construct a learner algorithm that runs in
polynomial time in each step and guarantees convergence to the optimal learner
payoff. All of these results make use of recently developed machinery that
converts the analysis of learning algorithms to the study of the class of
corresponding geometric objects known as menus.",2024-12-24,"Eshwar Ram Arunachaleswaran, Natalie Collina, Jon Schneider",http://arxiv.org/pdf/2412.18297v2,cs.LG
"Navigating Data Corruption in Machine Learning: Balancing Quality, Quantity, and Imputation Strategies","Data corruption, including missing and noisy data, poses significant
challenges in real-world machine learning. This study investigates the effects
of data corruption on model performance and explores strategies to mitigate
these effects through two experimental setups: supervised learning with NLP
tasks (NLP-SL) and deep reinforcement learning for traffic signal optimization
(Signal-RL). We analyze the relationship between data corruption levels and
model performance, evaluate the effectiveness of data imputation methods, and
assess the utility of enlarging datasets to address data corruption.
  Our results show that model performance under data corruption follows a
diminishing return curve, modeled by the exponential function. Missing data,
while detrimental, is less harmful than noisy data, which causes severe
performance degradation and training instability, particularly in sequential
decision-making tasks like Signal-RL. Imputation strategies involve a
trade-off: they recover missing information but may introduce noise. Their
effectiveness depends on imputation accuracy and corruption ratio. We identify
distinct regions in the imputation advantage heatmap, including an ""imputation
advantageous corner"" and an ""imputation disadvantageous edge"" and classify
tasks as ""noise-sensitive"" or ""noise-insensitive"" based on their decision
boundaries.
  Furthermore, we find that increasing dataset size mitigates but cannot fully
overcome the effects of data corruption. The marginal utility of additional
data diminishes as corruption increases. An empirical rule emerges:
approximately 30% of the data is critical for determining performance, while
the remaining 70% has minimal impact.
  These findings provide actionable insights into data preprocessing,
imputation strategies, and data collection practices, guiding the development
of robust machine learning systems in noisy environments.",2024-12-24,"Qi Liu, Wanjing Ma",http://arxiv.org/pdf/2412.18296v2,cs.LG
DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation,"Code review is a vital but demanding aspect of software development,
generating significant interest in automating review comments. Traditional
evaluation methods for these comments, primarily based on text similarity, face
two major challenges: inconsistent reliability of human-authored comments in
open-source projects and the weak correlation of text similarity with
objectives like enhancing code quality and detecting defects.
  This study empirically analyzes benchmark comments using a novel set of
criteria informed by prior research and developer interviews. We then similarly
revisit the evaluation of existing methodologies. Our evaluation framework,
DeepCRCEval, integrates human evaluators and Large Language Models (LLMs) for a
comprehensive reassessment of current techniques based on the criteria set.
Besides, we also introduce an innovative and efficient baseline, LLM-Reviewer,
leveraging the few-shot learning capabilities of LLMs for a target-oriented
comparison.
  Our research highlights the limitations of text similarity metrics, finding
that less than 10% of benchmark comments are high quality for automation. In
contrast, DeepCRCEval effectively distinguishes between high and low-quality
comments, proving to be a more reliable evaluation mechanism. Incorporating LLM
evaluators into DeepCRCEval significantly boosts efficiency, reducing time and
cost by 88.78% and 90.32%, respectively. Furthermore, LLM-Reviewer demonstrates
significant potential of focusing task real targets in comment generation.",2024-12-24,"Junyi Lu, Xiaojia Li, Zihan Hua, Lei Yu, Shiqi Cheng, Li Yang, Fengjun Zhang, Chun Zuo",http://arxiv.org/pdf/2412.18291v2,cs.LG
Dissipation alters modes of information encoding in small quantum reservoirs near criticality,"Quantum reservoir computing (QRC) has emerged as a promising paradigm for
harnessing near-term quantum devices to tackle temporal machine learning tasks.
Yet identifying the mechanisms that underlie enhanced performance remains
challenging, particularly in many-body open systems where nonlinear
interactions and dissipation intertwine in complex ways. Here, we investigate a
minimal model of a driven-dissipative quantum reservoir described by two
coupled Kerr-nonlinear oscillators, an experimentally realizable platform that
features controllable coupling, intrinsic nonlinearity, and tunable photon
loss. Using Partial Information Decomposition (PID), we examine how different
dynamical regimes encode input drive signals in terms of redundancy
(information shared by each oscillator) and synergy (information accessible
only through their joint observation). Our key results show that, near a
critical point marking a dynamical bifurcation, the system transitions from
predominantly redundant to synergistic encoding. We further demonstrate that
synergy amplifies short-term responsiveness, thereby enhancing immediate memory
retention, whereas strong dissipation leads to more redundant encoding that
supports long-term memory retention. These findings elucidate how the interplay
of instability and dissipation shapes information processing in small quantum
systems, providing a fine-grained, information-theoretic perspective for
analyzing and designing QRC platforms.",2024-12-24,"Krai Cheamsawat, Thiparat Chotibut",http://arxiv.org/pdf/2412.18290v2,cs.LG
Towards understanding how attention mechanism works in deep learning,"Attention mechanism has been extensively integrated within mainstream neural
network architectures, such as Transformers and graph attention networks. Yet,
its underlying working principles remain somewhat elusive. What is its essence?
Are there any connections between it and traditional machine learning
algorithms? In this study, we inspect the process of computing similarity using
classic metrics and vector space properties in manifold learning, clustering,
and supervised learning. We identify the key characteristics of similarity
computation and information propagation in these methods and demonstrate that
the self-attention mechanism in deep learning adheres to the same principles
but operates more flexibly and adaptively. We decompose the self-attention
mechanism into a learnable pseudo-metric function and an information
propagation process based on similarity computation. We prove that the
self-attention mechanism converges to a drift-diffusion process through
continuous modeling provided the pseudo-metric is a transformation of a metric
and certain reasonable assumptions hold. This equation could be transformed
into a heat equation under a new metric. In addition, we give a first-order
analysis of attention mechanism with a general pseudo-metric function. This
study aids in understanding the effects and principle of attention mechanism
through physical intuition. Finally, we propose a modified attention mechanism
called metric-attention by leveraging the concept of metric learning to
facilitate the ability to learn desired metrics more effectively. Experimental
results demonstrate that it outperforms self-attention regarding training
efficiency, accuracy, and robustness.",2024-12-24,"Tianyu Ruan, Shihua Zhang",http://arxiv.org/pdf/2412.18288v1,cs.LG
Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation,"Credit card fraud incurs a considerable cost for both cardholders and issuing
banks. Contemporary methods apply machine learning-based classifiers to detect
fraudulent behavior from labeled transaction records. But labeled data are
usually a small proportion of billions of real transactions due to expensive
labeling costs, which implies that they do not well exploit many natural
features from unlabeled data. Therefore, we propose a semi-supervised graph
neural network for fraud detection. Specifically, we leverage transaction
records to construct a temporal transaction graph, which is composed of
temporal transactions (nodes) and interactions (edges) among them. Then we pass
messages among the nodes through a Gated Temporal Attention Network (GTAN) to
learn the transaction representation. We further model the fraud patterns
through risk propagation among transactions. The extensive experiments are
conducted on a real-world transaction dataset and two publicly available fraud
detection datasets. The result shows that our proposed method, namely GTAN,
outperforms other state-of-the-art baselines on three fraud detection datasets.
Semi-supervised experiments demonstrate the excellent fraud detection
performance of our model with only a tiny proportion of labeled data.",2024-12-24,"Sheng Xiang, Mingzhi Zhu, Dawei Cheng, Enxia Li, Ruihui Zhao, Yi Ouyang, Ling Chen, Yefeng Zheng",http://arxiv.org/pdf/2412.18287v1,cs.LG
On the Local Complexity of Linear Regions in Deep ReLU Networks,"We define the local complexity of a neural network with continuous piecewise
linear activations as a measure of the density of linear regions over an input
data distribution. We show theoretically that ReLU networks that learn
low-dimensional feature representations have a lower local complexity. This
allows us to connect recent empirical observations on feature learning at the
level of the weight matrices with concrete properties of the learned functions.
In particular, we show that the local complexity serves as an upper bound on
the total variation of the function over the input data distribution and thus
that feature learning can be related to adversarial robustness. Lastly, we
consider how optimization drives ReLU networks towards solutions with lower
local complexity. Overall, this work contributes a theoretical framework
towards relating geometric properties of ReLU networks to different aspects of
learning such as feature learning and representation cost.",2024-12-24,"Niket Patel, Guido Montúfar",http://arxiv.org/pdf/2412.18283v2,cs.LG
GDM4MMIMO: Generative Diffusion Models for Massive MIMO Communications,"Massive multiple-input multiple-output (MIMO) offers significant advantages
in spectral and energy efficiencies, positioning it as a cornerstone technology
of fifth-generation (5G) wireless communication systems and a promising
solution for the burgeoning data demands anticipated in sixth-generation (6G)
networks. In recent years, with the continuous advancement of artificial
intelligence (AI), a multitude of task-oriented generative foundation models
(GFMs) have emerged, achieving remarkable performance in various fields such as
computer vision (CV), natural language processing (NLP), and autonomous
driving. As a pioneering force, these models are driving the paradigm shift in
AI towards generative AI (GenAI). Among them, the generative diffusion model
(GDM), as one of state-of-the-art families of generative models, demonstrates
an exceptional capability to learn implicit prior knowledge and robust
generalization capabilities, thereby enhancing its versatility and
effectiveness across diverse applications. In this paper, we delve into the
potential applications of GDM in massive MIMO communications. Specifically, we
first provide an overview of massive MIMO communication, the framework of GFMs,
and the working mechanism of GDM. Following this, we discuss recent research
advancements in the field and present a case study of near-field channel
estimation based on GDM, demonstrating its promising potential for facilitating
efficient ultra-dimensional channel statement information (CSI) acquisition in
the context of massive MIMO communications. Finally, we highlight several
pressing challenges in future mobile communications and identify promising
research directions surrounding GDM.",2024-12-24,"Zhenzhou Jin, Li You, Huibin Zhou, Yuanshuo Wang, Xiaofeng Liu, Xinrui Gong, Xiqi Gao, Derrick Wing Kwan Ng, Xiang-Gen Xia",http://arxiv.org/pdf/2412.18281v1,cs.LG
Towards Modality Generalization: A Benchmark and Prospective Analysis,"Multi-modal learning has achieved remarkable success by integrating
information from various modalities, achieving superior performance in tasks
like recognition and retrieval compared to uni-modal approaches. However,
real-world scenarios often present novel modalities that are unseen during
training due to resource and privacy constraints, a challenge current methods
struggle to address. This paper introduces Modality Generalization (MG), which
focuses on enabling models to generalize to unseen modalities. We define two
cases: weak MG, where both seen and unseen modalities can be mapped into a
joint embedding space via existing perceptors, and strong MG, where no such
mappings exist. To facilitate progress, we propose a comprehensive benchmark
featuring multi-modal algorithms and adapt existing methods that focus on
generalization. Extensive experiments highlight the complexity of MG, exposing
the limitations of existing methods and identifying key directions for future
research. Our work provides a foundation for advancing robust and adaptable
multi-modal models, enabling them to handle unseen modalities in realistic
scenarios.",2024-12-24,"Xiaohao Liu, Xiaobo Xia, Zhuo Huang, Tat-Seng Chua",http://arxiv.org/pdf/2412.18277v1,cs.LG
NoiseHGNN: Synthesized Similarity Graph-Based Neural Network For Noised Heterogeneous Graph Representation Learning,"Real-world graph data environments intrinsically exist noise (e.g., link and
structure errors) that inevitably disturb the effectiveness of graph
representation and downstream learning tasks. For homogeneous graphs, the
latest works use original node features to synthesize a similarity graph that
can correct the structure of the noised graph. This idea is based on the
homogeneity assumption, which states that similar nodes in the homogeneous
graph tend to have direct links in the original graph. However, similar nodes
in heterogeneous graphs usually do not have direct links, which can not be used
to correct the original noise graph. This causes a significant challenge in
noised heterogeneous graph learning. To this end, this paper proposes a novel
synthesized similarity-based graph neural network compatible with noised
heterogeneous graph learning. First, we calculate the original feature
similarities of all nodes to synthesize a similarity-based high-order graph.
Second, we propose a similarity-aware encoder to embed original and synthesized
graphs with shared parameters. Then, instead of graph-to-graph supervising, we
synchronously supervise the original and synthesized graph embeddings to
predict the same labels. Meanwhile, a target-based graph extracted from the
synthesized graph contrasts the structure of the metapath-based graph extracted
from the original graph to learn the mutual information. Extensive experiments
in numerous real-world datasets show the proposed method achieves
state-of-the-art records in the noised heterogeneous graph learning tasks. In
highlights, +5$\sim$6\% improvements are observed in several noised datasets
compared with previous SOTA methods. The code and datasets are available at
https://github.com/kg-cc/NoiseHGNN.",2024-12-24,"Xiong Zhang, Cheng Xie, Haoran Duan, Beibei Yu",http://arxiv.org/pdf/2412.18267v1,cs.LG
High-Rank Irreducible Cartesian Tensor Decomposition and Bases of Equivariant Spaces,"Irreducible Cartesian tensors (ICTs) play a crucial role in the design of
equivariant graph neural networks, as well as in theoretical chemistry and
chemical physics. Meanwhile, the design space of available linear operations on
tensors that preserve symmetry presents a significant challenge. The ICT
decomposition and a basis of this equivariant space are difficult to obtain for
high-rank tensors. After decades of research, Bonvicini (2024) recently
achieves an explicit ICT decomposition for $n=5$ with factorial time/space
complexity. In this work we, for the first time, obtains decomposition matrices
for ICTs up to rank $n=9$ with reduced and affordable complexity, by
constructing what we call path matrices. The path matrices are obtained via
performing chain-like contractions with Clebsch-Gordan matrices following the
parentage scheme. We prove and leverage that the concatenation of path matrices
is an orthonormal change-of-basis matrix between the Cartesian tensor product
space and the spherical direct sum spaces. Furthermore, we identify a complete
orthogonal basis for the equivariant space, rather than a spanning set
(Pearce-Crump, 2023), through this path matrices technique. To the best of our
knowledge, this is also the first analytic, rather than numerical, method for
theoretically obtaining arbitrary rank orthogonal ICT decomposition matrices
and orthogonal equivariant bases. We further extend our result to the arbitrary
tensor product and direct sum spaces, enabling free design between different
spaces while keeping symmetry. The Python code is available at
https://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases, where
the $n=6,\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and
4m32s on 28-cores Intel(R) Xeon(R) Gold 6330 CPU @ 2.00GHz, respectively.",2024-12-24,"Shihao Shao, Yikang Li, Zhouchen Lin, Qinghua Cui",http://arxiv.org/pdf/2412.18263v6,cs.LG
Efficient Contrastive Explanations on Demand,"Recent work revealed a tight connection between adversarial robustness and
restricted forms of symbolic explanations, namely distance-based (formal)
explanations. This connection is significant because it represents a first step
towards making the computation of symbolic explanations as efficient as
deciding the existence of adversarial examples, especially for highly complex
machine learning (ML) models. However, a major performance bottleneck remains,
because of the very large number of features that ML models may possess, in
particular for deep neural networks. This paper proposes novel algorithms to
compute the so-called contrastive explanations for ML models with a large
number of features, by leveraging on adversarial robustness. Furthermore, the
paper also proposes novel algorithms for listing explanations and finding
smallest contrastive explanations. The experimental results demonstrate the
performance gains achieved by the novel algorithms proposed in this paper.",2024-12-24,"Yacine Izza, Joao Marques-Silva",http://arxiv.org/pdf/2412.18262v1,cs.LG
Robust Semi-Supervised Learning in Open Environments,"Semi-supervised learning (SSL) aims to improve performance by exploiting
unlabeled data when labels are scarce. Conventional SSL studies typically
assume close environments where important factors (e.g., label, feature,
distribution) between labeled and unlabeled data are consistent. However, more
practical tasks involve open environments where important factors between
labeled and unlabeled data are inconsistent. It has been reported that
exploiting inconsistent unlabeled data causes severe performance degradation,
even worse than the simple supervised learning baseline. Manually verifying the
quality of unlabeled data is not desirable, therefore, it is important to study
robust SSL with inconsistent unlabeled data in open environments. This paper
briefly introduces some advances in this line of research, focusing on
techniques concerning label, feature, and data distribution inconsistency in
SSL, and presents the evaluation benchmarks. Open research problems are also
discussed for reference purposes.",2024-12-24,"Lan-Zhe Guo, Lin-Han Jia, Jie-Jing Shao, Yu-Feng Li",http://arxiv.org/pdf/2412.18256v1,cs.LG
RNN-Based Models for Predicting Seizure Onset in Epileptic Patients,"Early management and better clinical outcomes for epileptic patients depend
on seizure prediction. The accuracy and false alarm rates of existing systems
are often compromised by their dependence on static thresholds and basic
Electroencephalogram (EEG) properties. A novel Recurrent Neural Network
(RNN)-based method for seizure start prediction is proposed in the article to
overcome these limitations. As opposed to conventional techniques, the proposed
system makes use of Long Short-Term Memory (LSTM) networks to extract temporal
correlations from unprocessed EEG data. It enables the system to adapt
dynamically to the unique EEG patterns of each patient, improving prediction
accuracy. The methodology of the system comprises thorough data collecting,
preprocessing, and LSTM-based feature extraction. Annotated EEG datasets are
then used for model training and validation. Results show a considerable
reduction in false alarm rates (average of 6.8%) and an improvement in
prediction accuracy (90.2% sensitivity, 88.9% specificity, and AUC-ROC of 93).
Additionally, computational efficiency is significantly higher than that of
existing systems (12 ms processing time, 45 MB memory consumption). About
improving seizure prediction reliability, these results demonstrate the
effectiveness of the proposed RNN-based strategy, opening up possibilities for
its practical application to improve epilepsy treatment.",2024-12-24,"Mathan Kumar Mounagurusamy, Thiyagarajan V S, Abdur Rahman, Shravan Chandak, D. Balaji, Venkateswara Rao Jallepalli",http://arxiv.org/pdf/2501.16334v1,cs.LG
Detection and Forecasting of Parkinson Disease Progression from Speech Signal Features Using MultiLayer Perceptron and LSTM,"Accurate diagnosis of Parkinson disease, especially in its early stages, can
be a challenging task. The application of machine learning techniques helps
improve the diagnostic accuracy of Parkinson disease detection but only few
studies have presented work towards the prediction of disease progression. In
this research work, Long Short Term Memory LSTM was trained using the
diagnostic features on Parkinson patients speech signals, to predict the
disease progression while a Multilayer Perceptron MLP was trained on the same
diagnostic features to detect the disease. Diagnostic features selected using
two well-known feature selection methods named Relief-F and Sequential Forward
Selection and applied on LSTM and MLP have shown to accurately predict the
disease progression as stage 2 and 3 and its existence respectively.",2024-12-24,"Majid Ali, Hina Shakir, Asia Samreen, Sohaib Ahmed",http://arxiv.org/pdf/2412.18248v1,cs.LG
Fréchet regression with implicit denoising and multicollinearity reduction,"Fr\'echet regression extends linear regression to model complex responses
  in metric spaces, making it particularly relevant for multi-label regression,
  where eachinstance can have multiple associated labels. However, addressing
  noise and dependencies among predictors within this framework remains un
derexplored. In this paper, we present an extension of the Global Fr\'echet re
gression model that enables explicit modeling of relationships between input
  variables and multiple responses. To address challenges arising from noise
  and multicollinearity, we propose a novel framework based on implicit regu
larization, which preserves the intrinsic structure of the data while
effectively
  capturing complex dependencies. Our approach ensures accurate and efficient
  modeling without the biases introduced by traditional explicit regularization
  methods. Theoretical guarantees are provided, and the performance of the
  proposed method is demonstrated through numerical experiments.",2024-12-24,"Dou El Kefel Mansouri, Seif-Eddine Benkabou, Khalid Benabdeslem",http://arxiv.org/pdf/2412.18247v2,cs.LG
OMG-HD: A High-Resolution AI Weather Model for End-to-End Forecasts from Observations,"In recent years, Artificial Intelligence Weather Prediction (AIWP) models
have achieved performance comparable to, or even surpassing, traditional
Numerical Weather Prediction (NWP) models by leveraging reanalysis data.
However, a less-explored approach involves training AIWP models directly on
observational data, enhancing computational efficiency and improving forecast
accuracy by reducing the uncertainties introduced through data assimilation
processes. In this study, we propose OMG-HD, a novel AI-based regional
high-resolution weather forecasting model designed to make predictions directly
from observational data sources, including surface stations, radar, and
satellite, thereby removing the need for operational data assimilation. Our
evaluation shows that OMG-HD outperforms both the European Centre for
Medium-Range Weather Forecasts (ECMWF)'s high-resolution operational
forecasting system, IFS-HRES, and the High-Resolution Rapid Refresh (HRRR)
model at lead times of up to 12 hours across the contiguous United States
(CONUS) region. We achieve up to a 13% improvement on RMSE for 2-meter
temperature, 17% on 10-meter wind speed, 48% on 2-meter specific humidity, and
32% on surface pressure compared to HRRR. Our method shows that it is possible
to use AI-driven approaches for rapid weather predictions without relying on
NWP-derived weather fields as model input. This is a promising step towards
using observational data directly to make operational forecasts with AIWP
models.",2024-12-24,"Pengcheng Zhao, Jiang Bian, Zekun Ni, Weixin Jin, Jonathan Weyn, Zuliang Fang, Siqi Xiang, Haiyu Dong, Bin Zhang, Hongyu Sun, Kit Thambiratnam, Qi Zhang",http://arxiv.org/pdf/2412.18239v1,cs.LG
Schödinger Bridge Type Diffusion Models as an Extension of Variational Autoencoders,"Generative diffusion models use time-forward and backward stochastic
differential equations to connect the data and prior distributions. While
conventional diffusion models (e.g., score-based models) only learn the
backward process, more flexible frameworks have been proposed to also learn the
forward process by employing the Schr\""odinger bridge (SB). However, due to the
complexity of the mathematical structure behind SB-type models, we can not
easily give an intuitive understanding of their objective function. In this
work, we propose a unified framework to construct diffusion models by
reinterpreting the SB-type models as an extension of variational autoencoders.
In this context, the data processing inequality plays a crucial role. As a
result, we find that the objective function consists of the prior loss and
drift matching parts.",2024-12-24,"Kentaro Kaba, Reo Shimizu, Masayuki Ohzeki, Yuki Sughiyama",http://arxiv.org/pdf/2412.18237v1,cs.LG
Conditional Deep Canonical Time Warping,"Temporal alignment of sequences is a fundamental challenge in many
applications, such as computer vision and bioinformatics, where local time
shifting needs to be accounted for. Misalignment can lead to poor model
generalization, especially in high-dimensional sequences. Existing methods
often struggle with optimization when dealing with high-dimensional sparse
data, falling into poor alignments. Feature selection is frequently used to
enhance model performance for sparse data. However, a fixed set of selected
features would not generally work for dynamically changing sequences and would
need to be modified based on the state of the sequence. Therefore, modifying
the selected feature based on contextual input would result in better
alignment. Our suggested method, Conditional Deep Canonical Temporal Time
Warping (CDCTW), is designed for temporal alignment in sparse temporal data to
address these challenges. CDCTW enhances alignment accuracy for high
dimensional time-dependent views be performing dynamic time warping on data
embedded in maximally correlated subspace which handles sparsity with novel
feature selection method. We validate the effectiveness of CDCTW through
extensive experiments on various datasets, demonstrating superior performance
over previous techniques.",2024-12-24,"Afek Steinberg, Ran Eisenberg, Ofir Lindenbaum",http://arxiv.org/pdf/2412.18234v2,cs.LG
Towards Macro-AUC oriented Imbalanced Multi-Label Continual Learning,"In Continual Learning (CL), while existing work primarily focuses on the
multi-class classification task, there has been limited research on Multi-Label
Learning (MLL). In practice, MLL datasets are often class-imbalanced, making it
inherently challenging, a problem that is even more acute in CL. Due to its
sensitivity to imbalance, Macro-AUC is an appropriate and widely used measure
in MLL. However, there is no research to optimize Macro-AUC in MLCL
specifically. To fill this gap, in this paper, we propose a new memory
replay-based method to tackle the imbalance issue for Macro-AUC-oriented MLCL.
Specifically, inspired by recent theory work, we propose a new Reweighted
Label-Distribution-Aware Margin (RLDAM) loss. Furthermore, to be compatible
with the RLDAM loss, a new memory-updating strategy named Weight Retain
Updating (WRU) is proposed to maintain the numbers of positive and negative
instances of the original dataset in memory. Theoretically, we provide superior
generalization analyses of the RLDAM-based algorithm in terms of Macro-AUC,
separately in batch MLL and MLCL settings. This is the first work to offer
theoretical generalization analyses in MLCL to our knowledge. Finally, a series
of experimental results illustrate the effectiveness of our method over several
baselines. Our codes are available at
https://github.com/ML-Group-SDU/Macro-AUC-CL.",2024-12-24,"Yan Zhang, Guoqiang Wu, Bingzheng Wang, Teng Pang, Haoliang Sun, Yilong Yin",http://arxiv.org/pdf/2412.18231v1,cs.LG
Leveraging Convolutional Neural Network-Transformer Synergy for Predictive Modeling in Risk-Based Applications,"With the development of the financial industry, credit default prediction, as
an important task in financial risk management, has received increasing
attention. Traditional credit default prediction methods mostly rely on machine
learning models, such as decision trees and random forests, but these methods
have certain limitations in processing complex data and capturing potential
risk patterns. To this end, this paper proposes a deep learning model based on
the combination of convolutional neural networks (CNN) and Transformer for
credit user default prediction. The model combines the advantages of CNN in
local feature extraction with the ability of Transformer in global dependency
modeling, effectively improving the accuracy and robustness of credit default
prediction. Through experiments on public credit default datasets, the results
show that the CNN+Transformer model outperforms traditional machine learning
models, such as random forests and XGBoost, in multiple evaluation indicators
such as accuracy, AUC, and KS value, demonstrating its powerful ability in
complex financial data modeling. Further experimental analysis shows that
appropriate optimizer selection and learning rate adjustment play a vital role
in improving model performance. In addition, the ablation experiment of the
model verifies the advantages of the combination of CNN and Transformer and
proves the complementarity of the two in credit default prediction. This study
provides a new idea for credit default prediction and provides strong support
for risk assessment and intelligent decision-making in the financial field.
Future research can further improve the prediction effect and generalization
ability by introducing more unstructured data and improving the model
architecture.",2024-12-24,"Yuhan Wang, Zhen Xu, Yue Yao, Jinsong Liu, Jiating Lin",http://arxiv.org/pdf/2412.18222v1,cs.LG
GIMS: Image Matching System Based on Adaptive Graph Construction and Graph Neural Network,"Feature-based image matching has extensive applications in computer vision.
Keypoints detected in images can be naturally represented as graph structures,
and Graph Neural Networks (GNNs) have been shown to outperform traditional deep
learning techniques. Consequently, the paradigm of image matching via GNNs has
gained significant prominence in recent academic research. In this paper, we
first introduce an innovative adaptive graph construction method that utilizes
a filtering mechanism based on distance and dynamic threshold similarity. This
method dynamically adjusts the criteria for incorporating new vertices based on
the characteristics of existing vertices, allowing for the construction of more
precise and robust graph structures while avoiding redundancy. We further
combine the vertex processing capabilities of GNNs with the global awareness
capabilities of Transformers to enhance the model's representation of spatial
and feature information within graph structures. This hybrid model provides a
deeper understanding of the interrelationships between vertices and their
contributions to the matching process. Additionally, we employ the Sinkhorn
algorithm to iteratively solve for optimal matching results. Finally, we
validate our system using extensive image datasets and conduct comprehensive
comparative experiments. Experimental results demonstrate that our system
achieves an average improvement of 3.8x-40.3x in overall matching performance.
Additionally, the number of vertices and edges significantly impacts training
efficiency and memory usage; therefore, we employ multi-GPU technology to
accelerate the training process. Our code is available at
https://github.com/songxf1024/GIMS.",2024-12-24,"Xianfeng Song, Yi Zou, Zheng Shi, Zheng Liu",http://arxiv.org/pdf/2412.18221v1,cs.LG
On the Effectiveness of Adversarial Training on Malware Classifiers,"Adversarial Training (AT) has been widely applied to harden learning-based
classifiers against adversarial evasive attacks. However, its effectiveness in
identifying and strengthening vulnerable areas of the model's decision space
while maintaining high performance on clean data of malware classifiers remains
an under-explored area. In this context, the robustness that AT achieves has
often been assessed against unrealistic or weak adversarial attacks, which
negatively affect performance on clean data and are arguably no longer threats.
Previous work seems to suggest robustness is a task-dependent property of AT.
We instead argue it is a more complex problem that requires exploring AT and
the intertwined roles played by certain factors within data, feature
representations, classifiers, and robust optimization settings, as well as
proper evaluation factors, such as the realism of evasion attacks, to gain a
true sense of AT's effectiveness. In our paper, we address this gap by
systematically exploring the role such factors have in hardening malware
classifiers through AT. Contrary to recent prior work, a key observation of our
research and extensive experiments confirm the hypotheses that all such factors
influence the actual effectiveness of AT, as demonstrated by the varying
degrees of success from our empirical analysis. We identify five evaluation
pitfalls that affect state-of-the-art studies and summarize our insights in ten
takeaways to draw promising research directions toward better understanding the
factors' settings under which adversarial training works at best.",2024-12-24,"Hamid Bostani, Jacopo Cortellazzi, Daniel Arp, Fabio Pierazzi, Veelasha Moonsamy, Lorenzo Cavallaro",http://arxiv.org/pdf/2412.18218v1,cs.LG
U-Mamba-Net: A highly efficient Mamba-based U-net style network for noisy and reverberant speech separation,"The topic of speech separation involves separating mixed speech with multiple
overlapping speakers into several streams, with each stream containing speech
from only one speaker. Many highly effective models have emerged and
proliferated rapidly over time. However, the size and computational load of
these models have also increased accordingly. This is a disaster for the
community, as researchers need more time and computational resources to
reproduce and compare existing models. In this paper, we propose U-mamba-net: a
lightweight Mamba-based U-style model for speech separation in complex
environments. Mamba is a state space sequence model that incorporates feature
selection capabilities. U-style network is a fully convolutional neural network
whose symmetric contracting and expansive paths are able to learn
multi-resolution features. In our work, Mamba serves as a feature filter,
alternating with U-Net. We test the proposed model on Libri2mix. The results
show that U-Mamba-Net achieves improved performance with quite low
computational cost.",2024-12-24,"Shaoxiang Dang, Tetsuya Matsumoto, Yoshinori Takeuchi, Hiroaki Kudo",http://arxiv.org/pdf/2412.18217v1,cs.LG
Accelerating AIGC Services with Latent Action Diffusion Scheduling in Edge Networks,"Artificial Intelligence Generated Content (AIGC) has gained significant
popularity for creating diverse content. Current AIGC models primarily focus on
content quality within a centralized framework, resulting in a high service
delay and negative user experiences. However, not only does the workload of an
AIGC task depend on the AIGC model's complexity rather than the amount of data,
but the large model and its multi-layer encoder structure also result in a huge
demand for computational and memory resources. These unique characteristics
pose new challenges in its modeling, deployment, and scheduling at edge
networks. Thus, we model an offloading problem among edges for providing real
AIGC services and propose LAD-TS, a novel Latent Action Diffusion-based Task
Scheduling method that orchestrates multiple edge servers for expedited AIGC
services. The LAD-TS generates a near-optimal offloading decision by leveraging
the diffusion model's conditional generation capability and the reinforcement
learning's environment interaction ability, thereby minimizing the service
delays under multiple resource constraints. Meanwhile, a latent action
diffusion strategy is designed to guide decision generation by utilizing
historical action probability, enabling rapid achievement of near-optimal
decisions. Furthermore, we develop DEdgeAI, a prototype edge system with a
refined AIGC model deployment to implement and evaluate our LAD-TS method.
DEdgeAI provides a real AIGC service for users, demonstrating up to 29.18%
shorter service delays than the current five representative AIGC platforms. We
release our open-source code at https://github.com/ChangfuXu/DEdgeAI/.",2024-12-24,"Changfu Xu, Jianxiong Guo, Wanyu Lin, Haodong Zou, Wentao Fan, Tian Wang, Xiaowen Chu, Jiannong Cao",http://arxiv.org/pdf/2412.18212v1,cs.LG
"Quantum framework for Reinforcement Learning: integrating Markov Decision Process, quantum arithmetic, and trajectory search","This paper introduces a quantum framework for addressing reinforcement
learning (RL) tasks, grounded in the quantum principles and leveraging a fully
quantum model of the classical Markov Decision Process (MDP). By employing
quantum concepts and a quantum search algorithm, this work presents the
implementation and optimization of the agent-environment interactions entirely
within the quantum domain, eliminating reliance on classical computations. Key
contributions include the quantum-based state transitions, return calculation,
and trajectory search mechanism that utilize quantum principles to demonstrate
the realization of RL processes through quantum phenomena. The implementation
emphasizes the fundamental role of quantum superposition in enhancing
computational efficiency for RL tasks. Results demonstrate the capacity of a
quantum model to achieve quantum enhancement in RL, highlighting the potential
of fully quantum implementations in decision-making tasks. This work not only
underscores the applicability of quantum computing in machine learning but also
contributes the field of quantum reinforcement learning (QRL) by offering a
robust framework for understanding and exploiting quantum computing in RL
systems.",2024-12-24,"Thet Htar Su, Shaswot Shresthamali, Masaaki Kondo",http://arxiv.org/pdf/2412.18208v2,cs.LG
Sharper Error Bounds in Late Fusion Multi-view Clustering Using Eigenvalue Proportion,"Multi-view clustering (MVC) aims to integrate complementary information from
multiple views to enhance clustering performance. Late Fusion Multi-View
Clustering (LFMVC) has shown promise by synthesizing diverse clustering results
into a unified consensus. However, current LFMVC methods struggle with noisy
and redundant partitions and often fail to capture high-order correlations
across views. To address these limitations, we present a novel theoretical
framework for analyzing the generalization error bounds of multiple kernel
$k$-means, leveraging local Rademacher complexity and principal eigenvalue
proportions. Our analysis establishes a convergence rate of $\mathcal{O}(1/n)$,
significantly improving upon the existing rate in the order of
$\mathcal{O}(\sqrt{k/n})$. Building on this insight, we propose a low-pass
graph filtering strategy within a multiple linear $k$-means framework to
mitigate noise and redundancy, further refining the principal eigenvalue
proportion and enhancing clustering accuracy. Experimental results on benchmark
datasets confirm that our approach outperforms state-of-the-art methods in
clustering performance and robustness. The related codes is available at
https://github.com/csliangdu/GMLKM .",2024-12-24,"Liang Du, Henghui Jiang, Xiaodong Li, Yiqing Guo, Yan Chen, Feijiang Li, Peng Zhou, Yuhua Qian",http://arxiv.org/pdf/2412.18207v1,cs.LG
Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs Algorithms,"This paper leverages machine learning algorithms to forecast and analyze
financial time series. The process begins with a denoising autoencoder to
filter out random noise fluctuations from the main contract price data. Then,
one-dimensional convolution reduces the dimensionality of the filtered data and
extracts key information. The filtered and dimensionality-reduced price data is
fed into a GANs network, and its output serve as input of a fully connected
network. Through cross-validation, a model is trained to capture features that
precede large price fluctuations. The model predicts the likelihood and
direction of significant price changes in real-time price sequences, placing
trades at moments of high prediction accuracy. Empirical results demonstrate
that using autoencoders and convolution to filter and denoise financial data,
combined with GANs, achieves a certain level of predictive performance,
validating the capabilities of machine learning algorithms to discover
underlying patterns in financial sequences. Keywords - CNN;GANs;
Cryptocurrency; Prediction.",2024-12-24,"Zhuohuan Hu, Richard Yu, Zizhou Zhang, Haoran Zheng, Qianying Liu, Yining Zhou",http://arxiv.org/pdf/2412.18202v4,cs.LG
Leveraging Deep Learning with Multi-Head Attention for Accurate Extraction of Medicine from Handwritten Prescriptions,"Extracting medication names from handwritten doctor prescriptions is
challenging due to the wide variability in handwriting styles and prescription
formats. This paper presents a robust method for extracting medicine names
using a combination of Mask R-CNN and Transformer-based Optical Character
Recognition (TrOCR) with Multi-Head Attention and Positional Embeddings. A
novel dataset, featuring diverse handwritten prescriptions from various regions
of Pakistan, was utilized to fine-tune the model on different handwriting
styles. The Mask R-CNN model segments the prescription images to focus on the
medicinal sections, while the TrOCR model, enhanced by Multi-Head Attention and
Positional Embeddings, transcribes the isolated text. The transcribed text is
then matched against a pre-existing database for accurate identification. The
proposed approach achieved a character error rate (CER) of 1.4% on standard
benchmarks, highlighting its potential as a reliable and efficient tool for
automating medicine name extraction.",2024-12-24,"Usman Ali, Sahil Ranmbail, Muhammad Nadeem, Hamid Ishfaq, Muhammad Umer Ramzan, Waqas Ali",http://arxiv.org/pdf/2412.18199v1,cs.LG
Robustness-aware Automatic Prompt Optimization,"The performance of Large Language Models (LLMs) depends on the quality of
prompts and the semantic and structural integrity of the input data. However,
existing prompt generation methods primarily focus on well-structured input
data, often neglecting the impact of perturbed inputs on prompt effectiveness.
To address this limitation, we propose BATprompt (By Adversarial Training
prompt), a novel method for prompt generation designed to withstand input
perturbations (such as typos in the input). Inspired by adversarial training
techniques, BATprompt demonstrates strong performance on a variety of perturbed
tasks through a two-step process: adversarial perturbation and iterative
optimization on unperturbed input via LLM. Unlike conventional adversarial
attack methods, BATprompt does not need access to model parameters and
gradients. Instead, BATprompt leverages the advanced reasoning, language
understanding and self reflection capabilities of LLMs to simulate gradients,
guiding the generation of adversarial perturbations and optimizing prompt
performance. We evaluate BATprompt on multiple datasets across both language
understanding and generation tasks. The results indicate that BATprompt
outperforms existing prompt generation methods, delivering superior robustness
and performance under diverse perturbation scenarios.",2024-12-24,"Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Hang Gao, Fan Yang, Ruixiang Tang, Yongfeng Zhang",http://arxiv.org/pdf/2412.18196v2,cs.LG
"Learning Sign Language Representation using CNN LSTM, 3DCNN, CNN RNN LSTM and CCN TD","Existing Sign Language Learning applications focus on the demonstration of
the sign in the hope that the student will copy a sign correctly. In these
cases, only a teacher can confirm that the sign was completed correctly, by
reviewing a video captured manually. Sign Language Translation is a widely
explored field in visual recognition. This paper seeks to explore the
algorithms that will allow for real-time, video sign translation, and grading
of sign language accuracy for new sign language users. This required algorithms
capable of recognizing and processing spatial and temporal features. The aim of
this paper is to evaluate and identify the best neural network algorithm that
can facilitate a sign language tuition system of this nature. Modern popular
algorithms including CNN and 3DCNN are compared on a dataset not yet explored,
Trinidad and Tobago Sign Language as well as an American Sign Language dataset.
The 3DCNN algorithm was found to be the best performing neural network
algorithm from these systems with 91% accuracy in the TTSL dataset and 83%
accuracy in the ASL dataset.",2024-12-24,"Nikita Louison, Wayne Goodridge, Koffka Khan",http://arxiv.org/pdf/2412.18187v1,cs.LG
Unified Stochastic Framework for Neural Network Quantization and Pruning,"Quantization and pruning are two essential techniques for compressing neural
networks, yet they are often treated independently, with limited theoretical
analysis connecting them. This paper introduces a unified framework for
post-training quantization and pruning using stochastic path-following
algorithms. Our approach builds on the Stochastic Path Following Quantization
(SPFQ) method, extending its applicability to pruning and low-bit quantization,
including challenging 1-bit regimes. By incorporating a scaling parameter and
generalizing the stochastic operator, the proposed method achieves robust error
correction and yields rigorous theoretical error bounds for both quantization
and pruning as well as their combination.",2024-12-24,"Haoyu Zhang, Rayan Saab",http://arxiv.org/pdf/2412.18184v3,cs.LG
PCM Selector: Penalized Covariate-Mediator Selection Operator for Evaluating Linear Causal Effects,"For a data-generating process for random variables that can be described with
a linear structural equation model, we consider a situation in which (i) a set
of covariates satisfying the back-door criterion cannot be observed or (ii)
such a set can be observed, but standard statistical estimation methods cannot
be applied to estimate causal effects because of
multicollinearity/high-dimensional data problems. We propose a novel two-stage
penalized regression approach, the penalized covariate-mediator selection
operator (PCM Selector), to estimate the causal effects in such scenarios.
Unlike existing penalized regression analyses, when a set of intermediate
variables is available, PCM Selector provides a consistent or less biased
estimator of the causal effect. In addition, PCM Selector provides a variable
selection procedure for intermediate variables to obtain better estimation
accuracy of the causal effects than does the back-door criterion.",2024-12-24,"Hisayoshi Nanmo, Manabu Kuroki",http://arxiv.org/pdf/2412.18180v3,cs.LG
Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization,"Online continual learning (OCL) seeks to learn new tasks from data streams
that appear only once, while retaining knowledge of previously learned tasks.
Most existing methods rely on replay, focusing on enhancing memory retention
through regularization or distillation. However, they often overlook the
adaptability of the model, limiting the ability to learn generalizable and
discriminative features incrementally from online training data. To address
this, we introduce a plug-and-play module, S6MOD, which can be integrated into
most existing methods and directly improve adaptability. Specifically, S6MOD
introduces an extra branch after the backbone, where a mixture of
discretization selectively adjusts parameters in a selective state space model,
enriching selective scan patterns such that the model can adaptively select the
most sensitive discretization method for current dynamics. We further design a
class-conditional routing algorithm for dynamic, uncertainty-based adjustment
and implement a contrastive discretization loss to optimize it. Extensive
experiments combining our module with various models demonstrate that S6MOD
significantly enhances model adaptability, leading to substantial performance
gains and achieving the state-of-the-art results.",2024-12-24,"Sihao Liu, Yibo Yang, Xiaojie Li, David A. Clifton, Bernard Ghanem",http://arxiv.org/pdf/2412.18177v1,cs.LG
MERCURY: A fast and versatile multi-resolution based global emulator of compound climate hazards,"High-impact climate damages are often driven by compounding climate
conditions. For example, elevated heat stress conditions can arise from a
combination of high humidity and temperature. To explore future changes in
compounding hazards under a range of climate scenarios and with large
ensembles, climate emulators can provide light-weight, data-driven complements
to Earth System Models. Yet, only a few existing emulators can jointly emulate
multiple climate variables. In this study, we present the Multi-resolution
EmulatoR for CompoUnd climate Risk analYsis: MERCURY. MERCURY extends
multi-resolution analysis to a spatio-temporal framework for versatile
emulation of multiple variables. MERCURY leverages data-driven, image
compression techniques to generate emulations in a memory-efficient manner.
MERCURY consists of a regional component that represents the monthly, regional
response of a given variable to yearly Global Mean Temperature (GMT) using a
probabilistic regression based additive model, resolving regional
cross-correlations. It then adapts a reverse lifting-scheme operator to jointly
spatially disaggregate regional, monthly values to grid-cell level. We
demonstrate MERCURY's capabilities on representing the humid-heat metric, Wet
Bulb Globe Temperature, as derived from temperature and relative humidity
emulations. The emulated WBGT spatial correlations correspond well to those of
ESMs and the 95% and 97.5% quantiles of WBGT distributions are well captured,
with an average of 5% deviation. MERCURY's setup allows for region-specific
emulations from which one can efficiently ""zoom"" into the grid-cell level
across multiple variables by means of the reverse lifting-scheme operator. This
circumvents the traditional problem of having to emulate complete,
global-fields of climate data and resulting storage requirements.",2024-12-24,"Shruti Nath, Julie Carreau, Kai Kornhuber, Peter Pfleiderer, Carl-Friedrich Schleussner, Philippe Naveau",http://arxiv.org/pdf/2501.04018v1,cs.LG
"Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence","Diffusion models have emerged as powerful tools for generative modeling,
demonstrating exceptional capability in capturing target data distributions
from large datasets. However, fine-tuning these massive models for specific
downstream tasks, constraints, and human preferences remains a critical
challenge. While recent advances have leveraged reinforcement learning
algorithms to tackle this problem, much of the progress has been empirical,
with limited theoretical understanding. To bridge this gap, we propose a
stochastic control framework for fine-tuning diffusion models. Building on
denoising diffusion probabilistic models as the pre-trained reference dynamics,
our approach integrates linear dynamics control with Kullback-Leibler
regularization. We establish the well-posedness and regularity of the
stochastic control problem and develop a policy iteration algorithm (PI-FT) for
numerical solution. We show that PI-FT achieves global convergence at a linear
rate. Unlike existing work that assumes regularities throughout training, we
prove that the control and value sequences generated by the algorithm maintain
the regularity. Additionally, we explore extensions of our framework to
parametric settings and continuous-time formulations.",2024-12-24,"Yinbin Han, Meisam Razaviyayn, Renyuan Xu",http://arxiv.org/pdf/2412.18164v1,cs.LG
Neural Conformal Control for Time Series Forecasting,"We introduce a neural network conformal prediction method for time series
that enhances adaptivity in non-stationary environments. Our approach acts as a
neural controller designed to achieve desired target coverage, leveraging
auxiliary multi-view data with neural network encoders in an end-to-end manner
to further enhance adaptivity. Additionally, our model is designed to enhance
the consistency of prediction intervals in different quantiles by integrating
monotonicity constraints and leverages data from related tasks to boost
few-shot learning performance. Using real-world datasets from epidemics,
electric demand, weather, and others, we empirically demonstrate significant
improvements in coverage and probabilistic accuracy, and find that our method
is the only one that combines good calibration with consistency in prediction
intervals.",2024-12-24,"Ruipu Li, Alexander Rodríguez",http://arxiv.org/pdf/2412.18144v1,cs.LG
An Instrumental Value for Data Production and its Application to Data Pricing,"How much value does a dataset or a data production process have to an agent
who wishes to use the data to assist decision-making? This is a fundamental
question towards understanding the value of data as well as further pricing of
data. This paper develops an approach for capturing the instrumental value of
data production processes, which takes two key factors into account: (a) the
context of the agent's decision-making problem; (b) prior data or information
the agent already possesses. We ''micro-found'' our valuation concepts by
showing how they connect to classic notions of information design and signals
in information economics. When instantiated in the domain of Bayesian linear
regression, our value naturally corresponds to information gain. Based on our
designed data value, we then study a basic monopoly pricing setting with a
buyer looking to purchase from a seller some labeled data of a certain feature
direction in order to improve a Bayesian regression model. We show that when
the seller has the ability to fully customize any data request, she can extract
the first-best revenue (i.e., full surplus) from any population of buyers,
i.e., achieving first-degree price discrimination. If the seller can only sell
data that are derived from an existing data pool, this limits her ability to
customize, and achieving first-best revenue becomes generally impossible.
However, we design a mechanism that achieves seller revenue at most $\log
(\kappa)$ less than the first-best revenue, where $\kappa$ is the condition
number associated with the data matrix. A corollary of this result is that the
seller can extract the first-best revenue in the multi-armed bandits special
case.",2024-12-24,"Rui Ai, Boxiang Lyu, Zhaoran Wang, Zhuoran Yang, Haifeng Xu",http://arxiv.org/pdf/2412.18140v1,cs.LG
What Constitutes a Less Discriminatory Algorithm?,"Disparate impact doctrine offers an important legal apparatus for targeting
discriminatory data-driven algorithmic decisions. A recent body of work has
focused on conceptualizing one particular construct from this doctrine: the
less discriminatory alternative, an alternative policy that reduces disparities
while meeting the same business needs of a status quo or baseline policy.
However, attempts to operationalize this construct in the algorithmic setting
must grapple with some thorny challenges and ambiguities. In this paper, we
attempt to raise and resolve important questions about less discriminatory
algorithms (LDAs). How should we formally define LDAs, and how does this
interact with different societal goals they might serve? And how feasible is it
for firms or plaintiffs to computationally search for candidate LDAs? We find
that formal LDA definitions face fundamental challenges when they attempt to
evaluate and compare predictive models in the absence of held-out data. As a
result, we argue that LDA definitions cannot be purely quantitative, and must
rely on standards of ""reasonableness."" We then identify both mathematical and
computational constraints on firms' ability to efficiently conduct a proactive
search for LDAs, but we provide evidence that these limits are ""weak"" in a
formal sense. By defining LDAs formally, we put forward a framework in which
both firms and plaintiffs can search for alternative models that comport with
societal goals.",2024-12-24,"Benjamin Laufer, Manish Raghavan, Solon Barocas",http://arxiv.org/pdf/2412.18138v2,cs.LG
Learning Randomized Reductions and Program Properties,"The correctness of computations remains a significant challenge in computer
science, with traditional approaches relying on automated testing or formal
verification. Self-testing/correcting programs introduce an alternative
paradigm, allowing a program to verify and correct its own outputs via
randomized reductions, a concept that previously required manual derivation. In
this paper, we present Bitween, a method and tool for automated learning of
randomized (self)-reductions and program properties in numerical programs.
Bitween combines symbolic analysis and machine learning, with a surprising
finding: polynomial-time linear regression, a basic optimization method, is not
only sufficient but also highly effective for deriving complex randomized
self-reductions and program invariants, often outperforming sophisticated
mixed-integer linear programming solvers. We establish a theoretical framework
for learning these reductions and introduce RSR-Bench, a benchmark suite for
evaluating Bitween's capabilities on scientific and machine learning functions.
Our empirical results show that Bitween surpasses state-of-the-art tools in
scalability, stability, and sample efficiency when evaluated on nonlinear
invariant benchmarks like NLA-DigBench. Bitween is open-source as a Python
package and accessible via a web interface that supports C language programs.",2024-12-24,"Ferhat Erata, Orr Paradise, Timos Antonopoulos, ThanhVu Nguyen, Shafi Goldwasser, Ruzica Piskac",http://arxiv.org/pdf/2412.18134v1,cs.LG
Age Optimal Sampling for Unreliable Channels under Unknown Channel Statistics,"In this paper, we study a system in which a sensor forwards status updates to
a receiver through an error-prone channel, while the receiver sends the
transmission results back to the sensor via a reliable channel. Both channels
are subject to random delays. To evaluate the timeliness of the status
information at the receiver, we use the Age of Information (AoI) metric. The
objective is to design a sampling policy that minimizes the expected
time-average AoI, even when the channel statistics (e.g., delay distributions)
are unknown. We first review the threshold structure of the optimal offline
policy under known channel statistics and then reformulate the design of the
online algorithm as a stochastic approximation problem. We propose a
Robbins-Monro algorithm to solve this problem and demonstrate that the optimal
threshold can be approximated almost surely. Moreover, we prove that the
cumulative AoI regret of the online algorithm increases with rate
$\mathcal{O}(\ln K)$, where $K$ is the number of successful transmissions. In
addition, our algorithm is shown to be minimax order optimal, in the sense that
for any online learning algorithm, the cumulative AoI regret up to the $K$-th
successful transmissions grows with the rate at least $\Omega(\ln K)$ in the
worst case delay distribution. Finally, we improve the stability of the
proposed online learning algorithm through a momentum-based stochastic gradient
descent algorithm. Simulation results validate the performance of our proposed
algorithm.",2024-12-24,"Hongyi He, Haoyue Tang, Jiayu Pan, Jintao Wang, Jian Song, Leandros Tassiulas",http://arxiv.org/pdf/2412.18119v2,cs.LG
Tackling the Dynamicity in a Production LLM Serving System with SOTA Optimizations via Hybrid Prefill/Decode/Verify Scheduling on Efficient Meta-kernels,"Meeting growing demands for low latency and cost efficiency in
production-grade large language model (LLM) serving systems requires
integrating advanced optimization techniques. However, dynamic and
unpredictable input-output lengths of LLM, compounded by these optimizations,
exacerbate the issues of workload variability, making it difficult to maintain
high efficiency on AI accelerators, especially DSAs with tile-based programming
models. To address this challenge, we introduce XY-Serve, a versatile, Ascend
native, end-to-end production LLM-serving system. The core idea is an
abstraction mechanism that smooths out the workload variability by decomposing
computations into unified, hardware-friendly, fine-grained meta primitives. For
attention, we propose a meta-kernel that computes the basic pattern of
matmul-softmax-matmul with architectural-aware tile sizes. For GEMM, we
introduce a virtual padding scheme that adapts to dynamic shape changes while
using highly efficient GEMM primitives with assorted fixed tile sizes. XY-Serve
sits harmoniously with vLLM. Experimental results show up to 89% end-to-end
throughput improvement compared with current publicly available baselines on
Ascend NPUs. Additionally, our approach outperforms existing GEMM (average
14.6% faster) and attention (average 21.5% faster) kernels relative to existing
libraries. While the work is Ascend native, we believe the approach can be
readily applicable to SIMT architectures as well.",2024-12-24,"Mingcong Song, Xinru Tang, Fengfan Hou, Jing Li, Wei Wei, Yipeng Ma, Runqiu Xiao, Hongjie Si, Dingcheng Jiang, Shouyi Yin, Yang Hu, Guoping Long",http://arxiv.org/pdf/2412.18106v1,cs.LG
An Attention-based Framework with Multistation Information for Earthquake Early Warnings,"Earthquake early warning systems play crucial roles in reducing the risk of
seismic disasters. Previously, the dominant modeling system was the
single-station models. Such models digest signal data received at a given
station and predict earth-quake parameters, such as the p-phase arrival time,
intensity, and magnitude at that location. Various methods have demonstrated
adequate performance. However, most of these methods present the challenges of
the difficulty of speeding up the alarm time, providing early warning for
distant areas, and considering global information to enhance performance.
Recently, deep learning has significantly impacted many fields, including
seismology. Thus, this paper proposes a deep learning-based framework, called
SENSE, for the intensity prediction task of earthquake early warning systems.
To explicitly consider global information from a regional or national
perspective, the input to SENSE comprises statistics from a set of stations in
a given region or country. The SENSE model is designed to learn the
relationships among the set of input stations and the locality-specific
characteristics of each station. Thus, SENSE is not only expected to provide
more reliable forecasts by considering multistation data but also has the
ability to provide early warnings to distant areas that have not yet received
signals. This study conducted extensive experiments on datasets from Taiwan and
Japan. The results revealed that SENSE can deliver competitive or even better
performances compared with other state-of-the-art methods.",2024-12-24,"Yu-Ming Huang, Kuan-Yu Chen, Wen-Wei Lin, Da-Yi Chen",http://arxiv.org/pdf/2412.18099v1,cs.LG
BRIDGE: Bundle Recommendation via Instruction-Driven Generation,"Bundle recommendation aims to suggest a set of interconnected items to users.
However, diverse interaction types and sparse interaction matrices often pose
challenges for previous approaches in accurately predicting user-bundle
adoptions. Inspired by the distant supervision strategy and generative
paradigm, we propose BRIDGE, a novel framework for bundle recommendation. It
consists of two main components namely the correlation-based item clustering
and the pseudo bundle generation modules. Inspired by the distant supervision
approach, the former is to generate more auxiliary information, e.g.,
instructive item clusters, for training without using external data. This
information is subsequently aggregated with collaborative signals from user
historical interactions to create pseudo `ideal' bundles. This capability
allows BRIDGE to explore all aspects of bundles, rather than being limited to
existing real-world bundles. It effectively bridging the gap between user
imagination and predefined bundles, hence improving the bundle recommendation
performance. Experimental results validate the superiority of our models over
state-of-the-art ranking-based methods across five benchmark datasets.",2024-12-24,"Tuan-Nghia Bui, Huy-Son Nguyen, Cam-Van Nguyen Thi, Hoang-Quynh Le, Duc-Trong Le",http://arxiv.org/pdf/2412.18092v1,cs.LG
Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner,"Motion planning is a crucial component in autonomous driving.
State-of-the-art motion planners are trained on meticulously curated datasets,
which are not only expensive to annotate but also insufficient in capturing
rarely seen critical scenarios. Failing to account for such scenarios poses a
significant risk to motion planners and may lead to incidents during testing.
An intuitive solution is to manually compose such scenarios by programming and
executing a simulator (e.g., CARLA). However, this approach incurs substantial
human costs. Motivated by this, we propose an inexpensive method for generating
diverse critical traffic scenarios to train more robust motion planners. First,
we represent traffic scenarios as scripts, which are then used by the simulator
to generate traffic scenarios. Next, we develop a method that accepts
user-specified text descriptions, which a Large Language Model translates into
scripts using in-context learning. The output scripts are sent to the simulator
that produces the corresponding traffic scenarios. As our method can generate
abundant safety-critical traffic scenarios, we use them as synthetic training
data for motion planners. To demonstrate the value of generated scenarios, we
train existing motion planners on our synthetic data, real-world datasets, and
a combination of both. Our experiments show that motion planners trained with
our data significantly outperform those trained solely on real-world data,
showing the usefulness of our synthetic data and the effectiveness of our data
generation method. Our source code is available at
https://ezharjan.github.io/AutoSceneGen.",2024-12-24,Aizierjiang Aiersilan,http://arxiv.org/pdf/2412.18086v2,cs.LG
Heterogeneous transfer learning for high dimensional regression with feature mismatch,"We consider the problem of transferring knowledge from a source, or proxy,
domain to a new target domain for learning a high-dimensional regression model
with possibly different features. Recently, the statistical properties of
homogeneous transfer learning have been investigated. However, most homogeneous
transfer and multi-task learning methods assume that the target and proxy
domains have the same feature space, limiting their practical applicability. In
applications, target and proxy feature spaces are frequently inherently
different, for example, due to the inability to measure some variables in the
target data-poor environments. Conversely, existing heterogeneous transfer
learning methods do not provide statistical error guarantees, limiting their
utility for scientific discovery. We propose a two-stage method that involves
learning the relationship between the missing and observed features through a
projection step in the proxy data and then solving a joint penalized regression
optimization problem in the target data. We develop an upper bound on the
method's parameter estimation risk and prediction risk, assuming that the proxy
and the target domain parameters are sparsely different. Our results elucidate
how estimation and prediction error depend on the complexity of the model,
sample size, the extent of overlap, and correlation between matched and
mismatched features.",2024-12-24,"Jae Ho Chang, Massimiliano Russo, Subhadeep Paul",http://arxiv.org/pdf/2412.18081v1,cs.LG
MMFactory: A Universal Solution Search Engine for Vision-Language Tasks,"With advances in foundational and vision-language models, and effective
fine-tuning techniques, a large number of both general and special-purpose
models have been developed for a variety of visual tasks. Despite the
flexibility and accessibility of these models, no single model is able to
handle all tasks and/or applications that may be envisioned by potential users.
Recent approaches, such as visual programming and multimodal LLMs with
integrated tools aim to tackle complex visual tasks, by way of program
synthesis. However, such approaches overlook user constraints (e.g.,
performance / computational needs), produce test-time sample-specific solutions
that are difficult to deploy, and, sometimes, require low-level instructions
that maybe beyond the abilities of a naive user. To address these limitations,
we introduce MMFactory, a universal framework that includes model and metrics
routing components, acting like a solution search engine across various
available models. Based on a task description and few sample input-output pairs
and (optionally) resource and/or performance constraints, MMFactory can suggest
a diverse pool of programmatic solutions by instantiating and combining
visio-lingual tools from its model repository. In addition to synthesizing
these solutions, MMFactory also proposes metrics and benchmarks performance /
resource characteristics, allowing users to pick a solution that meets their
unique design constraints. From the technical perspective, we also introduced a
committee-based solution proposer that leverages multi-agent LLM conversation
to generate executable, diverse, universal, and robust solutions for the user.
Experimental results show that MMFactory outperforms existing methods by
delivering state-of-the-art solutions tailored to user problem specifications.
Project page is available at https://davidhalladay.github.io/mmfactory_demo.",2024-12-24,"Wan-Cyuan Fan, Tanzila Rahman, Leonid Sigal",http://arxiv.org/pdf/2412.18072v1,cs.LG
Diverse Concept Proposals for Concept Bottleneck Models,"Concept bottleneck models are interpretable predictive models that are often
used in domains where model trust is a key priority, such as healthcare. They
identify a small number of human-interpretable concepts in the data, which they
then use to make predictions. Learning relevant concepts from data proves to be
a challenging task. The most predictive concepts may not align with expert
intuition, thus, failing interpretability with no recourse. Our proposed
approach identifies a number of predictive concepts that explain the data. By
offering multiple alternative explanations, we allow the human expert to choose
the one that best aligns with their expectation. To demonstrate our method, we
show that it is able discover all possible concept representations on a
synthetic dataset. On EHR data, our model was able to identify 4 out of the 5
pre-defined concepts without supervision.",2024-12-24,"Katrina Brown, Marton Havasi, Finale Doshi-Velez",http://arxiv.org/pdf/2412.18059v1,cs.LG
Beyond Gradient Averaging in Parallel Optimization: Improved Robustness through Gradient Agreement Filtering,"We introduce Gradient Agreement Filtering (GAF) to improve on gradient
averaging in distributed deep learning optimization. Traditional distributed
data-parallel stochastic gradient descent involves averaging gradients of
microbatches to calculate a macrobatch gradient that is then used to update
model parameters. We find that gradients across microbatches are often
orthogonal or negatively correlated, especially in late stages of training,
which leads to memorization of the training set, reducing generalization. In
this paper, we introduce a simple, computationally effective way to reduce
gradient variance by computing the cosine distance between micro-gradients
during training and filtering out conflicting updates prior to averaging. We
improve validation accuracy with significantly smaller microbatch sizes. We
also show this reduces memorizing noisy labels. We demonstrate the
effectiveness of this technique on standard image classification benchmarks
including CIFAR-100 and CIFAR-100N-Fine. We show this technique consistently
outperforms validation accuracy, in some cases by up to 18.2\% compared to
traditional training approaches while reducing the computation required nearly
an order of magnitude because we can now rely on smaller microbatch sizes
without destabilizing training.",2024-12-24,"Francois Chaubard, Duncan Eddy, Mykel J. Kochenderfer",http://arxiv.org/pdf/2412.18052v2,cs.LG
Fair Knowledge Tracing in Second Language Acquisition,"In second-language acquisition, predictive modeling aids educators in
implementing diverse teaching strategies, attracting significant research
attention. However, while model accuracy is widely explored, model fairness
remains under-examined. Model fairness ensures equitable treatment of groups,
preventing unintentional biases based on attributes such as gender, ethnicity,
or economic background. A fair model should produce impartial outcomes that do
not systematically disadvantage any group.
  This study evaluates the fairness of two predictive models using the Duolingo
dataset's en\_es (English learners speaking Spanish), es\_en (Spanish learners
speaking English), and fr\_en (French learners speaking English) tracks. We
analyze: 1. Algorithmic fairness across platforms (iOS, Android, Web). 2.
Algorithmic fairness between developed and developing countries.
  Key findings include: 1. Deep learning outperforms machine learning in
second-language knowledge tracing due to improved accuracy and fairness. 2.
Both models favor mobile users over non-mobile users. 3. Machine learning
exhibits stronger bias against developing countries compared to deep learning.
4. Deep learning strikes a better balance of fairness and accuracy in the
en\_es and es\_en tracks, while machine learning is more suitable for fr\_en.
  This study highlights the importance of addressing fairness in predictive
models to ensure equitable educational strategies across platforms and regions.",2024-12-23,"Weitao Tang, Guanliang Chen, Shuaishuai Zu, Jiangyi Luo",http://arxiv.org/pdf/2412.18048v1,cs.LG
Emoji Retrieval from Gibberish or Garbled Social Media Text: A Novel Methodology and A Case Study,"Emojis are widely used across social media platforms but are often lost in
noisy or garbled text, posing challenges for data analysis and machine
learning. Conventional preprocessing approaches recommend removing such text,
risking the loss of emojis and their contextual meaning. This paper proposes a
three-step reverse-engineering methodology to retrieve emojis from garbled text
in social media posts. The methodology also identifies reasons for the
generation of such text during social media data mining. To evaluate its
effectiveness, the approach was applied to 509,248 Tweets about the Mpox
outbreak, a dataset referenced in about 30 prior works that failed to retrieve
emojis from garbled text. Our method retrieved 157,748 emojis from 76,914
Tweets. Improvements in text readability and coherence were demonstrated
through metrics such as Flesch Reading Ease, Flesch-Kincaid Grade Level,
Coleman-Liau Index, Automated Readability Index, Dale-Chall Readability Score,
Text Standard, and Reading Time. Additionally, the frequency of individual
emojis and their patterns of usage in these Tweets were analyzed, and the
results are presented.",2024-12-23,"Shuqi Cui, Nirmalya Thakur, Audrey Poon",http://arxiv.org/pdf/2412.18046v1,cs.LG
An information theoretic limit to data amplification,"In recent years generative artificial intelligence has been used to create
data to support science analysis. For example, Generative Adversarial Networks
(GANs) have been trained using Monte Carlo simulated input and then used to
generate data for the same problem. This has the advantage that a GAN creates
data in a significantly reduced computing time. N training events for a GAN can
result in GN generated events with the gain factor, G, being more than one.
This appears to violate the principle that one cannot get information for free.
This is not the only way to amplify data so this process will be referred to as
data amplification which is studied using information theoretic concepts. It is
shown that a gain of greater than one is possible whilst keeping the
information content of the data unchanged. This leads to a mathematical bound
which only depends on the number of generated and training events. This study
determines conditions on both the underlying and reconstructed probability
distributions to ensure this bound. In particular, the resolution of variables
in amplified data is not improved by the process but the increase in sample
size can still improve statistical significance. The bound is confirmed using
computer simulation and analysis of GAN generated data from the literature.",2024-12-23,"S. J. Watts, L. Crow",http://arxiv.org/pdf/2412.18041v1,cs.LG
Theoretical Constraints on the Expressive Power of $\mathsf{RoPE}$-based Tensor Attention Transformers,"Tensor Attention extends traditional attention mechanisms by capturing
high-order correlations across multiple modalities, addressing the limitations
of classical matrix-based attention. Meanwhile, Rotary Position Embedding
($\mathsf{RoPE}$) has shown superior performance in encoding positional
information in long-context scenarios, significantly enhancing transformer
models' expressiveness. Despite these empirical successes, the theoretical
limitations of these technologies remain underexplored. In this study, we
analyze the circuit complexity of Tensor Attention and $\mathsf{RoPE}$-based
Tensor Attention, showing that with polynomial precision, constant-depth
layers, and linear or sublinear hidden dimension, they cannot solve fixed
membership problems or $(A_{F,r})^*$ closure problems, under the assumption
that $\mathsf{TC}^0 \neq \mathsf{NC}^1$. These findings highlight a gap between
the empirical performance and theoretical constraints of Tensor Attention and
$\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that
could guide the development of more theoretically grounded approaches to
Transformer model design and scaling.",2024-12-23,"Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Mingda Wan",http://arxiv.org/pdf/2412.18040v1,cs.LG
Moving boundaries: An appreciation of John Hopfield,"The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey
Hinton, ""for foundational discoveries and inventions that enable machine
learning with artificial neural networks."" As noted by the Nobel committee,
their work moved the boundaries of physics. This is a brief reflection on
Hopfield's work, its implications for the emergence of biological physics as a
part of physics, the path from his early papers to the modern revolution in
artificial intelligence, and prospects for the future.",2024-12-23,William Bialek,http://arxiv.org/pdf/2412.18030v1,cs.LG
Multimodal Learning with Uncertainty Quantification based on Discounted Belief Fusion,"Multimodal AI models are increasingly used in fields like healthcare,
finance, and autonomous driving, where information is drawn from multiple
sources or modalities such as images, texts, audios, videos. However,
effectively managing uncertainty - arising from noise, insufficient evidence,
or conflicts between modalities - is crucial for reliable decision-making.
Current uncertainty-aware machine learning methods leveraging, for example,
evidence averaging, or evidence accumulation underestimate uncertainties in
high-conflict scenarios. Moreover, the state-of-the-art evidence averaging
strategy is not order invariant and fails to scale to multiple modalities. To
address these challenges, we propose a novel multimodal learning method with
order-invariant evidence fusion and introduce a conflict-based discounting
mechanism that reallocates uncertain mass when unreliable modalities are
detected. We provide both theoretical analysis and experimental validation,
demonstrating that unlike the previous work, the proposed approach effectively
distinguishes between conflicting and non-conflicting samples based on the
provided uncertainty estimates, and outperforms the previous models in
uncertainty-based conflict detection.",2024-12-23,"Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier",http://arxiv.org/pdf/2412.18024v2,cs.LG
Combinatorial Regularity for Relatively Perfect Discrete Morse Gradient Vector Fields of ReLU Neural Networks,"One common function class in machine learning is the class of ReLU neural
networks. ReLU neural networks induce a piecewise linear decomposition of their
input space called the canonical polyhedral complex. It has previously been
established that it is decidable whether a ReLU neural network is piecewise
linear Morse. In order to expand computational tools for analyzing the
topological properties of ReLU neural networks, and to harness the strengths of
discrete Morse theory, we introduce a schematic for translating between a given
piecewise linear Morse function (e.g. parameters of a ReLU neural network) on a
canonical polyhedral complex and a compatible (``relatively perfect"") discrete
Morse function on the same complex. Our approach is constructive, producing an
algorithm that can be used to determine if a given vertex in a canonical
polyhedral complex corresponds to a piecewise linear Morse critical point.
Furthermore we provide an algorithm for constructing a consistent discrete
Morse pairing on cells in the canonical polyhedral complex which contain this
vertex. We additionally provide some new realizability results with respect to
sublevel set topology in the case of shallow ReLU neural networks.",2024-12-23,"Robyn Brooks, Marissa Masden",http://arxiv.org/pdf/2412.18005v2,cs.LG
Shifted Composition III: Local Error Framework for KL Divergence,"Coupling arguments are a central tool for bounding the deviation between two
stochastic processes, but traditionally have been limited to Wasserstein
metrics. In this paper, we apply the shifted composition rule--an
information-theoretic principle introduced in our earlier work--in order to
adapt coupling arguments to the Kullback-Leibler (KL) divergence. Our framework
combine the strengths of two previously disparate approaches: local error
analysis and Girsanov's theorem. Akin to the former, it yields tight bounds by
incorporating the so-called weak error, and is user-friendly in that it only
requires easily verified local assumptions; and akin to the latter, it yields
KL divergence guarantees and applies beyond Wasserstein contractivity.
  We apply this framework to the problem of sampling from a target distribution
$\pi$. Here, the two stochastic processes are the Langevin diffusion and an
algorithmic discretization thereof. Our framework provides a unified analysis
when $\pi$ is assumed to be strongly log-concave (SLC), weakly log-concave
(WLC), or to satisfy a log-Sobolev inequality (LSI). Among other results, this
yields KL guarantees for the randomized midpoint discretization of the Langevin
diffusion. Notably, our result: (1) yields the optimal $\tilde O(\sqrt
d/\epsilon)$ rate in the SLC and LSI settings; (2) is the first result to hold
beyond the 2-Wasserstein metric in the SLC setting; and (3) is the first result
to hold in \emph{any} metric in the WLC and LSI settings.",2024-12-23,"Jason M. Altschuler, Sinho Chewi",http://arxiv.org/pdf/2412.17997v1,cs.LG
Time Series Feature Redundancy Paradox: An Empirical Study Based on Mortgage Default Prediction,"With the widespread application of machine learning in financial risk
management, conventional wisdom suggests that longer training periods and more
feature variables contribute to improved model performance. This paper,
focusing on mortgage default prediction, empirically discovers a phenomenon
that contradicts traditional knowledge: in time series prediction, increased
training data timespan and additional non-critical features actually lead to
significant deterioration in prediction effectiveness. Using Fannie Mae's
mortgage data, the study compares predictive performance across different time
window lengths (2012-2022) and feature combinations, revealing that shorter
time windows (such as single-year periods) paired with carefully selected key
features yield superior prediction results. The experimental results indicate
that extended time spans may introduce noise from historical data and outdated
market patterns, while excessive non-critical features interfere with the
model's learning of core default factors. This research not only challenges the
traditional ""more is better"" approach in data modeling but also provides new
insights and practical guidance for feature selection and time window
optimization in financial risk prediction.",2024-12-23,"Chengyue Huang, Yahe Yang",http://arxiv.org/pdf/2501.00034v1,cs.LG
Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models,"Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics,
requiring the computation of collision-free paths for multiple agents moving
from their respective start to goal positions. Coordinating multiple agents in
a shared environment poses significant challenges, especially in continuous
spaces where traditional optimization algorithms struggle with scalability.
Moreover, these algorithms often depend on discretized representations of the
environment, which can be impractical in image-based or high-dimensional
settings. Recently, diffusion models have shown promise in single-agent path
planning, capturing complex trajectory distributions and generating smooth
paths that navigate continuous, high-dimensional spaces. However, directly
extending diffusion models to MAPF introduces new challenges since these models
struggle to ensure constraint feasibility, such as inter-agent collision
avoidance. To overcome this limitation, this work proposes a novel approach
that integrates constrained optimization with diffusion models for MAPF in
continuous spaces. This unique combination directly produces feasible
multi-agent trajectories that respect collision avoidance and kinematic
constraints. The effectiveness of our approach is demonstrated across various
challenging simulated scenarios of varying dimensionality.",2024-12-23,"Jinhao Liang, Jacob K. Christopher, Sven Koenig, Ferdinando Fioretto",http://arxiv.org/pdf/2412.17993v1,cs.LG
Data-driven Modeling of Parameterized Nonlinear Fluid Dynamical Systems with a Dynamics-embedded Conditional Generative Adversarial Network,"This work presents a data-driven solution to accurately predict parameterized
nonlinear fluid dynamical systems using a dynamics-generator conditional GAN
(Dyn-cGAN) as a surrogate model. The Dyn-cGAN includes a dynamics block within
a modified conditional GAN, enabling the simultaneous identification of
temporal dynamics and their dependence on system parameters. The learned
Dyn-cGAN model takes into account the system parameters to predict the flow
fields of the system accurately. We evaluate the effectiveness and limitations
of the developed Dyn-cGAN through numerical studies of various parameterized
nonlinear fluid dynamical systems, including flow over a cylinder and a 2-D
cavity problem, with different Reynolds numbers. Furthermore, we examine how
Reynolds number affects the accuracy of the predictions for both case studies.
Additionally, we investigate the impact of the number of time steps involved in
the process of dynamics block training on the accuracy of predictions, and we
find that an optimal value exists based on errors and mutual information
relative to the ground truth.",2024-12-23,"Abdolvahhab Rostamijavanani, Shanwu Li, Yongchao Yang",http://arxiv.org/pdf/2412.17978v1,cs.LG
"Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks","Sickle cell anemia, which is characterized by abnormal erythrocyte
morphology, can be detected using microscopic images. Computational techniques
in medicine enhance the diagnosis and treatment efficiency. However, many
computational techniques, particularly those based on Convolutional Neural
Networks (CNNs), require high resources and time for training, highlighting the
research opportunities in methods with low computational overhead. In this
paper, we propose a novel approach combining conventional classifiers,
segmented images, and CNNs for the automated classification of sickle cell
disease. We evaluated the impact of segmented images on classification,
providing insight into deep learning integration. Our results demonstrate that
using segmented images and CNN features with an SVM achieves an accuracy of
96.80%. This finding is relevant for computationally efficient scenarios,
paving the way for future research and advancements in medical-image analysis.",2024-12-23,"Victor Júnio Alcântara Cardoso, Rodrigo Moreira, João Fernando Mari, Larissa Ferreira Rodrigues Moreira",http://arxiv.org/pdf/2412.17975v1,cs.LG
CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models,"Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.",2024-12-23,"Ruibo Tu, Hedvig Kjellström, Gustav Eje Henter, Cheng Zhang",http://arxiv.org/pdf/2412.17970v1,cs.LG
tuGEMM: Area-Power-Efficient Temporal Unary GEMM Architecture for Low-Precision Edge AI,"General matrix multiplication (GEMM) is a ubiquitous computing
kernel/algorithm for data processing in diverse applications, including
artificial intelligence (AI) and deep learning (DL). Recent shift towards edge
computing has inspired GEMM architectures based on unary computing, which are
predominantly stochastic and rate-coded systems. This paper proposes a novel
GEMM architecture based on temporal-coding, called tuGEMM, that performs exact
computation. We introduce two variants of tuGEMM, serial and parallel, with
distinct area/power-latency trade-offs. Post-synthesis Power-Performance-Area
(PPA) in 45 nm CMOS are reported for 2-bit, 4-bit, and 8-bit computations. The
designs illustrate significant advantages in area-power efficiency over
state-of-the-art stochastic unary systems especially at low precisions, e.g.
incurring just 0.03 mm^2 and 9 mW for 4 bits, and 0.01 mm^2 and 4 mW for 2
bits. This makes tuGEMM ideal for power constrained mobile and edge devices
performing always-on real-time sensory processing.",2024-12-23,"Harideep Nair, Prabhu Vellaisamy, Albert Chen, Joseph Finn, Anna Li, Manav Trivedi, John Paul Shen",http://arxiv.org/pdf/2412.17966v1,cs.LG
Extending Graph Condensation to Multi-Label Datasets: A Benchmark Study,"As graph data grows increasingly complicate, training graph neural networks
(GNNs) on large-scale datasets presents significant challenges, including
computational resource constraints, data redundancy, and transmission
inefficiencies. While existing graph condensation techniques have shown promise
in addressing these issues, they are predominantly designed for single-label
datasets, where each node is associated with a single class label. However,
many real-world applications, such as social network analysis and
bioinformatics, involve multi-label graph datasets, where one node can have
various related labels. To deal with this problem, we extends traditional graph
condensation approaches to accommodate multi-label datasets by introducing
modifications to synthetic dataset initialization and condensing optimization.
Through experiments on eight real-world multi-label graph datasets, we prove
the effectiveness of our method. In experiment, the GCond framework, combined
with K-Center initialization and binary cross-entropy loss (BCELoss), achieves
best performance in general. This benchmark for multi-label graph condensation
not only enhances the scalability and efficiency of GNNs for multi-label graph
data, but also offering substantial benefits for diverse real-world
applications.",2024-12-23,"Liangliang Zhang, Haoran Bao, Yao Ma",http://arxiv.org/pdf/2412.17961v1,cs.LG
ArchComplete: Autoregressive 3D Architectural Design Generation with Hierarchical Diffusion-Based Upsampling,"Recent advances in 3D generative models have shown promising results but
often fall short in capturing the complexity of architectural geometries and
topologies and fine geometric details at high resolutions. To tackle this, we
present ArchComplete, a two-stage voxel-based 3D generative pipeline consisting
of a vector-quantised model, whose composition is modelled with an
autoregressive transformer for generating coarse shapes, followed by a
hierarchical upsampling strategy for further enrichment with fine structures
and details. Key to our pipeline is (i) learning a contextually rich codebook
of local patch embeddings, optimised alongside a 2.5D perceptual loss that
captures global spatial correspondence of projections onto three axis-aligned
orthogonal planes, and (ii) redefining upsampling as a set of conditional
diffusion models learning from a hierarchy of randomly cropped coarse-to-fine
local volumetric patches. Trained on our introduced dataset of 3D house models
with fully modelled exterior and interior, ArchComplete autoregressively
generates models at the resolution of $64^{3}$ and progressively refines them
up to $512^{3}$, with voxel sizes as small as $ \approx 9\text{cm}$.
ArchComplete solves a variety of tasks, including genetic interpolation and
variation, unconditional synthesis, shape and plan-drawing completion, as well
as geometric detailisation, while achieving state-of-the-art performance in
quality, diversity, and computational efficiency.",2024-12-23,"S. Rasoulzadeh, M. Bank, I. Kovacic, K. Schinegger, S. Rutzinger, M. Wimmer",http://arxiv.org/pdf/2412.17957v2,cs.LG
Study of the Proper NNUE Dataset,"NNUE (Efficiently Updatable Neural Networks) has revolutionized chess engine
development, with nearly all top engines adopting NNUE models to maintain
competitive performance. A key challenge in NNUE training is the creation of
high-quality datasets, particularly in complex domains like chess, where
tactical and strategic evaluations are essential. However, methods for
constructing effective datasets remain poorly understood and under-documented.
In this paper, we propose an algorithm for generating and filtering datasets
composed of ""quiet"" positions that are stable and free from tactical
volatility. Our approach provides a clear methodology for dataset creation,
which can be replicated and generalized across various evaluation functions.
Testing demonstrates significant improvements in engine performance, confirming
the effectiveness of our method.",2024-12-23,"Daniel Tan, Neftali Watkinson Medina",http://arxiv.org/pdf/2412.17948v1,cs.LG
VITRO: Vocabulary Inversion for Time-series Representation Optimization,"Although LLMs have demonstrated remarkable capabilities in processing and
generating textual data, their pre-trained vocabularies are ill-suited for
capturing the nuanced temporal dynamics and patterns inherent in time series.
The discrete, symbolic nature of natural language tokens, which these
vocabularies are designed to represent, does not align well with the
continuous, numerical nature of time series data. To address this fundamental
limitation, we propose VITRO. Our method adapts textual inversion optimization
from the vision-language domain in order to learn a new time series per-dataset
vocabulary that bridges the gap between the discrete, semantic nature of
natural language and the continuous, numerical nature of time series data. We
show that learnable time series-specific pseudo-word embeddings represent time
series data better than existing general language model vocabularies, with
VITRO-enhanced methods achieving state-of-the-art performance in long-term
forecasting across most datasets.",2024-12-23,"Filippos Bellos, Nam H. Nguyen, Jason J. Corso",http://arxiv.org/pdf/2412.17921v1,cs.LG
Causal Composition Diffusion Model for Closed-loop Traffic Generation,"Simulation is critical for safety evaluation in autonomous driving,
particularly in capturing complex interactive behaviors. However, generating
realistic and controllable traffic scenarios in long-tail situations remains a
significant challenge. Existing generative models suffer from the conflicting
objective between user-defined controllability and realism constraints, which
is amplified in safety-critical contexts. In this work, we introduce the Causal
Compositional Diffusion Model (CCDiff), a structure-guided diffusion framework
to address these challenges. We first formulate the learning of controllable
and realistic closed-loop simulation as a constrained optimization problem.
Then, CCDiff maximizes controllability while adhering to realism by
automatically identifying and injecting causal structures directly into the
diffusion process, providing structured guidance to enhance both realism and
controllability. Through rigorous evaluations on benchmark datasets and in a
closed-loop simulator, CCDiff demonstrates substantial gains over
state-of-the-art approaches in generating realistic and user-preferred
trajectories. Our results show CCDiff's effectiveness in extracting and
leveraging causal structures, showing improved closed-loop performance based on
key metrics such as collision rate, off-road rate, FDE, and comfort.",2024-12-23,"Haohong Lin, Xin Huang, Tung Phan-Minh, David S. Hayden, Huan Zhang, Ding Zhao, Siddhartha Srinivasa, Eric M. Wolff, Hongge Chen",http://arxiv.org/pdf/2412.17920v2,cs.LG
Data-Driven Priors in the Maximum Entropy on the Mean Method for Linear Inverse Problems,"We establish the theoretical framework for implementing the maximumn entropy
on the mean (MEM) method for linear inverse problems in the setting of
approximate (data-driven) priors. We prove a.s. convergence for empirical means
and further develop general estimates for the difference between the MEM
solutions with different priors $\mu$ and $\nu$ based upon the epigraphical
distance between their respective log-moment generating functions. These
estimates allow us to establish a rate of convergence in expectation for
empirical means. We illustrate our results with denoising on MNIST and
Fashion-MNIST data sets.",2024-12-23,"Matthew King-Roskamp, Rustum Choksi, Tim Hoheisel",http://arxiv.org/pdf/2412.17916v1,cs.LG
A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON,"""A common decision made by people, whether healthy or with health conditions,
is choosing meals like breakfast, lunch, and dinner, comprising combinations of
foods for appetizer, main course, side dishes, desserts, and beverages. Often,
this decision involves tradeoffs between nutritious choices (e.g., salt and
sugar levels, nutrition content) and convenience (e.g., cost and accessibility,
cuisine type, food source type). We present a data-driven solution for meal
recommendations that considers customizable meal configurations and time
horizons. This solution balances user preferences while accounting for food
constituents and cooking processes. Our contributions include introducing
goodness measures, a recipe conversion method from text to the recently
introduced multimodal rich recipe representation (R3) format, learning methods
using contextual bandits that show promising preliminary results, and the
prototype, usage-inspired, BEACON system.""",2024-12-23,"Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Nitin Gupta, Zach Abdulrahman, Andrew Davison, Biplav Srivastava",http://arxiv.org/pdf/2412.17910v1,cs.LG
"Trading Devil RL: Backdoor attack via Stock market, Bayesian Optimization and Reinforcement Learning","With the rapid development of generative artificial intelligence,
particularly large language models a number of sub-fields of deep learning have
made significant progress and are now very useful in everyday applications. For
example,financial institutions simulate a wide range of scenarios for various
models created by their research teams using reinforcement learning, both
before production and after regular operations. In this work, we propose a
backdoor attack that focuses solely on data poisoning and a method of detection
by dynamic systems and statistical analysis of the distribution of data. This
particular backdoor attack is classified as an attack without prior
consideration or trigger, and we name it FinanceLLMsBackRL. Our aim is to
examine the potential effects of large language models that use reinforcement
learning systems for text production or speech recognition, finance, physics,
or the ecosystem of contemporary artificial intelligence models.",2024-12-23,Orson Mengara,http://arxiv.org/pdf/2412.17908v3,cs.LG
"A Multimodal Emotion Recognition System: Integrating Facial Expressions, Body Movement, Speech, and Spoken Language","Traditional psychological evaluations rely heavily on human observation and
interpretation, which are prone to subjectivity, bias, fatigue, and
inconsistency. To address these limitations, this work presents a multimodal
emotion recognition system that provides a standardised, objective, and
data-driven tool to support evaluators, such as psychologists, psychiatrists,
and clinicians. The system integrates recognition of facial expressions,
speech, spoken language, and body movement analysis to capture subtle emotional
cues that are often overlooked in human evaluations. By combining these
modalities, the system provides more robust and comprehensive emotional state
assessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in
a simulated real-world condition demonstrates the system's potential to provide
reliable emotional insights to improve the diagnostic accuracy. This work
highlights the promise of automated multimodal analysis as a valuable
complement to traditional psychological evaluation practices, with applications
in clinical and therapeutic settings.",2024-12-23,Kris Kraack,http://arxiv.org/pdf/2412.17907v1,cs.LG
Token Statistics Transformer: Linear-Time Attention via Variational Rate Reduction,"The attention operator is arguably the key distinguishing factor of
transformer architectures, which have demonstrated state-of-the-art performance
on a variety of tasks. However, transformer attention operators often impose a
significant computational burden, with the computational complexity scaling
quadratically with the number of tokens. In this work, we propose a novel
transformer attention operator whose computational complexity scales linearly
with the number of tokens. We derive our network architecture by extending
prior work which has shown that a transformer style architecture naturally
arises by ""white-box"" architecture design, where each layer of the network is
designed to implement an incremental optimization step of a maximal coding rate
reduction objective (MCR$^2$). Specifically, we derive a novel variational form
of the MCR$^2$ objective and show that the architecture that results from
unrolled gradient descent of this variational objective leads to a new
attention module called Token Statistics Self-Attention (TSSA). TSSA has linear
computational and memory complexity and radically departs from the typical
attention architecture that computes pairwise similarities between tokens.
Experiments on vision, language, and long sequence tasks show that simply
swapping TSSA for standard self-attention, which we refer to as the Token
Statistics Transformer (ToST), achieves competitive performance with
conventional transformers while being significantly more computationally
efficient and interpretable. Our results also somewhat call into question the
conventional wisdom that pairwise similarity style attention mechanisms are
critical to the success of transformer architectures. Code will be available at
https://github.com/RobinWu218/ToST.",2024-12-23,"Ziyang Wu, Tianjiao Ding, Yifu Lu, Druv Pai, Jingyuan Zhang, Weida Wang, Yaodong Yu, Yi Ma, Benjamin D. Haeffele",http://arxiv.org/pdf/2412.17810v1,cs.LG
Examining Imbalance Effects on Performance and Demographic Fairness of Clinical Language Models,"Data imbalance is a fundamental challenge in applying language models to
biomedical applications, particularly in ICD code prediction tasks where label
and demographic distributions are uneven. While state-of-the-art language
models have been increasingly adopted in biomedical tasks, few studies have
systematically examined how data imbalance affects model performance and
fairness across demographic groups. This study fills the gap by statistically
probing the relationship between data imbalance and model performance in ICD
code prediction. We analyze imbalances in a standard benchmark data across
gender, age, ethnicity, and social determinants of health by state-of-the-art
biomedical language models. By deploying diverse performance metrics and
statistical analyses, we explore the influence of data imbalance on performance
variations and demographic fairness. Our study shows that data imbalance
significantly impacts model performance and fairness, but feature similarity to
the majority class may be a more critical factor. We believe this study
provides valuable insights for developing more equitable and robust language
models in healthcare applications.",2024-12-23,"Precious Jones, Weisi Liu, I-Chan Huang, Xiaolei Huang",http://arxiv.org/pdf/2412.17803v2,cs.LG
Observation Interference in Partially Observable Assistance Games,"We study partially observable assistance games (POAGs), a model of the
human-AI value alignment problem which allows the human and the AI assistant to
have partial observations. Motivated by concerns of AI deception, we study a
qualitatively new phenomenon made possible by partial observability: would an
AI assistant ever have an incentive to interfere with the human's observations?
First, we prove that sometimes an optimal assistant must take
observation-interfering actions, even when the human is playing optimally, and
even when there are otherwise-equivalent actions available that do not
interfere with observations. Though this result seems to contradict the classic
theorem from single-agent decision making that the value of perfect information
is nonnegative, we resolve this seeming contradiction by developing a notion of
interference defined on entire policies. This can be viewed as an extension of
the classic result that the value of perfect information is nonnegative into
the cooperative multiagent setting. Second, we prove that if the human is
simply making decisions based on their immediate outcomes, the assistant might
need to interfere with observations as a way to query the human's preferences.
We show that this incentive for interference goes away if the human is playing
optimally, or if we introduce a communication channel for the human to
communicate their preferences to the assistant. Third, we show that if the
human acts according to the Boltzmann model of irrationality, this can create
an incentive for the assistant to interfere with observations. Finally, we use
an experimental model to analyze tradeoffs faced by the AI assistant in
practice when considering whether or not to take observation-interfering
actions.",2024-12-23,"Scott Emmons, Caspar Oesterheld, Vincent Conitzer, Stuart Russell",http://arxiv.org/pdf/2412.17797v1,cs.LG
"Memory makes computation universal, remember?","Recent breakthroughs in AI capability have been attributed to increasingly
sophisticated architectures and alignment techniques, but a simpler principle
may explain these advances: memory makes computation universal. Memory enables
universal computation through two fundamental capabilities: recursive state
maintenance and reliable history access. We formally prove these requirements
are both necessary and sufficient for universal computation. This principle
manifests across scales, from cellular computation to neural networks to
language models. Complex behavior emerges not from sophisticated processing
units but from maintaining and accessing state across time. We demonstrate how
parallel systems like neural networks achieve universal computation despite
limitations in their basic units by maintaining state across iterations. This
theoretical framework reveals a universal pattern: computational advances
consistently emerge from enhanced abilities to maintain and access state rather
than from more complex basic operations. Our analysis unifies understanding of
computation across biological systems, artificial intelligence, and human
cognition, reminding us that humanity's own computational capabilities have
evolved in step with our technical ability to remember through oral traditions,
writing, and now computing.",2024-12-23,Erik Garrison,http://arxiv.org/pdf/2412.17794v1,cs.LG
From KAN to GR-KAN: Advancing Speech Enhancement with KAN-Based Methodology,"Deep neural network (DNN)-based speech enhancement (SE) usually uses
conventional activation functions, which lack the expressiveness to capture
complex multiscale structures needed for high-fidelity SE. Group-Rational KAN
(GR-KAN), a variant of Kolmogorov-Arnold Networks (KAN), retains KAN's
expressiveness while improving scalability on complex tasks. We adapt GR-KAN to
existing DNN-based SE by replacing dense layers with GR-KAN layers in the
time-frequency (T-F) domain MP-SENet and adapting GR-KAN's activations into the
1D CNN layers in the time-domain Demucs. Results on Voicebank-DEMAND show that
GR-KAN requires up to 4x fewer parameters while improving PESQ by up to 0.1. In
contrast, KAN, facing scalability issues, outperforms MLP on a small-scale
signal modeling task but fails to improve MP-SENet. We demonstrate the first
successful use of KAN-based methods for consistent improvement in both time-
and SoTA TF-domain SE, establishing GR-KAN as a promising alternative for SE.",2024-12-23,"Haoyang Li, Yuchen Hu, Chen Chen, Sabato Marco Siniscalchi, Songting Liu, Eng Siong Chng",http://arxiv.org/pdf/2412.17778v2,cs.LG
Towards structure-preserving quantum encodings,"Harnessing the potential computational advantage of quantum computers for
machine learning tasks relies on the uploading of classical data onto quantum
computers through what are commonly referred to as quantum encodings. The
choice of such encodings may vary substantially from one task to another, and
there exist only a few cases where structure has provided insight into their
design and implementation, such as symmetry in geometric quantum learning.
Here, we propose the perspective that category theory offers a natural
mathematical framework for analyzing encodings that respect structure inherent
in datasets and learning tasks. We illustrate this with pedagogical examples,
which include geometric quantum machine learning, quantum metric learning,
topological data analysis, and more. Moreover, our perspective provides a
language in which to ask meaningful and mathematically precise questions for
the design of quantum encodings and circuits for quantum machine learning
tasks.",2024-12-23,"Arthur J. Parzygnat, Tai-Danae Bradley, Andrew Vlasic, Anh Pham",http://arxiv.org/pdf/2412.17772v1,cs.LG
ResearchTown: Simulator of Human Research Community,"Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.",2024-12-23,"Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You",http://arxiv.org/pdf/2412.17767v1,cs.LG
HyperQ-Opt: Q-learning for Hyperparameter Optimization,"Hyperparameter optimization (HPO) is critical for enhancing the performance
of machine learning models, yet it often involves a computationally intensive
search across a large parameter space. Traditional approaches such as Grid
Search and Random Search suffer from inefficiency and limited scalability,
while surrogate models like Sequential Model-based Bayesian Optimization (SMBO)
rely heavily on heuristic predictions that can lead to suboptimal results. This
paper presents a novel perspective on HPO by formulating it as a sequential
decision-making problem and leveraging Q-learning, a reinforcement learning
technique, to optimize hyperparameters. The study explores the works of H.S.
Jomaa et al. and Qi et al., which model HPO as a Markov Decision Process (MDP)
and utilize Q-learning to iteratively refine hyperparameter settings. The
approaches are evaluated for their ability to find optimal or near-optimal
configurations within a limited number of trials, demonstrating the potential
of reinforcement learning to outperform conventional methods. Additionally,
this paper identifies research gaps in existing formulations, including the
limitations of discrete search spaces and reliance on heuristic policies, and
suggests avenues for future exploration. By shifting the paradigm toward
policy-based optimization, this work contributes to advancing HPO methods for
scalable and efficient machine learning applications.",2024-12-23,Md. Tarek Hasan,http://arxiv.org/pdf/2412.17765v1,cs.LG
The Superposition of Diffusion Models Using the Itô Density Estimator,"The Cambrian explosion of easily accessible pre-trained diffusion models
suggests a demand for methods that combine multiple different pre-trained
diffusion models without incurring the significant computational burden of
re-training a larger combined model. In this paper, we cast the problem of
combining multiple pre-trained diffusion models at the generation stage under a
novel proposed framework termed superposition. Theoretically, we derive
superposition from rigorous first principles stemming from the celebrated
continuity equation and design two novel algorithms tailor-made for combining
diffusion models in SuperDiff. SuperDiff leverages a new scalable It\^o density
estimator for the log likelihood of the diffusion SDE which incurs no
additional overhead compared to the well-known Hutchinson's estimator needed
for divergence calculations. We demonstrate that SuperDiff is scalable to large
pre-trained diffusion models as superposition is performed solely through
composition during inference, and also enjoys painless implementation as it
combines different pre-trained vector fields through an automated re-weighting
scheme. Notably, we show that SuperDiff is efficient during inference time, and
mimics traditional composition operators such as the logical OR and the logical
AND. We empirically demonstrate the utility of using SuperDiff for generating
more diverse images on CIFAR-10, more faithful prompt conditioned image editing
using Stable Diffusion, as well as improved conditional molecule generation and
unconditional de novo structure design of proteins.
https://github.com/necludov/super-diffusion",2024-12-23,"Marta Skreta, Lazar Atanackovic, Avishek Joey Bose, Alexander Tong, Kirill Neklyudov",http://arxiv.org/pdf/2412.17762v2,cs.LG
"Survey of Large Multimodal Model Datasets, Application Categories and Taxonomy","Multimodal learning, a rapidly evolving field in artificial intelligence,
seeks to construct more versatile and robust systems by integrating and
analyzing diverse types of data, including text, images, audio, and video.
Inspired by the human ability to assimilate information through many senses,
this method enables applications such as text-to-video conversion, visual
question answering, and image captioning. Recent developments in datasets that
support multimodal language models (MLLMs) are highlighted in this overview.
Large-scale multimodal datasets are essential because they allow for thorough
testing and training of these models. With an emphasis on their contributions
to the discipline, the study examines a variety of datasets, including those
for training, domain-specific tasks, and real-world applications. It also
emphasizes how crucial benchmark datasets are for assessing models' performance
in a range of scenarios, scalability, and applicability. Since multimodal
learning is always changing, overcoming these obstacles will help AI research
and applications reach new heights.",2024-12-23,"Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Bhargava Kumar, Amit Agarwal, Ishan Banerjee, Srikant Panda, Tejaswini Kumar",http://arxiv.org/pdf/2412.17759v1,cs.LG
Minimax Optimal Simple Regret in Two-Armed Best-Arm Identification,"This study investigates an asymptotically minimax optimal algorithm in the
two-armed fixed-budget best-arm identification (BAI) problem. Given two
treatment arms, the objective is to identify the arm with the highest expected
outcome through an adaptive experiment. We focus on the Neyman allocation,
where treatment arms are allocated following the ratio of their outcome
standard deviations. Our primary contribution is to prove the minimax
optimality of the Neyman allocation for the simple regret, defined as the
difference between the expected outcomes of the true best arm and the estimated
best arm. Specifically, we first derive a minimax lower bound for the expected
simple regret, which characterizes the worst-case performance achievable under
the location-shift distributions, including Gaussian distributions. We then
show that the simple regret of the Neyman allocation asymptotically matches
this lower bound, including the constant term, not just the rate in terms of
the sample size, under the worst-case distribution. Notably, our optimality
result holds without imposing locality restrictions on the distribution, such
as the local asymptotic normality. Furthermore, we demonstrate that the Neyman
allocation reduces to the uniform allocation, i.e., the standard randomized
controlled trial, under Bernoulli distributions.",2024-12-23,Masahiro Kato,http://arxiv.org/pdf/2412.17753v2,cs.LG
Deliberation in Latent Space via Differentiable Cache Augmentation,"Techniques enabling large language models (LLMs) to ""think more"" by
generating and attending to intermediate reasoning steps have shown promise in
solving complex problems. However, the standard approaches generate sequences
of discrete tokens immediately before responding, and so they can incur
significant latency costs and be challenging to optimize. In this work, we
demonstrate that a frozen LLM can be augmented with an offline coprocessor that
operates on the model's key-value (kv) cache. This coprocessor augments the
cache with a set of latent embeddings designed to improve the fidelity of
subsequent decoding. We train this coprocessor using the language modeling loss
from the decoder on standard pretraining data, while keeping the decoder itself
frozen. This approach enables the model to learn, in an end-to-end
differentiable fashion, how to distill additional computation into its
kv-cache. Because the decoder remains unchanged, the coprocessor can operate
offline and asynchronously, and the language model can function normally if the
coprocessor is unavailable or if a given cache is deemed not to require extra
computation. We show experimentally that when a cache is augmented, the decoder
achieves lower perplexity on numerous subsequent tokens. Furthermore, even
without any task-specific training, our experiments demonstrate that cache
augmentation consistently reduces perplexity and improves performance across a
range of reasoning-intensive tasks.",2024-12-23,"Luyang Liu, Jonas Pfeiffer, Jiaxing Wu, Jun Xie, Arthur Szlam",http://arxiv.org/pdf/2412.17747v1,cs.LG
Sensitivity Curve Maximization: Attacking Robust Aggregators in Distributed Learning,"In distributed learning agents aim at collaboratively solving a global
learning problem. It becomes more and more likely that individual agents are
malicious or faulty with an increasing size of the network. This leads to a
degeneration or complete breakdown of the learning process. Classical
aggregation schemes are prone to breakdown at small contamination rates,
therefore robust aggregation schemes are sought for. While robust aggregation
schemes can generally tolerate larger contamination rates, many have been shown
to be susceptible to carefully crafted malicious attacks. In this work, we show
how the sensitivity curve (SC), a classical tool from robust statistics, can be
used to systematically derive optimal attack patterns against arbitrary robust
aggregators, in most cases rendering them ineffective. We show the
effectiveness of the proposed attack in multiple simulations.",2024-12-23,"Christian A. Schroth, Stefan Vlaski, Abdelhak M. Zoubir",http://arxiv.org/pdf/2412.17740v1,cs.LG
Contextual Feedback Loops: Amplifying Deep Reasoning with Iterative Top-Down Feedback,"Conventional deep networks rely on one-way backpropagation that overlooks
reconciling high-level predictions with lower-level representations. We propose
\emph{Contextual Feedback Loops} (CFLs), a lightweight mechanism that
re-injects top-down context into earlier layers for iterative refinement.
Concretely, CFLs map the network's prediction to a compact \emph{context
vector}, which is fused back into each layer via gating adapters. Unrolled over
multiple feedback steps, CFLs unify feed-forward and feedback-driven inference,
letting top-level outputs continually refine lower-level features. Despite
minimal overhead, CFLs yield consistent gains on tasks including CIFAR-10,
ImageNet-1k, SpeechCommands, and GLUE SST-2. Moreover, by a Banach Fixed Point
argument under mild Lipschitz conditions, these updates converge stably.
Overall, CFLs show that even modest top-down feedback can substantially improve
deep models, aligning with cognitive theories of iterative perception.",2024-12-23,"Jacob Fein-Ashley, Rajgopal Kannan, Viktor Prasanna",http://arxiv.org/pdf/2412.17737v6,cs.LG
LASE: Learned Adjacency Spectral Embeddings,"We put forth a principled design of a neural architecture to learn nodal
Adjacency Spectral Embeddings (ASE) from graph inputs. By bringing to bear the
gradient descent (GD) method and leveraging the principle of algorithm
unrolling, we truncate and re-interpret each GD iteration as a layer in a graph
neural network (GNN) that is trained to approximate the ASE. Accordingly, we
call the resulting embeddings and our parametric model Learned ASE (LASE),
which is interpretable, parameter efficient, robust to inputs with unobserved
edges, and offers controllable complexity during inference. LASE layers combine
Graph Convolutional Network (GCN) and fully-connected Graph Attention Network
(GAT) modules, which is intuitively pleasing since GCN-based local aggregations
alone are insufficient to express the sought graph eigenvectors. We propose
several refinements to the unrolled LASE architecture (such as sparse attention
in the GAT module and decoupled layerwise parameters) that offer favorable
approximation error versus computation tradeoffs; even outperforming
heavily-optimized eigendecomposition routines from scientific computing
libraries. Because LASE is a differentiable function with respect to its
parameters as well as its graph input, we can seamlessly integrate it as a
trainable module within a larger (semi-)supervised graph representation
learning pipeline. The resulting end-to-end system effectively learns
``discriminative ASEs'' that exhibit competitive performance in supervised link
prediction and node classification tasks, outperforming a GNN even when the
latter is endowed with open loop, meaning task-agnostic, precomputed spectral
positional encodings.",2024-12-23,"Sofía Pérez Casulo, Marcelo Fiori, Federico Larroca, Gonzalo Mateos",http://arxiv.org/pdf/2412.17734v1,cs.LG
VidTwin: Video VAE with Decoupled Structure and Dynamics,"Recent advancements in video autoencoders (Video AEs) have significantly
improved the quality and efficiency of video generation. In this paper, we
propose a novel and compact video autoencoder, VidTwin, that decouples video
into two distinct latent spaces: Structure latent vectors, which capture
overall content and global movement, and Dynamics latent vectors, which
represent fine-grained details and rapid movements. Specifically, our approach
leverages an Encoder-Decoder backbone, augmented with two submodules for
extracting these latent spaces, respectively. The first submodule employs a
Q-Former to extract low-frequency motion trends, followed by downsampling
blocks to remove redundant content details. The second averages the latent
vectors along the spatial dimension to capture rapid motion. Extensive
experiments show that VidTwin achieves a high compression rate of 0.20% with
high reconstruction quality (PSNR of 28.14 on the MCL-JCV dataset), and
performs efficiently and effectively in downstream generative tasks. Moreover,
our model demonstrates explainability and scalability, paving the way for
future research in video latent representation and generation. Check our
project page for more details: https://vidtwin.github.io/.",2024-12-23,"Yuchi Wang, Junliang Guo, Xinyi Xie, Tianyu He, Xu Sun, Jiang Bian",http://arxiv.org/pdf/2412.17726v2,cs.LG
Asynchronous Federated Learning: A Scalable Approach for Decentralized Machine Learning,"Federated Learning (FL) has emerged as a powerful paradigm for decentralized
machine learning, enabling collaborative model training across diverse clients
without sharing raw data. However, traditional FL approaches often face
limitations in scalability and efficiency due to their reliance on synchronous
client updates, which can result in significant delays and increased
communication overhead, particularly in heterogeneous and dynamic environments.
To address these challenges in this paper, we propose an Asynchronous Federated
Learning (AFL) algorithm, which allows clients to update the global model
independently and asynchronously. Our key contributions include a comprehensive
convergence analysis of AFL in the presence of client delays and model
staleness. By leveraging martingale difference sequence theory and variance
bounds, we ensure robust convergence despite asynchronous updates. Assuming
strongly convex local objective functions, we establish bounds on gradient
variance under random client sampling and derive a recursion formula
quantifying the impact of client delays on convergence.
  The proposed AFL algorithm addresses key limitations of traditional FL
methods, such as inefficiency due to global synchronization and susceptibility
to client drift. It enhances scalability, robustness, and efficiency in
real-world settings with heterogeneous client populations and dynamic network
conditions. Our results underscore the potential of AFL to drive advancements
in distributed learning systems, particularly for large-scale,
privacy-preserving applications in resource-constrained environments.",2024-12-23,"Ali Forootani, Raffaele Iervolino",http://arxiv.org/pdf/2412.17723v2,cs.LG
Fast Causal Discovery by Approximate Kernel-based Generalized Score Functions with Linear Computational Complexity,"Score-based causal discovery methods can effectively identify causal
relationships by evaluating candidate graphs and selecting the one with the
highest score. One popular class of scores is kernel-based generalized score
functions, which can adapt to a wide range of scenarios and work well in
practice because they circumvent assumptions about causal mechanisms and data
distributions. Despite these advantages, kernel-based generalized score
functions pose serious computational challenges in time and space, with a time
complexity of $\mathcal{O}(n^3)$ and a memory complexity of $\mathcal{O}(n^2)$,
where $n$ is the sample size. In this paper, we propose an approximate
kernel-based generalized score function with $\mathcal{O}(n)$ time and space
complexities by using low-rank technique and designing a set of rules to handle
the complex composite matrix operations required to calculate the score, as
well as developing sampling algorithms for different data types to benefit the
handling of diverse data types efficiently. Our extensive causal discovery
experiments on both synthetic and real-world data demonstrate that compared to
the state-of-the-art method, our method can not only significantly reduce
computational costs, but also achieve comparable accuracy, especially for large
datasets.",2024-12-23,"Yixin Ren, Haocheng Zhang, Yewei Xia, Hao Zhang, Jihong Guan, Shuigeng Zhou",http://arxiv.org/pdf/2412.17717v1,cs.LG
MRANet: A Modified Residual Attention Networks for Lung and Colon Cancer Classification,"Lung and colon cancers are predominant contributors to cancer mortality.
Early and accurate diagnosis is crucial for effective treatment. By utilizing
imaging technology in different image detection, learning models have shown
promise in automating cancer classification from histopathological images. This
includes the histopathological diagnosis, an important factor in cancer type
identification. This research focuses on creating a high-efficiency
deep-learning model for identifying lung and colon cancer from
histopathological images. We proposed a novel approach based on a modified
residual attention network architecture. The model was trained on a dataset of
25,000 high-resolution histopathological images across several classes. Our
proposed model achieved an exceptional accuracy of 99.30%, 96.63%, and 97.56%
for two, three, and five classes, respectively; those are outperforming other
state-of-the-art architectures. This study presents a highly accurate deep
learning model for lung and colon cancer classification. The superior
performance of our proposed model addresses a critical need in medical AI
applications.",2024-12-23,"Diponkor Bala, S M Rakib Ul Karim, Rownak Ara Rasul",http://arxiv.org/pdf/2412.17700v1,cs.LG
FedTLU: Federated Learning with Targeted Layer Updates,"Federated learning (FL) addresses privacy concerns in training language
models by enabling multiple clients to contribute to the training, without
sending their data to others. However, non-IID (identically and independently
distributed) data across clients often limits FL's performance. This issue is
especially challenging during model fine-tuning, as noise due to variations in
clients' data distributions can harm model convergence near stationary points.
This paper proposes a targeted layer update strategy for fine-tuning in FL.
Instead of randomly updating layers of the language model, as often done in
practice, we use a scoring mechanism to identify and update the most critical
layers, avoiding excessively noisy or even poisoned updates by freezing the
parameters in other layers. We show in extensive experiments that our method
improves convergence and performance in non-IID settings, offering a more
efficient approach to fine-tuning federated language models.",2024-12-23,"Jong-Ik Park, Carlee Joe-Wong",http://arxiv.org/pdf/2412.17692v2,cs.LG
COBRA: COmBinatorial Retrieval Augmentation for Few-Shot Adaptation,"Retrieval augmentation, the practice of retrieving additional data from large
auxiliary pools, has emerged as an effective technique for enhancing model
performance in the low-data regime. Prior approaches have employed only
nearest-neighbor based strategies for data selection, which retrieve auxiliary
samples with high similarity to instances in the target task. However, these
approaches are prone to selecting highly redundant samples, since they fail to
incorporate any notion of diversity. In our work, we first demonstrate that
data selection strategies used in prior retrieval-augmented few-shot adaptation
settings can be generalized using a class of functions known as Combinatorial
Mutual Information (CMI) measures. We then propose COBRA (COmBinatorial
Retrieval Augmentation), which employs an alternative CMI measure that
considers both diversity and similarity to a target dataset. COBRA consistently
outperforms previous retrieval approaches across image classification tasks and
few-shot learning techniques when used to retrieve samples from LAION-2B. COBRA
introduces negligible computational overhead to the cost of retrieval while
providing significant gains in downstream model performance.",2024-12-23,"Arnav M. Das, Gantavya Bhatt, Lilly Kumari, Sahil Verma, Jeff Bilmes",http://arxiv.org/pdf/2412.17684v2,cs.LG
Benchmarking Generative AI Models for Deep Learning Test Input Generation,"Test Input Generators (TIGs) are crucial to assess the ability of Deep
Learning (DL) image classifiers to provide correct predictions for inputs
beyond their training and test sets. Recent advancements in Generative AI
(GenAI) models have made them a powerful tool for creating and manipulating
synthetic images, although these advancements also imply increased complexity
and resource demands for training.
  In this work, we benchmark and combine different GenAI models with TIGs,
assessing their effectiveness, efficiency, and quality of the generated test
images, in terms of domain validity and label preservation. We conduct an
empirical study involving three different GenAI architectures (VAEs, GANs,
Diffusion Models), five classification tasks of increasing complexity, and 364
human evaluations. Our results show that simpler architectures, such as VAEs,
are sufficient for less complex datasets like MNIST. However, when dealing with
feature-rich datasets, such as ImageNet, more sophisticated architectures like
Diffusion Models achieve superior performance by generating a higher number of
valid, misclassification-inducing inputs.",2024-12-23,"Maryam, Matteo Biagiola, Andrea Stocco, Vincenzo Riccio",http://arxiv.org/pdf/2412.17652v1,cs.LG
Rate of Model Collapse in Recursive Training,"Given the ease of creating synthetic data from machine learning models, new
models can be potentially trained on synthetic data generated by previous
models. This recursive training process raises concerns about the long-term
impact on model quality. As models are recursively trained on generated data
from previous rounds, their ability to capture the nuances of the original
human-generated data may degrade. This is often referred to as \emph{model
collapse}. In this work, we ask how fast model collapse occurs for some
well-studied distribution families under maximum likelihood (ML or near ML)
estimation during recursive training. Surprisingly, even for fundamental
distributions such as discrete and Gaussian distributions, the exact rate of
model collapse is unknown. In this work, we theoretically characterize the rate
of collapse in these fundamental settings and complement it with experimental
evaluations. Our results show that for discrete distributions, the time to
forget a word is approximately linearly dependent on the number of times it
occurred in the original corpus, and for Gaussian models, the standard
deviation reduces to zero roughly at $n$ iterations, where $n$ is the number of
samples at each iteration. Both of these findings imply that model forgetting,
at least in these simple distributions under near ML estimation with many
samples, takes a long time.",2024-12-23,"Ananda Theertha Suresh, Andrew Thangaraj, Aditya Nanda Kishore Khandavally",http://arxiv.org/pdf/2412.17646v1,cs.LG
Tracking the Feature Dynamics in LLM Training: A Mechanistic Study,"Understanding training dynamics and feature evolution is crucial for the
mechanistic interpretability of large language models (LLMs). Although sparse
autoencoders (SAEs) have been used to identify features within LLMs, a clear
picture of how these features evolve during training remains elusive. In this
study, we: (1) introduce SAE-Track, a novel method to efficiently obtain a
continual series of SAEs; (2) mechanistically investigate feature formation and
develop a progress measure for it ; and (3) analyze and visualize feature drift
during training. Our work provides new insights into the dynamics of features
in LLMs, enhancing our understanding of training mechanisms and feature
evolution.",2024-12-23,"Yang Xu, Yi Wang, Hao Wang",http://arxiv.org/pdf/2412.17626v2,cs.LG
Towards An Unsupervised Learning Scheme for Efficiently Solving Parameterized Mixed-Integer Programs,"In this paper, we describe a novel unsupervised learning scheme for
accelerating the solution of a family of mixed integer programming (MIP)
problems. Distinct substantially from existing learning-to-optimize methods,
our proposal seeks to train an autoencoder (AE) for binary variables in an
unsupervised learning fashion, using data of optimal solutions to historical
instances for a parametric family of MIPs. By a deliberate design of AE
architecture and exploitation of its statistical implication, we present a
simple and straightforward strategy to construct a class of cutting plane
constraints from the decoder parameters of an offline-trained AE. These
constraints reliably enclose the optimal binary solutions of new problem
instances thanks to the representation strength of the AE. More importantly,
their integration into the primal MIP problem leads to a tightened MIP with the
reduced feasible region, which can be resolved at decision time using
off-the-shelf solvers with much higher efficiency. Our method is applied to a
benchmark batch process scheduling problem formulated as a mixed integer linear
programming (MILP) problem. Comprehensive results demonstrate that our approach
significantly reduces the computational cost of off-the-shelf MILP solvers
while retaining a high solution quality. The codes of this work are
open-sourced at https://github.com/qushiyuan/AE4BV.",2024-12-23,"Shiyuan Qu, Fenglian Dong, Zhiwei Wei, Chao Shang",http://arxiv.org/pdf/2412.17623v2,cs.LG
Be More Diverse than the Most Diverse: Optimal Mixtures of Generative Models via Mixture-UCB Bandit Algorithms,"The availability of multiple training algorithms and architectures for
generative models requires a selection mechanism to form a single model over a
group of well-trained generation models. The selection task is commonly
addressed by identifying the model that maximizes an evaluation score based on
the diversity and quality of the generated data. However, such a best-model
identification approach overlooks the possibility that a mixture of available
models can outperform each individual model. In this work, we numerically show
that a mixture of generative models on benchmark image datasets can indeed
achieve a better evaluation score (based on FID and KID scores), compared to
the individual models. This observation motivates the development of efficient
algorithms for selecting the optimal mixture of the models. To address this, we
formulate a quadratic optimization problem to find an optimal mixture model
achieving the maximum of kernel-based evaluation scores including kernel
inception distance (KID) and R\'enyi kernel entropy (RKE). To identify the
optimal mixture of the models using the fewest possible sample queries, we view
the selection task as a multi-armed bandit (MAB) problem and propose the
Mixture Upper Confidence Bound (Mixture-UCB) algorithm that provably converges
to the optimal mixture of the involved models. More broadly, the proposed
Mixture-UCB can be extended to optimize every convex quadratic function of the
mixture weights in a general MAB setting. We prove a regret bound for the
Mixture-UCB algorithm and perform several numerical experiments to show the
success of Mixture-UCB in finding the optimal mixture of text and image
generative models. The project code is available at
https://github.com/Rezaei-Parham/Mixture-UCB.",2024-12-23,"Parham Rezaei, Farzan Farnia, Cheuk Ting Li",http://arxiv.org/pdf/2412.17622v2,cs.LG
Can Stability be Detrimental? Better Generalization through Gradient Descent Instabilities,"Traditional analyses of gradient descent optimization show that, when the
largest eigenvalue of the loss Hessian - often referred to as the sharpness -
is below a critical learning-rate threshold, then training is 'stable' and
training loss decreases monotonically. Recent studies, however, have suggested
that the majority of modern deep neural networks achieve good performance
despite operating outside this stable regime. In this work, we demonstrate that
such instabilities, induced by large learning rates, move model parameters
toward flatter regions of the loss landscape. Our crucial insight lies in
noting that, during these instabilities, the orientation of the Hessian
eigenvectors rotate. This, we conjecture, allows the model to explore regions
of the loss landscape that display more desirable geometrical properties for
generalization, such as flatness. These rotations are a consequence of network
depth, and we prove that for any network with depth > 1, unstable growth in
parameters cause rotations in the principal components of the Hessian, which
promote exploration of the parameter space away from unstable directions. Our
empirical studies reveal an implicit regularization effect in gradient descent
with large learning rates operating beyond the stability threshold. We find
these lead to excellent generalization performance on modern benchmark
datasets.",2024-12-23,"Lawrence Wang, Stephen J. Roberts",http://arxiv.org/pdf/2412.17613v1,cs.LG
Towards Foundation Models on Graphs: An Analysis on Cross-Dataset Transfer of Pretrained GNNs,"To develop a preliminary understanding towards Graph Foundation Models, we
study the extent to which pretrained Graph Neural Networks can be applied
across datasets, an effort requiring to be agnostic to dataset-specific
features and their encodings. We build upon a purely structural pretraining
approach and propose an extension to capture feature information while still
being feature-agnostic. We evaluate pretrained models on downstream tasks for
varying amounts of training samples and choices of pretraining datasets. Our
preliminary results indicate that embeddings from pretrained models improve
generalization only with enough downstream data points and in a degree which
depends on the quantity and properties of pretraining data. Feature information
can lead to improvements, but currently requires some similarities between
pretraining and downstream feature spaces.",2024-12-23,"Fabrizio Frasca, Fabian Jogl, Moshe Eliasof, Matan Ostrovsky, Carola-Bibiane Schönlieb, Thomas Gärtner, Haggai Maron",http://arxiv.org/pdf/2412.17609v1,cs.LG
EasyTime: Time Series Forecasting Made Easy,"Time series forecasting has important applications across diverse domains.
EasyTime, the system we demonstrate, facilitates easy use of time-series
forecasting methods by researchers and practitioners alike. First, EasyTime
enables one-click evaluation, enabling researchers to evaluate new forecasting
methods using the suite of diverse time series datasets collected in the
preexisting time series forecasting benchmark (TFB). This is achieved by
leveraging TFB's flexible and consistent evaluation pipeline. Second, when
practitioners must perform forecasting on a new dataset, a nontrivial first
step is often to find an appropriate forecasting method. EasyTime provides an
Automated Ensemble module that combines the promising forecasting methods to
yield superior forecasting accuracy compared to individual methods. Third,
EasyTime offers a natural language Q&A module leveraging large language models.
Given a question like ""Which method is best for long term forecasting on time
series with strong seasonality?"", EasyTime converts the question into SQL
queries on the database of results obtained by TFB and then returns an answer
in natural language and charts. By demonstrating EasyTime, we intend to show
how it is possible to simplify the use of time series forecasting and to offer
better support for the development of new generations of time series
forecasting methods.",2024-12-23,"Xiangfei Qiu, Xiuwen Li, Ruiyang Pang, Zhicheng Pan, Xingjian Wu, Liu Yang, Jilin Hu, Yang Shu, Xuesong Lu, Chengcheng Yang, Chenjuan Guo, Aoying Zhou, Christian S. Jensen, Bin Yang",http://arxiv.org/pdf/2412.17603v1,cs.LG
The ELEVATE-AI LLMs Framework: An Evaluation Framework for Use of Large Language Models in HEOR: an ISPOR Working Group Report,"Introduction. Generative Artificial Intelligence, particularly large language
models (LLMs), offers transformative potential for Health Economics and
Outcomes Research (HEOR). However, evaluating the quality, transparency, and
rigor of LLM-assisted research lacks standardized guidance. This article
introduces the ELEVATE AI LLMs framework and checklist, designed to support
researchers and reviewers in assessing LLM use in HEOR.
  Methods. The ELEVATE AI LLMs framework was developed through a targeted
review of existing guidelines and evaluation frameworks. The framework
comprises ten evaluation domains, including model characteristics, accuracy,
comprehensiveness, and fairness. The accompanying checklist operationalizes the
framework. To validate the framework, we applied it to two published studies,
demonstrating its usability across different HEOR tasks.
  Results. The ELEVATE AI LLMs framework provides a comprehensive structure for
evaluating LLM-assisted research, while the checklist facilitates practical
application. Validation of the framework and checklist on studies of systematic
literature reviews and health economic modeling highlighted their ability to
identify strengths and gaps in reporting.
  Limitations. While the ELEVATE AI LLMs framework provides robust guidance,
its broader generalizability and applicability to diverse HEOR tasks require
further empirical testing. Additionally, several metrics adapted from computer
science need further validation in HEOR contexts.
  Conclusion. The ELEVATE AI LLMs framework and checklist fill a critical gap
in HEOR by offering structured guidance for evaluating LLM-assisted research.
By promoting transparency, accuracy, and reproducibility, they aim to
standardize and improve the integration of LLMs into HEOR, ensuring their
outputs meet the field's rigorous standards.",2024-12-23,"Rachael L. Fleurence, Dalia Dawoud, Jiang Bian, Mitchell K. Higashi, Xiaoyan Wang, Hua Xu, Jagpreet Chhatwal, Turgay Ayer",http://arxiv.org/pdf/2501.12394v1,cs.LG
Graph Size-imbalanced Learning with Energy-guided Structural Smoothing,"Graph is a prevalent data structure employed to represent the relationships
between entities, frequently serving as a tool to depict and simulate numerous
systems, such as molecules and social networks. However, real-world graphs
usually suffer from the size-imbalanced problem in the multi-graph
classification, i.e., a long-tailed distribution with respect to the number of
nodes. Recent studies find that off-the-shelf Graph Neural Networks (GNNs)
would compromise model performance under the long-tailed settings. We
investigate this phenomenon and discover that the long-tailed graph
distribution greatly exacerbates the discrepancies in structural features. To
alleviate this problem, we propose a novel energy-based size-imbalanced
learning framework named \textbf{SIMBA}, which smooths the features between
head and tail graphs and re-weights them based on the energy propagation.
Specifically, we construct a higher-level graph abstraction named
\textit{Graphs-to-Graph} according to the correlations between graphs to link
independent graphs and smooths the structural discrepancies. We further devise
an energy-based message-passing belief propagation method for re-weighting
lower compatible graphs in the training process and further smooth local
feature discrepancies. Extensive experimental results over five public
size-imbalanced datasets demonstrate the superior effectiveness of the model
for size-imbalanced graph classification tasks.",2024-12-23,"Jiawen Qin, Pengfeng Huang, Qingyun Sun, Cheng Ji, Xingcheng Fu, Jianxin Li",http://arxiv.org/pdf/2412.17591v1,cs.LG
"PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World","Imagine a world where AI can handle your work while you sleep - organizing
your research materials, drafting a report, or creating a presentation you need
for tomorrow. However, while current digital agents can perform simple tasks,
they are far from capable of handling the complex real-world work that humans
routinely perform. We present PC Agent, an AI system that demonstrates a
crucial step toward this vision through human cognition transfer. Our key
insight is that the path from executing simple ""tasks"" to handling complex
""work"" lies in efficiently capturing and learning from human cognitive
processes during computer use. To validate this hypothesis, we introduce three
key innovations: (1) PC Tracker, a lightweight infrastructure that efficiently
collects high-quality human-computer interaction trajectories with complete
cognitive context; (2) a two-stage cognition completion pipeline that
transforms raw interaction data into rich cognitive trajectories by completing
action semantics and thought processes; and (3) a multi-agent system combining
a planning agent for decision-making with a grounding agent for robust visual
grounding. Our preliminary experiments in PowerPoint presentation creation
reveal that complex digital work capabilities can be achieved with a small
amount of high-quality cognitive data - PC Agent, trained on just 133 cognitive
trajectories, can handle sophisticated work scenarios involving up to 50 steps
across multiple applications. This demonstrates the data efficiency of our
approach, highlighting that the key to training capable digital agents lies in
collecting human cognitive data. By open-sourcing our complete framework,
including the data collection infrastructure and cognition completion methods,
we aim to lower the barriers for the research community to develop truly
capable digital agents.",2024-12-23,"Yanheng He, Jiahe Jin, Shijie Xia, Jiadi Su, Runze Fan, Haoyang Zou, Xiangkun Hu, Pengfei Liu",http://arxiv.org/pdf/2412.17589v1,cs.LG
Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework,"Cotton crops, often called ""white gold,"" face significant production
challenges, primarily due to various leaf-affecting diseases. As a major global
source of fiber, timely and accurate disease identification is crucial to
ensure optimal yields and maintain crop health. While deep learning and machine
learning techniques have been explored to address this challenge, there remains
a gap in developing lightweight models with fewer parameters which could be
computationally effective for agricultural practitioners. To address this, we
propose an innovative deep learning framework integrating a subset of trainable
layers from MobileNet, transfer learning, data augmentation, a learning rate
decay schedule, model checkpoints, and early stopping mechanisms. Our model
demonstrates exceptional performance, accurately classifying seven cotton
disease types with an overall accuracy of 98.42% and class-wise precision
ranging from 96% to 100%. This results in significantly enhanced efficiency,
surpassing recent approaches in accuracy and model complexity. The existing
models in the literature have yet to attain such high accuracy, even when
tested on data sets with fewer disease types. The substantial performance
improvement, combined with the lightweight nature of the model, makes it
practically suitable for real-world applications in smart farming. By offering
a high-performing and efficient solution, our framework can potentially address
challenges in cotton cultivation, contributing to sustainable agricultural
practices.",2024-12-23,"Aswini Kumar Patra, Tejashwini Gajurel",http://arxiv.org/pdf/2412.17587v1,cs.LG
Enhancing Reconstruction-Based Out-of-Distribution Detection in Brain MRI with Model and Metric Ensembles,"Out-of-distribution (OOD) detection is crucial for safely deploying automated
medical image analysis systems, as abnormal patterns in images could hamper
their performance. However, OOD detection in medical imaging remains an open
challenge, and we address three gaps: the underexplored potential of a simple
OOD detection model, the lack of optimization of deep learning strategies
specifically for OOD detection, and the selection of appropriate reconstruction
metrics. In this study, we investigated the effectiveness of a
reconstruction-based autoencoder for unsupervised detection of synthetic
artifacts in brain MRI. We evaluated the general reconstruction capability of
the model, analyzed the impact of the selected training epoch and
reconstruction metrics, assessed the potential of model and/or metric
ensembles, and tested the model on a dataset containing a diverse range of
artifacts. Among the metrics assessed, the contrast component of SSIM and LPIPS
consistently outperformed others in detecting homogeneous circular anomalies.
By combining two well-converged models and using LPIPS and contrast as
reconstruction metrics, we achieved a pixel-level area under the
Precision-Recall curve of 0.66. Furthermore, with the more realistic OOD
dataset, we observed that the detection performance varied between artifact
types; local artifacts were more difficult to detect, while global artifacts
showed better detection results. These findings underscore the importance of
carefully selecting metrics and model configurations, and highlight the need
for tailored approaches, as standard deep learning approaches do not always
align with the unique needs of OOD detection.",2024-12-23,"Evi M. C. Huijben, Sina Amirrajab, Josien P. W. Pluim",http://arxiv.org/pdf/2412.17586v1,cs.LG
HPCNeuroNet: A Neuromorphic Approach Merging SNN Temporal Dynamics with Transformer Attention for FPGA-based Particle Physics,"This paper presents the innovative HPCNeuroNet model, a pioneering fusion of
Spiking Neural Networks (SNNs), Transformers, and high-performance computing
tailored for particle physics, particularly in particle identification from
detector responses. Our approach leverages SNNs' intrinsic temporal dynamics
and Transformers' robust attention mechanisms to enhance performance when
discerning intricate particle interactions. At the heart of HPCNeuroNet lies
the integration of the sequential dynamism inherent in SNNs with the
context-aware attention capabilities of Transformers, enabling the model to
precisely decode and interpret complex detector data. HPCNeuroNet is realized
through the HLS4ML framework and optimized for deployment in FPGA environments.
The model accuracy and scalability are also enhanced by this architectural
choice. Benchmarked against machine learning models, HPCNeuroNet showcases
better performance metrics, underlining its transformative potential in
high-energy physics. We demonstrate that the combination of SNNs, Transformers,
and FPGA-based high-performance computing in particle physics signifies a
significant step forward and provides a strong foundation for future research.",2024-12-23,"Murat Isik, Hiruna Vishwamith, Jonathan Naoukin, I. Can Dikmen",http://arxiv.org/pdf/2412.17571v1,cs.LG
The Dynamic Duo of Collaborative Masking and Target for Advanced Masked Autoencoder Learning,"Masked autoencoders (MAE) have recently succeeded in self-supervised vision
representation learning. Previous work mainly applied custom-designed (e.g.,
random, block-wise) masking or teacher (e.g., CLIP)-guided masking and targets.
However, they ignore the potential role of the self-training (student) model in
giving feedback to the teacher for masking and targets. In this work, we
present to integrate Collaborative Masking and Targets for boosting Masked
AutoEncoders, namely CMT-MAE. Specifically, CMT-MAE leverages a simple
collaborative masking mechanism through linear aggregation across attentions
from both teacher and student models. We further propose using the output
features from those two models as the collaborative target of the decoder. Our
simple and effective framework pre-trained on ImageNet-1K achieves
state-of-the-art linear probing and fine-tuning performance. In particular,
using ViT-base, we improve the fine-tuning results of the vanilla MAE from
83.6% to 85.7%.",2024-12-23,Shentong Mo,http://arxiv.org/pdf/2412.17566v1,cs.LG
Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction,"Cellular traffic forecasting is a critical task that enables network
operators to efficiently allocate resources and address anomalies in rapidly
evolving environments. The exponential growth of data collected from base
stations poses significant challenges to processing and analysis. While machine
learning (ML) algorithms have emerged as powerful tools for handling these
large datasets and providing accurate predictions, their environmental impact,
particularly in terms of energy consumption, is often overlooked in favor of
their predictive capabilities. This study investigates the potential of two
bio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing
through Echo State Networks (ESNs) for cellular traffic forecasting. The
evaluation focuses on both their predictive performance and energy efficiency.
These models are implemented in both centralized and federated settings to
analyze their effectiveness and energy consumption in decentralized systems.
Additionally, we compare bio-inspired models with traditional architectures,
such as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), to provide a comprehensive evaluation. Using data collected from three
diverse locations in Barcelona, Spain, we examine the trade-offs between
predictive accuracy and energy demands across these approaches. The results
indicate that bio-inspired models, such as SNNs and ESNs, can achieve
significant energy savings while maintaining predictive accuracy comparable to
traditional architectures. Furthermore, federated implementations were tested
to evaluate their energy efficiency in decentralized settings compared to
centralized systems, particularly in combination with bio-inspired models.
These findings offer valuable insights into the potential of bio-inspired
models for sustainable and privacy-preserving cellular traffic forecasting.",2024-12-23,"Theodoros Tsiolakis, Nikolaos Pavlidis, Vasileios Perifanis, Pavlos Efraimidis",http://arxiv.org/pdf/2412.17565v1,cs.LG
GQSA: Group Quantization and Sparsity for Accelerating Large Language Model Inference,"Model compression has emerged as a mainstream solution to reduce memory usage
and computational overhead. This paper presents Group Quantization and Sparse
Acceleration (GQSA), a novel compression technique tailored for LLMs.
Traditional methods typically focus exclusively on either quantization or
sparsification, but relying on a single strategy often results in significant
performance loss at high compression rates. In contrast, GQSA integrates
quantization and sparsification in a tightly coupled manner, leveraging
GPU-friendly structured group sparsity and quantization for efficient
acceleration. Building upon system-algorithm co-design principles, we propose a
two-stage sparse optimization strategy that ensures the performance superiority
of the compressed model. On the engine side, we introduce a ""task-centric""
parallel strategy, which, to the best of our knowledge, is the first
application in the domain of sparse computing. Compared to the traditional 2:4
sparse method, the GQSA offers a more flexible and adjustable sparsity rate, as
well as a higher weight compression rate, and is efficiently compatible with
weight-only quantization methods. Experimental results demonstrate that, under
the GQSA W4S50% compression setting, the model's accuracy surpasses that of
both 2:4 pruning and W2 quantization. Furthermore, at the inference level, GQSA
outperforms W2 by 1.26$\times$ and 2:4 pruning by 2.35$\times$ in terms of
speed.",2024-12-23,"Chao Zeng, Songwei Liu, Shu Yang, Fangmin Chen, Xing Mei, Lean Fu",http://arxiv.org/pdf/2412.17560v3,cs.LG
Probability-density-aware Semi-supervised Learning,"Semi-supervised learning (SSL) assumes that neighbor points lie in the same
category (neighbor assumption), and points in different clusters belong to
various categories (cluster assumption). Existing methods usually rely on
similarity measures to retrieve the similar neighbor points, ignoring cluster
assumption, which may not utilize unlabeled information sufficiently and
effectively. This paper first provides a systematical investigation into the
significant role of probability density in SSL and lays a solid theoretical
foundation for cluster assumption. To this end, we introduce a
Probability-Density-Aware Measure (PM) to discern the similarity between
neighbor points. To further improve Label Propagation, we also design a
Probability-Density-Aware Measure Label Propagation (PMLP) algorithm to fully
consider the cluster assumption in label propagation. Last but not least, we
prove that traditional pseudo-labeling could be viewed as a particular case of
PMLP, which provides a comprehensive theoretical understanding of PMLP's
superior performance. Extensive experiments demonstrate that PMLP achieves
outstanding performance compared with other recent methods.",2024-12-23,"Shuyang Liu, Ruiqiu Zheng, Yunhang Shen, Ke Li, Xing Sun, Zhou Yu, Shaohui Lin",http://arxiv.org/pdf/2412.17547v2,cs.LG
Leveraging Cardiovascular Simulations for In-Vivo Prediction of Cardiac Biomarkers,"Whole-body hemodynamics simulators, which model blood flow and pressure
waveforms as functions of physiological parameters, are now essential tools for
studying cardiovascular systems. However, solving the corresponding inverse
problem of mapping observations (e.g., arterial pressure waveforms at specific
locations in the arterial network) back to plausible physiological parameters
remains challenging. Leveraging recent advances in simulation-based inference,
we cast this problem as statistical inference by training an amortized neural
posterior estimator on a newly built large dataset of cardiac simulations that
we publicly release. To better align simulated data with real-world
measurements, we incorporate stochastic elements modeling exogenous effects.
The proposed framework can further integrate in-vivo data sources to refine its
predictive capabilities on real-world data. In silico, we demonstrate that the
proposed framework enables finely quantifying uncertainty associated with
individual measurements, allowing trustworthy prediction of four biomarkers of
clinical interest--namely Heart Rate, Cardiac Output, Systemic Vascular
Resistance, and Left Ventricular Ejection Time--from arterial pressure
waveforms and photoplethysmograms. Furthermore, we validate the framework in
vivo, where our method accurately captures temporal trends in CO and SVR
monitoring on the VitalDB dataset. Finally, the predictive error made by the
model monotonically increases with the predicted uncertainty, thereby directly
supporting the automatic rejection of unusable measurements.",2024-12-23,"Laura Manduchi, Antoine Wehenkel, Jens Behrmann, Luca Pegolotti, Andy C. Miller, Ozan Sener, Marco Cuturi, Guillermo Sapiro, Jörn-Henrik Jacobsen",http://arxiv.org/pdf/2412.17542v1,cs.LG
Constructing Fair Latent Space for Intersection of Fairness and Explainability,"As the use of machine learning models has increased, numerous studies have
aimed to enhance fairness. However, research on the intersection of fairness
and explainability remains insufficient, leading to potential issues in gaining
the trust of actual users. Here, we propose a novel module that constructs a
fair latent space, enabling faithful explanation while ensuring fairness. The
fair latent space is constructed by disentangling and redistributing labels and
sensitive attributes, allowing the generation of counterfactual explanations
for each type of information. Our module is attached to a pretrained generative
model, transforming its biased latent space into a fair latent space.
Additionally, since only the module needs to be trained, there are advantages
in terms of time and cost savings, without the need to train the entire
generative model. We validate the fair latent space with various fairness
metrics and demonstrate that our approach can effectively provide explanations
for biased decisions and assurances of fairness.",2024-12-23,"Hyungjun Joo, Hyeonggeun Han, Sehwan Kim, Sangwoo Hong, Jungwoo Lee",http://arxiv.org/pdf/2412.17523v2,cs.LG
Optimal Convergence Rates for Neural Operators,"We introduce the neural tangent kernel (NTK) regime for two-layer neural
operators and analyze their generalization properties. For early-stopped
gradient descent (GD), we derive fast convergence rates that are known to be
minimax optimal within the framework of non-parametric regression in
reproducing kernel Hilbert spaces (RKHS). We provide bounds on the number of
hidden neurons and the number of second-stage samples necessary for
generalization. To justify our NTK regime, we additionally show that any
operator approximable by a neural operator can also be approximated by an
operator from the RKHS. A key application of neural operators is learning
surrogate maps for the solution operators of partial differential equations
(PDEs). We consider the standard Poisson equation to illustrate our theoretical
findings with simulations.",2024-12-23,"Mike Nguyen, Nicole Mücke",http://arxiv.org/pdf/2412.17518v1,cs.LG
BEE: Metric-Adapted Explanations via Baseline Exploration-Exploitation,"Two prominent challenges in explainability research involve 1) the nuanced
evaluation of explanations and 2) the modeling of missing information through
baseline representations. The existing literature introduces diverse evaluation
metrics, each scrutinizing the quality of explanations through distinct lenses.
Additionally, various baseline representations have been proposed, each
modeling the notion of missingness differently. Yet, a consensus on the
ultimate evaluation metric and baseline representation remains elusive. This
work acknowledges the diversity in explanation metrics and baselines,
demonstrating that different metrics exhibit preferences for distinct
explanation maps resulting from the utilization of different baseline
representations and distributions. To address the diversity in metrics and
accommodate the variety of baseline representations in a unified manner, we
propose Baseline Exploration-Exploitation (BEE) - a path-integration method
that introduces randomness to the integration process by modeling the baseline
as a learned random tensor. This tensor follows a learned mixture of baseline
distributions optimized through a contextual exploration-exploitation procedure
to enhance performance on the specific metric of interest. By resampling the
baseline from the learned distribution, BEE generates a comprehensive set of
explanation maps, facilitating the selection of the best-performing explanation
map in this broad set for the given metric. Extensive evaluations across
various model architectures showcase the superior performance of BEE in
comparison to state-of-the-art explanation methods on a variety of objective
evaluation metrics.",2024-12-23,"Oren Barkan, Yehonatan Elisha, Jonathan Weill, Noam Koenigstein",http://arxiv.org/pdf/2412.17512v1,cs.LG
An efficient search-and-score algorithm for ancestral graphs using multivariate information scores,"We propose a greedy search-and-score algorithm for ancestral graphs, which
include directed as well as bidirected edges, originating from unobserved
latent variables. The normalized likelihood score of ancestral graphs is
estimated in terms of multivariate information over relevant ``ac-connected
subsets'' of vertices, C, that are connected through collider paths confined to
the ancestor set of C. For computational efficiency, the proposed two-step
algorithm relies on local information scores limited to the close surrounding
vertices of each node (step 1) and edge (step 2). This computational strategy,
although restricted to information contributions from ac-connected subsets
containing up to two-collider paths, is shown to outperform state-of-the-art
causal discovery methods on challenging benchmark datasets.",2024-12-23,"Nikita Lagrange, Herve Isambert",http://arxiv.org/pdf/2412.17508v1,cs.LG
Uncertainties of Satellite-based Essential Climate Variables from Deep Learning,"Accurate uncertainty information associated with essential climate variables
(ECVs) is crucial for reliable climate modeling and understanding the
spatiotemporal evolution of the Earth system. In recent years, geoscience and
climate scientists have benefited from rapid progress in deep learning to
advance the estimation of ECV products with improved accuracy. However, the
quantification of uncertainties associated with the output of such deep
learning models has yet to be thoroughly adopted. This survey explores the
types of uncertainties associated with ECVs estimated from deep learning and
the techniques to quantify them. The focus is on highlighting the importance of
quantifying uncertainties inherent in ECV estimates, considering the dynamic
and multifaceted nature of climate data. The survey starts by clarifying the
definition of aleatoric and epistemic uncertainties and their roles in a
typical satellite observation processing workflow, followed by bridging the gap
between conventional statistical and deep learning views on uncertainties.
Then, we comprehensively review the existing techniques for quantifying
uncertainties associated with deep learning algorithms, focusing on their
application in ECV studies. The specific need for modification to fit the
requirements from both the Earth observation side and the deep learning side in
such interdisciplinary tasks is discussed. Finally, we demonstrate our findings
with two ECV examples, snow cover and terrestrial water storage, and provide
our perspectives for future research.",2024-12-23,"Junyang Gou, Arnt-Børre Salberg, Mostafa Kiani Shahvandi, Mohammad J. Tourian, Ulrich Meyer, Eva Boergens, Anders U. Waldeland, Isabella Velicogna, Fredrik Dahl, Adrian Jäggi, Konrad Schindler, Benedikt Soja",http://arxiv.org/pdf/2412.17506v1,cs.LG
More is Less? A Simulation-Based Approach to Dynamic Interactions between Biases in Multimodal Models,"Multimodal machine learning models, such as those that combine text and image
modalities, are increasingly used in critical domains including public safety,
security, and healthcare. However, these systems inherit biases from their
single modalities. This study proposes a systemic framework for analyzing
dynamic multimodal bias interactions. Using the MMBias dataset, which
encompasses categories prone to bias such as religion, nationality, and sexual
orientation, this study adopts a simulation-based heuristic approach to compute
bias scores for text-only, image-only, and multimodal embeddings. A framework
is developed to classify bias interactions as amplification (multimodal bias
exceeds both unimodal biases), mitigation (multimodal bias is lower than both),
and neutrality (multimodal bias lies between unimodal biases), with
proportional analyzes conducted to identify the dominant mode and dynamics in
these interactions. The findings highlight that amplification (22\%) occurs
when text and image biases are comparable, while mitigation (11\%) arises under
the dominance of text bias, highlighting the stabilizing role of image bias.
Neutral interactions (67\%) are related to a higher text bias without
divergence. Conditional probabilities highlight the text's dominance in
mitigation and mixed contributions in neutral and amplification cases,
underscoring complex modality interplay. In doing so, the study encourages the
use of this heuristic, systemic, and interpretable framework to analyze
multimodal bias interactions, providing insight into how intermodal biases
dynamically interact, with practical applications for multimodal modeling and
transferability to context-based datasets, all essential for developing fair
and equitable AI models.",2024-12-23,Mounia Drissi,http://arxiv.org/pdf/2412.17505v1,cs.LG
Improving the Noise Estimation of Latent Neural Stochastic Differential Equations,"Latent neural stochastic differential equations (SDEs) have recently emerged
as a promising approach for learning generative models from stochastic time
series data. However, they systematically underestimate the noise level
inherent in such data, limiting their ability to capture stochastic dynamics
accurately. We investigate this underestimation in detail and propose a
straightforward solution: by including an explicit additional noise
regularization in the loss function, we are able to learn a model that
accurately captures the diffusion component of the data. We demonstrate our
results on a conceptual model system that highlights the improved latent neural
SDE's capability to model stochastic bistable dynamics.",2024-12-23,"Linus Heck, Maximilian Gelbrecht, Michael T. Schaub, Niklas Boers",http://arxiv.org/pdf/2412.17499v1,cs.LG
A Toolkit for Virtual Reality Data Collection,"Due to the still relatively low number of users, acquiring large-scale and
multidimensional virtual reality datasets remains a significant challenge.
Consequently, VR datasets comparable in size to state-of-the-art collections in
natural language processing or computer vision are rare or absent. However, the
availability of such datasets could unlock groundbreaking advancements in
deep-learning, psychological modeling, and data analysis in the context of VR.
In this paper, we present a versatile data collection toolkit designed to
facilitate the capturing of extensive VR datasets. Our toolkit seamlessly
integrates with any device, either directly via OpenXR or through the use of a
virtual device. Additionally, we introduce a robust data collection pipeline
that emphasizes ethical practices (e.g., ensuring data protection and
regulation) and ensures a standardized, reproducible methodology.",2024-12-23,"Tim Rolff, Niklas Hypki, Markus Lappe, Frank Steinicke",http://arxiv.org/pdf/2412.17490v1,cs.LG
DeepMF: Deep Motion Factorization for Closed-Loop Safety-Critical Driving Scenario Simulation,"Safety-critical traffic scenarios are of great practical relevance to
evaluating the robustness of autonomous driving (AD) systems. Given that these
long-tail events are extremely rare in real-world traffic data, there is a
growing body of work dedicated to the automatic traffic scenario generation.
However, nearly all existing algorithms for generating safety-critical
scenarios rely on snippets of previously recorded traffic events, transforming
normal traffic flow into accident-prone situations directly. In other words,
safety-critical traffic scenario generation is hindsight and not applicable to
newly encountered and open-ended traffic events.In this paper, we propose the
Deep Motion Factorization (DeepMF) framework, which extends static
safety-critical driving scenario generation to closed-loop and interactive
adversarial traffic simulation. DeepMF casts safety-critical traffic simulation
as a Bayesian factorization that includes the assignment of hazardous traffic
participants, the motion prediction of selected opponents, the reaction
estimation of autonomous vehicle (AV) and the probability estimation of the
accident occur. All the aforementioned terms are calculated using decoupled
deep neural networks, with inputs limited to the current observation and
historical states. Consequently, DeepMF can effectively and efficiently
simulate safety-critical traffic scenarios at any triggered time and for any
duration by maximizing the compounded posterior probability of traffic risk.
Extensive experiments demonstrate that DeepMF excels in terms of risk
management, flexibility, and diversity, showcasing outstanding performance in
simulating a wide range of realistic, high-risk traffic scenarios.",2024-12-23,"Yizhe Li, Linrui Zhang, Xueqian Wang, Houde Liu, Bin Liang",http://arxiv.org/pdf/2412.17487v1,cs.LG
Line Graph Vietoris-Rips Persistence Diagram for Topological Graph Representation Learning,"While message passing graph neural networks result in informative node
embeddings, they may suffer from describing the topological properties of
graphs. To this end, node filtration has been widely used as an attempt to
obtain the topological information of a graph using persistence diagrams.
However, these attempts have faced the problem of losing node embedding
information, which in turn prevents them from providing a more expressive graph
representation. To tackle this issue, we shift our focus to edge filtration and
introduce a novel edge filtration-based persistence diagram, named Topological
Edge Diagram (TED), which is mathematically proven to preserve node embedding
information as well as contain additional topological information. To implement
TED, we propose a neural network based algorithm, named Line Graph
Vietoris-Rips (LGVR) Persistence Diagram, that extracts edge information by
transforming a graph into its line graph. Through LGVR, we propose two model
frameworks that can be applied to any message passing GNNs, and prove that they
are strictly more powerful than Weisfeiler-Lehman type colorings. Finally we
empirically validate superior performance of our models on several graph
classification and regression benchmarks.",2024-12-23,"Jaesun Shin, Eunjoo Jeon, Taewon Cho, Namkyeong Cho, Youngjune Gwon",http://arxiv.org/pdf/2412.17468v1,cs.LG
Learning from Summarized Data: Gaussian Process Regression with Sample Quasi-Likelihood,"Gaussian process regression is a powerful Bayesian nonlinear regression
method. Recent research has enabled the capture of many types of observations
using non-Gaussian likelihoods. To deal with various tasks in spatial modeling,
we benefit from this development. Difficulties still arise when we can only
access summarized data consisting of representative features, summary
statistics, and data point counts. Such situations frequently occur primarily
due to concerns about confidentiality and management costs associated with
spatial data. This study tackles learning and inference using only summarized
data within the framework of Gaussian process regression. To address this
challenge, we analyze the approximation errors in the marginal likelihood and
posterior distribution that arise from utilizing representative features. We
also introduce the concept of sample quasi-likelihood, which facilitates
learning and inference using only summarized data. Non-Gaussian likelihoods
satisfying certain assumptions can be captured by specifying a variance
function that characterizes a sample quasi-likelihood function. Theoretical and
experimental results demonstrate that the approximation performance is
influenced by the granularity of summarized data relative to the length scale
of covariance functions. Experiments on a real-world dataset highlight the
practicality of our method for spatial modeling.",2024-12-23,Yuta Shikuri,http://arxiv.org/pdf/2412.17455v2,cs.LG
A Temporal Convolutional Network-based Approach for Network Intrusion Detection,"Network intrusion detection is critical for securing modern networks, yet the
complexity of network traffic poses significant challenges to traditional
methods. This study proposes a Temporal Convolutional Network(TCN) model
featuring a residual block architecture with dilated convolutions to capture
dependencies in network traffic data while ensuring training stability. The
TCN's ability to process sequences in parallel enables faster, more accurate
sequence modeling than Recurrent Neural Networks. Evaluated on the Edge-IIoTset
dataset, which includes 15 classes with normal traffic and 14 cyberattack
types, the proposed model achieved an accuracy of 96.72% and a loss of 0.0688,
outperforming 1D CNN, CNN-LSTM, CNN-GRU, CNN-BiLSTM, and CNN-GRU-LSTM models. A
class-wise classification report, encompassing metrics such as recall,
precision, accuracy, and F1-score, demonstrated the TCN model's superior
performance across varied attack categories, including Malware, Injection, and
DDoS. These results underscore the model's potential in addressing the
complexities of network intrusion detection effectively.",2024-12-23,"Rukmini Nazre, Rujuta Budke, Omkar Oak, Suraj Sawant, Amit Joshi",http://arxiv.org/pdf/2412.17452v1,cs.LG
Diving into Self-Evolving Training for Multimodal Reasoning,"Reasoning ability is essential for Large Multimodal Models (LMMs). In the
absence of multimodal chain-of-thought annotated data, self-evolving training,
where the model learns from its own outputs, has emerged as an effective and
scalable approach for enhancing reasoning abilities. Despite its growing usage,
a comprehensive understanding of self-evolving training, particularly in the
context of multimodal reasoning, remains limited. In this paper, we delve into
the intricacies of self-evolving training for multimodal reasoning, pinpointing
three key factors: Training Method, Reward Model, and Prompt Variation. We
systematically examine each factor and explore how various configurations
affect the training's effectiveness. Our analysis leads to a set of best
practices for each factor, aimed at optimizing multimodal reasoning.
Furthermore, we explore the Self-Evolution Dynamics during training and the
impact of automatic balancing mechanisms in boosting performance. After all the
investigations, we present a final recipe for self-evolving training in
multimodal reasoning, encapsulating these design choices into a framework we
call MSTaR (Multimodal Self-evolving Training for Reasoning), which is
universally effective for models with different sizes on various benchmarks,
e.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning
benchmarks without using additional human annotations, as demonstrated on
MiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this
study fills a significant gap in the understanding of self-evolving training
for multimodal reasoning and offers a robust framework for future research. Our
policy and reward models, as well as the collected data, is released to
facilitate further investigation in multimodal reasoning.",2024-12-23,"Wei Liu, Junlong Li, Xiwen Zhang, Fan Zhou, Yu Cheng, Junxian He",http://arxiv.org/pdf/2412.17451v1,cs.LG
Applying LLM and Topic Modelling in Psychotherapeutic Contexts,"This study explores the use of Large language models to analyze therapist
remarks in a psychotherapeutic setting. The paper focuses on the application of
BERTopic, a machine learning-based topic modeling tool, to the dialogue of two
different groups of therapists (classical and modern), which makes it possible
to identify and describe a set of topics that consistently emerge across these
groups. The paper describes in detail the chosen algorithm for BERTopic, which
included creating a vector space from a corpus of therapist remarks, reducing
its dimensionality, clustering the space, and creating and optimizing topic
representation. Along with the automatic topical modeling by the BERTopic, the
research involved an expert assessment of the findings and manual topic
structure optimization. The topic modeling results highlighted the most common
and stable topics in therapists speech, offering insights into how language
patterns in therapy develop and remain stable across different therapeutic
styles. This work contributes to the growing field of machine learning in
psychotherapy by demonstrating the potential of automated methods to improve
both the practice and training of therapists. The study highlights the value of
topic modeling as a tool for gaining a deeper understanding of therapeutic
dialogue and offers new opportunities for improving therapeutic effectiveness
and clinical supervision.",2024-12-23,"Alexander Vanin, Vadim Bolshev, Anastasia Panfilova",http://arxiv.org/pdf/2412.17449v1,cs.LG
Markov Process-Based Graph Convolutional Networks for Entity Classification in Knowledge Graphs,"Despite the vast amount of information encoded in Knowledge Graphs (KGs),
information about the class affiliation of entities remains often incomplete.
Graph Convolutional Networks (GCNs) have been shown to be effective predictors
of complete information about the class affiliation of entities in KGs.
However, these models do not learn the class affiliation of entities in KGs
incorporating the complexity of the task, which negatively affects the models
prediction capabilities. To address this problem, we introduce a Markov
process-based architecture into well-known GCN architectures. This end-to-end
network learns the prediction of class affiliation of entities in KGs within a
Markov process. The number of computational steps is learned during training
using a geometric distribution. At the same time, the loss function combines
insights from the field of evidential learning. The experiments show a
performance improvement over existing models in several studied architectures
and datasets. Based on the chosen hyperparameters for the geometric
distribution, the expected number of computation steps can be adjusted to
improve efficiency and accuracy during training.",2024-12-23,"Johannes Mäkelburg, Yiwen Peng, Mehwish Alam, Tobias Weller, Maribel Acosta",http://arxiv.org/pdf/2412.17438v2,cs.LG
Pretraining with random noise for uncertainty calibration,"Uncertainty calibration is crucial for various machine learning applications,
yet it remains challenging. Many models exhibit hallucinations - confident yet
inaccurate responses - due to miscalibrated confidence. Here, we show that the
common practice of random initialization in deep learning, often considered a
standard technique, is an underlying cause of this miscalibration, leading to
excessively high confidence in untrained networks. Our method, inspired by
developmental neuroscience, addresses this issue by simply pretraining networks
with random noise and labels, reducing overconfidence and bringing initial
confidence levels closer to chance. This ensures optimal calibration, aligning
confidence with accuracy during subsequent data training, without the need for
additional pre- or post-processing. Pre-calibrated networks excel at
identifying ""unknown data,"" showing low confidence for out-of-distribution
inputs, thereby resolving confidence miscalibration.",2024-12-23,"Jeonghwan Cheon, Se-Bum Paik",http://arxiv.org/pdf/2412.17411v2,cs.LG
Towards Intrinsic Self-Correction Enhancement in Monte Carlo Tree Search Boosted Reasoning via Iterative Preference Learning,"With current state-of-the-art approaches aimed at enhancing the reasoning
capabilities of Large Language Models(LLMs) through iterative preference
learning inspired by AlphaZero, we propose to further enhance the step-wise
reasoning capabilities through intrinsic self-correction to some extent. Our
work leverages step-wise preference learning to enhance self-verification via
reinforcement learning. We initially conduct our work through a two-stage
training procedure. At the first stage, the self-correction reasoning ability
of an LLM is enhanced through its own predictions, relying entirely on
self-generated data within the intrinsic self-correction to some extent. At the
second stage, the baseline step-wise preference learning is leveraged via the
application of the enhanced self-correct policy achieved at the first stage. In
the evaluation of arithmetic reasoning tasks, our approach outperforms
OpenMath2-Llama3.1-8B, dart-math-mistral-7b-uniform on MATH with increases in
accuracy to 71.34%(+4.18%) and 48.06%(+4.94%) and LLama-3.1-8B-Instruct,
Mistral-7B-Instruct-v0.1 on GSM8K with increases in accuracy to 86.76%(+2.00%)
and 38.06%(+2.28%).",2024-12-23,"Huchen Jiang, Yangyang Ma, Chaofan Ding, Kexin Luan, Xinhan Di",http://arxiv.org/pdf/2412.17397v1,cs.LG
How Green Can AI Be? A Study of Trends in Machine Learning Environmental Impacts,"The compute requirements associated with training Artificial Intelligence
(AI) models have increased exponentially over time. Optimisation strategies aim
to reduce the energy consumption and environmental impacts associated with AI,
possibly shifting impacts from the use phase to the manufacturing phase in the
life-cycle of hardware. This paper investigates the evolution of individual
graphics cards production impacts and of the environmental impacts associated
with training Machine Learning (ML) models over time. We collect information on
graphics cards used to train ML models and released between 2013 and 2023. We
assess the environmental impacts associated with the production of each card to
visualize the trends on the same period. Then, using information on notable AI
systems from the Epoch AI dataset we assess the environmental impacts
associated with training each system. The environmental impacts of graphics
cards production have increased continuously. The energy consumption and
environmental impacts associated with training models have increased
exponentially, even when considering reduction strategies such as location
shifting to places with less carbon intensive electricity mixes. These results
suggest that current impact reduction strategies cannot curb the growth in the
environmental impacts of AI. This is consistent with rebound effect, where the
efficiency increases fuel the creation of even larger models thereby cancelling
the potential impact reduction. Furthermore, these results highlight the
importance of considering the impacts of hardware over the entire life-cycle
rather than the sole usage phase in order to avoid impact shifting. The
environmental impact of AI cannot be reduced without reducing AI activities as
well as increasing efficiency.",2024-12-23,"Clément Morand, Anne-Laure Ligozat, Aurélie Névéol",http://arxiv.org/pdf/2412.17376v1,cs.LG
Bi-Directional Multi-Scale Graph Dataset Condensation via Information Bottleneck,"Dataset condensation has significantly improved model training efficiency,
but its application on devices with different computing power brings new
requirements for different data sizes. Thus, condensing multiple scale graphs
simultaneously is the core of achieving efficient training in different
on-device scenarios. Existing efficient works for multi-scale graph dataset
condensation mainly perform efficient approximate computation in scale order
(large-to-small or small-to-large scales). However, for non-Euclidean
structures of sparse graph data, these two commonly used paradigms for
multi-scale graph dataset condensation have serious scaling down degradation
and scaling up collapse problems of a graph. The main bottleneck of the above
paradigms is whether the effective information of the original graph is fully
preserved when consenting to the primary sub-scale (the first of multiple
scales), which determines the condensation effect and consistency of all
scales. In this paper, we proposed a novel GNN-centric Bi-directional
Multi-Scale Graph Dataset Condensation (BiMSGC) framework, to explore unifying
paradigms by operating on both large-to-small and small-to-large for
multi-scale graph condensation. Based on the mutual information theory, we
estimate an optimal ``meso-scale'' to obtain the minimum necessary dense graph
preserving the maximum utility information of the original graph, and then we
achieve stable and consistent ``bi-directional'' condensation learning by
optimizing graph eigenbasis matching with information bottleneck on other
scales. Encouraging empirical results on several datasets demonstrates the
significant superiority of the proposed framework in graph condensation at
different scales.",2024-12-23,"Xingcheng Fu, Yisen Gao, Beining Yang, Yuxuan Wu, Haodong Qian, Qingyun Sun, Xianxian Li",http://arxiv.org/pdf/2412.17355v1,cs.LG
Efficacy of Full-Packet Encryption in Mitigating Protocol Detection for Evasive Virtual Private Networks,"Full-packet encryption is a technique used by modern evasive Virtual Private
Networks (VPNs) to avoid protocol-based flagging from censorship models by
disguising their traffic as random noise on the network. Traditional methods
for censoring full-packet-encryption based VPN protocols requires assuming a
substantial amount of collateral damage, as other non-VPN network traffic that
appears random will be blocked. I tested several machine learning-based
classification models against the Aggressive Circumvention of Censorship (ACC)
protocol, a fully-encrypted evasive VPN protocol which merges strategies from a
wide variety of currently in-use evasive VPN protocols. My testing found that
while ACC was able to survive our models when compared to random noise, it was
easily detectable with minimal collateral damage using several different
machine learning models when within a stream of regular network traffic. While
resistant to the current techniques deployed by nation-state censors, the ACC
protocol and other evasive protocols are potentially subject to packet-based
protocol identification utilizing similar classification models.",2024-12-23,Amy Iris Parker,http://arxiv.org/pdf/2412.17352v1,cs.LG
ORIGAMI: A generative transformer architecture for predictions from semi-structured data,"Despite the popularity and widespread use of semi-structured data formats
such as JSON, end-to-end supervised learning applied directly to such data
remains underexplored. We present ORIGAMI (Object RepresentatIon via Generative
Autoregressive ModellIng), a transformer-based architecture that directly
processes nested key/value pairs while preserving their hierarchical semantics.
Our key technical contributions include: (1) a structure-preserving tokenizer,
(2) a novel key/value position encoding scheme, and (3) a grammar-constrained
training and inference framework that ensures valid outputs and accelerates
training convergence. These enhancements enable efficient end-to-end modeling
of semi-structured data. By reformulating classification as next-token
prediction, ORIGAMI naturally handles both single-label and multi-label tasks
without architectural modifications. Empirical evaluation across diverse
domains demonstrates ORIGAMI's effectiveness: On standard tabular benchmarks
converted to JSON, ORIGAMI remains competitive with classical and
state-of-the-art approaches. On native JSON datasets, we outperform baselines
on multi-label classification and specialized models such as convolutional and
graph neural networks on a code classification task. Through extensive ablation
studies, we validate the impact of each architectural component and establish
ORIGAMI as a robust framework for end-to-end learning on semi-structured data.",2024-12-23,"Thomas Rückstieß, Alana Huang, Robin Vujanic",http://arxiv.org/pdf/2412.17348v1,cs.LG
Three-Class Text Sentiment Analysis Based on LSTM,"Sentiment analysis is a crucial task in natural language processing (NLP)
with applications in public opinion monitoring, market research, and beyond.
This paper introduces a three-class sentiment classification method for Weibo
comments using Long Short-Term Memory (LSTM) networks to discern positive,
neutral, and negative sentiments. LSTM, as a deep learning model, excels at
capturing long-distance dependencies in text data, providing significant
advantages over traditional machine learning approaches. Through preprocessing
and feature extraction from Weibo comment texts, our LSTM model achieves
precise sentiment prediction. Experimental results demonstrate superior
performance, achieving an accuracy of 98.31% and an F1 score of 98.28%, notably
outperforming conventional models and other deep learning methods. This
underscores the effectiveness of LSTM in capturing nuanced sentiment
information within text, thereby enhancing classification accuracy. Despite its
strengths, the LSTM model faces challenges such as high computational
complexity and slower processing times for lengthy texts. Moreover, complex
emotional expressions like sarcasm and humor pose additional difficulties.
Future work could explore combining pre-trained models or advancing feature
engineering techniques to further improve both accuracy and practicality.
Overall, this study provides an effective solution for sentiment analysis on
Weibo comments.",2024-12-23,Yin Qixuan,http://arxiv.org/pdf/2412.17347v1,cs.LG
On the Power and Limitations of Examples for Description Logic Concepts,"Labeled examples (i.e., positive and negative examples) are an attractive
medium for communicating complex concepts. They are useful for deriving concept
expressions (such as in concept learning, interactive concept specification,
and concept refinement) as well as for illustrating concept expressions to a
user or domain expert. We investigate the power of labeled examples for
describing description-logic concepts. Specifically, we systematically study
the existence and efficient computability of finite characterisations, i.e.
finite sets of labeled examples that uniquely characterize a single concept,
for a wide variety of description logics between EL and ALCQI, both without an
ontology and in the presence of a DL-Lite ontology. Finite characterisations
are relevant for debugging purposes, and their existence is a necessary
condition for exact learnability with membership queries.",2024-12-23,"Balder ten Cate, Raoul Koudijs, Ana Ozaki",http://arxiv.org/pdf/2412.17345v1,cs.LG
Reinforcement Learning with a Focus on Adjusting Policies to Reach Targets,"The objective of a reinforcement learning agent is to discover better actions
through exploration. However, typical exploration techniques aim to maximize
rewards, often incurring high costs in both exploration and learning processes.
We propose a novel deep reinforcement learning method, which prioritizes
achieving an aspiration level over maximizing expected return. This method
flexibly adjusts the degree of exploration based on the proportion of target
achievement. Through experiments on a motion control task and a navigation
task, this method achieved returns equal to or greater than other standard
methods. The results of the analysis showed two things: our method flexibly
adjusts the exploration scope, and it has the potential to enable the agent to
adapt to non-stationary environments. These findings indicated that this method
may have effectiveness in improving exploration efficiency in practical
applications of reinforcement learning.",2024-12-23,"Akane Tsuboya, Yu Kono, Tatsuji Takahashi",http://arxiv.org/pdf/2412.17344v1,cs.LG
APEX$^2$: Adaptive and Extreme Summarization for Personalized Knowledge Graphs,"Knowledge graphs (KGs), which store an extensive number of relational facts,
serve various applications. Recently, personalized knowledge graphs (PKGs) have
emerged as a solution to optimize storage costs by customizing their content to
align with users' specific interests within particular domains. In the real
world, on one hand, user queries and their underlying interests are inherently
evolving, requiring PKGs to adapt continuously; on the other hand, the
summarization is constantly expected to be as small as possible in terms of
storage cost. However, the existing PKG summarization methods implicitly assume
that the user's interests are constant and do not shift. Furthermore, when the
size constraint of PKG is extremely small, the existing methods cannot
distinguish which facts are more of immediate interest and guarantee the
utility of the summarized PKG. To address these limitations, we propose
APEX$^2$, a highly scalable PKG summarization framework designed with robust
theoretical guarantees to excel in adaptive summarization tasks with extremely
small size constraints. To be specific, after constructing an initial PKG,
APEX$^2$ continuously tracks the interest shift and adjusts the previous
summary. We evaluate APEX$^2$ under an evolving query setting on benchmark KGs
containing up to 12 million triples, summarizing with compression ratios $\leq
0.1\%$. The experiments show that APEX outperforms state-of-the-art baselines
in terms of both query-answering accuracy and efficiency.",2024-12-23,"Zihao Li, Dongqi Fu, Mengting Ai, Jingrui He",http://arxiv.org/pdf/2412.17336v1,cs.LG
Broadband Ground Motion Synthesis by Diffusion Model with Minimal Condition,"Earthquakes are rare. Hence there is a fundamental call for reliable methods
to generate realistic ground motion data for data-driven approaches in
seismology. Recent GAN-based methods fall short of the call, as the methods
either require special information such as geological traits or generate subpar
waveforms that fail to satisfy seismological constraints such as phase arrival
times. We propose a specialized Latent Diffusion Model (LDM) that reliably
generates realistic waveforms after learning from real earthquake data with
minimal conditions: location and magnitude. We also design a domain-specific
training method that exploits the traits of earthquake dataset: multiple
observed waveforms time-aligned and paired to each earthquake source that are
tagged with seismological metadata comprised of earthquake magnitude, depth of
focus, and the locations of epicenter and seismometers. We construct the
time-aligned earthquake dataset using Southern California Earthquake Data
Center (SCEDC) API, and train our model with the dataset and our proposed
training method for performance evaluation. Our model surpasses all comparable
data-driven methods in various test criteria not only from waveform generation
domain but also from seismology such as phase arrival time, GMPE analysis, and
spectrum analysis. Our result opens new future research directions for deep
learning applications in seismology.",2024-12-23,"Jaeheun Jung, Jaehyuk Lee, Chang-Hae Jung, Hanyoung Kim, Bosung Jung, Donghun Lee",http://arxiv.org/pdf/2412.17333v1,cs.LG
EcoSearch: A Constant-Delay Best-First Search Algorithm for Program Synthesis,"Many approaches to program synthesis perform a combinatorial search within a
large space of programs to find one that satisfies a given specification. To
tame the search space blowup, previous works introduced probabilistic and
neural approaches to guide this combinatorial search by inducing heuristic cost
functions. Best-first search algorithms ensure to search in the exact order
induced by the cost function, significantly reducing the portion of the program
space to be explored. We present a new best-first search algorithm called
EcoSearch, which is the first constant-delay algorithm for pre-generation cost
function: the amount of compute required between outputting two programs is
constant, and in particular does not increase over time. This key property
yields important speedups: we observe that EcoSearch outperforms its
predecessors on two classic domains.",2024-12-23,"Théo Matricon, Nathanaël Fijalkow, Guillaume Lagarde",http://arxiv.org/pdf/2412.17330v1,cs.LG
xPatch: Dual-Stream Time Series Forecasting with Exponential Seasonal-Trend Decomposition,"In recent years, the application of transformer-based models in time-series
forecasting has received significant attention. While often demonstrating
promising results, the transformer architecture encounters challenges in fully
exploiting the temporal relations within time series data due to its attention
mechanism. In this work, we design eXponential Patch (xPatch for short), a
novel dual-stream architecture that utilizes exponential decomposition.
Inspired by the classical exponential smoothing approaches, xPatch introduces
the innovative seasonal-trend exponential decomposition module. Additionally,
we propose a dual-flow architecture that consists of an MLP-based linear stream
and a CNN-based non-linear stream. This model investigates the benefits of
employing patching and channel-independence techniques within a non-transformer
model. Finally, we develop a robust arctangent loss function and a sigmoid
learning rate adjustment scheme, which prevent overfitting and boost
forecasting performance. The code is available at the following repository:
https://github.com/stitsyuk/xPatch.",2024-12-23,"Artyom Stitsyuk, Jaesik Choi",http://arxiv.org/pdf/2412.17323v3,cs.LG
In Defence of Post-hoc Explainability,"The widespread adoption of machine learning in scientific research has
created a fundamental tension between model opacity and scientific
understanding. Whilst some advocate for intrinsically interpretable models, we
introduce Computational Interpretabilism (CI) as a philosophical framework for
post-hoc interpretability in scientific AI. Drawing parallels with human
expertise, where post-hoc rationalisation coexists with reliable performance,
CI establishes that scientific knowledge emerges through structured model
interpretation when properly bounded by empirical validation. Through mediated
understanding and bounded factivity, we demonstrate how post-hoc methods
achieve epistemically justified insights without requiring complete mechanical
transparency, resolving tensions between model complexity and scientific
comprehension.",2024-12-23,Nick Oh,http://arxiv.org/pdf/2412.17883v1,cs.LG
Better Knowledge Enhancement for Privacy-Preserving Cross-Project Defect Prediction,"Cross-Project Defect Prediction (CPDP) poses a non-trivial challenge to
construct a reliable defect predictor by leveraging data from other projects,
particularly when data owners are concerned about data privacy. In recent
years, Federated Learning (FL) has become an emerging paradigm to guarantee
privacy information by collaborative training a global model among multiple
parties without sharing raw data. While the direct application of FL to the
CPDP task offers a promising solution to address privacy concerns, the data
heterogeneity arising from proprietary projects across different companies or
organizations will bring troubles for model training. In this paper, we study
the privacy-preserving cross-project defect prediction with data heterogeneity
under the federated learning framework. To address this problem, we propose a
novel knowledge enhancement approach named FedDP with two simple but effective
solutions: 1. Local Heterogeneity Awareness and 2. Global Knowledge
Distillation. Specifically, we employ open-source project data as the
distillation dataset and optimize the global model with the heterogeneity-aware
local model ensemble via knowledge distillation. Experimental results on 19
projects from two datasets demonstrate that our method significantly
outperforms baselines.",2024-12-23,"Yuying Wang, Yichen Li, Haozhao Wang, Lei Zhao, Xiaofang Zhang",http://arxiv.org/pdf/2412.17317v1,cs.LG
Fast Gradient Computation for RoPE Attention in Almost Linear Time,"The Rotary Position Embedding (RoPE) mechanism has become a powerful
enhancement to the Transformer architecture, which enables models to capture
token relationships when encoding positional information. However, the RoPE
mechanisms make the computations of attention mechanisms more complicated,
which makes efficient algorithms challenging. Earlier research introduced
almost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens,
algorithms for the forward computation under specific parameter settings.
However, achieving a subquadratic time algorithm for other parameter regimes
remains impossible unless the widely accepted Strong Exponential Time
Hypothesis (SETH) is disproven. In this work, we develop the first almost
linear time algorithm for backward computations in the RoPE-based attention
under bounded entries. Our approach builds on recent advancements in fast RoPE
attention computations, utilizing a novel combination of the polynomial method
and the Fast Fourier Transform. Furthermore, we show that with lower bounds
derived from the SETH, the bounded entry condition is necessary for
subquadratic performance.",2024-12-23,"Yifang Chen, Jiayan Huo, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song",http://arxiv.org/pdf/2412.17316v2,cs.LG
Collaborative Optimization in Financial Data Mining Through Deep Learning and ResNeXt,"This study proposes a multi-task learning framework based on ResNeXt, aiming
to solve the problem of feature extraction and task collaborative optimization
in financial data mining. Financial data usually has the complex
characteristics of high dimensionality, nonlinearity, and time series, and is
accompanied by potential correlations between multiple tasks, making it
difficult for traditional methods to meet the needs of data mining. This study
introduces the ResNeXt model into the multi-task learning framework and makes
full use of its group convolution mechanism to achieve efficient extraction of
local patterns and global features of financial data. At the same time, through
the design of task sharing layers and dedicated layers, it is established
between multiple related tasks. Deep collaborative optimization relationships.
Through flexible multi-task loss weight design, the model can effectively
balance the learning needs of different tasks and improve overall performance.
Experiments are conducted on a real S&P 500 financial data set, verifying the
significant advantages of the proposed framework in classification and
regression tasks. The results indicate that, when compared to other
conventional deep learning models, the proposed method delivers superior
performance in terms of accuracy, F1 score, root mean square error, and other
metrics, highlighting its outstanding effectiveness and robustness in handling
complex financial data. This research provides an efficient and adaptable
solution for financial data mining, and at the same time opens up a new
research direction for the combination of multi-task learning and deep
learning, which has important theoretical significance and practical
application value.",2024-12-23,"Pengbin Feng, Yankaiqi Li, Yijiashun Qi, Xiaojun Guo, Zhenghao Lin",http://arxiv.org/pdf/2412.17314v1,cs.LG
Improving Pareto Set Learning for Expensive Multi-objective Optimization via Stein Variational Hypernetworks,"Expensive multi-objective optimization problems (EMOPs) are common in
real-world scenarios where evaluating objective functions is costly and
involves extensive computations or physical experiments. Current Pareto set
learning methods for such problems often rely on surrogate models like Gaussian
processes to approximate the objective functions. These surrogate models can
become fragmented, resulting in numerous small uncertain regions between
explored solutions. When using acquisition functions such as the Lower
Confidence Bound (LCB), these uncertain regions can turn into pseudo-local
optima, complicating the search for globally optimal solutions. To address
these challenges, we propose a novel approach called SVH-PSL, which integrates
Stein Variational Gradient Descent (SVGD) with Hypernetworks for efficient
Pareto set learning. Our method addresses the issues of fragmented surrogate
models and pseudo-local optima by collectively moving particles in a manner
that smooths out the solution space. The particles interact with each other
through a kernel function, which helps maintain diversity and encourages the
exploration of underexplored regions. This kernel-based interaction prevents
particles from clustering around pseudo-local optima and promotes convergence
towards globally optimal solutions. Our approach aims to establish robust
relationships between trade-off reference vectors and their corresponding true
Pareto solutions, overcoming the limitations of existing methods. Through
extensive experiments across both synthetic and real-world MOO benchmarks, we
demonstrate that SVH-PSL significantly improves the quality of the learned
Pareto set, offering a promising solution for expensive multi-objective
optimization problems.",2024-12-23,"Minh-Duc Nguyen, Phuong Mai Dinh, Quang-Huy Nguyen, Long P. Hoang, Dung D. Le",http://arxiv.org/pdf/2412.17312v3,cs.LG
Exploiting Label Skewness for Spiking Neural Networks in Federated Learning,"The energy efficiency of deep spiking neural networks (SNNs) aligns with the
constraints of resource-limited edge devices, positioning SNNs as a promising
foundation for intelligent applications leveraging the extensive data collected
by these devices. To address data privacy concerns when deploying SNNs on edge
devices, federated learning (FL) facilitates collaborative model training by
leveraging data distributed across edge devices without transmitting local data
to a central server. However, existing FL approaches struggle with label-skewed
data across devices, which leads to drift in local SNN models and degrades the
performance of the global SNN model. In this paper, we propose a novel
framework called FedLEC, which incorporates intra-client label weight
calibration to balance the learning intensity across local labels and
inter-client knowledge distillation to mitigate local SNN model bias caused by
label absence. Extensive experiments with three different structured SNNs
across five datasets (i.e., three non-neuromorphic and two neuromorphic
datasets) demonstrate the efficiency of FedLEC. Compared to eight
state-of-the-art FL algorithms, FedLEC achieves an average accuracy improvement
of approximately 11.59% for the global SNN model under various label skew
distribution settings.",2024-12-23,"Di Yu, Xin Du, Linshan Jiang, Huijing Zhang, Shunwen Bai, Shuiguang Deng",http://arxiv.org/pdf/2412.17305v2,cs.LG
Enabling Time-series Foundation Model for Building Energy Forecasting via Contrastive Curriculum Learning,"Advances in time-series forecasting are driving a shift from conventional
machine learning models to foundation models (FMs) that are trained with
generalized knowledge. However, existing FMs still perform poorly in the energy
fields, such as building energy forecasting (BEF). This paper studies the
adaptation of FM to BEF tasks. We demonstrate the shortcomings of fine-tuning
FM straightforwardly from both the perspectives of FM and the data. To overcome
these limitations, we propose a new \textit{contrastive curriculum
learning}-based training method. Our method optimizes the ordering of training
data in the context of TSFM adaptation. Experiments show that our method can
improve the zero/few-shot performance by 14.6\% compared to the existing FMs.
Our code and new TSFM will be available at <Anonymous Github Repo>.",2024-12-23,"Rui Liang, Yang Deng, Donghua Xie, Fang He, Dan Wang",http://arxiv.org/pdf/2412.17285v1,cs.LG
Emerging Microelectronic Materials by Design: Navigating Combinatorial Design Space with Scarce and Dispersed Data,"The increasing demands of sustainable energy, electronics, and biomedical
applications call for next-generation functional materials with unprecedented
properties. Of particular interest are emerging materials that display
exceptional physical properties, making them promising candidates in
energy-efficient microelectronic devices. As the conventional Edisonian
approach becomes significantly outpaced by growing societal needs, emerging
computational modeling and machine learning (ML) methods are employed for the
rational design of materials. However, the complex physical mechanisms, cost of
first-principles calculations, and the dispersity and scarcity of data pose
challenges to both physics-based and data-driven materials modeling. Moreover,
the combinatorial composition-structure design space is high-dimensional and
often disjoint, making design optimization nontrivial. In this Account, we
review a team effort toward establishing a framework that integrates
data-driven and physics-based methods to address these challenges and
accelerate materials design. We begin by presenting our integrated materials
design framework and its three components in a general context. We then provide
an example of applying this materials design framework to metal-insulator
transition (MIT) materials, a specific type of emerging materials with
practical importance in next-generation memory technologies. We identify
multiple new materials which may display this property and propose pathways for
their synthesis. Finally, we identify some outstanding challenges in
data-driven materials design, such as materials data quality issues and
property-performance mismatch. We seek to raise awareness of these overlooked
issues hindering materials design, thus stimulating efforts toward developing
methods to mitigate the gaps.",2024-12-23,"Hengrui Zhang, Alexandru B. Georgescu, Suraj Yerramilli, Christopher Karpovich, Daniel W. Apley, Elsa A. Olivetti, James M. Rondinelli, Wei Chen",http://arxiv.org/pdf/2412.17283v2,cs.LG
Non-Convex Tensor Recovery from Local Measurements,"Motivated by the settings where sensing the entire tensor is infeasible, this
paper proposes a novel tensor compressed sensing model, where measurements are
only obtained from sensing each lateral slice via mutually independent
matrices. Leveraging the low tubal rank structure, we reparameterize the
unknown tensor ${\boldsymbol {\mathcal X}}^\star$ using two compact tensor
factors and formulate the recovery problem as a nonconvex minimization problem.
To solve the problem, we first propose an alternating minimization algorithm,
termed \textsf{Alt-PGD-Min}, that iteratively optimizes the two factors using a
projected gradient descent and an exact minimization step, respectively.
Despite nonconvexity, we prove that \textsf{Alt-PGD-Min} achieves
$\epsilon$-accuracy recovery with $\mathcal O\left( \kappa^2 \log
\frac{1}{\epsilon}\right)$ iteration complexity and $\mathcal O\left(
\kappa^6rn_3\log n_3 \left( \kappa^2r\left(n_1 + n_2 \right) + n_1 \log
\frac{1}{\epsilon}\right) \right)$ sample complexity, where $\kappa$ denotes
tensor condition number of $\boldsymbol{\mathcal X}^\star$. To further
accelerate the convergence, especially when the tensor is ill-conditioned with
large $\kappa$, we prove \textsf{Alt-ScalePGD-Min} that preconditions the
gradient update using an approximate Hessian that can be computed efficiently.
We show that \textsf{Alt-ScalePGD-Min} achieves $\kappa$ independent iteration
complexity $\mathcal O(\log \frac{1}{\epsilon})$ and improves the sample
complexity to $\mathcal O\left( \kappa^4 rn_3 \log n_3 \left(
\kappa^4r(n_1+n_2) + n_1 \log \frac{1}{\epsilon}\right) \right)$. Experiments
validate the effectiveness of the proposed methods.",2024-12-23,"Tongle Wu, Ying Sun, Jicong Fan",http://arxiv.org/pdf/2412.17281v1,cs.LG
Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning,"Fuzzy Graph Attention Network (FGAT), which combines Fuzzy Rough Sets and
Graph Attention Networks, has shown promise in tasks requiring robust
graph-based learning. However, existing models struggle to effectively capture
dependencies from multiple perspectives, limiting their ability to model
complex data. To address this gap, we propose the Multi-view Fuzzy Graph
Attention Network (MFGAT), a novel framework that constructs and aggregates
multi-view information using a specially designed Transformation Block. This
block dynamically transforms data from multiple aspects and aggregates the
resulting representations via a weighted sum mechanism, enabling comprehensive
multi-view modeling. The aggregated information is fed into FGAT to enhance
fuzzy graph convolutions. Additionally, we introduce a simple yet effective
learnable global pooling mechanism for improved graph-level understanding.
Extensive experiments on graph classification tasks demonstrate that MFGAT
outperforms state-of-the-art baselines, underscoring its effectiveness and
versatility.",2024-12-23,"Jinming Xing, Dongwen Luo, Qisen Cheng, Chang Xue, Ruilin Xing",http://arxiv.org/pdf/2412.17271v1,cs.LG
An Intrinsically Explainable Approach to Detecting Vertebral Compression Fractures in CT Scans via Neurosymbolic Modeling,"Vertebral compression fractures (VCFs) are a common and potentially serious
consequence of osteoporosis. Yet, they often remain undiagnosed. Opportunistic
screening, which involves automated analysis of medical imaging data acquired
primarily for other purposes, is a cost-effective method to identify
undiagnosed VCFs. In high-stakes scenarios like opportunistic medical
diagnosis, model interpretability is a key factor for the adoption of AI
recommendations. Rule-based methods are inherently explainable and closely
align with clinical guidelines, but they are not immediately applicable to
high-dimensional data such as CT scans. To address this gap, we introduce a
neurosymbolic approach for VCF detection in CT volumes. The proposed model
combines deep learning (DL) for vertebral segmentation with a shape-based
algorithm (SBA) that analyzes vertebral height distributions in salient
anatomical regions. This allows for the definition of a rule set over the
height distributions to detect VCFs. Evaluation of VerSe19 dataset shows that
our method achieves an accuracy of 96% and a sensitivity of 91% in VCF
detection. In comparison, a black box model, DenseNet, achieved an accuracy of
95% and sensitivity of 91% in the same dataset. Our results demonstrate that
our intrinsically explainable approach can match or surpass the performance of
black box deep neural networks while providing additional insights into why a
prediction was made. This transparency can enhance clinician's trust thus,
supporting more informed decision-making in VCF diagnosis and treatment
planning.",2024-12-23,"Blanca Inigo, Yiqing Shen, Benjamin D. Killeen, Michelle Song, Axel Krieger, Christopher Bradley, Mathias Unberath",http://arxiv.org/pdf/2412.17258v1,cs.LG
B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners,"In the absence of extensive human-annotated data for complex reasoning tasks,
self-improvement -- where models are trained on their own outputs -- has
emerged as a primary method for enhancing performance. However, the critical
factors underlying the mechanism of these iterative self-improving methods
remain poorly understood, such as under what conditions self-improvement is
effective, and what are the bottlenecks in the current iterations. In this
work, we identify and propose methods to monitor two pivotal factors in this
iterative process: (1) the model's ability to generate sufficiently diverse
responses (exploration); and (2) the effectiveness of external rewards in
distinguishing high-quality candidates from lower-quality ones (exploitation).
Using mathematical reasoning as a case study, we begin with a quantitative
analysis to track the dynamics of exploration and exploitation, discovering
that a model's exploratory capabilities rapidly deteriorate over iterations,
and the effectiveness of exploiting external rewards diminishes as well.
Motivated by these findings, we introduce B-STaR, a Self-Taught Reasoning
framework that autonomously adjusts configurations across iterations to Balance
exploration and exploitation, thereby optimizing the self-improving
effectiveness based on the current policy model and available rewards. Our
experiments on mathematical reasoning, coding, and commonsense reasoning
demonstrate that B-STaR not only enhances the model's exploratory capabilities
throughout training but also achieves a more effective balance between
exploration and exploitation, leading to superior performance.",2024-12-23,"Weihao Zeng, Yuzhen Huang, Lulu Zhao, Yijun Wang, Zifei Shan, Junxian He",http://arxiv.org/pdf/2412.17256v2,cs.LG
"Enhancing Multi-Text Long Video Generation Consistency without Tuning: Time-Frequency Analysis, Prompt Alignment, and Theory","Despite the considerable progress achieved in the long video generation
problem, there is still significant room to improve the consistency of the
videos, particularly in terms of smoothness and transitions between scenes. We
address these issues to enhance the consistency and coherence of videos
generated with either single or multiple prompts. We propose the Time-frequency
based temporal Attention Reweighting Algorithm (TiARA), which meticulously
edits the attention score matrix based on the Discrete Short-Time Fourier
Transform. Our method is supported by a theoretical guarantee, the
first-of-its-kind for frequency-based methods in diffusion models. For videos
generated by multiple prompts, we further investigate key factors affecting
prompt interpolation quality and propose PromptBlend, an advanced prompt
interpolation pipeline. The efficacy of our proposed method is validated via
extensive experimental results, exhibiting consistent and impressive
improvements over baseline methods. The code will be released upon acceptance.",2024-12-23,"Xingyao Li, Fengzhuo Zhang, Jiachun Pan, Yunlong Hou, Vincent Y. F. Tan, Zhuoran Yang",http://arxiv.org/pdf/2412.17254v1,cs.LG
A Coalition Game for On-demand Multi-modal 3D Automated Delivery System,"We introduce a multi-modal autonomous delivery optimization framework as a
coalition game for a fleet of UAVs and ADRs operating in two overlaying
networks to address last-mile delivery in urban environments, including
high-density areas, road-based routing, and real-world operational challenges.
The problem is defined as multiple depot pickup and delivery with time windows
constrained over operational restrictions, such as vehicle battery limitation,
precedence time window, and building obstruction. Subsequently, the coalition
game theory is applied to investigate cooperation structures among the modes to
capture how strategic collaboration among vehicles can improve overall routing
efficiency. To do so, a generalized reinforcement learning model is designed to
evaluate the cost-sharing and allocation to different coalitions for which
sub-additive property and non-empty core exist. Our methodology leverages an
end-to-end deep multi-agent policy gradient method augmented by a novel
spatio-temporal adjacency neighbourhood graph attention network and transformer
architecture using a heterogeneous edge-enhanced attention model. Conducting
several numerical experiments on last-mile delivery applications, the result
from the case study in the city of Mississauga shows that despite the
incorporation of an extensive network in the graph for two modes and a complex
training structure, the model addresses realistic operational constraints and
achieves high-quality solutions compared with the existing transformer-based
and heuristics methods and can perform well on non-homogeneous data
distribution, generalizes well on the different scale and configuration, and
demonstrate a robust performance under stochastic scenarios subject to wind
speed and direction.",2024-12-23,"Farzan Moosavi, Bilal Farooq",http://arxiv.org/pdf/2412.17252v1,cs.LG
GCS-M3VLT: Guided Context Self-Attention based Multi-modal Medical Vision Language Transformer for Retinal Image Captioning,"Retinal image analysis is crucial for diagnosing and treating eye diseases,
yet generating accurate medical reports from images remains challenging due to
variability in image quality and pathology, especially with limited labeled
data. Previous Transformer-based models struggled to integrate visual and
textual information under limited supervision. In response, we propose a novel
vision-language model for retinal image captioning that combines visual and
textual features through a guided context self-attention mechanism. This
approach captures both intricate details and the global clinical context, even
in data-scarce scenarios. Extensive experiments on the DeepEyeNet dataset
demonstrate a 0.023 BLEU@4 improvement, along with significant qualitative
advancements, highlighting the effectiveness of our model in generating
comprehensive medical captions.",2024-12-23,"Teja Krishna Cherukuri, Nagur Shareef Shaik, Jyostna Devi Bodapati, Dong Hye Ye",http://arxiv.org/pdf/2412.17251v1,cs.LG
Highly Optimized Kernels and Fine-Grained Codebooks for LLM Inference on Arm CPUs,"Large language models (LLMs) have transformed the way we think about language
understanding and generation, enthralling both researchers and developers.
However, deploying LLMs for inference has been a significant challenge due to
their unprecedented size and resource requirements. While quantizing model
weights to sub-byte precision has emerged as a promising solution to ease
memory pressure, the group quantization formats commonly used for LLM
quantization have significant compute overheads and a resource-intensive
dequantization process. As a result, a higher proportion of compute
instructions do not perform multiplies, i.e., real work, rendering them
unsuitable for meeting the required latency requirements for LLMs deployed on
commodity CPUs. In this work, we propose a set of highly optimized kernels to
accelerate LLM inference and unleash the full potential of CPUs, particularly
Arm CPUs. These kernels amortize the cost of loading the operands and the cost
of weight unpacking across multiple output rows. This, along with the
introduction of an optimized interleaved group data layout for weights and
decompression path optimizations to reduce unnecessary operations and
dequantization overhead while maximizing the use of vector and matrix multiply
operations, significantly improves the efficiency of MAC operations.
Furthermore, we present a groupwise non-uniform codebook-based quantization
method for ultra-low-precision quantization of LLMs to better match non-uniform
patterns in their weight distributions, demonstrating better throughput during
token generation while ensuring better quality than the state-of-the-art.
Applying these improvements to 4-bit LLMs results in a 3-3.2x improvement in
prompt processing and a 2x improvement in autoregressive decoding on Arm CPUs,
compared to LLaMA.cpp-based solution. The optimized kernels are available at
https://github.com/ggerganov/llama.cpp.",2024-12-23,"Dibakar Gope, David Mansell, Danny Loh, Ian Bratt",http://arxiv.org/pdf/2501.00032v1,cs.LG
FedMeld: A Model-dispersal Federated Learning Framework for Space-ground Integrated Networks,"To bridge the digital divide, the space-ground integrated networks (SGINs),
which will be a key component of the six-generation (6G) mobile networks, are
expected to deliver artificial intelligence (AI) services to every corner of
the world. One mission of SGINs is to support federated learning (FL) at a
global scale. However, existing space-ground integrated FL frameworks involve
ground stations or costly inter-satellite links, entailing excessive training
latency and communication costs. To overcome these limitations, we propose an
infrastructure-free federated learning framework based on a model dispersal
(FedMeld) strategy, which exploits periodic movement patterns and
store-carry-forward capabilities of satellites to enable parameter mixing
across large-scale geographical regions. We theoretically show that FedMeld
leads to global model convergence and quantify the effects of round interval
and mixing ratio between adjacent areas on its learning performance. Based on
the theoretical results, we formulate a joint optimization problem to design
the staleness control and mixing ratio (SC-MR) for minimizing the training
loss. By decomposing the problem into sequential SC and MR subproblems without
compromising the optimality, we derive the round interval solution in a closed
form and the mixing ratio in a semi-closed form to achieve the \textit{optimal}
latency-accuracy tradeoff. Experiments using various datasets demonstrate that
FedMeld achieves superior model accuracy while significantly reducing
communication costs as compared with traditional FL schemes for SGINs.",2024-12-23,"Qian Chen, Xianhao Chen, Kaibin Huang",http://arxiv.org/pdf/2412.17231v1,cs.LG
Brain-to-Text Benchmark '24: Lessons Learned,"Speech brain-computer interfaces aim to decipher what a person is trying to
say from neural activity alone, restoring communication to people with
paralysis who have lost the ability to speak intelligibly. The Brain-to-Text
Benchmark '24 and associated competition was created to foster the advancement
of decoding algorithms that convert neural activity to text. Here, we summarize
the lessons learned from the competition ending on June 1, 2024 (the top 4
entrants also presented their experiences in a recorded webinar). The largest
improvements in accuracy were achieved using an ensembling approach, where the
output of multiple independent decoders was merged using a fine-tuned large
language model (an approach used by all 3 top entrants). Performance gains were
also found by improving how the baseline recurrent neural network (RNN) model
was trained, including by optimizing learning rate scheduling and by using a
diphone training objective. Improving upon the model architecture itself proved
more difficult, however, with attempts to use deep state space models or
transformers not yet appearing to offer a benefit over the RNN baseline. The
benchmark will remain open indefinitely to support further work towards
increasing the accuracy of brain-to-text algorithms.",2024-12-23,"Francis R. Willett, Jingyuan Li, Trung Le, Chaofei Fan, Mingfei Chen, Eli Shlizerman, Yue Chen, Xin Zheng, Tatsuo S. Okubo, Tyler Benster, Hyun Dong Lee, Maxwell Kounga, E. Kelly Buchanan, David Zoltowski, Scott W. Linderman, Jaimie M. Henderson",http://arxiv.org/pdf/2412.17227v1,cs.LG
MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching,"Clinical trials drive improvements in cancer treatments and outcomes.
However, most adults with cancer do not participate in trials, and trials often
fail to enroll enough patients to answer their scientific questions. Artificial
intelligence could accelerate matching of patients to appropriate clinical
trials. Here, we describe the development and evaluation of the MatchMiner-AI
pipeline for clinical trial searching and ranking. MatchMiner-AI focuses on
matching patients to potential trials based on core criteria describing
clinical ""spaces,"" or disease contexts, targeted by a trial. It aims to
accelerate the human work of identifying potential matches, not to fully
automate trial screening. The pipeline includes modules for extraction of key
information from a patient's longitudinal electronic health record; rapid
ranking of candidate trial-patient matches based on embeddings in vector space;
and classification of whether a candidate match represents a reasonable
clinical consideration. Code and synthetic data are available at
https://huggingface.co/ksg-dfci/MatchMiner-AI . Model weights based on
synthetic data are available at https://huggingface.co/ksg-dfci/TrialSpace and
https://huggingface.co/ksg-dfci/TrialChecker . A simple cancer clinical trial
search engine to demonstrate pipeline components is available at
https://huggingface.co/spaces/ksg-dfci/trial_search_alpha .",2024-12-23,"Ethan Cerami, Pavel Trukhanov, Morgan A. Paul, Michael J. Hassett, Irbaz B. Riaz, James Lindsay, Emily Mallaber, Harry Klein, Gufran Gungor, Matthew Galvin, Stephen C. Van Nostrand, Joyce Yu, Tali Mazor, Kenneth L. Kehl",http://arxiv.org/pdf/2412.17228v1,cs.LG
Machine learning and natural language processing models to predict the extent of food processing,"The dramatic increase in consumption of ultra-processed food has been
associated with numerous adverse health effects. Given the public health
consequences linked to ultra-processed food consumption, it is highly relevant
to build computational models to predict the processing of food products. We
created a range of machine learning, deep learning, and NLP models to predict
the extent of food processing by integrating the FNDDS dataset of food products
and their nutrient profiles with their reported NOVA processing level. Starting
with the full nutritional panel of 102 features, we further implemented
coarse-graining of features to 65 and 13 nutrients by dropping flavonoids and
then by considering the 13-nutrient panel of FDA, respectively. LGBM Classifier
and Random Forest emerged as the best model for 102 and 65 nutrients,
respectively, with an F1-score of 0.9411 and 0.9345 and MCC of 0.8691 and
0.8543. For the 13-nutrient panel, Gradient Boost achieved the best F1-score of
0.9284 and MCC of 0.8425. We also implemented NLP based models, which exhibited
state-of-the-art performance. Besides distilling nutrients critical for model
performance, we present a user-friendly web server for predicting processing
level based on the nutrient panel of a food product:
https://cosylab.iiitd.edu.in/food-processing/.",2024-12-23,"Nalin Arora, Sumit Bhagat, Riya Dhama, Ganesh Bagler",http://arxiv.org/pdf/2412.17217v1,cs.LG
Q-LIME $π$: A Quantum-Inspired Extension to LIME,"Machine learning models offer powerful predictive capabilities but often lack
transparency. Local Interpretable Model-agnostic Explanations (LIME) addresses
this by perturbing features and measuring their impact on a model's output. In
text-based tasks, LIME typically removes present words (bits set to 1) to
identify high-impact tokens. We propose \textbf{Q-LIME $\pi$} (Quantum LIME
$\pi$), a quantum-inspired extension of LIME that encodes a binary feature
vector in a quantum state, leveraging superposition and interference to explore
local neighborhoods more efficiently. Our method focuses on flipping bits from
$1 \rightarrow 0$ to emulate LIME's ``removal'' strategy, and can be extended
to $0 \rightarrow 1$ where adding features is relevant. Experiments on subsets
of the IMDb dataset demonstrate that Q-LIME $\pi$ often achieves near-identical
top-feature rankings compared to classical LIME while exhibiting lower runtime
in small- to moderate-dimensional feature spaces. This quantum-classical hybrid
approach thus provides a new pathway for interpretable AI, suggesting that,
with further improvements in quantum hardware and methods, quantum parallelism
may facilitate more efficient local explanations for high-dimensional data.",2024-12-23,Nelson Colón Vargas,http://arxiv.org/pdf/2412.17197v1,cs.LG
Hierarchically Gated Experts for Efficient Online Continual Learning,"Continual Learning models aim to learn a set of tasks under the constraint
that the tasks arrive sequentially with no way to access data from previous
tasks. The Online Continual Learning framework poses a further challenge where
the tasks are unknown and instead the data arrives as a single stream. Building
on existing work, we propose a method for identifying these underlying tasks:
the Gated Experts (GE) algorithm, where a dynamically growing set of experts
allows for new knowledge to be acquired without catastrophic forgetting.
Furthermore, we extend GE to Hierarchically Gated Experts (HGE), a method which
is able to efficiently select the best expert for each data sample by
organising the experts into a hierarchical structure. On standard Continual
Learning benchmarks, GE and HGE are able to achieve results comparable with
current methods, with HGE doing so more efficiently.",2024-12-22,"Kevin Luong, Michael Thielscher",http://arxiv.org/pdf/2412.17188v1,cs.LG
Foundation Model for Lossy Compression of Spatiotemporal Scientific Data,"We present a foundation model (FM) for lossy scientific data compression,
combining a variational autoencoder (VAE) with a hyper-prior structure and a
super-resolution (SR) module. The VAE framework uses hyper-priors to model
latent space dependencies, enhancing compression efficiency. The SR module
refines low-resolution representations into high-resolution outputs, improving
reconstruction quality. By alternating between 2D and 3D convolutions, the
model efficiently captures spatiotemporal correlations in scientific data while
maintaining low computational cost. Experimental results demonstrate that the
FM generalizes well to unseen domains and varying data shapes, achieving up to
4 times higher compression ratios than state-of-the-art methods after
domain-specific fine-tuning. The SR module improves compression ratio by 30
percent compared to simple upsampling techniques. This approach significantly
reduces storage and transmission costs for large-scale scientific simulations
while preserving data integrity and fidelity.",2024-12-22,"Xiao Li, Jaemoon Lee, Anand Rangarajan, Sanjay Ranka",http://arxiv.org/pdf/2412.17184v1,cs.LG
Thermodynamic computing out of equilibrium,"We present the design for a thermodynamic computer that can perform arbitrary
nonlinear calculations in or out of equilibrium. Simple thermodynamic circuits,
fluctuating degrees of freedom in contact with a thermal bath and confined by a
quartic potential, display an activity that is a nonlinear function of their
input. Such circuits can therefore be regarded as thermodynamic neurons, and
can serve as the building blocks of networked structures that act as
thermodynamic neural networks, universal function approximators whose operation
is powered by thermal fluctuations. We simulate a digital model of a
thermodynamic neural network, and show that its parameters can be adjusted by
genetic algorithm to perform nonlinear calculations at specified observation
times, regardless of whether the system has attained thermal equilibrium. This
work expands the field of thermodynamic computing beyond the regime of thermal
equilibrium, enabling fully nonlinear computations, analogous to those
performed by classical neural networks, at specified observation times.",2024-12-22,"Stephen Whitelam, Corneel Casert",http://arxiv.org/pdf/2412.17183v2,cs.LG
"COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations","This study presents a data-driven analysis of COVID-19 discourse on YouTube,
examining the sentiment, toxicity, and thematic patterns of video content
published between January 2023 and October 2024. The analysis involved applying
advanced natural language processing (NLP) techniques: sentiment analysis with
VADER, toxicity detection with Detoxify, and topic modeling using Latent
Dirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of
video descriptions were positive, 36.63% were neutral, and 14.05% were
negative, indicating a generally informative and supportive tone in
pandemic-related content. Toxicity analysis identified only 0.91% of content as
toxic, suggesting minimal exposure to toxic content. Topic modeling revealed
two main themes, with 66.74% of the videos covering general health information
and pandemic-related impacts and 33.26% focused on news and real-time updates,
highlighting the dual informational role of YouTube. A recommendation system
was also developed using TF-IDF vectorization and cosine similarity, refined by
sentiment, toxicity, and topic filters to ensure relevant and context-aligned
video recommendations. This system achieved 69% aggregate coverage, with
monthly coverage rates consistently above 85%, demonstrating robust performance
and adaptability over time. Evaluation across recommendation sizes showed
coverage reaching 69% for five video recommendations and 79% for ten video
recommendations per video. In summary, this work presents a framework for
understanding COVID-19 discourse on YouTube and a recommendation system that
supports user engagement while promoting responsible and relevant content
related to COVID-19.",2024-12-22,"Vanessa Su, Nirmalya Thakur",http://arxiv.org/pdf/2412.17180v1,cs.LG
WPMixer: Efficient Multi-Resolution Mixing for Long-Term Time Series Forecasting,"Time series forecasting is crucial for various applications, such as weather
forecasting, power load forecasting, and financial analysis. In recent studies,
MLP-mixer models for time series forecasting have been shown as a promising
alternative to transformer-based models. However, the performance of these
models is still yet to reach its potential. In this paper, we propose Wavelet
Patch Mixer (WPMixer), a novel MLP-based model, for long-term time series
forecasting, which leverages the benefits of patching, multi-resolution wavelet
decomposition, and mixing. Our model is based on three key components: (i)
multi-resolution wavelet decomposition, (ii) patching and embedding, and (iii)
MLP mixing. Multi-resolution wavelet decomposition efficiently extracts
information in both the frequency and time domains. Patching allows the model
to capture an extended history with a look-back window and enhances capturing
local information while MLP mixing incorporates global information. Our model
significantly outperforms state-of-the-art MLP-based and transformer-based
models for long-term time series forecasting in a computationally efficient
way, demonstrating its efficacy and potential for practical applications.",2024-12-22,"Md Mahmuddun Nabi Murad, Mehmet Aktukmak, Yasin Yilmaz",http://arxiv.org/pdf/2412.17176v1,cs.LG
Enhancing Item Tokenization for Generative Recommendation through Self-Improvement,"Generative recommendation systems, driven by large language models (LLMs),
present an innovative approach to predicting user preferences by modeling items
as token sequences and generating recommendations in a generative manner. A
critical challenge in this approach is the effective tokenization of items,
ensuring that they are represented in a form compatible with LLMs. Current item
tokenization methods include using text descriptions, numerical strings, or
sequences of discrete tokens. While text-based representations integrate
seamlessly with LLM tokenization, they are often too lengthy, leading to
inefficiencies and complicating accurate generation. Numerical strings, while
concise, lack semantic depth and fail to capture meaningful item relationships.
Tokenizing items as sequences of newly defined tokens has gained traction, but
it often requires external models or algorithms for token assignment. These
external processes may not align with the LLM's internal pretrained
tokenization schema, leading to inconsistencies and reduced model performance.
To address these limitations, we propose a self-improving item tokenization
method that allows the LLM to refine its own item tokenizations during training
process. Our approach starts with item tokenizations generated by any external
model and periodically adjusts these tokenizations based on the LLM's learned
patterns. Such alignment process ensures consistency between the tokenization
and the LLM's internal understanding of the items, leading to more accurate
recommendations. Furthermore, our method is simple to implement and can be
integrated as a plug-and-play enhancement into existing generative
recommendation systems. Experimental results on multiple datasets and using
various initial tokenization strategies demonstrate the effectiveness of our
method, with an average improvement of 8\% in recommendation performance.",2024-12-22,"Runjin Chen, Mingxuan Ju, Ngoc Bui, Dimosthenis Antypas, Stanley Cai, Xiaopeng Wu, Leonardo Neves, Zhangyang Wang, Neil Shah, Tong Zhao",http://arxiv.org/pdf/2412.17171v1,cs.LG
Where Did Your Model Learn That? Label-free Influence for Self-supervised Learning,"Self-supervised learning (SSL) has revolutionized learning from large-scale
unlabeled datasets, yet the intrinsic relationship between pretraining data and
the learned representations remains poorly understood. Traditional supervised
learning benefits from gradient-based data attribution tools like influence
functions that measure the contribution of an individual data point to model
predictions. However, existing definitions of influence rely on labels, making
them unsuitable for SSL settings. We address this gap by introducing
Influence-SSL, a novel and label-free approach for defining influence functions
tailored to SSL. Our method harnesses the stability of learned representations
against data augmentations to identify training examples that help explain
model predictions. We provide both theoretical foundations and empirical
evidence to show the utility of Influence-SSL in analyzing pre-trained SSL
models. Our analysis reveals notable differences in how SSL models respond to
influential data compared to supervised models. Finally, we validate the
effectiveness of Influence-SSL through applications in duplicate detection,
outlier identification and fairness analysis. Code is available at:
\url{https://github.com/cryptonymous9/Influence-SSL}.",2024-12-22,"Nidhin Harilal, Amit Kiran Rege, Reza Akbarian Bafghi, Maziar Raissi, Claire Monteleoni",http://arxiv.org/pdf/2412.17170v1,cs.LG
Generative Diffusion Modeling: A Practical Handbook,"This handbook offers a unified perspective on diffusion models, encompassing
diffusion probabilistic models, score-based generative models, consistency
models, rectified flow, and related methods. By standardizing notations and
aligning them with code implementations, it aims to bridge the ""paper-to-code""
gap and facilitate robust implementations and fair comparisons. The content
encompasses the fundamentals of diffusion models, the pre-training process, and
various post-training methods. Post-training techniques include model
distillation and reward-based fine-tuning. Designed as a practical guide, it
emphasizes clarity and usability over theoretical depth, focusing on widely
adopted approaches in generative modeling with diffusion models.",2024-12-22,"Zihan Ding, Chi Jin",http://arxiv.org/pdf/2412.17162v1,cs.LG
The Potential of Convolutional Neural Networks for Cancer Detection,"Early detection is a prime requisite for successful cancer treatment and
increasing its survivability rates, particularly in the most common forms. CNNs
(Convolutional Neural Networks) are very potent tools for the analysis and
classification of medical images, with particular reference to the early
detection of different types of cancer. Ten different cancers have been
identified in most of these advances that use CNN techniques for
classification. The unique architectures of CNNs employed in each study are
focused on pattern recognition for each type of cancer through different
datasets. By comparing and analyzing these architectures, the strengths and
drawbacks of each approach are pointed out in terms of their efforts toward
improving the earlier detection of cancer. The opportunity to embrace CNNs
within the clinical sphere was interrogated as support or potential
substitution of traditional diagnostic techniques. Furthermore, challenges such
as integrating diverse data, how to interpret the results, and ethical dilemmas
continue to stalk this field with inconceivable hindrances. This study
identifies those CNN architectures that carry out the best work and offers a
comparative analysis that reveals to researchers the impact of CNNs on cancer
detection in the leap toward boosting diagnostic capabilities in health.",2024-12-22,"Hossein Molaeian, Kaveh Karamjani, Sina Teimouri, Saeed Roshani, Sobhan Roshani",http://arxiv.org/pdf/2412.17155v3,cs.LG
Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching,"Autoregressive (AR) models have achieved state-of-the-art performance in text
and image generation but suffer from slow generation due to the token-by-token
process. We ask an ambitious question: can a pre-trained AR model be adapted to
generate outputs in just one or two steps? If successful, this would
significantly advance the development and deployment of AR models. We notice
that existing works that try to speed up AR generation by generating multiple
tokens at once fundamentally cannot capture the output distribution due to the
conditional dependencies between tokens, limiting their effectiveness for
few-step generation. To address this, we propose Distilled Decoding (DD), which
uses flow matching to create a deterministic mapping from Gaussian distribution
to the output distribution of the pre-trained AR model. We then train a network
to distill this mapping, enabling few-step generation. DD doesn't need the
training data of the original AR model, making it more practical. We evaluate
DD on state-of-the-art image AR models and present promising results on
ImageNet-256. For VAR, which requires 10-step generation, DD enables one-step
generation (6.3$\times$ speed-up), with an acceptable increase in FID from 4.19
to 9.96. For LlamaGen, DD reduces generation from 256 steps to 1, achieving an
217.8$\times$ speed-up with a comparable FID increase from 4.11 to 11.35. In
both cases, baseline methods completely fail with FID>100. DD also excels on
text-to-image generation, reducing the generation from 256 steps to 2 for
LlamaGen with minimal FID increase from 25.70 to 28.95. As the first work to
demonstrate the possibility of one-step generation for image AR models, DD
challenges the prevailing notion that AR models are inherently slow, and opens
up new opportunities for efficient AR generation. The project website is at
https://imagination-research.github.io/distilled-decoding.",2024-12-22,"Enshu Liu, Xuefei Ning, Yu Wang, Zinan Lin",http://arxiv.org/pdf/2412.17153v2,cs.LG
Unifying Feature-Based Explanations with Functional ANOVA and Cooperative Game Theory,"Feature-based explanations, using perturbations or gradients, are a prevalent
tool to understand decisions of black box machine learning models. Yet,
differences between these methods still remain mostly unknown, which limits
their applicability for practitioners. In this work, we introduce a unified
framework for local and global feature-based explanations using two
well-established concepts: functional ANOVA (fANOVA) from statistics, and the
notion of value and interaction from cooperative game theory. We introduce
three fANOVA decompositions that determine the influence of feature
distributions, and use game-theoretic measures, such as the Shapley value and
interactions, to specify the influence of higher-order interactions. Our
framework combines these two dimensions to uncover similarities and differences
between a wide range of explanation techniques for features and groups of
features. We then empirically showcase the usefulness of our framework on
synthetic and real-world datasets.",2024-12-22,"Fabian Fumagalli, Maximilian Muschalik, Eyke Hüllermeier, Barbara Hammer, Julia Herbinger",http://arxiv.org/pdf/2412.17152v2,cs.LG
Bridging Auditory Perception and Language Comprehension through MEG-Driven Encoding Models,"Understanding the neural mechanisms behind auditory and linguistic processing
is key to advancing cognitive neuroscience. In this study, we use
Magnetoencephalography (MEG) data to analyze brain responses to spoken language
stimuli. We develop two distinct encoding models: an audio-to-MEG encoder,
which uses time-frequency decompositions (TFD) and wav2vec2 latent space
representations, and a text-to-MEG encoder, which leverages CLIP and GPT-2
embeddings. Both models successfully predict neural activity, demonstrating
significant correlations between estimated and observed MEG signals. However,
the text-to-MEG model outperforms the audio-based model, achieving higher
Pearson Correlation (PC) score. Spatially, we identify that auditory-based
embeddings (TFD and wav2vec2) predominantly activate lateral temporal regions,
which are responsible for primary auditory processing and the integration of
auditory signals. In contrast, textual embeddings (CLIP and GPT-2) primarily
engage the frontal cortex, particularly Broca's area, which is associated with
higher-order language processing, including semantic integration and language
production, especially in the 8-30 Hz frequency range. The strong involvement
of these regions suggests that auditory stimuli are processed through more
direct sensory pathways, while linguistic information is encoded via networks
that integrate meaning and cognitive control. Our results reveal distinct
neural pathways for auditory and linguistic information processing, with higher
encoding accuracy for text representations in the frontal regions. These
insights refine our understanding of the brain's functional architecture in
processing auditory and textual information, offering quantitative advancements
in the modelling of neural responses to complex language stimuli.",2024-12-22,"Matteo Ciferri, Matteo Ferrante, Nicola Toschi",http://arxiv.org/pdf/2501.03246v1,cs.LG
Empirical evaluation of normalizing flows in Markov Chain Monte Carlo,"Recent advances in MCMC use normalizing flows to precondition target
distributions and enable jumps to distant regions. However, there is currently
no systematic comparison of different normalizing flow architectures for MCMC.
As such, many works choose simple flow architectures that are readily available
and do not consider other models. Guidelines for choosing an appropriate
architecture would reduce analysis time for practitioners and motivate
researchers to take the recommended models as foundations to be improved. We
provide the first such guideline by extensively evaluating many normalizing
flow architectures on various flow-based MCMC methods and target distributions.
When the target density gradient is available, we show that flow-based MCMC
outperforms classic MCMC for suitable NF architecture choices with minor
hyperparameter tuning. When the gradient is unavailable, flow-based MCMC wins
with off-the-shelf architectures. We find contractive residual flows to be the
best general-purpose models with relatively low sensitivity to hyperparameter
choice. We also provide various insights into normalizing flow behavior within
MCMC when varying their hyperparameters, properties of target distributions,
and the overall computational budget.",2024-12-22,"David Nabergoj, Erik Štrumbelj",http://arxiv.org/pdf/2412.17136v1,cs.LG
Fairness in Reinforcement Learning with Bisimulation Metrics,"Ensuring long-term fairness is crucial when developing automated decision
making systems, specifically in dynamic and sequential environments. By
maximizing their reward without consideration of fairness, AI agents can
introduce disparities in their treatment of groups or individuals. In this
paper, we establish the connection between bisimulation metrics and group
fairness in reinforcement learning. We propose a novel approach that leverages
bisimulation metrics to learn reward functions and observation dynamics,
ensuring that learners treat groups fairly while reflecting the original
problem. We demonstrate the effectiveness of our method in addressing
disparities in sequential decision making problems through empirical evaluation
on a standard fairness benchmark consisting of lending and college admission
scenarios.",2024-12-22,"Sahand Rezaei-Shoshtari, Hanna Yurchyk, Scott Fujimoto, Doina Precup, David Meger",http://arxiv.org/pdf/2412.17123v2,cs.LG
Scalable Speech Enhancement with Dynamic Channel Pruning,"Speech Enhancement (SE) is essential for improving productivity in remote
collaborative environments. Although deep learning models are highly effective
at SE, their computational demands make them impractical for embedded systems.
Furthermore, acoustic conditions can change significantly in terms of
difficulty, whereas neural networks are usually static with regard to the
amount of computation performed. To this end, we introduce Dynamic Channel
Pruning to the audio domain for the first time and apply it to a custom
convolutional architecture for SE. Our approach works by identifying
unnecessary convolutional channels at runtime and saving computational
resources by not computing the activations for these channels and retrieving
their filters. When trained to only use 25% of channels, we save 29.6% of MACs
while only causing a 0.75% drop in PESQ. Thus, DynCP offers a promising path
toward deploying larger and more powerful SE solutions on resource-constrained
devices.",2024-12-22,"Riccardo Miccini, Clement Laroche, Tobias Piechowiak, Luca Pezzarossa",http://arxiv.org/pdf/2412.17121v1,cs.LG
Fair and Accurate Regression: Strong Formulations and Algorithms,"This paper introduces mixed-integer optimization methods to solve regression
problems that incorporate fairness metrics. We propose an exact formulation for
training fair regression models. To tackle this computationally hard problem,
we study the polynomially-solvable single-factor and single-observation
subproblems as building blocks and derive their closed convex hull
descriptions. Strong formulations obtained for the general fair regression
problem in this manner are utilized to solve the problem with a
branch-and-bound algorithm exactly or as a relaxation to produce fair and
accurate models rapidly. Moreover, to handle large-scale instances, we develop
a coordinate descent algorithm motivated by the convex-hull representation of
the single-factor fair regression problem to improve a given solution
efficiently. Numerical experiments conducted on fair least squares and fair
logistic regression problems show competitive statistical performance with
state-of-the-art methods while significantly reducing training times.",2024-12-22,"Anna Deza, Andrés Gómez, Alper Atamtürk",http://arxiv.org/pdf/2412.17116v1,cs.LG
Adam on Local Time: Addressing Nonstationarity in RL with Relative Adam Timesteps,"In reinforcement learning (RL), it is common to apply techniques used broadly
in machine learning such as neural network function approximators and
momentum-based optimizers. However, such tools were largely developed for
supervised learning rather than nonstationary RL, leading practitioners to
adopt target networks, clipped policy updates, and other RL-specific
implementation tricks to combat this mismatch, rather than directly adapting
this toolchain for use in RL. In this paper, we take a different approach and
instead address the effect of nonstationarity by adapting the widely used Adam
optimiser. We first analyse the impact of nonstationary gradient magnitude --
such as that caused by a change in target network -- on Adam's update size,
demonstrating that such a change can lead to large updates and hence
sub-optimal performance. To address this, we introduce Adam-Rel. Rather than
using the global timestep in the Adam update, Adam-Rel uses the local timestep
within an epoch, essentially resetting Adam's timestep to 0 after target
changes. We demonstrate that this avoids large updates and reduces to learning
rate annealing in the absence of such increases in gradient magnitude.
Evaluating Adam-Rel in both on-policy and off-policy RL, we demonstrate
improved performance in both Atari and Craftax. We then show that increases in
gradient norm occur in RL in practice, and examine the differences between our
theoretical model and the observed data.",2024-12-22,"Benjamin Ellis, Matthew T. Jackson, Andrei Lupu, Alexander D. Goldie, Mattie Fellows, Shimon Whiteson, Jakob Foerster",http://arxiv.org/pdf/2412.17113v1,cs.LG
Similarity Trajectories: Linking Sampling Process to Artifacts in Diffusion-Generated Images,"Artifact detection algorithms are crucial to correcting the output generated
by diffusion models. However, because of the variety of artifact forms,
existing methods require substantial annotated data for training. This
requirement limits their scalability and efficiency, which restricts their wide
application. This paper shows that the similarity of denoised images between
consecutive time steps during the sampling process is related to the severity
of artifacts in images generated by diffusion models. Building on this
observation, we introduce the concept of Similarity Trajectory to characterize
the sampling process and its correlation with the image artifacts presented.
Using an annotated data set of 680 images, which is only 0.1% of the amount of
data used in the prior work, we trained a classifier on these trajectories to
predict the presence of artifacts in images. By performing 10-fold validation
testing on the balanced annotated data set, the classifier can achieve an
accuracy of 72.35%, highlighting the connection between the Similarity
Trajectory and the occurrence of artifacts. This approach enables
differentiation between artifact-exhibiting and natural-looking images using
limited training data.",2024-12-22,"Dennis Menn, Feng Liang, Hung-Yueh Chiang, Diana Marculescu",http://arxiv.org/pdf/2412.17109v1,cs.LG
Grams: Gradient Descent with Adaptive Momentum Scaling,"We introduce $\mathbf{G}$radient Descent with $\mathbf{A}$daptive
$\mathbf{M}$omentum $\mathbf{S}$caling ($\mathbf{Grams}$), a novel optimization
algorithm that decouples the direction and magnitude of parameter updates in
deep learning. Unlike traditional optimizers that directly integrate momentum
into updates, Grams separates the update direction, derived from current
gradients, from momentum, which is used solely for adaptive magnitude scaling.
This approach enables Grams to achieve improved loss descent compared to
state-of-the-art cautious and momentum-based optimizers. We theoretically
demonstrate that Grams descents faster than other state-of-the-art optimizers
and establish a global convergence guarantee for Grams. We also validate its
effectiveness through extensive empirical evaluations. The results demonstrate
Grams' superior performance, including faster convergence and better
generalization, compared to widely-used optimizers such as Adam, Lion, and
their cautious variants. Our results highlight Grams' potential as a
transformative approach for efficiently training and fine-tuning large language
models. Code is available at https://github.com/Gunale0926/Grams.",2024-12-22,"Yang Cao, Xiaoyu Li, Zhao Song",http://arxiv.org/pdf/2412.17107v3,cs.LG
MARINA-P: Superior Performance in Non-smooth Federated Optimization with Adaptive Stepsizes,"Non-smooth communication-efficient federated optimization is crucial for many
machine learning applications, yet remains largely unexplored theoretically.
Recent advancements have primarily focused on smooth convex and non-convex
regimes, leaving a significant gap in understanding the non-smooth convex
setting. Additionally, existing literature often overlooks efficient
server-to-worker communication (downlink), focusing primarily on
worker-to-server communication (uplink). We consider a setup where uplink costs
are negligible and focus on optimizing downlink communication by improving
state-of-the-art schemes like EF21-P (arXiv:2209.15218) and MARINA-P
(arXiv:2402.06412) in the non-smooth convex setting. We extend the non-smooth
convex theory of EF21-P [Anonymous, 2024], originally developed for single-node
scenarios, to the distributed setting, and extend MARINA-P to the non-smooth
convex setting. For both algorithms, we prove an optimal $O(1/\sqrt{T})$
convergence rate and establish communication complexity bounds matching
classical subgradient methods. We provide theoretical guarantees under
constant, decreasing, and adaptive (Polyak-type) stepsizes. Our experiments
demonstrate that MARINA-P with correlated compressors outperforms other methods
in both smooth non-convex and non-smooth convex settings. This work presents
the first theoretical results for distributed non-smooth optimization with
server-to-worker compression, along with comprehensive analysis for various
stepsize schemes.",2024-12-22,"Igor Sokolov, Peter Richtárik",http://arxiv.org/pdf/2412.17082v1,cs.LG
Optimizing Data Curation through Spectral Analysis and Joint Batch Selection (SALN),"In modern deep learning models, long training times and large datasets
present significant challenges to both efficiency and scalability. Effective
data curation and sample selection are crucial for optimizing the training
process of deep neural networks. This paper introduces SALN, a method designed
to prioritize and select samples within each batch rather than from the entire
dataset. By utilizing jointly selected batches, SALN enhances training
efficiency compared to independent batch selection. The proposed method applies
a spectral analysis-based heuristic to identify the most informative data
points within each batch, improving both training speed and accuracy. The SALN
algorithm significantly reduces training time and enhances accuracy when
compared to traditional batch prioritization or standard training procedures.
It demonstrates up to an 8x reduction in training time and up to a 5\% increase
in accuracy over standard training methods. Moreover, SALN achieves better
performance and shorter training times compared to Google's JEST method
developed by DeepMind.",2024-12-22,Mohammadreza Sharifi,http://arxiv.org/pdf/2412.17069v1,cs.LG
Interactive Classification Metrics: A graphical application to build robust intuition for classification model evaluation,"Machine learning continues to grow in popularity in academia, in industry,
and is increasingly used in other fields. However, most of the common metrics
used to evaluate even simple binary classification models have shortcomings
that are neither immediately obvious nor consistently taught to practitioners.
Here we present Interactive Classification Metrics (ICM), an application to
visualize and explore the relationships between different evaluation metrics.
The user changes the distribution statistics and explores corresponding changes
across a suite of evaluation metrics. The interactive, graphical nature of this
tool emphasizes the tradeoffs of each metric without the overhead of data
wrangling and model training. The goals of this application are: (1) to aid
practitioners in the ever-expanding machine learning field to choose the most
appropriate evaluation metrics for their classification problem; (2) to promote
careful attention to interpretation that is required even in the simplest
scenarios like binary classification. Our application is publicly available for
free under the MIT license as a Python package on PyPI at
https://pypi.org/project/interactive-classification-metrics and on GitHub at
https://github.com/davhbrown/interactive_classification_metrics.",2024-12-22,"David H. Brown, Davide Chicco",http://arxiv.org/pdf/2412.17066v1,cs.LG
The HalluRAG Dataset: Detecting Closed-Domain Hallucinations in RAG Applications Using an LLM's Internal States,"Detecting hallucinations in large language models (LLMs) is critical for
enhancing their reliability and trustworthiness. Most research focuses on
hallucinations as deviations from information seen during training. However,
the opaque nature of an LLM's parametric knowledge complicates the
understanding of why generated texts appear ungrounded: The LLM might not have
picked up the necessary knowledge from large and often inaccessible datasets,
or the information might have been changed or contradicted during further
training. Our focus is on hallucinations involving information not used in
training, which we determine by using recency to ensure the information emerged
after a cut-off date. This study investigates these hallucinations by detecting
them at sentence level using different internal states of various LLMs. We
present HalluRAG, a dataset designed to train classifiers on these
hallucinations. Depending on the model and quantization, MLPs trained on
HalluRAG detect hallucinations with test accuracies ranging up to 75 %, with
Mistral-7B-Instruct-v0.1 achieving the highest test accuracies. Our results
show that IAVs detect hallucinations as effectively as CEVs and reveal that
answerable and unanswerable prompts are encoded differently as separate
classifiers for these categories improved accuracy. However, HalluRAG showed
some limited generalizability, advocating for more diversity in datasets on
hallucinations.",2024-12-22,"Fabian Ridder, Malte Schilling",http://arxiv.org/pdf/2412.17056v2,cs.LG
Differentially Private Random Block Coordinate Descent,"Coordinate Descent (CD) methods have gained significant attention in machine
learning due to their effectiveness in solving high-dimensional problems and
their ability to decompose complex optimization tasks. However, classical CD
methods were neither designed nor analyzed with data privacy in mind, a
critical concern when handling sensitive information. This has led to the
development of differentially private CD methods, such as DP-CD (Differentially
Private Coordinate Descent) proposed by Mangold et al. (ICML 2022), yet a
disparity remains between non-private CD and DP-CD methods. In our work, we
propose a differentially private random block coordinate descent method that
selects multiple coordinates with varying probabilities in each iteration using
sketch matrices. Our algorithm generalizes both DP-CD and the classical DP-SGD
(Differentially Private Stochastic Gradient Descent), while preserving the same
utility guarantees. Furthermore, we demonstrate that better utility can be
achieved through importance sampling, as our method takes advantage of the
heterogeneity in coordinate-wise smoothness constants, leading to improved
convergence rates.",2024-12-22,"Artavazd Maranjyan, Abdurakhmon Sadiev, Peter Richtárik",http://arxiv.org/pdf/2412.17054v1,cs.LG
DR-Encoder: Encode Low-rank Gradients with Random Prior for Large Language Models Differentially Privately,"The emergence of the Large Language Model (LLM) has shown their superiority
in a wide range of disciplines, including language understanding and
translation, relational logic reasoning, and even partial differential
equations solving. The transformer is the pervasive backbone architecture for
the foundation model construction. It is vital to research how to adjust the
Transformer architecture to achieve an end-to-end privacy guarantee in LLM
fine-tuning. In this paper, we investigate three potential information leakage
during a federated fine-tuning procedure for LLM (FedLLM). Based on the
potential information leakage, we provide an end-to-end privacy guarantee
solution for FedLLM by inserting two-stage randomness. The first stage is to
train a gradient auto-encoder with a Gaussian random prior based on the
statistical information of the gradients generated by local clients. The second
stage is to fine-tune the overall LLM with a differential privacy guarantee by
adopting appropriate Gaussian noises. We show the efficiency and accuracy gains
of our proposed method with several foundation models and two popular
evaluation benchmarks. Furthermore, we present a comprehensive privacy analysis
with Gaussian Differential Privacy (GDP) and Renyi Differential Privacy (RDP).",2024-12-22,"Huiwen Wu, Deyi Zhang, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Zhe Liu",http://arxiv.org/pdf/2412.17053v1,cs.LG
An OpenMind for 3D medical vision self-supervised learning,"The field of self-supervised learning (SSL) for 3D medical images lacks
consistency and standardization. While many methods have been developed, it is
impossible to identify the current state-of-the-art, due to i) varying and
small pretraining datasets, ii) varying architectures, and iii) being evaluated
on differing downstream datasets. In this paper, we bring clarity to this field
and lay the foundation for further method advancements through three key
contributions: We a) publish the largest publicly available pre-training
dataset comprising 114k 3D brain MRI volumes, enabling all practitioners to
pre-train on a large-scale dataset. We b) benchmark existing 3D self-supervised
learning methods on this dataset for a state-of-the-art CNN and Transformer
architecture, clarifying the state of 3D SSL pre-training. Among many findings,
we show that pre-trained methods can exceed a strong from-scratch nnU-Net
ResEnc-L baseline. Lastly, we c) publish the code of our pre-training and
fine-tuning frameworks and provide the pre-trained models created during the
benchmarking process to facilitate rapid adoption and reproduction.",2024-12-22,"Tassilo Wald, Constantin Ulrich, Jonathan Suprijadi, Sebastian Ziegler, Michal Nohel, Robin Peretzke, Gregor Köhler, Klaus H. Maier-Hein",http://arxiv.org/pdf/2412.17041v2,cs.LG
HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories,"To efficiently adapt large models or to train generative models of neural
representations, Hypernetworks have drawn interest. While hypernetworks work
well, training them is cumbersome, and often requires ground truth optimized
weights for each sample. However, obtaining each of these weights is a training
problem of its own-one needs to train, e.g., adaptation weights or even an
entire neural field for hypernetworks to regress to. In this work, we propose a
method to train hypernetworks, without the need for any per-sample ground
truth. Our key idea is to learn a Hypernetwork `Field` and estimate the entire
trajectory of network weight training instead of simply its converged state. In
other words, we introduce an additional input to the Hypernetwork, the
convergence state, which then makes it act as a neural field that models the
entire convergence pathway of a task network. A critical benefit in doing so is
that the gradient of the estimated weights at any convergence state must then
match the gradients of the original task -- this constraint alone is sufficient
to train the Hypernetwork Field. We demonstrate the effectiveness of our method
through the task of personalized image generation and 3D shape reconstruction
from images and point clouds, demonstrating competitive results without any
per-sample ground truth.",2024-12-22,"Eric Hedlin, Munawar Hayat, Fatih Porikli, Kwang Moo Yi, Shweta Mahajan",http://arxiv.org/pdf/2412.17040v2,cs.LG
Generate to Discriminate: Expert Routing for Continual Learning,"In many real-world settings, regulations and economic incentives permit the
sharing of models but not data across institutional boundaries. In such
scenarios, practitioners might hope to adapt models to new domains, without
losing performance on previous domains (so-called catastrophic forgetting).
While any single model may struggle to achieve this goal, learning an ensemble
of domain-specific experts offers the potential to adapt more closely to each
individual institution. However, a core challenge in this context is
determining which expert to deploy at test time. In this paper, we propose
Generate to Discriminate (G2D), a domain-incremental continual learning method
that leverages synthetic data to train a domain-discriminator that routes
samples at inference time to the appropriate expert. Surprisingly, we find that
leveraging synthetic data in this capacity is more effective than using the
samples to \textit{directly} train the downstream classifier (the more common
approach to leveraging synthetic data in the lifelong learning literature). We
observe that G2D outperforms competitive domain-incremental learning methods on
tasks in both vision and language modalities, providing a new perspective on
the use of synthetic data in the lifelong learning literature.",2024-12-22,"Yewon Byun, Sanket Vaibhav Mehta, Saurabh Garg, Emma Strubell, Michael Oberst, Bryan Wilder, Zachary C. Lipton",http://arxiv.org/pdf/2412.17009v2,cs.LG
Data value estimation on private gradients,"For gradient-based machine learning (ML) methods commonly adopted in practice
such as stochastic gradient descent, the de facto differential privacy (DP)
technique is perturbing the gradients with random Gaussian noise. Data
valuation attributes the ML performance to the training data and is widely used
in privacy-aware applications that require enforcing DP such as data pricing,
collaborative ML, and federated learning (FL). Can existing data valuation
methods still be used when DP is enforced via gradient perturbations? We show
that the answer is no with the default approach of injecting i.i.d.~random
noise to the gradients because the estimation uncertainty of the data value
estimation paradoxically linearly scales with more estimation budget, producing
estimates almost like random guesses. To address this issue, we propose to
instead inject carefully correlated noise to provably remove the linear scaling
of estimation uncertainty w.r.t.~the budget. We also empirically demonstrate
that our method gives better data value estimates on various ML tasks and is
applicable to use cases including dataset valuation and~FL.",2024-12-22,"Zijian Zhou, Xinyi Xu, Daniela Rus, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2412.17008v1,cs.LG
Solving Nonlinear Energy Supply and Demand System Using Physics-Informed Neural Networks,"Nonlinear differential equations and systems play a crucial role in modeling
systems where time-dependent factors exhibit nonlinear characteristics. Due to
their nonlinear nature, solving such systems often presents significant
difficulties and challenges. In this study, we propose a method utilizing
Physics-Informed Neural Networks (PINNs) to solve the nonlinear energy
supply-demand (ESD) system. We design a neural network with four outputs, where
each output approximates a function that corresponds to one of the unknown
functions in the nonlinear system of differential equations describing the
four-dimensional ESD problem. The neural network model is then trained and the
parameters are identified, optimized to achieve a more accurate solution. The
solutions obtained from the neural network for this problem are equivalent when
we compare and evaluate them against the Runge-Kutta numerical method of order
4/5 (RK45). However, the method utilizing neural networks is considered a
modern and promising approach, as it effectively exploits the superior
computational power of advanced computer systems, especially in solving complex
problems. Another advantage is that the neural network model, after being
trained, can solve the nonlinear system of differential equations across a
continuous domain. In other words, neural networks are not only trained to
approximate the solution functions for the nonlinear ESD system but can also
represent the complex dynamic relationships between the system's components.
However, this approach requires significant time and computational power due to
the need for model training.",2024-12-22,"Van Truong Vo, Samad Noeiaghdam, Denis Sidorov, Aliona Dreglea, Liguo Wang",http://arxiv.org/pdf/2412.17001v1,cs.LG
Reduced Order Models and Conditional Expectation -- Analysing Parametric Low-Order Approximations,"Systems may depend on parameters which one may control, or which serve to
optimise the system, or are imposed externally, or they could be uncertain.
This last case is taken as the ``Leitmotiv'' for the following. A reduced order
model is produced from the full order model by some kind of projection onto a
relatively low-dimensional manifold or subspace. The parameter dependent
reduction process produces a function of the parameters into the manifold. One
now wants to examine the relation between the full and the reduced state for
all possible parameter values of interest. Similarly, in the field of machine
learning, also a function of the parameter set into the image space of the
machine learning model is learned on a training set of samples, typically
minimising the mean-square error. This set may be seen as a sample from some
probability distribution, and thus the training is an approximate computation
of the expectation, giving an approximation to the conditional expectation, a
special case of an Bayesian updating where the Bayesian loss function is the
mean-square error. This offers the possibility of having a combined look at
these methods, and also of introducing more general loss functions.",2024-12-22,Hermann G. Matthies,http://arxiv.org/pdf/2412.19836v2,cs.LG
Multi-Agent Q-Learning for Real-Time Load Balancing User Association and Handover in Mobile Networks,"As next generation cellular networks become denser, associating users with
the optimal base stations at each time while ensuring no base station is
overloaded becomes critical for achieving stable and high network performance.
We propose multi-agent online Q-learning (QL) algorithms for performing
real-time load balancing user association and handover in dense cellular
networks. The load balancing constraints at all base stations couple the
actions of user agents, and we propose two multi-agent action selection
policies, one centralized and one distributed, to satisfy load balancing at
every learning step. In the centralized policy, the actions of UEs are
determined by a central load balancer (CLB) running an algorithm based on
swapping the worst connection to maximize the total learning reward. In the
distributed policy, each UE takes an action based on its local information by
participating in a distributed matching game with the BSs to maximize the local
reward. We then integrate these action selection policies into an online QL
algorithm that adapts in real-time to network dynamics including channel
variations and user mobility, using a reward function that considers a handover
cost to reduce handover frequency. The proposed multi-agent QL algorithm
features low-complexity and fast convergence, outperforming 3GPP max-SINR
association. Both policies adapt well to network dynamics at various UE speed
profiles from walking, running, to biking and suburban driving, illustrating
their robustness and real-time adaptability.",2024-12-22,"Alireza Alizadeh, Byungju Lim, Mai Vu",http://arxiv.org/pdf/2412.19835v1,cs.LG
FedCross: Intertemporal Federated Learning Under Evolutionary Games,"Federated Learning (FL) mitigates privacy leakage in decentralized machine
learning by allowing multiple clients to train collaboratively locally.
However, dynamic mobile networks with high mobility, intermittent connectivity,
and bandwidth limitation severely hinder model updates to the cloud server.
Although previous studies have typically addressed user mobility issue through
task reassignment or predictive modeling, frequent migrations may result in
high communication overhead. Overcoming this obstacle involves not only dealing
with resource constraints, but also finding ways to mitigate the challenges
posed by user migrations. We therefore propose an intertemporal incentive
framework, FedCross, which ensures the continuity of FL tasks by migrating
interrupted training tasks to feasible mobile devices. Specifically, FedCross
comprises two distinct stages. In Stage 1, we address the task allocation
problem across regions under resource constraints by employing a
multi-objective migration algorithm to quantify the optimal task receivers.
Moreover, we adopt evolutionary game theory to capture the dynamic
decision-making of users, forecasting the evolution of user proportions across
different regions to mitigate frequent migrations. In Stage 2, we utilize a
procurement auction mechanism to allocate rewards among base stations, ensuring
that those providing high-quality models receive optimal compensation. This
approach incentivizes sustained user participation, thereby ensuring the
overall feasibility of FedCross. Finally, experimental results validate the
theoretical soundness of FedCross and demonstrate its significant reduction in
communication overhead.",2024-12-22,"Jianfeng Lu, Ying Zhang, Riheng Jia, Shuqin Cao, Jing Liu, Hao Fu",http://arxiv.org/pdf/2412.16968v1,cs.LG
Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation,"We study equilibrium computation with extensive-form correlation in
two-player turn-taking stochastic games. Our main results are two-fold: (1) We
give an algorithm for computing a Stackelberg extensive-form correlated
equilibrium (SEFCE), which runs in time polynomial in the size of the game, as
well as the number of bits required to encode each input number. (2) We give an
efficient algorithm for approximately computing an optimal extensive-form
correlated equilibrium (EFCE) up to machine precision, i.e., the algorithm
achieves approximation error $\varepsilon$ in time polynomial in the size of
the game, as well as $\log(1 / \varepsilon)$.
  Our algorithm for SEFCE is the first polynomial-time algorithm for
equilibrium computation with commitment in such a general class of stochastic
games. Existing algorithms for SEFCE typically make stronger assumptions such
as no chance moves, and are designed for extensive-form games in the less
succinct tree form. Our algorithm for approximately optimal EFCE is, to our
knowledge, the first algorithm that achieves 3 desiderata simultaneously:
approximate optimality, polylogarithmic dependency on the approximation error,
and compatibility with stochastic games in the more succinct graph form.
Existing algorithms achieve at most 2 of these desiderata, often also relying
on additional technical assumptions.",2024-12-22,"Hanrui Zhang, Yu Cheng, Vincent Conitzer",http://arxiv.org/pdf/2412.16934v1,cs.LG
Revisiting In-Context Learning with Long Context Language Models,"In-Context Learning (ICL) is a technique by which language models make
predictions based on examples provided in their input context. Previously,
their context window size imposed a limit on the number of examples that can be
shown, making example selection techniques crucial for identifying the
maximally effective set of examples. However, the recent advent of Long Context
Language Models (LCLMs) has significantly increased the number of examples that
can be included in context, raising an important question of whether ICL
performance in a many-shot regime is still sensitive to the method of sample
selection. To answer this, we revisit these approaches in the context of LCLMs
through extensive experiments on 18 datasets spanning 4 tasks. Surprisingly, we
observe that sophisticated example selection techniques do not yield
significant improvements over a simple random sample selection method. Instead,
we find that the advent of LCLMs has fundamentally shifted the challenge of ICL
from that of selecting the most effective examples to that of collecting
sufficient examples to fill the context window. Specifically, in certain
datasets, including all available examples does not fully utilize the context
window; however, by augmenting the examples in context with a simple data
augmentation approach, we substantially improve ICL performance by 5%.",2024-12-22,"Jinheon Baek, Sun Jae Lee, Prakhar Gupta, Geunseob Oh, Siddharth Dalmia, Prateek Kolhar",http://arxiv.org/pdf/2412.16926v2,cs.LG
Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index,"This study introduces the Community Sentiment and Engagement Index (CSEI),
developed to capture nuanced public sentiment and engagement variations on
social media, particularly in response to major events related to COVID-19.
Constructed with diverse sentiment indicators, CSEI integrates features like
engagement, daily post count, compound sentiment, fine-grain sentiments (fear,
surprise, joy, sadness, anger, disgust, and neutral), readability,
offensiveness, and domain diversity. Each component is systematically weighted
through a multi-step Principal Component Analysis (PCA)-based framework,
prioritizing features according to their variance contributions across temporal
sentiment shifts. This approach dynamically adjusts component importance,
enabling CSEI to precisely capture high-sensitivity shifts in public sentiment.
The development of CSEI showed statistically significant correlations with its
constituent features, underscoring internal consistency and sensitivity to
specific sentiment dimensions. CSEI's responsiveness was validated using a
dataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15
major events, including the WHO's declaration of COVID-19 as a pandemic, the
first reported cases of COVID-19 across different countries, national
lockdowns, vaccine developments, and crucial public health measures. Cumulative
changes in CSEI revealed prominent peaks and valleys aligned with these events,
indicating significant patterns in public sentiment across different phases of
the pandemic. Pearson correlation analysis further confirmed a statistically
significant relationship between CSEI daily fluctuations and these events (p =
0.0428), highlighting the capacity of CSEI to infer and interpret shifts in
public sentiment and engagement in response to major events related to
COVID-19.",2024-12-22,"Nirmalya Thakur, Kesha A. Patel, Audrey Poon, Shuqi Cui, Nazif Azizi, Rishika Shah, Riyan Shah",http://arxiv.org/pdf/2412.16925v1,cs.LG
Learning to Generate Gradients for Test-Time Adaptation via Test-Time Training Layers,"Test-time adaptation (TTA) aims to fine-tune a trained model online using
unlabeled testing data to adapt to new environments or out-of-distribution
data, demonstrating broad application potential in real-world scenarios.
However, in this optimization process, unsupervised learning objectives like
entropy minimization frequently encounter noisy learning signals. These signals
produce unreliable gradients, which hinder the model ability to converge to an
optimal solution quickly and introduce significant instability into the
optimization process. In this paper, we seek to resolve these issues from the
perspective of optimizer design. Unlike prior TTA using manually designed
optimizers like SGD, we employ a learning-to-optimize approach to automatically
learn an optimizer, called Meta Gradient Generator (MGG). Specifically, we aim
for MGG to effectively utilize historical gradient information during the
online optimization process to optimize the current model. To this end, in MGG,
we design a lightweight and efficient sequence modeling layer -- gradient
memory layer. It exploits a self-supervised reconstruction loss to compress
historical gradient information into network parameters, thereby enabling
better memorization ability over a long-term adaptation process. We only need a
small number of unlabeled samples to pre-train MGG, and then the trained MGG
can be deployed to process unseen samples. Promising results on ImageNet-C, R,
Sketch, and A indicate that our method surpasses current state-of-the-art
methods with fewer updates, less data, and significantly shorter adaptation
iterations. Compared with a previous SOTA method SAR, we achieve 7.4% accuracy
improvement and 4.2 times faster adaptation speed on ImageNet-C.",2024-12-22,"Qi Deng, Shuaicheng Niu, Ronghao Zhang, Yaofo Chen, Runhao Zeng, Jian Chen, Xiping Hu",http://arxiv.org/pdf/2412.16901v1,cs.LG
Integrating Random Effects in Variational Autoencoders for Dimensionality Reduction of Correlated Data,"Variational Autoencoders (VAE) are widely used for dimensionality reduction
of large-scale tabular and image datasets, under the assumption of independence
between data observations. In practice, however, datasets are often correlated,
with typical sources of correlation including spatial, temporal and clustering
structures. Inspired by the literature on linear mixed models (LMM), we propose
LMMVAE -- a novel model which separates the classic VAE latent model into fixed
and random parts. While the fixed part assumes the latent variables are
independent as usual, the random part consists of latent variables which are
correlated between similar clusters in the data such as nearby locations or
successive measurements. The classic VAE architecture and loss are modified
accordingly. LMMVAE is shown to improve squared reconstruction error and
negative likelihood loss significantly on unseen data, with simulated as well
as real datasets from various applications and correlation scenarios. It also
shows improvement in the performance of downstream tasks such as supervised
classification on the learned representations.",2024-12-22,"Giora Simchoni, Saharon Rosset",http://arxiv.org/pdf/2412.16899v2,cs.LG
Rethinking Performance Analysis for Configurable Software Systems: A Case Study from a Fitness Landscape Perspective,"Modern software systems are often highly configurable to tailor varied
requirements from diverse stakeholders. Understanding the mapping between
configurations and the desired performance attributes plays a fundamental role
in advancing the controllability and tuning of the underlying system, yet has
long been a dark hole of knowledge due to its black-box nature. While there
have been previous efforts in performance analysis for these systems, they
analyze the configurations as isolated data points without considering their
inherent spatial relationships. This renders them incapable of interrogating
many important aspects of the configuration space like local optima. In this
work, we advocate a novel perspective to rethink performance analysis --
modeling the configuration space as a structured ``landscape''. To support this
proposition, we designed \our, an open-source, graph data mining empowered
fitness landscape analysis (FLA) framework. By applying this framework to $86$M
benchmarked configurations from $32$ running workloads of $3$ real-world
systems, we arrived at $6$ main findings, which together constitute a holistic
picture of the landscape topography, with thorough discussions about their
implications on both configuration tuning and performance modeling.",2024-12-22,"Mingyu Huang, Peili Mao, Ke Li",http://arxiv.org/pdf/2412.16888v2,cs.LG
Online Preference-based Reinforcement Learning with Self-augmented Feedback from Large Language Model,"Preference-based reinforcement learning (PbRL) provides a powerful paradigm
to avoid meticulous reward engineering by learning rewards based on human
preferences. However, real-time human feedback is hard to obtain in online
tasks. Most work suppose there is a ""scripted teacher"" that utilizes privileged
predefined reward to provide preference feedback. In this paper, we propose a
RL Self-augmented Large Language Model Feedback (RL-SaLLM-F) technique that
does not rely on privileged information for online PbRL. RL-SaLLM-F leverages
the reflective and discriminative capabilities of LLM to generate
self-augmented trajectories and provide preference labels for reward learning.
First, we identify an failure issue in LLM-based preference discrimination,
specifically ""query ambiguity"", in online PbRL. Then LLM is employed to provide
preference labels and generate self-augmented imagined trajectories that better
achieve the task goal, thereby enhancing the quality and efficiency of
feedback. Additionally, a double-check mechanism is introduced to mitigate
randomness in the preference labels, improving the reliability of LLM feedback.
The experiment across multiple tasks in the MetaWorld benchmark demonstrates
the specific contributions of each proposed module in RL-SaLLM-F, and shows
that self-augmented LLM feedback can effectively replace the impractical
""scripted teacher"" feedback. In summary, RL-SaLLM-F introduces a new direction
of feedback acquisition in online PbRL that does not rely on any online
privileged information, offering an efficient and lightweight solution with
LLM-driven feedback.",2024-12-22,"Songjun Tu, Jingbo Sun, Qichao Zhang, Xiangyuan Lan, Dongbin Zhao",http://arxiv.org/pdf/2412.16878v1,cs.LG
"Engineering Carbon Credits Towards A Responsible FinTech Era: The Practices, Implications, and Future","Carbon emissions significantly contribute to climate change, and carbon
credits have emerged as a key tool for mitigating environmental damage and
helping organizations manage their carbon footprint. Despite their growing
importance across sectors, fully leveraging carbon credits remains challenging.
This study explores engineering practices and fintech solutions to enhance
carbon emission management. We first review the negative impacts of carbon
emission non-disclosure, revealing its adverse effects on financial stability
and market value. Organizations are encouraged to actively manage emissions and
disclose relevant data to mitigate risks. Next, we analyze factors influencing
carbon prices and review advanced prediction algorithms that optimize carbon
credit purchasing strategies, reducing costs and improving efficiency.
Additionally, we examine corporate carbon emission prediction models, which
offer accurate performance assessments and aid in planning future carbon credit
needs. By integrating carbon price and emission predictions, we propose
research directions, including corporate carbon management cost forecasting.
This study provides a foundation for future quantitative research on the
financial and market impacts of carbon management practices and is the first
systematic review focusing on computing solutions and engineering practices for
carbon credits.",2024-12-22,"Qingwen Zeng, Hanlin Xu, Nanjun Xu, Flora Salim, Junbin Gao, Huaming Chen",http://arxiv.org/pdf/2501.14750v1,cs.LG
A Parameter-Efficient Quantum Anomaly Detection Method on a Superconducting Quantum Processor,"Quantum machine learning has gained attention for its potential to address
computational challenges. However, whether those algorithms can effectively
solve practical problems and outperform their classical counterparts,
especially on current quantum hardware, remains a critical question. In this
work, we propose a novel quantum machine learning method, called
Parameter-Efficient Quantum Anomaly Detection (PEQAD), for practical image
anomaly detection, which aims to achieve both parameter efficiency and superior
accuracy compared to classical models. Emulation results indicate that PEQAD
demonstrates favourable recognition capabilities compared to classical
baselines, achieving an average accuracy of over 90% on benchmarks with
significantly fewer trainable parameters. Theoretical analysis confirms that
PEQAD has a comparable expressivity to classical counterparts while requiring
only a fraction of the parameters. Furthermore, we demonstrate the first
implementation of a quantum anomaly detection method for general image datasets
on a superconducting quantum processor. Specifically, we achieve an accuracy of
over 80% with only 16 parameters on the device, providing initial evidence of
PEQAD's practical viability in the noisy intermediate-scale quantum era and
highlighting its significant reduction in parameter requirements.",2024-12-22,"Maida Wang, Jinyang Jiang, Peter V. Coveney",http://arxiv.org/pdf/2412.16867v3,cs.LG
Sharpness-Aware Minimization with Adaptive Regularization for Training Deep Neural Networks,"Sharpness-Aware Minimization (SAM) has proven highly effective in improving
model generalization in machine learning tasks. However, SAM employs a fixed
hyperparameter associated with the regularization to characterize the sharpness
of the model. Despite its success, research on adaptive regularization methods
based on SAM remains scarce. In this paper, we propose the SAM with Adaptive
Regularization (SAMAR), which introduces a flexible sharpness ratio rule to
update the regularization parameter dynamically. We provide theoretical proof
of the convergence of SAMAR for functions satisfying the Lipschitz continuity.
Additionally, experiments on image recognition tasks using CIFAR-10 and
CIFAR-100 demonstrate that SAMAR enhances accuracy and model generalization.",2024-12-22,"Jinping Zou, Xiaoge Deng, Tao Sun",http://arxiv.org/pdf/2412.16854v1,cs.LG
RoboSignature: Robust Signature and Watermarking on Network Attacks,"Generative models have enabled easy creation and generation of images of all
kinds given a single prompt. However, this has also raised ethical concerns
about what is an actual piece of content created by humans or cameras compared
to model-generated content like images or videos. Watermarking data generated
by modern generative models is a popular method to provide information on the
source of the content. The goal is for all generated images to conceal an
invisible watermark, allowing for future detection or identification. The
Stable Signature finetunes the decoder of Latent Diffusion Models such that a
unique watermark is rooted in any image produced by the decoder. In this paper,
we present a novel adversarial fine-tuning attack that disrupts the model's
ability to embed the intended watermark, exposing a significant vulnerability
in existing watermarking methods. To address this, we further propose a
tamper-resistant fine-tuning algorithm inspired by methods developed for large
language models, tailored to the specific requirements of watermarking in LDMs.
Our findings emphasize the importance of anticipating and defending against
potential vulnerabilities in generative systems.",2024-12-22,"Aryaman Shaan, Garvit Banga, Raghav Mantri",http://arxiv.org/pdf/2412.19834v1,cs.LG
ACL-QL: Adaptive Conservative Level in Q-Learning for Offline Reinforcement Learning,"Offline Reinforcement Learning (RL), which operates solely on static datasets
without further interactions with the environment, provides an appealing
alternative to learning a safe and promising control policy. The prevailing
methods typically learn a conservative policy to mitigate the problem of
Q-value overestimation, but it is prone to overdo it, leading to an overly
conservative policy. Moreover, they optimize all samples equally with fixed
constraints, lacking the nuanced ability to control conservative levels in a
fine-grained manner. Consequently, this limitation results in a performance
decline. To address the above two challenges in a united way, we propose a
framework, Adaptive Conservative Level in Q-Learning (ACL-QL), which limits the
Q-values in a mild range and enables adaptive control on the conservative level
over each state-action pair, i.e., lifting the Q-values more for good
transitions and less for bad transitions. We theoretically analyze the
conditions under which the conservative level of the learned Q-function can be
limited in a mild range and how to optimize each transition adaptively.
Motivated by the theoretical analysis, we propose a novel algorithm, ACL-QL,
which uses two learnable adaptive weight functions to control the conservative
level over each transition. Subsequently, we design a monotonicity loss and
surrogate losses to train the adaptive weight functions, Q-function, and policy
network alternatively. We evaluate ACL-QL on the commonly used D4RL benchmark
and conduct extensive ablation studies to illustrate the effectiveness and
state-of-the-art performance compared to existing offline DRL baselines.",2024-12-22,"Kun Wu, Yinuo Zhao, Zhiyuan Xu, Zhengping Che, Chengxiang Yin, Chi Harold Liu, Feiferi Feng, Jian Tang",http://arxiv.org/pdf/2412.16848v2,cs.LG
Graph Learning-based Regional Heavy Rainfall Prediction Using Low-Cost Rain Gauges,"Accurate and timely prediction of heavy rainfall events is crucial for
effective flood risk management and disaster preparedness. By monitoring,
analysing, and evaluating rainfall data at a local level, it is not only
possible to take effective actions to prevent any severe climate variation but
also to improve the planning of surface and underground hydrological resources.
However, developing countries often lack the weather stations to collect data
continuously due to the high cost of installation and maintenance. In light of
this, the contribution of the present paper is twofold: first, we propose a
low-cost IoT system for automatic recording, monitoring, and prediction of
rainfall in rural regions. Second, we propose a novel approach to regional
heavy rainfall prediction by implementing graph neural networks (GNNs), which
are particularly well-suited for capturing the complex spatial dependencies
inherent in rainfall patterns. The proposed approach was tested using a
historical dataset spanning 72 months, with daily measurements, and
experimental results demonstrated the effectiveness of the proposed method in
predicting heavy rainfall events, making this approach particularly attractive
for regions with limited resources or where traditional weather radar or
station coverage is sparse.",2024-12-22,Edwin Salcedo,http://arxiv.org/pdf/2412.16842v1,cs.LG
KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis,"Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.",2024-12-22,"Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio",http://arxiv.org/pdf/2412.16833v4,cs.LG
Algorithm Design for Continual Learning in IoT Networks,"Continual learning (CL) is a new online learning technique over sequentially
generated streaming data from different tasks, aiming to maintain a small
forgetting loss on previously-learned tasks. Existing work focuses on reducing
the forgetting loss under a given task sequence. However, if similar tasks
continuously appear to the end time, the forgetting loss is still huge on prior
distinct tasks. In practical IoT networks, an autonomous vehicle to sample data
and learn different tasks can route and alter the order of task pattern at
increased travelling cost. To our best knowledge, we are the first to study how
to opportunistically route the testing object and alter the task sequence in
CL. We formulate a new optimization problem and prove it NP-hard. We propose a
polynomial-time algorithm to achieve approximation ratios of $\frac{3}{2}$ for
underparameterized case and $\frac{3}{2} + r^{1-T}$ for overparameterized case,
respectively, where $r:=1-\frac{n}{m}$ is a parameter of feature number $m$ and
sample number $n$ and $T$ is the task number. Simulation results verify our
algorithm's close-to-optimum performance.",2024-12-22,"Shugang Hao, Lingjie Duan",http://arxiv.org/pdf/2412.16830v2,cs.LG
Layer- and Timestep-Adaptive Differentiable Token Compression Ratios for Efficient Diffusion Transformers,"Diffusion Transformers (DiTs) have achieved state-of-the-art (SOTA) image
generation quality but suffer from high latency and memory inefficiency, making
them difficult to deploy on resource-constrained devices. One major efficiency
bottleneck is that existing DiTs apply equal computation across all regions of
an image. However, not all image tokens are equally important, and certain
localized areas require more computation, such as objects. To address this, we
propose DiffCR, a dynamic DiT inference framework with differentiable
compression ratios, which automatically learns to dynamically route computation
across layers and timesteps for each image token, resulting in efficient DiTs.
Specifically, DiffCR integrates three features: (1) A token-level routing
scheme where each DiT layer includes a router that is fine-tuned jointly with
model weights to predict token importance scores. In this way, unimportant
tokens bypass the entire layer's computation; (2) A layer-wise differentiable
ratio mechanism where different DiT layers automatically learn varying
compression ratios from a zero initialization, resulting in large compression
ratios in redundant layers while others remain less compressed or even
uncompressed; (3) A timestep-wise differentiable ratio mechanism where each
denoising timestep learns its own compression ratio. The resulting pattern
shows higher ratios for noisier timesteps and lower ratios as the image becomes
clearer. Extensive experiments on text-to-image and inpainting tasks show that
DiffCR effectively captures dynamism across token, layer, and timestep axes,
achieving superior trade-offs between generation quality and efficiency
compared to prior works. The project website is available at
https://www.haoranyou.com/diffcr.",2024-12-22,"Haoran You, Connelly Barnes, Yuqian Zhou, Yan Kang, Zhenbang Du, Wei Zhou, Lingzhi Zhang, Yotam Nitzan, Xiaoyang Liu, Zhe Lin, Eli Shechtman, Sohrab Amirghodsi, Yingyan Celine Lin",http://arxiv.org/pdf/2412.16822v2,cs.LG
Bi-Sparse Unsupervised Feature Selection,"To efficiently deal with high-dimensional datasets in many areas,
unsupervised feature selection (UFS) has become a rising technique for
dimension reduction. Even though there are many UFS methods, most of them only
consider the global structure of datasets by embedding a single sparse
regularization or constraint. In this paper, we introduce a novel bi-sparse UFS
method, called BSUFS, to simultaneously characterize both global and local
structures. The core idea of BSUFS is to incorporate $\ell_{2,p}$-norm and
$\ell_q$-norm into the classical principal component analysis (PCA), which
enables our proposed method to select relevant features and filter out
irrelevant noise accurately. Here, the parameters $p$ and $q$ are within the
range of [0,1). Therefore, BSUFS not only constructs a unified framework for
bi-sparse optimization, but also includes some existing works as special cases.
To solve the resulting non-convex model, we propose an efficient proximal
alternating minimization (PAM) algorithm using Riemannian manifold optimization
and sparse optimization techniques. Theoretically, PAM is proven to have global
convergence, i.e., for any random initial point, the generated sequence
converges to a critical point that satisfies the first-order optimality
condition. Extensive numerical experiments on synthetic and real-world datasets
demonstrate the effectiveness of our proposed BSUFS. Specifically, the average
accuracy (ACC) is improved by at least 4.71% and the normalized mutual
information (NMI) is improved by at least 3.14% on average compared to the
existing UFS competitors. The results validate the advantages of bi-sparse
optimization in feature selection and show its potential for other fields in
image processing. Our code will be available at https://github.com/xianchaoxiu.",2024-12-22,"Xianchao Xiu, Chenyi Huang, Pan Shang, Wanquan Liu",http://arxiv.org/pdf/2412.16819v1,cs.LG
Unsupervised Discovery of Formulas for Mathematical Constants,"Ongoing efforts that span over decades show a rise of AI methods for
accelerating scientific discovery, yet accelerating discovery in mathematics
remains a persistent challenge for AI. Specifically, AI methods were not
effective in creation of formulas for mathematical constants because each such
formula must be correct for infinite digits of precision, with ""near-true""
formulas providing no insight toward the correct ones. Consequently, formula
discovery lacks a clear distance metric needed to guide automated discovery in
this realm.
  In this work, we propose a systematic methodology for categorization,
characterization, and pattern identification of such formulas. The key to our
methodology is introducing metrics based on the convergence dynamics of the
formulas, rather than on the numerical value of the formula. These metrics
enable the first automated clustering of mathematical formulas. We demonstrate
this methodology on Polynomial Continued Fraction formulas, which are
ubiquitous in their intrinsic connections to mathematical constants, and
generalize many mathematical functions and structures.
  We test our methodology on a set of 1,768,900 such formulas, identifying many
known formulas for mathematical constants, and discover previously unknown
formulas for $\pi$, $\ln(2)$, Gauss', and Lemniscate's constants. The uncovered
patterns enable a direct generalization of individual formulas to infinite
families, unveiling rich mathematical structures. This success paves the way
towards a generative model that creates formulas fulfilling specified
mathematical properties, accelerating the rate of discovery of useful formulas.",2024-12-22,"Michael Shalyt, Uri Seligmann, Itay Beit Halachmi, Ofir David, Rotem Elimelech, Ido Kaminer",http://arxiv.org/pdf/2412.16818v1,cs.LG
Balls-and-Bins Sampling for DP-SGD,"We introduce the Balls-and-Bins sampling for differentially private (DP)
optimization methods such as DP-SGD. While it has been common practice to use
some form of shuffling in DP-SGD implementations, privacy accounting algorithms
have typically assumed that Poisson subsampling is used instead. Recent work by
Chua et al. (ICML 2024), however, pointed out that shuffling based DP-SGD can
have a much larger privacy cost in practical regimes of parameters. In this
work we show that the Balls-and-Bins sampling achieves the ""best-of-both""
samplers, namely, the implementation of Balls-and-Bins sampling is similar to
that of Shuffling and models trained using DP-SGD with Balls-and-Bins sampling
achieve utility comparable to those trained using DP-SGD with Shuffling at the
same noise multiplier, and yet, Balls-and-Bins sampling enjoys
similar-or-better privacy amplification as compared to Poisson subsampling in
practical regimes.",2024-12-21,"Lynn Chua, Badih Ghazi, Charlie Harrison, Ethan Leeman, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chiyuan Zhang",http://arxiv.org/pdf/2412.16802v2,cs.LG
Gradient-Based Non-Linear Inverse Learning,"We study statistical inverse learning in the context of nonlinear inverse
problems under random design. Specifically, we address a class of nonlinear
problems by employing gradient descent (GD) and stochastic gradient descent
(SGD) with mini-batching, both using constant step sizes. Our analysis derives
convergence rates for both algorithms under classical a priori assumptions on
the smoothness of the target function. These assumptions are expressed in terms
of the integral operator associated with the tangent kernel, as well as through
a bound on the effective dimension. Additionally, we establish stopping times
that yield minimax-optimal convergence rates within the classical reproducing
kernel Hilbert space (RKHS) framework. These results demonstrate the efficacy
of GD and SGD in achieving optimal rates for nonlinear inverse problems in
random design.",2024-12-21,"Abhishake, Nicole Mücke, Tapio Helin",http://arxiv.org/pdf/2412.16794v1,cs.LG
Enhancing web traffic attacks identification through ensemble methods and feature selection,"Websites, as essential digital assets, are highly vulnerable to cyberattacks
because of their high traffic volume and the significant impact of breaches.
This study aims to enhance the identification of web traffic attacks by
leveraging machine learning techniques. A methodology was proposed to extract
relevant features from HTTP traces using the CSIC2010 v2 dataset, which
simulates e-commerce web traffic. Ensemble methods, such as Random Forest and
Extreme Gradient Boosting, were employed and compared against baseline
classifiers, including k-nearest Neighbor, LASSO, and Support Vector Machines.
The results demonstrate that the ensemble methods outperform baseline
classifiers by approximately 20% in predictive accuracy, achieving an Area
Under the ROC Curve (AUC) of 0.989. Feature selection methods such as
Information Gain, LASSO, and Random Forest further enhance the robustness of
these models. This study highlights the efficacy of ensemble models in
improving attack detection while minimizing performance variability, offering a
practical framework for securing web traffic in diverse application contexts.",2024-12-21,"Daniel Urda, Branly Martínez, Nuño Basurto, Meelis Kull, Ángel Arroyo, Álvaro Herrero",http://arxiv.org/pdf/2412.16791v1,cs.LG
Symplectic Neural Flows for Modeling and Discovery,"Hamilton's equations are fundamental for modeling complex physical systems,
where preserving key properties such as energy and momentum is crucial for
reliable long-term simulations. Geometric integrators are widely used for this
purpose, but neural network-based methods that incorporate these principles
remain underexplored. This work introduces SympFlow, a time-dependent
symplectic neural network designed using parameterized Hamiltonian flow maps.
This design allows for backward error analysis and ensures the preservation of
the symplectic structure. SympFlow allows for two key applications: (i)
providing a time-continuous symplectic approximation of the exact flow of a
Hamiltonian system--purely based on the differential equations it satisfies,
and (ii) approximating the flow map of an unknown Hamiltonian system relying on
trajectory data. We demonstrate the effectiveness of SympFlow on diverse
problems, including chaotic and dissipative systems, showing improved energy
conservation compared to general-purpose numerical methods and accurate",2024-12-21,"Priscilla Canizares, Davide Murari, Carola-Bibiane Schönlieb, Ferdia Sherry, Zakhar Shumaylov",http://arxiv.org/pdf/2412.16787v1,cs.LG
Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification,"Machine unlearning (MU), which seeks to erase the influence of specific
unwanted data from already-trained models, is becoming increasingly vital in
model editing, particularly to comply with evolving data regulations like the
``right to be forgotten''. Conventional approaches are predominantly
model-based, typically requiring retraining or fine-tuning the model's weights
to meet unlearning requirements. In this work, we approach the MU problem from
a novel input perturbation-based perspective, where the model weights remain
intact throughout the unlearning process. We demonstrate the existence of a
proactive input-based unlearning strategy, referred to forget vector, which can
be generated as an input-agnostic data perturbation and remains as effective as
model-based approximate unlearning approaches. We also explore forget vector
arithmetic, whereby multiple class-specific forget vectors are combined through
simple operations (e.g., linear combinations) to generate new forget vectors
for unseen unlearning tasks, such as forgetting arbitrary subsets across
classes. Extensive experiments validate the effectiveness and adaptability of
the forget vector, showcasing its competitive performance relative to
state-of-the-art model-based methods. Codes are available at
https://github.com/Changchangsun/Forget-Vector.",2024-12-21,"Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Yan Yan, Sijia Liu",http://arxiv.org/pdf/2412.16780v4,cs.LG
Fed-ZOE: Communication-Efficient Over-the-Air Federated Learning via Zeroth-Order Estimation,"As 6G and beyond networks grow increasingly complex and interconnected,
federated learning (FL) emerges as an indispensable paradigm for securely and
efficiently leveraging decentralized edge data for AI. By virtue of the
superposition property of communication signals, over-the-air FL (OtA-FL)
achieves constant communication overhead irrespective of the number of edge
devices (EDs). However, training neural networks over the air still incurs
substantial communication costs, as the number of transmitted symbols equals
the number of trainable parameters. To alleviate this issue, the most
straightforward approach is to reduce the number of transmitted symbols by 1)
gradient compression and 2) gradient sparsification. Unfortunately, these
methods are incompatible with OtA-FL due to the loss of its superposition
property. In this work, we introduce federated zeroth-order estimation
(Fed-ZOE), an efficient framework inspired by the randomized gradient estimator
(RGE) commonly used in zeroth-order optimization (ZOO). In FedZOE, EDs perform
local weight updates as in standard FL, but instead of transmitting full
gradient vectors, they send compressed local model update vectors in the form
of several scalar-valued inner products between the local model update vectors
and random vectors. These scalar values enable the parameter server (PS) to
reconstruct the gradient using the RGE trick with highly reduced overhead, as
well as preserving the superposition property. Unlike conventional ZOO
leveraging RGE for step-wise gradient descent, Fed-ZOE compresses local model
update vectors before transmission, thereby achieving higher accuracy and
computational efficiency. Numerical evaluations using ResNet-18 on datasets
such as CIFAR-10, TinyImageNet, SVHN, CIFAR-100, and Brain-CT demonstrate that
Fed-ZOE achieves performance comparable to Fed-OtA while drastically reducing
communication costs.",2024-12-21,"Jonggyu Jang, Hyeonsu Lyu, David J. Love, Hyun Jong Yang",http://arxiv.org/pdf/2412.16779v1,cs.LG
HyperCLIP: Adapting Vision-Language models with Hypernetworks,"Self-supervised vision-language models trained with contrastive objectives
form the basis of current state-of-the-art methods in AI vision tasks. The
success of these models is a direct consequence of the huge web-scale datasets
used to train them, but they require correspondingly large vision components to
properly learn powerful and general representations from such a broad data
domain. This poses a challenge for deploying large vision-language models,
especially in resource-constrained environments. To address this, we propose an
alternate vision-language architecture, called HyperCLIP, that uses a small
image encoder along with a hypernetwork that dynamically adapts image encoder
weights to each new set of text inputs. All three components of the model
(hypernetwork, image encoder, and text encoder) are pre-trained jointly
end-to-end, and with a trained HyperCLIP model, we can generate new zero-shot
deployment-friendly image classifiers for any task with a single forward pass
through the text encoder and hypernetwork. HyperCLIP increases the zero-shot
accuracy of SigLIP trained models with small image encoders by up to 3% on
ImageNet and 5% on CIFAR-100 with minimal training throughput overhead.",2024-12-21,"Victor Akinwande, Mohammad Sadegh Norouzzadeh, Devin Willmott, Anna Bair, Madan Ravi Ganesh, J. Zico Kolter",http://arxiv.org/pdf/2412.16777v1,cs.LG
DMesh++: An Efficient Differentiable Mesh for Complex Shapes,"Recent probabilistic methods for 3D triangular meshes capture diverse shapes
by differentiable mesh connectivity, but face high computational costs with
increased shape details. We introduce a new differentiable mesh processing
method in 2D and 3D that addresses this challenge and efficiently handles
meshes with intricate structures. Additionally, we present an algorithm that
adapts the mesh resolution to local geometry in 2D for efficient
representation. We demonstrate the effectiveness of our approach on 2D point
cloud and 3D multi-view reconstruction tasks. Visit our project page
(https://sonsang.github.io/dmesh2-project) for source code and supplementary
material.",2024-12-21,"Sanghyun Son, Matheus Gadelha, Yang Zhou, Matthew Fisher, Zexiang Xu, Yi-Ling Qiao, Ming C. Lin, Yi Zhou",http://arxiv.org/pdf/2412.16776v1,cs.LG
Fast Multi-Group Gaussian Process Factor Models,"Gaussian processes are now commonly used in dimensionality reduction
approaches tailored to neuroscience, especially to describe changes in
high-dimensional neural activity over time. As recording capabilities expand to
include neuronal populations across multiple brain areas, cortical layers, and
cell types, interest in extending Gaussian process factor models to
characterize multi-population interactions has grown. However, the cubic
runtime scaling of current methods with the length of experimental trials and
the number of recorded populations (groups) precludes their application to
large-scale multi-population recordings. Here, we improve this scaling from
cubic to linear in both trial length and group number. We present two
approximate approaches to fitting multi-group Gaussian process factor models
based on (1) inducing variables and (2) the frequency domain. Empirically, both
methods achieved orders of magnitude speed-up with minimal impact on
statistical performance, in simulation and on neural recordings of hundreds of
neurons across three brain areas. The frequency domain approach, in particular,
consistently provided the greatest runtime benefits with the fewest trade-offs
in statistical performance. We further characterize the estimation biases
introduced by the frequency domain approach and demonstrate effective
strategies to mitigate them. This work enables a powerful class of analysis
techniques to keep pace with the growing scale of multi-population recordings,
opening new avenues for exploring brain function.",2024-12-21,"Evren Gokcen, Anna I. Jasper, Adam Kohn, Christian K. Machens, Byron M. Yu",http://arxiv.org/pdf/2412.16773v1,cs.LG
Assessing Social Alignment: Do Personality-Prompted Large Language Models Behave Like Humans?,"The ongoing revolution in language modelling has led to various novel
applications, some of which rely on the emerging ""social abilities"" of large
language models (LLMs). Already, many turn to the new ""cyber friends"" for
advice during pivotal moments of their lives and trust them with their deepest
secrets, implying that accurate shaping of LLMs' ""personalities"" is paramount.
Leveraging the vast diversity of data on which LLMs are pretrained,
state-of-the-art approaches prompt them to adopt a particular personality. We
ask (i) if personality-prompted models behave (i.e. ""make"" decisions when
presented with a social situation) in line with the ascribed personality, and
(ii) if their behavior can be finely controlled. We use classic psychological
experiments - the Milgram Experiment and the Ultimatum Game - as social
interaction testbeds and apply personality prompting to GPT-3.5/4/4o-mini/4o.
Our experiments reveal failure modes of the prompt-based modulation of the
models' ""behavior"", thus challenging the feasibility of personality prompting
with today's LLMs.",2024-12-21,"Ivan Zakazov, Mikolaj Boronski, Lorenzo Drudi, Robert West",http://arxiv.org/pdf/2412.16772v1,cs.LG
BoostMD: Accelerating molecular sampling by leveraging ML force field features from previous time-steps,"Simulating atomic-scale processes, such as protein dynamics and catalytic
reactions, is crucial for advancements in biology, chemistry, and materials
science. Machine learning force fields (MLFFs) have emerged as powerful tools
that achieve near quantum mechanical accuracy, with promising generalization
capabilities. However, their practical use is often limited by long inference
times compared to classical force fields, especially when running extensive
molecular dynamics (MD) simulations required for many biological applications.
In this study, we introduce BoostMD, a surrogate model architecture designed to
accelerate MD simulations. BoostMD leverages node features computed at previous
time steps to predict energies and forces based on positional changes. This
approach reduces the complexity of the learning task, allowing BoostMD to be
both smaller and significantly faster than conventional MLFFs. During
simulations, the computationally intensive reference MLFF is evaluated only
every $N$ steps, while the lightweight BoostMD model handles the intermediate
steps at a fraction of the computational cost. Our experiments demonstrate that
BoostMD achieves an eight-fold speedup compared to the reference model and
generalizes to unseen dipeptides. Furthermore, we find that BoostMD accurately
samples the ground-truth Boltzmann distribution when running molecular
dynamics. By combining efficient feature reuse with a streamlined architecture,
BoostMD offers a robust solution for conducting large-scale, long-timescale
molecular simulations, making high-accuracy ML-driven modeling more accessible
and practical.",2024-12-21,"Lars L. Schaaf, Ilyes Batatia, Christoph Brunken, Thomas D. Barrett, Jules Tilly",http://arxiv.org/pdf/2412.18633v1,cs.LG
"Does calibration mean what they say it means; or, the reference class problem rises again","Discussions of statistical criteria for fairness commonly convey the
normative significance of calibration within groups by invoking what risk
scores ""mean."" On the Same Meaning picture, group-calibrated scores ""mean the
same thing"" (on average) across individuals from different groups and
accordingly, guard against disparate treatment of individuals based on group
membership. My contention is that calibration guarantees no such thing. Since
concrete actual people belong to many groups, calibration cannot ensure the
kind of consistent score interpretation that the Same Meaning picture implies
matters for fairness, unless calibration is met within every group to which an
individual belongs. Alas only perfect predictors may meet this bar. The Same
Meaning picture thus commits a reference class fallacy by inferring from
calibration within some group to the ""meaning"" or evidential value of an
individual's score, because they are a member of that group. The reference
class answer it presumes does not only lack justification; it is very likely
wrong. I then show that the reference class problem besets not just calibration
but other group statistical criteria that claim a close connection to fairness.
Reflecting on the origins of this oversight opens a wider lens onto the
predominant methodology in algorithmic fairness based on stylized cases.",2024-12-21,Lily Hu,http://arxiv.org/pdf/2412.16769v2,cs.LG
A Comparative Study on Machine Learning Models to Classify Diseases Based on Patient Behaviour and Habits,"In recent years, ML algorithms have been shown to be useful for predicting
diseases based on health data and posed a potential application area for these
algorithms such as modeling of diseases. The majority of these applications
employ supervised rather than unsupervised ML algorithms. In addition, each
year, the amount of data in medical science grows rapidly. Moreover, these data
include clinical and Patient-Related Factors (PRF), such as height, weight,
age, other physical characteristics, blood sugar, lipids, insulin, etc., all of
which will change continually over time. Analysis of historical data can help
identify disease risk factors and their interactions, which is useful for
disease diagnosis and prediction. This wealth of valuable information in these
data will help doctors diagnose accurately and people can become more aware of
the risk factors and key indicators to act proactively. The purpose of this
study is to use six supervised ML approaches to fill this gap by conducting a
comprehensive experiment to investigate the correlation between PRF and
Diabetes, Stroke, Heart Disease (HD), and Kidney Disease (KD). Moreover, it
will investigate the link between Diabetes, Stroke, and KD and PRF with HD.
Further, the research aims to compare and evaluate various ML algorithms for
classifying diseases based on the PRF. Additionally, it aims to compare and
evaluate ML algorithms for classifying HD based on PRF as well as Diabetes,
Stroke, Asthma, Skin Cancer, and KD as attributes. Lastly, HD predictions will
be provided through a Web-based application on the most accurate classifier,
which allows the users to input their values and predict the output.",2024-12-21,"Elham Musaaed, Nabil Hewahi, Abdulla Alasaadi",http://arxiv.org/pdf/2412.16768v1,cs.LG
Optimization Insights into Deep Diagonal Linear Networks,"Overparameterized models trained with (stochastic) gradient descent are
ubiquitous in modern machine learning. These large models achieve unprecedented
performance on test data, but their theoretical understanding is still limited.
In this paper, we take a step towards filling this gap by adopting an
optimization perspective. More precisely, we study the implicit regularization
properties of the gradient flow ""algorithm"" for estimating the parameters of a
deep diagonal neural network. Our main contribution is showing that this
gradient flow induces a mirror flow dynamic on the model, meaning that it is
biased towards a specific solution of the problem depending on the
initialization of the network. Along the way, we prove several properties of
the trajectory.",2024-12-21,"Hippolyte Labarrière, Cesare Molinari, Lorenzo Rosasco, Silvia Villa, Cristian Vega",http://arxiv.org/pdf/2412.16765v2,cs.LG
Paraformer: Parameterization of Sub-grid Scale Processes Using Transformers,"One of the major sources of uncertainty in the current generation of Global
Climate Models (GCMs) is the representation of sub-grid scale physical
processes. Over the years, a series of deep-learning-based parameterization
schemes have been developed and tested on both idealized and real-geography
GCMs. However, datasets on which previous deep-learning models were trained
either contain limited variables or have low spatial-temporal coverage, which
can not fully simulate the parameterization process. Additionally, these
schemes rely on classical architectures while the latest attention mechanism
used in Transformer models remains unexplored in this field. In this paper, we
propose Paraformer, a ""memory-aware"" Transformer-based model on ClimSim, the
largest dataset ever created for climate parameterization. Our results
demonstrate that the proposed model successfully captures the complex
non-linear dependencies in the sub-grid scale variables and outperforms
classical deep-learning architectures. This work highlights the applicability
of the attenuation mechanism in this field and provides valuable insights for
developing future deep-learning-based climate parameterization schemes.",2024-12-21,"Shuochen Wang, Nishant Yadav, Auroop R. Ganguly",http://arxiv.org/pdf/2412.16763v1,cs.LG
Leveraging Highly Approximated Multipliers in DNN Inference,"In this work, we present a control variate approximation technique that
enables the exploitation of highly approximate multipliers in Deep Neural
Network (DNN) accelerators. Our approach does not require retraining and
significantly decreases the induced error due to approximate multiplications,
improving the overall inference accuracy. As a result, our approach enables
satisfying tight accuracy loss constraints while boosting the power savings.
Our experimental evaluation, across six different DNNs and several approximate
multipliers, demonstrates the versatility of our approach and shows that
compared to the accurate design, our control variate approximation achieves the
same performance, 45% power reduction, and less than 1% average accuracy loss.
Compared to the corresponding approximate designs without using our technique,
our approach improves the accuracy by 1.9x on average.",2024-12-21,"Georgios Zervakis, Fabio Frustaci, Ourania Spantidi, Iraklis Anagnostopoulos, Hussam Amrouch, Jörg Henkel",http://arxiv.org/pdf/2412.16757v1,cs.LG
Gradient-based Trajectory Optimization with Parallelized Differentiable Traffic Simulation,"We present a parallelized differentiable traffic simulator based on the
Intelligent Driver Model (IDM), a car-following framework that incorporates
driver behavior as key variables. Our vehicle simulator efficiently models
vehicle motion, generating trajectories that can be supervised to fit
real-world data. By leveraging its differentiable nature, IDM parameters are
optimized using gradient-based methods. With the capability to simulate up to 2
million vehicles in real time, the system is scalable for large-scale
trajectory optimization. We show that we can use the simulator to filter noise
in the input trajectories (trajectory filtering), reconstruct dense
trajectories from sparse ones (trajectory reconstruction), and predict future
trajectories (trajectory prediction), with all generated trajectories adhering
to physical laws. We validate our simulator and algorithm on several datasets
including NGSIM and Waymo Open Dataset. The code is publicly available at:
https://github.com/SonSang/diffidm.",2024-12-21,"Sanghyun Son, Laura Zheng, Brian Clipp, Connor Greenwell, Sujin Philip, Ming C. Lin",http://arxiv.org/pdf/2412.16750v2,cs.LG
Solving Inverse Problems via Diffusion Optimal Control,"Existing approaches to diffusion-based inverse problem solvers frame the
signal recovery task as a probabilistic sampling episode, where the solution is
drawn from the desired posterior distribution. This framework suffers from
several critical drawbacks, including the intractability of the conditional
likelihood function, strict dependence on the score network approximation, and
poor $\mathbf{x}_0$ prediction quality. We demonstrate that these limitations
can be sidestepped by reframing the generative process as a discrete optimal
control episode. We derive a diffusion-based optimal controller inspired by the
iterative Linear Quadratic Regulator (iLQR) algorithm. This framework is fully
general and able to handle any differentiable forward measurement operator,
including super-resolution, inpainting, Gaussian deblurring, nonlinear
deblurring, and even highly nonlinear neural classifiers. Furthermore, we show
that the idealized posterior sampling equation can be recovered as a special
case of our algorithm. We then evaluate our method against a selection of
neural inverse problem solvers, and establish a new baseline in image
reconstruction with inverse problems.",2024-12-21,"Henry Li, Marcus Pereira",http://arxiv.org/pdf/2412.16748v1,cs.LG
KKANs: Kurkova-Kolmogorov-Arnold Networks and Their Learning Dynamics,"Inspired by the Kolmogorov-Arnold representation theorem and Kurkova's
principle of using approximate representations, we propose the
Kurkova-Kolmogorov-Arnold Network (KKAN), a new two-block architecture that
combines robust multi-layer perceptron (MLP) based inner functions with
flexible linear combinations of basis functions as outer functions. We first
prove that KKAN is a universal approximator, and then we demonstrate its
versatility across scientific machine-learning applications, including function
regression, physics-informed machine learning (PIML), and operator-learning
frameworks. The benchmark results show that KKANs outperform MLPs and the
original Kolmogorov-Arnold Networks (KANs) in function approximation and
operator learning tasks and achieve performance comparable to fully optimized
MLPs for PIML. To better understand the behavior of the new representation
models, we analyze their geometric complexity and learning dynamics using
information bottleneck theory, identifying three universal learning stages,
fitting, transition, and diffusion, across all types of architectures. We find
a strong correlation between geometric complexity and signal-to-noise ratio
(SNR), with optimal generalization achieved during the diffusion stage.
Additionally, we propose self-scaled residual-based attention weights to
maintain high SNR dynamically, ensuring uniform convergence and prolonged
learning.",2024-12-21,"Juan Diego Toscano, Li-Lian Wang, George Em Karniadakis",http://arxiv.org/pdf/2412.16738v1,cs.LG
Coupling Neural Networks and Physics Equations For Li-Ion Battery State-of-Charge Prediction,"Estimating the evolution of the battery's State of Charge (SoC) in response
to its usage is critical for implementing effective power management policies
and for ultimately improving the system's lifetime. Most existing estimation
methods are either physics-based digital twins of the battery or data-driven
models such as Neural Networks (NNs). In this work, we propose two new
contributions in this domain. First, we introduce a novel NN architecture
formed by two cascaded branches: one to predict the current SoC based on sensor
readings, and one to estimate the SoC at a future time as a function of the
load behavior. Second, we integrate battery dynamics equations into the
training of our NN, merging the physics-based and data-driven approaches, to
improve the models' generalization over variable prediction horizons. We
validate our approach on two publicly accessible datasets, showing that our
Physics-Informed Neural Networks (PINNs) outperform purely data-driven ones
while also obtaining superior prediction accuracy with a smaller architecture
with respect to the state-of-the-art.",2024-12-21,"Giovanni Pollo, Alessio Burrello, Enrico Macii, Massimo Poncino, Sara Vinco, Daniele Jahier Pagliari",http://arxiv.org/pdf/2412.16724v1,cs.LG
Lillama: Large Language Models Compression via Low-Rank Feature Distillation,"Current LLM structured pruning methods typically involve two steps: (1)
compression with calibration data and (2) costly continued pretraining on
billions of tokens to recover lost performance. This second step is necessary
as the first significantly impacts model accuracy. Prior research suggests
pretrained Transformer weights aren't inherently low-rank, unlike their
activations, which may explain this drop. Based on this observation, we propose
Lillama, a compression method that locally distills activations with low-rank
weights. Using SVD for initialization and a joint loss combining teacher and
student activations, we accelerate convergence and reduce memory use with local
gradient updates. Lillama compresses Mixtral-8x7B within minutes on a single
A100 GPU, removing 10 billion parameters while retaining over 95% of its
original performance. Phi-2 3B can be compressed by 40% with just 13 million
calibration tokens, resulting in a small model that competes with recent models
of similar size. The method generalizes well to non-transformer architectures,
compressing Mamba-3B by 20% while maintaining 99% performance.",2024-12-21,"Yaya Sy, Christophe Cerisara, Irina Illina",http://arxiv.org/pdf/2412.16719v2,cs.LG
GANFusion: Feed-Forward Text-to-3D with Diffusion in GAN Space,"We train a feed-forward text-to-3D diffusion generator for human characters
using only single-view 2D data for supervision. Existing 3D generative models
cannot yet match the fidelity of image or video generative models.
State-of-the-art 3D generators are either trained with explicit 3D supervision
and are thus limited by the volume and diversity of existing 3D data.
Meanwhile, generators that can be trained with only 2D data as supervision
typically produce coarser results, cannot be text-conditioned, or must revert
to test-time optimization. We observe that GAN- and diffusion-based generators
have complementary qualities: GANs can be trained efficiently with 2D
supervision to produce high-quality 3D objects but are hard to condition on
text. In contrast, denoising diffusion models can be conditioned efficiently
but tend to be hard to train with only 2D supervision. We introduce GANFusion,
which starts by generating unconditional triplane features for 3D data using a
GAN architecture trained with only single-view 2D data. We then generate random
samples from the GAN, caption them, and train a text-conditioned diffusion
model that directly learns to sample from the space of good triplane features
that can be decoded into 3D objects.",2024-12-21,"Souhaib Attaiki, Paul Guerrero, Duygu Ceylan, Niloy J. Mitra, Maks Ovsjanikov",http://arxiv.org/pdf/2412.16717v1,cs.LG
A Unifying Family of Data-Adaptive Partitioning Algorithms,"Clustering algorithms remain valuable tools for grouping and summarizing the
most important aspects of data. Example areas where this is the case include
image segmentation, dimension reduction, signals analysis, model order
reduction, numerical analysis, and others. As a consequence, many clustering
approaches have been developed to satisfy the unique needs of each particular
field. In this article, we present a family of data-adaptive partitioning
algorithms that unifies several well-known methods (e.g., k-means and
k-subspaces). Indexed by a single parameter and employing a common minimization
strategy, the algorithms are easy to use and interpret, and scale well to
large, high-dimensional problems. In addition, we develop an adaptive mechanism
that (a) exhibits skill at automatically uncovering data structures and problem
parameters without any expert knowledge and, (b) can be used to augment other
existing methods. By demonstrating the performance of our methods on examples
from disparate fields including subspace clustering, model order reduction, and
matrix approximation, we hope to highlight their versatility and potential for
extending the boundaries of existing scientific domains. We believe our
family's parametrized structure represents a synergism of algorithms that will
foster new developments and directions, not least within the data science
community.",2024-12-21,"Guy B. Oldaker IV, Maria Emelianenko",http://arxiv.org/pdf/2412.16713v1,cs.LG
From Correlation to Causation: Understanding Climate Change through Causal Analysis and LLM Interpretations,"This research presents a three-step causal inference framework that
integrates correlation analysis, machine learning-based causality discovery,
and LLM-driven interpretations to identify socioeconomic factors influencing
carbon emissions and contributing to climate change. The approach begins with
identifying correlations, progresses to causal analysis, and enhances decision
making through LLM-generated inquiries about the context of climate change. The
proposed framework offers adaptable solutions that support data-driven
policy-making and strategic decision-making in climate-related contexts,
uncovering causal relationships within the climate change domain.",2024-12-21,Shan Shan,http://arxiv.org/pdf/2412.16691v1,cs.LG
Subgoal Discovery Using a Free Energy Paradigm and State Aggregations,"Reinforcement learning (RL) plays a major role in solving complex sequential
decision-making tasks. Hierarchical and goal-conditioned RL are promising
methods for dealing with two major problems in RL, namely sample inefficiency
and difficulties in reward shaping. These methods tackle the mentioned problems
by decomposing a task into simpler subtasks and temporally abstracting a task
in the action space. One of the key components for task decomposition of these
methods is subgoal discovery. We can use the subgoal states to define
hierarchies of actions and also use them in decomposing complex tasks. Under
the assumption that subgoal states are more unpredictable, we propose a free
energy paradigm to discover them. This is achieved by using free energy to
select between two spaces, the main space and an aggregation space. The $model
\; changes$ from neighboring states to a given state shows the unpredictability
of a given state, and therefore it is used in this paper for subgoal discovery.
Our empirical results on navigation tasks like grid-world environments show
that our proposed method can be applied for subgoal discovery without prior
knowledge of the task. Our proposed method is also robust to the stochasticity
of environments.",2024-12-21,"Amirhossein Mesbah, Reshad Hosseini, Seyed Pooya Shariatpanahi, Majid Nili Ahmadabadi",http://arxiv.org/pdf/2412.16687v2,cs.LG
The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents,"Large Language Model (LLM) agents are increasingly being deployed as
conversational assistants capable of performing complex real-world tasks
through tool integration. This enhanced ability to interact with external
systems and process various data sources, while powerful, introduces
significant security vulnerabilities. In particular, indirect prompt injection
attacks pose a critical threat, where malicious instructions embedded within
external data sources can manipulate agents to deviate from user intentions.
While existing defenses based on rule constraints, source spotlighting, and
authentication protocols show promise, they struggle to maintain robust
security while preserving task functionality. We propose a novel and orthogonal
perspective that reframes agent security from preventing harmful actions to
ensuring task alignment, requiring every agent action to serve user objectives.
Based on this insight, we develop Task Shield, a test-time defense mechanism
that systematically verifies whether each instruction and tool call contributes
to user-specified goals. Through experiments on the AgentDojo benchmark, we
demonstrate that Task Shield reduces attack success rates (2.07\%) while
maintaining high task utility (69.79\%) on GPT-4o.",2024-12-21,"Feiran Jia, Tong Wu, Xin Qin, Anna Squicciarini",http://arxiv.org/pdf/2412.16682v1,cs.LG
Label Privacy in Split Learning for Large Models with Parameter-Efficient Training,"As deep learning models become larger and more expensive, many practitioners
turn to fine-tuning APIs. These web services allow fine-tuning a model between
two parties: the client that provides the data, and the server that hosts the
model. While convenient, these APIs raise a new concern: the data of the client
is at risk of privacy breach during the training procedure. This challenge
presents an important practical case of vertical federated learning, where the
two parties perform parameter-efficient fine-tuning (PEFT) of a large model. In
this study, we systematically search for a way to fine-tune models over an API
while keeping the labels private. We analyze the privacy of LoRA, a popular
approach for parameter-efficient fine-tuning when training over an API. Using
this analysis, we propose P$^3$EFT, a multi-party split learning algorithm that
takes advantage of existing PEFT properties to maintain privacy at a lower
performance overhead. To validate our algorithm, we fine-tune
DeBERTa-v2-XXLarge, Flan-T5 Large and LLaMA-2 7B using LoRA adapters on a range
of NLP tasks. We find that P$^3$EFT is competitive with existing
privacy-preserving methods in multi-party and two-party setups while having
higher accuracy.",2024-12-21,"Philip Zmushko, Marat Mansurov, Ruslan Svirschevski, Denis Kuznedelev, Max Ryabinin, Aleksandr Beznosikov",http://arxiv.org/pdf/2412.16669v1,cs.LG
Transformer-based toxin-protein interaction analysis prioritizes airborne particulate matter components with potential adverse health effects,"Air pollution, particularly airborne particulate matter (PM), poses a
significant threat to public health globally. It is crucial to comprehend the
association between PM-associated toxic components and their cellular targets
in humans to understand the mechanisms by which air pollution impacts health
and to establish causal relationships between air pollution and public health
consequences. Although many studies have explored the impact of PM on human
health, the understanding of the association between toxins and the associated
targets remain limited. Leveraging cutting-edge deep learning technologies, we
developed tipFormer (toxin-protein interaction prediction based on
transformer), a novel deep-learning tool for identifying toxic components
capable of penetrating human cells and instigating pathogenic biological
activities and signaling cascades. Experimental results show that tipFormer
effectively captures interactions between proteins and toxic components. It
incorporates dual pre-trained language models to encode protein sequences and
chemicals. It employs a convolutional encoder to assimilate the sequential
attributes of proteins and chemicals. It then introduces a learning module with
a cross-attention mechanism to decode and elucidate the multifaceted
interactions pivotal for the hotspots binding proteins and chemicals.
Experimental results show that tipFormer effectively captures interactions
between proteins and toxic components. This approach offers significant value
to air quality and toxicology researchers by allowing high-throughput
identification and prioritization of hazards. It supports more targeted
laboratory studies and field measurements, ultimately enhancing our
understanding of how air pollution impacts human health.",2024-12-21,"Yan Zhu, Shihao Wang, Yong Han, Yao Lu, Shulan Qiu, Ling Jin, Xiangdong Li, Weixiong Zhang",http://arxiv.org/pdf/2412.16664v1,cs.LG
An explainable operator approximation framework under the guideline of Green's function,"Traditional numerical methods, such as the finite element method and finite
volume method, adress partial differential equations (PDEs) by discretizing
them into algebraic equations and solving these iteratively. However, this
process is often computationally expensive and time-consuming. An alternative
approach involves transforming PDEs into integral equations and solving them
using Green's functions, which provide analytical solutions. Nevertheless,
deriving Green's functions analytically is a challenging and non-trivial task,
particularly for complex systems. In this study, we introduce a novel
framework, termed GreensONet, which is constructed based on the strucutre of
deep operator networks (DeepONet) to learn embedded Green's functions and solve
PDEs via Green's integral formulation. Specifically, the Trunk Net within
GreensONet is designed to approximate the unknown Green's functions of the
system, while the Branch Net are utilized to approximate the auxiliary
gradients of the Green's function. These outputs are subsequently employed to
perform surface integrals and volume integrals, incorporating user-defined
boundary conditions and source terms, respectively. The effectiveness of the
proposed framework is demonstrated on three types of PDEs in bounded domains:
3D heat conduction equations, reaction-diffusion equations, and Stokes
equations. Comparative results in these cases demonstrate that GreenONet's
accuracy and generalization ability surpass those of existing methods,
including Physics-Informed Neural Networks (PINN), DeepONet, Physics-Informed
DeepONet (PI-DeepONet), and Fourier Neural Operators (FNO).",2024-12-21,"Jianghang Gu, Ling Wen, Yuntian Chen, Shiyi Chen",http://arxiv.org/pdf/2412.16644v1,cs.LG
"Deep Learning for Spatio-Temporal Fusion in Land Surface Temperature Estimation: A Comprehensive Survey, Experimental Analysis, and Future Trends","The rapid advancements in satellite remote sensing have enhanced the
capability to monitor and analyze the Earth's surface. Among the many variables
captured through satellite sensors, Land Surface Temperature (LST) plays a
critical role in understanding key environmental processes. However, obtaining
high-resolution LST data remains a challenge, as satellite sensors often face a
trade-off between spatial and temporal resolutions. In response,
Spatio-Temporal Fusion (STF) has emerged as a powerful method to integrate two
satellite data sources, one providing high spatial but low temporal resolution,
and the other offering high temporal but low spatial resolution. Although a
range of STF techniques have been proposed, from traditional methods to
cutting-edge deep learning (DL) models, most have focused on surface
reflectance, with limited application to LST estimation. DL approaches, in
particular, show promise in improving the spatial and temporal resolutions of
LST by capturing complex, non-linear relationships between input and output LST
data. This paper offers a comprehensive review of the latest advancements in
DL-based STF techniques for LST estimation. We analyze key research
developments, mathematically formulate the STF problem, and introduce a novel
taxonomy for DL-based STF methods. Furthermore, we discuss the challenges faced
by current methods and highlight future research directions. In addition, we
present the first open-source benchmark STF dataset for LST estimation,
consisting of 51 pairs of MODIS-Landsat images spanning from 2013 to 2024. To
support our findings, we conduct extensive experiments on state-of-the-art
methods and present both quantitative and qualitative assessments. This is the
first survey paper focused on DL-based STF for LST estimation. We hope it
serves as a valuable reference for researchers and paves the way for future
research in this field.",2024-12-21,"Sofiane Bouaziz, Adel Hafiane, Raphael Canals, Rachid Nedjai",http://arxiv.org/pdf/2412.16631v1,cs.LG
Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for Optimized Structural Integrity,"Gaussian Splatting (GS) has emerged as a crucial technique for representing
discrete volumetric radiance fields. It leverages unique parametrization to
mitigate computational demands in scene optimization. This work introduces
Topology-Aware 3D Gaussian Splatting (Topology-GS), which addresses two key
limitations in current approaches: compromised pixel-level structural integrity
due to incomplete initial geometric coverage, and inadequate feature-level
integrity from insufficient topological constraints during optimization. To
overcome these limitations, Topology-GS incorporates a novel interpolation
strategy, Local Persistent Voronoi Interpolation (LPVI), and a topology-focused
regularization term based on persistent barcodes, named PersLoss. LPVI utilizes
persistent homology to guide adaptive interpolation, enhancing point coverage
in low-curvature areas while preserving topological structure. PersLoss aligns
the visual perceptual similarity of rendered images with ground truth by
constraining distances between their topological features. Comprehensive
experiments on three novel-view synthesis benchmarks demonstrate that
Topology-GS outperforms existing methods in terms of PSNR, SSIM, and LPIPS
metrics, while maintaining efficient memory usage. This study pioneers the
integration of topology with 3D-GS, laying the groundwork for future research
in this area.",2024-12-21,"Tianqi Shen, Shaohua Liu, Jiaqi Feng, Ziye Ma, Ning An",http://arxiv.org/pdf/2412.16619v3,cs.LG
Large Language Model Can Be a Foundation for Hidden Rationale-Based Retrieval,"Despite the recent advancement in Retrieval-Augmented Generation (RAG)
systems, most retrieval methodologies are often developed for factual
retrieval, which assumes query and positive documents are semantically similar.
In this paper, we instead propose and study a more challenging type of
retrieval task, called hidden rationale retrieval, in which query and document
are not similar but can be inferred by reasoning chains, logic relationships,
or empirical experiences. To address such problems, an instruction-tuned Large
language model (LLM) with a cross-encoder architecture could be a reasonable
choice. To further strengthen pioneering LLM-based retrievers, we design a
special instruction that transforms the retrieval task into a generative task
by prompting LLM to answer a binary-choice question. The model can be
fine-tuned with direct preference optimization (DPO). The framework is also
optimized for computational efficiency with no performance degradation. We name
this retrieval framework by RaHoRe and verify its zero-shot and fine-tuned
performance superiority on Emotional Support Conversation (ESC), compared with
previous retrieval works. Our study suggests the potential to employ LLM as a
foundation for a wider scope of retrieval tasks. Our codes, models, and
datasets are available on https://github.com/flyfree5/LaHoRe.",2024-12-21,"Luo Ji, Feixiang Guo, Teng Chen, Qingqing Gu, Xiaoyu Wang, Ningyuan Xi, Yihong Wang, Peng Yu, Yue Zhao, Hongyang Lei, Zhonglin Jiang, Yong Chen",http://arxiv.org/pdf/2412.16615v2,cs.LG
